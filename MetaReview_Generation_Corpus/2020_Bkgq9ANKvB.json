{"year": "2020", "forum": "Bkgq9ANKvB", "title": "Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates", "decision": "Reject", "meta_review": "Thank you very much for the detailed feedback to the reviewers, which helped us better understand your paper.\nThanks also for revising the manuscript significantly; many parts were indeed revised. \nHowever, due to the major revision, we find more points to be further discussed, which requires another round of reviews/rebuttals.\nFor this reason, we decided not to accept this paper.\nWe hope that the reviewers' comments are useful for improving the paper for potential future publication.\n", "reviews": [{"review_id": "Bkgq9ANKvB-0", "review_text": "This paper proposed peer loss function for learning with noisy labels, combining two areas learning with noisy labels and peer prediction together. The novelty and the significance are both borderline (or below). There are 4 major issues I have found so far. References: Looking at section 1.1 the related work, the references are a bit too old. While I am not sure about the area of peer prediction, in the area of learning with noisy labels (in a general sense), there were often 10 to 15 papers from every NeurIPS, ICML, ICLR and CVPR in recent years. The authors didn't survey the literature after 2016 at all... Nowadays most papers focus on sample selection/reweighting and label correction rather than loss correction in this area, but there are still many recent papers on designing more robust losses, see https://arxiv.org/abs/1805.07836 (NeurIPS 2018 spotlight), https://openreview.net/forum?id=rklB76EKPr and references therein. Note also that some label-noise related papers may not have the term label noise or noisy labels in the title, for example, https://openreview.net/forum?id=B1xWcj0qYm (ICLR 2019). Motivation: The motivating claim \"existing approaches require practitioners to specify noise rates\" is wrong... Many loss correction methods can estimate the transition matrix T (which is indispensable in any loss correction) without knowing the noise rate, when there are anchor points or even no anchor points in the noisy training data. See https://arxiv.org/abs/1906.00189 (NeurIPS 2019) and references therein. See also the public comment posted by Nontawat when a special symmetric condition is assumed on the surrogate loss function. Novelty: The paper introduced peer prediction, an area in computational economics and algorithmic game theory, to learning with noisy labels. This should be novel (to the best of my knowledge) and I like it! However, the obtained loss is very similar to the general loss correction approach, see https://arxiv.org/abs/1609.03683 (CVPR 2017 oral). This fact undermines the novelty of the paper, significantly. The authors should clarity the connection to and the difference from the loss correction approach. Significance: The proposed method focuses on binary classification, otherwise the paper will be much more significant! Note that the backward and forward corrections can both be applied to multi-class classification. Moreover, similar to many theory papers, the experiments are too simple, where single-hidden-layer neural networks were trained on 10 UCI benchmark datasets. I have to say this may not be enough for ICLR that should be a more deep learning conference.", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for detailed comments , and for providing pointers to the more recent literature . We want to clarify our motivation , novelty and significance . We do think the reviewer might have missed the main novelty and contribution of peer loss in that peer loss operates without the need of estimating the transition matrix T. Reference : We apologize for not surveying sufficiently the most recent results . We wanted to focus on comparing with the more classical results . We are working on an updated related work section based on the reviewer \u2019 s and Nontawat \u2019 s comments . We thank the reviewer for relevant pointers . Motivation : When we claim \u201c existing approaches require practitioners to specify noise rates \u201d , it includes the cases when the transition matrix T need to and can be estimated . Probably our claim was not clear - we wanted to say that these existing methods require * explicit * knowledge of T , so in practice , the practitioners will need to estimate these Ts and plug in . We are indeed aware of these line of work . But this was exactly one of our main motivations ! We felt this requirement of additional estimation steps might complicate the learning process , and the additional errors introduced via learning these parameters are concerning too . Peer loss does * not * require the knowledge or estimation of these Ts , and operates without the need of * specifying * the noise rates . We now start to think that a better way to position our paper is to say we contribute to \u201c learning with noisy labels without specifying the error rates \u201d . We do not claim that our results will challenge all existing works that require estimation of the transition matrices , we are simply trying to provide an alternative that operates without these estimates and when these estimates might not be reliable/available . Nonetheless , in our experiments , we provide evidences that even we give the surrogate loss function method ( e.g. , [ Natarajan et al 13 ] ) a perfect estimate of the noise rates , peer loss has shown advantages . We are glad the reviewer 2 in fact mentioned the challenge of estimating instance dependent transition matrix - part of the reason that we are excited about peer loss is that peer loss removes the need of estimating transition matrix and it opens up a new possibility in handling instance-dependent label noises . We acknowledge the comments , from both Nontawat and the reviewer , that for symmetric error rates case there exist methods that do not require the knowledge of error rates . We focus on asymmetric error rate cases . We are updating our draft and will clarify this . Novelty : Thank you for pointing out the CVPR 2017 paper ( we now cited ) . There seems to be a misunderstanding - unless we are mistaking , the proposed loss function and the correction procedure therein would require the transition matrix T to perform backward and forward corrections . In fact , the proposed loss correction method is derived from the surrogate loss function literature ( again , e.g. , [ Natarajan et al 13 ] ) , which is one of the baseline method we compare to . We want to emphasize again our operation of peer loss does * not * require this knowledge of T. We do not see any further connection , but would love to hear a more specific pointer if the reviewer disagrees . Please let us know , thanks . Our connection of using peer prediction in this learning with noisy label setting frees up the requirement of estimating the transition matrix , which we believe is novel ( this was acknowledged in other reviewer \u2019 s comments , including R3 and Nontawat \u2019 s ) . * Updated comments * : After reading the CVPR more carefully , the paper did mention the Hessian of ReLU is invariant to noises , so minimizing it will not need the specification of noise rates . First , this is not the same as the proposed loss correction approach , which is the focus of the paper ; Second , it is acknowledged in the paper that `` this does not provide any assurance on minima : indeed , stationary points may change location due to label noise . '' Significance : Again because of that peer loss does not require the knowledge of transition matrix , our method generalizes to multi-class labels easily . In an earlier draft we do provide a justification , but we wanted to stay focused with our binary setting , since our results are already dense . In the updated version , we will add the preliminary results back . * Update * : we have restructured our presentation , and have added an experiment on CIFAR-10 . We hope the above helps clarify our contributions . Thank you for reading our paper , and we are happy to discuss further ."}, {"review_id": "Bkgq9ANKvB-1", "review_text": "The paper studies the label noise problem with the motivation of without estimating the flip rate or transition matrix. This is an interesting direction for dealing with label noise. Most of the previous studies need either estimate the transition matrix or put restrictions on it, e.g., to be symmetric. A very related work to this paper: L_{DMI}: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise, where no restrictions have been made on the class-dependent transition matrix and the proposed method does not need to estimate the transition matrix. The authors may need to discuss the paper. The paper is not well-presented. I tried several times to go through the details but failed. The reasons are, e.g., (1) notation is not clear, e.g., R(X). \\tilde{Y}, and R have been abused. (2) Intuitive explanations are limited. (3) Lots of details can be put on the appendix, keeping the main part to have a strong and clear logic. It seems the theories of the paper depends on a very strong assumption, i.e., \"Suppose S(.) is able to elicit the Bayes optimal classifier f^*\". By quickly go through the proofs in the appendix, it seems there is a strong connection to the paper L_{DMI}. Some claims are strong. In the literature, with a mild assumption, the class-dependent transition matrix can accurately be estimated just from noisy data with theoretical guarantees. There are also methods proposed for this. Estimating class-dependent transition matrix is not a bottleneck. I think the challenge is about how to learn instance-dependent transition matrix. Overall, this is an interesting paper but needs to be improved.", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for his/her comments . We will clarify our contribution in comparing to L_ { DMI } , our assumptions made for the theoretical results , and our claims . Compare to L_ { DMI } : While we are working hard to compare us with L_ { DMI } and update our draft , we \u2019 d like to mention that the pointed article was submitted to arXiv on Sep 8 , 2019 , which was roughly two weeks before ICLR deadline . We feel that would be too fresh for us to include a thorough comparison - around the point , we have pretty much finalized our results and were focusing on writing up our draft . We have received a public comment on L_ { DMI } , and have commented publicly about the differences . We copy the responses at the end too . Since received the comment , we have looked into the codes shared by the authors of L_ { DMI } . We do realize the experiments presented therein largely focused on simple noise model , with noises being either added to only one class ( one single noise parameter , and this makes the problem much easier ! as one class has entirely clean labels , and the other class still has dominantly clean label ! ) , and symmetric noises ( different class labels have the same error rates , again one noise parameter ) . We do think our results provide evidence that peer loss is robust to different asymmetric noise settings . Our assumptions : Inly our conceptual results in Section 3 require S to elicit Bayes optimal classifier . Our main results on the specific forms of peer losses in Section 4 do * not * require any of such . Our theoretical results and properties hold for any hypothesis class . For instance , in Theorem 3,4 ( Sec 4.1 ) , Theorem 5 ( Sec 4.2 ) , the results are over a generic hypothesis class $ \\mathcal F $ . On our claim : Probably our claim was not clear - we wanted to say that these existing methods require * explicit * knowledge of T , so in practice , the practitioners will need to estimate these Ts and plug in . We are indeed aware of these line of work . But this was exactly one of our main motivations ! We felt this requirement of additional estimation steps might complicate the learning process , and the additional errors introduced via learning these parameters are concerning too . Peer loss does * not * require the knowledge or estimation of these Ts , and operates without the need of * specifying * the noise rates . We now start to think that a better way to position our paper is to say we contribute to \u201c learning with noisy labels without specifying the error rates \u201d . We do not claim that our results will challenge all existing works that require estimation of the transition matrices , we are simply trying to provide an alternative that operates without these estimates and when these estimates might not be reliable/available . Nonetheless , in our experiments , we provide evidence that peer loss has shown advantages , even we give the surrogate loss function method ( e.g. , [ Natarajan et al 13 ] ) a perfect estimate of the noise rates . We are glad the reviewer mentioned the challenge of estimating instance dependent transition matrix - part of the reason that we are excited about peer loss is that peer loss removes the need of estimating transition matrix and it opens up a new possibility in handling instance-dependent label noises . We hope the above clarifies our contribution . Happy to discuss further . \u2014\u2014\u2014\u2014\u2014 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Earlier public comments to the difference between our work and L_ { DMI } : - We aimed for a simple-to-optimize loss function that can easily adapt to existing ERM solutions . After the submission , we have observed other successes in adapting peer loss to more sophisticated neural network solutions , differentially private ERM , and semi-supervised learning etc . [ 1 ] seems to require estimations of a joint distribution matrix , and then to invoke computing a certain information theoretical measure . - With above concern , it is not entirely clear to us about the sample complexity requirement in [ 1 ] , and the sensitivity to noises in this estimation . We do provide calibration guarantees and generalization bounds . - We provide conditions when the loss functions are convex . In general , we do think computationally peer loss functions are easy to optimize with , in comparing to information theoretical measures . - We provide extensive comparisons with the state-of-the-art learning with noisy label approaches ( which even have access to the error rate information ) . - We provide theoretical guarantees for both Bayes ' optimal classifiers and general hypothesis classes , and establish a broad connection between learning with noisy labels with peer prediction score functions . It is true we have focused on CA , but the connection implies the possibility of applying other peer prediction functions ."}, {"review_id": "Bkgq9ANKvB-2", "review_text": "This paper studies the problem of learning classifiers from noisy data without specifying the noise rates. Inspired by the literature of peer prediction, the authors propose peer loss. First, a scoring function is introduced, minimizing which we can elicit the Bayes optimal classifier f*. Then the authors use the setting of CA to induces a scoring matrix, and then the peer loss. Moreover, this paper explores the theoretical properties of peer loss when p=0.5. In particular, the authors propose \\alpha weighted peer loss to provide strong theoretical guarantees of the proposed ERM framework. The calibration and generalization abilities are also discussed in section 4.3. Finally, empirical studies show that the propose peer loss indeed remedies the difficulty of determining the noise rates in noisy label learning. This paper is well written. The theoretical properties of the proposed peer loss are thoroughly explored. The motivation is rational with a good theoretical guarantee, i.e. Theorem 1. Moreover, the tackled problem, i.e. avoiding specifying the noise rates, is significant to the community. Nevertheless, Some parts of this paper may be confusing: - The computation of the scoring matrix delta is not that clear. Can the authors provide the detailed computation steps of the example? - In the proof of Lemma 6, can the authors provide a proof sketch of the equivalence of the last two equations? - Third, where is the definition of p? In the experiments, the authors propose to tuning the hyperparameter alpha. I would be appreciated if the authors provide the sensitivity experiments of alpha to show its fluence for the final prediction. Though I'm not that familiar with learning from noisy labels, I think it is a good paper and I suggest to accept.", "rating": "8: Accept", "reply_text": "We thank the reviewer for the comments , and for acknowledging our contribution of \u201c avoiding specifying the noise rates , is significant to the community. \u201d Below we clarify Detailed examples for computing Delta : First of all , we compute the marginals of $ f^ * $ and $ \\tilde { Y } $ : $ P \\bigl ( f^ * ( x ) =-1\\bigr ) = P \\bigl ( f^ * ( x ) =-1|Y=-1\\bigr ) P ( Y=-1 ) + P \\bigl ( f^ * ( x ) =-1|Y=+1\\bigr ) P ( Y=+1 ) = ( 1-e^ * _ { -1 } ) \\cdot 0.4 + e^ * _ { +1 } \\cdot 0.6 = 0.5 $ , and $ P \\bigl ( f^ * ( x ) =+1\\bigr ) = 1-P \\bigl ( f^ * ( x ) =-1\\bigr ) = 0.5 $ . For noisy labels : $ P \\bigl ( \\tilde { Y } =-1\\bigr ) = P \\bigl ( \\tilde { Y } =-1|Y=-1\\bigr ) P ( Y=-1 ) + P \\bigl ( \\tilde { Y } =-1|Y=+1\\bigr ) P ( Y=+1 ) = ( 1-e_ { -1 } ) \\cdot 0.4 + e_ { +1 } \\cdot 0.6 = 0.52 $ , and $ P \\bigl ( f^ * ( x ) =+1\\bigr ) = 1-P \\bigl ( f^ * ( x ) =-1\\bigr ) = 0.48 $ . For the joint distribution : $ P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) = P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1|Y=-1\\bigr ) P ( Y=-1 ) +P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1|Y=+1\\bigr ) P ( Y=+1 ) = ( 1-e^ * _ { -1 } ) ( 1-e_ { -1 } ) \\cdot 0.4+e^ * _ { +1 } \\cdot e_ { +1 } \\cdot 0.6 = 0.296 $ , and $ P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =+1\\bigr ) = P\\bigl ( f^ * ( X ) =-1\\bigr ) - P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) = 0.264 $ . Further $ P\\bigl ( f^ * ( X ) =+1 , \\tilde { Y } =-1\\bigr ) = P\\bigl ( \\tilde { Y } =-1\\bigr ) - P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) = 0.224 , $ $ ~P\\bigl ( f^ * ( X ) =+1 , \\tilde { Y } =+1\\bigr ) = P\\bigl ( f^ * ( X ) =+1\\bigr ) - P\\bigl ( f^ * ( X ) =+1 , \\tilde { Y } =-1\\bigr ) = 0.216 . $ With above , the entries in Delta can be computed easily , for instance $ $ \\Delta ( 1,1 ) =P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) - P\\bigl ( f^ * ( x ) =-1\\bigr ) \\cdot P\\bigl ( \\tilde { Y } = -1\\bigr ) = 0.296 - 0.5 * 0.52 = 0.036 $ $ We do notice a miscalculation in the draft ; we will update ! Lemma 6 : We apologize for the unclear last step - this was due to the reshuffle of results . We have used a partial results in Lemma 1 . We updated the draft : Since $ R^ * $ can be written as a function of $ X $ and $ Y $ , due to conditional independence between $ R $ and $ X $ ( conditional on $ Y $ ) , by chain rule $ ( R^ * =-1 , R=+1 ) = P ( Y=+1 ) ( 1-e_ { +1 } ) e^ * _ { +1 } + P ( Y=-1 ) e_ { -1 } \\cdot ( 1-e^ * _ { -1 } ) $ . Since $ $ P ( R=+1 ) = P ( Y=+1 ) ( 1-e_ { +1 } ) +P ( Y=-1 ) \\cdot e_ { -1 } , P ( R^ * =+1 ) = P ( Y=+1 ) ( 1-e^ * _ { +1 } ) +P ( Y=-1 ) \\cdot e^ * _ { -1 } $ $ We then have $ $ P ( R^ * =+1 , R=-1 ) - P ( R^ * =+1 ) P ( R=-1 ) =-P ( Y=+1 ) P ( Y=-1 ) ( 1-e_ { +1 } -e_ { -1 } ) ( 1-e^ * _ { +1 } -e^ * _ { -1 } ) . $ $ The above equation establishes the last equivalence . On p : We accidentally dropped the definition of $ p : = P ( Y=1 ) $ , which is simply the marginal distribution of true label Y . On sensitivity of alpha : Most of alphas are close to 1 . We thank the reviewer for the comment ; we will provide the details and discussion in the updated draft . We hope the above clarifies !"}], "0": {"review_id": "Bkgq9ANKvB-0", "review_text": "This paper proposed peer loss function for learning with noisy labels, combining two areas learning with noisy labels and peer prediction together. The novelty and the significance are both borderline (or below). There are 4 major issues I have found so far. References: Looking at section 1.1 the related work, the references are a bit too old. While I am not sure about the area of peer prediction, in the area of learning with noisy labels (in a general sense), there were often 10 to 15 papers from every NeurIPS, ICML, ICLR and CVPR in recent years. The authors didn't survey the literature after 2016 at all... Nowadays most papers focus on sample selection/reweighting and label correction rather than loss correction in this area, but there are still many recent papers on designing more robust losses, see https://arxiv.org/abs/1805.07836 (NeurIPS 2018 spotlight), https://openreview.net/forum?id=rklB76EKPr and references therein. Note also that some label-noise related papers may not have the term label noise or noisy labels in the title, for example, https://openreview.net/forum?id=B1xWcj0qYm (ICLR 2019). Motivation: The motivating claim \"existing approaches require practitioners to specify noise rates\" is wrong... Many loss correction methods can estimate the transition matrix T (which is indispensable in any loss correction) without knowing the noise rate, when there are anchor points or even no anchor points in the noisy training data. See https://arxiv.org/abs/1906.00189 (NeurIPS 2019) and references therein. See also the public comment posted by Nontawat when a special symmetric condition is assumed on the surrogate loss function. Novelty: The paper introduced peer prediction, an area in computational economics and algorithmic game theory, to learning with noisy labels. This should be novel (to the best of my knowledge) and I like it! However, the obtained loss is very similar to the general loss correction approach, see https://arxiv.org/abs/1609.03683 (CVPR 2017 oral). This fact undermines the novelty of the paper, significantly. The authors should clarity the connection to and the difference from the loss correction approach. Significance: The proposed method focuses on binary classification, otherwise the paper will be much more significant! Note that the backward and forward corrections can both be applied to multi-class classification. Moreover, similar to many theory papers, the experiments are too simple, where single-hidden-layer neural networks were trained on 10 UCI benchmark datasets. I have to say this may not be enough for ICLR that should be a more deep learning conference.", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for detailed comments , and for providing pointers to the more recent literature . We want to clarify our motivation , novelty and significance . We do think the reviewer might have missed the main novelty and contribution of peer loss in that peer loss operates without the need of estimating the transition matrix T. Reference : We apologize for not surveying sufficiently the most recent results . We wanted to focus on comparing with the more classical results . We are working on an updated related work section based on the reviewer \u2019 s and Nontawat \u2019 s comments . We thank the reviewer for relevant pointers . Motivation : When we claim \u201c existing approaches require practitioners to specify noise rates \u201d , it includes the cases when the transition matrix T need to and can be estimated . Probably our claim was not clear - we wanted to say that these existing methods require * explicit * knowledge of T , so in practice , the practitioners will need to estimate these Ts and plug in . We are indeed aware of these line of work . But this was exactly one of our main motivations ! We felt this requirement of additional estimation steps might complicate the learning process , and the additional errors introduced via learning these parameters are concerning too . Peer loss does * not * require the knowledge or estimation of these Ts , and operates without the need of * specifying * the noise rates . We now start to think that a better way to position our paper is to say we contribute to \u201c learning with noisy labels without specifying the error rates \u201d . We do not claim that our results will challenge all existing works that require estimation of the transition matrices , we are simply trying to provide an alternative that operates without these estimates and when these estimates might not be reliable/available . Nonetheless , in our experiments , we provide evidences that even we give the surrogate loss function method ( e.g. , [ Natarajan et al 13 ] ) a perfect estimate of the noise rates , peer loss has shown advantages . We are glad the reviewer 2 in fact mentioned the challenge of estimating instance dependent transition matrix - part of the reason that we are excited about peer loss is that peer loss removes the need of estimating transition matrix and it opens up a new possibility in handling instance-dependent label noises . We acknowledge the comments , from both Nontawat and the reviewer , that for symmetric error rates case there exist methods that do not require the knowledge of error rates . We focus on asymmetric error rate cases . We are updating our draft and will clarify this . Novelty : Thank you for pointing out the CVPR 2017 paper ( we now cited ) . There seems to be a misunderstanding - unless we are mistaking , the proposed loss function and the correction procedure therein would require the transition matrix T to perform backward and forward corrections . In fact , the proposed loss correction method is derived from the surrogate loss function literature ( again , e.g. , [ Natarajan et al 13 ] ) , which is one of the baseline method we compare to . We want to emphasize again our operation of peer loss does * not * require this knowledge of T. We do not see any further connection , but would love to hear a more specific pointer if the reviewer disagrees . Please let us know , thanks . Our connection of using peer prediction in this learning with noisy label setting frees up the requirement of estimating the transition matrix , which we believe is novel ( this was acknowledged in other reviewer \u2019 s comments , including R3 and Nontawat \u2019 s ) . * Updated comments * : After reading the CVPR more carefully , the paper did mention the Hessian of ReLU is invariant to noises , so minimizing it will not need the specification of noise rates . First , this is not the same as the proposed loss correction approach , which is the focus of the paper ; Second , it is acknowledged in the paper that `` this does not provide any assurance on minima : indeed , stationary points may change location due to label noise . '' Significance : Again because of that peer loss does not require the knowledge of transition matrix , our method generalizes to multi-class labels easily . In an earlier draft we do provide a justification , but we wanted to stay focused with our binary setting , since our results are already dense . In the updated version , we will add the preliminary results back . * Update * : we have restructured our presentation , and have added an experiment on CIFAR-10 . We hope the above helps clarify our contributions . Thank you for reading our paper , and we are happy to discuss further ."}, "1": {"review_id": "Bkgq9ANKvB-1", "review_text": "The paper studies the label noise problem with the motivation of without estimating the flip rate or transition matrix. This is an interesting direction for dealing with label noise. Most of the previous studies need either estimate the transition matrix or put restrictions on it, e.g., to be symmetric. A very related work to this paper: L_{DMI}: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise, where no restrictions have been made on the class-dependent transition matrix and the proposed method does not need to estimate the transition matrix. The authors may need to discuss the paper. The paper is not well-presented. I tried several times to go through the details but failed. The reasons are, e.g., (1) notation is not clear, e.g., R(X). \\tilde{Y}, and R have been abused. (2) Intuitive explanations are limited. (3) Lots of details can be put on the appendix, keeping the main part to have a strong and clear logic. It seems the theories of the paper depends on a very strong assumption, i.e., \"Suppose S(.) is able to elicit the Bayes optimal classifier f^*\". By quickly go through the proofs in the appendix, it seems there is a strong connection to the paper L_{DMI}. Some claims are strong. In the literature, with a mild assumption, the class-dependent transition matrix can accurately be estimated just from noisy data with theoretical guarantees. There are also methods proposed for this. Estimating class-dependent transition matrix is not a bottleneck. I think the challenge is about how to learn instance-dependent transition matrix. Overall, this is an interesting paper but needs to be improved.", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for his/her comments . We will clarify our contribution in comparing to L_ { DMI } , our assumptions made for the theoretical results , and our claims . Compare to L_ { DMI } : While we are working hard to compare us with L_ { DMI } and update our draft , we \u2019 d like to mention that the pointed article was submitted to arXiv on Sep 8 , 2019 , which was roughly two weeks before ICLR deadline . We feel that would be too fresh for us to include a thorough comparison - around the point , we have pretty much finalized our results and were focusing on writing up our draft . We have received a public comment on L_ { DMI } , and have commented publicly about the differences . We copy the responses at the end too . Since received the comment , we have looked into the codes shared by the authors of L_ { DMI } . We do realize the experiments presented therein largely focused on simple noise model , with noises being either added to only one class ( one single noise parameter , and this makes the problem much easier ! as one class has entirely clean labels , and the other class still has dominantly clean label ! ) , and symmetric noises ( different class labels have the same error rates , again one noise parameter ) . We do think our results provide evidence that peer loss is robust to different asymmetric noise settings . Our assumptions : Inly our conceptual results in Section 3 require S to elicit Bayes optimal classifier . Our main results on the specific forms of peer losses in Section 4 do * not * require any of such . Our theoretical results and properties hold for any hypothesis class . For instance , in Theorem 3,4 ( Sec 4.1 ) , Theorem 5 ( Sec 4.2 ) , the results are over a generic hypothesis class $ \\mathcal F $ . On our claim : Probably our claim was not clear - we wanted to say that these existing methods require * explicit * knowledge of T , so in practice , the practitioners will need to estimate these Ts and plug in . We are indeed aware of these line of work . But this was exactly one of our main motivations ! We felt this requirement of additional estimation steps might complicate the learning process , and the additional errors introduced via learning these parameters are concerning too . Peer loss does * not * require the knowledge or estimation of these Ts , and operates without the need of * specifying * the noise rates . We now start to think that a better way to position our paper is to say we contribute to \u201c learning with noisy labels without specifying the error rates \u201d . We do not claim that our results will challenge all existing works that require estimation of the transition matrices , we are simply trying to provide an alternative that operates without these estimates and when these estimates might not be reliable/available . Nonetheless , in our experiments , we provide evidence that peer loss has shown advantages , even we give the surrogate loss function method ( e.g. , [ Natarajan et al 13 ] ) a perfect estimate of the noise rates . We are glad the reviewer mentioned the challenge of estimating instance dependent transition matrix - part of the reason that we are excited about peer loss is that peer loss removes the need of estimating transition matrix and it opens up a new possibility in handling instance-dependent label noises . We hope the above clarifies our contribution . Happy to discuss further . \u2014\u2014\u2014\u2014\u2014 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Earlier public comments to the difference between our work and L_ { DMI } : - We aimed for a simple-to-optimize loss function that can easily adapt to existing ERM solutions . After the submission , we have observed other successes in adapting peer loss to more sophisticated neural network solutions , differentially private ERM , and semi-supervised learning etc . [ 1 ] seems to require estimations of a joint distribution matrix , and then to invoke computing a certain information theoretical measure . - With above concern , it is not entirely clear to us about the sample complexity requirement in [ 1 ] , and the sensitivity to noises in this estimation . We do provide calibration guarantees and generalization bounds . - We provide conditions when the loss functions are convex . In general , we do think computationally peer loss functions are easy to optimize with , in comparing to information theoretical measures . - We provide extensive comparisons with the state-of-the-art learning with noisy label approaches ( which even have access to the error rate information ) . - We provide theoretical guarantees for both Bayes ' optimal classifiers and general hypothesis classes , and establish a broad connection between learning with noisy labels with peer prediction score functions . It is true we have focused on CA , but the connection implies the possibility of applying other peer prediction functions ."}, "2": {"review_id": "Bkgq9ANKvB-2", "review_text": "This paper studies the problem of learning classifiers from noisy data without specifying the noise rates. Inspired by the literature of peer prediction, the authors propose peer loss. First, a scoring function is introduced, minimizing which we can elicit the Bayes optimal classifier f*. Then the authors use the setting of CA to induces a scoring matrix, and then the peer loss. Moreover, this paper explores the theoretical properties of peer loss when p=0.5. In particular, the authors propose \\alpha weighted peer loss to provide strong theoretical guarantees of the proposed ERM framework. The calibration and generalization abilities are also discussed in section 4.3. Finally, empirical studies show that the propose peer loss indeed remedies the difficulty of determining the noise rates in noisy label learning. This paper is well written. The theoretical properties of the proposed peer loss are thoroughly explored. The motivation is rational with a good theoretical guarantee, i.e. Theorem 1. Moreover, the tackled problem, i.e. avoiding specifying the noise rates, is significant to the community. Nevertheless, Some parts of this paper may be confusing: - The computation of the scoring matrix delta is not that clear. Can the authors provide the detailed computation steps of the example? - In the proof of Lemma 6, can the authors provide a proof sketch of the equivalence of the last two equations? - Third, where is the definition of p? In the experiments, the authors propose to tuning the hyperparameter alpha. I would be appreciated if the authors provide the sensitivity experiments of alpha to show its fluence for the final prediction. Though I'm not that familiar with learning from noisy labels, I think it is a good paper and I suggest to accept.", "rating": "8: Accept", "reply_text": "We thank the reviewer for the comments , and for acknowledging our contribution of \u201c avoiding specifying the noise rates , is significant to the community. \u201d Below we clarify Detailed examples for computing Delta : First of all , we compute the marginals of $ f^ * $ and $ \\tilde { Y } $ : $ P \\bigl ( f^ * ( x ) =-1\\bigr ) = P \\bigl ( f^ * ( x ) =-1|Y=-1\\bigr ) P ( Y=-1 ) + P \\bigl ( f^ * ( x ) =-1|Y=+1\\bigr ) P ( Y=+1 ) = ( 1-e^ * _ { -1 } ) \\cdot 0.4 + e^ * _ { +1 } \\cdot 0.6 = 0.5 $ , and $ P \\bigl ( f^ * ( x ) =+1\\bigr ) = 1-P \\bigl ( f^ * ( x ) =-1\\bigr ) = 0.5 $ . For noisy labels : $ P \\bigl ( \\tilde { Y } =-1\\bigr ) = P \\bigl ( \\tilde { Y } =-1|Y=-1\\bigr ) P ( Y=-1 ) + P \\bigl ( \\tilde { Y } =-1|Y=+1\\bigr ) P ( Y=+1 ) = ( 1-e_ { -1 } ) \\cdot 0.4 + e_ { +1 } \\cdot 0.6 = 0.52 $ , and $ P \\bigl ( f^ * ( x ) =+1\\bigr ) = 1-P \\bigl ( f^ * ( x ) =-1\\bigr ) = 0.48 $ . For the joint distribution : $ P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) = P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1|Y=-1\\bigr ) P ( Y=-1 ) +P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1|Y=+1\\bigr ) P ( Y=+1 ) = ( 1-e^ * _ { -1 } ) ( 1-e_ { -1 } ) \\cdot 0.4+e^ * _ { +1 } \\cdot e_ { +1 } \\cdot 0.6 = 0.296 $ , and $ P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =+1\\bigr ) = P\\bigl ( f^ * ( X ) =-1\\bigr ) - P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) = 0.264 $ . Further $ P\\bigl ( f^ * ( X ) =+1 , \\tilde { Y } =-1\\bigr ) = P\\bigl ( \\tilde { Y } =-1\\bigr ) - P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) = 0.224 , $ $ ~P\\bigl ( f^ * ( X ) =+1 , \\tilde { Y } =+1\\bigr ) = P\\bigl ( f^ * ( X ) =+1\\bigr ) - P\\bigl ( f^ * ( X ) =+1 , \\tilde { Y } =-1\\bigr ) = 0.216 . $ With above , the entries in Delta can be computed easily , for instance $ $ \\Delta ( 1,1 ) =P\\bigl ( f^ * ( X ) =-1 , \\tilde { Y } =-1\\bigr ) - P\\bigl ( f^ * ( x ) =-1\\bigr ) \\cdot P\\bigl ( \\tilde { Y } = -1\\bigr ) = 0.296 - 0.5 * 0.52 = 0.036 $ $ We do notice a miscalculation in the draft ; we will update ! Lemma 6 : We apologize for the unclear last step - this was due to the reshuffle of results . We have used a partial results in Lemma 1 . We updated the draft : Since $ R^ * $ can be written as a function of $ X $ and $ Y $ , due to conditional independence between $ R $ and $ X $ ( conditional on $ Y $ ) , by chain rule $ ( R^ * =-1 , R=+1 ) = P ( Y=+1 ) ( 1-e_ { +1 } ) e^ * _ { +1 } + P ( Y=-1 ) e_ { -1 } \\cdot ( 1-e^ * _ { -1 } ) $ . Since $ $ P ( R=+1 ) = P ( Y=+1 ) ( 1-e_ { +1 } ) +P ( Y=-1 ) \\cdot e_ { -1 } , P ( R^ * =+1 ) = P ( Y=+1 ) ( 1-e^ * _ { +1 } ) +P ( Y=-1 ) \\cdot e^ * _ { -1 } $ $ We then have $ $ P ( R^ * =+1 , R=-1 ) - P ( R^ * =+1 ) P ( R=-1 ) =-P ( Y=+1 ) P ( Y=-1 ) ( 1-e_ { +1 } -e_ { -1 } ) ( 1-e^ * _ { +1 } -e^ * _ { -1 } ) . $ $ The above equation establishes the last equivalence . On p : We accidentally dropped the definition of $ p : = P ( Y=1 ) $ , which is simply the marginal distribution of true label Y . On sensitivity of alpha : Most of alphas are close to 1 . We thank the reviewer for the comment ; we will provide the details and discussion in the updated draft . We hope the above clarifies !"}}