{"year": "2017", "forum": "HyTqHL5xg", "title": "Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data", "decision": "Accept (Poster)", "meta_review": "The paper provides a clear application of variational methods for learning non-linear state-space models, which is of increasing interest, and of general relevance to the community.", "reviews": [{"review_id": "HyTqHL5xg-0", "review_text": "This is mainly a (well-written) toy application paper. It explains SGVB can be applied to state-space models. The main idea is to cast a state-space model as a deterministic temporal transformation, with innovation variables acting as latent variables. The prior over the innovation variables is not a function of time. Approximate inference is performed over these innovation variables, rather the states. This is a solution to a fairly specific problem (e.g. it doesn't discuss how priors over the beta's can depend on the past), but an interesting application nonetheless. The ideas could have been explained more compactly and more clearly; the paper dives into specifics fairly quickly, which seems a missed opportunity. My compliments for the amount of detail put in the paper and appendix. The experiments are on toy examples, but show promise. - Section 2.1: \u201cIn our notation, one would typically set beta_t = w_t, though other variants are possible\u201d -> It\u2019s probably better to clarify that if F_t and B_t and not in beta_t, they are not given a Bayesian treatment (but e.g. merely optimized). - Section 2.2 last paragraph: \u201cA key contribution is [\u2026] forcing the latent space to fit the transition\u201d. This seems rather trivial to achieve. - Eq 9: \u201cThis interpretation implies the factorization of the recognition model:..\u201d The factorization is not implied anywhere: i.e. you could in principle use q(beta|x) = q(w|x,v)q(v)", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your feedback . We would like to address several points raised in your review : 1 . We are not sure whether we agree on what you call a \u201c fairly specific problem \u201d . System identification is * not * a fairly specific problem . On the contrary , it remains an unsolved challenge , and is of utter importance in Reinforcement Learning/Control of , e.g. , robots . We agree that this can be stated more clearly , and we have adjusted the introduction accordingly . 2.Thank you for pointing out the glitch in section 2.1 . In order to avoid misunderstandings , we would like to point out that F_t and B_t are explicitly given a Bayesian treatment in our algorithm . As section 3.3 shows , the locally linear matrices are gathered in v_t , which is itself a component of \\beta_t . This is a difference to classical filtering-only like the Kalman filter does . 3.It is unclear to us why forcing the latent space to fit the transition is trivial . To the best of our knowledge , previous approaches have tried the opposite direction , and only the reparametrization enabled us to reverse the direction . Our experiments confirm that this greatly improves model performance . To elaborate , we refer to our answer given to a pre-review question by Reviewer3 , part of which has found its way into the revised paper : \u201c We set off with an important observation : Previous methods such as DKF aim at fitting the latent dynamics to a latent state z that is beneficial for reconstruction . This encourages learning of a stationary auto-encoder with focus of extracting as much from a single image as possible , as we see with DKF . Importantly , velocity is not necessary for excellent reconstruction -- -after all , the original data set renderer from ground truth latents to observations discards velocity . Once the latent states are set , it is hard to adjust the transition to them . This would require changing the latent states slightly , and that comes at a cost of decreasing the reconstruction ( temporarily ) . The learning algorithm is stuck in a local optimum with good compression only . The model choice prohibits finding the global optimum with a good generative model via optimization , not the problem itself. \u201d We have adjusted our related work section to clearly state this more clearly . 4.Indeed , the factorization of the posterior is not \u201c implied \u201d in a rigorous mathematical sense , just that it is a natural factorization given the interpretation of v and w , respectively . We have adapted the respective section accordingly ."}, {"review_id": "HyTqHL5xg-1", "review_text": "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the latent state to maintain all of the information relevant to predictions, rather than leaving it implicit in the observations. Experiments show the proposed method is better able to learn meaningful representations of sequence data. The proposed DVBF is well motivated, and for the most part the presentation is clear. The experiments show interesting results on illustrative toy examples. I think the contribution is interesting and potentially useful, so I\u2019d recommend acceptance. The SVAE method of Johnson et al. (2016) deserves more discussion than the two sentences devoted to it, since the method seems pretty closely related. Like the DVBF, the SVAE imposes a Markovianity assumption, and it is able to handle similar kinds of problems. From what I understand, the most important algorithmic difference is that the SVAE q network predicts potentials, whereas the DVBF q network predicts innovations. What are the tradeoffs between the two? Section 2.2 says they do the latter in the interest of solving control-related tasks, but I\u2019m not clear why this follows. Is there a reason SVAEs don\u2019t meet all the desiderata mentioned at the end of the Introduction? Since the SVAE code is publicly available, one could probably compare against it in the experiments. I\u2019m a bit confused about the role of uncertainty about v. In principle, one could estimate the transition parameters by maximum likelihood (i.e. fitting a point estimate of v), but this isn\u2019t what\u2019s done. Instead, v is integrated out as part of the marginal likelihood, which I interpret as giving the flexibility to model different dynamics for different sequences. But if this is the case, then shouldn\u2019t the q distribution for v depend on the data, rather than being data-independent as in Eqn. (9)? ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your kind feedback . We would like to address two points you raised in your review : 1 . Relation to SVAE : The main overlap between SVAE and DVBF is that graphical models are exploited . One of the key abilities we are trying to achieve when using SGVB is efficient inference , a feature where DVBF and SVAE differ significantly . SVAE aims to solve inference on arbitrary graphical models ( which needn \u2019 t be Markovian ) through message-passing subroutines . We indeed ran their code on their given example , essentially a simplified version of Bouncing Ball ( with 1 ground truth latent instead of 4 ) . As of now , it is written in pure python ( including automatic differentiation of pure python code ) , it is non-trivial to port to , e.g. , tensorflow . The current implementation , however , prohibited application to our data set -- -even the simple example took several days to train , as compared to a few hours for DVBF on our more intricate data set . DVBF aims to solve inference for and of dynamical systems , a very particular but nonetheless important subclass of graphical models . Hence , we can exploit streamlined architectures for follow-up control-related tasks , which allow \u201c real-time \u201d inference . We make it possible to apply the recently very successful approximate inference algorithms via neural architectures . On this very important subclass , we show unprecedented results . 2.Weight uncertainty on v : Firstly , we would like to stress that it is up to user and application which parts of the transition are assigned to v or w , respectively . The locally linear transition in section 3.3 is only one possible instance . In this particular case , it works as follows : v gathers M matrix triplets ( A^ ( i ) , B^ ( i ) , C^ ( i ) ) . You can consider these as M basic linear systems , independent of a specific data point . It is possible to learn them via maximum likelihood , as you suggest . To prevent overfitting , however , they are regularized in a Bayesian way as in , e.g. , [ * ] . As you also point out correctly , it makes sense to have the dynamics for a specific sequence be dependent on the sequence . This is achieved by making the mixture weights \\alpha data-dependent ( and hence part of w ) . Long story short : We learn probabilistically regularized , data-independent basic systems , and then mix them depending on data . [ * ] Blundell et al. , 2015 , Weight Uncertainty in Neural Networks , http : //jmlr.org/proceedings/papers/v37/blundell15.pdf"}, {"review_id": "HyTqHL5xg-2", "review_text": "The paper proposes to use the very standard SVGB in a sequential setting like several previous works did. However, they proposes to have a clear state space constraints similar to Linear Gaussian Models: Markovian latent space and conditional independence of observed variables given the latent variables. However the model is in this case non-linear. These assumptions are well motivated by the goal of having meaningful latent variables. The experiments are interesting but I'm still not completely convinced by the regression results in Figure 3, namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function. Also, why isn't the model from (Watter et al., 2015) not included ? After rereading I'm not sure I understand why the coordinates should be combined in a 3x3 checkerboard as said in Figure 5a. Then paper is well motivated and the resulting model is novel enough, the bouncing ball experiment is not quite convincing, especially in prediction, as the problem is fully determined by its initial velocity and position. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your feedback . We would like to address several points raised in your review : - Linear Regression : As footnote 3 indicates , we did test nonlinear regression via neural networks from inferred latent states to ground truth latents . The result was the same : Angle reconstruction works for both , velocity reconstruction only for DVBF . We chose linear regression because a ) it allows for looking at and reporting measures such as goodness of fit in a way neural networks can not , and b ) the fact that a simple linear regression allows for perfect recovery indicates the strength of the latent embedding found by DVBF . - E2C ( Watter et al. , 2015 ) : E2C crucially depends on the user stacking data such that all temporal information is present in one sample . While technically working on raw pixels , this enhancement of data significantly simplifies finding temporal derivatives . E2C requires a qualitatively different data set to work on , to the extent that E2C can not serve as a fair baseline . As stated in our paper , the E2C objective function is not rigorously implemented within the SGVB framework . It averages two loosely connected lower bounds and adds another KL term with the sole purpose of regularizing the transition . For DVBF the transition is a natural part of the lower bound , which fixes this theoretical flaw . E2C works on data that uniformly samples control * and * state space . This assumption is very strong in itself . Moreover , such data acquisition is virtually impossible for any real application as it would require a priori insight into the control of the system . It has not been shown that E2C works in a more realistic data regime , while DVBF does . - Bouncing Ball/Checkerboard : Firstly , please note that there are random control inputs present , so that the trajectory is not fully determined by the initial state . Moreover , there is noise present in the simulator . Apart from that , our algorithm relies on the system being deterministic up to process noise and given control inputs , and identify the underlying system . Bouncing Ball is no more or less random than most control problems in , e.g. , OpenAI Gym . Secondly , the checkerboard is quite a remarkable result . It is designed to show how well DVBF reconstructs the unknown ground truth : The ground truth position of the ball lies within the 2D unit square , the bounding box . Again , we wanted to visualize how ground truth reappears in the learned latent states . To do so , we wanted to show how the ground truth bounding box is warped into the latent space . To this end , we partitioned ( discretized ) the ground truth unit square into a regular 3x3 checkerboard with respective coloring . Remarkably , there is almost no warping present ! That means that DVBF not only learned to extract the 2D position from the 256 pixels , but also aligned them in two dimensions of the latent space almost exactly as they do in the physical system . The algorithm does the exact same pixel-to-2D inference that a human observer automatically does when we looking at the image -- -which is why at first glance it seems this would be an easy task , which it isn \u2019 t ."}], "0": {"review_id": "HyTqHL5xg-0", "review_text": "This is mainly a (well-written) toy application paper. It explains SGVB can be applied to state-space models. The main idea is to cast a state-space model as a deterministic temporal transformation, with innovation variables acting as latent variables. The prior over the innovation variables is not a function of time. Approximate inference is performed over these innovation variables, rather the states. This is a solution to a fairly specific problem (e.g. it doesn't discuss how priors over the beta's can depend on the past), but an interesting application nonetheless. The ideas could have been explained more compactly and more clearly; the paper dives into specifics fairly quickly, which seems a missed opportunity. My compliments for the amount of detail put in the paper and appendix. The experiments are on toy examples, but show promise. - Section 2.1: \u201cIn our notation, one would typically set beta_t = w_t, though other variants are possible\u201d -> It\u2019s probably better to clarify that if F_t and B_t and not in beta_t, they are not given a Bayesian treatment (but e.g. merely optimized). - Section 2.2 last paragraph: \u201cA key contribution is [\u2026] forcing the latent space to fit the transition\u201d. This seems rather trivial to achieve. - Eq 9: \u201cThis interpretation implies the factorization of the recognition model:..\u201d The factorization is not implied anywhere: i.e. you could in principle use q(beta|x) = q(w|x,v)q(v)", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your feedback . We would like to address several points raised in your review : 1 . We are not sure whether we agree on what you call a \u201c fairly specific problem \u201d . System identification is * not * a fairly specific problem . On the contrary , it remains an unsolved challenge , and is of utter importance in Reinforcement Learning/Control of , e.g. , robots . We agree that this can be stated more clearly , and we have adjusted the introduction accordingly . 2.Thank you for pointing out the glitch in section 2.1 . In order to avoid misunderstandings , we would like to point out that F_t and B_t are explicitly given a Bayesian treatment in our algorithm . As section 3.3 shows , the locally linear matrices are gathered in v_t , which is itself a component of \\beta_t . This is a difference to classical filtering-only like the Kalman filter does . 3.It is unclear to us why forcing the latent space to fit the transition is trivial . To the best of our knowledge , previous approaches have tried the opposite direction , and only the reparametrization enabled us to reverse the direction . Our experiments confirm that this greatly improves model performance . To elaborate , we refer to our answer given to a pre-review question by Reviewer3 , part of which has found its way into the revised paper : \u201c We set off with an important observation : Previous methods such as DKF aim at fitting the latent dynamics to a latent state z that is beneficial for reconstruction . This encourages learning of a stationary auto-encoder with focus of extracting as much from a single image as possible , as we see with DKF . Importantly , velocity is not necessary for excellent reconstruction -- -after all , the original data set renderer from ground truth latents to observations discards velocity . Once the latent states are set , it is hard to adjust the transition to them . This would require changing the latent states slightly , and that comes at a cost of decreasing the reconstruction ( temporarily ) . The learning algorithm is stuck in a local optimum with good compression only . The model choice prohibits finding the global optimum with a good generative model via optimization , not the problem itself. \u201d We have adjusted our related work section to clearly state this more clearly . 4.Indeed , the factorization of the posterior is not \u201c implied \u201d in a rigorous mathematical sense , just that it is a natural factorization given the interpretation of v and w , respectively . We have adapted the respective section accordingly ."}, "1": {"review_id": "HyTqHL5xg-1", "review_text": "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the latent state to maintain all of the information relevant to predictions, rather than leaving it implicit in the observations. Experiments show the proposed method is better able to learn meaningful representations of sequence data. The proposed DVBF is well motivated, and for the most part the presentation is clear. The experiments show interesting results on illustrative toy examples. I think the contribution is interesting and potentially useful, so I\u2019d recommend acceptance. The SVAE method of Johnson et al. (2016) deserves more discussion than the two sentences devoted to it, since the method seems pretty closely related. Like the DVBF, the SVAE imposes a Markovianity assumption, and it is able to handle similar kinds of problems. From what I understand, the most important algorithmic difference is that the SVAE q network predicts potentials, whereas the DVBF q network predicts innovations. What are the tradeoffs between the two? Section 2.2 says they do the latter in the interest of solving control-related tasks, but I\u2019m not clear why this follows. Is there a reason SVAEs don\u2019t meet all the desiderata mentioned at the end of the Introduction? Since the SVAE code is publicly available, one could probably compare against it in the experiments. I\u2019m a bit confused about the role of uncertainty about v. In principle, one could estimate the transition parameters by maximum likelihood (i.e. fitting a point estimate of v), but this isn\u2019t what\u2019s done. Instead, v is integrated out as part of the marginal likelihood, which I interpret as giving the flexibility to model different dynamics for different sequences. But if this is the case, then shouldn\u2019t the q distribution for v depend on the data, rather than being data-independent as in Eqn. (9)? ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your kind feedback . We would like to address two points you raised in your review : 1 . Relation to SVAE : The main overlap between SVAE and DVBF is that graphical models are exploited . One of the key abilities we are trying to achieve when using SGVB is efficient inference , a feature where DVBF and SVAE differ significantly . SVAE aims to solve inference on arbitrary graphical models ( which needn \u2019 t be Markovian ) through message-passing subroutines . We indeed ran their code on their given example , essentially a simplified version of Bouncing Ball ( with 1 ground truth latent instead of 4 ) . As of now , it is written in pure python ( including automatic differentiation of pure python code ) , it is non-trivial to port to , e.g. , tensorflow . The current implementation , however , prohibited application to our data set -- -even the simple example took several days to train , as compared to a few hours for DVBF on our more intricate data set . DVBF aims to solve inference for and of dynamical systems , a very particular but nonetheless important subclass of graphical models . Hence , we can exploit streamlined architectures for follow-up control-related tasks , which allow \u201c real-time \u201d inference . We make it possible to apply the recently very successful approximate inference algorithms via neural architectures . On this very important subclass , we show unprecedented results . 2.Weight uncertainty on v : Firstly , we would like to stress that it is up to user and application which parts of the transition are assigned to v or w , respectively . The locally linear transition in section 3.3 is only one possible instance . In this particular case , it works as follows : v gathers M matrix triplets ( A^ ( i ) , B^ ( i ) , C^ ( i ) ) . You can consider these as M basic linear systems , independent of a specific data point . It is possible to learn them via maximum likelihood , as you suggest . To prevent overfitting , however , they are regularized in a Bayesian way as in , e.g. , [ * ] . As you also point out correctly , it makes sense to have the dynamics for a specific sequence be dependent on the sequence . This is achieved by making the mixture weights \\alpha data-dependent ( and hence part of w ) . Long story short : We learn probabilistically regularized , data-independent basic systems , and then mix them depending on data . [ * ] Blundell et al. , 2015 , Weight Uncertainty in Neural Networks , http : //jmlr.org/proceedings/papers/v37/blundell15.pdf"}, "2": {"review_id": "HyTqHL5xg-2", "review_text": "The paper proposes to use the very standard SVGB in a sequential setting like several previous works did. However, they proposes to have a clear state space constraints similar to Linear Gaussian Models: Markovian latent space and conditional independence of observed variables given the latent variables. However the model is in this case non-linear. These assumptions are well motivated by the goal of having meaningful latent variables. The experiments are interesting but I'm still not completely convinced by the regression results in Figure 3, namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function. Also, why isn't the model from (Watter et al., 2015) not included ? After rereading I'm not sure I understand why the coordinates should be combined in a 3x3 checkerboard as said in Figure 5a. Then paper is well motivated and the resulting model is novel enough, the bouncing ball experiment is not quite convincing, especially in prediction, as the problem is fully determined by its initial velocity and position. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your feedback . We would like to address several points raised in your review : - Linear Regression : As footnote 3 indicates , we did test nonlinear regression via neural networks from inferred latent states to ground truth latents . The result was the same : Angle reconstruction works for both , velocity reconstruction only for DVBF . We chose linear regression because a ) it allows for looking at and reporting measures such as goodness of fit in a way neural networks can not , and b ) the fact that a simple linear regression allows for perfect recovery indicates the strength of the latent embedding found by DVBF . - E2C ( Watter et al. , 2015 ) : E2C crucially depends on the user stacking data such that all temporal information is present in one sample . While technically working on raw pixels , this enhancement of data significantly simplifies finding temporal derivatives . E2C requires a qualitatively different data set to work on , to the extent that E2C can not serve as a fair baseline . As stated in our paper , the E2C objective function is not rigorously implemented within the SGVB framework . It averages two loosely connected lower bounds and adds another KL term with the sole purpose of regularizing the transition . For DVBF the transition is a natural part of the lower bound , which fixes this theoretical flaw . E2C works on data that uniformly samples control * and * state space . This assumption is very strong in itself . Moreover , such data acquisition is virtually impossible for any real application as it would require a priori insight into the control of the system . It has not been shown that E2C works in a more realistic data regime , while DVBF does . - Bouncing Ball/Checkerboard : Firstly , please note that there are random control inputs present , so that the trajectory is not fully determined by the initial state . Moreover , there is noise present in the simulator . Apart from that , our algorithm relies on the system being deterministic up to process noise and given control inputs , and identify the underlying system . Bouncing Ball is no more or less random than most control problems in , e.g. , OpenAI Gym . Secondly , the checkerboard is quite a remarkable result . It is designed to show how well DVBF reconstructs the unknown ground truth : The ground truth position of the ball lies within the 2D unit square , the bounding box . Again , we wanted to visualize how ground truth reappears in the learned latent states . To do so , we wanted to show how the ground truth bounding box is warped into the latent space . To this end , we partitioned ( discretized ) the ground truth unit square into a regular 3x3 checkerboard with respective coloring . Remarkably , there is almost no warping present ! That means that DVBF not only learned to extract the 2D position from the 256 pixels , but also aligned them in two dimensions of the latent space almost exactly as they do in the physical system . The algorithm does the exact same pixel-to-2D inference that a human observer automatically does when we looking at the image -- -which is why at first glance it seems this would be an easy task , which it isn \u2019 t ."}}