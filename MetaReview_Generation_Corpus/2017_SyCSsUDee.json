{"year": "2017", "forum": "SyCSsUDee", "title": "Semantic Noise Modeling for Better Representation Learning", "decision": "Reject", "meta_review": "The reviewers all expressed concerns with the technical quality of this work. In particular, the reviewers are concerned that ignoring certain entropy terms in the objective is problematic and would require significantly more justification theoretically and empirically. The reviewers believe that the authors had to resort to unjustified tricks such as adding noise in order to compensate for the missing terms in the objective. Some of the reviewers also had concerns with the choice of experiments, expressing that the authors did not choose the right baseline comparisons to compare to (e.g. convolutional networks vs. fully connected networks on MNIST). Hopefully the thorough feedback and lengthly discussion, along with the authors' responses (both in the text and additions to the paper and appendix), will lead to a stronger submission to a future conference.", "reviews": [{"review_id": "SyCSsUDee-0", "review_text": "The paper introduces supervised deep learning with layer-wise reconstruction loss (in addition to the supervised loss) and class-conditional semantic additive noise for better representation learning. Total correlation measure and additional insights from auto-encoder are used to derive layer-wise reconstruction loss and is further combined with supervised loss. When combining with supervised loss the class-conditional additive noise model is proposed, which showed consistent improvement over the baseline model. Experiments on MNIST and CIFAR-10 datasets while changing the number of training examples per class are done extensively. The derivation of Equation (3) from total correlation is hacky. Moreover, assuming graphical model between X, Y and Z, it should be more carefully derived to estimate H(X|Z) and H(Z|Y). The current proposal, encoding Z and Y from X and decoding from encoded representation is not really well justified. Is \\sigma in Equation 8 trainable parameter or hyperparameter? If it is trainable how it is trained? If it is not, how are they set? Does j correspond to one of the class? The proposed feature augmentation sounds like simply adding gaussian noise to the pre-softmax neurons. That being said, the proposed method is not different from gaussian dropout (Wang and Manning, ICML 2013) but applied on different layers. In addition, there is a missing reference (DisturbLabel: Regularizing CNN on the Loss Layer, CVPR 2016) that applied synthetic noise process on the loss layer. Experiments should be done for multiple times with different random subsets and authors should provide mean and standard error. Overall, I believe the proposed method is not very well justified and has limited novelty. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "First of all , we have made overall revisions to the manuscript including detailed mathematical derivations for the base model ( Section 2.1 with Appendix_A1 ) and clear explanations of the proposed noise modeling method ( Section 2.2 ) . > > From reviewer : The paper introduces supervised deep learning with layer-wise reconstruction loss ( in addition to the supervised loss ) and class-conditional semantic additive noise for better representation learning . Total correlation measure and additional insights from auto-encoder are used to derive layer-wise reconstruction loss and is further combined with supervised loss . When combining with supervised loss the class-conditional additive noise model is proposed , which showed consistent improvement over the baseline model . Experiments on MNIST and CIFAR-10 datasets while changing the number of training examples per class are done extensively . > > To reviewer : Yes , we applied hierarchical reconstruction losses derived from hierarchical conditional entropies which is obtained from the sum of hierarchical mutual informations . Strictly speaking , the target unsupervised objective for the base supervised learning model consists of the reconstruction loss of the observation x ( with x_R reconstructed from the top most latent representation z ) and the reconstruction loss of the latent representation z ( with z_R reconstructed from the output y ) ; not all of the layer-wise reconstruction losses . > > From reviewer : The derivation of Equation ( 3 ) from total correlation is hacky . Moreover , assuming graphical model between X , Y and Z , it should be more carefully derived to estimate H ( X|Z ) and H ( Z|Y ) . The current proposal , encoding Z and Y from X and decoding from encoded representation is not really well justified . > > To reviewer : The derivation of reconstruction errors from the conditional entropy terms corresponds to the general auto-encoder framework described in \u201c Stacked denoising autoencoders , JMLR2010 \u201d . We added the details of mathematical derivation ( including noise models for probabilistic analysis of the neural network model ) in the revised manuscript ( Appendix_A1 ) . > > From reviewer : Is \\sigma in Equation 8 trainable parameter or hyperparameter ? If it is trainable how it is trained ? If it is not , how are they set ? Does j correspond to one of the class ? The proposed feature augmentation sounds like simply adding gaussian noise to the pre-softmax neurons . That being said , the proposed method is not different from gaussian dropout ( Wang and Manning , ICML 2013 ) but applied on different layers . In addition , there is a missing reference ( DisturbLabel : Regularizing CNN on the Loss Layer , CVPR 2016 ) that applied synthetic noise process on the loss layer . > > To reviewer : As we described in the paper , we assumed that if the perturbation in latent space guarantees to preserve the original semantics well , we could get a better generalization effect on the given training examples . So , we propose a method for augmenting in the latent space Z ( while preserving the original semantics well ) , not the output space Y . Yes , we simply add gaussian noise to the pre-softmax output neurons in order to obtain perturbed Y . But , the perturbed Y is used for making the \u201c semantic noise \u201d on the latent space Z ( that \u2019 s exactly what we want to introduce in this paper ) via the reconstruction path of the based model ( perturbation on the output space is not directly used for the target loss as in \u201c DisturbLabel , CVPR2016 \u201d ) . From experiments ( in Section 4.4 ) , we showed the difference between the most commonly considered \u201c random perturbation directly on Z \u201d and the proposed \u201c semantic perturbation indirectly modeled from the direct perturbation of Y \u201d . \u201c Gaussian dropout , ICML2013 \u201d is a kind of a computationally efficient version of the dropout , which drops a subset of hidden units randomly sampled during training . The proposed noise modeling method focuses on semantic-preserving perturbation on the latent space , so it is different from the dropout ( or gaussian dropout ) approaches . > > From reviewer : Experiments should be done for multiple times with different random subsets and authors should provide mean and standard error . Overall , I believe the proposed method is not very well justified and has limited novelty . > > To reviewer : As described in the original manuscript , Table.1 shows the average of 3 trials with different random splits , and the results according to each trial are summarized in Table.2 ( in Appendix_A3 ) . We added std_dev in Table.1 . Thanks for the comments ."}, {"review_id": "SyCSsUDee-1", "review_text": "The paper presents a new regularization technique for neural networks, which seeks to maximize correlation between input variables, latent variables and outputs. This is achieved by defining a measure of total correlation between these variables and decomposing it in terms of entropies and conditional entropies. Authors explain that they do not actually maximize the total correlation, but a lower-bound of it that ignores simple entropy terms, and only considers conditional entropies. It is not clearly explained what is the rationale for discarding these entropy terms. Entropies measures are applying to probability distributions (i.e. this implies that the variables in the model should be random). The link between the conditional entropy formulation and the reconstruction error is not made explicit. In order to link these two views, I would have expected, for example, a noise model for the units of the network. Later in the paper, it is claimed that the original ladder network is not suitable for supervised learning with small samples, and some empirical results seek to demonstrate this. But a more theoretical explanation why it is the case would have been welcome. The MNIST results are shown for a particular convolutional neural network architecture, however, most ladder network results for this dataset have been produced on standard fully-connected architectures. Results for such neural network architecture would have been desirable for more comparability with original ladder neural network results.", "rating": "3: Clear rejection", "reply_text": "First of all , we have made overall revisions to the manuscript including detailed mathematical derivations for the base model ( Section 2.1 with Appendix_A1 ) and clear explanations of the proposed noise modeling method ( Section 2.2 ) . > > From reviewer : The paper presents a new regularization technique for neural networks , which seeks to maximize correlation between input variables , latent variables and outputs . This is achieved by defining a measure of total correlation between these variables and decomposing it in terms of entropies and conditional entropies . Authors explain that they do not actually maximize the total correlation , but a lower-bound of it that ignores simple entropy terms , and only considers conditional entropies . It is not clearly explained what is the rationale for discarding these entropy terms . > > To reviewer : It is a relatively loose lower bound which is defined without taking H ( Z ) into consideration . We agree with that H ( Z ) is anyway affected by the process of H ( Z|Y ) being minimized in our target objective . However , H ( Z ) is an upper bound of H ( Z|Y ) , so minimizing H ( Z|Y ) does not necessarily encourage a decrease in H ( Z ) . We experimentally show that we can obtain good base model even from this relatively loose lower bound ( Section 4.3 ) . > > From reviewer : Entropies measures are applying to probability distributions ( i.e.this implies that the variables in the model should be random ) . The link between the conditional entropy formulation and the reconstruction error is not made explicit . In order to link these two views , I would have expected , for example , a noise model for the units of the network . > > To reviewer : The derivation of reconstruction errors from the conditional entropies corresponds to the general auto-encoder framework described in \u201c Stacked denoising autoencoders , JMLR2010 \u201d . We added the details of mathematical derivation ( including noise models for probabilistic analysis of the neural network model ) in the revised manuscript ( Appendix_A1 ) . > > From reviewer : Later in the paper , it is claimed that the original ladder network is not suitable for supervised learning with small samples , and some empirical results seek to demonstrate this . But a more theoretical explanation why it is the case would have been welcome . The MNIST results are shown for a particular convolutional neural network architecture , however , most ladder network results for this dataset have been produced on standard fully-connected architectures . Results for such neural network architecture would have been desirable for more comparability with original ladder neural network results . > > To reviewer : We experimented again with the same architecture as the ladder network , and updated the results to the revised manuscript ( Appendix_A2 ) . From the results , the ladder network and our model show similar performance in over 200 per-class examples . However , we can see that the proposed method shows notable performance benefit as the dataset scale goes down to below 200 per-class examples ( e.g. , in a case of 10 per-class training examples , the proposed method achieves 22.11 % of error rate , while the ladder network shows 29.66 % ) . Thanks for the advice ."}, {"review_id": "SyCSsUDee-2", "review_text": "This paper introduces a maximum total correlation procedure, adds a target and then adds noise perturbations. Technical issues: The move from (1) to (2) is problematic. Yes it is a lower bound, but by igoring H(Z), equation (2) ignores the fact that H(Z) will potentially vary more significantly that H(Z|Y). As a result of removing H(Z), the objective (2) encourages Z that are low entropy as the H(Z) term is ignored, doubly so as low entropy Z results in low entropy Z|Y. Yes the -H(X|Z) mitigates against a complete entropy collapse for H(Z), but it still neglects critical terms. In fact one might wonder if this is the reason that semantic noise addition needs to be done anyway, just to push up the entropy of Z to stop it reducing too much. In (3) arbitrary balancing paramters lamda_1 and lambda_2 are introduced ex-nihilo - they were not there in (2). This is not ever justified. Then in (5), a further choice is made by simply adding L_{NLL} to the objective. But in the supervised case, the targets are known and so turn up in H(Z|Y). Hence now H(Z|Y) should be conditioned on the targets. However instead another objective is added again without justification, and the conditional entropy of Z is left disconnected from the data it is to be conditioned on. One might argue the C(X,Y,Z) simply acts as a prior on the networks (and hence implicitly on the weights) that we consider, which is then combined with a likelihood term, but this case is not made. In fact there is no explicit probabilistic or information theoretic motivation for the chosen objective. Given these issues, it is then not too surprising that some further things need to be done, such as semantic noise addition to actually get things working properly. It may be the form of noise addition is a good idea, but given the troublesome objective being used in the first place, it is very hard to draw conclusions. In summary, substantially better theoretical justification of the chosen model is needed, before any reasonable conclusion on the semantic noise modelling can be made.", "rating": "2: Strong rejection", "reply_text": "( 1 ) Ignoring H ( Z ) from the lower bound I wonder why H ( Z ) will be lowered as a result of ignoring H ( Z ) ( based on the term \u201c the objective ( 2 ) encourages Z that are low entropy as the H ( Z ) term is ignored \u201d ) . We agree with the following term \u201c low entropy Z results in low entropy Z|Y \u201d , since H ( Z ) > = H ( Z|Y ) . However , minimizing H ( X|Z ) +H ( Z|Y ) ( our objective ) does not necessarily encourage a decrease in H ( Z ) . We have empirically confirmed that the assumption ( maximizing the lower bound defined without taking H ( Z ) into consideration ) would yield a good base representation for supervised learning . From the experimental results that `` proposed-base ( without noise addition ) '' shows better performance than previous approaches , it can be confirmed that the formulation is not the reason that semantic noise addition needs to be done anyway . I agree , however , that considering H ( Z ) might be a better model than ignoring H ( Z ) . But this requires an appropriate prior to P ( Z ) , which may require fairly uncertain assumptions . ( 2 ) L_ { NLL } and loss weighting coefficients lambda_1 & lambda_2 Remark that X , Y are an observation and its output , and Z is a latent representation of this framework as already described in the manuscript . From the base feedforward model described in Fig.1 ( a ) , we assume that good base representation Z for supervised learning ( that \u2019 s why we consider the classification loss L_NLL ) can be obtained by maximizing total correlation between the variables . So , eq ( 2 ) starts from \u201c maximization of total correlation + L_ { NLL } \u201d ( we will clarify these contents through manuscript revision ) . From [ ref.1 ] , it is known that maximization of -H ( X|Z ) can be formulated as minimization of L_rec ( x , x_R ) averaged over the observations x . Similarly , it is easy to show that -H ( Z|Y ) corresponds to L_rec ( z , z_R ) averaged over z = f_ { theta_1 } ( x ) . Since H ( X|Z ) and H ( Z|Y ) in eq ( 2 ) are respectively proportional to L_rec ( x , x_R ) and L_rec ( z , z_R ) in eq ( 3 ) , lambda_1 and lambda_2 are required . [ ref.1 ] Pascal Vincent , Hugo Larochelle , Isabelle Lajoie , Yoshua Bengio , and Pierre-Antoine Manzagol . Stacked denoising autoencoders : Learning useful representations in a deep network with a local denoising criterion . Journal of Machine Learning Research ( JMLR ) , 11:3371\u20133408 , 2010 . ( 3 ) Adding the perturbation NLL loss The addition of supervised loss is to make the model as discriminative as possible when finite capacity exists [ ref.2 ] . We can use the proposed model as is ( \u201c proposed-base \u201d in the manuscript ) , but we empirically show that the addition of supervised loss via class-conditional perturbation ( \u201c proposed ( class-conditional ) \u201d in the manuscript which is the main idea of this paper ) generalizes better . [ ref.2 ] Hugo Larochelle and Yoshua Bengio . Classification using discriminative restricted boltzmann machines . In International Conference on Machine Learning ( ICML ) , 2008 . In conclusion , please note that this mathematical model is not a complete analytical model but a motivating model for proposed semantic noise modeling method . P.S.We are glad to clarify any misunderstanding in our manuscript through active discussion with the reviewers as well as other readers . If there 's any unclear point , we kindly ask you to point it out here in the discussion forum ."}], "0": {"review_id": "SyCSsUDee-0", "review_text": "The paper introduces supervised deep learning with layer-wise reconstruction loss (in addition to the supervised loss) and class-conditional semantic additive noise for better representation learning. Total correlation measure and additional insights from auto-encoder are used to derive layer-wise reconstruction loss and is further combined with supervised loss. When combining with supervised loss the class-conditional additive noise model is proposed, which showed consistent improvement over the baseline model. Experiments on MNIST and CIFAR-10 datasets while changing the number of training examples per class are done extensively. The derivation of Equation (3) from total correlation is hacky. Moreover, assuming graphical model between X, Y and Z, it should be more carefully derived to estimate H(X|Z) and H(Z|Y). The current proposal, encoding Z and Y from X and decoding from encoded representation is not really well justified. Is \\sigma in Equation 8 trainable parameter or hyperparameter? If it is trainable how it is trained? If it is not, how are they set? Does j correspond to one of the class? The proposed feature augmentation sounds like simply adding gaussian noise to the pre-softmax neurons. That being said, the proposed method is not different from gaussian dropout (Wang and Manning, ICML 2013) but applied on different layers. In addition, there is a missing reference (DisturbLabel: Regularizing CNN on the Loss Layer, CVPR 2016) that applied synthetic noise process on the loss layer. Experiments should be done for multiple times with different random subsets and authors should provide mean and standard error. Overall, I believe the proposed method is not very well justified and has limited novelty. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "First of all , we have made overall revisions to the manuscript including detailed mathematical derivations for the base model ( Section 2.1 with Appendix_A1 ) and clear explanations of the proposed noise modeling method ( Section 2.2 ) . > > From reviewer : The paper introduces supervised deep learning with layer-wise reconstruction loss ( in addition to the supervised loss ) and class-conditional semantic additive noise for better representation learning . Total correlation measure and additional insights from auto-encoder are used to derive layer-wise reconstruction loss and is further combined with supervised loss . When combining with supervised loss the class-conditional additive noise model is proposed , which showed consistent improvement over the baseline model . Experiments on MNIST and CIFAR-10 datasets while changing the number of training examples per class are done extensively . > > To reviewer : Yes , we applied hierarchical reconstruction losses derived from hierarchical conditional entropies which is obtained from the sum of hierarchical mutual informations . Strictly speaking , the target unsupervised objective for the base supervised learning model consists of the reconstruction loss of the observation x ( with x_R reconstructed from the top most latent representation z ) and the reconstruction loss of the latent representation z ( with z_R reconstructed from the output y ) ; not all of the layer-wise reconstruction losses . > > From reviewer : The derivation of Equation ( 3 ) from total correlation is hacky . Moreover , assuming graphical model between X , Y and Z , it should be more carefully derived to estimate H ( X|Z ) and H ( Z|Y ) . The current proposal , encoding Z and Y from X and decoding from encoded representation is not really well justified . > > To reviewer : The derivation of reconstruction errors from the conditional entropy terms corresponds to the general auto-encoder framework described in \u201c Stacked denoising autoencoders , JMLR2010 \u201d . We added the details of mathematical derivation ( including noise models for probabilistic analysis of the neural network model ) in the revised manuscript ( Appendix_A1 ) . > > From reviewer : Is \\sigma in Equation 8 trainable parameter or hyperparameter ? If it is trainable how it is trained ? If it is not , how are they set ? Does j correspond to one of the class ? The proposed feature augmentation sounds like simply adding gaussian noise to the pre-softmax neurons . That being said , the proposed method is not different from gaussian dropout ( Wang and Manning , ICML 2013 ) but applied on different layers . In addition , there is a missing reference ( DisturbLabel : Regularizing CNN on the Loss Layer , CVPR 2016 ) that applied synthetic noise process on the loss layer . > > To reviewer : As we described in the paper , we assumed that if the perturbation in latent space guarantees to preserve the original semantics well , we could get a better generalization effect on the given training examples . So , we propose a method for augmenting in the latent space Z ( while preserving the original semantics well ) , not the output space Y . Yes , we simply add gaussian noise to the pre-softmax output neurons in order to obtain perturbed Y . But , the perturbed Y is used for making the \u201c semantic noise \u201d on the latent space Z ( that \u2019 s exactly what we want to introduce in this paper ) via the reconstruction path of the based model ( perturbation on the output space is not directly used for the target loss as in \u201c DisturbLabel , CVPR2016 \u201d ) . From experiments ( in Section 4.4 ) , we showed the difference between the most commonly considered \u201c random perturbation directly on Z \u201d and the proposed \u201c semantic perturbation indirectly modeled from the direct perturbation of Y \u201d . \u201c Gaussian dropout , ICML2013 \u201d is a kind of a computationally efficient version of the dropout , which drops a subset of hidden units randomly sampled during training . The proposed noise modeling method focuses on semantic-preserving perturbation on the latent space , so it is different from the dropout ( or gaussian dropout ) approaches . > > From reviewer : Experiments should be done for multiple times with different random subsets and authors should provide mean and standard error . Overall , I believe the proposed method is not very well justified and has limited novelty . > > To reviewer : As described in the original manuscript , Table.1 shows the average of 3 trials with different random splits , and the results according to each trial are summarized in Table.2 ( in Appendix_A3 ) . We added std_dev in Table.1 . Thanks for the comments ."}, "1": {"review_id": "SyCSsUDee-1", "review_text": "The paper presents a new regularization technique for neural networks, which seeks to maximize correlation between input variables, latent variables and outputs. This is achieved by defining a measure of total correlation between these variables and decomposing it in terms of entropies and conditional entropies. Authors explain that they do not actually maximize the total correlation, but a lower-bound of it that ignores simple entropy terms, and only considers conditional entropies. It is not clearly explained what is the rationale for discarding these entropy terms. Entropies measures are applying to probability distributions (i.e. this implies that the variables in the model should be random). The link between the conditional entropy formulation and the reconstruction error is not made explicit. In order to link these two views, I would have expected, for example, a noise model for the units of the network. Later in the paper, it is claimed that the original ladder network is not suitable for supervised learning with small samples, and some empirical results seek to demonstrate this. But a more theoretical explanation why it is the case would have been welcome. The MNIST results are shown for a particular convolutional neural network architecture, however, most ladder network results for this dataset have been produced on standard fully-connected architectures. Results for such neural network architecture would have been desirable for more comparability with original ladder neural network results.", "rating": "3: Clear rejection", "reply_text": "First of all , we have made overall revisions to the manuscript including detailed mathematical derivations for the base model ( Section 2.1 with Appendix_A1 ) and clear explanations of the proposed noise modeling method ( Section 2.2 ) . > > From reviewer : The paper presents a new regularization technique for neural networks , which seeks to maximize correlation between input variables , latent variables and outputs . This is achieved by defining a measure of total correlation between these variables and decomposing it in terms of entropies and conditional entropies . Authors explain that they do not actually maximize the total correlation , but a lower-bound of it that ignores simple entropy terms , and only considers conditional entropies . It is not clearly explained what is the rationale for discarding these entropy terms . > > To reviewer : It is a relatively loose lower bound which is defined without taking H ( Z ) into consideration . We agree with that H ( Z ) is anyway affected by the process of H ( Z|Y ) being minimized in our target objective . However , H ( Z ) is an upper bound of H ( Z|Y ) , so minimizing H ( Z|Y ) does not necessarily encourage a decrease in H ( Z ) . We experimentally show that we can obtain good base model even from this relatively loose lower bound ( Section 4.3 ) . > > From reviewer : Entropies measures are applying to probability distributions ( i.e.this implies that the variables in the model should be random ) . The link between the conditional entropy formulation and the reconstruction error is not made explicit . In order to link these two views , I would have expected , for example , a noise model for the units of the network . > > To reviewer : The derivation of reconstruction errors from the conditional entropies corresponds to the general auto-encoder framework described in \u201c Stacked denoising autoencoders , JMLR2010 \u201d . We added the details of mathematical derivation ( including noise models for probabilistic analysis of the neural network model ) in the revised manuscript ( Appendix_A1 ) . > > From reviewer : Later in the paper , it is claimed that the original ladder network is not suitable for supervised learning with small samples , and some empirical results seek to demonstrate this . But a more theoretical explanation why it is the case would have been welcome . The MNIST results are shown for a particular convolutional neural network architecture , however , most ladder network results for this dataset have been produced on standard fully-connected architectures . Results for such neural network architecture would have been desirable for more comparability with original ladder neural network results . > > To reviewer : We experimented again with the same architecture as the ladder network , and updated the results to the revised manuscript ( Appendix_A2 ) . From the results , the ladder network and our model show similar performance in over 200 per-class examples . However , we can see that the proposed method shows notable performance benefit as the dataset scale goes down to below 200 per-class examples ( e.g. , in a case of 10 per-class training examples , the proposed method achieves 22.11 % of error rate , while the ladder network shows 29.66 % ) . Thanks for the advice ."}, "2": {"review_id": "SyCSsUDee-2", "review_text": "This paper introduces a maximum total correlation procedure, adds a target and then adds noise perturbations. Technical issues: The move from (1) to (2) is problematic. Yes it is a lower bound, but by igoring H(Z), equation (2) ignores the fact that H(Z) will potentially vary more significantly that H(Z|Y). As a result of removing H(Z), the objective (2) encourages Z that are low entropy as the H(Z) term is ignored, doubly so as low entropy Z results in low entropy Z|Y. Yes the -H(X|Z) mitigates against a complete entropy collapse for H(Z), but it still neglects critical terms. In fact one might wonder if this is the reason that semantic noise addition needs to be done anyway, just to push up the entropy of Z to stop it reducing too much. In (3) arbitrary balancing paramters lamda_1 and lambda_2 are introduced ex-nihilo - they were not there in (2). This is not ever justified. Then in (5), a further choice is made by simply adding L_{NLL} to the objective. But in the supervised case, the targets are known and so turn up in H(Z|Y). Hence now H(Z|Y) should be conditioned on the targets. However instead another objective is added again without justification, and the conditional entropy of Z is left disconnected from the data it is to be conditioned on. One might argue the C(X,Y,Z) simply acts as a prior on the networks (and hence implicitly on the weights) that we consider, which is then combined with a likelihood term, but this case is not made. In fact there is no explicit probabilistic or information theoretic motivation for the chosen objective. Given these issues, it is then not too surprising that some further things need to be done, such as semantic noise addition to actually get things working properly. It may be the form of noise addition is a good idea, but given the troublesome objective being used in the first place, it is very hard to draw conclusions. In summary, substantially better theoretical justification of the chosen model is needed, before any reasonable conclusion on the semantic noise modelling can be made.", "rating": "2: Strong rejection", "reply_text": "( 1 ) Ignoring H ( Z ) from the lower bound I wonder why H ( Z ) will be lowered as a result of ignoring H ( Z ) ( based on the term \u201c the objective ( 2 ) encourages Z that are low entropy as the H ( Z ) term is ignored \u201d ) . We agree with the following term \u201c low entropy Z results in low entropy Z|Y \u201d , since H ( Z ) > = H ( Z|Y ) . However , minimizing H ( X|Z ) +H ( Z|Y ) ( our objective ) does not necessarily encourage a decrease in H ( Z ) . We have empirically confirmed that the assumption ( maximizing the lower bound defined without taking H ( Z ) into consideration ) would yield a good base representation for supervised learning . From the experimental results that `` proposed-base ( without noise addition ) '' shows better performance than previous approaches , it can be confirmed that the formulation is not the reason that semantic noise addition needs to be done anyway . I agree , however , that considering H ( Z ) might be a better model than ignoring H ( Z ) . But this requires an appropriate prior to P ( Z ) , which may require fairly uncertain assumptions . ( 2 ) L_ { NLL } and loss weighting coefficients lambda_1 & lambda_2 Remark that X , Y are an observation and its output , and Z is a latent representation of this framework as already described in the manuscript . From the base feedforward model described in Fig.1 ( a ) , we assume that good base representation Z for supervised learning ( that \u2019 s why we consider the classification loss L_NLL ) can be obtained by maximizing total correlation between the variables . So , eq ( 2 ) starts from \u201c maximization of total correlation + L_ { NLL } \u201d ( we will clarify these contents through manuscript revision ) . From [ ref.1 ] , it is known that maximization of -H ( X|Z ) can be formulated as minimization of L_rec ( x , x_R ) averaged over the observations x . Similarly , it is easy to show that -H ( Z|Y ) corresponds to L_rec ( z , z_R ) averaged over z = f_ { theta_1 } ( x ) . Since H ( X|Z ) and H ( Z|Y ) in eq ( 2 ) are respectively proportional to L_rec ( x , x_R ) and L_rec ( z , z_R ) in eq ( 3 ) , lambda_1 and lambda_2 are required . [ ref.1 ] Pascal Vincent , Hugo Larochelle , Isabelle Lajoie , Yoshua Bengio , and Pierre-Antoine Manzagol . Stacked denoising autoencoders : Learning useful representations in a deep network with a local denoising criterion . Journal of Machine Learning Research ( JMLR ) , 11:3371\u20133408 , 2010 . ( 3 ) Adding the perturbation NLL loss The addition of supervised loss is to make the model as discriminative as possible when finite capacity exists [ ref.2 ] . We can use the proposed model as is ( \u201c proposed-base \u201d in the manuscript ) , but we empirically show that the addition of supervised loss via class-conditional perturbation ( \u201c proposed ( class-conditional ) \u201d in the manuscript which is the main idea of this paper ) generalizes better . [ ref.2 ] Hugo Larochelle and Yoshua Bengio . Classification using discriminative restricted boltzmann machines . In International Conference on Machine Learning ( ICML ) , 2008 . In conclusion , please note that this mathematical model is not a complete analytical model but a motivating model for proposed semantic noise modeling method . P.S.We are glad to clarify any misunderstanding in our manuscript through active discussion with the reviewers as well as other readers . If there 's any unclear point , we kindly ask you to point it out here in the discussion forum ."}}