{"year": "2019", "forum": "Byg0DsCqYQ", "title": "Robust Conditional Generative Adversarial Networks", "decision": "Accept (Poster)", "meta_review": "The proposed method suggests a way to do robust conditional image generation with GANs. The premise is to make the image to image translation model resilient to noise by leveraging structure in the output space, with an unsupervised \"pathway\".\n\nIn general, the qualitative results seem reasonable on a a number of datasets, including those suggested by reviewers. The method appears simple, novel and easy to try.  The main concerns seem to be that the idea is maybe too simple, but I'm not particularly bothered by that. The authors showed it working well on a variety of tasks (synthetic and natural), provide SSIM numbers that look compelling (despite SSIM's short-comings) and otherwise give compelling arguments for the technical soundness of the approach.\n\nThus, I recommend acceptance.", "reviews": [{"review_id": "Byg0DsCqYQ-0", "review_text": "Authors propose to augment a conditional GAN model with an unsupervised branch for spanning target manifold and show better performance than the conditional GAN in natural scene generation and face generation. However the novelty is limited and not well explained. 1.Similar idea of using an autoencoder as another branch to help image generation has been proposed in Ma et al.\u2019s work. Liqian Ma, Qianru Sun, Stamatios Georgoulis, Luc Van Gool, Bernt Schiele, Mario Fritz. Disentangled Person Image Generation, CVPR 2018. 2. In the paper authors claim that skip connection makes it harder to train the longer path, which is kind of contradictory to what is commonly done in tasks of image classification, semantic segmentation and depth estimation. Can authors explain this claim? In addition, it is not clear why maximizing the variance can address the challenge of training longer path. 3. In Table 1, the improvement over baselines is small in case of sparse inpaint setting. 4. In Figure 4, the fourth row is more blurry than the third row although with less artifacts like black dots. %%%%%%%% After rebuttal %%%%%%%% I appreciate authors' efforts to address my comments and am satisfied with their response. I will change decision from rejection to acceptance.", "rating": "6: Marginally above acceptance threshold", "reply_text": "2b ) 'In addition , it is not clear why maximizing the variance can address the challenge of training longer path . ' : Reducing the correlations of the weights has several advantages that are well-studied in both computer vision and machine learning . Several methods for decorrelating the weights has been used in deep networks , for instance [ 6-10 ] . An intuitive idea about why we have included this loss : By reducing the correlations we encourage our method to explore different 'principal ' directions in different layers , which is beneficial for training the network . Similar observations and experiments for the benefit of exploring different directions during training have been explored in [ 4-6 ] . 3 ) 'Covariance is computed for decov loss but it is not clear which layer \u2019 s representation is used to compute covariance . ' : We have actually included the requested information in the original submission ( sec.4 , page 7 in the revised manuscript ) . 4 ) 'In Table 1 , the improvement over baselines is small in case of sparse inpainting setting . ' : We appreciate the comment ; we have performed a similar analysis in sec D.2 ( appendix ) . In short : the improvement in the additional noise experiments ( sparse inpainting task ) is not marginal but quite significant ( up to 15 % ) . Furthermore , we believe the experiments that we have conducted cover several cases and the results are always consistent , i.e.RoC-GAN * always * improve the baseline , while in the regions of more extreme noise or adversarial perturbations the difference is substantial . 5 ) 'In Figure 4 , the fourth row is more blurry than the third row although with less artifacts like black dots . ' : We argue that the black dots the reviewer mentions make the images unrealistic . Such irregularities can have detrimental effect for higher level tasks accepting those images as input . Nevertheless , to demonstrate with quantitative metrics the difference , we have added a new metric for the experiments of faces . The metric is focused on the similarity of the identities of the facial images . We have measured the distance between the methods ' outputs and the target images and prepared the cumulative plot . Please find the complete metric analysis in section D.4 in the appendix . [ 4 ] Jia , Kui et al . `` Improving training of deep neural networks via singular value bounding '' , CVPR 2017 . [ 5 ] Miyato , Takeru et al . `` Spectral normalization for generative adversarial networks '' , ICLR 2018 . [ 6 ] Bansal , Nitin et al . `` Can We Gain More from Orthogonality Regularizations in Training Deep CNNs ? `` , Arxiv . [ 7 ] Cohen , Taco and Welling , Max `` Group equivariant convolutional networks '' , ICML 2016 . [ 8 ] Cogswell , Michael , et al . `` Reducing overfitting in deep networks by decorrelating representations . `` , ICLR 2016 . [ 9 ] Rodriguez , Pau et al . `` Regularizing cnns with locally constrained decorrelations '' , Arxiv . [ 10 ] Ozay , Mete and Okatani , Takayuki `` Optimization on Submanifolds of Convolution Kernels in CNNs '' , Arxiv ."}, {"review_id": "Byg0DsCqYQ-1", "review_text": "General: In general, this is a well-written paper. This work focuses on the robustness of conditional GAN(RoC-GAN) when facing the noise. The authors claim the generator of RoC-Gan will span the target manifold, even in the presence of large amounts of noise. The main contribution of the paper is to introduce a two-pathway model, where one of them is used to perform regression as ordinary GAN while the other one helps the whole model span the target domain. Strength: 1. The idea is simple and straightforward. The authors provide necessary theoretical analysis and empirical validation for their model. 2. The proposed method seems technically correct to me. i.e. Although I am not very sure how well it works in practice, the idea is fine. Possible Improvements: 1. I agree adding another auto-encoder as a helper may give better generation results by spanning the whole target space, but I don't think this constraint is strong enough in practice. 2. In section 3.3, the time complexity of computing 'L_deconv' seems extremely large. From the perspective of numerical optimization, optimizing such a matrix will cause trouble if the dimension of weight matrices are large. i.e. optimizing the high-dimensional covariance matrix seems a problem to me. 3. The experiments looks good. The experiments could be more convincing if using more complex data sets(e.g. CIFAR10, ImageNet) besides CelebA. My concern for using such data sets(the resolution of images is low and the distribution is simple) is that: although the noise seems to corrupt most of the image, the distribution of the image is not complex, so the generative model can recover it easily. Since this is a more empirical paper, the experiments should be more convincing. Conclusion: The author(s) are thoughtful and they put lots of work on this paper. The proposed method is simple. For novelty and significance, I think the idea is not very fancy to me. I am not very convinced by the method proposed in the paper. Although the paper demonstrates the robustness of their model with different experiments, most of them were not performed on deep neural networks and complicated data sets. As a conclusion, I vote for weak rejection. Minor suggestion: Increase the resolution of the figures. ------------------------------- After Rebuttal --------------------------------- I am very satisfied with the authors' response, so I will change my vote from rejection to acceptance.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for recognizing the effort and contribution of our method . In addition to the general answer above , we answer each of the improvement points below : 1 ) ' I agree adding another auto-encoder as a helper may give better generation results by spanning the whole target space , but I do n't think this constraint is strong enough in practice . ' : We respectfully disagree with the reviewer ; we have demonstrated in a series of experiments how this modification is beneficial . We provide the intuition , the synthetic experiment , a linear analogy analysis , and several experiments . In the revision we add a visual example for the linear subspace ( appendix , sec.B ) .We demonstrate how one corrupted and one clean image can have similar reconstructions from a PCA model . 2 ) 'In section 3.3 , the time complexity of computing ' $ L_deconv $ ' seems extremely large . From the perspective of numerical optimization , optimizing such a matrix will cause trouble if the dimension of weight matrices are large . i.e.optimizing the high-dimensional covariance matrix seems a problem to me . ' : In the implementation details ( section 4 ; page 7 ) , we mention that we use $ L_deconv $ in the output of the encoders . Those layers include tensors of $ batch x 1 x 1 x channels $ where the number of channels is typically up to 1024 . In our experiments for 4 layer network channels=512 , for the 5 and 6 layer networks channels=768 . Cogswell et al . ( [ 1 ] ) include an analysis for deeper networks . In practice , we have not noticed a significant computational burden , but this can be further explored in the future . 3 ) 'The experiments look good . The experiments could be more convincing if using more complex data sets ( e.g.CIFAR10 , ImageNet ) besides CelebA . My concern for using such data sets ( the resolution of images is low and the distribution is simple ) is that : although the noise seems to corrupt most of the image , the distribution of the image is not complex , so the generative model can recover it easily . Since this is a more empirical paper , the experiments should be more convincing . ' : We have conducted the requested experiments on Imagenet ( appendix , sec.D.1 ) .The results are in line with those reported in the main paper -- particularly the natural scenes case and confirm the advantages of our method . That is , RoC-GAN outperform the cGAN in both denoising and sparse inpainting while the difference is increased when evaluated with additional noise . We note that the same hyper-parameters ( as the rest of the paper ) are used ; additional tuning per experiment might be beneficial however for avoiding confusion all the hyper-parameters remain the same . 4 ) 'Although the paper demonstrates the robustness of their model with different experiments , most of them were not performed on deep neural networks and complicated data sets . ' : In the revised version we have included an experiment on Imagenet ( appendix , sec.D.1 ) .Our model is not architecture dependent . Specifically , RoC-GAN can be seen as a meta algorithm which can be used to augment any existing cGAN model to achieve additional robustness . We have made our best effort to demonstrate that with i ) similar types of noise , ii ) types of noise 'unseen ' during training , iii ) adversarial perturbations . 5 ) 'Minor suggestion : Increase the resolution of the figures . ' : We will add new figures to reflect the AAE method added and improve older ones the next few days . We appreciate the proposal . [ 1 ] Cogswell , Michael , et al . `` Reducing overfitting in deep networks by decorrelating representations . `` , ICLR 2016 ."}, {"review_id": "Byg0DsCqYQ-2", "review_text": "This manuscript proposes a robust version of conditional GAN (named RoC-GAN) that leverage the intrinsic structure in the output space. To achieve robustness, the authors replace the single pathway in the generator with two different pathways that partially share weights. The authors study the theoretical properties of RoC-GAN and prove that it shares the same properties as the vanilla GAN. For quantitative evaluations, the authors use two datasets of natural scenes and faces and evaluate denoising and sparse inpainting using the SSIM metric. - The idea is simple and seems to be working. The methodological novelties seem more-or-less limited, but the theoretical analysis and the intuitive (and well-motivated) modification over CGANs add merits to the paper. - The theoretical analysis of the method relates RoC-GAN to the original GAN, rather than CGAN! What is the connection here? If RoC-GAN is very similar to CGAN from a theoretical point of view (which it seems to be), then all the analysis to relate it to traditional GAN seem useless. - The extensive experiments in the supplementary material are appreciated. But the authors only compare their method with one single previous work (i.e., Rick Chang et al. (2017)), while there are several similar related works (either based on adversarial training strategies or simple denoising AEs). - Also, ablation studies can further show how each component of the model contributes to the final results. What if we were to only use the two-path generator without adversarial training? Different components of the final loss function can be removed and analyzed one at a time! - What are the conditions for mode-collapse for the proposed GAN? There are no discussions on this. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "In addition to the general answer above , we answer each of the points raised below : 1 ) 'The idea is simple and seems to be working . The methodological novelties seem more-or-less limited , but the theoretical analysis and the intuitive ( and well-motivated ) modification over CGANs add merits to the paper . ' : We thank the reviewer for the recognition of the work . 2 ) 'The theoretical analysis of the method relates RoC-GAN to the original GAN , rather than CGAN ! What is the connection here ? If RoC-GAN is very similar to CGAN from a theoretical point of view ( which it seems to be ) , then all the analysis to relate it to traditional GAN seem useless . ' : On the contrary , we prove that our RoC-GAN shares the same theoretical properties as GAN ; this can be seen as a sanity check , conforming that our method shares some beneficial theoretical properties with well-studied methods . Similar proofs are provided in other extensions to cGAN , such as Zhe et al . ( [ 1 ] ) .3 ) 'The extensive experiments in the supplementary material are appreciated . But the authors only compare their method with one single previous work ( i.e. , Rick Chang et al . ( 2017 ) ) , while there are several similar related works ( either based on adversarial training strategies or simple denoising AEs ) . ' : The goal of this work is not to propose a state-of-the-art network per se , but rather to present a method that is more robust to additional sources of noise . Our model is not architecture dependent . Specifically , RoC-GAN can be seen as a meta algorithm which can be used to augment any existing cGAN model to achieve additional robustness . We scrutinize the robustness under : i ) similar types of noise , ii ) types of noise not encountered during training , iii ) adversarial perturbations . In addition to those , we also note that our method performs favorably when tested with samples similar as the training distribution . We have included an external method to illustrate that even strong performing networks can have difficulty in such tasks . However , if there are some specific works that the reviewers feel are particularly relevant , we are happy to evaluate their pre-trained models . 4 ) 'Ablation studies can further show how each component of the model contributes to the final results . What if we were to only use the two-path generator without adversarial training ? Different components of the final loss function can be removed and analyzed one at a time ! ' : We appreciate the reviewer 's proposal ; indeed in the synthetic experiment we optimize only the generators to simplify the problem ; please see sec.3.4.In addition , removing one by one the losses is performed in sec.E.2 ( appendix ) . Even though our experiments are not exhaustive , we consider that we have covered a wide range of choices ; those demonstrate the merits or trade-offs of our RoC-GAN . 5 ) 'What are the conditions for mode-collapse for the proposed GAN ? There are no discussions on this . ' : We follow the same strategy as popular methods in cGAN ( [ 2 ] , [ 3 ] ) . We agree with the reviewer that mode collapse is significant especially in original GAN training , however there are other works tackling this issue , e.g. [ 4-6 ] . [ 1 ] Gan , Zhe , et al . `` Triangle generative adversarial networks . `` , NIPS 2017 . [ 2 ] Isola , Phillip et al . `` Image-to-Image Translation with Conditional Adversarial Networks '' , CVPR 2017 . [ 3 ] Zhu , Jun-Yan et al . `` Toward multimodal image-to-image translation '' , NIPS 2017 . [ 4 ] Che , Tong et al . `` Mode Regularized Generative Adversarial Networks '' , ICLR 2017 . [ 5 ] Anonymous , `` Generative Adversarial Network Training is a Continual Learning Problem '' , under review ICLR 2019 . [ 6 ] Anonymous , `` DISTRIBUTIONAL CONCAVITY REGULARIZATION FOR GANS '' , under review ICLR 2019 ."}], "0": {"review_id": "Byg0DsCqYQ-0", "review_text": "Authors propose to augment a conditional GAN model with an unsupervised branch for spanning target manifold and show better performance than the conditional GAN in natural scene generation and face generation. However the novelty is limited and not well explained. 1.Similar idea of using an autoencoder as another branch to help image generation has been proposed in Ma et al.\u2019s work. Liqian Ma, Qianru Sun, Stamatios Georgoulis, Luc Van Gool, Bernt Schiele, Mario Fritz. Disentangled Person Image Generation, CVPR 2018. 2. In the paper authors claim that skip connection makes it harder to train the longer path, which is kind of contradictory to what is commonly done in tasks of image classification, semantic segmentation and depth estimation. Can authors explain this claim? In addition, it is not clear why maximizing the variance can address the challenge of training longer path. 3. In Table 1, the improvement over baselines is small in case of sparse inpaint setting. 4. In Figure 4, the fourth row is more blurry than the third row although with less artifacts like black dots. %%%%%%%% After rebuttal %%%%%%%% I appreciate authors' efforts to address my comments and am satisfied with their response. I will change decision from rejection to acceptance.", "rating": "6: Marginally above acceptance threshold", "reply_text": "2b ) 'In addition , it is not clear why maximizing the variance can address the challenge of training longer path . ' : Reducing the correlations of the weights has several advantages that are well-studied in both computer vision and machine learning . Several methods for decorrelating the weights has been used in deep networks , for instance [ 6-10 ] . An intuitive idea about why we have included this loss : By reducing the correlations we encourage our method to explore different 'principal ' directions in different layers , which is beneficial for training the network . Similar observations and experiments for the benefit of exploring different directions during training have been explored in [ 4-6 ] . 3 ) 'Covariance is computed for decov loss but it is not clear which layer \u2019 s representation is used to compute covariance . ' : We have actually included the requested information in the original submission ( sec.4 , page 7 in the revised manuscript ) . 4 ) 'In Table 1 , the improvement over baselines is small in case of sparse inpainting setting . ' : We appreciate the comment ; we have performed a similar analysis in sec D.2 ( appendix ) . In short : the improvement in the additional noise experiments ( sparse inpainting task ) is not marginal but quite significant ( up to 15 % ) . Furthermore , we believe the experiments that we have conducted cover several cases and the results are always consistent , i.e.RoC-GAN * always * improve the baseline , while in the regions of more extreme noise or adversarial perturbations the difference is substantial . 5 ) 'In Figure 4 , the fourth row is more blurry than the third row although with less artifacts like black dots . ' : We argue that the black dots the reviewer mentions make the images unrealistic . Such irregularities can have detrimental effect for higher level tasks accepting those images as input . Nevertheless , to demonstrate with quantitative metrics the difference , we have added a new metric for the experiments of faces . The metric is focused on the similarity of the identities of the facial images . We have measured the distance between the methods ' outputs and the target images and prepared the cumulative plot . Please find the complete metric analysis in section D.4 in the appendix . [ 4 ] Jia , Kui et al . `` Improving training of deep neural networks via singular value bounding '' , CVPR 2017 . [ 5 ] Miyato , Takeru et al . `` Spectral normalization for generative adversarial networks '' , ICLR 2018 . [ 6 ] Bansal , Nitin et al . `` Can We Gain More from Orthogonality Regularizations in Training Deep CNNs ? `` , Arxiv . [ 7 ] Cohen , Taco and Welling , Max `` Group equivariant convolutional networks '' , ICML 2016 . [ 8 ] Cogswell , Michael , et al . `` Reducing overfitting in deep networks by decorrelating representations . `` , ICLR 2016 . [ 9 ] Rodriguez , Pau et al . `` Regularizing cnns with locally constrained decorrelations '' , Arxiv . [ 10 ] Ozay , Mete and Okatani , Takayuki `` Optimization on Submanifolds of Convolution Kernels in CNNs '' , Arxiv ."}, "1": {"review_id": "Byg0DsCqYQ-1", "review_text": "General: In general, this is a well-written paper. This work focuses on the robustness of conditional GAN(RoC-GAN) when facing the noise. The authors claim the generator of RoC-Gan will span the target manifold, even in the presence of large amounts of noise. The main contribution of the paper is to introduce a two-pathway model, where one of them is used to perform regression as ordinary GAN while the other one helps the whole model span the target domain. Strength: 1. The idea is simple and straightforward. The authors provide necessary theoretical analysis and empirical validation for their model. 2. The proposed method seems technically correct to me. i.e. Although I am not very sure how well it works in practice, the idea is fine. Possible Improvements: 1. I agree adding another auto-encoder as a helper may give better generation results by spanning the whole target space, but I don't think this constraint is strong enough in practice. 2. In section 3.3, the time complexity of computing 'L_deconv' seems extremely large. From the perspective of numerical optimization, optimizing such a matrix will cause trouble if the dimension of weight matrices are large. i.e. optimizing the high-dimensional covariance matrix seems a problem to me. 3. The experiments looks good. The experiments could be more convincing if using more complex data sets(e.g. CIFAR10, ImageNet) besides CelebA. My concern for using such data sets(the resolution of images is low and the distribution is simple) is that: although the noise seems to corrupt most of the image, the distribution of the image is not complex, so the generative model can recover it easily. Since this is a more empirical paper, the experiments should be more convincing. Conclusion: The author(s) are thoughtful and they put lots of work on this paper. The proposed method is simple. For novelty and significance, I think the idea is not very fancy to me. I am not very convinced by the method proposed in the paper. Although the paper demonstrates the robustness of their model with different experiments, most of them were not performed on deep neural networks and complicated data sets. As a conclusion, I vote for weak rejection. Minor suggestion: Increase the resolution of the figures. ------------------------------- After Rebuttal --------------------------------- I am very satisfied with the authors' response, so I will change my vote from rejection to acceptance.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for recognizing the effort and contribution of our method . In addition to the general answer above , we answer each of the improvement points below : 1 ) ' I agree adding another auto-encoder as a helper may give better generation results by spanning the whole target space , but I do n't think this constraint is strong enough in practice . ' : We respectfully disagree with the reviewer ; we have demonstrated in a series of experiments how this modification is beneficial . We provide the intuition , the synthetic experiment , a linear analogy analysis , and several experiments . In the revision we add a visual example for the linear subspace ( appendix , sec.B ) .We demonstrate how one corrupted and one clean image can have similar reconstructions from a PCA model . 2 ) 'In section 3.3 , the time complexity of computing ' $ L_deconv $ ' seems extremely large . From the perspective of numerical optimization , optimizing such a matrix will cause trouble if the dimension of weight matrices are large . i.e.optimizing the high-dimensional covariance matrix seems a problem to me . ' : In the implementation details ( section 4 ; page 7 ) , we mention that we use $ L_deconv $ in the output of the encoders . Those layers include tensors of $ batch x 1 x 1 x channels $ where the number of channels is typically up to 1024 . In our experiments for 4 layer network channels=512 , for the 5 and 6 layer networks channels=768 . Cogswell et al . ( [ 1 ] ) include an analysis for deeper networks . In practice , we have not noticed a significant computational burden , but this can be further explored in the future . 3 ) 'The experiments look good . The experiments could be more convincing if using more complex data sets ( e.g.CIFAR10 , ImageNet ) besides CelebA . My concern for using such data sets ( the resolution of images is low and the distribution is simple ) is that : although the noise seems to corrupt most of the image , the distribution of the image is not complex , so the generative model can recover it easily . Since this is a more empirical paper , the experiments should be more convincing . ' : We have conducted the requested experiments on Imagenet ( appendix , sec.D.1 ) .The results are in line with those reported in the main paper -- particularly the natural scenes case and confirm the advantages of our method . That is , RoC-GAN outperform the cGAN in both denoising and sparse inpainting while the difference is increased when evaluated with additional noise . We note that the same hyper-parameters ( as the rest of the paper ) are used ; additional tuning per experiment might be beneficial however for avoiding confusion all the hyper-parameters remain the same . 4 ) 'Although the paper demonstrates the robustness of their model with different experiments , most of them were not performed on deep neural networks and complicated data sets . ' : In the revised version we have included an experiment on Imagenet ( appendix , sec.D.1 ) .Our model is not architecture dependent . Specifically , RoC-GAN can be seen as a meta algorithm which can be used to augment any existing cGAN model to achieve additional robustness . We have made our best effort to demonstrate that with i ) similar types of noise , ii ) types of noise 'unseen ' during training , iii ) adversarial perturbations . 5 ) 'Minor suggestion : Increase the resolution of the figures . ' : We will add new figures to reflect the AAE method added and improve older ones the next few days . We appreciate the proposal . [ 1 ] Cogswell , Michael , et al . `` Reducing overfitting in deep networks by decorrelating representations . `` , ICLR 2016 ."}, "2": {"review_id": "Byg0DsCqYQ-2", "review_text": "This manuscript proposes a robust version of conditional GAN (named RoC-GAN) that leverage the intrinsic structure in the output space. To achieve robustness, the authors replace the single pathway in the generator with two different pathways that partially share weights. The authors study the theoretical properties of RoC-GAN and prove that it shares the same properties as the vanilla GAN. For quantitative evaluations, the authors use two datasets of natural scenes and faces and evaluate denoising and sparse inpainting using the SSIM metric. - The idea is simple and seems to be working. The methodological novelties seem more-or-less limited, but the theoretical analysis and the intuitive (and well-motivated) modification over CGANs add merits to the paper. - The theoretical analysis of the method relates RoC-GAN to the original GAN, rather than CGAN! What is the connection here? If RoC-GAN is very similar to CGAN from a theoretical point of view (which it seems to be), then all the analysis to relate it to traditional GAN seem useless. - The extensive experiments in the supplementary material are appreciated. But the authors only compare their method with one single previous work (i.e., Rick Chang et al. (2017)), while there are several similar related works (either based on adversarial training strategies or simple denoising AEs). - Also, ablation studies can further show how each component of the model contributes to the final results. What if we were to only use the two-path generator without adversarial training? Different components of the final loss function can be removed and analyzed one at a time! - What are the conditions for mode-collapse for the proposed GAN? There are no discussions on this. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "In addition to the general answer above , we answer each of the points raised below : 1 ) 'The idea is simple and seems to be working . The methodological novelties seem more-or-less limited , but the theoretical analysis and the intuitive ( and well-motivated ) modification over CGANs add merits to the paper . ' : We thank the reviewer for the recognition of the work . 2 ) 'The theoretical analysis of the method relates RoC-GAN to the original GAN , rather than CGAN ! What is the connection here ? If RoC-GAN is very similar to CGAN from a theoretical point of view ( which it seems to be ) , then all the analysis to relate it to traditional GAN seem useless . ' : On the contrary , we prove that our RoC-GAN shares the same theoretical properties as GAN ; this can be seen as a sanity check , conforming that our method shares some beneficial theoretical properties with well-studied methods . Similar proofs are provided in other extensions to cGAN , such as Zhe et al . ( [ 1 ] ) .3 ) 'The extensive experiments in the supplementary material are appreciated . But the authors only compare their method with one single previous work ( i.e. , Rick Chang et al . ( 2017 ) ) , while there are several similar related works ( either based on adversarial training strategies or simple denoising AEs ) . ' : The goal of this work is not to propose a state-of-the-art network per se , but rather to present a method that is more robust to additional sources of noise . Our model is not architecture dependent . Specifically , RoC-GAN can be seen as a meta algorithm which can be used to augment any existing cGAN model to achieve additional robustness . We scrutinize the robustness under : i ) similar types of noise , ii ) types of noise not encountered during training , iii ) adversarial perturbations . In addition to those , we also note that our method performs favorably when tested with samples similar as the training distribution . We have included an external method to illustrate that even strong performing networks can have difficulty in such tasks . However , if there are some specific works that the reviewers feel are particularly relevant , we are happy to evaluate their pre-trained models . 4 ) 'Ablation studies can further show how each component of the model contributes to the final results . What if we were to only use the two-path generator without adversarial training ? Different components of the final loss function can be removed and analyzed one at a time ! ' : We appreciate the reviewer 's proposal ; indeed in the synthetic experiment we optimize only the generators to simplify the problem ; please see sec.3.4.In addition , removing one by one the losses is performed in sec.E.2 ( appendix ) . Even though our experiments are not exhaustive , we consider that we have covered a wide range of choices ; those demonstrate the merits or trade-offs of our RoC-GAN . 5 ) 'What are the conditions for mode-collapse for the proposed GAN ? There are no discussions on this . ' : We follow the same strategy as popular methods in cGAN ( [ 2 ] , [ 3 ] ) . We agree with the reviewer that mode collapse is significant especially in original GAN training , however there are other works tackling this issue , e.g. [ 4-6 ] . [ 1 ] Gan , Zhe , et al . `` Triangle generative adversarial networks . `` , NIPS 2017 . [ 2 ] Isola , Phillip et al . `` Image-to-Image Translation with Conditional Adversarial Networks '' , CVPR 2017 . [ 3 ] Zhu , Jun-Yan et al . `` Toward multimodal image-to-image translation '' , NIPS 2017 . [ 4 ] Che , Tong et al . `` Mode Regularized Generative Adversarial Networks '' , ICLR 2017 . [ 5 ] Anonymous , `` Generative Adversarial Network Training is a Continual Learning Problem '' , under review ICLR 2019 . [ 6 ] Anonymous , `` DISTRIBUTIONAL CONCAVITY REGULARIZATION FOR GANS '' , under review ICLR 2019 ."}}