{"year": "2021", "forum": "Ogga20D2HO-", "title": "FedMix: Approximation of Mixup under Mean Augmented Federated Learning", "decision": "Accept (Poster)", "meta_review": "The paper proposes to apply Mixup to Federated Learning (FL) for addressing the challenge of non-iid data. The idea is very simple, but seems to work well in empirical evaluation. Some concerns were raised regarding the communication costs and privacy. The authors rebuttal and revised draft provide reasonable answers to these concerns. \n\nFor the final version, it is suggested that the authors can address the following issues:\n\n1) Improve the writing - especially the formulation of the proposed method\n\n2) Provide more discussions and experiments on the communication costs. ", "reviews": [{"review_id": "Ogga20D2HO--0", "review_text": "This paper studies an interesting idea that applies Mixup to Federated Learning ( FL ) for addressing some challenges such as non-iid data . Basically , this is an empirical paper , and the overall organization is good , easy to read . However , I have several questions . 1.The authors claimed that `` FedMix approximates Global Mixup '' . In that case , why do not use Global Mixup directly ? By comparing ( 4 ) with ( 3 ) , both Global Mixup and FedMix use private image $ ( X_j , y_j ) $ , which can not violate privacy . 2.The mathematics is poorly written . ( a ) What is $ \\ell $ in $ \\frac { \\partial \\ell } { \\partial x } $ ? It could be $ \\ell ( x ) $ , $ \\ell ( f ( ( 1+\\lambda ) x_i ) , y_i ) $ , and $ \\ell ( f ( ( 1+\\lambda ) x_i+\\lambda x_j ) , y_j ) $ and so on . Please write it explicitly . ( b ) The last equation on Page 5 missed a $ \\frac { 1 } { |J| } $ on the left hand side since $ \\bar x $ or $ \\bar y $ means averages x_j or y_j . ( c ) In proposition 1 , it says `` we ignore the second order term ( i.e. , $ O ( \\lambda^2 ) $ ) '' , but why there is a $ \\lambda^2 $ in ( 4 ) ? Please check $ \\lambda ( 1-\\lambda ) =\\lambda - \\lambda^2 $ . ( d ) In Algorithm 1 and Algorithm 2 , what is k in `` LocalUpdate $ ( k , w_t , X_g , Y_g ) $ '' since there is no $ k $ in Algorithm 2 ? In Algorithm 2 , it seems the input is $ k , w_t , X_g , Y_g $ based on `` LocalUpdate $ ( k , w_t , X_g , Y_g ) $ '' , but what is $ X , Y $ in $ \\ell_1 $ and $ \\ell_2 $ ? In addition , what is $ x $ in $ \\ell_3 $ . I gauss $ w $ in Algorithm 2 should be $ w_t $ . 3.Based on Figure 1 and Algorithms 1 and 2 , $ \\ell_ { FedMix } $ is an approximation of $ \\ell_ { NaiveMix } $ rather than $ \\ell_ { GlobalMixup } $ , which can be easily verified by using Taylor expansion . In that case , NaiveMix and FedMix is very close when $ \\lambda $ is very small . However , the experimental results shows that FedMix is more closer to GlobalMixup than NaiveMix , which is not reasonable . Any explanations ? Did you use the approximation of GlobalMixup as FedMix ? If so , I think the presented results are not so interesting . 4.The experiments only conducted on three small data sets , but in FL , we are usually interested in big data . It would be better if the authors can provides results on big data such as ImageNet . 5.In table 8 , why NaiveMix and FedMix use different $ \\lambda $ for CIFAR10 ? On the other hand , why do n't you try different $ \\lambda $ for NaiveMix ? After Rebuttal The authors have addressed my main concerns , and I have updated my score to 6 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for a detailed review . We address the concerns below : 1.Why not use Global Mixup ? Global Mixup and FedMix uses same $ ( X_j , y_j ) $ , which does not violate privacy . We believe that it is due to critical misunderstanding . Global Mixup does hurt privacy and just an * * ideal * * baseline . It allows the client to directly access individual data points from other clients to perform Mixup , which is not possible in the actual federated setting . Our FedMix , on the other hand , approximates the Global Mixup , but in a way such that it only requires the client to have access to averages of data from other clients , without violating privacy constraints . The loss of FedMix in Equation ( 4 ) is just for a single entry , but that could be expanded to a loss value for a batch that only requires averaged data from other clients ( bottom of page 5 in the original paper ) , which is impossible for Global Mixup . 2 . ( a ) What is $ \\ell $ in $ \\frac { \\partial \\ell } { \\partial x } $ ? Since the loss function can be viewed as a function of $ x $ and $ y $ in the form of $ \\ell ( f ( x ) , y ) $ , $ \\frac { \\partial \\ell } { \\partial x } $ is simply a derivative function of loss by input . We will clarify this in the next version . 2 . ( b ) Divide by batch size before Sum operation > > > Thank you for the correction . We will revise accordingly . 2 . ( c ) Why is there $ \\mathcal { O } ( \\lambda^2 ) $ term in $ \\lambda ( 1-\\lambda ) $ > > > We will correct this point . 2 . ( d ) What is $ k $ in LocalUpdate ? $ X , Y $ in $ \\ell_2 $ ? $ x $ in $ \\ell_3 $ . $ k $ is the id of the client being traded , as stated in the \u201c for \u201d argument just above the LocalUpdate line . Algorithm 2 has $ X , Y $ , which is batch data selected from $ X_k $ and $ Y_k $ , data and labels of client $ k $ . $ x $ in $ \\ell_3 $ is an entry from $ X $ , as denoted just below the line . $ w $ in Algorithm 2 is $ w_t $ . We will revise algorithms accordingly so that all parameters are easily identifiable and understandable . 3.FedMix is an approximation of NaiveMix but performance of FedMix is closer to Global Mixup . We believe that this is also a misunderstanding . ( 1 ) FedMix is a valid mathematical approximation of Global Mixup ( see proof for Proposition 1 of our paper in appendix ) . While this approximation naturally coincides with that of NaiveMix ( since NaiveMix is equivalent to Global Mixup if we linearly approximate Mixup function ) , our only interest is that FedMix can be some approximation ( even though it is rough ) of Global Mixup . Therefore , it is * * not * * unreasonable that FedMix is close to Global Mixup compared to other algorithms not directly related to Global Mixup . In fact , it is desirable since Global Mixup is an ideal baseline . ( 2 ) Our results clearly demonstrate that NaiveMix < FedMix < Global Mixup in terms of accuracy , but our FedMix is much closer to our NaiveMix than ideal Global Mixup , contrary to the reviewer 's concern . In fact , this question 3 is a is bit unclear to us , so it may be the case that we misunderstood your intentions . If so , please ask again with little more details so that we can better understand . 4.How about big data such as ImageNet ? We agree with your concern that the scale of our experiment is below the size of big , real world federated learning applications . However , as FL is a relatively new problem to the machine learning field , the majority of papers studying FL simulated their data with small datasets such as MNIST and CIFAR-10 , so it is also an issue with the majority of research papers in this area ( and in our best knowledge , we did not find any FL paper with ImageNet experiments ) . In particular , the non-iid issue of FL we consider may occur regardless of the scale , and we expect that our mixup-based solution leveraging private data from other non-iid clients is not so sensitive to scale . For future work , we believe that our methods can be extended to the large scale datasets more relevant of real world federated learning situations . 5.Why is $ \\lambda $ different ? Why not test different $ \\lambda $ for NaiveMix ? We treated $ \\lambda $ as a hyperparameter , and picked the value that resulted in the best performance . NaiveMix was also fairly evaluated in this way . We will also append the results for NaiveMix in Table 5 ."}, {"review_id": "Ogga20D2HO--1", "review_text": "In this work , the authors aim to approach the non-iid data issue in FL by allowing for mean of the local client data to be transmitted in addition to the model parameters . I find this work very interesting and the paper well executed . First , the authors present the logic for MAFL , which encompasses the sending and receiving of other clients ' averaged data , followed by FedMix , a method for augmenting the local data-set with the averaged data from other clients . Throughout the method section and their experiments , the authors show the benefits of MAFL+FedMix by ablation to other MixUp inspired approaches . My issues with this paper are along some different aspects : Privacy : Sending statistics of local data is inherently less private than sending model parameters alone . The authors mention this explicitly , but do not go into more detail . I understand that the notion of privacy in FL is a research topic in itself , but I would wish for a more nuanced discussion of the trade-offs here . Throughout the experiment section , the largest 'federation ' of devices is N=100 for Cifar100 and Femnist . Taking cifar100 as example , each client has 50k/100 = 500 data-points , the average of which I can agree intuitively to be not very informative ( at least visually ) and the 'discriminative information ' that the authors mention , is presumably not very high . However , 500 data-points can still be considered a large amount of data-points for the federated scenario . As the number of data-points per client $ n_k $ decreases , the more information about individual data-points is contained in their average . The problem is increased as $ M_k > 1 $ . Further , 'discriminative information ' is not the only privacy-worthy information in FL . Differential Privacy , for example , is trying to quantify if an individual data-point is present in a local data-set . Since a client receives a concatenation $ ( X_g , Y_g ) = ( { \\bar { x } _1 , \\bar { x } _2 , ... , \\bar { x } _N } , { \\bar { y } _1 , \\bar { y } _2 , ... , \\bar { y } _N } ) $ of all clients ' averaged data-sets , an individual client 's participation in the training can also not be hidden from other clients . Furthermore , the formulation in Algorithm 1 implicitly assumes a continual learning setup where clients might be collecting more data as training progresses . In its current formulation , the authors do not mention if the batches are re-computed randomly , opening up the possibility for attacks on the differences between batches across time . Computational Burden : FedMix requires computing gradients through the Taylor expansion ( EQ 4 ) , which increases computation and memory requirements . Especially in a federated setting , computation and memory are constrained resources , so I would expect the authors to provide some estimates over the additional requirements for computing gradients $ \\nabla_w l_ { FedMix } $ Experimental Evaluation : I am missing some details on the setup for the FEMNIST dataset . At the moments , the authors mention selecting 100 clients , however I wonder if they used the writer-id or re-shuffled to create a controlled label-skew . If they used the writer-id , how did they select the subset of 100 clients ? Some details : I believe in Figure 1 b ) , the indices above 'Local data ' should be $ i $ , not $ j $ . Directly below Figure 1 , the sentence should begin with : `` A more practical approach to ... '' Algorithm 2 could be improved , I believe . I see no space constraint that would prevent including some more detailed information analogous to Algorithm 3 in the Appendix . I am assuming the gradient is calculated mini-batch wise . Ideally , the $ LocalUpdate $ would receive the same arguments as those that it is being called with on the server side for example . Top of page 5 : 'meshed ' - > 'mashed ' . Just above Eq ( 2 ) : ' ... client i has access to ... ' ( remove 'an ' ) . The experiments that would make this evaluation great in my opinion : Train on the full FEMNIST set of 3600clients including all those clients with very small number of data-points . Then introduce a cut-off-threshold for the minimum number of data-points that each client has to have in order to send its averaged data to the server . Alternatively , add random noise to these averages in relation to how much data is present . There is probably a differential privacy formulation that would make the required noise-level explicit . This noise level or cut-off-point should give more insight on several dimensions of the proposed work : - How sensitive is FedMix to different minimum required data-points as a trade-off with privacy . - How sensitive is $ \\lambda $ to different number of data-points per client ( or the consequence of fixed $ \\lambda $ generally as number of data-points per client differs ) . Since no other experiment has different number of data-points per client , I believe this to be relevant . Additionally , to further increase privacy , the authors might consider ( randomly ) averaging some of the elements in $ ( X_g , Y_g ) $ before sending the data to clients and study those effects . Summarizing , I want to thank the authors for this very interesting read and interesting insights . If the authors provide a more nuanced/detailed discussion of the privacy aspects of their work and extend their experimental section with the more holistic FEMNIST experiment I described above , I will raise my score ! I see no violation of the CoE in this work . Finally , I can not believe that the authors let the opportunity slide to name their algorithm 'FedUp ' ; )", "rating": "7: Good paper, accept", "reply_text": "7.Train on the full FEMNIST set of 3600clients including all those clients with very small number of data-points . Then introduce a cut-off-threshold for the minimum number of data-points that each client has to have in order to send its averaged data to the server . ... We thank the reviewer for suggesting a nice holistic experiment . We are currently running the experiment with $ N=3600 $ clients , but sadly , we think this will take too much time , from about several days to several weeks . Thus , we first briefly present test results with $ N=300 $ clients ( we had $ N=100 $ for our main FEMNIST result ) . We think $ N=300 $ will not result in a significant difference , since we do have a sufficient number of clients that have few local data , but if you have concerns and think setting $ N=3600 $ is necessary , please remind us . We introduced various cut-off threshold values to see the effect of constraining clients ' updates to the server . In the most extreme case , a threshold of 200 excludes about half of all clients from sending their averaged data . For each threshold , we also test various $ \\lambda $ values to assess the model 's sensitivity to $ \\lambda $ . We added the details of this new experiment as well as the results in the revision . To summarize , the threshold of 100 ( excluding < 10 % of clients ) resulted in the best possible performance ( even better than the case without the cut point ) . We think that excluding clients with substantially fewer data than others could improve performance since there is less overfitting to such local clients ' data . However , a further increase in the threshold resulted in a decline in performance , likely because there is fewer data to Mixup with , reducing its effectiveness . The reviewer also suggests to observe sensitivity of $ \\lambda $ to different number of data per client . We evaluated performance for various values of $ \\lambda $ without using cut off option here . We observe that $ \\lambda=0.2 $ is the optimal value ( same as for our $ N=100 $ main experiment ) , although there is only a small drop in performance for $ \\lambda=0.05,0.1 $ as each results in only 0.2 % less test accuracy . Comparing against CIFAR-10 in Table 5 ( where all clients have same number of data ) , the performance of the model in this experiment is less sensitive to value of $ \\lambda $ . Meanwhile , we also evaluated for each client that has different number of data in this experiment . We observe that there is no particular tendency on the sensitive to $ \\lambda $ according to the number of data . This experiment was also added on Appendix in the revision . 8.Additionally , to further increase privacy , the authors might consider ( randomly ) averaging some of the elements in $ ( X_g , y_g ) $ before sending the data to clients and study those effects . Thank you for suggesting a very interesting extension . Averaging among $ ( X_g , y_g ) $ as suggested by the reviewer practically can provide additional protection of privacy . This procedure will further increase privacy but will result in less number of data points in the set $ ( X_g , y_g ) $ for training . We added the results of this additional experiment in the appendix of the revision . First we define a parameter $ m $ indicating how much entries of $ ( X_g , y_g ) $ were used for further random averaging . On CIFAR-10 , for $ m=4 $ , FedMix results in an accuracy of 81.6 % , which is even higher than our main result of 81.2 % , although not by much . Meanwhile , $ m=10 $ results in a significant decrease to 78.4 % . We think that optimal value of $ m $ is decided by balancing between higher privacy ( larger $ m $ ) and more data points in $ ( X_g , y_g ) $ ( smaller $ m $ ) . We think that this averaging among $ ( X_g , y_g ) $ opens the possibility of averaged data come from more than $ n_k $ individual data , further ensuring privacy , and potentially even increasing performance ."}, {"review_id": "Ogga20D2HO--2", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper proposed MAFL , a novel approach to conduct Mixup under the federated learning setting whiling preserving data privacy . The proposed FedMix scheme is inspired by Taylor \u2019 s expansion of the global Mixup formulation . The effectiveness of MAFL is justified via empirical studies over a simulated federated learning environment , which indicates that Mixup achieves better test accuracies on various machine learning tasks . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Reasons for score : My overall evaluation score on the current manuscript is borderline reject . The research direction on studying the effectiveness of data augmentation under the federated learning setting is promising . The formulation and motivation of the proposed MAFL scheme are sound . The main justification on FedMix is from the experimental study , which can be further improved e.g.the communication cost and privacy of FedMix can be more explicitly studied . If the proposed MAFL scheme can be supported by some theoretical analysis , the current manuscript can be much stronger . I will be happy to increase my overall evaluation score if my major concerns are addressed . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper studies the effectiveness and practicality of conducting data augmentation under the federated learning scenario , which is quite promising and can potentially gain impact . 2.The proposed FedMix method is motivated via using Taylor expansion to approximate the global Mixup data augmentation objective , which makes sense in general . 3.Extensive experimental results are provided under the image classification and the next-word prediction tasks under the simulated non-iid environment , which indicates that FedMix enjoys high effectiveness on improving the model test accuracy under the data heterogeneity . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : 1 . The main concern on the proposed FedMix method is communication and computation efficiency . From the proposed Algorithm 1 , for each FL round , MAFL requires all available clients to upload their locally averaged data batches . It is easy to imagine in a real federated learning environment ( with up to $ 10^ { 10 } $ available clients ) , it can lead to a significant communication overhead [ 1 ] . Thus , it would be useful to explicitly study the communication cost of MAFL , e.g.report Test Accuracy vs the amount of communication for Figure 2 can help to understand the communication efficiency of MAFL better . 2.It \u2019 s not clear how MAFL splits the local datasets . Does it a conduct random split ? Would it be possible for each local client to put \u201c similar \u201d ( e.g.data points within the same class ) into the same batch ? Such an approach intuitively preserves more data property in $ \\bar x $ and $ \\bar y $ . 3.Although a value of small $ M_k $ in MAFL leads to worse data privacy , it \u2019 s easy to imagine the proposed MAFL can be combined with other differential private ( DP ) method e.g . [ 2 ] .It will be useful to consider a DP version of MAFL . 4.The authors are encouraged to add the baseline of \u201c Global Mixup \u201d to Table 2 , 3 , 4 , 6 , 7 to understand the gap between the proposed FedMix method and the \u201c ideal \u201d baseline . 5.The FedProx result on FEMNIST is a bit confusing , what accuracy will FedProx reach for running 32 FL rounds ? 6.For the image classification tasks , it seems FedMix outperforms other baselines . However , for the language task e.g.Table 2 , it only matches the accuracy of NaiveMix . Does it mean FedMix can be improved for augmenting language examples ? 7.The approach to simulate data heterogeneity in the current paper can be generalized by the method proposed in [ 3-4 ] . It would be useful to consider the Dirichlet distribution based data partition strategy . [ 1 ] https : //arxiv.org/pdf/1912.04977.pdf [ 2 ] https : //arxiv.org/pdf/1710.06963.pdf [ 3 ] https : //arxiv.org/pdf/1905.12022.pdf [ 4 ] https : //arxiv.org/pdf/2002.06440.pdf # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Minor Comments : 1 . It seems the CIFAR-10 and CIFAR-100 curves in Figure 2 are not reaching to full convergence . Thus , it would be helpful to run the experiments for more FL rounds . 2.Missing references : [ 1-2 ] . And some references are sort of outdated e.g. \u201c Federated optimization in heterogeneous networks \u201d ( T Li et al ) was accepted to MLSys 2020 . [ 1 ] https : //arxiv.org/abs/1912.04977 [ 2 ] https : //arxiv.org/abs/1908.07873 # # # # # # # # # # # # # # # # # # # # # # Post Rebuttal # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Most of my concerns on the current manuscript are addressed . I tend to increase my overall evaluation score to 6 . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #", "rating": "6: Marginally above acceptance threshold", "reply_text": "5.The FedProx result on FEMNIST is a bit confusing , what accuracy will FedProx reach for running 32 FL rounds ? FedProx shows 80.8 % accuracy after 32 FL rounds . But as we clearly mentioned in the caption , Table 1 shows the test accuracy after ( target rounds ) and the required number of rounds to reach ( target test accuracy ) . Hence , round 29 for FedProx in Table 1 does not mean that it achieves 84.6 % with 29 rounds , but it means that it took 29 rounds to reach test accuracy of 80 % . So the result would be interpreted that while FedProx reached 80 % accuracy slightly faster , the final accuracy ( with 200 rounds for all methods ) was much lower than FedProx+FedMix . We revised the table to make sure the readers understand the data more easily . 6.Can FedMix be improved for augmenting language models ? While Mixup has been successfully implemented in NLP [ 1 ] , Mixup is not a popular procedure implemented in most prominent works in NLP . Interestingly , even Global Mixup does not result in an obvious increase in performance compared to FedMix . At some Mixup ratio , Global Mixup sometimes results in performance degradation than FedMix or other baselines . We think that for FedMix to be more effective , Global Mixup should first show more significant improvement over FedAvg , which is not that case in this task . We think that this is the main reason why FedMix and NaiveMix show similar performances , but we want to stress that both FedMix and NaiveMix are the members under our MAFL framework and they are still better compared to other baselines in Shakespeare dataset . We also note that since Mixup on raw input is not possible on the language datasets as it is done for images , we implement a latent Mixup version of each method ( discussion about this alternative version on image classification tasks is present in the appendix of the original paper ) . 7.Use Dirichlet distribution to introduce data heterogeneity . We thank the reviewer for providing another good way to introduce data heterogeneity . We conducted additional experiments using Dirichlet distribution with $ \\alpha=0.5 $ to introduce the suggested heterogeneity on CIFAR-10 dataset . To summarize , FedMix still has the best performance with 88.4 % accuracy , while FedAvg results in 87.6 % accuracy . Since this setting is * * less * * heterogeneous than our introduction of a limited number of classes per client , there is a smaller difference between the algorithms . We added the results in the revision in Appendix J . Minor comments 1.Convergence of FedMix on CIFAR-10 and CIFAR-100 We ran some of the experiments for more FL rounds . For instance , when tested for 1,000 rounds on CIFAR-10 , FedAvg converges to 82.7 % accuracy , and FedMix to 84.4 % accuracy , outperforming FedAvg . 2.Missing References References are added and fixed in our revision . [ 1 ] https : //arxiv.org/abs/1905.08941.pdf"}], "0": {"review_id": "Ogga20D2HO--0", "review_text": "This paper studies an interesting idea that applies Mixup to Federated Learning ( FL ) for addressing some challenges such as non-iid data . Basically , this is an empirical paper , and the overall organization is good , easy to read . However , I have several questions . 1.The authors claimed that `` FedMix approximates Global Mixup '' . In that case , why do not use Global Mixup directly ? By comparing ( 4 ) with ( 3 ) , both Global Mixup and FedMix use private image $ ( X_j , y_j ) $ , which can not violate privacy . 2.The mathematics is poorly written . ( a ) What is $ \\ell $ in $ \\frac { \\partial \\ell } { \\partial x } $ ? It could be $ \\ell ( x ) $ , $ \\ell ( f ( ( 1+\\lambda ) x_i ) , y_i ) $ , and $ \\ell ( f ( ( 1+\\lambda ) x_i+\\lambda x_j ) , y_j ) $ and so on . Please write it explicitly . ( b ) The last equation on Page 5 missed a $ \\frac { 1 } { |J| } $ on the left hand side since $ \\bar x $ or $ \\bar y $ means averages x_j or y_j . ( c ) In proposition 1 , it says `` we ignore the second order term ( i.e. , $ O ( \\lambda^2 ) $ ) '' , but why there is a $ \\lambda^2 $ in ( 4 ) ? Please check $ \\lambda ( 1-\\lambda ) =\\lambda - \\lambda^2 $ . ( d ) In Algorithm 1 and Algorithm 2 , what is k in `` LocalUpdate $ ( k , w_t , X_g , Y_g ) $ '' since there is no $ k $ in Algorithm 2 ? In Algorithm 2 , it seems the input is $ k , w_t , X_g , Y_g $ based on `` LocalUpdate $ ( k , w_t , X_g , Y_g ) $ '' , but what is $ X , Y $ in $ \\ell_1 $ and $ \\ell_2 $ ? In addition , what is $ x $ in $ \\ell_3 $ . I gauss $ w $ in Algorithm 2 should be $ w_t $ . 3.Based on Figure 1 and Algorithms 1 and 2 , $ \\ell_ { FedMix } $ is an approximation of $ \\ell_ { NaiveMix } $ rather than $ \\ell_ { GlobalMixup } $ , which can be easily verified by using Taylor expansion . In that case , NaiveMix and FedMix is very close when $ \\lambda $ is very small . However , the experimental results shows that FedMix is more closer to GlobalMixup than NaiveMix , which is not reasonable . Any explanations ? Did you use the approximation of GlobalMixup as FedMix ? If so , I think the presented results are not so interesting . 4.The experiments only conducted on three small data sets , but in FL , we are usually interested in big data . It would be better if the authors can provides results on big data such as ImageNet . 5.In table 8 , why NaiveMix and FedMix use different $ \\lambda $ for CIFAR10 ? On the other hand , why do n't you try different $ \\lambda $ for NaiveMix ? After Rebuttal The authors have addressed my main concerns , and I have updated my score to 6 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for a detailed review . We address the concerns below : 1.Why not use Global Mixup ? Global Mixup and FedMix uses same $ ( X_j , y_j ) $ , which does not violate privacy . We believe that it is due to critical misunderstanding . Global Mixup does hurt privacy and just an * * ideal * * baseline . It allows the client to directly access individual data points from other clients to perform Mixup , which is not possible in the actual federated setting . Our FedMix , on the other hand , approximates the Global Mixup , but in a way such that it only requires the client to have access to averages of data from other clients , without violating privacy constraints . The loss of FedMix in Equation ( 4 ) is just for a single entry , but that could be expanded to a loss value for a batch that only requires averaged data from other clients ( bottom of page 5 in the original paper ) , which is impossible for Global Mixup . 2 . ( a ) What is $ \\ell $ in $ \\frac { \\partial \\ell } { \\partial x } $ ? Since the loss function can be viewed as a function of $ x $ and $ y $ in the form of $ \\ell ( f ( x ) , y ) $ , $ \\frac { \\partial \\ell } { \\partial x } $ is simply a derivative function of loss by input . We will clarify this in the next version . 2 . ( b ) Divide by batch size before Sum operation > > > Thank you for the correction . We will revise accordingly . 2 . ( c ) Why is there $ \\mathcal { O } ( \\lambda^2 ) $ term in $ \\lambda ( 1-\\lambda ) $ > > > We will correct this point . 2 . ( d ) What is $ k $ in LocalUpdate ? $ X , Y $ in $ \\ell_2 $ ? $ x $ in $ \\ell_3 $ . $ k $ is the id of the client being traded , as stated in the \u201c for \u201d argument just above the LocalUpdate line . Algorithm 2 has $ X , Y $ , which is batch data selected from $ X_k $ and $ Y_k $ , data and labels of client $ k $ . $ x $ in $ \\ell_3 $ is an entry from $ X $ , as denoted just below the line . $ w $ in Algorithm 2 is $ w_t $ . We will revise algorithms accordingly so that all parameters are easily identifiable and understandable . 3.FedMix is an approximation of NaiveMix but performance of FedMix is closer to Global Mixup . We believe that this is also a misunderstanding . ( 1 ) FedMix is a valid mathematical approximation of Global Mixup ( see proof for Proposition 1 of our paper in appendix ) . While this approximation naturally coincides with that of NaiveMix ( since NaiveMix is equivalent to Global Mixup if we linearly approximate Mixup function ) , our only interest is that FedMix can be some approximation ( even though it is rough ) of Global Mixup . Therefore , it is * * not * * unreasonable that FedMix is close to Global Mixup compared to other algorithms not directly related to Global Mixup . In fact , it is desirable since Global Mixup is an ideal baseline . ( 2 ) Our results clearly demonstrate that NaiveMix < FedMix < Global Mixup in terms of accuracy , but our FedMix is much closer to our NaiveMix than ideal Global Mixup , contrary to the reviewer 's concern . In fact , this question 3 is a is bit unclear to us , so it may be the case that we misunderstood your intentions . If so , please ask again with little more details so that we can better understand . 4.How about big data such as ImageNet ? We agree with your concern that the scale of our experiment is below the size of big , real world federated learning applications . However , as FL is a relatively new problem to the machine learning field , the majority of papers studying FL simulated their data with small datasets such as MNIST and CIFAR-10 , so it is also an issue with the majority of research papers in this area ( and in our best knowledge , we did not find any FL paper with ImageNet experiments ) . In particular , the non-iid issue of FL we consider may occur regardless of the scale , and we expect that our mixup-based solution leveraging private data from other non-iid clients is not so sensitive to scale . For future work , we believe that our methods can be extended to the large scale datasets more relevant of real world federated learning situations . 5.Why is $ \\lambda $ different ? Why not test different $ \\lambda $ for NaiveMix ? We treated $ \\lambda $ as a hyperparameter , and picked the value that resulted in the best performance . NaiveMix was also fairly evaluated in this way . We will also append the results for NaiveMix in Table 5 ."}, "1": {"review_id": "Ogga20D2HO--1", "review_text": "In this work , the authors aim to approach the non-iid data issue in FL by allowing for mean of the local client data to be transmitted in addition to the model parameters . I find this work very interesting and the paper well executed . First , the authors present the logic for MAFL , which encompasses the sending and receiving of other clients ' averaged data , followed by FedMix , a method for augmenting the local data-set with the averaged data from other clients . Throughout the method section and their experiments , the authors show the benefits of MAFL+FedMix by ablation to other MixUp inspired approaches . My issues with this paper are along some different aspects : Privacy : Sending statistics of local data is inherently less private than sending model parameters alone . The authors mention this explicitly , but do not go into more detail . I understand that the notion of privacy in FL is a research topic in itself , but I would wish for a more nuanced discussion of the trade-offs here . Throughout the experiment section , the largest 'federation ' of devices is N=100 for Cifar100 and Femnist . Taking cifar100 as example , each client has 50k/100 = 500 data-points , the average of which I can agree intuitively to be not very informative ( at least visually ) and the 'discriminative information ' that the authors mention , is presumably not very high . However , 500 data-points can still be considered a large amount of data-points for the federated scenario . As the number of data-points per client $ n_k $ decreases , the more information about individual data-points is contained in their average . The problem is increased as $ M_k > 1 $ . Further , 'discriminative information ' is not the only privacy-worthy information in FL . Differential Privacy , for example , is trying to quantify if an individual data-point is present in a local data-set . Since a client receives a concatenation $ ( X_g , Y_g ) = ( { \\bar { x } _1 , \\bar { x } _2 , ... , \\bar { x } _N } , { \\bar { y } _1 , \\bar { y } _2 , ... , \\bar { y } _N } ) $ of all clients ' averaged data-sets , an individual client 's participation in the training can also not be hidden from other clients . Furthermore , the formulation in Algorithm 1 implicitly assumes a continual learning setup where clients might be collecting more data as training progresses . In its current formulation , the authors do not mention if the batches are re-computed randomly , opening up the possibility for attacks on the differences between batches across time . Computational Burden : FedMix requires computing gradients through the Taylor expansion ( EQ 4 ) , which increases computation and memory requirements . Especially in a federated setting , computation and memory are constrained resources , so I would expect the authors to provide some estimates over the additional requirements for computing gradients $ \\nabla_w l_ { FedMix } $ Experimental Evaluation : I am missing some details on the setup for the FEMNIST dataset . At the moments , the authors mention selecting 100 clients , however I wonder if they used the writer-id or re-shuffled to create a controlled label-skew . If they used the writer-id , how did they select the subset of 100 clients ? Some details : I believe in Figure 1 b ) , the indices above 'Local data ' should be $ i $ , not $ j $ . Directly below Figure 1 , the sentence should begin with : `` A more practical approach to ... '' Algorithm 2 could be improved , I believe . I see no space constraint that would prevent including some more detailed information analogous to Algorithm 3 in the Appendix . I am assuming the gradient is calculated mini-batch wise . Ideally , the $ LocalUpdate $ would receive the same arguments as those that it is being called with on the server side for example . Top of page 5 : 'meshed ' - > 'mashed ' . Just above Eq ( 2 ) : ' ... client i has access to ... ' ( remove 'an ' ) . The experiments that would make this evaluation great in my opinion : Train on the full FEMNIST set of 3600clients including all those clients with very small number of data-points . Then introduce a cut-off-threshold for the minimum number of data-points that each client has to have in order to send its averaged data to the server . Alternatively , add random noise to these averages in relation to how much data is present . There is probably a differential privacy formulation that would make the required noise-level explicit . This noise level or cut-off-point should give more insight on several dimensions of the proposed work : - How sensitive is FedMix to different minimum required data-points as a trade-off with privacy . - How sensitive is $ \\lambda $ to different number of data-points per client ( or the consequence of fixed $ \\lambda $ generally as number of data-points per client differs ) . Since no other experiment has different number of data-points per client , I believe this to be relevant . Additionally , to further increase privacy , the authors might consider ( randomly ) averaging some of the elements in $ ( X_g , Y_g ) $ before sending the data to clients and study those effects . Summarizing , I want to thank the authors for this very interesting read and interesting insights . If the authors provide a more nuanced/detailed discussion of the privacy aspects of their work and extend their experimental section with the more holistic FEMNIST experiment I described above , I will raise my score ! I see no violation of the CoE in this work . Finally , I can not believe that the authors let the opportunity slide to name their algorithm 'FedUp ' ; )", "rating": "7: Good paper, accept", "reply_text": "7.Train on the full FEMNIST set of 3600clients including all those clients with very small number of data-points . Then introduce a cut-off-threshold for the minimum number of data-points that each client has to have in order to send its averaged data to the server . ... We thank the reviewer for suggesting a nice holistic experiment . We are currently running the experiment with $ N=3600 $ clients , but sadly , we think this will take too much time , from about several days to several weeks . Thus , we first briefly present test results with $ N=300 $ clients ( we had $ N=100 $ for our main FEMNIST result ) . We think $ N=300 $ will not result in a significant difference , since we do have a sufficient number of clients that have few local data , but if you have concerns and think setting $ N=3600 $ is necessary , please remind us . We introduced various cut-off threshold values to see the effect of constraining clients ' updates to the server . In the most extreme case , a threshold of 200 excludes about half of all clients from sending their averaged data . For each threshold , we also test various $ \\lambda $ values to assess the model 's sensitivity to $ \\lambda $ . We added the details of this new experiment as well as the results in the revision . To summarize , the threshold of 100 ( excluding < 10 % of clients ) resulted in the best possible performance ( even better than the case without the cut point ) . We think that excluding clients with substantially fewer data than others could improve performance since there is less overfitting to such local clients ' data . However , a further increase in the threshold resulted in a decline in performance , likely because there is fewer data to Mixup with , reducing its effectiveness . The reviewer also suggests to observe sensitivity of $ \\lambda $ to different number of data per client . We evaluated performance for various values of $ \\lambda $ without using cut off option here . We observe that $ \\lambda=0.2 $ is the optimal value ( same as for our $ N=100 $ main experiment ) , although there is only a small drop in performance for $ \\lambda=0.05,0.1 $ as each results in only 0.2 % less test accuracy . Comparing against CIFAR-10 in Table 5 ( where all clients have same number of data ) , the performance of the model in this experiment is less sensitive to value of $ \\lambda $ . Meanwhile , we also evaluated for each client that has different number of data in this experiment . We observe that there is no particular tendency on the sensitive to $ \\lambda $ according to the number of data . This experiment was also added on Appendix in the revision . 8.Additionally , to further increase privacy , the authors might consider ( randomly ) averaging some of the elements in $ ( X_g , y_g ) $ before sending the data to clients and study those effects . Thank you for suggesting a very interesting extension . Averaging among $ ( X_g , y_g ) $ as suggested by the reviewer practically can provide additional protection of privacy . This procedure will further increase privacy but will result in less number of data points in the set $ ( X_g , y_g ) $ for training . We added the results of this additional experiment in the appendix of the revision . First we define a parameter $ m $ indicating how much entries of $ ( X_g , y_g ) $ were used for further random averaging . On CIFAR-10 , for $ m=4 $ , FedMix results in an accuracy of 81.6 % , which is even higher than our main result of 81.2 % , although not by much . Meanwhile , $ m=10 $ results in a significant decrease to 78.4 % . We think that optimal value of $ m $ is decided by balancing between higher privacy ( larger $ m $ ) and more data points in $ ( X_g , y_g ) $ ( smaller $ m $ ) . We think that this averaging among $ ( X_g , y_g ) $ opens the possibility of averaged data come from more than $ n_k $ individual data , further ensuring privacy , and potentially even increasing performance ."}, "2": {"review_id": "Ogga20D2HO--2", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper proposed MAFL , a novel approach to conduct Mixup under the federated learning setting whiling preserving data privacy . The proposed FedMix scheme is inspired by Taylor \u2019 s expansion of the global Mixup formulation . The effectiveness of MAFL is justified via empirical studies over a simulated federated learning environment , which indicates that Mixup achieves better test accuracies on various machine learning tasks . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Reasons for score : My overall evaluation score on the current manuscript is borderline reject . The research direction on studying the effectiveness of data augmentation under the federated learning setting is promising . The formulation and motivation of the proposed MAFL scheme are sound . The main justification on FedMix is from the experimental study , which can be further improved e.g.the communication cost and privacy of FedMix can be more explicitly studied . If the proposed MAFL scheme can be supported by some theoretical analysis , the current manuscript can be much stronger . I will be happy to increase my overall evaluation score if my major concerns are addressed . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper studies the effectiveness and practicality of conducting data augmentation under the federated learning scenario , which is quite promising and can potentially gain impact . 2.The proposed FedMix method is motivated via using Taylor expansion to approximate the global Mixup data augmentation objective , which makes sense in general . 3.Extensive experimental results are provided under the image classification and the next-word prediction tasks under the simulated non-iid environment , which indicates that FedMix enjoys high effectiveness on improving the model test accuracy under the data heterogeneity . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : 1 . The main concern on the proposed FedMix method is communication and computation efficiency . From the proposed Algorithm 1 , for each FL round , MAFL requires all available clients to upload their locally averaged data batches . It is easy to imagine in a real federated learning environment ( with up to $ 10^ { 10 } $ available clients ) , it can lead to a significant communication overhead [ 1 ] . Thus , it would be useful to explicitly study the communication cost of MAFL , e.g.report Test Accuracy vs the amount of communication for Figure 2 can help to understand the communication efficiency of MAFL better . 2.It \u2019 s not clear how MAFL splits the local datasets . Does it a conduct random split ? Would it be possible for each local client to put \u201c similar \u201d ( e.g.data points within the same class ) into the same batch ? Such an approach intuitively preserves more data property in $ \\bar x $ and $ \\bar y $ . 3.Although a value of small $ M_k $ in MAFL leads to worse data privacy , it \u2019 s easy to imagine the proposed MAFL can be combined with other differential private ( DP ) method e.g . [ 2 ] .It will be useful to consider a DP version of MAFL . 4.The authors are encouraged to add the baseline of \u201c Global Mixup \u201d to Table 2 , 3 , 4 , 6 , 7 to understand the gap between the proposed FedMix method and the \u201c ideal \u201d baseline . 5.The FedProx result on FEMNIST is a bit confusing , what accuracy will FedProx reach for running 32 FL rounds ? 6.For the image classification tasks , it seems FedMix outperforms other baselines . However , for the language task e.g.Table 2 , it only matches the accuracy of NaiveMix . Does it mean FedMix can be improved for augmenting language examples ? 7.The approach to simulate data heterogeneity in the current paper can be generalized by the method proposed in [ 3-4 ] . It would be useful to consider the Dirichlet distribution based data partition strategy . [ 1 ] https : //arxiv.org/pdf/1912.04977.pdf [ 2 ] https : //arxiv.org/pdf/1710.06963.pdf [ 3 ] https : //arxiv.org/pdf/1905.12022.pdf [ 4 ] https : //arxiv.org/pdf/2002.06440.pdf # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Minor Comments : 1 . It seems the CIFAR-10 and CIFAR-100 curves in Figure 2 are not reaching to full convergence . Thus , it would be helpful to run the experiments for more FL rounds . 2.Missing references : [ 1-2 ] . And some references are sort of outdated e.g. \u201c Federated optimization in heterogeneous networks \u201d ( T Li et al ) was accepted to MLSys 2020 . [ 1 ] https : //arxiv.org/abs/1912.04977 [ 2 ] https : //arxiv.org/abs/1908.07873 # # # # # # # # # # # # # # # # # # # # # # Post Rebuttal # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Most of my concerns on the current manuscript are addressed . I tend to increase my overall evaluation score to 6 . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #", "rating": "6: Marginally above acceptance threshold", "reply_text": "5.The FedProx result on FEMNIST is a bit confusing , what accuracy will FedProx reach for running 32 FL rounds ? FedProx shows 80.8 % accuracy after 32 FL rounds . But as we clearly mentioned in the caption , Table 1 shows the test accuracy after ( target rounds ) and the required number of rounds to reach ( target test accuracy ) . Hence , round 29 for FedProx in Table 1 does not mean that it achieves 84.6 % with 29 rounds , but it means that it took 29 rounds to reach test accuracy of 80 % . So the result would be interpreted that while FedProx reached 80 % accuracy slightly faster , the final accuracy ( with 200 rounds for all methods ) was much lower than FedProx+FedMix . We revised the table to make sure the readers understand the data more easily . 6.Can FedMix be improved for augmenting language models ? While Mixup has been successfully implemented in NLP [ 1 ] , Mixup is not a popular procedure implemented in most prominent works in NLP . Interestingly , even Global Mixup does not result in an obvious increase in performance compared to FedMix . At some Mixup ratio , Global Mixup sometimes results in performance degradation than FedMix or other baselines . We think that for FedMix to be more effective , Global Mixup should first show more significant improvement over FedAvg , which is not that case in this task . We think that this is the main reason why FedMix and NaiveMix show similar performances , but we want to stress that both FedMix and NaiveMix are the members under our MAFL framework and they are still better compared to other baselines in Shakespeare dataset . We also note that since Mixup on raw input is not possible on the language datasets as it is done for images , we implement a latent Mixup version of each method ( discussion about this alternative version on image classification tasks is present in the appendix of the original paper ) . 7.Use Dirichlet distribution to introduce data heterogeneity . We thank the reviewer for providing another good way to introduce data heterogeneity . We conducted additional experiments using Dirichlet distribution with $ \\alpha=0.5 $ to introduce the suggested heterogeneity on CIFAR-10 dataset . To summarize , FedMix still has the best performance with 88.4 % accuracy , while FedAvg results in 87.6 % accuracy . Since this setting is * * less * * heterogeneous than our introduction of a limited number of classes per client , there is a smaller difference between the algorithms . We added the results in the revision in Appendix J . Minor comments 1.Convergence of FedMix on CIFAR-10 and CIFAR-100 We ran some of the experiments for more FL rounds . For instance , when tested for 1,000 rounds on CIFAR-10 , FedAvg converges to 82.7 % accuracy , and FedMix to 84.4 % accuracy , outperforming FedAvg . 2.Missing References References are added and fixed in our revision . [ 1 ] https : //arxiv.org/abs/1905.08941.pdf"}}