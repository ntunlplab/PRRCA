{"year": "2019", "forum": "rkxn7nR5KX", "title": "Incremental Few-Shot Learning with Attention Attractor Networks", "decision": "Reject", "meta_review": "This paper proposes an approach for incremental learning of new classes using meta-learning.\nStrengths: The framework is interesting. The reviewers agree that the paper is well-written and clear. The experiments include comparisons to prior work, and the ablation studies are useful for judging the performance of the method.\nWeaknesses: The paper does not provide significant insights over Gidaris & Komodakis '18. Reviewer 1 was also concerned that the motivation for RBP is not entirely clear.\nOverall, the reviewers found that the strengths did not outweigh the weaknesses. Hence, I recommend reject.\n", "reviews": [{"review_id": "rkxn7nR5KX-0", "review_text": "The paper addresses the incremental few-shot learning problem where a model starts with base network and then introduces the novel classes, building a connection between novel and base classes via an attention module. Strengths: + clear writing. + the experiments are compared with related work and the ablation studies can verify the effectiveness of the proposed (or \"introduced\" would be a precise term) recurrent BP. Weakness: - [Novelty] The paper title is called attention attractor network, which shares very relevance to previous CVPR work (Gidaris & Komodakis, 2018). So the first thing I was looking for is the clear description of the difference between these two. Unfortunately, in related work, authors mention the CVPR work without stating the difference (last few lines in Section 2). As such, I don't see much novelty in the paper compared with previous work. Eqn. (7)-(10) explicitly describes the attention formula. What's the distinction from the CVPR work? - [Motivation of the regularizer using Recurrent BP is not clear] The use of recurrent BP is probably the most distinction from previous work. However, I don't see a clear description on why such a technique is necessary. Starting from the first line in Section 3.3, \"since there is no closed-form of the regularizer in Eqn (13)\", E needs BPTT or the introduced recurrent BP. This part is simply a re-adaption of other algorithms. A very simple question is, how about use other regularizers to replace Eqn (13)? - [Some experiments missing] The experiments section 4.6 uses a case of None and \"best WD\" to address some of my concerns. This is good. Does the \"gamma random\" indicates only E is used without the ||W||^2? why the best WD for one-shot is zero? This implies the model is best for applying no weight decay? What's the effect of using the recurrent BP technique to the CVPR work? Is there some similar improvement? If yes, then the paper makes some contribution by the regularization. If not, what's the reason? How about using the truncated BPTT with a larger T? In general, I think the recurrent BP part should be the highlight of the paper and yet authors fail to spread such a spirit in the abstract or title. And there are some experiments missed as I mentioned above. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the review . We are currently revising the paper and will incorporate your helpful suggestions ( to add discussion to CVPR work , add BPTT with larger T , and highlight the RBP algorithm ) . - Novelty : First , we would like to address the novelty issue . Although both our work and the CVPR paper uses attention mechanism , the two methods are actually very different . The new weights in their method are based on Prototypical Networks , i.e.simply averaging the embedding . We however optimize the weights on the new task and backprop through the optimization , which is a challenging step in learning our model . The attention mechanism is also formulated differently . Whereas the attended content is used as multiplicative gating in their work , we used it as an additive energy term in the overall objective function to optimize . - Applying RBP to the CVPR work : The CVPR work is based on a Prototypical Network which computes weights for the novel classes in a single layer , and regular backpropagation is sufficient . Since there is no iterative optimization involved , we do not see anything that allows us to apply RBP to the CVPR work , or any need for it . - Motivation of RBP : Since we have an iterative optimization procedure in the model , directly differentiating through the procedure is not straightforward . Also , as shown in the experiment , regular backprop through time does not learn a stable objective function . Prior work focus on the case where there is a closed form solution ( Bertinetto et al.2018 ) , where RBP allows us to backprop through any converging optimization layers , which is more general . - Best WD : Yes , in that experiment , no weight decay is needed ( although adding a small amount of WD does not hurt the performance ) . In the other experiments , we found a small amount of weight decay ( 1E-5 ) helped . - BPTT with larger T : Thank you for the suggestion . We are currently adding more experiments that use a larger T for BPTT and will update the paper with the latest results ."}, {"review_id": "rkxn7nR5KX-1", "review_text": "This work addresses incremental few-shot learning that learns novel classes without forgetting old classes, which is interesting and different from conventional few-shot learning that considers only the few-shot learning task of interest. This problem is also related closely to the important problem of life-long learning. This work presents an interesting framework based on meta-learning by learning to learn how to attend to the old classes using an attention mechanism. Experimental results also show improvement over two related works on incremental few-shot learning. The writing is quite clear. Some concerns, especially its novelty, are listed below. 1. The novelty appears to be limited. The presented framework looks quite similar to the recent work Spyros Gidaris and Nikos Komodakis. Dynamic few-shot visual learning without forgetting. CVPR'18 that addresses the same problem in a similar manner: 1) learn a base feature extractor and classifier; and then 2) attend to old classes also via meta-learning and attention mechanism. As mentioned by the authors, \"The main difference to this work is that we use an iterative optimization to compute W_b\". More discussions on the iterative optimization and why it matters may be helpful. Another related work is \"Deep Meta-Learning: Learning to Learn in the Concept Space\", Arxiv'18, that also relies on an external base classes for few-shot learning. Similar to the proposed research, it also learns a feature extractor and a classifier from the base classes, which are used to regularize the learning of novel classes, in an end-to-end meta-learning manner. Extending it for the incremental setting seems natural. 2. To learn a few novel classes, all U_k on old classes are relearned, which seems quite time-consuming with a large vocabulary of base classes. 3. To learn a few novel classes, old data on base classes are still required, which seems different from how humans learn -- humans learn novel concepts solely from a few examples without forgetting old concepts, without requiring examples on old concepts. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the review . We would like first explain the novelty aspect of our paper . - Novelty : Although both our work and the CVPR paper use an attention mechanism , the two methods are actually very different . The new weights in their method are based on Prototypical Nets , i.e.simply averaging the embedding . We however optimize the weights on the new task and backprop through the optimization , which is a challenging step in learning our model . The attention mechanism is also formulated differently . Whereas the attended content is used as multiplicative gating in their work , we used it as an additive energy term in the overall objective function to optimize . Secondly , there seem to be a couple crucial misunderstandings in the review . We will revise our paper to make sure that our points are clearly stated . - Learning of novel classes needs old data : We are afraid that there might be a big misunderstanding . The whole incremental few-shot learning problem is set up so that reviewing old data is * not * allowed . Otherwise the problem can be very trivial to solve : just sample some old data and new data and train jointly . We believe that learning novel classes * without * reviewing old data is an important and challenging problem , especially learning it iteratively , since many models will run into catastrophic forgetting . We have shown that while BPTT does not perform well in this scenario , the proposed meta-learning algorithm can solve it . - Learning of novel classes involves relearning U_k . During learning of novel classes , U_k is fixed and * not * re-learned . U_k is learned during the meta-learning stage , where the novel classes are subsampled from the training set classes ( Train_B set ) . Also the size of U_k is the same as a fully connected softmax layer , which is quite small compared to all the parameters of a deep CNN model ."}, {"review_id": "rkxn7nR5KX-2", "review_text": "This paper proposes a novel few-shot learning method that achieves better overall accuracies on base and novel classes. The key idea is to regularize the learning of novel classes such that base classes are not forgotten. I mainly have the following two concerns. -In Table 2, I observe that performance on novel classess is actually not improved. The main improvement lies in overall accuracy. As numbers of training samples between base and novel classes are not balanced, there must be some trade-off between obtaining better performance on base or novel classes. For instance, stopping early when training on novel classes would result in high base accuracy but low novel accuracy. Fine-tuning on novel classes for more iterations would lead to high novel accuracy but low base accuracy. Such trade-off can be also controlled by simply over-sampling novel or base classes. I would suggest the authors to study more on understanding this trade-off. In addition, another naive baseline is to train a softmax classifier at the second stage on both base and novel class training samples and sample mini-batch by uniformly sampling over novel and base classes. -The following two papers extensively studied the problem of achieving better overall accuracies on base and novel classes. Including comparison and discussion with those two papers will enhance this paper further. Low-Shot Learning from Imaginary Data low-shot visual recognition by shrinking and hallucinating features", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for the comments and pointing out related work . We are revising our paper and adding the discussion of these and other relevant papers . In response to one of the public comments , we have compared our approach to these two papers : The ICCV 2017 paper proposes the SGM loss , which makes the learned classifier from the few-shot examples have a smaller gradient value when learning on all examples . The CVPR 2018 paper proposes the prototypical matching networks , a combination of prototypical network and matching network . The paper also adds hallucination , which generates new examples . In contrast to these approaches , we directly learn a logistic regression classifier during the few-shot episode , which is very simple and straightforward . Although vanilla logistic regression has been shown to be worse in these prior work ( since the logistic regression can not see old data ) , we found that it can be improved significantly by differentiating through the few-shot learning iterations , taking into account the additional regularizer .. - Uniform samples : We also would like to emphasize that , in the learning of novel classes , the base class data is * not * available , thus making the problem very challenging . Therefore , the proposed \u201c naive baseline \u201d which samples a mini-batch uniformly over novel and base classes , will not be comparable to the new approach introduced in the paper , which does not rely on reviewing the old data . - Early stopping : Since we are learning an objective function that needs to be solved until convergence . Stopping early is possible but that relies on an external validation set , which might not be available since we do not have access to the old data when learning the novel classes . Lastly , the reviewer is right that there is a trade-off between learning novel and remembering old classes . Getting better results on the novel class is is indeed possible but has the undesired effect , of catastrophic forgetting . In our setting of incremental few-shot learning the goal is to have the best performance on * both base and novel classes * . Hence we focus on the \\delta bar metric , and our method has a clear win on this crucial metric ."}], "0": {"review_id": "rkxn7nR5KX-0", "review_text": "The paper addresses the incremental few-shot learning problem where a model starts with base network and then introduces the novel classes, building a connection between novel and base classes via an attention module. Strengths: + clear writing. + the experiments are compared with related work and the ablation studies can verify the effectiveness of the proposed (or \"introduced\" would be a precise term) recurrent BP. Weakness: - [Novelty] The paper title is called attention attractor network, which shares very relevance to previous CVPR work (Gidaris & Komodakis, 2018). So the first thing I was looking for is the clear description of the difference between these two. Unfortunately, in related work, authors mention the CVPR work without stating the difference (last few lines in Section 2). As such, I don't see much novelty in the paper compared with previous work. Eqn. (7)-(10) explicitly describes the attention formula. What's the distinction from the CVPR work? - [Motivation of the regularizer using Recurrent BP is not clear] The use of recurrent BP is probably the most distinction from previous work. However, I don't see a clear description on why such a technique is necessary. Starting from the first line in Section 3.3, \"since there is no closed-form of the regularizer in Eqn (13)\", E needs BPTT or the introduced recurrent BP. This part is simply a re-adaption of other algorithms. A very simple question is, how about use other regularizers to replace Eqn (13)? - [Some experiments missing] The experiments section 4.6 uses a case of None and \"best WD\" to address some of my concerns. This is good. Does the \"gamma random\" indicates only E is used without the ||W||^2? why the best WD for one-shot is zero? This implies the model is best for applying no weight decay? What's the effect of using the recurrent BP technique to the CVPR work? Is there some similar improvement? If yes, then the paper makes some contribution by the regularization. If not, what's the reason? How about using the truncated BPTT with a larger T? In general, I think the recurrent BP part should be the highlight of the paper and yet authors fail to spread such a spirit in the abstract or title. And there are some experiments missed as I mentioned above. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the review . We are currently revising the paper and will incorporate your helpful suggestions ( to add discussion to CVPR work , add BPTT with larger T , and highlight the RBP algorithm ) . - Novelty : First , we would like to address the novelty issue . Although both our work and the CVPR paper uses attention mechanism , the two methods are actually very different . The new weights in their method are based on Prototypical Networks , i.e.simply averaging the embedding . We however optimize the weights on the new task and backprop through the optimization , which is a challenging step in learning our model . The attention mechanism is also formulated differently . Whereas the attended content is used as multiplicative gating in their work , we used it as an additive energy term in the overall objective function to optimize . - Applying RBP to the CVPR work : The CVPR work is based on a Prototypical Network which computes weights for the novel classes in a single layer , and regular backpropagation is sufficient . Since there is no iterative optimization involved , we do not see anything that allows us to apply RBP to the CVPR work , or any need for it . - Motivation of RBP : Since we have an iterative optimization procedure in the model , directly differentiating through the procedure is not straightforward . Also , as shown in the experiment , regular backprop through time does not learn a stable objective function . Prior work focus on the case where there is a closed form solution ( Bertinetto et al.2018 ) , where RBP allows us to backprop through any converging optimization layers , which is more general . - Best WD : Yes , in that experiment , no weight decay is needed ( although adding a small amount of WD does not hurt the performance ) . In the other experiments , we found a small amount of weight decay ( 1E-5 ) helped . - BPTT with larger T : Thank you for the suggestion . We are currently adding more experiments that use a larger T for BPTT and will update the paper with the latest results ."}, "1": {"review_id": "rkxn7nR5KX-1", "review_text": "This work addresses incremental few-shot learning that learns novel classes without forgetting old classes, which is interesting and different from conventional few-shot learning that considers only the few-shot learning task of interest. This problem is also related closely to the important problem of life-long learning. This work presents an interesting framework based on meta-learning by learning to learn how to attend to the old classes using an attention mechanism. Experimental results also show improvement over two related works on incremental few-shot learning. The writing is quite clear. Some concerns, especially its novelty, are listed below. 1. The novelty appears to be limited. The presented framework looks quite similar to the recent work Spyros Gidaris and Nikos Komodakis. Dynamic few-shot visual learning without forgetting. CVPR'18 that addresses the same problem in a similar manner: 1) learn a base feature extractor and classifier; and then 2) attend to old classes also via meta-learning and attention mechanism. As mentioned by the authors, \"The main difference to this work is that we use an iterative optimization to compute W_b\". More discussions on the iterative optimization and why it matters may be helpful. Another related work is \"Deep Meta-Learning: Learning to Learn in the Concept Space\", Arxiv'18, that also relies on an external base classes for few-shot learning. Similar to the proposed research, it also learns a feature extractor and a classifier from the base classes, which are used to regularize the learning of novel classes, in an end-to-end meta-learning manner. Extending it for the incremental setting seems natural. 2. To learn a few novel classes, all U_k on old classes are relearned, which seems quite time-consuming with a large vocabulary of base classes. 3. To learn a few novel classes, old data on base classes are still required, which seems different from how humans learn -- humans learn novel concepts solely from a few examples without forgetting old concepts, without requiring examples on old concepts. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the review . We would like first explain the novelty aspect of our paper . - Novelty : Although both our work and the CVPR paper use an attention mechanism , the two methods are actually very different . The new weights in their method are based on Prototypical Nets , i.e.simply averaging the embedding . We however optimize the weights on the new task and backprop through the optimization , which is a challenging step in learning our model . The attention mechanism is also formulated differently . Whereas the attended content is used as multiplicative gating in their work , we used it as an additive energy term in the overall objective function to optimize . Secondly , there seem to be a couple crucial misunderstandings in the review . We will revise our paper to make sure that our points are clearly stated . - Learning of novel classes needs old data : We are afraid that there might be a big misunderstanding . The whole incremental few-shot learning problem is set up so that reviewing old data is * not * allowed . Otherwise the problem can be very trivial to solve : just sample some old data and new data and train jointly . We believe that learning novel classes * without * reviewing old data is an important and challenging problem , especially learning it iteratively , since many models will run into catastrophic forgetting . We have shown that while BPTT does not perform well in this scenario , the proposed meta-learning algorithm can solve it . - Learning of novel classes involves relearning U_k . During learning of novel classes , U_k is fixed and * not * re-learned . U_k is learned during the meta-learning stage , where the novel classes are subsampled from the training set classes ( Train_B set ) . Also the size of U_k is the same as a fully connected softmax layer , which is quite small compared to all the parameters of a deep CNN model ."}, "2": {"review_id": "rkxn7nR5KX-2", "review_text": "This paper proposes a novel few-shot learning method that achieves better overall accuracies on base and novel classes. The key idea is to regularize the learning of novel classes such that base classes are not forgotten. I mainly have the following two concerns. -In Table 2, I observe that performance on novel classess is actually not improved. The main improvement lies in overall accuracy. As numbers of training samples between base and novel classes are not balanced, there must be some trade-off between obtaining better performance on base or novel classes. For instance, stopping early when training on novel classes would result in high base accuracy but low novel accuracy. Fine-tuning on novel classes for more iterations would lead to high novel accuracy but low base accuracy. Such trade-off can be also controlled by simply over-sampling novel or base classes. I would suggest the authors to study more on understanding this trade-off. In addition, another naive baseline is to train a softmax classifier at the second stage on both base and novel class training samples and sample mini-batch by uniformly sampling over novel and base classes. -The following two papers extensively studied the problem of achieving better overall accuracies on base and novel classes. Including comparison and discussion with those two papers will enhance this paper further. Low-Shot Learning from Imaginary Data low-shot visual recognition by shrinking and hallucinating features", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for the comments and pointing out related work . We are revising our paper and adding the discussion of these and other relevant papers . In response to one of the public comments , we have compared our approach to these two papers : The ICCV 2017 paper proposes the SGM loss , which makes the learned classifier from the few-shot examples have a smaller gradient value when learning on all examples . The CVPR 2018 paper proposes the prototypical matching networks , a combination of prototypical network and matching network . The paper also adds hallucination , which generates new examples . In contrast to these approaches , we directly learn a logistic regression classifier during the few-shot episode , which is very simple and straightforward . Although vanilla logistic regression has been shown to be worse in these prior work ( since the logistic regression can not see old data ) , we found that it can be improved significantly by differentiating through the few-shot learning iterations , taking into account the additional regularizer .. - Uniform samples : We also would like to emphasize that , in the learning of novel classes , the base class data is * not * available , thus making the problem very challenging . Therefore , the proposed \u201c naive baseline \u201d which samples a mini-batch uniformly over novel and base classes , will not be comparable to the new approach introduced in the paper , which does not rely on reviewing the old data . - Early stopping : Since we are learning an objective function that needs to be solved until convergence . Stopping early is possible but that relies on an external validation set , which might not be available since we do not have access to the old data when learning the novel classes . Lastly , the reviewer is right that there is a trade-off between learning novel and remembering old classes . Getting better results on the novel class is is indeed possible but has the undesired effect , of catastrophic forgetting . In our setting of incremental few-shot learning the goal is to have the best performance on * both base and novel classes * . Hence we focus on the \\delta bar metric , and our method has a clear win on this crucial metric ."}}