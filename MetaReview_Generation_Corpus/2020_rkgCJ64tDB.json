{"year": "2020", "forum": "rkgCJ64tDB", "title": "Scale-Equivariant Neural Networks with Decomposed Convolutional Filters", "decision": "Reject", "meta_review": "This paper presents a CNN architecture equivariant to scaling and translation which is realized by the proposed joint convolution across the space and scaling groups. All reviewers find the theorical side of the paper is sound and interesting. Through the discussion based on authors\u2019 rebuttal, one reviewer decided to update the score to Weak Accept, putting this paper on the borderline. However, some concerns still remain. Some reviewers are still not convinced regarding the novelty of the paper, particularly in terms of the difference from (Chen+,2019). Also, they agree that experiments are still very weak and not convincing enough. Overall, as there was no opinion to champion this paper, I\u2019d like to recommend rejection this time. \nI encourage authors to polish the experimentations taking in the reviewers\u2019 suggestions. \n", "reviews": [{"review_id": "rkgCJ64tDB-0", "review_text": "*Paper summary* The authors propose a CNN architecture, that is theoretically equivariant to isotropic scalings and translations. For this they add an extra scale-dimension to activation tensors, along with the existing two spatial dimensions. In practice they implement this with scale-steerable filters, which are discretised and truncated in both the spatial and scale-dimensions. They also provide a deformation robustness analysis. *Paper decision* Thank you for writing a very interesting paper indeed. I have to admit I am somewhat on the fence about this paper. I think it contains many nice ideas, but the experimental section is somewhat lacking in terms of comparisons or insights which I can gain, and the theory has some missing elements too (which I shall discuss below). For that reason, I am recommending a weak reject, but would very easily upgrade this if the authors provide strong rebuttal to my comments below. *Supporting arguments* -Experiments: The experiments are quite light, although I must admit that many other works in the area of equivariance are also light on experimentation and if there is enough theory, that is not such a great issue. The main issues I have are 1) the choice of experiments, 2) the comparisons against an insufficient number of baselines, and 3) the ablation studies. 1) The choice of experiments: I think looking at scaled-MNIST is not particularly useful as an experiment nowadays, unless used as a toy experiment. A larger dataset with real-life scale variations would have been better. Furthermore, I\u2019m not sure what the image reconstruction task is supposed to tell the reader, that the ScDCFNet is able to generalise to new scales? 2) There is a lot of concurrent work on multiscale architecture. To name a few: Multigrid Neural Architectures, Ke et al., 2017 Feature Pyramid Networks for Object Detection, Lin et al., 2017 Multi-Scale Dense Networks for Resource Efficient Image Classification, Huang et al., 2018 Deep Scale-spaces, Worrall and Welling, 2019 I believe these works should at least be cited, but ideally compared against. 3) I would have liked to have seen some numerical results for the verification of scale equivariance. In the first layer the equivariance improbably going to be close to perfect because there is no truncation of the scale-dimension in the network, but after this layer I predict the equivariance error increases due to truncations effects. This would be a similar effect to other works, such as \u201cDeep Scale-spaces\u201d (Worrall and Welling, 2019). -Theory: I think the theory is very interesting and a meaningful contribution in its own right. The authors treat scale-translation in continuous space as a group action on signals. This motivates the convolution presented in Theorem 1. This is a group convolution as per Cohen and Welling, (2016) modified to continuous space for a non-compact group. (Actually, this should be mentioned in the text as a matter of good scholarship). This is nice, since the group convolution has not been used in for a regular representation of a non-compact group (other than translation) as far as I can tell. What is perhaps not clear for me is how the theory breaks down in practice, since the implementation requires discretisation in space AND scale, which is not discussed much and furthermore, filters are restricted in spatial AND scale dimensions, leading to truncation errors in the equivariance. This last perspective was not discussed, and I feel it rather should be. The theory goes further into deformation stability, which is a fresh perspective in the equivariance literature, so I am happy for its inclusion. Perhaps more motivation for why you think this is necessary would be warmly welcomed. *Smaller questions/notes for the authors* - Technically this is scale-translation equivariance, you even write this in the method section of your paper, why is it not in the title? The reason I mention this Is because there are scale equivariant networks, which are not translation equivariant in the literature, see \u201cWarped Convolutions: Efficient Invariance to Spatial Transformations\u201d (Henriques and Vedaldi, 2019). - Please make the link between Theorem 1 and the group convolution of Cohen and Welling (2016) - Last paragraph of page 1: A steerable-in-scale filter does exist, see \u201cDeformable kernels for early vision\u201d (Perona, 1991) - Please use numbering for all display-mode equations. - This scheme works perfectly in the continuous-image setting, but how about for discretized images? In that case it cannot be scale-translation equivariant because the scaling-action is no longer part of a group. - In equations 6 and 7, what is the specific motivation for using the laplacian eigen-decompositions as a basis? Is it for steerability with respect to the scale-translation action? Otherwise, surely any basis will do? - Remark 2: If you are considering a truncation of the scale-axis, surely you can still use an L2 norm when quantifying the robustness of your representation? - Bandlimiting of the filters: I would consider citing \u201cStructured Receptive Fields in CNNs\u201d, (Jacobsen et al., 2016) - Pooling: A useful citation here would be \u201cMaking Convolutional Networks Shift-Invariant Again\u201d (Zhang, 2019). They precise low pass filter before pooling. - Experiments: \u2014I\u2019m not clear on the reason to include reasons with and without batch normalization. This is quite unconventional \u2014 Did you ever use scale augmentation? What is the effect of training on one scale and then testing on another? ", "rating": "6: Weak Accept", "reply_text": "We would like to thank the reviewer for reading our manuscript and providing valuable comments . Please see below our detailed response , and the manuscript has also been updated accordingly . * * Major comments * * \u2014 scaled-MNIST is OK as a toy experiment , but a larger dataset with real-life scale-variations would be better . Furthermore , what the image reconstruction task is supposed to tell the reader ? The purpose of the image reconstruction experiment is to demonstrate that ScDCFNet is able to generalize to new scales . Furthermore , we want to show that the image code produced by an ScDCFNet encoder is more interpretable , i.e. , it contains the input scale information , and manipulating the image code before feeding it to the decoder can produced rescaled versions of the input . We agree with the reviewer that experiments on a larger dataset with real-life scale variations would be great . Due to limited resources , the current paper does not have such a result . Beyond MNIST and Fashion MNIST , we have conducted extra experiments on scaled-CIFAR10 dataset , where the improvement in classification accuracy in this experiment is not as pronounced as the SMNIST/SFashion MNIST dataset . We think the reason is that the objects in the CIFAR dataset ( unlike MNIST and Fashion MNIST ) are almost visually indiscernible after rescaling . In other words , small object images like CIFAR are not proper for the current study . Meanwhile , as suggested by R3 and a volunteer reviewer , we did conduct an extra experiment on the SMNIST dataset with the conventional 10k/50k train/test splits and compare the result of the ScDCFNet to other benchmark models . The results have been updated in Table 1 . We will keep working on optimizing the implementation of our proposed model and its application with larger datasets with real-life scale-variations . \u2014Citing concurrent works and compare against them . We would like to thank the reviewer for pointing us to the interesting concurrent works on multiscale network architectures . Citations of these prior works have been added in our revised paper . As mentioned before , comparisons between our proposed model against more baselines have been added in Table 1 . \u2014 More numerical results for the verification of scale-equivariance . In the first layer the equivariance improbably going to be close to perfect because there is no truncation of the scale-dimension in the network , but after this layer I predict the equivariance error increases due to truncations effects . We have added another numerical result on the verification of scale-equivariance in Figure 3 as requested by the reviewer . The reviewer is absolutely correct that as the network goes deeper , the equivariance relation is subject to numerical contamination incurred by ( 1 ) a truncation of the global scaling group to a finite interval , and ( 2 ) the boundary \u201c leakage \u201d issue caused by the non-degenerate joint-convolution , i.e. , when the joint filter is not a delta function in the scale dimension ( c.f.Remark 1 . ) There are two ways to mitigate this issue . First , we can choose a joint convolutional filter that is compactly supported on a smaller scale interval ( this has also been pointed out in [ 1 ] . ) Both Figure 3 ( a ) and Figure 3 ( b ) show that convolutional filters with a smaller number of \u201c taps \u201d in scale ( i.e. , smaller filter size in scale ) lead to a smaller numerical error in equivariance as the network depth progresses .. Second , instead of using a zero-padding , a \u201c replicate \u201d padding should be implemented for the scale dimension before the scale-convolution . This argument is verified by comparing Figure 3 ( b ) to Figure 3 ( a ) ( noticing the different error scales in these two figures . ) The detailed explanation has been added in Appendix B.1 and Section 5.1 . \u2014 The theory is very interesting and a meaningful contribution in its own right . However a reference to [ 2 ] as a motivation for Theorem 1 needs to be mentioned in the text . We thank the reviewer again for kindly acknowledging the theoretical contribution of our paper . A reference to [ 2 ] has been added for Theorem 1 ."}, {"review_id": "rkgCJ64tDB-1", "review_text": "This paper is introducing a scale-equivariant CNN architecture with joint convolutions over spatial and scale space. Moreover, the authors used decomposable convolutional filters to reduce the number of parameters. Based on Therom 1, it is shown that scale-equivariance is achieved if and only if joint convolutions are conducted over spatial and scale space. Overall, the contribution seems meaningful but incremental that the method is almost similar to the 'RotDCF: Decomposition of convolutional filters for rotation-equivariant deep network'. - to verify scale equivariance, visualizing features with tsne would be interesting - in table 1, what is the reason for doing experiments with and without batchnorm? - what if the baseline's size is close to the proposed method, how it would be improved? - it would be better to show how the decomposed filters reduce the total number of parameters. - also comparing flops would be informative. - the author's name of 'Locally scale-invariant convolutional neural networks' is wrongly written.", "rating": "3: Weak Reject", "reply_text": "We would like to thank the reviewer for reading our manuscript and providing valuable comments . Please see below our detailed response , and the manuscript has also been updated accordingly . \u2014 Overall , the contribution seems meaningful but incremental that the method is almost similar to the \u201c RotDCF : Decomposition of convolutional filters for rotation-equivariant deep network \u201d . We would like to thank R1 for pointing out the contribution of our paper . Meanwhile , we would also like to emphasize that our contribution is not just incremental compared to RotDCF : First , the scaling group , unlike SO ( 2 ) , is non-compact , and the generalization of the group convolution on SO ( 2 ) to the scaling group is non-trivial ( R3 has kindly pointed this out . ) For example , [ 1 ] correctly proposed a rotation-equivariant CNN by encoding the rotation information in the phase angle of a vector field ; however , its direct generalization to scale-equivariant CNN in [ 2 ] is mathematically flawed , for the scaling group has been treated in [ 2 ] as a compact cyclic group . Second , the representation stability of the proposed ScDCFNet is also a non-trivial extension of RotDCFNet \u2014because of the non-compactness of the scaling group , we can only quantify the representation stability in the L_infinity norm instead of the regular L_2 norm ( this has been explained in Remark 2 . ) \u2014To verify scale equivariance , visualizing features with tsne would be interesting . t-SNE is indeed an interesting tool to visualize the representation of a collection of data . However , our intention is to verify scaling-translation-equivariance on the image level , i.e. , roughly speaking , if an input image is spatially rescaled , is its feature map rescaled accordingly ( or does equation ( 4 ) hold true ? ) Using t-SNE visualization will not achieve this goal . \u2014In table 1 , what is the reason for doing experiments with and without batchnorm ? The reason why we include experiments with and without batch-normalization is that the batch-normalization module needs to be modified for ScDCFNet so that scaling-translation-equivariance still holds true . This has been explained in Appendix B.1 and Section 5 ( right before Section 5.1 . ) \u2014 What if the baseline 's size is close to the proposed method , how it would be improved ? Table 1 shows the accuracy of our proposed model while changing the model size , i.e. , changing the number of low-frequency components ( K and K_\\alpha ) that are retained . In general , as the model size increases ( i.e. , larger K and K_\\alpha ) , the accuracy of the proposed model is improved . However , as pointed out also in our response to R4 , K and K_\\alpha can not be too large because otherwise aliasing would occur . Another way to increase the model size of ScDCFNet is to increase the number of unstructured channel M. In particular , when trained on SMNIST with 2000 images , if we set K = 5 and K_\\alpha = 2 , while at the same time change M from 16 to 32 , the accuracy of ScDCFNet increases from 93.51 % to 93.76 % , while the model size is now similar to that of the baseline CNN ( with an accuracy of 92.60 % . ) \u2014 It would be better to show how the decomposed filters reduce the total number of parameters . The reason why ( and how much ) truncating the filter decomposition can reduce the number of parameters is explained in Section 3.2 on page 4 ( under \u201c Number of trainable parameters \u201d . ) \u2014Also comparing flops would be informative . The comparison of computational flops is explained in Theorem 2 and proved in Appendix A.2 . \u2014 The author 's name of \u201c Locally scale-invariant convolutional neural networks \u201d is wrongly written . Thank you for pointing that out . This has been fixed in the revised paper . [ 1 ] Diego Marcos et al , \u201c Rotation Equivariant Vector Field Networks. \u201d ICCV 2017 . [ 2 ] Diego Marcos et al , \u201c Scale Equivariance in CNNs with Vector Fields. \u201d arXiv : 1807.11783 , 2018 ."}, {"review_id": "rkgCJ64tDB-2", "review_text": "The paper proposes a scale-equivariant Neural Networks model to solve the multi-scale image classification task. The main contributions are the proposed joint convolution across the spatial and scale space, and the decomposed filters to reduce computation cost and improve robustness. The paper is generally well-written and well placed in the literature. Different from existing work on the scale-equivariance CNNs, they build a more general model that allows different scale information to transfer through different layers. The experiments also suggest the model achieving scale-equivariance and the superior performance of the proposed method compared with several baselines. However, for the novelty part of the proposed method (the separable basis decomposition), it is not convincing enough because the differences between this paper and Cheng et al. (2019) and Weiler et al. (2018b) are not clear. Questions: 1. The authors claim that the joint convolutions across the space and the scaling group are both \"sufficient\" and \"necessary\". Although the experiments show that the proposed method achieves better performance, which might indicate the \"sufficiency\" of the architecture, however, how should the \"necessity\" be proved? 2. How should \"K\" and \"K_\\alpha\" be selected (Table 1)? When data is enough (e.g., 5000), it seems that only some specific values can improve performance. 3. How much can the model size be reduced compared with other multiscale image classification models? And could you provide some concrete comparisons about the computation cost? Typos: - 1st line in 2nd paragraph of Introduction: rotation-equivarianc(e)", "rating": "6: Weak Accept", "reply_text": "We would like to thank the reviewer for reading our manuscript and providing valuable comments . Please see below our detailed response , and the manuscript has also been updated accordingly . \u2014 The authors claim that the joint convolutions across the space and the scaling group are both \u201c sufficient \u201d and \u201c necessary \u201d . Although the experiments might indicate the \u201c sufficiency \u201d of the architecture , however , how should the \u201c necessity \u201d be proved ? Our claim in Theorem 1 is that conducting joint-convolutions is both \u201c sufficient \u201d and \u201c necessary \u201d to achieve \u201c scaling-translation-equivariance \u201d , i.e. , equation ( 4 ) holds true for all l. The proof of \u201c necessity \u201d ( as well as \u201c sufficiency \u201d ) is detailed in Appendix A.1 . The better performance in the experiments on multiscale image classification is a result of the fact that \u201c scaling-translation-equivariance \u201d has been achieved through joint-convolutions . \u2014 How should \u201c K \u201d and \u201c K_\\alpha \u201d be selected ( Table 1 ) ? The numbers of basis functions , i.e. , \u201c K \u201d and \u201c K_\\alpha \u201d , can not be set to too large because otherwise aliasing effects would occur ( this is similar to [ 1 ] . ) On the other hand , setting \u201c K \u201d and \u201c K_\\alpha \u201d to too small will also limit the expressive power of the network . Our experiments show that setting \u201c K = 8 \u201d and \u201c K_\\alpha = 3 \u201d leads to consistently improved performance while using only a fraction ( 67 % ) of the trainable parameters when compared to a regular CNN . \u2014 How much can the model size be reduced compared with other multiscale image classification models ? Concrete comparisons about the computation cost ? The comparison of the model size and performance between the proposed method and other multiscale image classification models has been added in Table 1 . The detailed analysis of the computational cost is stated in Theorem 2 and proved in Appendix A.2 . In particular , when basis functions are truncated to \u201c K = 8 \u201d and \u201c K_\\alpha = 3 \u201d , we achieve 80 % reduction in computational cost . [ 1 ] Maurice Weiler et al. , \u201c Learning Steerable Filters for Rotation Equivariant CNNs. \u201d CVPR 2018 ."}], "0": {"review_id": "rkgCJ64tDB-0", "review_text": "*Paper summary* The authors propose a CNN architecture, that is theoretically equivariant to isotropic scalings and translations. For this they add an extra scale-dimension to activation tensors, along with the existing two spatial dimensions. In practice they implement this with scale-steerable filters, which are discretised and truncated in both the spatial and scale-dimensions. They also provide a deformation robustness analysis. *Paper decision* Thank you for writing a very interesting paper indeed. I have to admit I am somewhat on the fence about this paper. I think it contains many nice ideas, but the experimental section is somewhat lacking in terms of comparisons or insights which I can gain, and the theory has some missing elements too (which I shall discuss below). For that reason, I am recommending a weak reject, but would very easily upgrade this if the authors provide strong rebuttal to my comments below. *Supporting arguments* -Experiments: The experiments are quite light, although I must admit that many other works in the area of equivariance are also light on experimentation and if there is enough theory, that is not such a great issue. The main issues I have are 1) the choice of experiments, 2) the comparisons against an insufficient number of baselines, and 3) the ablation studies. 1) The choice of experiments: I think looking at scaled-MNIST is not particularly useful as an experiment nowadays, unless used as a toy experiment. A larger dataset with real-life scale variations would have been better. Furthermore, I\u2019m not sure what the image reconstruction task is supposed to tell the reader, that the ScDCFNet is able to generalise to new scales? 2) There is a lot of concurrent work on multiscale architecture. To name a few: Multigrid Neural Architectures, Ke et al., 2017 Feature Pyramid Networks for Object Detection, Lin et al., 2017 Multi-Scale Dense Networks for Resource Efficient Image Classification, Huang et al., 2018 Deep Scale-spaces, Worrall and Welling, 2019 I believe these works should at least be cited, but ideally compared against. 3) I would have liked to have seen some numerical results for the verification of scale equivariance. In the first layer the equivariance improbably going to be close to perfect because there is no truncation of the scale-dimension in the network, but after this layer I predict the equivariance error increases due to truncations effects. This would be a similar effect to other works, such as \u201cDeep Scale-spaces\u201d (Worrall and Welling, 2019). -Theory: I think the theory is very interesting and a meaningful contribution in its own right. The authors treat scale-translation in continuous space as a group action on signals. This motivates the convolution presented in Theorem 1. This is a group convolution as per Cohen and Welling, (2016) modified to continuous space for a non-compact group. (Actually, this should be mentioned in the text as a matter of good scholarship). This is nice, since the group convolution has not been used in for a regular representation of a non-compact group (other than translation) as far as I can tell. What is perhaps not clear for me is how the theory breaks down in practice, since the implementation requires discretisation in space AND scale, which is not discussed much and furthermore, filters are restricted in spatial AND scale dimensions, leading to truncation errors in the equivariance. This last perspective was not discussed, and I feel it rather should be. The theory goes further into deformation stability, which is a fresh perspective in the equivariance literature, so I am happy for its inclusion. Perhaps more motivation for why you think this is necessary would be warmly welcomed. *Smaller questions/notes for the authors* - Technically this is scale-translation equivariance, you even write this in the method section of your paper, why is it not in the title? The reason I mention this Is because there are scale equivariant networks, which are not translation equivariant in the literature, see \u201cWarped Convolutions: Efficient Invariance to Spatial Transformations\u201d (Henriques and Vedaldi, 2019). - Please make the link between Theorem 1 and the group convolution of Cohen and Welling (2016) - Last paragraph of page 1: A steerable-in-scale filter does exist, see \u201cDeformable kernels for early vision\u201d (Perona, 1991) - Please use numbering for all display-mode equations. - This scheme works perfectly in the continuous-image setting, but how about for discretized images? In that case it cannot be scale-translation equivariant because the scaling-action is no longer part of a group. - In equations 6 and 7, what is the specific motivation for using the laplacian eigen-decompositions as a basis? Is it for steerability with respect to the scale-translation action? Otherwise, surely any basis will do? - Remark 2: If you are considering a truncation of the scale-axis, surely you can still use an L2 norm when quantifying the robustness of your representation? - Bandlimiting of the filters: I would consider citing \u201cStructured Receptive Fields in CNNs\u201d, (Jacobsen et al., 2016) - Pooling: A useful citation here would be \u201cMaking Convolutional Networks Shift-Invariant Again\u201d (Zhang, 2019). They precise low pass filter before pooling. - Experiments: \u2014I\u2019m not clear on the reason to include reasons with and without batch normalization. This is quite unconventional \u2014 Did you ever use scale augmentation? What is the effect of training on one scale and then testing on another? ", "rating": "6: Weak Accept", "reply_text": "We would like to thank the reviewer for reading our manuscript and providing valuable comments . Please see below our detailed response , and the manuscript has also been updated accordingly . * * Major comments * * \u2014 scaled-MNIST is OK as a toy experiment , but a larger dataset with real-life scale-variations would be better . Furthermore , what the image reconstruction task is supposed to tell the reader ? The purpose of the image reconstruction experiment is to demonstrate that ScDCFNet is able to generalize to new scales . Furthermore , we want to show that the image code produced by an ScDCFNet encoder is more interpretable , i.e. , it contains the input scale information , and manipulating the image code before feeding it to the decoder can produced rescaled versions of the input . We agree with the reviewer that experiments on a larger dataset with real-life scale variations would be great . Due to limited resources , the current paper does not have such a result . Beyond MNIST and Fashion MNIST , we have conducted extra experiments on scaled-CIFAR10 dataset , where the improvement in classification accuracy in this experiment is not as pronounced as the SMNIST/SFashion MNIST dataset . We think the reason is that the objects in the CIFAR dataset ( unlike MNIST and Fashion MNIST ) are almost visually indiscernible after rescaling . In other words , small object images like CIFAR are not proper for the current study . Meanwhile , as suggested by R3 and a volunteer reviewer , we did conduct an extra experiment on the SMNIST dataset with the conventional 10k/50k train/test splits and compare the result of the ScDCFNet to other benchmark models . The results have been updated in Table 1 . We will keep working on optimizing the implementation of our proposed model and its application with larger datasets with real-life scale-variations . \u2014Citing concurrent works and compare against them . We would like to thank the reviewer for pointing us to the interesting concurrent works on multiscale network architectures . Citations of these prior works have been added in our revised paper . As mentioned before , comparisons between our proposed model against more baselines have been added in Table 1 . \u2014 More numerical results for the verification of scale-equivariance . In the first layer the equivariance improbably going to be close to perfect because there is no truncation of the scale-dimension in the network , but after this layer I predict the equivariance error increases due to truncations effects . We have added another numerical result on the verification of scale-equivariance in Figure 3 as requested by the reviewer . The reviewer is absolutely correct that as the network goes deeper , the equivariance relation is subject to numerical contamination incurred by ( 1 ) a truncation of the global scaling group to a finite interval , and ( 2 ) the boundary \u201c leakage \u201d issue caused by the non-degenerate joint-convolution , i.e. , when the joint filter is not a delta function in the scale dimension ( c.f.Remark 1 . ) There are two ways to mitigate this issue . First , we can choose a joint convolutional filter that is compactly supported on a smaller scale interval ( this has also been pointed out in [ 1 ] . ) Both Figure 3 ( a ) and Figure 3 ( b ) show that convolutional filters with a smaller number of \u201c taps \u201d in scale ( i.e. , smaller filter size in scale ) lead to a smaller numerical error in equivariance as the network depth progresses .. Second , instead of using a zero-padding , a \u201c replicate \u201d padding should be implemented for the scale dimension before the scale-convolution . This argument is verified by comparing Figure 3 ( b ) to Figure 3 ( a ) ( noticing the different error scales in these two figures . ) The detailed explanation has been added in Appendix B.1 and Section 5.1 . \u2014 The theory is very interesting and a meaningful contribution in its own right . However a reference to [ 2 ] as a motivation for Theorem 1 needs to be mentioned in the text . We thank the reviewer again for kindly acknowledging the theoretical contribution of our paper . A reference to [ 2 ] has been added for Theorem 1 ."}, "1": {"review_id": "rkgCJ64tDB-1", "review_text": "This paper is introducing a scale-equivariant CNN architecture with joint convolutions over spatial and scale space. Moreover, the authors used decomposable convolutional filters to reduce the number of parameters. Based on Therom 1, it is shown that scale-equivariance is achieved if and only if joint convolutions are conducted over spatial and scale space. Overall, the contribution seems meaningful but incremental that the method is almost similar to the 'RotDCF: Decomposition of convolutional filters for rotation-equivariant deep network'. - to verify scale equivariance, visualizing features with tsne would be interesting - in table 1, what is the reason for doing experiments with and without batchnorm? - what if the baseline's size is close to the proposed method, how it would be improved? - it would be better to show how the decomposed filters reduce the total number of parameters. - also comparing flops would be informative. - the author's name of 'Locally scale-invariant convolutional neural networks' is wrongly written.", "rating": "3: Weak Reject", "reply_text": "We would like to thank the reviewer for reading our manuscript and providing valuable comments . Please see below our detailed response , and the manuscript has also been updated accordingly . \u2014 Overall , the contribution seems meaningful but incremental that the method is almost similar to the \u201c RotDCF : Decomposition of convolutional filters for rotation-equivariant deep network \u201d . We would like to thank R1 for pointing out the contribution of our paper . Meanwhile , we would also like to emphasize that our contribution is not just incremental compared to RotDCF : First , the scaling group , unlike SO ( 2 ) , is non-compact , and the generalization of the group convolution on SO ( 2 ) to the scaling group is non-trivial ( R3 has kindly pointed this out . ) For example , [ 1 ] correctly proposed a rotation-equivariant CNN by encoding the rotation information in the phase angle of a vector field ; however , its direct generalization to scale-equivariant CNN in [ 2 ] is mathematically flawed , for the scaling group has been treated in [ 2 ] as a compact cyclic group . Second , the representation stability of the proposed ScDCFNet is also a non-trivial extension of RotDCFNet \u2014because of the non-compactness of the scaling group , we can only quantify the representation stability in the L_infinity norm instead of the regular L_2 norm ( this has been explained in Remark 2 . ) \u2014To verify scale equivariance , visualizing features with tsne would be interesting . t-SNE is indeed an interesting tool to visualize the representation of a collection of data . However , our intention is to verify scaling-translation-equivariance on the image level , i.e. , roughly speaking , if an input image is spatially rescaled , is its feature map rescaled accordingly ( or does equation ( 4 ) hold true ? ) Using t-SNE visualization will not achieve this goal . \u2014In table 1 , what is the reason for doing experiments with and without batchnorm ? The reason why we include experiments with and without batch-normalization is that the batch-normalization module needs to be modified for ScDCFNet so that scaling-translation-equivariance still holds true . This has been explained in Appendix B.1 and Section 5 ( right before Section 5.1 . ) \u2014 What if the baseline 's size is close to the proposed method , how it would be improved ? Table 1 shows the accuracy of our proposed model while changing the model size , i.e. , changing the number of low-frequency components ( K and K_\\alpha ) that are retained . In general , as the model size increases ( i.e. , larger K and K_\\alpha ) , the accuracy of the proposed model is improved . However , as pointed out also in our response to R4 , K and K_\\alpha can not be too large because otherwise aliasing would occur . Another way to increase the model size of ScDCFNet is to increase the number of unstructured channel M. In particular , when trained on SMNIST with 2000 images , if we set K = 5 and K_\\alpha = 2 , while at the same time change M from 16 to 32 , the accuracy of ScDCFNet increases from 93.51 % to 93.76 % , while the model size is now similar to that of the baseline CNN ( with an accuracy of 92.60 % . ) \u2014 It would be better to show how the decomposed filters reduce the total number of parameters . The reason why ( and how much ) truncating the filter decomposition can reduce the number of parameters is explained in Section 3.2 on page 4 ( under \u201c Number of trainable parameters \u201d . ) \u2014Also comparing flops would be informative . The comparison of computational flops is explained in Theorem 2 and proved in Appendix A.2 . \u2014 The author 's name of \u201c Locally scale-invariant convolutional neural networks \u201d is wrongly written . Thank you for pointing that out . This has been fixed in the revised paper . [ 1 ] Diego Marcos et al , \u201c Rotation Equivariant Vector Field Networks. \u201d ICCV 2017 . [ 2 ] Diego Marcos et al , \u201c Scale Equivariance in CNNs with Vector Fields. \u201d arXiv : 1807.11783 , 2018 ."}, "2": {"review_id": "rkgCJ64tDB-2", "review_text": "The paper proposes a scale-equivariant Neural Networks model to solve the multi-scale image classification task. The main contributions are the proposed joint convolution across the spatial and scale space, and the decomposed filters to reduce computation cost and improve robustness. The paper is generally well-written and well placed in the literature. Different from existing work on the scale-equivariance CNNs, they build a more general model that allows different scale information to transfer through different layers. The experiments also suggest the model achieving scale-equivariance and the superior performance of the proposed method compared with several baselines. However, for the novelty part of the proposed method (the separable basis decomposition), it is not convincing enough because the differences between this paper and Cheng et al. (2019) and Weiler et al. (2018b) are not clear. Questions: 1. The authors claim that the joint convolutions across the space and the scaling group are both \"sufficient\" and \"necessary\". Although the experiments show that the proposed method achieves better performance, which might indicate the \"sufficiency\" of the architecture, however, how should the \"necessity\" be proved? 2. How should \"K\" and \"K_\\alpha\" be selected (Table 1)? When data is enough (e.g., 5000), it seems that only some specific values can improve performance. 3. How much can the model size be reduced compared with other multiscale image classification models? And could you provide some concrete comparisons about the computation cost? Typos: - 1st line in 2nd paragraph of Introduction: rotation-equivarianc(e)", "rating": "6: Weak Accept", "reply_text": "We would like to thank the reviewer for reading our manuscript and providing valuable comments . Please see below our detailed response , and the manuscript has also been updated accordingly . \u2014 The authors claim that the joint convolutions across the space and the scaling group are both \u201c sufficient \u201d and \u201c necessary \u201d . Although the experiments might indicate the \u201c sufficiency \u201d of the architecture , however , how should the \u201c necessity \u201d be proved ? Our claim in Theorem 1 is that conducting joint-convolutions is both \u201c sufficient \u201d and \u201c necessary \u201d to achieve \u201c scaling-translation-equivariance \u201d , i.e. , equation ( 4 ) holds true for all l. The proof of \u201c necessity \u201d ( as well as \u201c sufficiency \u201d ) is detailed in Appendix A.1 . The better performance in the experiments on multiscale image classification is a result of the fact that \u201c scaling-translation-equivariance \u201d has been achieved through joint-convolutions . \u2014 How should \u201c K \u201d and \u201c K_\\alpha \u201d be selected ( Table 1 ) ? The numbers of basis functions , i.e. , \u201c K \u201d and \u201c K_\\alpha \u201d , can not be set to too large because otherwise aliasing effects would occur ( this is similar to [ 1 ] . ) On the other hand , setting \u201c K \u201d and \u201c K_\\alpha \u201d to too small will also limit the expressive power of the network . Our experiments show that setting \u201c K = 8 \u201d and \u201c K_\\alpha = 3 \u201d leads to consistently improved performance while using only a fraction ( 67 % ) of the trainable parameters when compared to a regular CNN . \u2014 How much can the model size be reduced compared with other multiscale image classification models ? Concrete comparisons about the computation cost ? The comparison of the model size and performance between the proposed method and other multiscale image classification models has been added in Table 1 . The detailed analysis of the computational cost is stated in Theorem 2 and proved in Appendix A.2 . In particular , when basis functions are truncated to \u201c K = 8 \u201d and \u201c K_\\alpha = 3 \u201d , we achieve 80 % reduction in computational cost . [ 1 ] Maurice Weiler et al. , \u201c Learning Steerable Filters for Rotation Equivariant CNNs. \u201d CVPR 2018 ."}}