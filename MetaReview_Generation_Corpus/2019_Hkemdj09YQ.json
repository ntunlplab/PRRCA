{"year": "2019", "forum": "Hkemdj09YQ", "title": "Rectified Gradient: Layer-wise Thresholding for Sharp and Coherent Attribution Maps", "decision": "Reject", "meta_review": "The main goal of the submission is to figure out a way to produce less \"noisy\" saliency maps. The RectGrad method uses some thresholding during backprop, like Guided Backprop. The visuals of the proposed method are good, but the reviewers rightfully point out that evaluating whether the proposed method is any good is not obvious. The ROAR/KAR results are perhaps not telling the whole story (and the authors claim that RectGrad is not expected to get a high ROAR score, but I would like to see this developed more in a further version of this work).\n\nGenerally, I feel like there was a healthy back and forth between authors and R3 on the main concerns of this work. I agree that the mathematical justification for RectGrad seems not fully developed. Given all of these concerns, at this point I cannot support acceptance of this work at ICLR.", "reviews": [{"review_id": "Hkemdj09YQ-0", "review_text": "Summary of the paper: This paper proposed RectGrad, a gradient-based attribution method that tries to avoid the problem of noise in the attribution map. Further, authors hypothesize that noise is caused by the network carrying irrelevant features, as opposed to saturation, discontinuities, etc as hypothesized by related papers. The paper is well written and easy to read through. Strengths: - Formally addresses a hitherto unanswered question of why saliency maps are noisy. This is an important contribution. - RectGrad is easy to implement. Questions for authors: - Since the authors are saying that the validity of their hypothesis is \u201ctrivial\u201d, it would be nice to have this statement supported by more quantitative, dataset-wide analyses on the feature map and training dataset occlusion tests. For e.g., what percentage of the test dataset shows attributions on the 10x10 occluded patch? - How does RectGrad compare with simply applying a final threshold on other attribution maps? How do the results on training data and feature occlusion change after such a threshold is applied? How do results on adversarial attacks change? - Could this method generalize to non-ReLU networks? - Premise that auxiliary objects in the image are part of the background is not necessarily true. For instance, the hand in \u201clighter\u201d is clearly important to know that the flame is from a lighter and not from a candle or some other form of fire. Similarly, the leaves in the \u201cfrog\u201d example. - (Optional) As shown in (https://openreview.net/forum?id=B1xeyhCctQ) gradients on ReLU networks overlook the bias term. In the light of this, what is the authors\u2019 take on whether a high bias-attribution is the cause for the noisy gradient-attribution? - (Optional) In some sense, RectGrad works because layers closer to the input may capture more focussed features than layers close to input which may activate features spread out all over the image. It would be interesting to see if RectGrad works for really small networks such as MobileNet (https://arxiv.org/abs/1801.04381) where such an explicit hierarchy of features may not be there. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the friendly and detailed review . Before reading our reply for your review , we politely ask you to read \u201c Our Common Reply to All Reviewers \u201d first . C1 : `` Since the authors are saying that the validity of their hypothesis is \u201c trivial \u201d , it would be nice to have this statement supported by more quantitative , dataset-wide analyses on the feature map and training dataset occlusion tests . For e.g. , what percentage of the test dataset shows attributions on the 10x10 occluded patch ? '' A1 : Before summarizing additional experiment results , we would like to make a clarification . Our hypothesis is comprised of two parts : ( 1 ) background features cause noise in saliency maps and ( 2 ) background features are trivial or irrelevant to the classification task . The Reviewer seems to be implying that we have claimed both parts ( 1 ) and ( 2 ) to be trivial . However , it is only part ( 1 ) that we have claimed to be trivial by the definition of gradient . We have never claimed part ( 2 ) is trivial . We performed two additional experiments to demonstrate that DNNs do not filter out irrelevant features during forward propagation / that background feature activations are irrelevant to the classification task . First , as the Reviewer suggested , we measured how much attribution is on the 10x10 occluded patch . Since we don \u2019 t have a criterion of how much attribution is trivial enough to be seen as \u201c no attribution \u201d , we instead summed all absolute attribution within the patch and took the average across the test dataset . We repeated this with other attribution methods and created a bar chart comparing the average . Results are shown in Figure 8 . Ideally , there should be nearly zero attribution , but we observed that the saliency map assigned the most attribution to the patch among all attribution methods . This shows that DNNs do not filter our irrelevant features during forward propagation ( by definition of gradient ) and that other attribution methods alleviate this problem . Second , we created segmentation masks for 10 correctly classified CIFAR10 images of each class ( total 100 images ) and repeated the feature map occlusion test . We recorded ( class logit ) \u2013 ( largest logit among the other 9 classes ) and took the average over all the images . Figure 9 in Appendix A.1 shows that the difference is generally positive throughout the occlusion process ( i.e. , the class does not change throughout the occlusion process ) , and this implies the irrelevance of background features to the classification task . C2 : `` How does RectGrad compare with simply applying a final threshold on other attribution maps ? '' A2 : We found that noise can accumulate during backpropagation . Specifically , irrelevant features may have trivial gradient near the output layer ; however , since gradient is calculated by successive multiplication , the noise can grow exponentially as gradient is propagated towards the input layer . This often results in confusing attribution maps which assign high attribution to entirely irrelevant regions ( e.g.baseline methods assign high attribution to uniform background in `` lighter '' example in Figure 6 ) , especially for deep networks such as Inception . In such situation , simply applying a final threshold does not work . RectGrad does not suffer from this problem since it thresholds irrelevant features at every layer and hence stops noise accumulation in the first place ( Section 4.1 explains how RectGrad thresholds irrelevant features ) . ( Updated 11/23 ) In Appendix A.2 , we corroborate this claim by comparing Saliency map and RectGrad attributions as they are propagated towards the input layer . We have also surveyed samples for 1.5k randomly chosen ImageNet images , and we found them to be generally consistent with our claims in the paper . As we mentioned in \u201c Our Common Reply to All Reviewers \u201d , we have uploaded the 1.5k samples in anonymous Google drives so that the Reviewers can inspect them if he/she is not convinced by the results in the paper . However , as it always is with DNN interpretability research , it is difficult to demonstrate the efficacy of the proposed method or erase the cherry-picking concern just with large-scale samples . We are aware of this fact and that is why we have conducted numerous additional quantitative experiments ( e.g.A3 ) .It would be very much appreciated if the Reviewer understands and takes this situation into account when reviewing the revised version of this work ."}, {"review_id": "Hkemdj09YQ-1", "review_text": "This paper studies how to better visually interpret a deep neural network. It proposes a new method to produce less noisy saliency maps, named RectGrad. RectGrad thresholds gradient during backprop in a layer-wise fashion in a similar manner to a previous work called Guided Backprop. The difference is that Guided Backprop employs a constant threshold, i.e. 0, while RectGrad uses an adaptive threshold based on a percentile hyper-parameter. The paper is well-written, including a comprehensive review of previous related works, an meaningful meta-level discussion for motivation, and a clear explanation of the proposed method. One of my biggest concern is regarding the experiment and evaluation section. Conclusions are drawn based on the visualization of a few saliency maps. I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking and . For example, this is the conclusion in the Adversarial Attack paragraph: \u201cwe can conclude that Rectified Gradient is equally or more class sensitive than baseline attribution methods\u201d. As pointed out by the paper, the conclusion can be drawn from Figure 8 in the main paper and Figure 10 in Appendix A.1. However, the proposed method tends to produce a saliency map with higher sparsity, therefore the difference may appear more apparent. It is stretching to conclude that it is more class sensitive without further quantitative validation. Evaluation appears to be a common concern to the work on saliency maps. The existing quantitative evaluation in the paper seems disconnected to the visual nature of saliency maps. Concretely, when can we say one saliency map looks better than another? Since this paper claims to produce less noisy saliency maps, what does it mean quantitatively? Is it true that it produces less pixels on the background? If so, can we evaluate it with foreground-background segmentation annotation to prove that point? Though how to evaluate saliency maps remains an open question, I feel some discussion on this paper would make the paper more insightful. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the friendly and detailed review . Before reading our reply for your review , we politely ask you to read \u201c Our Common Reply to All Reviewers \u201d first . C1 : `` One of my biggest concern is regarding the experiment and evaluation section . Conclusions are drawn based on the visualization of a few saliency maps . I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking . For example , this is the conclusion in the Adversarial Attack paragraph : \u201c we can conclude that Rectified Gradient is equally or more class sensitive than baseline attribution methods \u201d . As pointed out by the paper , the conclusion can be drawn from Figure 8 in the main paper and Figure 10 in Appendix A.1 . '' A1 : We have surveyed samples for 1.5k randomly chosen ImageNet images , and we found them to be generally consistent with our claims in the paper . As we mentioned in \u201c Our Common Reply to All Reviewers \u201d , we have uploaded the 1.5k samples in anonymous Google drives so that the Reviewers can inspect them if he/she is not convinced by the results in the paper . However , as it always is with DNN interpretability research , it is difficult to demonstrate the efficacy of the proposed method or erase the cherry-picking concern just with large-scale samples . We are aware of this fact and that is why we have conducted numerous additional quantitative experiments ( e.g.AN2 A3 ) .It would be very much appreciated if the Reviewer understands and takes this situation into account when reviewing the revised version of this work . C2 : `` However , the proposed method tends to produce a saliency map with higher sparsity , therefore the difference may appear more apparent . '' A2 : We applied final threshold to baseline attribution methods such that RectGrad and baseline attribution maps have similar levels of sparsity . The final threshold details are described in Our Common Reply to All Reviewers . We then repeated all qualitative experiments on 1.5k randomly chosen ImageNet images ( image links listed in comment above ) . We have observed that the conclusions still generally hold even after final threshold . We also believe that the ability of our method to control the threshold hyper parameter to make the difference more/less apparent is an advantage , rather than a disadvantage . If the image was near the decision boundary in the first place , then the adversarial attack would change only a small portion of internal activation patterns . This may lead to attribution maps which are indistinguishable from attribution maps for original images . Baseline methods have no effective way of dealing with this except final threshold . However , as we have observed , final threshold still results in noisy attribution maps for baseline methods . For RectGrad , the user can control the threshold percentile q to visually understand which features really account for the change in DNN decision . C3 : `` It is stretching to conclude that it is more class sensitive without further quantitative validation . '' A3 : To our knowledge , there is no previous work in quantitatively validating how class sensitive an attribution method is . There only exist qualitative methods : ( 1 ) comparing original attribution map with those produced with respect to another class ( Smilkov et al.2017 , https : //arxiv.org/abs/1706.03825 ) and ( 2 ) adversarial attack ( Nie et al.2018 , https : //arxiv.org/abs/1805.07039 ) . We have chosen the latter method since it is deterministic ; for the former method , there are 1000 other classes to choose from , and we thought this could lead to space trouble or cherry-picking concerns . Hence the large-scale adversarial attack samples are the best we can do to convince the Reviewer in the current situation ."}, {"review_id": "Hkemdj09YQ-2", "review_text": "In the paper, the authors proposed a new saliency map method, based on some empirical observations about the cause of noisy gradients. Specifically, through experiments, the authors clarified that the noisy gradients are due to irrelevant information propagated in the forward pass in DNN. Because the backpropagation follows the same pass, irrelevant feature are conveyed back to the input, which results in noisy gradients. To avoid noisy gradients, the authors proposed a new backpropagation named Rectified Gradient (RectGrad). In RectGrad, the backward pass is filtered out if the product of the forward signal and the backward signal are smaller than a threshold. The authors claim that, with this modification in backpropagation, the gradients get less noisy. In some experiments, the authors presented that RectGrad can produce clear saliency maps. I liked the first half of the paper: the observations that irrelevant forward passes are causing noisy gradients seem to be convincing. The experiments are designed well to support the claim. Here, I would like to point out, that noisy gradients in occluded images may be because of the convolutional structures. Each filter in convolution layer is trained to respond to certain patterns. Because the same filter is used for each of subimages, some filters can be activated occasionally on occluded parts. I think this does not happen if the network is densely connected without convolutional structures. The trained dense connection will be optimized to remove the effects of occluded parts. Hence, for such networks, the gradient will be zeros for occluded parts. The second half of the paper (Sec.4 and 5) are not very much convincing to me. Below, I raise several concerns. 1. There is no justification on the definition of RectGrad: Why Rl = I(al * Rl > t) R(l+1)? The authors presented Rl = I(al * Rl > t) R(l+1) as RectGrad, that can filter out irrelevant passes. However, there is no clear derivation of this formula: the definition suddenly appears. If the irrelevant forward passes are causes of noisy gradients, the modification Rl = I(al > t) R(l+1) seems to be more natural to me. It is also a natural extension to the ReLU backward pass Rl = I(al > 0) R(l+1). Why we need to filter out negative signals in backward pass? 2. The experimental results are less convincing: Is RectGrad truly good? In Sec.5.2, the authors presented saliency maps only on a few images, and claimed that they look nicely. However, it is not clear that those \"nicely looking\" saliency map are truly good ones. I expect the authors to put much efforts on quantitative comparisons rather than qualitative comparisons, so that we can understand that those \"nicely looking\" saliency maps are truly good ones. Sec.5.3 presents some quantitative comparisons, however, the reported Sensitivity and ROAR/KAR on RectGrad are not significant. The authors mentioned that this may be because of the sparsity of RectGrad. However, if the sparsity is the harm, the underlying observations of RectGrad may have some errors. I think the current manuscript has an inconsistency between the fundamental idea (based on empirical observations) and the performance of RectGrad. [Minor Concern] In Sec.5, the authors frequently refer to the figures in appendix. I think the main body of the paper should be self-contatined. I therefore think that some of the figures related to main results should appear in the main part. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for the friendly and detailed review . Before reading our reply for your review , we politely ask you to read \u201c Our Common Reply to All Reviewers \u201d first . C1 : `` I liked the first half of the paper : the observations that irrelevant forward passes are causing noisy gradients seem to be convincing . The experiments are designed well to support the claim . Here , I would like to point out , that noisy gradients in occluded images may be because of the convolutional structures . Each filter in convolution layer is trained to respond to certain patterns . Because the same filter is used for each of subimages , some filters can be activated occasionally on occluded parts . I think this does not happen if the network is densely connected without convolutional structures . The trained dense connection will be optimized to remove the effects of occluded parts . Hence , for such networks , the gradient will be zeros for occluded parts . '' A1 : Thank you for the compliments ! Note that if we only use dense layers as the Reviewer suggested , we would not be able to achieve such high test accuracy . Hence the problem of noisy gradients for CNNs would have to be addressed sooner or later . In addition , at the preliminary stage of this research , we also found that using fully connected layers does not solve this problem . We speculate this happens due to two reasons : ( 1 ) random initialization of weights and ( 2 ) lack of incentive for the network to `` not remove forward signal from irrelevant features '' or `` zero out weights corresponding to irrelevant features '' . Correspondingly , we found that using l2 loss / weight decay k||w||^2 does remove noise from saliency maps . However , by the time the weight decay coefficient k was high enough to produce clear saliency maps , DNN lacked the expressiveness to achieve sufficiently high test accuracy . Therefore , we did not include this observation in the final version of our paper . C2 : `` There is no justification on the definition of RectGrad : Why Rl = I ( al * Rl > t ) R ( l+1 ) ? The authors presented Rl = I ( al * Rl > t ) R ( l+1 ) as RectGrad , that can filter out irrelevant passes . However , there is no clear derivation of this formula : the definition suddenly appears . If the irrelevant forward passes are causes of noisy gradients , the modification Rl = I ( al > t ) R ( l+1 ) seems to be more natural to me . It is also a natural extension to the ReLU backward pass Rl = I ( al > 0 ) R ( l+1 ) . Why we need to filter out negative signals in backward pass ? '' A2 : We direct the Reviewer to Section 4.1 where we explain the rationale behind the definition of RectGrad in the revised version of the paper . We also direct the Reviewer to A2 of our reply to AN2 , where we answer `` how does RectGrad compare with simply applying a final threshold on other attribution maps ? `` . C3 : `` The experimental results are less convincing : Is RectGrad truly good ? In Sec.5.2 , the authors presented saliency maps only on a few images , and claimed that they look nicely. \u201d A3 : We direct the Reviewer to A1 of our reply to AN1 , where we reply to `` One of my biggest concern is regarding the experiment and evaluation section . Conclusions are drawn based on the visualization of a few saliency maps . I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking. \u201d We have also proven through additional quantitative experiments that RectGrad attribution maps are not only sparse , but significantly less noisy than baseline attribution maps . We direct the Reviewer to A5 of our reply to AN1 , where we answer `` since this paper claims to produce less noisy saliency maps , what does it mean quantitatively ? Is it true that it produces less pixels on the background ? If so , can we evaluate it with foreground-background segmentation annotation to prove that point ? ''"}], "0": {"review_id": "Hkemdj09YQ-0", "review_text": "Summary of the paper: This paper proposed RectGrad, a gradient-based attribution method that tries to avoid the problem of noise in the attribution map. Further, authors hypothesize that noise is caused by the network carrying irrelevant features, as opposed to saturation, discontinuities, etc as hypothesized by related papers. The paper is well written and easy to read through. Strengths: - Formally addresses a hitherto unanswered question of why saliency maps are noisy. This is an important contribution. - RectGrad is easy to implement. Questions for authors: - Since the authors are saying that the validity of their hypothesis is \u201ctrivial\u201d, it would be nice to have this statement supported by more quantitative, dataset-wide analyses on the feature map and training dataset occlusion tests. For e.g., what percentage of the test dataset shows attributions on the 10x10 occluded patch? - How does RectGrad compare with simply applying a final threshold on other attribution maps? How do the results on training data and feature occlusion change after such a threshold is applied? How do results on adversarial attacks change? - Could this method generalize to non-ReLU networks? - Premise that auxiliary objects in the image are part of the background is not necessarily true. For instance, the hand in \u201clighter\u201d is clearly important to know that the flame is from a lighter and not from a candle or some other form of fire. Similarly, the leaves in the \u201cfrog\u201d example. - (Optional) As shown in (https://openreview.net/forum?id=B1xeyhCctQ) gradients on ReLU networks overlook the bias term. In the light of this, what is the authors\u2019 take on whether a high bias-attribution is the cause for the noisy gradient-attribution? - (Optional) In some sense, RectGrad works because layers closer to the input may capture more focussed features than layers close to input which may activate features spread out all over the image. It would be interesting to see if RectGrad works for really small networks such as MobileNet (https://arxiv.org/abs/1801.04381) where such an explicit hierarchy of features may not be there. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the friendly and detailed review . Before reading our reply for your review , we politely ask you to read \u201c Our Common Reply to All Reviewers \u201d first . C1 : `` Since the authors are saying that the validity of their hypothesis is \u201c trivial \u201d , it would be nice to have this statement supported by more quantitative , dataset-wide analyses on the feature map and training dataset occlusion tests . For e.g. , what percentage of the test dataset shows attributions on the 10x10 occluded patch ? '' A1 : Before summarizing additional experiment results , we would like to make a clarification . Our hypothesis is comprised of two parts : ( 1 ) background features cause noise in saliency maps and ( 2 ) background features are trivial or irrelevant to the classification task . The Reviewer seems to be implying that we have claimed both parts ( 1 ) and ( 2 ) to be trivial . However , it is only part ( 1 ) that we have claimed to be trivial by the definition of gradient . We have never claimed part ( 2 ) is trivial . We performed two additional experiments to demonstrate that DNNs do not filter out irrelevant features during forward propagation / that background feature activations are irrelevant to the classification task . First , as the Reviewer suggested , we measured how much attribution is on the 10x10 occluded patch . Since we don \u2019 t have a criterion of how much attribution is trivial enough to be seen as \u201c no attribution \u201d , we instead summed all absolute attribution within the patch and took the average across the test dataset . We repeated this with other attribution methods and created a bar chart comparing the average . Results are shown in Figure 8 . Ideally , there should be nearly zero attribution , but we observed that the saliency map assigned the most attribution to the patch among all attribution methods . This shows that DNNs do not filter our irrelevant features during forward propagation ( by definition of gradient ) and that other attribution methods alleviate this problem . Second , we created segmentation masks for 10 correctly classified CIFAR10 images of each class ( total 100 images ) and repeated the feature map occlusion test . We recorded ( class logit ) \u2013 ( largest logit among the other 9 classes ) and took the average over all the images . Figure 9 in Appendix A.1 shows that the difference is generally positive throughout the occlusion process ( i.e. , the class does not change throughout the occlusion process ) , and this implies the irrelevance of background features to the classification task . C2 : `` How does RectGrad compare with simply applying a final threshold on other attribution maps ? '' A2 : We found that noise can accumulate during backpropagation . Specifically , irrelevant features may have trivial gradient near the output layer ; however , since gradient is calculated by successive multiplication , the noise can grow exponentially as gradient is propagated towards the input layer . This often results in confusing attribution maps which assign high attribution to entirely irrelevant regions ( e.g.baseline methods assign high attribution to uniform background in `` lighter '' example in Figure 6 ) , especially for deep networks such as Inception . In such situation , simply applying a final threshold does not work . RectGrad does not suffer from this problem since it thresholds irrelevant features at every layer and hence stops noise accumulation in the first place ( Section 4.1 explains how RectGrad thresholds irrelevant features ) . ( Updated 11/23 ) In Appendix A.2 , we corroborate this claim by comparing Saliency map and RectGrad attributions as they are propagated towards the input layer . We have also surveyed samples for 1.5k randomly chosen ImageNet images , and we found them to be generally consistent with our claims in the paper . As we mentioned in \u201c Our Common Reply to All Reviewers \u201d , we have uploaded the 1.5k samples in anonymous Google drives so that the Reviewers can inspect them if he/she is not convinced by the results in the paper . However , as it always is with DNN interpretability research , it is difficult to demonstrate the efficacy of the proposed method or erase the cherry-picking concern just with large-scale samples . We are aware of this fact and that is why we have conducted numerous additional quantitative experiments ( e.g.A3 ) .It would be very much appreciated if the Reviewer understands and takes this situation into account when reviewing the revised version of this work ."}, "1": {"review_id": "Hkemdj09YQ-1", "review_text": "This paper studies how to better visually interpret a deep neural network. It proposes a new method to produce less noisy saliency maps, named RectGrad. RectGrad thresholds gradient during backprop in a layer-wise fashion in a similar manner to a previous work called Guided Backprop. The difference is that Guided Backprop employs a constant threshold, i.e. 0, while RectGrad uses an adaptive threshold based on a percentile hyper-parameter. The paper is well-written, including a comprehensive review of previous related works, an meaningful meta-level discussion for motivation, and a clear explanation of the proposed method. One of my biggest concern is regarding the experiment and evaluation section. Conclusions are drawn based on the visualization of a few saliency maps. I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking and . For example, this is the conclusion in the Adversarial Attack paragraph: \u201cwe can conclude that Rectified Gradient is equally or more class sensitive than baseline attribution methods\u201d. As pointed out by the paper, the conclusion can be drawn from Figure 8 in the main paper and Figure 10 in Appendix A.1. However, the proposed method tends to produce a saliency map with higher sparsity, therefore the difference may appear more apparent. It is stretching to conclude that it is more class sensitive without further quantitative validation. Evaluation appears to be a common concern to the work on saliency maps. The existing quantitative evaluation in the paper seems disconnected to the visual nature of saliency maps. Concretely, when can we say one saliency map looks better than another? Since this paper claims to produce less noisy saliency maps, what does it mean quantitatively? Is it true that it produces less pixels on the background? If so, can we evaluate it with foreground-background segmentation annotation to prove that point? Though how to evaluate saliency maps remains an open question, I feel some discussion on this paper would make the paper more insightful. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the friendly and detailed review . Before reading our reply for your review , we politely ask you to read \u201c Our Common Reply to All Reviewers \u201d first . C1 : `` One of my biggest concern is regarding the experiment and evaluation section . Conclusions are drawn based on the visualization of a few saliency maps . I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking . For example , this is the conclusion in the Adversarial Attack paragraph : \u201c we can conclude that Rectified Gradient is equally or more class sensitive than baseline attribution methods \u201d . As pointed out by the paper , the conclusion can be drawn from Figure 8 in the main paper and Figure 10 in Appendix A.1 . '' A1 : We have surveyed samples for 1.5k randomly chosen ImageNet images , and we found them to be generally consistent with our claims in the paper . As we mentioned in \u201c Our Common Reply to All Reviewers \u201d , we have uploaded the 1.5k samples in anonymous Google drives so that the Reviewers can inspect them if he/she is not convinced by the results in the paper . However , as it always is with DNN interpretability research , it is difficult to demonstrate the efficacy of the proposed method or erase the cherry-picking concern just with large-scale samples . We are aware of this fact and that is why we have conducted numerous additional quantitative experiments ( e.g.AN2 A3 ) .It would be very much appreciated if the Reviewer understands and takes this situation into account when reviewing the revised version of this work . C2 : `` However , the proposed method tends to produce a saliency map with higher sparsity , therefore the difference may appear more apparent . '' A2 : We applied final threshold to baseline attribution methods such that RectGrad and baseline attribution maps have similar levels of sparsity . The final threshold details are described in Our Common Reply to All Reviewers . We then repeated all qualitative experiments on 1.5k randomly chosen ImageNet images ( image links listed in comment above ) . We have observed that the conclusions still generally hold even after final threshold . We also believe that the ability of our method to control the threshold hyper parameter to make the difference more/less apparent is an advantage , rather than a disadvantage . If the image was near the decision boundary in the first place , then the adversarial attack would change only a small portion of internal activation patterns . This may lead to attribution maps which are indistinguishable from attribution maps for original images . Baseline methods have no effective way of dealing with this except final threshold . However , as we have observed , final threshold still results in noisy attribution maps for baseline methods . For RectGrad , the user can control the threshold percentile q to visually understand which features really account for the change in DNN decision . C3 : `` It is stretching to conclude that it is more class sensitive without further quantitative validation . '' A3 : To our knowledge , there is no previous work in quantitatively validating how class sensitive an attribution method is . There only exist qualitative methods : ( 1 ) comparing original attribution map with those produced with respect to another class ( Smilkov et al.2017 , https : //arxiv.org/abs/1706.03825 ) and ( 2 ) adversarial attack ( Nie et al.2018 , https : //arxiv.org/abs/1805.07039 ) . We have chosen the latter method since it is deterministic ; for the former method , there are 1000 other classes to choose from , and we thought this could lead to space trouble or cherry-picking concerns . Hence the large-scale adversarial attack samples are the best we can do to convince the Reviewer in the current situation ."}, "2": {"review_id": "Hkemdj09YQ-2", "review_text": "In the paper, the authors proposed a new saliency map method, based on some empirical observations about the cause of noisy gradients. Specifically, through experiments, the authors clarified that the noisy gradients are due to irrelevant information propagated in the forward pass in DNN. Because the backpropagation follows the same pass, irrelevant feature are conveyed back to the input, which results in noisy gradients. To avoid noisy gradients, the authors proposed a new backpropagation named Rectified Gradient (RectGrad). In RectGrad, the backward pass is filtered out if the product of the forward signal and the backward signal are smaller than a threshold. The authors claim that, with this modification in backpropagation, the gradients get less noisy. In some experiments, the authors presented that RectGrad can produce clear saliency maps. I liked the first half of the paper: the observations that irrelevant forward passes are causing noisy gradients seem to be convincing. The experiments are designed well to support the claim. Here, I would like to point out, that noisy gradients in occluded images may be because of the convolutional structures. Each filter in convolution layer is trained to respond to certain patterns. Because the same filter is used for each of subimages, some filters can be activated occasionally on occluded parts. I think this does not happen if the network is densely connected without convolutional structures. The trained dense connection will be optimized to remove the effects of occluded parts. Hence, for such networks, the gradient will be zeros for occluded parts. The second half of the paper (Sec.4 and 5) are not very much convincing to me. Below, I raise several concerns. 1. There is no justification on the definition of RectGrad: Why Rl = I(al * Rl > t) R(l+1)? The authors presented Rl = I(al * Rl > t) R(l+1) as RectGrad, that can filter out irrelevant passes. However, there is no clear derivation of this formula: the definition suddenly appears. If the irrelevant forward passes are causes of noisy gradients, the modification Rl = I(al > t) R(l+1) seems to be more natural to me. It is also a natural extension to the ReLU backward pass Rl = I(al > 0) R(l+1). Why we need to filter out negative signals in backward pass? 2. The experimental results are less convincing: Is RectGrad truly good? In Sec.5.2, the authors presented saliency maps only on a few images, and claimed that they look nicely. However, it is not clear that those \"nicely looking\" saliency map are truly good ones. I expect the authors to put much efforts on quantitative comparisons rather than qualitative comparisons, so that we can understand that those \"nicely looking\" saliency maps are truly good ones. Sec.5.3 presents some quantitative comparisons, however, the reported Sensitivity and ROAR/KAR on RectGrad are not significant. The authors mentioned that this may be because of the sparsity of RectGrad. However, if the sparsity is the harm, the underlying observations of RectGrad may have some errors. I think the current manuscript has an inconsistency between the fundamental idea (based on empirical observations) and the performance of RectGrad. [Minor Concern] In Sec.5, the authors frequently refer to the figures in appendix. I think the main body of the paper should be self-contatined. I therefore think that some of the figures related to main results should appear in the main part. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for the friendly and detailed review . Before reading our reply for your review , we politely ask you to read \u201c Our Common Reply to All Reviewers \u201d first . C1 : `` I liked the first half of the paper : the observations that irrelevant forward passes are causing noisy gradients seem to be convincing . The experiments are designed well to support the claim . Here , I would like to point out , that noisy gradients in occluded images may be because of the convolutional structures . Each filter in convolution layer is trained to respond to certain patterns . Because the same filter is used for each of subimages , some filters can be activated occasionally on occluded parts . I think this does not happen if the network is densely connected without convolutional structures . The trained dense connection will be optimized to remove the effects of occluded parts . Hence , for such networks , the gradient will be zeros for occluded parts . '' A1 : Thank you for the compliments ! Note that if we only use dense layers as the Reviewer suggested , we would not be able to achieve such high test accuracy . Hence the problem of noisy gradients for CNNs would have to be addressed sooner or later . In addition , at the preliminary stage of this research , we also found that using fully connected layers does not solve this problem . We speculate this happens due to two reasons : ( 1 ) random initialization of weights and ( 2 ) lack of incentive for the network to `` not remove forward signal from irrelevant features '' or `` zero out weights corresponding to irrelevant features '' . Correspondingly , we found that using l2 loss / weight decay k||w||^2 does remove noise from saliency maps . However , by the time the weight decay coefficient k was high enough to produce clear saliency maps , DNN lacked the expressiveness to achieve sufficiently high test accuracy . Therefore , we did not include this observation in the final version of our paper . C2 : `` There is no justification on the definition of RectGrad : Why Rl = I ( al * Rl > t ) R ( l+1 ) ? The authors presented Rl = I ( al * Rl > t ) R ( l+1 ) as RectGrad , that can filter out irrelevant passes . However , there is no clear derivation of this formula : the definition suddenly appears . If the irrelevant forward passes are causes of noisy gradients , the modification Rl = I ( al > t ) R ( l+1 ) seems to be more natural to me . It is also a natural extension to the ReLU backward pass Rl = I ( al > 0 ) R ( l+1 ) . Why we need to filter out negative signals in backward pass ? '' A2 : We direct the Reviewer to Section 4.1 where we explain the rationale behind the definition of RectGrad in the revised version of the paper . We also direct the Reviewer to A2 of our reply to AN2 , where we answer `` how does RectGrad compare with simply applying a final threshold on other attribution maps ? `` . C3 : `` The experimental results are less convincing : Is RectGrad truly good ? In Sec.5.2 , the authors presented saliency maps only on a few images , and claimed that they look nicely. \u201d A3 : We direct the Reviewer to A1 of our reply to AN1 , where we reply to `` One of my biggest concern is regarding the experiment and evaluation section . Conclusions are drawn based on the visualization of a few saliency maps . I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking. \u201d We have also proven through additional quantitative experiments that RectGrad attribution maps are not only sparse , but significantly less noisy than baseline attribution maps . We direct the Reviewer to A5 of our reply to AN1 , where we answer `` since this paper claims to produce less noisy saliency maps , what does it mean quantitatively ? Is it true that it produces less pixels on the background ? If so , can we evaluate it with foreground-background segmentation annotation to prove that point ? ''"}}