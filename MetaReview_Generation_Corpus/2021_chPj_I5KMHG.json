{"year": "2021", "forum": "chPj_I5KMHG", "title": "Grounding Language to Autonomously-Acquired Skills via Goal Generation", "decision": "Accept (Poster)", "meta_review": "This paper presents a new approach to grounding language-based RL tasks via an intermediate semantic representation, in an architecture called language-goal-behavior (LGB).  The architecture permits learning a mapping from internal goals to behavior  (GB) separately from learning a mapping from language to internal goals (LG), and prior to flexibly combining all three (LGB).  The architecture is studied in a specific implementation called DECSTR.  The architecture has multiple desired attributes including support for intrinsic motivation, decoupling skill acquisition from language grounding, and strategy switching.  The experiments demonstrate the utility of different components in the architecture with a variety of ablation results.\n\nThe reviews initially found the paper to be poorly organized with required content described only in the appendix (R1, R2, R4), with unclear main contributions (R1, R2, R4), and with results restricted to demonstrations (R3).  Despite these reservations, the reviewers found the content to be potentially relevant though narrow in scope.\n\nThe authors substantially revised the paper. They improved its organization, clarified contributions, separated the architecture from the specific examples, and improved the experimental baselines.  After reading the revised paper, the reviewers agreed that the paper's organization and insights were improved, making the new paper's contribution and insight clear.  The experimental baselines were also improved, providing more support for the potential utility of the proposed method.\n\nThree reviewers indicate to accept this paper for its contribution of a novel approach to grounding language and behavior with an intermediate semantic representation. No substantial concerns were raised on the content of the revised paper. The paper is therefore accepted.", "reviews": [{"review_id": "chPj_I5KMHG-0", "review_text": "* * Summary * * This paper proposes DECSTR , a goal-driven RL framework where the goal is represented as a binary vector that encodes the semantic relationships between objects . The state is assumed to contain disentangled features for each of the objects ( and other features relating to the agent \u2019 s end-effectors ) . The architecture is based on Deep Sets ( Zaher et al. , 2017 ) , which allows the pairs of the objects to be encoded with a shared network . The paper also introduces a curriculum learning strategy similar to CURIOUS ( Colas et al. , 2019 ) , which relies on metrics such as competence and learning progress ( LP ) in order to select goals to pursue during an episode . One key difference is that unlike CURIOUS which uses expert-defined \u201c goal buckets \u201d , DECSTR groups the goals based on recency of discovery . Once trained to be able to behave with respect to these semantic relationship goals , the second phase is language grounding . They learn a module ( implemented as C-VAE ) that converts from natural language text to the semantic configuration goal space . Experiments were conducted in the Fetch Manipulate robotic arm environment and compared with ablations of DECSTR without some of its components , demonstrating strong performance and generalization to various types of language instructions . * * Pros * * : - The paper is well-motivated , citing literature from several fields . - The sum is greater than its parts : many components in DECSTR are based on existing works ( e.g.Deep Sets , C-VAE , using LP for intrinsically motivated goals , etc . ) , but empirically they have shown through ablations that all of their components were necessary for the agent to solve the Fetch Manipulation task successfully . - The experiment sections are fairly thorough , with ablations on the components of their methods ( as said above ) , and various kinds of language command generalization evaluations ( in a similar style to IMAGINE ( Colas et al. , 2020 ) . - The interpretability of the semantic goal space aspect is interesting . And being able to have the agent explicitly maps from the natural language text to the semantic goal space also helps us debug/understand what the agent is thinking at inference time * * Cons * * : - Part of the thesis is that decoupling of sensorimotor learning from language acquisition is advantageous to an end-to-end language to sensorimotor learning . I have concerns/clarification about some of the baselines , which might not have been a fair comparison with DECSTR ( see question 1 & 2 below ) - Some parts of the method are unclear/vague without reading the appendix section to get the full detail . I understand that is due to the space limitation issue and because there are so many components to DECSTR . ( see question 3 ) * * Recommendation * * : Overall , I vote for marginally below acceptance threshold in the current form . As mentioned in the strengths section , I do like the motivation of the paper and the strong performance of the method . But I am also suspicious of the poor performance of the baselines ( e.g.Figure 1c ) , which may be due to not having HER , instead of their proposed contributions . It would be good if the authors can clarify that concern . * * Question * * : 1 . In Figure 1c , for the Language Goals baseline , was HER applied to the Language Goals in this case ( i.e.similar to ACTRCE ( Chan et al. , 2019 ) , IMAGINE ( Colas et al. , 2020 ) ? Similarly , was HER applied to the Position-Goals baseline ? If not , then it is possible the difference in performance between DECSTR and these baselines may be due more to HER than due to the difference in goal representation . 2.Would it be possible to train Phase 1 and Phase 2 together or in an end-to-end fashion ? This would provide a \u2018 coupled \u2019 version that is different from any of the baselines studied in the paper because it still uses the semantic configuration as the intermediate goal representation while having joint training of the language representation and the sensorimotor . If this baseline struggles to learn ( possibly due to difficult optimization/local minimas ) , then this will help further strengthen the thesis of the importance of decoupling the learning process into two distinct phases . 3.Section 3.2 : the main text and appendix C.2 was not very clear about the second inductive bias for the symmetry of the behavior required to achieve $ above ( o_i , o_j ) $ and $ above ( o_j , o_i ) $ . Are you saying , for example , if we are trying to have object 1 above object 2 , then we specify the goal in the form $ g_1 $ , while if we want object 2 above object 1 , then we specify the goal in the form $ g_2 $ ? * * Minor comments * * : * When using double quotes in latex , use backticks for the opening quote . * * After rebuttal responses * * : I have read the authors \u2019 updated draft and response to my concerns , as well as the other reviews . The updated paper provides a clearer framing and some missing baselines have also been included . I raised my evaluation to a weak acceptance for the paper .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 4 for their helpful feedback . Here we answer comments that were specific to Reviewer 4 . Concerns shared with other reviewers are addressed in the general answer . * * Concerns about the baselines * * We are indeed using HER in the design of our baselines . The baselines are designed so as to reduce to its minimum the number of potential confounding factors . For this reason , we keep most modules strictly equivalent ( HER included ) . The main answer provides further details about the baselines , including the new Language baseline that will replace the older one . The reviewer is also asking whether we could train the DECSTR agent with Phase 1 and Phase 2 coupled together or in an end-to-end fashion . As long as there is a fixed intermediate representation , the gradients can not flow backward , which prevents any end-to-end learning . The new end-to-end language-conditioned baseline implements a state-of-the-art language-conditioned RL architecture and performs this coupled learning . Furthermore , the introduction of the language-conditioned goal generator makes the emergence of behavioral diversity possible , as many valid configurations can be generated for a given language input . Other implementations of our architecture could mix the two phases : either run them asynchronously , or make repeated cycles between them , etc . This could allow the tutor to guide its selection of instructions so as to orient the sensorimotor learning of the agent . * * Organization of the method section * * As explained in the main answer , we deeply reorganized the method and experimental sections . This was made easier by the reflection on the focus of the paper , as outlined in the main answer . Important details are also moved back from the appendix to the main document to facilitate comprehension . We fixed backticks , thank you . * * Conclusion * * It seems Reviewer 4 is mostly concerned about the design of the baselines . Answering their concern , we declared using HER in our baselines . The main answer details improvements made on both baselines : improving the position baseline and redefining the language baseline to better support our main contribution . We hope the new organizations of the method and experiment section help understanding ."}, {"review_id": "chPj_I5KMHG-1", "review_text": "This work proposed DECSTR , a procedure for encouraging intrinsic motivation via an intermediate semantic state-space representation . The authors propose an intermediate semantic state space that the intrinsically motivated agent learns to explore . For the environment provided ( a 3-block system ) , the agent fully explores the symbolic state space , reaching all feasible symbolic states . In the second part of the work , the authors train a language model capable of proposing symbolic goals ( in the form of symbolic states ) from natural language input and shows that the previously-intrinsically-motivated agent can now be made to reach these goals , demonstrating that the symbolic-goal-conditioned policy is sufficient for instruction following in their 3-block domain . The work is generally interesting , and seems to address a simple version of a broader class of problems that embodied agents typically struggle with , particularly in the absence of clear goals . However , the approach presented in the behavior ( in particular the form of the semantic representation that is claimed as one of the primary contributions of the work ) is very specific to the single problem used for demonstrations in the paper , limiting the potential impact of the work . Firstand I think the most significant issue with the submissionis that many critical experimental details are included only in the lengthy appendix . Much of this information , including the information provided to the learning algorithm at every step and how that information is encoded such that it allows for a relatively object-agnostic representation , is only available in sufficient detail in the appendix . Relatedly , visualizations of the approach and experimental setup also only appear in the appendix , yet are extremely helpful ( if not essential ) for understanding . Detail critical to understanding the approach should be included in the body of the text . Second , it is unclear exactly what problem is being solved in this work or what its primary contribution is . A clearer statement of its motivations will be necessary before publication . /What problem is the robot or system designers trying to overcome ? / Right now , the paper seems to come up with three potential answers to this question , none of which necessarily rises above the others . Here are what I think the main contributions of the work could be : 1 . * The proposed semantic representation * The semantic goal representation used to define the space of intrinsic motivation seems to be a novel contribution . However , if the paper were to focus on this aspect of the contribution , it would need to do a better job understating why this representation were useful beyond a relatively small manipulation task . Critically : using only one problem setting with only three blocks is insufficient to convince the reader that this representation is useful more generally ( as might be suggested by much of the talk about Inductive Bias ) . 2 . * State of the art state-space exploration in intrinsic motivation . * This might be true , though I find such a thing hard to measure . In addition , it seems that many if not all of the tools used in the learning process are not novel . ( Perhaps a combination of this and point 1. is the primary contribution . ) 3 . * State of the art performance on language-driven block manipulation tasks . * This might be true as well , but the results are so-far unconvincing . All baselines are varied forms of the proposed agent , which makes it difficult to compare against other approaches ( e.g.something like Li et al 2019 ) . The paper currently seems to claim that the combination of progress in these three areas is a novel contribution ; I am sympathetic to this idea ( as I do not believe that every paper needs to be `` state of the art '' in one single thing ) , though it is sufficiently unclear at the moment what the takeaway message of the paper is that I can not recommend it be published in its current state . In particular , the authors need to work on honing the message of the paper . It is also not unlikely that one or two more experiments will need to be added to support the focused narrative . Smaller comments - The name of algorithm should appear in the body of the text , not a footnote . Relatedly , it is unclear how the proposed approach uses the `` Deep Sets '' work in such a way that it justifies inclusion in the name of the proposed technique . - The paper/Introduction would benefit from a summary of contributions : even after reading , it may not be clear to a reader which contributions are from this paper versus other work . - Relatedly , much of the discussion of Inductive Biases that appear throughout the paper is of mixed relevance for this work . On the one hand , it is clear how the idea of an object-centric inductive bias helped to inform how the input to the neural network was encoded in a way that might allow the agent to apply its knowledge learned between two of the objects to a policy that allows it to manipulate all three . However , the goal condition is necessarily specific when it comes to representing which objects to which each element it refers . The structure of the goal and the semantic relations it encodes are quite specific to the particular problem at hand , and it is - The reward for the `` Position only '' baseline seems artificially constructed : a non-binary reward function would likely allow the system to learn more easily . As of now I am unconvinced that the authors have worked hard enough to make a fair baseline for comparison . This is particularly problematic since this baseline is a key motivator for the existence of the proposed semantic goal representation . - The paper overall is quite well written , despite relegating too much information to the abstracts .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 2 for their helpful feedback . Here , we answer comments that were specific to Reviewer 2 . Concerns shared with other reviewers are addressed in the general answer . * * Comments on contributions and experimental section * * Reviewer 2 seems to be mostly concerned about the lack of focus of our paper . We thank R2 for their very constructive suggestions on that aspect . These helped us refocus our paper as detailed in the main answer . We believe the organization of the experimental section is drastically improved by the new positioning of the paper . We also moved important information and visualisations back from the appendix to the main document . * * Generality of the semantic representation * * We answer this comment in the main answer . * * Smaller comments * * * DECSTR is now the name of the particular instance of the general LGB architecture we propose . This particular implementation relies on Deep Sets , which can justify the use of the term in the name . However , we removed \u201c DECSTR \u201d from the title of the paper , as it is only a secondary contribution , the LGB architecture being the central contribution . * We now explicitly list our contributions in the introduction * The description of inductive biases is indeed secondary given the new focus of the paper on the general LGB architecture . The methods section is updated accordingly . * We thank Reviewer 2 for a comment that pushed to allocate extra resources to the position baseline . We reached higher performance by combining non-binary rewards ( as advised by Reviewer 2 ) and the multi-criteria HER method from Lanier et al. , 2019 . This helps get the Position baseline closer to state-of-the-art RL approaches for manipulation tasks . * * Conclusion * * It seems the main concerns of Reviewer 2 are about the contribution and challenge statements as well as the organization of the experimental section . We hope that our answers and the new version of the paper help resolve them ."}, {"review_id": "chPj_I5KMHG-2", "review_text": "The DECSTR system 's intrinsic motivations may be applicable to other application domains , depending on how objects and relations are enumerated . This potential is not explored beyond the toy environment presented . The learning methods ( especially inductive biases ) are hand-crafted based on human-level knowledge about semantic predicates , but only two ( `` above '' and `` close '' ) are demonstrated . Without demonstrating the system on any other configuration or world , it 's difficult to tell whether it 's able to solve only the problem it 's been crafted to solve in this specific environment . Questions : 3.1 `` in principle ... could use any other combination of binary predicates and could be extended to use n-ary predicates '' this claim is not demonstrated in the paper , and in 3.2 the inductive biases seem bespoke crafted for binary predicate 'above ' which has particular symmetry . Would similar careful design of inductive biases be necessary and possible for n-ary predicates that do not demonstrate these as easily ( e.g. , `` topmost '' ) ? What about predicates that involve an unspecified number of discrete arguments , like `` base '' - > holding up an indefinite N of other objects/structures in `` use the green block as the base '' . 3.4 `` or is union '' this does n't generally hold for natural language . A statement like `` put the red block or the green block above the yellow block '' does not mean to put both red and green ( union of goals ) above yellow . Typically langauge `` or '' is `` xor '' ; is the notion of `` or '' here not given in language or not meant to represent human language ? Areas for Improvement : 5 `` a learning architecture that discovers and masters all reachable configurations from a set of relational primitives '' this is literally true but only demonstrated on ' a ' single set of relational primitives , so it feels like overclaiming . Nits : - double citation for Mandler , 2012 in intro in adjacent sentences can be condensed to once - footnotes on other side of period - `` Besides '' in `` Blocks Manipulation '' seems a bit off-sounding ; maybe `` In addition , '' ? - typo section 3 `` based o abstract '' - Typo section 5 backwards quotes `` overlapping waves '' LHS . - `` Caregiver '' in section 5 is an unintroduced role . The rest of the paper does not frame DECSTR or the oracle generator this way . - Ending the paper with `` etc . '' feels weird/informal .", "rating": "7: Good paper, accept", "reply_text": "We thank Reviewer 3 for their helpful feedback . Here , we answer comments that were specific to Reviewer 3 . Concerns shared with other reviewers are addressed in the general answer . * * Application to other domains * * We partly answer this point in the main answer . The definition of semantic representations is domain-specific just like the definition of goal spaces and reward functions in traditional goal-conditioned RL . Instead of defining the set of tasks , we define the set of possible behaviors by defining the dimensions of that space . In the main answer , we argue that it is an easier task that involves less prior knowledge . From a developmental point of view , such sensors could be innate or acquired very early by infants , as it is the case for spatial predicates ( Mandler , 2012 ) . In future work , we would like to investigate how to learn these predicates from social interactions . The question of learning semantic predicates that can be used across a large variety of domains is also very interesting . However , the main contribution of this paper is to define and demonstrate the benefits of the decoupled LGB architecture over standard language-conditioned RL approaches . In this demonstration , DECSTR provides an illustration of the three properties emerging from LGB architectures ( see main answer ) . Thus , the design/learning of semantic representation that generalize across domains and allow to represent a diversity of interesting behaviors is orthogonal to the main contribution of the paper . * * About the use of more complicated predicates * * `` in principle ... could use any other combination of binary predicates and could be extended to use n-ary predicates '' : by this sentence , we mean that semantic representations can be composed of any combinations of n-ary predicates that we can think of . Of course , more complicated semantic representations also involve more complicated learning architectures to handle them . We clarified this sentence in the new version . About the \u201c above \u201d inductive bias : we can argue that infants who have an innate sensor for the \u201c above \u201d relation might also have the innate implicit knowledge of the symmetry of that relation . About other predicates : the sentence \u201c use the green block as the base \u201d could be seen as describing many binary \u201c above \u201d relations where the green block is always the block below . \u201c Top-most \u201d could also use a binary predicate \u201c generally above \u201d that does not require horizontal alignment , it would then refer to the block that is never the block below in all the existing \u201c generally above \u201d relations . Overall , inductive biases are not theoretically required to handle n-ary predicates , but they are practically useful for our current algorithms to work with reasonable sample sizes . Future implementations of the LGB architecture might require the use of Graph Neural Networks to handle relations between several nodes-objects . * * About logical combinations of instructions * * Reviewer 3 is right , our logical combinations are symbolic and are not expressed directly by text . It can be seen as assuming that the agent has an innate knowledge of the OR , AND and NOT logical functions , and can use them to combine any atomic instructions it discovered during its interaction with the tutor . How to translate complicated sentences that express logical combinations into logical trees of basic instructions that the agent could handle is very interesting but out of the scope of this present work . * * '' a learning architecture that discovers and masters all reachable configurations from a set of relational primitives '' * * We acknowledge that this formulation could be misinterpreted and corrected it . * * Typos * * We thank Reviewer 3 for pointing minor errors in the text . We corrected them in the new version . * * Conclusion * * Reviewer 3 seems mostly concerned about the generality of our approach and its use in other domains . With our new positioning detailed in the main answer , we argue that this paper presents a general architecture ( LGB ) and that DECSTR is only a particular implementation of it , to demonstrate its benefits . The design of semantic representations is orthogonal to the approach of this paper but is an interesting topic for future research . Designing semantic representation is defining the space of behaviors that the agent can explore . Although it is simpler than designing space of achievable goals and their associated rewards , it remains domain dependent . Designing or learning general predicates , and designing learning architecture able to handle complicated n-ary predicates is out of the scope of this paper ."}, {"review_id": "chPj_I5KMHG-3", "review_text": "This paper introduces DECSTR , which is an agent having a high-level representation of spatial relations between objects . DECSTR is a learning architecture that discovers and masters all reachable configurations from a set of relational spatial primitives . They demonstrated the characteristics in a proof-of-concept setup . In the introduction , the inspiration obtained from developmental psychology is described . Motivation and background are broadly introduced . A wide range of related works are introduced in section 2 . The motivation and target of this paper are ambitious and important . However , from the `` methods '' part , i.e. , section 3 , this paper is hard to follow . The supplementary material helps to understand . However , I believe some of the informative and detailed information in the supplementary material should come to the main manuscript . The proposed method , i.e. , DECSTR , is comprised of many components . Therefore , the main contribution is also not clear . # What is the main argument of the paper ? Experimental conditions are also hard to follow . In evaluation , Figure 1 shows ablation studies alone , i.e. , comparison with the variants of DECSTR . Therefore , the contribution of the paper is hard to grasp . We can understand what kind of task is achieved in this paper . Currently , the paper somehow seems to be a demonstration of DECSTR . In this sense , if the authors state research questions , challenges , and contributions of this paper more clearly , that will make this paper more impactful .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank Reviewer 1 for their helpful feedback . Here , we answer comments that were specific to Reviewer 1 . Concerns shared with other reviewers are addressed in the general answer . * * The method section is hard to follow * * As detailed in the main answer , the new organization of the method section presents the general LGB architecture , the environment , then follows the three modules of the proposed instantiation of the LGB architecture with DECSTR : * the semantic representation ; * the intrinsically-motivated goal-conditioned RL algorithm * the language-conditioned goal generator . This new organization should be easier to follow . In addition , we moved part of the information from the appendix back to the main paper to facilitate comprehension . * * Ablations and baselines * * We call \u201c baselines \u201d variants of our algorithm that implement defining features from related state-of-the-art approaches ( language-conditioned RL and continuous goal conditioned RL for manipulation tasks respectively ) . We call \u201c ablations \u201d variants of DECSTR that aim at showing the importance of its components ( inductive biases , curriculum , etc . ) . Our main answer and the new version of the paper clarify the purpose and definitions of our two baselines . * * The paper seems to be a demonstration of DECSTR * * We agree that the focus of the paper was not clear in the previous version . We hope the new positioning outlined in the main answer helps resolving these concerns . The paper will be about the novel RL architecture LGB . Most of its properties emerge from its design ( decoupling , goal generation leading to behavioral diversity and enabling strategy switching ) . DECSTR is thus a concrete illustration of these properties in a specific setup . We argue that other implementations following the same overall architecture will demonstrate similar properties and benefits over existing approaches . * * Conclusion * * It seems the main concerns of Reviewer 1 are about the contribution and challenge statements as well as the organization of the methods and experimental section . We hope that our answers and the new version of the paper help resolve them ."}], "0": {"review_id": "chPj_I5KMHG-0", "review_text": "* * Summary * * This paper proposes DECSTR , a goal-driven RL framework where the goal is represented as a binary vector that encodes the semantic relationships between objects . The state is assumed to contain disentangled features for each of the objects ( and other features relating to the agent \u2019 s end-effectors ) . The architecture is based on Deep Sets ( Zaher et al. , 2017 ) , which allows the pairs of the objects to be encoded with a shared network . The paper also introduces a curriculum learning strategy similar to CURIOUS ( Colas et al. , 2019 ) , which relies on metrics such as competence and learning progress ( LP ) in order to select goals to pursue during an episode . One key difference is that unlike CURIOUS which uses expert-defined \u201c goal buckets \u201d , DECSTR groups the goals based on recency of discovery . Once trained to be able to behave with respect to these semantic relationship goals , the second phase is language grounding . They learn a module ( implemented as C-VAE ) that converts from natural language text to the semantic configuration goal space . Experiments were conducted in the Fetch Manipulate robotic arm environment and compared with ablations of DECSTR without some of its components , demonstrating strong performance and generalization to various types of language instructions . * * Pros * * : - The paper is well-motivated , citing literature from several fields . - The sum is greater than its parts : many components in DECSTR are based on existing works ( e.g.Deep Sets , C-VAE , using LP for intrinsically motivated goals , etc . ) , but empirically they have shown through ablations that all of their components were necessary for the agent to solve the Fetch Manipulation task successfully . - The experiment sections are fairly thorough , with ablations on the components of their methods ( as said above ) , and various kinds of language command generalization evaluations ( in a similar style to IMAGINE ( Colas et al. , 2020 ) . - The interpretability of the semantic goal space aspect is interesting . And being able to have the agent explicitly maps from the natural language text to the semantic goal space also helps us debug/understand what the agent is thinking at inference time * * Cons * * : - Part of the thesis is that decoupling of sensorimotor learning from language acquisition is advantageous to an end-to-end language to sensorimotor learning . I have concerns/clarification about some of the baselines , which might not have been a fair comparison with DECSTR ( see question 1 & 2 below ) - Some parts of the method are unclear/vague without reading the appendix section to get the full detail . I understand that is due to the space limitation issue and because there are so many components to DECSTR . ( see question 3 ) * * Recommendation * * : Overall , I vote for marginally below acceptance threshold in the current form . As mentioned in the strengths section , I do like the motivation of the paper and the strong performance of the method . But I am also suspicious of the poor performance of the baselines ( e.g.Figure 1c ) , which may be due to not having HER , instead of their proposed contributions . It would be good if the authors can clarify that concern . * * Question * * : 1 . In Figure 1c , for the Language Goals baseline , was HER applied to the Language Goals in this case ( i.e.similar to ACTRCE ( Chan et al. , 2019 ) , IMAGINE ( Colas et al. , 2020 ) ? Similarly , was HER applied to the Position-Goals baseline ? If not , then it is possible the difference in performance between DECSTR and these baselines may be due more to HER than due to the difference in goal representation . 2.Would it be possible to train Phase 1 and Phase 2 together or in an end-to-end fashion ? This would provide a \u2018 coupled \u2019 version that is different from any of the baselines studied in the paper because it still uses the semantic configuration as the intermediate goal representation while having joint training of the language representation and the sensorimotor . If this baseline struggles to learn ( possibly due to difficult optimization/local minimas ) , then this will help further strengthen the thesis of the importance of decoupling the learning process into two distinct phases . 3.Section 3.2 : the main text and appendix C.2 was not very clear about the second inductive bias for the symmetry of the behavior required to achieve $ above ( o_i , o_j ) $ and $ above ( o_j , o_i ) $ . Are you saying , for example , if we are trying to have object 1 above object 2 , then we specify the goal in the form $ g_1 $ , while if we want object 2 above object 1 , then we specify the goal in the form $ g_2 $ ? * * Minor comments * * : * When using double quotes in latex , use backticks for the opening quote . * * After rebuttal responses * * : I have read the authors \u2019 updated draft and response to my concerns , as well as the other reviews . The updated paper provides a clearer framing and some missing baselines have also been included . I raised my evaluation to a weak acceptance for the paper .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 4 for their helpful feedback . Here we answer comments that were specific to Reviewer 4 . Concerns shared with other reviewers are addressed in the general answer . * * Concerns about the baselines * * We are indeed using HER in the design of our baselines . The baselines are designed so as to reduce to its minimum the number of potential confounding factors . For this reason , we keep most modules strictly equivalent ( HER included ) . The main answer provides further details about the baselines , including the new Language baseline that will replace the older one . The reviewer is also asking whether we could train the DECSTR agent with Phase 1 and Phase 2 coupled together or in an end-to-end fashion . As long as there is a fixed intermediate representation , the gradients can not flow backward , which prevents any end-to-end learning . The new end-to-end language-conditioned baseline implements a state-of-the-art language-conditioned RL architecture and performs this coupled learning . Furthermore , the introduction of the language-conditioned goal generator makes the emergence of behavioral diversity possible , as many valid configurations can be generated for a given language input . Other implementations of our architecture could mix the two phases : either run them asynchronously , or make repeated cycles between them , etc . This could allow the tutor to guide its selection of instructions so as to orient the sensorimotor learning of the agent . * * Organization of the method section * * As explained in the main answer , we deeply reorganized the method and experimental sections . This was made easier by the reflection on the focus of the paper , as outlined in the main answer . Important details are also moved back from the appendix to the main document to facilitate comprehension . We fixed backticks , thank you . * * Conclusion * * It seems Reviewer 4 is mostly concerned about the design of the baselines . Answering their concern , we declared using HER in our baselines . The main answer details improvements made on both baselines : improving the position baseline and redefining the language baseline to better support our main contribution . We hope the new organizations of the method and experiment section help understanding ."}, "1": {"review_id": "chPj_I5KMHG-1", "review_text": "This work proposed DECSTR , a procedure for encouraging intrinsic motivation via an intermediate semantic state-space representation . The authors propose an intermediate semantic state space that the intrinsically motivated agent learns to explore . For the environment provided ( a 3-block system ) , the agent fully explores the symbolic state space , reaching all feasible symbolic states . In the second part of the work , the authors train a language model capable of proposing symbolic goals ( in the form of symbolic states ) from natural language input and shows that the previously-intrinsically-motivated agent can now be made to reach these goals , demonstrating that the symbolic-goal-conditioned policy is sufficient for instruction following in their 3-block domain . The work is generally interesting , and seems to address a simple version of a broader class of problems that embodied agents typically struggle with , particularly in the absence of clear goals . However , the approach presented in the behavior ( in particular the form of the semantic representation that is claimed as one of the primary contributions of the work ) is very specific to the single problem used for demonstrations in the paper , limiting the potential impact of the work . Firstand I think the most significant issue with the submissionis that many critical experimental details are included only in the lengthy appendix . Much of this information , including the information provided to the learning algorithm at every step and how that information is encoded such that it allows for a relatively object-agnostic representation , is only available in sufficient detail in the appendix . Relatedly , visualizations of the approach and experimental setup also only appear in the appendix , yet are extremely helpful ( if not essential ) for understanding . Detail critical to understanding the approach should be included in the body of the text . Second , it is unclear exactly what problem is being solved in this work or what its primary contribution is . A clearer statement of its motivations will be necessary before publication . /What problem is the robot or system designers trying to overcome ? / Right now , the paper seems to come up with three potential answers to this question , none of which necessarily rises above the others . Here are what I think the main contributions of the work could be : 1 . * The proposed semantic representation * The semantic goal representation used to define the space of intrinsic motivation seems to be a novel contribution . However , if the paper were to focus on this aspect of the contribution , it would need to do a better job understating why this representation were useful beyond a relatively small manipulation task . Critically : using only one problem setting with only three blocks is insufficient to convince the reader that this representation is useful more generally ( as might be suggested by much of the talk about Inductive Bias ) . 2 . * State of the art state-space exploration in intrinsic motivation . * This might be true , though I find such a thing hard to measure . In addition , it seems that many if not all of the tools used in the learning process are not novel . ( Perhaps a combination of this and point 1. is the primary contribution . ) 3 . * State of the art performance on language-driven block manipulation tasks . * This might be true as well , but the results are so-far unconvincing . All baselines are varied forms of the proposed agent , which makes it difficult to compare against other approaches ( e.g.something like Li et al 2019 ) . The paper currently seems to claim that the combination of progress in these three areas is a novel contribution ; I am sympathetic to this idea ( as I do not believe that every paper needs to be `` state of the art '' in one single thing ) , though it is sufficiently unclear at the moment what the takeaway message of the paper is that I can not recommend it be published in its current state . In particular , the authors need to work on honing the message of the paper . It is also not unlikely that one or two more experiments will need to be added to support the focused narrative . Smaller comments - The name of algorithm should appear in the body of the text , not a footnote . Relatedly , it is unclear how the proposed approach uses the `` Deep Sets '' work in such a way that it justifies inclusion in the name of the proposed technique . - The paper/Introduction would benefit from a summary of contributions : even after reading , it may not be clear to a reader which contributions are from this paper versus other work . - Relatedly , much of the discussion of Inductive Biases that appear throughout the paper is of mixed relevance for this work . On the one hand , it is clear how the idea of an object-centric inductive bias helped to inform how the input to the neural network was encoded in a way that might allow the agent to apply its knowledge learned between two of the objects to a policy that allows it to manipulate all three . However , the goal condition is necessarily specific when it comes to representing which objects to which each element it refers . The structure of the goal and the semantic relations it encodes are quite specific to the particular problem at hand , and it is - The reward for the `` Position only '' baseline seems artificially constructed : a non-binary reward function would likely allow the system to learn more easily . As of now I am unconvinced that the authors have worked hard enough to make a fair baseline for comparison . This is particularly problematic since this baseline is a key motivator for the existence of the proposed semantic goal representation . - The paper overall is quite well written , despite relegating too much information to the abstracts .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 2 for their helpful feedback . Here , we answer comments that were specific to Reviewer 2 . Concerns shared with other reviewers are addressed in the general answer . * * Comments on contributions and experimental section * * Reviewer 2 seems to be mostly concerned about the lack of focus of our paper . We thank R2 for their very constructive suggestions on that aspect . These helped us refocus our paper as detailed in the main answer . We believe the organization of the experimental section is drastically improved by the new positioning of the paper . We also moved important information and visualisations back from the appendix to the main document . * * Generality of the semantic representation * * We answer this comment in the main answer . * * Smaller comments * * * DECSTR is now the name of the particular instance of the general LGB architecture we propose . This particular implementation relies on Deep Sets , which can justify the use of the term in the name . However , we removed \u201c DECSTR \u201d from the title of the paper , as it is only a secondary contribution , the LGB architecture being the central contribution . * We now explicitly list our contributions in the introduction * The description of inductive biases is indeed secondary given the new focus of the paper on the general LGB architecture . The methods section is updated accordingly . * We thank Reviewer 2 for a comment that pushed to allocate extra resources to the position baseline . We reached higher performance by combining non-binary rewards ( as advised by Reviewer 2 ) and the multi-criteria HER method from Lanier et al. , 2019 . This helps get the Position baseline closer to state-of-the-art RL approaches for manipulation tasks . * * Conclusion * * It seems the main concerns of Reviewer 2 are about the contribution and challenge statements as well as the organization of the experimental section . We hope that our answers and the new version of the paper help resolve them ."}, "2": {"review_id": "chPj_I5KMHG-2", "review_text": "The DECSTR system 's intrinsic motivations may be applicable to other application domains , depending on how objects and relations are enumerated . This potential is not explored beyond the toy environment presented . The learning methods ( especially inductive biases ) are hand-crafted based on human-level knowledge about semantic predicates , but only two ( `` above '' and `` close '' ) are demonstrated . Without demonstrating the system on any other configuration or world , it 's difficult to tell whether it 's able to solve only the problem it 's been crafted to solve in this specific environment . Questions : 3.1 `` in principle ... could use any other combination of binary predicates and could be extended to use n-ary predicates '' this claim is not demonstrated in the paper , and in 3.2 the inductive biases seem bespoke crafted for binary predicate 'above ' which has particular symmetry . Would similar careful design of inductive biases be necessary and possible for n-ary predicates that do not demonstrate these as easily ( e.g. , `` topmost '' ) ? What about predicates that involve an unspecified number of discrete arguments , like `` base '' - > holding up an indefinite N of other objects/structures in `` use the green block as the base '' . 3.4 `` or is union '' this does n't generally hold for natural language . A statement like `` put the red block or the green block above the yellow block '' does not mean to put both red and green ( union of goals ) above yellow . Typically langauge `` or '' is `` xor '' ; is the notion of `` or '' here not given in language or not meant to represent human language ? Areas for Improvement : 5 `` a learning architecture that discovers and masters all reachable configurations from a set of relational primitives '' this is literally true but only demonstrated on ' a ' single set of relational primitives , so it feels like overclaiming . Nits : - double citation for Mandler , 2012 in intro in adjacent sentences can be condensed to once - footnotes on other side of period - `` Besides '' in `` Blocks Manipulation '' seems a bit off-sounding ; maybe `` In addition , '' ? - typo section 3 `` based o abstract '' - Typo section 5 backwards quotes `` overlapping waves '' LHS . - `` Caregiver '' in section 5 is an unintroduced role . The rest of the paper does not frame DECSTR or the oracle generator this way . - Ending the paper with `` etc . '' feels weird/informal .", "rating": "7: Good paper, accept", "reply_text": "We thank Reviewer 3 for their helpful feedback . Here , we answer comments that were specific to Reviewer 3 . Concerns shared with other reviewers are addressed in the general answer . * * Application to other domains * * We partly answer this point in the main answer . The definition of semantic representations is domain-specific just like the definition of goal spaces and reward functions in traditional goal-conditioned RL . Instead of defining the set of tasks , we define the set of possible behaviors by defining the dimensions of that space . In the main answer , we argue that it is an easier task that involves less prior knowledge . From a developmental point of view , such sensors could be innate or acquired very early by infants , as it is the case for spatial predicates ( Mandler , 2012 ) . In future work , we would like to investigate how to learn these predicates from social interactions . The question of learning semantic predicates that can be used across a large variety of domains is also very interesting . However , the main contribution of this paper is to define and demonstrate the benefits of the decoupled LGB architecture over standard language-conditioned RL approaches . In this demonstration , DECSTR provides an illustration of the three properties emerging from LGB architectures ( see main answer ) . Thus , the design/learning of semantic representation that generalize across domains and allow to represent a diversity of interesting behaviors is orthogonal to the main contribution of the paper . * * About the use of more complicated predicates * * `` in principle ... could use any other combination of binary predicates and could be extended to use n-ary predicates '' : by this sentence , we mean that semantic representations can be composed of any combinations of n-ary predicates that we can think of . Of course , more complicated semantic representations also involve more complicated learning architectures to handle them . We clarified this sentence in the new version . About the \u201c above \u201d inductive bias : we can argue that infants who have an innate sensor for the \u201c above \u201d relation might also have the innate implicit knowledge of the symmetry of that relation . About other predicates : the sentence \u201c use the green block as the base \u201d could be seen as describing many binary \u201c above \u201d relations where the green block is always the block below . \u201c Top-most \u201d could also use a binary predicate \u201c generally above \u201d that does not require horizontal alignment , it would then refer to the block that is never the block below in all the existing \u201c generally above \u201d relations . Overall , inductive biases are not theoretically required to handle n-ary predicates , but they are practically useful for our current algorithms to work with reasonable sample sizes . Future implementations of the LGB architecture might require the use of Graph Neural Networks to handle relations between several nodes-objects . * * About logical combinations of instructions * * Reviewer 3 is right , our logical combinations are symbolic and are not expressed directly by text . It can be seen as assuming that the agent has an innate knowledge of the OR , AND and NOT logical functions , and can use them to combine any atomic instructions it discovered during its interaction with the tutor . How to translate complicated sentences that express logical combinations into logical trees of basic instructions that the agent could handle is very interesting but out of the scope of this present work . * * '' a learning architecture that discovers and masters all reachable configurations from a set of relational primitives '' * * We acknowledge that this formulation could be misinterpreted and corrected it . * * Typos * * We thank Reviewer 3 for pointing minor errors in the text . We corrected them in the new version . * * Conclusion * * Reviewer 3 seems mostly concerned about the generality of our approach and its use in other domains . With our new positioning detailed in the main answer , we argue that this paper presents a general architecture ( LGB ) and that DECSTR is only a particular implementation of it , to demonstrate its benefits . The design of semantic representations is orthogonal to the approach of this paper but is an interesting topic for future research . Designing semantic representation is defining the space of behaviors that the agent can explore . Although it is simpler than designing space of achievable goals and their associated rewards , it remains domain dependent . Designing or learning general predicates , and designing learning architecture able to handle complicated n-ary predicates is out of the scope of this paper ."}, "3": {"review_id": "chPj_I5KMHG-3", "review_text": "This paper introduces DECSTR , which is an agent having a high-level representation of spatial relations between objects . DECSTR is a learning architecture that discovers and masters all reachable configurations from a set of relational spatial primitives . They demonstrated the characteristics in a proof-of-concept setup . In the introduction , the inspiration obtained from developmental psychology is described . Motivation and background are broadly introduced . A wide range of related works are introduced in section 2 . The motivation and target of this paper are ambitious and important . However , from the `` methods '' part , i.e. , section 3 , this paper is hard to follow . The supplementary material helps to understand . However , I believe some of the informative and detailed information in the supplementary material should come to the main manuscript . The proposed method , i.e. , DECSTR , is comprised of many components . Therefore , the main contribution is also not clear . # What is the main argument of the paper ? Experimental conditions are also hard to follow . In evaluation , Figure 1 shows ablation studies alone , i.e. , comparison with the variants of DECSTR . Therefore , the contribution of the paper is hard to grasp . We can understand what kind of task is achieved in this paper . Currently , the paper somehow seems to be a demonstration of DECSTR . In this sense , if the authors state research questions , challenges , and contributions of this paper more clearly , that will make this paper more impactful .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank Reviewer 1 for their helpful feedback . Here , we answer comments that were specific to Reviewer 1 . Concerns shared with other reviewers are addressed in the general answer . * * The method section is hard to follow * * As detailed in the main answer , the new organization of the method section presents the general LGB architecture , the environment , then follows the three modules of the proposed instantiation of the LGB architecture with DECSTR : * the semantic representation ; * the intrinsically-motivated goal-conditioned RL algorithm * the language-conditioned goal generator . This new organization should be easier to follow . In addition , we moved part of the information from the appendix back to the main paper to facilitate comprehension . * * Ablations and baselines * * We call \u201c baselines \u201d variants of our algorithm that implement defining features from related state-of-the-art approaches ( language-conditioned RL and continuous goal conditioned RL for manipulation tasks respectively ) . We call \u201c ablations \u201d variants of DECSTR that aim at showing the importance of its components ( inductive biases , curriculum , etc . ) . Our main answer and the new version of the paper clarify the purpose and definitions of our two baselines . * * The paper seems to be a demonstration of DECSTR * * We agree that the focus of the paper was not clear in the previous version . We hope the new positioning outlined in the main answer helps resolving these concerns . The paper will be about the novel RL architecture LGB . Most of its properties emerge from its design ( decoupling , goal generation leading to behavioral diversity and enabling strategy switching ) . DECSTR is thus a concrete illustration of these properties in a specific setup . We argue that other implementations following the same overall architecture will demonstrate similar properties and benefits over existing approaches . * * Conclusion * * It seems the main concerns of Reviewer 1 are about the contribution and challenge statements as well as the organization of the methods and experimental section . We hope that our answers and the new version of the paper help resolve them ."}}