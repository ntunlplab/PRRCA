{"year": "2019", "forum": "ryxnHhRqFm", "title": "Global-to-local Memory Pointer Networks for Task-Oriented Dialogue", "decision": "Accept (Poster)", "meta_review": "Interesting paper applying memory networks that encode external knowledge (represented in the form of triples) and conversation context for task oriented dialogues. Experiments demonstrate improvements over the state of the art on two public datasets. \nNotation and presentation in the first version of the paper were not very clear, hence many question and answers were exchanged during the reviews. \n", "reviews": [{"review_id": "ryxnHhRqFm-0", "review_text": "The paper presents a new model for reading and writing memory in the context of task-oriented dialogue. The model contains three main components: an encoder, a decoder, and an external KB. The external KB is in the format of an SVO triple store. The encoder encodes the dialogue history and, in doing so, writes its hidden states to memory and generates a \"global memory pointer\" as its last hidden state. The decoder takes as input the global memory pointer, the encoded dialogue state history, and the external KB and then generates a response using a two-step process in which it 1) generates a template response using tags to designate slots that need filling and 2) looks up the correct filler for each slot using the template+global memory pointer as a query. The authors evaluate the model on a simulated dialogue dataset (bAbI) and on a human-human dataset (Stanford Multi-domain Dialogue or SMD) as well as in a human eval. They show substantial improvements over existing models on SMD (the more interesting of the datasets) in terms of entity F1--i.e. the number of correctly-generated entities in the response. They also show improvement on bAbI specifically on cases involving OOVs. On the human evaluation, they show improvements in terms of both \"appropriateness\" and \"human-likeness\". Overall, I think this is a nice and well-motivated model. I very much appreciate the thoroughness of the evaluation (two different datasets, plus a human evaluation). The level of analysis of the model was also good, although there (inevitably) could have been more. Since it is such a complex model, I would have liked to see more thorough ablations or at least better descriptions of the baselines, in order to better understand which specific pieces of the model yield which types of gains. A few particular questions below: - You describe the auxiliary loss on the global pointer, and mention an ablation study that show that this improves performance. Maybe I am overlooking something, but I cannot find this ablation in the paper or appendix. It would be nice to see how large the effect is. - Following on the above, why no similar auxiliary losses on additional components, e.g. the template generation? Were these tried and deemed unnecessary or vice-versa (i.e. the default was no auxiliary loss and they were only added when needed)? Either way, it would be nice to better communicate the experiments/intuitions that motivated the particular architecture you arrived at. - I really appreciate that you run a human eval. But why not have humans evaluate objective \"correctness\" as well? It seems trivial to ask people to say whether or not the answer is correct/communicates the same information as the gold. ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review and feedback . The question which you mentioned , the replies are as followed : 1 . You describe the auxiliary loss on the global pointer , and mention an ablation study that show that this improves performance . Maybe I am overlooking something , but I can not find this ablation in the paper or appendix . It would be nice to see how large the effect is . Reply : The ablation study of our global memory pointer G is in Table 4 , the GLMP w/o G. For SMD dataset , without G gave us around 8.3 % additional loss . 2.Following on the above , why no similar auxiliary losses on additional components , e.g.the template generation ? Were these tried and deemed unnecessary or vice-versa ( i.e.the default was no auxiliary loss and they were only added when needed ) ? Reply : Our model has three loss functions , Loss_g for global memory pointer , Loss_v for sketch response generation and Loss_l for local memory pointer . The template generation loss you mentioned is included as Loss_v , which is a standard cross-entropy loss . 3.I really appreciate that you run a human eval . But why not have humans evaluate objective `` correctness '' as well ? Reply : In our evaluation setting , we combine the correctness and the appropriateness , as the criteria we mentioned in the appendix A.3 ."}, {"review_id": "ryxnHhRqFm-1", "review_text": "This is, in general, a well-written paper with extensive experimentation. The authors tried to describe their architecture both with equations as well as graphically. However, I would like to mention the following: In Section 2.1 I am not sure all the symbols are clearly defined. For example, I could not locate the definitions of n, l etc. Even if they are easy to assume, I am fond of appropriate definitions. Also, I suspect that some symbols, like n, are not used consistently across the manuscript. I am also confused about the loss function. Which loss function is used when? I am missing one more figure. From Fig 2 it's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time (i.e. not independently) In Section 2.3, it's not clear to me how the expected output word will be picked up from the local memory pointer. Same goes for the entity table. How can you guarantee that that position n+l+1 is a null token? What was the initial query vector and how did you initialise that? Did different initialisations had any effect on performance? If you can please provide an example of a memory position. Also, i would like to see a description of how the OOV tasks are handled. Finally, your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches, but with a traditional approach, such as pydial? And some minor suggestions: Not all the abbreviations are defined. For example QRN, GMN, KVR. It would also be nice to have the references of the respective methods included in the Tables or their captions. Parts of Figs. 1&2 are pixelised. It would be nice to have everything vectorised. I would prefer to see the training details (in fact, I would even be favorable of having more of those) in the main body of the manuscript, rather than in the appendix. There are some minor typos, such as \"our approach that utilizing the recurrent\" or \"in each datasets\"", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review and feedback . The question which you mentioned , the replies are as followed : 1 . In Section 2.1 I am not sure all the symbols are clearly defined . Reply : We will make the definitions more appropriate and consistent . 2.I am also confused about the loss function . Which loss function is used when ? Reply : Our model has three loss functions : Loss_g for global memory pointer , Loss_v for sketch response generation and Loss_l for local memory pointer . During training , they are summed and optimized simultaneously . 3.I am missing one more figure . From Fig 2 it 's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time ( i.e.not independently ) Reply : As shown in the block diagram Fig 1 ( a ) , first , the global memory encoder encodes dialogue history and writes its hidden states into the external knowledge . Then the last hidden state is used to read the external knowledge and generate the global memory pointer at the same time . Later during the decoding stage , the local memory decoder generates sketch responses . Then the global memory pointer and the sketch RNN hidden state are passed to the external knowledge , which returns the local memory pointer that can copy plain text to replace the sketch tags and obtain the final system response . 4.In Section 2.3 , it 's not clear to me how the expected output word will be picked up from the local memory pointer . Same goes for the entity table . Reply : Sorry that we did not make it clear . As the visualization in Fig 3 , the right column is the local memory pointers for time step 0 to 3 . For example , in step 3 , when our sketch RNN generated tags such as \u201c @ address \u201d , the word will be picked out from the learned local memory pointer , which points to the memory node \u201c [ 783_arcadia_pl ] address chevron \u201d . Therefore , we took the Object word \u201c 783_arcadia_pl \u201d out as the real address . Otherwise , the output word is generated from the vocabulary 5 . How can you guarantee that that position n+l+1 is a null token ? Reply : We manually assign token of \u201c n+l+1 \u201d position to be \u201c NULL \u201d during preprocessing . 6.What was the initial query vector and how did you initialise that ? Did different initialisations had any effect on performance ? Reply : The query vector is the vector to query the external knowledge . In the encoder , the query vector is the last hidden state of context RNN . In the decoder , the query vectors are the hidden states of the sketch RNN . 7.If you can please provide an example of a memory position . Reply : The example of memory position is shown in the left part of Fig 3 , as you can see , our external knowledge includes the kB and the dialogue history . 8.Also , i would like to see a description of how the OOV tasks are handled . Reply : Sorry that we did not make it clear . In Sec 2.2 , we explain that our model can mitigate the OOV problem is because we use the context RNN hidden states as the global contextual representation , and feed into the external knowledge . Therefore , the embedding of each token includes its RNN hidden state , including embeddings of OOV tokens . 9.Finally , your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches , but with a traditional approach , such as pydial ? Reply : We mainly followed previous works to compare end-to-end models without human feature engineer efforts . In Table 3 , results of the rule-based system from the Eric et al. , 2017 are reported , we can observe the improvement over the traditional pipeline solution on the SMD human-human dialogue dataset ."}, {"review_id": "ryxnHhRqFm-2", "review_text": "This paper puts forward a new global+local memory pointer network to tackle task-oriented dialogue problem. The idea of introducing global memory is novel and experimental results show its effectiveness to encode external knowledge in most cases. Here're some comments: 1. In global memory pointer, the users employ non-normalized probability (non-softmax). What is the difference in performance if one uses softmax? 2. In (11), there's no linear weights. Will higher weights in global/local help? 3. As pointed out in ablation study, it's weird that in task5 global memory pointer does not help. 4. The main competitor of this algorithm is mem2seq. While mem2seq includes DSTC2 and In-car Assistant, and especially in-car assistant provides the first example dialogue, why does the paper not include expeirments on these two datasets?", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and feedback . The question which you mentioned , the replies are as followed : 1 . In global memory pointer , the users employ non-normalized probability ( non-softmax ) . What is the difference in performance if one uses softmax ? Reply : Sorry that we did not make it clear . We treat the training of global memory pointer as a multi-label learning problem , instead of a multi-class classification problem . For example , if the system generates a response like \u201c Starbucks is 4_miles away \u201d , both \u201c Starbucks \u201d and \u201c 4_miles \u201d are model \u2019 s outputs . 2.In ( 11 ) , there 's no linear weights . Will higher weights in global/local help ? Reply : In our experiments , we tried to add the linear weights in ( 11 ) as hyper-parameters , the results are similar . 3.As pointed out in ablation study , it 's weird that in task5 global memory pointer does not help . Reply : Note that our ablation study on bAbI dialogue is on its OOV setting , which could be considered as a zero-shot scenario . Therefore , we observe a performance tradeoff between the normal setting and the OOV setting , that is , if we increase the dropout ratio , the accuracy in normal setting may decrease and the accuracy in OOV setting may increase . Therefore , after we rerun the ablation study on task5 OOV with the same dropout rate , the performance difference between with and without global memory pointer is very little . We will include this explanation in the paper . 4.The main competitor of this algorithm is mem2seq.While mem2seq includes DSTC2 and In-car Assistant , and especially in-car assistant provides the first example dialogue , why does the paper not include expeirments on these two datasets ? Reply : Sorry that we did not make it clear . The \u201c SMD \u201d dataset in our experiment is exactly the same as the \u201c In-Car Assistant \u201d dataset in the Mem2Seq paper ( different naming ) , both came from the paper Eric et al , 2017 . Therefore , the results are comparable . Second , We did not include the DSTC2 in our paper is because it is a \u201c human-machine \u201d dataset which is originally designed as a DST task , not a response generation task . That dataset has many noisy system responses as well . We take one of the dialogues as an example , one can observe that the system responses are not properly collected . ... User : < SILENCE > System : the_lucky_star is a nice place in the south of town and the prices are cheap User : what else is there System : the_lucky_star is a great restaurant User : anything else System : The post code of the_lucky_star is the_lucky_star_post_code ..."}], "0": {"review_id": "ryxnHhRqFm-0", "review_text": "The paper presents a new model for reading and writing memory in the context of task-oriented dialogue. The model contains three main components: an encoder, a decoder, and an external KB. The external KB is in the format of an SVO triple store. The encoder encodes the dialogue history and, in doing so, writes its hidden states to memory and generates a \"global memory pointer\" as its last hidden state. The decoder takes as input the global memory pointer, the encoded dialogue state history, and the external KB and then generates a response using a two-step process in which it 1) generates a template response using tags to designate slots that need filling and 2) looks up the correct filler for each slot using the template+global memory pointer as a query. The authors evaluate the model on a simulated dialogue dataset (bAbI) and on a human-human dataset (Stanford Multi-domain Dialogue or SMD) as well as in a human eval. They show substantial improvements over existing models on SMD (the more interesting of the datasets) in terms of entity F1--i.e. the number of correctly-generated entities in the response. They also show improvement on bAbI specifically on cases involving OOVs. On the human evaluation, they show improvements in terms of both \"appropriateness\" and \"human-likeness\". Overall, I think this is a nice and well-motivated model. I very much appreciate the thoroughness of the evaluation (two different datasets, plus a human evaluation). The level of analysis of the model was also good, although there (inevitably) could have been more. Since it is such a complex model, I would have liked to see more thorough ablations or at least better descriptions of the baselines, in order to better understand which specific pieces of the model yield which types of gains. A few particular questions below: - You describe the auxiliary loss on the global pointer, and mention an ablation study that show that this improves performance. Maybe I am overlooking something, but I cannot find this ablation in the paper or appendix. It would be nice to see how large the effect is. - Following on the above, why no similar auxiliary losses on additional components, e.g. the template generation? Were these tried and deemed unnecessary or vice-versa (i.e. the default was no auxiliary loss and they were only added when needed)? Either way, it would be nice to better communicate the experiments/intuitions that motivated the particular architecture you arrived at. - I really appreciate that you run a human eval. But why not have humans evaluate objective \"correctness\" as well? It seems trivial to ask people to say whether or not the answer is correct/communicates the same information as the gold. ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review and feedback . The question which you mentioned , the replies are as followed : 1 . You describe the auxiliary loss on the global pointer , and mention an ablation study that show that this improves performance . Maybe I am overlooking something , but I can not find this ablation in the paper or appendix . It would be nice to see how large the effect is . Reply : The ablation study of our global memory pointer G is in Table 4 , the GLMP w/o G. For SMD dataset , without G gave us around 8.3 % additional loss . 2.Following on the above , why no similar auxiliary losses on additional components , e.g.the template generation ? Were these tried and deemed unnecessary or vice-versa ( i.e.the default was no auxiliary loss and they were only added when needed ) ? Reply : Our model has three loss functions , Loss_g for global memory pointer , Loss_v for sketch response generation and Loss_l for local memory pointer . The template generation loss you mentioned is included as Loss_v , which is a standard cross-entropy loss . 3.I really appreciate that you run a human eval . But why not have humans evaluate objective `` correctness '' as well ? Reply : In our evaluation setting , we combine the correctness and the appropriateness , as the criteria we mentioned in the appendix A.3 ."}, "1": {"review_id": "ryxnHhRqFm-1", "review_text": "This is, in general, a well-written paper with extensive experimentation. The authors tried to describe their architecture both with equations as well as graphically. However, I would like to mention the following: In Section 2.1 I am not sure all the symbols are clearly defined. For example, I could not locate the definitions of n, l etc. Even if they are easy to assume, I am fond of appropriate definitions. Also, I suspect that some symbols, like n, are not used consistently across the manuscript. I am also confused about the loss function. Which loss function is used when? I am missing one more figure. From Fig 2 it's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time (i.e. not independently) In Section 2.3, it's not clear to me how the expected output word will be picked up from the local memory pointer. Same goes for the entity table. How can you guarantee that that position n+l+1 is a null token? What was the initial query vector and how did you initialise that? Did different initialisations had any effect on performance? If you can please provide an example of a memory position. Also, i would like to see a description of how the OOV tasks are handled. Finally, your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches, but with a traditional approach, such as pydial? And some minor suggestions: Not all the abbreviations are defined. For example QRN, GMN, KVR. It would also be nice to have the references of the respective methods included in the Tables or their captions. Parts of Figs. 1&2 are pixelised. It would be nice to have everything vectorised. I would prefer to see the training details (in fact, I would even be favorable of having more of those) in the main body of the manuscript, rather than in the appendix. There are some minor typos, such as \"our approach that utilizing the recurrent\" or \"in each datasets\"", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review and feedback . The question which you mentioned , the replies are as followed : 1 . In Section 2.1 I am not sure all the symbols are clearly defined . Reply : We will make the definitions more appropriate and consistent . 2.I am also confused about the loss function . Which loss function is used when ? Reply : Our model has three loss functions : Loss_g for global memory pointer , Loss_v for sketch response generation and Loss_l for local memory pointer . During training , they are summed and optimized simultaneously . 3.I am missing one more figure . From Fig 2 it 's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time ( i.e.not independently ) Reply : As shown in the block diagram Fig 1 ( a ) , first , the global memory encoder encodes dialogue history and writes its hidden states into the external knowledge . Then the last hidden state is used to read the external knowledge and generate the global memory pointer at the same time . Later during the decoding stage , the local memory decoder generates sketch responses . Then the global memory pointer and the sketch RNN hidden state are passed to the external knowledge , which returns the local memory pointer that can copy plain text to replace the sketch tags and obtain the final system response . 4.In Section 2.3 , it 's not clear to me how the expected output word will be picked up from the local memory pointer . Same goes for the entity table . Reply : Sorry that we did not make it clear . As the visualization in Fig 3 , the right column is the local memory pointers for time step 0 to 3 . For example , in step 3 , when our sketch RNN generated tags such as \u201c @ address \u201d , the word will be picked out from the learned local memory pointer , which points to the memory node \u201c [ 783_arcadia_pl ] address chevron \u201d . Therefore , we took the Object word \u201c 783_arcadia_pl \u201d out as the real address . Otherwise , the output word is generated from the vocabulary 5 . How can you guarantee that that position n+l+1 is a null token ? Reply : We manually assign token of \u201c n+l+1 \u201d position to be \u201c NULL \u201d during preprocessing . 6.What was the initial query vector and how did you initialise that ? Did different initialisations had any effect on performance ? Reply : The query vector is the vector to query the external knowledge . In the encoder , the query vector is the last hidden state of context RNN . In the decoder , the query vectors are the hidden states of the sketch RNN . 7.If you can please provide an example of a memory position . Reply : The example of memory position is shown in the left part of Fig 3 , as you can see , our external knowledge includes the kB and the dialogue history . 8.Also , i would like to see a description of how the OOV tasks are handled . Reply : Sorry that we did not make it clear . In Sec 2.2 , we explain that our model can mitigate the OOV problem is because we use the context RNN hidden states as the global contextual representation , and feed into the external knowledge . Therefore , the embedding of each token includes its RNN hidden state , including embeddings of OOV tokens . 9.Finally , your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches , but with a traditional approach , such as pydial ? Reply : We mainly followed previous works to compare end-to-end models without human feature engineer efforts . In Table 3 , results of the rule-based system from the Eric et al. , 2017 are reported , we can observe the improvement over the traditional pipeline solution on the SMD human-human dialogue dataset ."}, "2": {"review_id": "ryxnHhRqFm-2", "review_text": "This paper puts forward a new global+local memory pointer network to tackle task-oriented dialogue problem. The idea of introducing global memory is novel and experimental results show its effectiveness to encode external knowledge in most cases. Here're some comments: 1. In global memory pointer, the users employ non-normalized probability (non-softmax). What is the difference in performance if one uses softmax? 2. In (11), there's no linear weights. Will higher weights in global/local help? 3. As pointed out in ablation study, it's weird that in task5 global memory pointer does not help. 4. The main competitor of this algorithm is mem2seq. While mem2seq includes DSTC2 and In-car Assistant, and especially in-car assistant provides the first example dialogue, why does the paper not include expeirments on these two datasets?", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and feedback . The question which you mentioned , the replies are as followed : 1 . In global memory pointer , the users employ non-normalized probability ( non-softmax ) . What is the difference in performance if one uses softmax ? Reply : Sorry that we did not make it clear . We treat the training of global memory pointer as a multi-label learning problem , instead of a multi-class classification problem . For example , if the system generates a response like \u201c Starbucks is 4_miles away \u201d , both \u201c Starbucks \u201d and \u201c 4_miles \u201d are model \u2019 s outputs . 2.In ( 11 ) , there 's no linear weights . Will higher weights in global/local help ? Reply : In our experiments , we tried to add the linear weights in ( 11 ) as hyper-parameters , the results are similar . 3.As pointed out in ablation study , it 's weird that in task5 global memory pointer does not help . Reply : Note that our ablation study on bAbI dialogue is on its OOV setting , which could be considered as a zero-shot scenario . Therefore , we observe a performance tradeoff between the normal setting and the OOV setting , that is , if we increase the dropout ratio , the accuracy in normal setting may decrease and the accuracy in OOV setting may increase . Therefore , after we rerun the ablation study on task5 OOV with the same dropout rate , the performance difference between with and without global memory pointer is very little . We will include this explanation in the paper . 4.The main competitor of this algorithm is mem2seq.While mem2seq includes DSTC2 and In-car Assistant , and especially in-car assistant provides the first example dialogue , why does the paper not include expeirments on these two datasets ? Reply : Sorry that we did not make it clear . The \u201c SMD \u201d dataset in our experiment is exactly the same as the \u201c In-Car Assistant \u201d dataset in the Mem2Seq paper ( different naming ) , both came from the paper Eric et al , 2017 . Therefore , the results are comparable . Second , We did not include the DSTC2 in our paper is because it is a \u201c human-machine \u201d dataset which is originally designed as a DST task , not a response generation task . That dataset has many noisy system responses as well . We take one of the dialogues as an example , one can observe that the system responses are not properly collected . ... User : < SILENCE > System : the_lucky_star is a nice place in the south of town and the prices are cheap User : what else is there System : the_lucky_star is a great restaurant User : anything else System : The post code of the_lucky_star is the_lucky_star_post_code ..."}}