{"year": "2020", "forum": "BygXFkSYDH", "title": "Target-Embedding Autoencoders for Supervised Representation Learning", "decision": "Accept (Talk)", "meta_review": "The paper presents a general view of supervised learning models that are jointly trained with a model for embedding the labels (targets), which the authors dub target-embedding autoencoders (TEAs).  Similar models have been studied before, but this paper unifies the idea and studies more carefully various components of it.  It provides a proof for the specific case of linear models and a set of experiments on disease trajectory prediction tasks.  The reviewer concerns were addressed well by the authors and I believe the paper is now strong.  It would be even stronger if it included more tasks (and in particular some \"typical\" tasks that more of the community is focusing on), and the theoretical part is to my mind not a major contribution, or at least not as large as the paper implies, because it analyzes a much simpler model than anyone is likely to use TEAs for.", "reviews": [{"review_id": "BygXFkSYDH-0", "review_text": "This work introduces the idea of target embedding autoencoders for supervised prediction, designed to learn intermediate latent representations jointly optimized to be both predictable from features and predictive of targets. This is meant to help with generalization and has certain theoretical guarantees. It is an interesting problem setting to consider where Y is high dimensional instead of X. More examples of this would be useful to provide in the intro. I think this is crucial to understand where this method might be useful. Figure 1 is super informative and very nice! Section 2: Why do we expect that this paradigm of autoencoder based regularization \u201cgeneralizes\u201d better? I like the explicit and honest discussion of prior work in this section. One question is how important is the choice of reconstruction loss function - L2, vs max likelihood gaussian, vs L1, vs cross entropy, etc for performance? Another question: how bad is performance if the learning is done stagewise - first the Y-Z-Y^ representation is learned and then the X->Z predictor is learned. If something is out of distribution, how easy are TEA based learners to finetune? Overall the idea seems reasonable - if the targets have some common set of factors, just predict those instead of predicting the full target value which might be harder to get right. It\u2019s just a question of whether this holds true in many domains and how well this reconstruction loss generalizes across problems? Section 3: \u201cWe havenoted that TEA components can in principle be instantiated by any architecture. Does its benefit extend beyond the commonly-studied domain of static classification?\u201d -> not clear what this means? Does this mean this algorithm has been proposed before or is it that it can ALSO work on non static classification tasks? Not clear how to situate this claim The theoretical section seems to follow largely from Le et al, but with important distinctions on dimensionalities of various spaces involved. I wonder if the authors can comment on how often Assumption 1 and 2 are actually satisified? Related Work: Is the main difference between Yu 2014 and this just in the norm based regularization? I don\u2019t think so, can this be made more clear. This seems also fairly related to Yeh, is it just a generalization of that paradigm? Or is there more to it? In light of the contribution of Yeh, this seems like slightly more marginal of a contribution? Is the main points of contribution the theoretical analysis and the extended experiments to sequence data rather than static classification? The results do seem to show a signficant benefit as compared to FEA or base models. It also seems like this is applicable across multiple disease datasets. Do the authors think that this could be applicable to other domains altogether? Would it be quick to run a comparison on these? Generally seems like a well grounded and meaningful contribution with many improvements. Would be curious to see applications to other datasets and also some improvements/clarifications noted above? ", "rating": "8: Accept", "reply_text": "Thank you for your insightful comments and questions . We give answers to each in turn . We believe the specific positioning and contribution of the paper may not have been the most clear . Therefore we start by emphasizing the focus of our work , in light of some of the questions . ( 1 ) First , we motivate and formalize TEA as a * general * framework , which `` provide [ s ] a unifying perspective on recent applications of autoencoders to label-embedding '' in disparate domains ( p. 1 ) . ( 2 ) This sets the stage for our theoretical contribution , which is to provide a * guarantee of generalization * for linear TEAs by demonstrating uniform stability . This allows us to distill its benefit in the simplest setting , removing any confounding factors from domain-specific architectures . ( 3 ) Our empirical novelty ( in addition to verifying our claim for the linear case ) is to extend validation of this approach to the * temporal * domain -- -for multi-variate sequence forecasting with recurrent architectures . While we make the point that certain prior works can be interpreted as specific instantiations of TEAs in the * static * setting , we are the first to do so in the recurrent , sequential setting and for both regression and classification -- -underscoring the further generality of this approach beyond feedforward instantiations . * * * Section 1 * * * ( 1.1 ) More examples in the introduction : We agree that more immediate examples of high-dimensional output would be useful . We will explicitly include ( in para.2 ) examples from the related work that we cite , including 3D voxel prediction [ Girdhar , ECCV 2016 ] , image segmentation [ Oktay , T-MI 2018 ] , as well as any kind of object annotation such as images , text , and music [ Table 7 ] . ( Note that for the latter , the vast majority of work takes data with bag-of-features vectors as input , although in principle this need not be the case , e.g.with more complicated underlying models ) . This is in addition to the ( already mentioned ) temporal setting of multi-variate sequence trajectory forecasting that we focus on as our empirical contribution . * * * Section 2 * * * ( 2.1 ) Why do we expect autoencoding to help generalization : In the case of FEAs , the intuition is that what is reconstructive of features is likely to encode what is discriminative ( downstream ) . Specifically , [ Le , NIPS 2018 ] quantifies the generalization benefit for the linear case , capturing the intuition that reconstruction is `` more likely to prefer a more robust model amongst a set of similarly effective models '' . In the case of TEAs , the intuition is similar but entirely opposite -- -that what is reconstructive of targets is likely to encode what is predictable ( upstream ) . Here , the inverted setting warrants moving the cross-representability assumption into latent space , and we analogously quantify the generalization benefit ( Section 3 ) . ( 2.2 ) Importance of choice of reconstruction loss : As noted in Theorem 1 ( Section 3 ) , the bound is obtained if the reconstruction loss is strongly convex . The ( most commonly used ) quadratic loss function is 2-strongly convex . The logistic loss function and hinge loss function are convex , but not strongly convex . However , as noted in [ Liu , TPAMI 2016 ] , in statistical learning theory we often assume that $ h ( x ) \\in [ -U , U ] $ for hypothesis $ h $ and some positive constant $ U $ , in which case the loss functions may be strongly convex ( e.g.the logistic loss function is then $ exp ( -U ) /4 $ -strongly convex ) . In our experiments , the datasets are chosen to obtain a variety of binary , continuous , and mixed-target settings , and we empirically observe the benefit of TEAs in all cases . We agree that future research may empirically explore the effect of a wide variety of reconstruction losses -- -both convex and otherwise . ( 2.3 ) How bad is performance if learning is done stagewise : This is a very relevant question , considering the importance of joint training to obtaining uniform stability . We actually examined this as part of our source-of-gains analysis ( Section 5 ) . For every setting of our experiments , we performed the `` No Joint '' setting ( i.e.only first two stages of Algorithm 1 are performed like you mentioned , skipping the joint training stage ) , as well as the `` No Staged '' setting ( i.e.only the final joint training stage is performed , skipping the ( pre ) -training stages ) . In all cases , both linear and nonlinear ( Tables 4-5 , and more detail in Appendix E ) , we observe that both sources of benefit are important for performance : neither setting performs quite as well as when both are combined ( p. 8 ) . In other words , training stagewise is still better than having no target-autoencoding at all , but not as good as when combined with joint-training . ( Finally , as expected the `` Neither '' setting -- -equivalent to vanilla prediction -- -performs the worst ) ."}, {"review_id": "BygXFkSYDH-1", "review_text": "This paper examines target-embedding autoencoders (TEAs) in theory and practice. TEAs autoencode the output (rather than input) space and find a mapping from the input to the latent representation of the output. The forward pass of the decoder (for the output space) is shared by the input-to-output computation. Target-embedding autoencoders (TEAs) have previously been proposed and used in practice (though not necessarily by the \"TEA\" name). The paper's presentation is confusing on this matter, at it claims to be the first to \"motivate and formalize\" TEAs; I do not believe it is appropriate to claim such a contribution in light of prior work. [Girdhar et al.] clearly utilizes a target-embedding autoencoder (see [Girdhar et al.] Figure 2). In addition, more recent published work clearly utilizes TEAs (though not named as such) as the centerpiece of their approaches. See, for example: [A] Adrian V. Dalca, John Guttag, Mert R. Sabuncu. Anatomical Priors in Convolutional Networks for Unsupervised Biomedical Segmentation. CVPR, 2018. [B] Mohammadreza Mostajabi, Michael Maire, Gregory Shakhnarovich. Regularizing Deep Networks by Modeling and Predicting Label Structure. CVPR, 2018. Figure 2 of [A] and Figure 1 of [B] both clearly depict applying target-embedding autoencoders on semantic image segmentation problems. [B] operates in the same supervised representation-learning setting proposed here. Notably, [B] utilizes staged training -- learning the autoencoder first -- as discussed in Section 2 of the submitted paper, and finds that to be important for achieving a regularization effect. The real applications explored by [A] and [B] are perhaps more challenging than the datasets used in experiments here. The concluding sentence of the paper,\"Target-representation learning is potentially applicable to any high-dimensional prediction task, and exploring its utility for specific domain-architectures may be a practical direction for future research\" should be changed -- prior work has already successfully utilized TEAs in the specific domain of image segmentation. Given that the paper has missed (not cited) highly related published work that applies TEAs in practice, a rewrite of Section 4 is required. In the appendix, Table 6, Table 7 and Section B.1 also need significant updates. The proposed approach is no longer a unique entry in Table 6 or 7 -- e.g. [B] already contributed \"autoencoder component as regularization for learning predictor\" (Table 7). Additionally, toy experiments in Section 5 appear less significant a contribution when multiple full-scale systems already employ TEAs. This paper's theoretical analysis does appear to set it apart from prior work. However, theorems are developed for an extremely limited context (linear TEAs) and it is unclear whether or how they might extend to practical use cases (i.e. TEAs that are nonlinear, deep neural networks). --- The extensive author response and updated paper address many of my original concerns. I have updated my overall rating.", "rating": "6: Weak Accept", "reply_text": "Thank you for your thoughtful comments , and for referring to further papers applying target-embedding to image segmentation . Mainly , you point out that ( 1 ) target-embedding has previously been proposed and used in practice . In addition , you mention that ( 2 ) the theory developed is limited in practice due to the linear setting for analysis , and that ( 3 ) the experiments are `` toy '' , considering that imaging applications are `` more challenging '' . We address each in turn . We believe the specific positioning and contribution of the paper may not have been the most clear . Therefore we start by emphasizing our focus , in light of your comments . ( 1 ) First , we motivate and formalize TEA as a * general * framework , which `` provide [ s ] a unifying perspective on recent applications of autoencoders to label-embedding '' in disparate domains ( p. 1 ) . ( 2 ) This sets the stage for our theoretical contribution , which is to provide a * guarantee of generalization * for linear TEAs by demonstrating uniform stability . This allows us to distill its benefit in the simplest setting , removing any confounding factors from domain-specific architectures . ( 3 ) Our empirical novelty ( in addition to verifying our claim for the linear case ) is to extend validation of this approach to the * temporal * domain -- -for multi-variate sequence forecasting with recurrent architectures . While we make the point that certain prior works can be interpreted as specific instantiations of TEAs in the * static * setting , we are the first to do so in the recurrent , sequential setting and for both regression and classification -- -underscoring the further generality of this approach beyond feedforward instantiations ."}, {"review_id": "BygXFkSYDH-2", "review_text": "1. Summary: In this paper, the authors proposed a Target-Embedding Autoendocer (TEA) model for supervised representation learning. Different from the traditional feature embedding autoencoder model, TEA tries to learn a compact latent representation that can reconstruct the target vector. Hypothetically, this model should be especially useful when the target vector has a much higher dimension than the feature vector. The authors analyzed the proved some characteristics of this framework and conducted empirical experiments on three datasets to prove its effectiveness. 2. Overall assessment: The motivation of this paper is well justified. It's easy to follow and fun to read, even for a person who is not an expert in this area, like me. However, there still exist some problems in this paper. It needs more improvement to get published in a competitive conference like ICLR. 3. Comments: 3.1 Datasets used in this paper cannot fully prove the effectiveness of this framework. These datasets are all from very similar domains. The dimension of target vectors is comparable to that of feature vectors. In my view, it's necessary to test on more different types of datasets to prove the usefulness of a model, especially if it is a general framework like TEA. 3.2 Models used in this paper are relatively simple. Demonstrate the performance of TEA on more advanced models and more difficult tasks can deliver more insights to the community. 3.3 No state-of-the-art models are used in experiments. It's very likely that some existing work has already adopted the idea of target embedding. There also exist much other work on dealing with high dimensional target vector problem. How are the performances of these models? What is the advantage of the proposed framework over these existing work? 3.4 The source of gain part on page 8 should contain more explanations and analysis. This part is one of the most important parts of this paper. It can provide quite valuable insights to readers. I hope the author can expand it. 3.5 More details about training and inference are needed. The authors only use a few sentences to describe their three staged training process. I still have some questions left after reading it, such as how do you train the shared parts in TEA? Do you update its parameters in all stages? What the effect of the order of training? What will happen if I change it?", "rating": "6: Weak Accept", "reply_text": "Thank you for your thoughtful comments . We give answers to each in turn . We believe the specific positioning and contribution of the paper may not have been the most clear . Therefore we start by emphasizing our focus , in light of your comments . ( 1 ) First , we motivate and formalize TEA as a * general * framework , which `` provide [ s ] a unifying perspective on recent applications of autoencoders to label-embedding '' in disparate domains ( p. 1 ) . ( 2 ) This sets the stage for our theoretical contribution , which is to provide a * guarantee of generalization * for linear TEAs by demonstrating uniform stability . This allows us to distill its benefit in the simplest setting , removing any confounding factors from domain-specific architectures . ( 3 ) Our empirical novelty ( in addition to verifying our claim for the linear case ) is to extend validation of this approach to the * temporal * domain -- -for multi-variate sequence forecasting with recurrent architectures . While we make the point that certain prior works can be interpreted as specific instantiations of TEAs in the * static * setting , we are the first to do so in the recurrent , sequential setting and for both regression and classification -- -underscoring the further generality of this approach beyond feedforward instantiations . ( 3.1 ) `` Datasets [ ... ] can not prove the effectiveness of this framework '' : We wish to kindly point out that it is actually * not * our objective to prove the effectiveness of this framework * from scratch * . The fact that this general idea works well in a number of ( static ) settings is already known ( and we cite and mention them throughout the paper ) . In fact , the empirical efficacy of existing domain applications is precisely what motivates our main theoretical contribution : To `` provide a unified perspective on recent applications '' ( p. 1 ) of this idea , which allows us to first focus on examining * why * it works ( our theoretical contribution ) . As noted throughout the paper ( p. 5 , 6 , and 8 ) , the application work of e.g . [ Girdhar , ECCV 2016 ] and [ Yeh , AAAI 2017 ] can be interpreted as specific instantiations of TEAs in the * static * setting -- -the latter in the ( 1 ) multi-label classification setting ( with additional refinements ) , and the former specifically for ( 2 ) voxel prediction with convolutional architectures ( under the `` indirect '' variant ) . ( 3 ) Moreover , the various works on label-space reduction [ Table 7 ] can loosely be considered under the umbrella of target-space embedding , as is ( 4 ) the work of [ Oktay , T-MI 2018 ] for image segmentation . In that sense , while we unify the essential common thread between these disparate applications under the concept of TEA ( Sections 1-2 ) , there is already empirical evidence of the benefit of target-embedding in the commonly considered static setting . Now , what has * not * been empirically explored at all is the utility of target-embedding in the * temporal * setting -- -for multivariate sequence data , especially via recurrent architectures and for both regression and classification . We are the first to do this , and we find that TEAs generously extend to this setting . This is our empirical contribution ( in addition to verifying our claims for the linear case , plus extensive sensitivities ) . Furthermore , the domain of disease trajectories was specifically and carefully selected as a particularly appropriate testbed , due to the fact that medical knowledge in this domain gives us confidence that the requisite prior for TEAs is satisfied -- -i.e.that variations in targets are driven by a lower-dimensional set of underlying factors ( p. 1 , 3 , and 5 ) ; see scientific papers cited ( p. 6 ) . These points are all explained ( with more detail ) in the beginning of Section 5 ( pp.6-7 ) , as well as a negative example to highlight the importance of the prior ( Appendix E.4 ) ."}, {"review_id": "BygXFkSYDH-3", "review_text": "This is an extremely well-written and well-motivated paper. The idea of target-embedding autoencoders is extremely relevant for problems where the dimension of the label space is as large (or larger) than the dimension of the input features. The experiments are thorough, the theoretical guarantees are extremely well thought of and derived. The applications to modelling the progression of cystic fibrosis and Alzheimer's are extremely useful and timely. I vote for a strong accept for this paper. I would like to see some references to the extreme multi-label classification problems (http://manikvarma.org/downloads/XC/XMLRepository.html) and some of the other probabilistic approaches attempted in this domain (please see https://papers.nips.cc/paper/5770-large-scale-bayesian-multi-label-learning-via-topic-based-label-embeddings and the references and citations). ", "rating": "8: Accept", "reply_text": "Thank you for your thoughtful comments and suggestions . We agree that the field of * extreme * multi-label classification [ 3 ] is relevant as well , especially in the context of our discussion for Table 7 . We also agree that the probabilistic methods in [ 1 ] and [ 2 ] present alternative approaches with advantages in performance and use cases ; they will provide more context in the related work discussion . Finally , we also find [ 4 ] worth referencing in light of the setting for our experiments . We thank you for pointing out these works : we will reference [ 1 ] , [ 2 ] , [ 3 ] , and [ 4 ] in our discussion of related work . [ 1 ] Piyush Rai , Changwei Hu , Ricardo Henao , and Lawrence Carin . Large-Scale Bayesian Multi-Label Learning via Topic-Based Label Embeddings . In NIPS , 2015 . [ 2 ] Ashish Kapoor , Raajay Viswanathan , and Prateek Jain . Multilabel Classification using Bayesian Compressed Sensing . In NIPS , 2012 . [ 3 ] Kush Bhatia , Himanshu Jain , Purushottam Kar , Manik Varma , and Prateek Jain . Sparse Local Embeddings for Extreme Multi-label Classification . In NIPS 2015 . [ 4 ] Yan Yan , Glenn Fung , Jennifer G. Dy , and Romer Rosales . Medical coding classification by leveraging inter-code relationships . In KDD 2010 ."}], "0": {"review_id": "BygXFkSYDH-0", "review_text": "This work introduces the idea of target embedding autoencoders for supervised prediction, designed to learn intermediate latent representations jointly optimized to be both predictable from features and predictive of targets. This is meant to help with generalization and has certain theoretical guarantees. It is an interesting problem setting to consider where Y is high dimensional instead of X. More examples of this would be useful to provide in the intro. I think this is crucial to understand where this method might be useful. Figure 1 is super informative and very nice! Section 2: Why do we expect that this paradigm of autoencoder based regularization \u201cgeneralizes\u201d better? I like the explicit and honest discussion of prior work in this section. One question is how important is the choice of reconstruction loss function - L2, vs max likelihood gaussian, vs L1, vs cross entropy, etc for performance? Another question: how bad is performance if the learning is done stagewise - first the Y-Z-Y^ representation is learned and then the X->Z predictor is learned. If something is out of distribution, how easy are TEA based learners to finetune? Overall the idea seems reasonable - if the targets have some common set of factors, just predict those instead of predicting the full target value which might be harder to get right. It\u2019s just a question of whether this holds true in many domains and how well this reconstruction loss generalizes across problems? Section 3: \u201cWe havenoted that TEA components can in principle be instantiated by any architecture. Does its benefit extend beyond the commonly-studied domain of static classification?\u201d -> not clear what this means? Does this mean this algorithm has been proposed before or is it that it can ALSO work on non static classification tasks? Not clear how to situate this claim The theoretical section seems to follow largely from Le et al, but with important distinctions on dimensionalities of various spaces involved. I wonder if the authors can comment on how often Assumption 1 and 2 are actually satisified? Related Work: Is the main difference between Yu 2014 and this just in the norm based regularization? I don\u2019t think so, can this be made more clear. This seems also fairly related to Yeh, is it just a generalization of that paradigm? Or is there more to it? In light of the contribution of Yeh, this seems like slightly more marginal of a contribution? Is the main points of contribution the theoretical analysis and the extended experiments to sequence data rather than static classification? The results do seem to show a signficant benefit as compared to FEA or base models. It also seems like this is applicable across multiple disease datasets. Do the authors think that this could be applicable to other domains altogether? Would it be quick to run a comparison on these? Generally seems like a well grounded and meaningful contribution with many improvements. Would be curious to see applications to other datasets and also some improvements/clarifications noted above? ", "rating": "8: Accept", "reply_text": "Thank you for your insightful comments and questions . We give answers to each in turn . We believe the specific positioning and contribution of the paper may not have been the most clear . Therefore we start by emphasizing the focus of our work , in light of some of the questions . ( 1 ) First , we motivate and formalize TEA as a * general * framework , which `` provide [ s ] a unifying perspective on recent applications of autoencoders to label-embedding '' in disparate domains ( p. 1 ) . ( 2 ) This sets the stage for our theoretical contribution , which is to provide a * guarantee of generalization * for linear TEAs by demonstrating uniform stability . This allows us to distill its benefit in the simplest setting , removing any confounding factors from domain-specific architectures . ( 3 ) Our empirical novelty ( in addition to verifying our claim for the linear case ) is to extend validation of this approach to the * temporal * domain -- -for multi-variate sequence forecasting with recurrent architectures . While we make the point that certain prior works can be interpreted as specific instantiations of TEAs in the * static * setting , we are the first to do so in the recurrent , sequential setting and for both regression and classification -- -underscoring the further generality of this approach beyond feedforward instantiations . * * * Section 1 * * * ( 1.1 ) More examples in the introduction : We agree that more immediate examples of high-dimensional output would be useful . We will explicitly include ( in para.2 ) examples from the related work that we cite , including 3D voxel prediction [ Girdhar , ECCV 2016 ] , image segmentation [ Oktay , T-MI 2018 ] , as well as any kind of object annotation such as images , text , and music [ Table 7 ] . ( Note that for the latter , the vast majority of work takes data with bag-of-features vectors as input , although in principle this need not be the case , e.g.with more complicated underlying models ) . This is in addition to the ( already mentioned ) temporal setting of multi-variate sequence trajectory forecasting that we focus on as our empirical contribution . * * * Section 2 * * * ( 2.1 ) Why do we expect autoencoding to help generalization : In the case of FEAs , the intuition is that what is reconstructive of features is likely to encode what is discriminative ( downstream ) . Specifically , [ Le , NIPS 2018 ] quantifies the generalization benefit for the linear case , capturing the intuition that reconstruction is `` more likely to prefer a more robust model amongst a set of similarly effective models '' . In the case of TEAs , the intuition is similar but entirely opposite -- -that what is reconstructive of targets is likely to encode what is predictable ( upstream ) . Here , the inverted setting warrants moving the cross-representability assumption into latent space , and we analogously quantify the generalization benefit ( Section 3 ) . ( 2.2 ) Importance of choice of reconstruction loss : As noted in Theorem 1 ( Section 3 ) , the bound is obtained if the reconstruction loss is strongly convex . The ( most commonly used ) quadratic loss function is 2-strongly convex . The logistic loss function and hinge loss function are convex , but not strongly convex . However , as noted in [ Liu , TPAMI 2016 ] , in statistical learning theory we often assume that $ h ( x ) \\in [ -U , U ] $ for hypothesis $ h $ and some positive constant $ U $ , in which case the loss functions may be strongly convex ( e.g.the logistic loss function is then $ exp ( -U ) /4 $ -strongly convex ) . In our experiments , the datasets are chosen to obtain a variety of binary , continuous , and mixed-target settings , and we empirically observe the benefit of TEAs in all cases . We agree that future research may empirically explore the effect of a wide variety of reconstruction losses -- -both convex and otherwise . ( 2.3 ) How bad is performance if learning is done stagewise : This is a very relevant question , considering the importance of joint training to obtaining uniform stability . We actually examined this as part of our source-of-gains analysis ( Section 5 ) . For every setting of our experiments , we performed the `` No Joint '' setting ( i.e.only first two stages of Algorithm 1 are performed like you mentioned , skipping the joint training stage ) , as well as the `` No Staged '' setting ( i.e.only the final joint training stage is performed , skipping the ( pre ) -training stages ) . In all cases , both linear and nonlinear ( Tables 4-5 , and more detail in Appendix E ) , we observe that both sources of benefit are important for performance : neither setting performs quite as well as when both are combined ( p. 8 ) . In other words , training stagewise is still better than having no target-autoencoding at all , but not as good as when combined with joint-training . ( Finally , as expected the `` Neither '' setting -- -equivalent to vanilla prediction -- -performs the worst ) ."}, "1": {"review_id": "BygXFkSYDH-1", "review_text": "This paper examines target-embedding autoencoders (TEAs) in theory and practice. TEAs autoencode the output (rather than input) space and find a mapping from the input to the latent representation of the output. The forward pass of the decoder (for the output space) is shared by the input-to-output computation. Target-embedding autoencoders (TEAs) have previously been proposed and used in practice (though not necessarily by the \"TEA\" name). The paper's presentation is confusing on this matter, at it claims to be the first to \"motivate and formalize\" TEAs; I do not believe it is appropriate to claim such a contribution in light of prior work. [Girdhar et al.] clearly utilizes a target-embedding autoencoder (see [Girdhar et al.] Figure 2). In addition, more recent published work clearly utilizes TEAs (though not named as such) as the centerpiece of their approaches. See, for example: [A] Adrian V. Dalca, John Guttag, Mert R. Sabuncu. Anatomical Priors in Convolutional Networks for Unsupervised Biomedical Segmentation. CVPR, 2018. [B] Mohammadreza Mostajabi, Michael Maire, Gregory Shakhnarovich. Regularizing Deep Networks by Modeling and Predicting Label Structure. CVPR, 2018. Figure 2 of [A] and Figure 1 of [B] both clearly depict applying target-embedding autoencoders on semantic image segmentation problems. [B] operates in the same supervised representation-learning setting proposed here. Notably, [B] utilizes staged training -- learning the autoencoder first -- as discussed in Section 2 of the submitted paper, and finds that to be important for achieving a regularization effect. The real applications explored by [A] and [B] are perhaps more challenging than the datasets used in experiments here. The concluding sentence of the paper,\"Target-representation learning is potentially applicable to any high-dimensional prediction task, and exploring its utility for specific domain-architectures may be a practical direction for future research\" should be changed -- prior work has already successfully utilized TEAs in the specific domain of image segmentation. Given that the paper has missed (not cited) highly related published work that applies TEAs in practice, a rewrite of Section 4 is required. In the appendix, Table 6, Table 7 and Section B.1 also need significant updates. The proposed approach is no longer a unique entry in Table 6 or 7 -- e.g. [B] already contributed \"autoencoder component as regularization for learning predictor\" (Table 7). Additionally, toy experiments in Section 5 appear less significant a contribution when multiple full-scale systems already employ TEAs. This paper's theoretical analysis does appear to set it apart from prior work. However, theorems are developed for an extremely limited context (linear TEAs) and it is unclear whether or how they might extend to practical use cases (i.e. TEAs that are nonlinear, deep neural networks). --- The extensive author response and updated paper address many of my original concerns. I have updated my overall rating.", "rating": "6: Weak Accept", "reply_text": "Thank you for your thoughtful comments , and for referring to further papers applying target-embedding to image segmentation . Mainly , you point out that ( 1 ) target-embedding has previously been proposed and used in practice . In addition , you mention that ( 2 ) the theory developed is limited in practice due to the linear setting for analysis , and that ( 3 ) the experiments are `` toy '' , considering that imaging applications are `` more challenging '' . We address each in turn . We believe the specific positioning and contribution of the paper may not have been the most clear . Therefore we start by emphasizing our focus , in light of your comments . ( 1 ) First , we motivate and formalize TEA as a * general * framework , which `` provide [ s ] a unifying perspective on recent applications of autoencoders to label-embedding '' in disparate domains ( p. 1 ) . ( 2 ) This sets the stage for our theoretical contribution , which is to provide a * guarantee of generalization * for linear TEAs by demonstrating uniform stability . This allows us to distill its benefit in the simplest setting , removing any confounding factors from domain-specific architectures . ( 3 ) Our empirical novelty ( in addition to verifying our claim for the linear case ) is to extend validation of this approach to the * temporal * domain -- -for multi-variate sequence forecasting with recurrent architectures . While we make the point that certain prior works can be interpreted as specific instantiations of TEAs in the * static * setting , we are the first to do so in the recurrent , sequential setting and for both regression and classification -- -underscoring the further generality of this approach beyond feedforward instantiations ."}, "2": {"review_id": "BygXFkSYDH-2", "review_text": "1. Summary: In this paper, the authors proposed a Target-Embedding Autoendocer (TEA) model for supervised representation learning. Different from the traditional feature embedding autoencoder model, TEA tries to learn a compact latent representation that can reconstruct the target vector. Hypothetically, this model should be especially useful when the target vector has a much higher dimension than the feature vector. The authors analyzed the proved some characteristics of this framework and conducted empirical experiments on three datasets to prove its effectiveness. 2. Overall assessment: The motivation of this paper is well justified. It's easy to follow and fun to read, even for a person who is not an expert in this area, like me. However, there still exist some problems in this paper. It needs more improvement to get published in a competitive conference like ICLR. 3. Comments: 3.1 Datasets used in this paper cannot fully prove the effectiveness of this framework. These datasets are all from very similar domains. The dimension of target vectors is comparable to that of feature vectors. In my view, it's necessary to test on more different types of datasets to prove the usefulness of a model, especially if it is a general framework like TEA. 3.2 Models used in this paper are relatively simple. Demonstrate the performance of TEA on more advanced models and more difficult tasks can deliver more insights to the community. 3.3 No state-of-the-art models are used in experiments. It's very likely that some existing work has already adopted the idea of target embedding. There also exist much other work on dealing with high dimensional target vector problem. How are the performances of these models? What is the advantage of the proposed framework over these existing work? 3.4 The source of gain part on page 8 should contain more explanations and analysis. This part is one of the most important parts of this paper. It can provide quite valuable insights to readers. I hope the author can expand it. 3.5 More details about training and inference are needed. The authors only use a few sentences to describe their three staged training process. I still have some questions left after reading it, such as how do you train the shared parts in TEA? Do you update its parameters in all stages? What the effect of the order of training? What will happen if I change it?", "rating": "6: Weak Accept", "reply_text": "Thank you for your thoughtful comments . We give answers to each in turn . We believe the specific positioning and contribution of the paper may not have been the most clear . Therefore we start by emphasizing our focus , in light of your comments . ( 1 ) First , we motivate and formalize TEA as a * general * framework , which `` provide [ s ] a unifying perspective on recent applications of autoencoders to label-embedding '' in disparate domains ( p. 1 ) . ( 2 ) This sets the stage for our theoretical contribution , which is to provide a * guarantee of generalization * for linear TEAs by demonstrating uniform stability . This allows us to distill its benefit in the simplest setting , removing any confounding factors from domain-specific architectures . ( 3 ) Our empirical novelty ( in addition to verifying our claim for the linear case ) is to extend validation of this approach to the * temporal * domain -- -for multi-variate sequence forecasting with recurrent architectures . While we make the point that certain prior works can be interpreted as specific instantiations of TEAs in the * static * setting , we are the first to do so in the recurrent , sequential setting and for both regression and classification -- -underscoring the further generality of this approach beyond feedforward instantiations . ( 3.1 ) `` Datasets [ ... ] can not prove the effectiveness of this framework '' : We wish to kindly point out that it is actually * not * our objective to prove the effectiveness of this framework * from scratch * . The fact that this general idea works well in a number of ( static ) settings is already known ( and we cite and mention them throughout the paper ) . In fact , the empirical efficacy of existing domain applications is precisely what motivates our main theoretical contribution : To `` provide a unified perspective on recent applications '' ( p. 1 ) of this idea , which allows us to first focus on examining * why * it works ( our theoretical contribution ) . As noted throughout the paper ( p. 5 , 6 , and 8 ) , the application work of e.g . [ Girdhar , ECCV 2016 ] and [ Yeh , AAAI 2017 ] can be interpreted as specific instantiations of TEAs in the * static * setting -- -the latter in the ( 1 ) multi-label classification setting ( with additional refinements ) , and the former specifically for ( 2 ) voxel prediction with convolutional architectures ( under the `` indirect '' variant ) . ( 3 ) Moreover , the various works on label-space reduction [ Table 7 ] can loosely be considered under the umbrella of target-space embedding , as is ( 4 ) the work of [ Oktay , T-MI 2018 ] for image segmentation . In that sense , while we unify the essential common thread between these disparate applications under the concept of TEA ( Sections 1-2 ) , there is already empirical evidence of the benefit of target-embedding in the commonly considered static setting . Now , what has * not * been empirically explored at all is the utility of target-embedding in the * temporal * setting -- -for multivariate sequence data , especially via recurrent architectures and for both regression and classification . We are the first to do this , and we find that TEAs generously extend to this setting . This is our empirical contribution ( in addition to verifying our claims for the linear case , plus extensive sensitivities ) . Furthermore , the domain of disease trajectories was specifically and carefully selected as a particularly appropriate testbed , due to the fact that medical knowledge in this domain gives us confidence that the requisite prior for TEAs is satisfied -- -i.e.that variations in targets are driven by a lower-dimensional set of underlying factors ( p. 1 , 3 , and 5 ) ; see scientific papers cited ( p. 6 ) . These points are all explained ( with more detail ) in the beginning of Section 5 ( pp.6-7 ) , as well as a negative example to highlight the importance of the prior ( Appendix E.4 ) ."}, "3": {"review_id": "BygXFkSYDH-3", "review_text": "This is an extremely well-written and well-motivated paper. The idea of target-embedding autoencoders is extremely relevant for problems where the dimension of the label space is as large (or larger) than the dimension of the input features. The experiments are thorough, the theoretical guarantees are extremely well thought of and derived. The applications to modelling the progression of cystic fibrosis and Alzheimer's are extremely useful and timely. I vote for a strong accept for this paper. I would like to see some references to the extreme multi-label classification problems (http://manikvarma.org/downloads/XC/XMLRepository.html) and some of the other probabilistic approaches attempted in this domain (please see https://papers.nips.cc/paper/5770-large-scale-bayesian-multi-label-learning-via-topic-based-label-embeddings and the references and citations). ", "rating": "8: Accept", "reply_text": "Thank you for your thoughtful comments and suggestions . We agree that the field of * extreme * multi-label classification [ 3 ] is relevant as well , especially in the context of our discussion for Table 7 . We also agree that the probabilistic methods in [ 1 ] and [ 2 ] present alternative approaches with advantages in performance and use cases ; they will provide more context in the related work discussion . Finally , we also find [ 4 ] worth referencing in light of the setting for our experiments . We thank you for pointing out these works : we will reference [ 1 ] , [ 2 ] , [ 3 ] , and [ 4 ] in our discussion of related work . [ 1 ] Piyush Rai , Changwei Hu , Ricardo Henao , and Lawrence Carin . Large-Scale Bayesian Multi-Label Learning via Topic-Based Label Embeddings . In NIPS , 2015 . [ 2 ] Ashish Kapoor , Raajay Viswanathan , and Prateek Jain . Multilabel Classification using Bayesian Compressed Sensing . In NIPS , 2012 . [ 3 ] Kush Bhatia , Himanshu Jain , Purushottam Kar , Manik Varma , and Prateek Jain . Sparse Local Embeddings for Extreme Multi-label Classification . In NIPS 2015 . [ 4 ] Yan Yan , Glenn Fung , Jennifer G. Dy , and Romer Rosales . Medical coding classification by leveraging inter-code relationships . In KDD 2010 ."}}