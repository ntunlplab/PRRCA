{"year": "2021", "forum": "rYt0p0Um9r", "title": "Do Deeper Convolutional Networks Perform Better?", "decision": "Reject", "meta_review": "Reviewers appreciate the numerical results presented in this paper. However, the paper needs a more rigorous theoretical investigation of the empirical phenomenon, or a more comprehensive empirical exploration to pinpoint the key factors. I recommend the authors to incorporate the suggestions from the reviewers and submit the paper to the next top conference.", "reviews": [{"review_id": "rYt0p0Um9r-0", "review_text": "# # # Post-rebuttal update : I am raising my score from 4 to 5 , to recognize extensive updates to the paper experiments and numerous clarifications during the discussion , as well as to acknowledge that some of my initial concerns were not justified , e.g.asking for similar studies for MLPs ( which was effectively done in the original submission ) , or questioning whether the Frobenius norm in Figure 7 really goes down ( which was demonstrated better in the latest update ) . However , I can not give it a higher score / advocate for acceptance because I still find section 4 ( and follow-up discussion ) to be more misleading/confusing than helpful when it comes to explaining the observed phenomena . Precisely , even after the discussion , I still believe that 1 ) Experiments in Figure 7 should be done with circular-padded convolutions ( to rule out the more trivial explanation of the decreasing norm ) , and on small subsets of CIFAR10/Imagenet32 ( to establish whether low-norm is indeed associated with poor performance on image classification ) . 2 ) A precise definition of norm for nonlinear networks should be provided , and a link with the Frobenius norm of the linear networks should be established . I do n't understand what exactly `` the norm in the corresponding RKHS '' means , and how the reader was supposed to infer it from the text or our earlier discussion . Further , if possible , this norm should also be evaluated on the actual nonlinear networks , and compared to other notions of norms discussed in prior literature ( e.g.https : //arxiv.org/pdf/1706.08947.pdf ) , where lower norm is typically associated with better test accuracy . 3 ) A proper discussion about the non-monotonic dependence on depth in the context of provided intuition should be given . Current intuition can be interpreted as either predicting monotonic decrease in accuracy with depth ( learning solutions of lower and lower norms ) , or as predicting a sharp drop in accuracy at a certain depth ( point where the minimum-norm solution can be learned ) , but neither interpretation explains the hill-shaped dependence , which again makes me question whether this is indeed the right explanation . Without section 4 , the paper still has novel empirical results , but in my opinion they are neither surprising ( e.g.a hill-shaped dependence of accuracy is my default expectation of any NN hyper-parameter ) nor actionable ( there are no hints regarding what the peak depends on / how to guess it ) enough for publication at this time . A more rigorous investigation into explaining the phenomenon , or a more comprehensive empirical exploration to identify what does and what does n't influence the best depth , would make this a great paper at a later conference . Best , R4. # # # Original review : # # # # Paper Synopsis : The paper empirically studies the effect of depth on generalization in CNNs , and finds that , unlike in the case of width , generalization can decrease beyond a certain critical depth . The paper proposes an intuition for why this happens , by observing that in linear CNNs , the Frobenius norm of the trained network decreases with depth , and thus potentially converges to the minimum-norm solution , which corresponds to simple linear regression . By analogy and with some empirical evidence , the paper conjectures that CNNs converge to MLPs as they become deeper . # # # # Pros : Apart from certain aspects that I discuss below , the paper is clear and easy to read . I especially appreciate considering a variety of experimental settings ( different datasets , number of classes , vanilla-CNNs and ResNets ) , as well as toy examples . Code is provided , which is another strong point of the paper . The question asked in the title of the paper is interesting and worth investigating . # # # # Cons : My major concerns are : 1 . The main takeaway message appears either trivial , or at least miscommunicated . 2.Experimental evidence is unconvincing of [ the stronger , non-trivial interpretation of ] the key message of the paper and the proposed intuition . 3.The proposed intuition is not convincing theoretically . I am open to be persuaded otherwise in case if I misunderstood certain claims . Below are my specific thoughts on each of the points : 1 . What concretely is the claim of the paper ? Is it 1._ \u201c For each task , architecture , and training algorithm , there is a depth optimal for generalization ? \u201d _ If so , this is a truism . 2._ \u201c ... , in addition , beyond this optimal depth , generalization monotonically decreases ? \u201d _ This is not supported by Figures 12 . ( f , g ) , where it remains roughly flat or even goes up , while train accuracy and loss seem to have reached the optimum per Figures 12 . ( b , c ) , and 11 . ( a ) . 3._ \u201c among CNNs with 100 % training accuracy , the best depth for generalization is the smallest one \u201d _ ( per the main contribution # 3 , page 2 ) ? This is not supported by Figure 1 . ( b ) , 12 . ( e , f ) , where the best network is not the most shallow . 4._ \u201c The critical depth threshold is independent of certain parameters of the task/architecture/training algorithm \u201d _ ? Sadly , the paper does not answer this question , but admits this would be a good direction for future work ( I agree ) . As such , my takeaway from the paper is only that _ \u201c Double descent usually doesn \u2019 t happen through depth \u201d _ in CNNs . Unfortunately , I find this observation quite trivial , and not particularly novel , see for instance [ 1 , Figure 3 ] . 2.Below , I interpret the claim of the paper as _ \u201c double descent doesn \u2019 t happen in CNNs ; further , CNN performance converges to that of MLPs as they become deeper \u201d _ . Firstly , Figures 2 . ( b , c , e , f ) , and 3 . ( c , f ) are all in the classical regime ( < 100 % training accuracy ) , and therefore somewhat unrelated to the claim of the paper , which concerns generalization trends of 100 % accurate networks ( to be clear , including the whole range of depths from 1 is highly appreciated , but to corroborate the claims of the paper multiple depths beyond 100 % training accuracy are needed ) . Further , no plot shows a convincing _convergence_ of CNN performance to that of an MLP , rather , I see that in some cases the curves _intersect_ ( in Figure 2 , but not in Figure 3 ) . Finally , Figures 12 . ( f , g ) showcase settings where the double descent arguably does occur ( i.e.flat or increasing test performance ) , which makes the claim that it does not happen through depth less robust and more hyper-parameter dependent . 3.Regarding the intuition about CNN to MLP convergence . My key concern is that most image classification datasets , including both considered CIFAR-10 and ImageNet32 can not be perfectly fit with a linear function . The linear regression solution will not interpolate the training data . Therefore , whatever mechanism is behind the degradation of performance of deep nonlinear CNNs , it can not possibly be convergence to a linear solution , because they fit the training data perfectly , and the linear solution does not . As such , I believe the intuition that may work in the deep linear case , is _guaranteed_ to not apply to nonlinear networks . If my interpretation of the intuition is wrong , I kindly ask the authors to clarify their reasoning , explicitating precise logical steps and assumptions made . Other , more specific suggestions that may improve the quality of the paper and make the results more convincing : 1 . I believe the paper would be much stronger if it performed ( or referenced , if applicable ) equivalent studies , including toy examples , for deep MLPs , and compared/contrasted findings with CNNs . This would be especially useful to help validate claims about CNN to MLP convergence . For example , is the decreasing norm with depth specific only to deep linear networks with constraints , or to deep linear networks in general ? 2.I find the experiment in Figure 6 very interesting , but I think it can be strengthened in a few ways . Firstly , could you please provide measurements for depths < 5 , as in other figures ? Secondly , I assume \u201c SAME \u201d , zero padding was used ( if not , please let me know and ignore the following point ) . In this case , the norm of the deep linear CNN would decrease with depth even without training , at initialization , due to convolving over more and more zeros at the edges as one goes deeper into the network . Therefore , it would be important to control for this effect ( for example by using circular-padded convolutions ) . Finally , I believe this same toy experiment could have been conducted on a small subset of CIFAR-10 ( that can be fit linearly ) , and the results would be more convincing , since I am otherwise not confident the observed effect is not due to some quirk of this specific toy task ( e.g.would the same trend be observed if the test samples were everywhere in the image , and not at the bottom quadrant ? What if train samples were in the center ? What if the training set had multiple squares ? etc ) . # # # # To summarize : 1. am convinced by the observations that double descent _does not necessarily happen_ through depth in CNNs . 2.I am not convinced that it never happens , and I am not convinced one can use it in practice to select optimal depth . 3.Further , I am not convinced with the intuition and provided evidence that deep CNNs converge to MLPs . Unfortunately , I find ( 1 ) on its own not sufficiently surprising / useful / novel [ 1 , Figure 3 ] for publication . [ 1 ] [ Dynamical Isometry and a Mean Field Theory of CNNs : How to Train 10,000-Layer Vanilla Convolutional Neural Networks , Xiao et al , 2018 ] ( https : //arxiv.org/abs/1806.05393 )", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for their detailed feedback . We have updated our paper with the following additional experiments : 1 . We have added a subsection of experiments ( Section 3.3 , Appendix D.6 ) in the infinite-width regime , using the Convolutional Neural Tangent Kernel ( CNTK ) . The CNTK is deterministic ( eliminating the need for random seed sampling ) , and perfectly interpolates the data at all depths . We again observe that the test loss is monotonically increasing beyond a critical depth . Our experiments additionally show that for large depths the performance of the CNTK is comparable to that of the NTK . 2.We have run our main ResNet experiment at depths up to 100 ( Figures 5 , 13 and 14 ) , which makes clearer the trend that loss is increasing beyond a critical depth . 3.Per your suggestion , we ran additional experiments for the toy dataset in Section 4 and Appendix D.7 . We now address your concerns below . : * \u201c What concretely is the claim of the paper ? \u201d * The main claim of our paper is the following : \u201c In contrast to the case of width , double descent does not occur in convolutional neural networks of increasing depth . There is an optimal depth , after which test performance generally decreases and approaches that of fully connected neural networks. \u201d * \u201c This is not supported by Figures 12 . ( f , g ) , where it remains roughly flat or even goes up , while train accuracy and loss seem to have reached the optimum per Figures 12 . ( b , c ) , and 11 . ( a ) . [ ... ] Finally , Figures 12 . ( f , g ) showcase settings where the double descent arguably does occur ( i.e.flat or increasing test performance ) , which makes the claim that it does not happen through depth less robust and more hyper-parameter dependent. \u201d * For ResNet ( Figures 1b , 5 ) , the test loss increases past a critical depth . The results are less pronounced for the test accuracy because test accuracy is only a proxy for the quantity being optimized . We have updated our paper by adding depths to our ResNet plots ( Figures 5 , 13 ( previously 12 ) , 14 ( previously 13 ) ) , which more convincingly shows that test loss increases and test accuracy decreases past a critical depth . * \u201c ` among CNNs with 100 % training accuracy , the best depth for generalization is the smallest one \u2019 ( per the main contribution # 3 , page 2 ) ? This is not supported by Figure 1 . ( b ) , 12 . ( e , f ) , where the best network is not the most shallow. \u201d * We are not claiming that the best depth for generalization is the smallest one , but that there is a critical depth threshold past which test performance generally decreases . In fact , we have now updated the paper to include convolutional neural tangent kernel ( CNTK ) experiments ( Section 3.3 , Appendix D.6 ) in which all models achieve 100 % training accuracy , but the test loss monotonically decreases and then increases . * \u201c Firstly , Figures 2 . ( b , c , e , f ) , and 3 . ( c , f ) are all in the classical regime ( < 100 % training accuracy ) , and therefore somewhat unrelated to the claim of the paper \u201d * This was the reason we originally included the experiments in Figure 4 , which present the extension of the networks from Figures 2 and 3 to the over-parameterized regime ( through increasing width ) . Even in this setting , we continue to see a decrease in test accuracy as depth increases . * \u201c Further , no plot shows a convincing convergence of CNN performance to that of an MLP , rather , I see that in some cases the curves intersect \u201d * We are not claiming that the solution learned by the CNN in the nonlinear setting converges to that of a nonlinear MLP , but rather that the accuracy and error of the deep CNN becomes comparable to that of an MLP . This is an important claim since the performance of a nonlinear MLP is suboptimal for image classification . * \u201c My key concern is that most image classification datasets , including both considered CIFAR-10 and ImageNet32 can not be perfectly fit with a linear function. \u201d * To clarify , our hypothesis is that non-linear CNNs will have performance approaching that of a non-linear MLP as depth increases ( as is shown in Figures 2 and 3 ) . While it is indeed true that a linear network can not interpolate Cifar10 , we can achieve 100 % accuracy using a non-linear MLP , and it is the accuracy of these models that we hypothesize non-linear CNNs of increasing depth will approach . For instance , all MLPs shown in Figures 2 and 3 have nonlinear activations and interpolate the training data , and we observe that the accuracy of deep CNNs approaches that of deep MLPs ( and is even worse in some cases ) . To give intuition for this , we analyze the generalization of linear CNNs as compared to linear MLPs and demonstrate that the norm of the operator from a deep CNN approaches that of the minimum norm solution ( the solution from a linear MLP ) ."}, {"review_id": "rYt0p0Um9r-1", "review_text": "* Summary : This paper mainly answers a fundamental question : what is the role of depth in convolutional networks ? Specifically , the authors present an empirical analysis of the impact of the depth on the generalization in CNNs . Experiments on CIFAR10 and ImageNet32 demonstrate that the test performance beyond a critical depth . My detailed comments are as follows . * Positive points : 1 . This paper is significant to understand deep neural networks and helps to develop new deep learning algorithm . 2.This paper provides many empirical studies to analyze the effect of increasing depth on test performance . * Negative points : 1 . The importance and novelty of the research should be emphasized . Recently , there are some works [ 1 ] [ 2 ] [ 3 ] study the role of depth in DNN . What is the difference from these works ? [ 1 ] Do Deep Convolutional Nets Really Need to Be Deep and Convolutional ? ICLR 2017 [ 2 ] Understanding intermediate layers using linear classifier probes . arXiv , 2016 . [ 3 ] Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors . 2020 2.This paper analyzes the linear neural networks and demonstrates that increasing depth leads to poor generalization . However , existing works apply non-linear neural networks in real-world case . It would be better to provide analysis on non-linear neural networks . 3.The authors suggest that practitioners should decrease depth in these settings to obtain better test performance . However , ResNet-101 has better test performance than ResNet-18 in practice . Could you please give more explanations ?", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for their feedback . We address the stated negative points below : * \u201c Recently , there are some works [ 1 ] [ 2 ] [ 3 ] study the role of depth in DNN . What is the difference from these works ? \u201d * While we already discuss Urban et al . ( 2017 ) in our related works section , we clarify further below . As mentioned in our related work section , our work differs from the analysis conducted in Urban et al ( 2017 ) . That paper studies the role of depth in student-teacher CNNs , where a \u201c shallow \u201d CNN ( defined as having fewer than 5 layers ) is trained to fit the logits of an ensemble of deep CNNs ( which only has 8 convolutional layers and is far smaller than both currently used CNNs and the models considered in our work ) . Our work , on the other hand analyzes the performance of models with increasing depth that are trained from scratch . Therefore the student-teacher analysis of Urban et al ( 2017 ) doesn \u2019 t apply here . We have updated the related work section to make this distinction clearer . * [ 2 ] and [ 3 ] do not appear to be relevant to the main topic of this current work , as both are related to neural network interpretability . In particular , both [ 2 ] and [ 3 ] attempt to understand the representations learned through intermediate layers of a deep network , while we study the test performance of networks of varying depth trained from scratch . * \u201c This paper analyzes the linear neural networks and demonstrates that increasing depth leads to poor generalization . However , existing works apply non-linear neural networks in real-world case . It would be better to provide analysis on non-linear neural networks. \u201d * The bulk of our experimental analysis ( provided in section 3 ) is already conducted on non-linear neural networks : the Fully-conv net , ResNets , and the CNTK . We demonstrate for these examples that increasing depth leads to worsening generalization . * \u201c The authors suggest that practitioners should decrease depth in these settings to obtain better test performance . However , ResNet-101 has better test performance than ResNet-18 in practice . Could you please give more explanations ? \u201d * The claim that ResNet-101 has better test-performance than ResNet-18 depends on a number of factors such as network width and the classification problem at hand . For CIFAR10 , as shown in plot 1 ( b ) , the width 64 ResNet-18 actually has the best test performance of all models considered . However , for models with smaller widths , the optimal depth model is somewhere between 18 and 101 , and thus it is certainly possible for ResNet-101 to have better test performance . Our claim is that there exists a critical depth and , beyond that critical depth , test performance begins to degrade . * If the reviewer is referring to ResNet performance on ImageNet , we note that the reported performance of ResNet-101 does not actually correspond to a training accuracy of 100 % . Hence , in accordance with our results , it is plausible that increasing depth for ResNet on full ImageNet could lead to better generalization . Lastly , we would like to mention that we have added in a number of new experiments : 1 . We have added a subsection of experiments ( Section 3.3 , Appendix D.6 ) in the infinite-width regime , using the Convolutional Neural Tangent Kernel ( CNTK ) . The CNTK is deterministic ( eliminating the need for random seed sampling ) , and perfectly interpolates the data at all depths . We again observe that the test loss is monotonically increasing beyond a critical depth . Our experiments additionally show that for large depths the performance of the CNTK is comparable to that of the NTK . 2.We have run our main ResNet experiment at depths up to 100 ( Figures 5 , 13 and 14 ) , which makes clearer the trend that loss is increasing beyond a critical depth . 3.We ran additional experiments for the toy dataset in Section 4 and Appendix D.7 ."}, {"review_id": "rYt0p0Um9r-2", "review_text": "* * * * * * * * * Summary Of The Manuscript : * * * * * * * * * This manuscript focuses on the problem of the impact of depth in Convolutional Neural Networks ( CNNs ) for better generalization . To investigate the issue , the authors did an empirical analysis of the problem statement through various strategies ( i.e.Deep CNNs - increasing depth vs . Fully Convolutional Networks , etc . ) and provided in-depth findings via experiments . Together with experiments and evaluation on standard benchmarks such as CIFAR-10 and ImageNet32 , the authors lead to the conclusion of their study that the testing performance will be poor if the increase in depth is higher . * * * * * * * * * Strength Of The Manuscript : * * * * * * * * * Clarity : ++ The paper reads very well and provides a very good description of related work and background , motivating the problem . Even outside of the contribution of this paper , I would recommend this paper to people getting started with CNNs as it provides a thorough description of the part of the pipelines it deals with . Also , all the empirical analyses have been described thoroughly and the various settings for the training and testing are performed in such a way to give better insights to novice readers . Novelty : ++ In terms of novelty , the stand-alone contribution of the manuscript is that through various strategies authors tried to give in-depth insights on the behavior of different linear and non-linear as well as deep learning models via increasing the depth for classification task on different benchmark datasets . Experiments : ++ There have been experiments performed across datasets with variety in terms of different models and their architectures . Additionally , the analyses provided in the manuscript is fairly consistent . Supplementary material also backs the analysis by providing the visualizations of training and testing errors . Besides , analysis/ablation studies are done on the models , by changing the widths , the effect of downsampling , and changing the kernel width , and after through all the settings finally check the performance difference . * * * * * * * * * Weakness Of The Manuscript : * * * * * * * * * Overall , apart from the contribution of the paper I have some concerns regarding the paper which are listed below . -- I believe that the authors did a tremendous job to reach the conclusion that the increase in depth is crucial for certain tasks and might lead to poor results in different situations if the depth is increased beyond the threshold . However , to back up this conclusion more effectively I believe that if the authors have performed more analysis by introducing a data-augmentation strategy , student-teacher training strategy , introducing learning rate variance and so more training strategies this manuscript will be a really a good point of start to a beginner . I encourage the authors to refer to this manuscript by Urban et al . [ 1 ] . -- The fact that has been mentioned corresponding to increase in depth leads to worsening the result have already been a point of view for much of the deep learning practitioners as He et al . [ 2 ] have already provided a really good analysis in the manuscript of ResNet , in contrast , the majority of the work in the current manuscript is already have been either published or have been known to the community . * * * * * * * * * Justification Of The Manuscript Review : * * * * * * * * * -- In the reviewer 's opinion , in its current form , the paper provides in-depth analysis for increasing /decreasing the depth of CNNs however there are certain points mentioned in the weakness section have been mentioned which needs some clarification from the authors during the rebuttal phase , if answered thoroughly , the reviewer believes that the manuscript will be a really good point of start for novice deep learning readers/practitioners . Therefore the current rating of the paper will be 6 in reviewers ' opinion as it is above the acceptance threshold marginally . References : [ 1 ] Urban , Gregor , et al . `` Do deep convolutional nets really need to be deep and convolutional ? . '' In ICLR ( 2017 ) . [ 2 ] He , Kaiming , et al . `` Deep residual learning for image recognition . '' Proceedings of the IEEE conference on computer vision and pattern recognition . 2016 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for their feedback and their positive comments . We would like to address the stated weaknesses and discuss new experiments that we added to our paper : * \u201c However , to back up this conclusion more effectively I believe that if the authors have performed more analysis by introducing a data-augmentation strategy , student-teacher training strategy , introducing learning rate variance and so more training strategies this manuscript will be a really a good point of start to a beginner. \u201d * Our experiments with ResNets in Section 3.2 follow the methodology of Yang et al ( 2020 ) , and do use the data augmentation strategy of random crops and random horizontal flips . We have updated the paper to make this explicit . * As mentioned in our related work section , our work differs from the analysis conducted in Urban et al ( 2017 ) . That paper studies the role of depth in student-teacher CNNs , where a \u201c shallow \u201d CNN ( defined as having fewer than 5 layers ) is trained to fit the logits of an ensemble of deep CNNs ( which only has 8 convolutional layers and is far smaller than both currently used CNNs and the models considered in our work ) . Our work , on the other hand analyzes the performance of models with increasing depth that are trained from scratch . Therefore the student-teacher analysis of Urban et al ( 2017 ) doesn \u2019 t apply here . We have updated the related work section to make this distinction clearer . * We have added a subsection of experiments ( Section 3.3 , Appendix D.6 ) in the infinite-width regime , using the Convolutional Neural Tangent Kernel ( CNTK ) . The CNTK is deterministic , and perfectly interpolates the data at all depths . We again observe that the test loss is monotonically increasing beyond a critical depth . Our experiments additionally show that for large depths the performance of the CNTK is comparable to that of the NTK . * Could you clarify what you mean by \u201c introducing learning rate variance \u201d ? As mentioned in Appendix C , our models are trained either using Adam , or SGD with momentum with a learning rate schedule . * \u201c The fact that has been mentioned corresponding to increase in depth leads to worsening the result have already been a point of view for much of the deep learning practitioners as He et al . [ 2 ] have already provided a really good analysis in the manuscript of ResNet , in contrast , the majority of the work in the current manuscript is already have been either published or have been known to the community. \u201d * We would like to clarify that our experiments are in the over-parameterized regime and are thus in stark contrast with those from He et al.2015 , which generally do not interpolate ( achieve 100 % training accuracy ) on the training set . The experiments in He et al . ( 2015 ) address the fact that increasing depth leads to training difficulty . For example , Figure 1 from their paper presents an example of a 56 depth network having higher training error than a 20 depth network . However , none of our networks have any issues with training and are able to perfectly interpolate the data . He et al . ( 2015 ) in fact has only 1 example demonstrating that deeper interpolating models perform worse ( ResNet 1202 on CIFAR10 ) . Our work presents a systematic analysis and demonstrates that this phenomenon occurs across a number of convolutional architectures . Additionally , our result is surprising in light of the double descent results regarding network width ."}, {"review_id": "rYt0p0Um9r-3", "review_text": "Summary of paper : The authors empirically study trends in neural network performance for models with fixed width but increasing depth . ( Previous work has investigated how increasing `` model complexity '' from neural network width affects test loss/accuracy , with `` double descent '' behavior -- the trends observed here are very different from double descent . ) The authors consider ResNets and fully-convolutional networks ( which contain only convolutional layers with a final pooling operation ) on CIFAR-10 and subsets of ImageNet32 . One primary finding is that the test accuracy of convolutional networks approaches that of fully-connected networks as depth increases ( Fig.2 ) .These experiments include sweeping model complexity past the `` interpolation threshold '' ( where 100 % train accuracy is achievable ) , by analogy with experiments that have observed double descent behavior when model complexity originates from width . The authors further study linear neural networks ( with convolutional or Toeplitz constraints against fully-connected layers ) where they can analyze properties of the learned solutions . In one experiment , they consider a toy problem ( Sect.4.1 ) of classifying the color of a single pixel in an image . This problem is chosen because the minimum Frobenius norm solution ( which is learned by the fully-connected network ) does not generalize , and the authors show that the norm of the solution learned by the linear convolutional network approaches this value with depth . A similar result is shown for linear autoencoders ( Fig.7 ) .A primary implication of the authors ' results is that increasing depth past the interpolation threshold may be detrimental to performance . Quality and Clarity : The quality of the work ( experiments and framing ) seems good , as far as I can gather , and the paper is clearly written and straightforward to read . Originality : The primary thrust of the paper ( studying the trend in loss/accuracy when model complexity originates from depth ) is in close analogy to prior works that have investigated network width and not especially novel . However , I did find the comparison between learned solutions of linear convolutional vs fully-connected networks to be interesting and different from prior works I 'm aware of . The class-dependence of the critical depth was also an interesting finding . Significance : I think the work brings an interesting basic question to light -- to what extent is behavior like double descent ( or the usual bias-variance tradeoff ) specific to the way in which model complexity is increased in neural networks , and it provides empirical support that the trends are very different when overparameterization arises from depth . Other comments : The observation that the performance of deep convolutional networks approaches that of a fully-connected networks has appeared in one prior work that I 'm aware of : https : //arxiv.org/abs/1806.05393 published in ICML 2018 . Fig.3 in that work shows the test performance of ultra-deep CNNs ( with an initialization scheme chosen specifically to help train ultra-deep networks ) on CIFAR-10 collapses to that of fully-connected networks ; Sect . 2.1.6. discusses how the behavior of signal propagation ( the model prior ) in random convolutional networks as they become deep approaches that of fully-connected architectures . Since I was familiar with this work , I am not especially surprised by the findings in this paper and hence the reason for my somewhat lower score and suggestion for incorporating a bit more ( richer ) content , either empirically or theoretically . I do think the results are interesting to publish in some form but am not sure the paper as it stands merits a conference rather than e.g.a workshop publication . I am open to raising my score however . I had several questions about the empirical results : -- Some of the trends seem to fluctuate a bit rather than behave smoothly after an inflection point ( e.g.Fig.1 ( b ) ) .Is there a reason for this ? -- Could the authors elaborate on why a lower Frobenius norm ( in the linear networks ) is a bad solution ? In general I might have naively thought that low norm solutions were good for generalization . -- In Fig.2 ( e ) the test accuracy of the fully-convolutional network actually dips below that of the fully-connected model . This seems a bit unexpected -- is there an understanding of why this occurs ? Finally , Fig.14 in the supplementary seems to be mislabeled ( y-axis reads `` Test MSE '' , caption refers to train loss ) .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for their feedback and their positive comments . Below , we address your concerns and describe additional experiments that we have included : * \u201c The observation that the performance of deep convolutional networks approaches that of a fully-connected networks has appeared in one prior work that I 'm aware of : https : //arxiv.org/abs/1806.05393 published in ICML 2018. \u201d * We thank the reviewer for pointing out the related work , and we have updated our related work section in the paper to discuss Xiao et al . ( 2018 ) .Figure 3 of Xiao et al . ( 2018 ) demonstrates that deeper models perform worse , for the specific initialization scheme considered in their paper . The paper hypothesizes that the decrease in test performance is due to \u201c attenuation of spatially non-uniform modes , \u201d which would be an artifact of the initialization scheme chosen . Our work shows that the decrease in test performance is a universal phenomenon in models used in practice . * While Xiao et al ( 2018 ) argues that the signal propagation for infinitely-wide , random convolutional networks approaches that of fully-connected networks , this does not give insight on the comparison of these two models after training . We have added additional experiments in the Convolutional Neural Tangent Kernel setting ( Section 3.3 ) to show that this phenomenon does indeed occur in the infinite-width regime after training . To address the additional questions : * \u201c Some of the trends seem to fluctuate a bit rather than behave smoothly after an inflection point ( e.g.Fig.1 ( b ) ) .Is there a reason for this ? \u201d * We believe that the lack of smoothness in some of the plots is due to noise from the random initialization . Additionally , since we can think of our train and test data as being sampled from an underlying distribution of images , there may be minor fluctuations in the observed trend . Nevertheless , we both expect and observe the general trend of increasing test loss after a critical depth . Our CNTK experiments ( Section 3.3 , Appendix D.6 ) , which are deterministic , show that the test loss is monotonically decreasing , and then increasing across a number of settings . * \u201c Could the authors elaborate on why a lower Frobenius norm ( in the linear networks ) is a bad solution ? \u201d * In the particular case of this experiment , the minimum Frobenius norm solution is not translation invariant , i.e.the corresponding solution will just place a 1 or -1 in the entry corresponding to the location of the red or blue square in the training set and thus just predicts 0 on the test examples . In general , the fact that a linear fully connected network will learn the minimum Frobenius-norm solution along with the observation that convolutional networks do better on image classification tasks means that the minimum Frobenius-norm is not necessarily optimal for image classification tasks . It is indeed possible that convolutional networks minimize the norm in some other space , which is better suited for image classification tasks . * \u201c In Fig.2 ( e ) the test accuracy of the fully-convolutional network actually dips below that of the fully-connected model [ ... ] \u201d * We believe this is due to the effect of random initialization ( i.e.not sampling enough random seeds ) and randomness in the draw of test data . However , we feel that understanding this more precisely would be an interesting direction of future work ."}], "0": {"review_id": "rYt0p0Um9r-0", "review_text": "# # # Post-rebuttal update : I am raising my score from 4 to 5 , to recognize extensive updates to the paper experiments and numerous clarifications during the discussion , as well as to acknowledge that some of my initial concerns were not justified , e.g.asking for similar studies for MLPs ( which was effectively done in the original submission ) , or questioning whether the Frobenius norm in Figure 7 really goes down ( which was demonstrated better in the latest update ) . However , I can not give it a higher score / advocate for acceptance because I still find section 4 ( and follow-up discussion ) to be more misleading/confusing than helpful when it comes to explaining the observed phenomena . Precisely , even after the discussion , I still believe that 1 ) Experiments in Figure 7 should be done with circular-padded convolutions ( to rule out the more trivial explanation of the decreasing norm ) , and on small subsets of CIFAR10/Imagenet32 ( to establish whether low-norm is indeed associated with poor performance on image classification ) . 2 ) A precise definition of norm for nonlinear networks should be provided , and a link with the Frobenius norm of the linear networks should be established . I do n't understand what exactly `` the norm in the corresponding RKHS '' means , and how the reader was supposed to infer it from the text or our earlier discussion . Further , if possible , this norm should also be evaluated on the actual nonlinear networks , and compared to other notions of norms discussed in prior literature ( e.g.https : //arxiv.org/pdf/1706.08947.pdf ) , where lower norm is typically associated with better test accuracy . 3 ) A proper discussion about the non-monotonic dependence on depth in the context of provided intuition should be given . Current intuition can be interpreted as either predicting monotonic decrease in accuracy with depth ( learning solutions of lower and lower norms ) , or as predicting a sharp drop in accuracy at a certain depth ( point where the minimum-norm solution can be learned ) , but neither interpretation explains the hill-shaped dependence , which again makes me question whether this is indeed the right explanation . Without section 4 , the paper still has novel empirical results , but in my opinion they are neither surprising ( e.g.a hill-shaped dependence of accuracy is my default expectation of any NN hyper-parameter ) nor actionable ( there are no hints regarding what the peak depends on / how to guess it ) enough for publication at this time . A more rigorous investigation into explaining the phenomenon , or a more comprehensive empirical exploration to identify what does and what does n't influence the best depth , would make this a great paper at a later conference . Best , R4. # # # Original review : # # # # Paper Synopsis : The paper empirically studies the effect of depth on generalization in CNNs , and finds that , unlike in the case of width , generalization can decrease beyond a certain critical depth . The paper proposes an intuition for why this happens , by observing that in linear CNNs , the Frobenius norm of the trained network decreases with depth , and thus potentially converges to the minimum-norm solution , which corresponds to simple linear regression . By analogy and with some empirical evidence , the paper conjectures that CNNs converge to MLPs as they become deeper . # # # # Pros : Apart from certain aspects that I discuss below , the paper is clear and easy to read . I especially appreciate considering a variety of experimental settings ( different datasets , number of classes , vanilla-CNNs and ResNets ) , as well as toy examples . Code is provided , which is another strong point of the paper . The question asked in the title of the paper is interesting and worth investigating . # # # # Cons : My major concerns are : 1 . The main takeaway message appears either trivial , or at least miscommunicated . 2.Experimental evidence is unconvincing of [ the stronger , non-trivial interpretation of ] the key message of the paper and the proposed intuition . 3.The proposed intuition is not convincing theoretically . I am open to be persuaded otherwise in case if I misunderstood certain claims . Below are my specific thoughts on each of the points : 1 . What concretely is the claim of the paper ? Is it 1._ \u201c For each task , architecture , and training algorithm , there is a depth optimal for generalization ? \u201d _ If so , this is a truism . 2._ \u201c ... , in addition , beyond this optimal depth , generalization monotonically decreases ? \u201d _ This is not supported by Figures 12 . ( f , g ) , where it remains roughly flat or even goes up , while train accuracy and loss seem to have reached the optimum per Figures 12 . ( b , c ) , and 11 . ( a ) . 3._ \u201c among CNNs with 100 % training accuracy , the best depth for generalization is the smallest one \u201d _ ( per the main contribution # 3 , page 2 ) ? This is not supported by Figure 1 . ( b ) , 12 . ( e , f ) , where the best network is not the most shallow . 4._ \u201c The critical depth threshold is independent of certain parameters of the task/architecture/training algorithm \u201d _ ? Sadly , the paper does not answer this question , but admits this would be a good direction for future work ( I agree ) . As such , my takeaway from the paper is only that _ \u201c Double descent usually doesn \u2019 t happen through depth \u201d _ in CNNs . Unfortunately , I find this observation quite trivial , and not particularly novel , see for instance [ 1 , Figure 3 ] . 2.Below , I interpret the claim of the paper as _ \u201c double descent doesn \u2019 t happen in CNNs ; further , CNN performance converges to that of MLPs as they become deeper \u201d _ . Firstly , Figures 2 . ( b , c , e , f ) , and 3 . ( c , f ) are all in the classical regime ( < 100 % training accuracy ) , and therefore somewhat unrelated to the claim of the paper , which concerns generalization trends of 100 % accurate networks ( to be clear , including the whole range of depths from 1 is highly appreciated , but to corroborate the claims of the paper multiple depths beyond 100 % training accuracy are needed ) . Further , no plot shows a convincing _convergence_ of CNN performance to that of an MLP , rather , I see that in some cases the curves _intersect_ ( in Figure 2 , but not in Figure 3 ) . Finally , Figures 12 . ( f , g ) showcase settings where the double descent arguably does occur ( i.e.flat or increasing test performance ) , which makes the claim that it does not happen through depth less robust and more hyper-parameter dependent . 3.Regarding the intuition about CNN to MLP convergence . My key concern is that most image classification datasets , including both considered CIFAR-10 and ImageNet32 can not be perfectly fit with a linear function . The linear regression solution will not interpolate the training data . Therefore , whatever mechanism is behind the degradation of performance of deep nonlinear CNNs , it can not possibly be convergence to a linear solution , because they fit the training data perfectly , and the linear solution does not . As such , I believe the intuition that may work in the deep linear case , is _guaranteed_ to not apply to nonlinear networks . If my interpretation of the intuition is wrong , I kindly ask the authors to clarify their reasoning , explicitating precise logical steps and assumptions made . Other , more specific suggestions that may improve the quality of the paper and make the results more convincing : 1 . I believe the paper would be much stronger if it performed ( or referenced , if applicable ) equivalent studies , including toy examples , for deep MLPs , and compared/contrasted findings with CNNs . This would be especially useful to help validate claims about CNN to MLP convergence . For example , is the decreasing norm with depth specific only to deep linear networks with constraints , or to deep linear networks in general ? 2.I find the experiment in Figure 6 very interesting , but I think it can be strengthened in a few ways . Firstly , could you please provide measurements for depths < 5 , as in other figures ? Secondly , I assume \u201c SAME \u201d , zero padding was used ( if not , please let me know and ignore the following point ) . In this case , the norm of the deep linear CNN would decrease with depth even without training , at initialization , due to convolving over more and more zeros at the edges as one goes deeper into the network . Therefore , it would be important to control for this effect ( for example by using circular-padded convolutions ) . Finally , I believe this same toy experiment could have been conducted on a small subset of CIFAR-10 ( that can be fit linearly ) , and the results would be more convincing , since I am otherwise not confident the observed effect is not due to some quirk of this specific toy task ( e.g.would the same trend be observed if the test samples were everywhere in the image , and not at the bottom quadrant ? What if train samples were in the center ? What if the training set had multiple squares ? etc ) . # # # # To summarize : 1. am convinced by the observations that double descent _does not necessarily happen_ through depth in CNNs . 2.I am not convinced that it never happens , and I am not convinced one can use it in practice to select optimal depth . 3.Further , I am not convinced with the intuition and provided evidence that deep CNNs converge to MLPs . Unfortunately , I find ( 1 ) on its own not sufficiently surprising / useful / novel [ 1 , Figure 3 ] for publication . [ 1 ] [ Dynamical Isometry and a Mean Field Theory of CNNs : How to Train 10,000-Layer Vanilla Convolutional Neural Networks , Xiao et al , 2018 ] ( https : //arxiv.org/abs/1806.05393 )", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for their detailed feedback . We have updated our paper with the following additional experiments : 1 . We have added a subsection of experiments ( Section 3.3 , Appendix D.6 ) in the infinite-width regime , using the Convolutional Neural Tangent Kernel ( CNTK ) . The CNTK is deterministic ( eliminating the need for random seed sampling ) , and perfectly interpolates the data at all depths . We again observe that the test loss is monotonically increasing beyond a critical depth . Our experiments additionally show that for large depths the performance of the CNTK is comparable to that of the NTK . 2.We have run our main ResNet experiment at depths up to 100 ( Figures 5 , 13 and 14 ) , which makes clearer the trend that loss is increasing beyond a critical depth . 3.Per your suggestion , we ran additional experiments for the toy dataset in Section 4 and Appendix D.7 . We now address your concerns below . : * \u201c What concretely is the claim of the paper ? \u201d * The main claim of our paper is the following : \u201c In contrast to the case of width , double descent does not occur in convolutional neural networks of increasing depth . There is an optimal depth , after which test performance generally decreases and approaches that of fully connected neural networks. \u201d * \u201c This is not supported by Figures 12 . ( f , g ) , where it remains roughly flat or even goes up , while train accuracy and loss seem to have reached the optimum per Figures 12 . ( b , c ) , and 11 . ( a ) . [ ... ] Finally , Figures 12 . ( f , g ) showcase settings where the double descent arguably does occur ( i.e.flat or increasing test performance ) , which makes the claim that it does not happen through depth less robust and more hyper-parameter dependent. \u201d * For ResNet ( Figures 1b , 5 ) , the test loss increases past a critical depth . The results are less pronounced for the test accuracy because test accuracy is only a proxy for the quantity being optimized . We have updated our paper by adding depths to our ResNet plots ( Figures 5 , 13 ( previously 12 ) , 14 ( previously 13 ) ) , which more convincingly shows that test loss increases and test accuracy decreases past a critical depth . * \u201c ` among CNNs with 100 % training accuracy , the best depth for generalization is the smallest one \u2019 ( per the main contribution # 3 , page 2 ) ? This is not supported by Figure 1 . ( b ) , 12 . ( e , f ) , where the best network is not the most shallow. \u201d * We are not claiming that the best depth for generalization is the smallest one , but that there is a critical depth threshold past which test performance generally decreases . In fact , we have now updated the paper to include convolutional neural tangent kernel ( CNTK ) experiments ( Section 3.3 , Appendix D.6 ) in which all models achieve 100 % training accuracy , but the test loss monotonically decreases and then increases . * \u201c Firstly , Figures 2 . ( b , c , e , f ) , and 3 . ( c , f ) are all in the classical regime ( < 100 % training accuracy ) , and therefore somewhat unrelated to the claim of the paper \u201d * This was the reason we originally included the experiments in Figure 4 , which present the extension of the networks from Figures 2 and 3 to the over-parameterized regime ( through increasing width ) . Even in this setting , we continue to see a decrease in test accuracy as depth increases . * \u201c Further , no plot shows a convincing convergence of CNN performance to that of an MLP , rather , I see that in some cases the curves intersect \u201d * We are not claiming that the solution learned by the CNN in the nonlinear setting converges to that of a nonlinear MLP , but rather that the accuracy and error of the deep CNN becomes comparable to that of an MLP . This is an important claim since the performance of a nonlinear MLP is suboptimal for image classification . * \u201c My key concern is that most image classification datasets , including both considered CIFAR-10 and ImageNet32 can not be perfectly fit with a linear function. \u201d * To clarify , our hypothesis is that non-linear CNNs will have performance approaching that of a non-linear MLP as depth increases ( as is shown in Figures 2 and 3 ) . While it is indeed true that a linear network can not interpolate Cifar10 , we can achieve 100 % accuracy using a non-linear MLP , and it is the accuracy of these models that we hypothesize non-linear CNNs of increasing depth will approach . For instance , all MLPs shown in Figures 2 and 3 have nonlinear activations and interpolate the training data , and we observe that the accuracy of deep CNNs approaches that of deep MLPs ( and is even worse in some cases ) . To give intuition for this , we analyze the generalization of linear CNNs as compared to linear MLPs and demonstrate that the norm of the operator from a deep CNN approaches that of the minimum norm solution ( the solution from a linear MLP ) ."}, "1": {"review_id": "rYt0p0Um9r-1", "review_text": "* Summary : This paper mainly answers a fundamental question : what is the role of depth in convolutional networks ? Specifically , the authors present an empirical analysis of the impact of the depth on the generalization in CNNs . Experiments on CIFAR10 and ImageNet32 demonstrate that the test performance beyond a critical depth . My detailed comments are as follows . * Positive points : 1 . This paper is significant to understand deep neural networks and helps to develop new deep learning algorithm . 2.This paper provides many empirical studies to analyze the effect of increasing depth on test performance . * Negative points : 1 . The importance and novelty of the research should be emphasized . Recently , there are some works [ 1 ] [ 2 ] [ 3 ] study the role of depth in DNN . What is the difference from these works ? [ 1 ] Do Deep Convolutional Nets Really Need to Be Deep and Convolutional ? ICLR 2017 [ 2 ] Understanding intermediate layers using linear classifier probes . arXiv , 2016 . [ 3 ] Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors . 2020 2.This paper analyzes the linear neural networks and demonstrates that increasing depth leads to poor generalization . However , existing works apply non-linear neural networks in real-world case . It would be better to provide analysis on non-linear neural networks . 3.The authors suggest that practitioners should decrease depth in these settings to obtain better test performance . However , ResNet-101 has better test performance than ResNet-18 in practice . Could you please give more explanations ?", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for their feedback . We address the stated negative points below : * \u201c Recently , there are some works [ 1 ] [ 2 ] [ 3 ] study the role of depth in DNN . What is the difference from these works ? \u201d * While we already discuss Urban et al . ( 2017 ) in our related works section , we clarify further below . As mentioned in our related work section , our work differs from the analysis conducted in Urban et al ( 2017 ) . That paper studies the role of depth in student-teacher CNNs , where a \u201c shallow \u201d CNN ( defined as having fewer than 5 layers ) is trained to fit the logits of an ensemble of deep CNNs ( which only has 8 convolutional layers and is far smaller than both currently used CNNs and the models considered in our work ) . Our work , on the other hand analyzes the performance of models with increasing depth that are trained from scratch . Therefore the student-teacher analysis of Urban et al ( 2017 ) doesn \u2019 t apply here . We have updated the related work section to make this distinction clearer . * [ 2 ] and [ 3 ] do not appear to be relevant to the main topic of this current work , as both are related to neural network interpretability . In particular , both [ 2 ] and [ 3 ] attempt to understand the representations learned through intermediate layers of a deep network , while we study the test performance of networks of varying depth trained from scratch . * \u201c This paper analyzes the linear neural networks and demonstrates that increasing depth leads to poor generalization . However , existing works apply non-linear neural networks in real-world case . It would be better to provide analysis on non-linear neural networks. \u201d * The bulk of our experimental analysis ( provided in section 3 ) is already conducted on non-linear neural networks : the Fully-conv net , ResNets , and the CNTK . We demonstrate for these examples that increasing depth leads to worsening generalization . * \u201c The authors suggest that practitioners should decrease depth in these settings to obtain better test performance . However , ResNet-101 has better test performance than ResNet-18 in practice . Could you please give more explanations ? \u201d * The claim that ResNet-101 has better test-performance than ResNet-18 depends on a number of factors such as network width and the classification problem at hand . For CIFAR10 , as shown in plot 1 ( b ) , the width 64 ResNet-18 actually has the best test performance of all models considered . However , for models with smaller widths , the optimal depth model is somewhere between 18 and 101 , and thus it is certainly possible for ResNet-101 to have better test performance . Our claim is that there exists a critical depth and , beyond that critical depth , test performance begins to degrade . * If the reviewer is referring to ResNet performance on ImageNet , we note that the reported performance of ResNet-101 does not actually correspond to a training accuracy of 100 % . Hence , in accordance with our results , it is plausible that increasing depth for ResNet on full ImageNet could lead to better generalization . Lastly , we would like to mention that we have added in a number of new experiments : 1 . We have added a subsection of experiments ( Section 3.3 , Appendix D.6 ) in the infinite-width regime , using the Convolutional Neural Tangent Kernel ( CNTK ) . The CNTK is deterministic ( eliminating the need for random seed sampling ) , and perfectly interpolates the data at all depths . We again observe that the test loss is monotonically increasing beyond a critical depth . Our experiments additionally show that for large depths the performance of the CNTK is comparable to that of the NTK . 2.We have run our main ResNet experiment at depths up to 100 ( Figures 5 , 13 and 14 ) , which makes clearer the trend that loss is increasing beyond a critical depth . 3.We ran additional experiments for the toy dataset in Section 4 and Appendix D.7 ."}, "2": {"review_id": "rYt0p0Um9r-2", "review_text": "* * * * * * * * * Summary Of The Manuscript : * * * * * * * * * This manuscript focuses on the problem of the impact of depth in Convolutional Neural Networks ( CNNs ) for better generalization . To investigate the issue , the authors did an empirical analysis of the problem statement through various strategies ( i.e.Deep CNNs - increasing depth vs . Fully Convolutional Networks , etc . ) and provided in-depth findings via experiments . Together with experiments and evaluation on standard benchmarks such as CIFAR-10 and ImageNet32 , the authors lead to the conclusion of their study that the testing performance will be poor if the increase in depth is higher . * * * * * * * * * Strength Of The Manuscript : * * * * * * * * * Clarity : ++ The paper reads very well and provides a very good description of related work and background , motivating the problem . Even outside of the contribution of this paper , I would recommend this paper to people getting started with CNNs as it provides a thorough description of the part of the pipelines it deals with . Also , all the empirical analyses have been described thoroughly and the various settings for the training and testing are performed in such a way to give better insights to novice readers . Novelty : ++ In terms of novelty , the stand-alone contribution of the manuscript is that through various strategies authors tried to give in-depth insights on the behavior of different linear and non-linear as well as deep learning models via increasing the depth for classification task on different benchmark datasets . Experiments : ++ There have been experiments performed across datasets with variety in terms of different models and their architectures . Additionally , the analyses provided in the manuscript is fairly consistent . Supplementary material also backs the analysis by providing the visualizations of training and testing errors . Besides , analysis/ablation studies are done on the models , by changing the widths , the effect of downsampling , and changing the kernel width , and after through all the settings finally check the performance difference . * * * * * * * * * Weakness Of The Manuscript : * * * * * * * * * Overall , apart from the contribution of the paper I have some concerns regarding the paper which are listed below . -- I believe that the authors did a tremendous job to reach the conclusion that the increase in depth is crucial for certain tasks and might lead to poor results in different situations if the depth is increased beyond the threshold . However , to back up this conclusion more effectively I believe that if the authors have performed more analysis by introducing a data-augmentation strategy , student-teacher training strategy , introducing learning rate variance and so more training strategies this manuscript will be a really a good point of start to a beginner . I encourage the authors to refer to this manuscript by Urban et al . [ 1 ] . -- The fact that has been mentioned corresponding to increase in depth leads to worsening the result have already been a point of view for much of the deep learning practitioners as He et al . [ 2 ] have already provided a really good analysis in the manuscript of ResNet , in contrast , the majority of the work in the current manuscript is already have been either published or have been known to the community . * * * * * * * * * Justification Of The Manuscript Review : * * * * * * * * * -- In the reviewer 's opinion , in its current form , the paper provides in-depth analysis for increasing /decreasing the depth of CNNs however there are certain points mentioned in the weakness section have been mentioned which needs some clarification from the authors during the rebuttal phase , if answered thoroughly , the reviewer believes that the manuscript will be a really good point of start for novice deep learning readers/practitioners . Therefore the current rating of the paper will be 6 in reviewers ' opinion as it is above the acceptance threshold marginally . References : [ 1 ] Urban , Gregor , et al . `` Do deep convolutional nets really need to be deep and convolutional ? . '' In ICLR ( 2017 ) . [ 2 ] He , Kaiming , et al . `` Deep residual learning for image recognition . '' Proceedings of the IEEE conference on computer vision and pattern recognition . 2016 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for their feedback and their positive comments . We would like to address the stated weaknesses and discuss new experiments that we added to our paper : * \u201c However , to back up this conclusion more effectively I believe that if the authors have performed more analysis by introducing a data-augmentation strategy , student-teacher training strategy , introducing learning rate variance and so more training strategies this manuscript will be a really a good point of start to a beginner. \u201d * Our experiments with ResNets in Section 3.2 follow the methodology of Yang et al ( 2020 ) , and do use the data augmentation strategy of random crops and random horizontal flips . We have updated the paper to make this explicit . * As mentioned in our related work section , our work differs from the analysis conducted in Urban et al ( 2017 ) . That paper studies the role of depth in student-teacher CNNs , where a \u201c shallow \u201d CNN ( defined as having fewer than 5 layers ) is trained to fit the logits of an ensemble of deep CNNs ( which only has 8 convolutional layers and is far smaller than both currently used CNNs and the models considered in our work ) . Our work , on the other hand analyzes the performance of models with increasing depth that are trained from scratch . Therefore the student-teacher analysis of Urban et al ( 2017 ) doesn \u2019 t apply here . We have updated the related work section to make this distinction clearer . * We have added a subsection of experiments ( Section 3.3 , Appendix D.6 ) in the infinite-width regime , using the Convolutional Neural Tangent Kernel ( CNTK ) . The CNTK is deterministic , and perfectly interpolates the data at all depths . We again observe that the test loss is monotonically increasing beyond a critical depth . Our experiments additionally show that for large depths the performance of the CNTK is comparable to that of the NTK . * Could you clarify what you mean by \u201c introducing learning rate variance \u201d ? As mentioned in Appendix C , our models are trained either using Adam , or SGD with momentum with a learning rate schedule . * \u201c The fact that has been mentioned corresponding to increase in depth leads to worsening the result have already been a point of view for much of the deep learning practitioners as He et al . [ 2 ] have already provided a really good analysis in the manuscript of ResNet , in contrast , the majority of the work in the current manuscript is already have been either published or have been known to the community. \u201d * We would like to clarify that our experiments are in the over-parameterized regime and are thus in stark contrast with those from He et al.2015 , which generally do not interpolate ( achieve 100 % training accuracy ) on the training set . The experiments in He et al . ( 2015 ) address the fact that increasing depth leads to training difficulty . For example , Figure 1 from their paper presents an example of a 56 depth network having higher training error than a 20 depth network . However , none of our networks have any issues with training and are able to perfectly interpolate the data . He et al . ( 2015 ) in fact has only 1 example demonstrating that deeper interpolating models perform worse ( ResNet 1202 on CIFAR10 ) . Our work presents a systematic analysis and demonstrates that this phenomenon occurs across a number of convolutional architectures . Additionally , our result is surprising in light of the double descent results regarding network width ."}, "3": {"review_id": "rYt0p0Um9r-3", "review_text": "Summary of paper : The authors empirically study trends in neural network performance for models with fixed width but increasing depth . ( Previous work has investigated how increasing `` model complexity '' from neural network width affects test loss/accuracy , with `` double descent '' behavior -- the trends observed here are very different from double descent . ) The authors consider ResNets and fully-convolutional networks ( which contain only convolutional layers with a final pooling operation ) on CIFAR-10 and subsets of ImageNet32 . One primary finding is that the test accuracy of convolutional networks approaches that of fully-connected networks as depth increases ( Fig.2 ) .These experiments include sweeping model complexity past the `` interpolation threshold '' ( where 100 % train accuracy is achievable ) , by analogy with experiments that have observed double descent behavior when model complexity originates from width . The authors further study linear neural networks ( with convolutional or Toeplitz constraints against fully-connected layers ) where they can analyze properties of the learned solutions . In one experiment , they consider a toy problem ( Sect.4.1 ) of classifying the color of a single pixel in an image . This problem is chosen because the minimum Frobenius norm solution ( which is learned by the fully-connected network ) does not generalize , and the authors show that the norm of the solution learned by the linear convolutional network approaches this value with depth . A similar result is shown for linear autoencoders ( Fig.7 ) .A primary implication of the authors ' results is that increasing depth past the interpolation threshold may be detrimental to performance . Quality and Clarity : The quality of the work ( experiments and framing ) seems good , as far as I can gather , and the paper is clearly written and straightforward to read . Originality : The primary thrust of the paper ( studying the trend in loss/accuracy when model complexity originates from depth ) is in close analogy to prior works that have investigated network width and not especially novel . However , I did find the comparison between learned solutions of linear convolutional vs fully-connected networks to be interesting and different from prior works I 'm aware of . The class-dependence of the critical depth was also an interesting finding . Significance : I think the work brings an interesting basic question to light -- to what extent is behavior like double descent ( or the usual bias-variance tradeoff ) specific to the way in which model complexity is increased in neural networks , and it provides empirical support that the trends are very different when overparameterization arises from depth . Other comments : The observation that the performance of deep convolutional networks approaches that of a fully-connected networks has appeared in one prior work that I 'm aware of : https : //arxiv.org/abs/1806.05393 published in ICML 2018 . Fig.3 in that work shows the test performance of ultra-deep CNNs ( with an initialization scheme chosen specifically to help train ultra-deep networks ) on CIFAR-10 collapses to that of fully-connected networks ; Sect . 2.1.6. discusses how the behavior of signal propagation ( the model prior ) in random convolutional networks as they become deep approaches that of fully-connected architectures . Since I was familiar with this work , I am not especially surprised by the findings in this paper and hence the reason for my somewhat lower score and suggestion for incorporating a bit more ( richer ) content , either empirically or theoretically . I do think the results are interesting to publish in some form but am not sure the paper as it stands merits a conference rather than e.g.a workshop publication . I am open to raising my score however . I had several questions about the empirical results : -- Some of the trends seem to fluctuate a bit rather than behave smoothly after an inflection point ( e.g.Fig.1 ( b ) ) .Is there a reason for this ? -- Could the authors elaborate on why a lower Frobenius norm ( in the linear networks ) is a bad solution ? In general I might have naively thought that low norm solutions were good for generalization . -- In Fig.2 ( e ) the test accuracy of the fully-convolutional network actually dips below that of the fully-connected model . This seems a bit unexpected -- is there an understanding of why this occurs ? Finally , Fig.14 in the supplementary seems to be mislabeled ( y-axis reads `` Test MSE '' , caption refers to train loss ) .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for their feedback and their positive comments . Below , we address your concerns and describe additional experiments that we have included : * \u201c The observation that the performance of deep convolutional networks approaches that of a fully-connected networks has appeared in one prior work that I 'm aware of : https : //arxiv.org/abs/1806.05393 published in ICML 2018. \u201d * We thank the reviewer for pointing out the related work , and we have updated our related work section in the paper to discuss Xiao et al . ( 2018 ) .Figure 3 of Xiao et al . ( 2018 ) demonstrates that deeper models perform worse , for the specific initialization scheme considered in their paper . The paper hypothesizes that the decrease in test performance is due to \u201c attenuation of spatially non-uniform modes , \u201d which would be an artifact of the initialization scheme chosen . Our work shows that the decrease in test performance is a universal phenomenon in models used in practice . * While Xiao et al ( 2018 ) argues that the signal propagation for infinitely-wide , random convolutional networks approaches that of fully-connected networks , this does not give insight on the comparison of these two models after training . We have added additional experiments in the Convolutional Neural Tangent Kernel setting ( Section 3.3 ) to show that this phenomenon does indeed occur in the infinite-width regime after training . To address the additional questions : * \u201c Some of the trends seem to fluctuate a bit rather than behave smoothly after an inflection point ( e.g.Fig.1 ( b ) ) .Is there a reason for this ? \u201d * We believe that the lack of smoothness in some of the plots is due to noise from the random initialization . Additionally , since we can think of our train and test data as being sampled from an underlying distribution of images , there may be minor fluctuations in the observed trend . Nevertheless , we both expect and observe the general trend of increasing test loss after a critical depth . Our CNTK experiments ( Section 3.3 , Appendix D.6 ) , which are deterministic , show that the test loss is monotonically decreasing , and then increasing across a number of settings . * \u201c Could the authors elaborate on why a lower Frobenius norm ( in the linear networks ) is a bad solution ? \u201d * In the particular case of this experiment , the minimum Frobenius norm solution is not translation invariant , i.e.the corresponding solution will just place a 1 or -1 in the entry corresponding to the location of the red or blue square in the training set and thus just predicts 0 on the test examples . In general , the fact that a linear fully connected network will learn the minimum Frobenius-norm solution along with the observation that convolutional networks do better on image classification tasks means that the minimum Frobenius-norm is not necessarily optimal for image classification tasks . It is indeed possible that convolutional networks minimize the norm in some other space , which is better suited for image classification tasks . * \u201c In Fig.2 ( e ) the test accuracy of the fully-convolutional network actually dips below that of the fully-connected model [ ... ] \u201d * We believe this is due to the effect of random initialization ( i.e.not sampling enough random seeds ) and randomness in the draw of test data . However , we feel that understanding this more precisely would be an interesting direction of future work ."}}