{"year": "2021", "forum": "AWOSz_mMAPx", "title": "Local Convergence Analysis of Gradient Descent Ascent with Finite Timescale Separation", "decision": "Accept (Poster)", "meta_review": "This paper treats the problem of running gradient descent-ascent (GDA) in min-max games with a different step-size for the two players. Earlier work by Jin et al. has shown that, when the ratio of the step-sizes is large enough, the stable fixed points of GDA coincide with the game's strict local min-max equilibria. The main contribution of this paper is an explicit characterization of a threshold value $\\tau^*$ of this ratio as the maximum eigenvalue of a specific matrix that involves the second derivatives of the game's min-max objective at each (strict local) equilibrium.\n\nThis paper generated a fairly intense discussion, and the reviewers showed extraordinary diligence in assessing the authors' work. Specifically, the reviewers raised a fair number of concerns concerning the initial write-up of the paper, but these concerns were mostly addressed by the authors in their revision and replies. As a result, all reviewers are now in favor of acceptance.\n\nAfter my own reading of both versions of the paper and the corresponding discussion, I concur with the reviewers' view and I am recommending acceptance subject to the following revisions for the final version of the paper:\n1. Follow the explicit recommendations of AnonReviewer3 regarding the numerical simulations (or, failing that, remove them altogether). [The authors' phrase that \"The theory we provide also does not strictly apply to using RMSprop\" does not suffice in this regard]\n2. Avoid vague statements like $\\tau \\to \\infty$ in the introduction regarding the work of Jin et al. and state precisely their contributions in this context. In the current version of the paper, a version of this is done in page 4, but the introduction is painting a different picture, so this discussion should be transferred there.\n3. A persisting concern is that the authors' characterization of $\\tau^*$ cannot inform a practical choice of step-size scaling (because the value of $\\tau^*$ derived by the authors depends on quantities that cannot be known to the optimizer). Neither the reviewers nor myself were particularly convinced by the authors' reply on this point. However, this can also be seen as an \"equilibrium refinement\" result, i.e., for a given value of $\\tau$ only certain equilibria can be stable. I believe this can be of interest to the community, even though the authors' characterization cannot directly inform the choice of $\\gamma_1$ and $\\gamma_2$ (or their ratio).\n\nModulo the above remarks (which the authors should incorporate in their paper), I am recommending acceptance.", "reviews": [{"review_id": "AWOSz_mMAPx-0", "review_text": "The paper studies the local asymptotic stability of a specific class of solutions points , referred to as strict local minmax equilibria ( or differential Stackelberg equilibria ) , in the case of Gradient Descent-Ascent Dynamics with a finite time-scale separation . The time-scale separation ( \\tau ) is being captured by the ratio of the step-sizes between the min and max agents respectively . Recently , Jin et al.showed the set of asymptotically stable critical points of gradient descent-ascent coincide with the set of differential Stackelberg equilibrium as the time separation goes to infinity . The paper shows that an infinitely large separation is not needed and some finite but large enough separation suffices . The paper provides a close analogue of another previous result by Mescheder about local stability of gradient descent dynamics in GANs under strong technical assumptions . The paper ends with GAN experiments where \\tau=1 , 2 , 4 , 8 are tested and the performance seems to peak at 4 . The paper performs a detailed theoretical analysis of the coupling between GDA and diff Stackelberg equilibria . Although this is positive , the results are not particularly surprising given the prior work . The writing of the paper could also be significantly improved . One issue that I had reading the paper is that at times and especially in the introduction the treatment of ( asymptotically stable ) , stable , unstable fixed points seem to be a little ambiguous.The paper only formally defines locally exponentially stable equilibrium in the preliminaries which is a notion that is not used in the introduction . I think it is important to set early on a clear terminology that is consistent throughout the whole paper . I am also a bit confused about some statements in the paper about which type of solution concepts are game theoretically meaningful . The paper seems to state that any critical point that does not satisfy the definitions of differential Stackelberg equilibria lack game theoretic meaning . From the paper the stable critical points of gradient descent-ascent coincide with the set of differential Stackelberg equilibrium as \\tau goes to infinity . All \u2018 bad critical points \u2019 ( critical points lacking game-theoretic meaning ) become unstable and all \u2018 good critical points \u2019 ( game-theoretically meaningful equilibria ) remain or become stable as \\tau goes to infinity . This seems like a strong statement . It seems to me that min-max solutions of bilinear zero-sum games does not satisfy the differential Stackelberg definition . Such statements would imply that min-max solutions are 1 ) bad critical points and 2 ) lack game theoretic meaning despite being the golden standard of a solution concept in game theory . Maybe I am missing something here ? [ 1 ] has recently shown that alternating GDA with fixed time-separation does not converge in the case of bilinear zero-sum games but is instead recurrent with the min-max equilibrium being stable but not asymptotically stable . This seems to be exactly the setting that you are studying . How are the results of [ 1 ] connected to yours ? I think that due to the tight match between the two settings a thorough discussion is needed . The definitions of differential/strict Nash/Stackelberg equilibria are two of several alternative definition/solution concepts that have only been recently introduced in the context of non-convex non-concave games . The paper should compare and contrast to other notions ideas ( e.g.proximal equilibria are only mentioned briefly [ 2 ] , see also [ 3 ] , [ 4 ] ) . Although one should of course not expect a global convergence as such a result would be too ambitious , the title could be interpreted as such a result by non-specialists . I think it might be better if the term local analysis is used instead . A more thorough discussion about non-convergence results for GDA and variants in zero-sum games could be also helpful [ 1,3,5-8 ] to dispel any possible confusion . In terms of the experimental results why do the simulations stop with \\tau=8 ? The theoretical results as well as the prior work by Jin et . al are supportive of arbitrary large \\tau . What happens e.g.for tau= 2^4 , 2^8 , .... It already seems that performance starts dropping for \\tau > 4 . Does this trend continue ? Does the performance have a unique peak ? or does it fluctuate ? The regularization results ( Theorem 3 ) remain true even for \\tau < < 1 e.g.\\tau = 2^ { -4 } , 2^ { -8 } , ... What would experiments show for such \\tau under regularization ? [ 1 ] Bailey et al.Finite Regret and Cycles with Fixed Step-Sizevia Alternating Gradient Descent-Ascent . COLT 2020 [ 2 ] Farnia et . al Do GANs always have Nash equilibria ? ICML 2020 [ 3 ] Vlatakis-Gkaragkounis et al.Poincar\u00e9 Recurrence , Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games . NeurIPS 2019 . [ 4 ] Zhang , et al.Optimality and Stability in Non-Convex-NonConcave Min-Max Optimization . arXiv e-prints , art . arXiv:2002.11875 , February 2020 . [ 5 ] Mertikopoulos et al . `` Cycles in adversarial regularized learning . '' Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms . Society for Industrial and Applied Mathematics , 2018 . [ 6 ] Cheung et al . `` Vortices instead of equilibria in minmax optimization : Chaos and butterfly effects of online learning in zero-sum games . '' arXiv preprint arXiv:1905.08396 ( 2019 ) . [ 7 ] Letcher `` On the Impossibility of Global Convergence in Multi-Loss Optimization . '' arXiv preprint arXiv:2005.12649 ( 2020 ) . [ 8 ] Hsieh , et . al . `` The limits of min-max optimization algorithms : convergence to spurious non-critical sets . '' arXiv preprint arXiv:2006.09065 ( 2020 ) .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer 1 , We just wanted to comment in hopes that you have seen our response to your review , and we would greatly appreciate further comments from you ."}, {"review_id": "AWOSz_mMAPx-1", "review_text": "The main result of the paper states that a strict local minmax point is a stable critical point of t-GDA for some large enough t , and that any non-strict local minmax can be made unstable by s-GDA if we choose s large enough . -Major issues My greatest concern is that the first part of the main result , that a strict local minmax is stable for t-GDA with all large , but finite t , is already known ( Jin et al.2020 ) .Specifically , the proof of Lemma 40 in ( Jin et al.2020 ) shows that for all large enough finite t , the Jacobian of t-GDA only has eigenvalues whose real part is smaller than 0 , which then implies the stability of t-GDA for a finite t. From what I can see , the reason why Jin et al.2020 stated their results in terms of infinite timescale separation is because they did not have a uniform bound on how large the timescale t should be , and therefore in general it can be made as large as possible ( but finite ) . The proof in the current submission has exactly the same feature : for every game , there is a finite t that makes t-GDA stable , but in general this t can be made arbitrarily large . It seems to me that the authors have not qualitatively improved over ( Jin et al.2020 ) ( although I believe the bounds in this paper are tighter ) . In the same vein , the converse statement also more or less appeared in ( Jin et al.2020 ) ; see the proof of Theorem 28 , p.24-25 therein . Due to the above , I can not see the claimed novelty of providing the first finite timescale separation for GDA , hence my rating . I 'm willing to change my score should the authors convince me that I have misunderstand something . -Minor issues 1 . The authors claimed that `` On the empirical side , it has been widely demonstrated that timescale separation in gradient descent-ascent is crucial to improving the solution quality when training generative adversarial networks . '' I believe this is an overstatement of what we currently know about GANs ; see https : //arxiv.org/pdf/1711.10337.pdf for a comprehensive empirical study of the effects on the timescale for GDA , which is not as conclusive as the authors stated . I would therefore suggest to tone down the sentence . 2.Appendix B.3 is quite weird . F ( x_k ) here should be a vector-valued mapping but the authors seem to view it as a function . Also , by F ( k ) = O ( M^k ) , did the authors mean ||x_ { k+1 } \u2212 x * || = O ( M^k ) ? - Post-revision evaluation : The authors have modified the statements of the main theorems as well as including a more detailed comparison to previous works , which clarifies my concern . I have thus increased my score . The technical contributions bring new insight into the studying of scale separation of GDA , and enables a tight characterization of many toy examples . I believe these are solid contributions and should be valued . On the down side , I 'd like to point out that the `` practical implication '' in this paper is a bit of stretch since the ImageNet experiments are run with RMSprop , whereas the analysis of this paper is highly specialized to GDA . Of course , studying adaptive algorithms in min-max games is exceedingly hard and well beyond the scope of this paper . What I recommend the authors is then : 1 . Explicitly notify the readers of the difference between RMSprop and GDA . 2.Find a nontrivial but simple example where 1-GDA provides an okay baseline ( say 7-layer CNNs for mixture of Gaussians or MNIST ) . Increase the time scale to show if it exhibits a similar behavior that a small $ \\tau $ gives the best result . This is directly verifying what the theory is saying , and hence feels more valuable to me .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Regarding minor point on empirical section : While we are happy to tone down the sentence as suggested , we would like to point out that in the cited paper it appears they always have the same learning rate and explore 1 versus 5 rollouts for the discriminator , e.g.which isn \u2019 t necessarily a contradiction of our claim . We are more suggesting that there has been numerous works touting the empirical success of different learning rates between the generator and discriminator and hence our work provides some theoretical backing for this heuristic . This is not to suggest or imply that timescale separation is strictly necessary for all GANs ( as the reference points out , not all GANs are created equal ) . Regarding appendix B.3 : Fair point . There is a conflation of the use of F here which we should not have done . On the one hand $ x_ { k+1 } =F ( x_k ) $ where F defines the dynamics and then in the next sentence F is used as a real valued function . We will change this so that $ x_ { k+1 } =h ( x_k ) $ some different function and then use F ( k ) to be a scalar value function such as the norm $ \\|x_k-x * \\| $ , e.g.The point was to define how big O , is being used in our convergence rates , but perhaps this is common enough that a reference would suffice . [ 1 ] Jin et al.arxiv 1902.00618 ( published ICML 2020 ) . What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization . [ 2 ] Kokotovic et al ( see , Chapter 3 ) . 1986.Singular Perturbation Methods in Control Analysis and Design ."}, {"review_id": "AWOSz_mMAPx-2", "review_text": "Motivated by the many applications of min-max optimization problems in Machine Learning , the authors examine the effect of using different learning rates for each player in Gradient Descent Ascent ( GDA ) for non-convex non-concave optimization problems . Prior work has already established that making the learning rate of one player infinitely larger than other player 's learning rate alleviates the cycling problems of GDA and makes game-theoretically meaningful equilibria the only asymptotically stable fixed points . The main contribution of this work is that it proves that we can get the same stability guarantees while keeping the learning rates of both players finite . This is crucial for practical applications where using unbounded learning rates in not an option . The authors employ this result to prove a variety of local convergence results in both deterministic ans stochastic settings . Pros : 1 ) The finite time scale separation is necessary in order to make the theoretical intuitions in prior work applicable for practical problems like trainings GANs . 2 ) The proof techniques used for this separation results are , to the best of my knowledge , significantly different and elaborate than the ones used in prior work ( Jin et al. , 2020 ) . 3 ) The theoretical findings are complemented with empirical evaluations both on small min-max problems and on complex ones like training GAN architectures . Cons : Theorem 28 in the arxiv version of Jin et al.2020 does not explicitly reference the existence of a finite time scale that satisfies their inclusion results . However , it is clear from the proof of Theorem 28 on page 24 that such a finite time-scale separation exists even though they do not provide an explicit formula for it . At least for one of the inclusion statements they explicitly mention that it holds for $ \\epsilon < \\epsilon_0 $ for some $ \\epsilon_0 $ where $ \\epsilon $ corresponds to $ 1/\\tau $ . Of course the result of the authors gives a more direct construction of the threshold $ \\tau^ * $ by reducing the search for it to an eignenvalue problem . From a practical standpoint though , both results are existential . Neither proof approach gives particular intuition on how this time scale can be found in a computationally efficient way . The added value of leveraging an array of mathematical tools to provide this explicit construction is unclear to me . Given the above concern and that the convergence results essentially leverage the asymptotic stability properties provided by Theorems 1 and 2 , I am assigning a weak reject score . However , I am willing to substantially increase my score if the authors address the above concern .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your review . Please see the common response to you and R3 for a detailed comment regarding the primary con you have listed . We hope this can clear up your concern and make it clear that the results you refer to from past work can only be thought of in the asymptotic sense and we make a significant advance by providing a tight non-asymptotic construction . As you mentioned in the beginning of your review , this is extremely important for practical applications where using unbounded learning rates is not an option . Below we address more specific aspects of your review to hopefully provide further clarification . In your review you state : `` Of course the result of the authors gives a more direct construction of the threshold $ \\tau^ { \\ast } $ by reducing the search for it to an eigenvalue problem . From a practical standpoint though , both results are existential . '' The construction of $ \\tau^ { \\ast } $ we provide is in fact not comparable to anything from [ 1 ] . This is because there is no construction given in [ 1 ] since it is an asymptotic result and is only stating local stability for GDA when $ \\tau\\rightarrow \\infty $ . Please refer back to the general response to you and reviewer 3 for more details . Moreover , our result is not only existential , but it is also constructive . From a practical standpoint , this is major difference and is important . From an existential point of view alone , our result is useful since it is saying that a finite timescale separation , which importantly results in an implementable algorithm as opposed to a timescale separation approaching infinity , can guarantee the type of convergence we would desire . Then , from a constructive point of view , since we can exactly compute $ \\tau^ { \\ast } $ , we can explore many types of problems to gain insights into what we can generally expect as necessary or sufficient for the desired behavior . We in fact did this for the many simpler experiments we ran , and found that the theoretical construction of $ \\tau^ { \\ast } $ was also tight as the theory would suggest and furthermore $ \\tau^ { \\ast } $ is often a reasonable finite value that allows for a range of learning for the discrete time update to converge to local minmax ( which would not be feasible if the timescale separation needed to actually approach infinity ) . This is helpful because it can inform heuristics for more complicated problems such as training generative adversarial networks as well as explain the success of heuristics that are already frequently deployed . To give a concrete example , we found that the insights we gained from the simple Dirac-GAN example turned out to effectively match up with what we observed in the performance of the generative adversarial network training experiments for various hyperparameter settings . Regarding \u201c The added value of leveraging an array of mathematical tools to provide this explicit construction is unclear to me. \u201d As noted in our general response to you and reviewer 3 , the new tools in our paper expose a number of opportunities for analyzing multiple hyperparameters as we demonstrate with Theorem 3 on generative adversarial networks . Moreover , also as noted above , because of the explicit construction allowed by these tools , we are able to see that 1 ) in practice the value of $ \\tau^\\ast $ is generally not large and 2 ) we can optimize for convergence rate by exploring the tradeoff between the choice of finite $ \\tau $ and the learning rate $ \\gamma_1 $ . The review says : \u201c The convergence results essentially leverage the asymptotic stability properties provided by Theorems 1 and 2. \u201d We believe that our convergence results are actually more meaningful than just thinking of them as asymptotic convergence in the neighborhood of a asymptotically stable equilibrium . To get this result , there are in fact several steps and it does not follow trivially from Theorems 1 and 2 . This is because $ J_ { \\tau } ( x^ { \\ast } ) $ has complex eigenvalues , so to obtain rates that do not assume $ J_ { \\tau } ( x^ { \\ast } ) $ has a positive definite symmetric part ( which is required to use the normal 2 norm convergence rate analysis techniques ) , we formulate an optimization problem for finding the stepsize given $ \\tau > \\tau^ { \\ast } $ that maximizes the spectral radius of the local linearization $ I-\\gamma_1 J_ { \\tau } ( x * ) $ . Furthermore , this analysis also includes an estimate on the region of convergence . Finally , we note that we have a number of other results including specializing to generative adversarial networks in Theorem 3 , extensive numerical experiments that range from interpretable and informative to large-scale training , results on the stochastic setting where we get almost sure asymptotic convergence using less restrictive stepsize assumptions than is typical since we do not need a two-timescale sequence given $ \\tau^ { \\ast } $ . [ 1 ] Jin et al.Arxiv 1902.00618 ( published in ICML 2020 ) . What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization ."}, {"review_id": "AWOSz_mMAPx-3", "review_text": "# # Summary This paper studies the stable points of gradient descent ascent with different step-sizes . Roughly , this paper 's main result is that for any fixed point for the GDA dynamics , that point is stable for GDA with a large enough timescale separation if and only if it is a local Stackelberg equilibrium . This result is quite intuitive since a similar result has been proved by Jin et al.2020 . ( the timescale had to go to infinity ) . Though , proving such a result for a * finite * timescale separation is a major improvement and is related to practical significant considerations . # # Pros and cons Strengths : the work is well motivated , and overall the paper is well written . Though if I think some of the technical aspects could be improved . The results may interest the community . The theoretical tools introduced could be used in other theoretical work . weaknesses : Some of the theory sections could be more developed to build intuitions on the phenomenon going on . It seems really hard for me to follow the current proof sketches since many notations are not properly introduced ( or at least any intuition about what they mean is proposed ) . ( see my section on questions/ comments ) The experiments are not really related to the theory . ( see my section about experiments ) I have some technical concerns and questions ( I would be glad if the authors can answer them ; see my section on questions ) The conclusion is overstating the results of the paper . # # Overall review Overall , this paper is a good paper that should be accepted if the authors fix some statements in the conclusion section and answer my questions about the theory . Also , the experimental section could be improved ( not by running more large scale experiments but by more related to the theory presented ) # # Questions and comments ( by decreasing order of importance ) : # # # technical question The most important question I have regards the guardian map you use . In the proof sketch of Theorem 1 where you state that the map $ \\nu ( \\tau ) : = det ( - ( J_\\tau \\oplus J_\\tau ) ) $ is a guardian map of $ \\mathcal { S } ( \\mathbb { C_-^\\circ } ) $ but if we look at lemma C.1 the result boils down to the fact that the eigenvalues of $ A \\oplus A $ are $ ( \\lambda_i + \\lambda_j ) $ with $ \\lambda_i , \\lambda_j \\in Sp ( A ) ) $ . However , it means that if $ A $ has a single eigenvalue in $ \\mathbb { C_-^\\circ } $ , then $ \\nu ( A ) $ is non zero . Some arguments should be added ( since $ A $ is a real matrix , the non-real eigenvalues are complex conjugates ) to justify that the only problematic case is when $ A $ has $ 0 $ as an eigenvalue . One quick fix would be to consider $ \\nu ( A ) : = det ( A ) det ( - ( A\\oplus A ) ) $ as guardian map $ . But I do not know how it would change the derivations in the proof of claim C.1 . I am quite novel with these notions , so my questions are : Am I missing something ? If yes , what ? If not , would the fix work , and will it change the results of Theorem 1 and 2 ? # # # Conclusion In the conclusion section , you write , \u201c We proves gradient descent-ascent converges to a critical point for a range of finite learning rate ratios if and only if the critical point is a differential Stackelberg equilibrium . This answers a standing open question about the convergence of first-order methods to local minimax equilibria. \u201d These two sentences may be misleading for the following reasons : - you only prove a * local * convergence result - The local distinction is important because the method can still cycle outside of these neighborhoods . ( see for instance [ Letcher 2020 ] ) - Also , the value of $ \\tau $ depends on the neighborhood . So it seems that you may have an infinite number of critical points , and the value of \\tau to globally ( max of the \\tau for each critical point ) only has local convergence to local minimax may be infinite . Do you agree with that statement ? # # # Experiments Your theory is about the nature of the stationary points found by the training dynamics ( are they theoretically meaningful ) , but you do not verify that training with different learning rates actually finds local minimax . Moreover , it is known that using different learning rates is necessary to get better empirical performances ( see , for instance [ Brock et al.2019 , Jolicoeur-Martineau et al.2020 ] or most of the SOTA results on https : //paperswithcode.com/paper/adversarial-score-matching-and-improved ) . I think that one experiment that would support your theory would be about looking at the eigenvalues of J_\\tau around the \u201c practical equilibria \u201d for different values of $ \\tau $ and see if you only get local minimax for large enough $ \\tau $ . In Assumption 1 , you suppose that $ ( w , \\theta ) $ is an equilibrium . But what kind of equilibrium ? Nash ? What do you need ? That it is a stationary point of the dynamics ? # # # About guardian maps Shouldn \u2019 t you add in the definition of a guardian map that the map is continuous ? # # # Related work Your examples 1 and 2 look very similar to the ones proposed by Zhang et al.2020 in section 5.2 . Can you comment on that ? ( I guess there is a difference , but I think this is related work that should be addressed , particularly Section 5.2 ) # # # Questions/comments on the appendix I think there is a typo that should be fixed on page 22 : you recall that $ A \\oplus B = A \\otimes B + B \\otimes A $ , which is , I think , incorrect . ( and it is the only place where I found a definition for $ \\oplus $ ) On page 24 , you mention more elegant constructions ( what are these construction ? ) . You also claim that you get the tightest bounds for $ \\tau $ . Can you compare these bounds ? Can you prove that you are tighter ? I do not understand the sentence `` we use $ A \\boxplus A $ because of its computational advantages . '' Do you mean algebraic computations ? Computational advantage usually refers to the algorithmic complexity to compute these quantities , but I guess this is not what you are talking about in the sentence . # # # Minor comments : Page 2 maybe define Schur complement Page 3 The notations $ vec $ is not introduced . Page 4 The Kronecker product and sum are not defined Proof of Lemma C.1 there is no n_1 and n_2 Refs : Brock , Andrew , Jeff Donahue , and Karen Simonyan . `` Large scale gan training for high fidelity natural image synthesis . '' arXiv preprint arXiv:1809.11096 ( 2018 ) . Zhang , Guojun , Pascal Poupart , and Yaoliang Yu . `` Optimality and Stability in Non-Convex-Non-Concave Min-Max Optimization . '' arXiv preprint arXiv:2002.11875 ( 2020 ) . Letcher , Alistair . `` On the Impossibility of Global Convergence in Multi-Loss Optimization . '' arXiv preprint arXiv:2005.12649 ( 2020 ) . Jolicoeur-Martineau , Alexia , et al . `` Adversarial score matching and improved sampling for image generation . '' arXiv preprint arXiv:2009.05475 ( 2020 ) .", "rating": "7: Good paper, accept", "reply_text": "Experiments : We do verify local minmax for a number of examples including the Dirac GAN . Moreover , we explored this in the Appendix since this is important with a number of examples which we felt were interpretable such as quadratic , polynomial , and torus games along with a simple generative adversarial network for learning a covariance matrix . Furthermore , for such examples , we confirmed our construction of $ \\tau^ { \\ast } $ was tight and in the supplementary material we included code to compute $ \\tau^ { \\ast } $ . For the generative adversarial networks with image datasets , we did not do this as they are much more computationally intensive and at present there are not great methods for this scale of problem to estimate the eigenvalues . Hence , we focused on performance for those experiments and found we could draw similar insights as from our simple examples as discussed in the experiments section . For the last point , we meant critical point , not equilibrium . We will change this in assumption 1 and in the Theorem 3 statement . Guard map : The definition [ 5 ] does not include this , however , the guard map we construct is continuous . We can add a comment about continuity . Related Work : These are just illustrative examples and not results . They have appeared in various forms across the literature including in [ 1,2,3,4 ] . We will add the citation to [ 4 ] in the paper as well . Questions on Appendix : Yes , that is a typo . It should be $ A\\oplus B=A\\otimes I+I\\otimes B $ . Thanks for the catch ! We will also move this definition up to the main , along with the definition of the vec operator . Regarding the more elegant constructions : We simply meant that you could directly compute $ \\tau^ { \\ast } $ via $ \\text { det } ( - ( J_ { \\tau } ( x^ { \\ast } ) \\oplus J_ { \\tau } ( x^ { \\ast } ) ) ) $ or even via a Lyapunov construction analogous to the approach in the instability proof ( Theorem 2 ) and these are both more \u201c interpretable \u201d than using $ \\text { det } ( - ( J_ { \\tau } ( x^ { \\ast } ) \\boxplus J_ { \\tau } ( x^ { \\ast } ) ) ) $ , since $ \\boxplus $ is not a common operator given that it uses duplication matrices to reduce the dimension of the problem . Specifically on this point , using $ \\boxplus $ actually reduces the computational complexity of finding $ \\tau^ { \\ast } $ since it removes redundancies . That is , the use of $ \\boxplus $ lets us reduce the computational complexity because it takes symmetric operators of say dimension $ n^2 $ and reduces to dimension $ n ( n+1 ) /2 $ . Specifically , the size of the matrix for which you need to solve the eigenvalue problem is of much lower dimension for $ \\boxplus $ versus $ \\oplus $ . The bound is tight because all guard maps by definition vanish for the same real values of the parameter $ \\tau $ ( see [ 6 ] , remark 2 ) , and hence $ \\tau^ { \\ast } $ is independent of the guard map and in our construction there is no approximation introduced . More specific to the question of comparison , as noted all guards by definition produces the same real roots so they would all lead to a tight construction of $ \\tau^ { \\ast } $ but potentially more computationally expensive . We will clarify/formalize this statement as it is an important point . Thanks for highlighting that . Minor comments : Thanks for the pointers . We will address each of these in our revision . [ 1 ] Fiez et al.ICML 2020 , Arxiv 2019 . Implicit Learning Dynamics in Stackelberg Games : Equilibria Characterization , Convergence Analysis , and Empirical Study , Convergence of Learning Dynamics in Stackelberg Games . [ 2 ] Jin et al.ICML 2020 . What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization . [ 3 ] Zhang et al.Arxiv 2020 . Optimality and Stability in Non-Convex-NonConcave Min-Max Optimization . [ 4 ] Mazumdar et al.SIMODS 2020 , Arxiv 2018 . On Gradient-Based Learning in Continuous Games . [ 5 ] Saydy . New stability/performance results for singularly perturbed systems . [ 6 ] Saydy et al.Guardian maps and the generalized stability of parametrized families of matrices and polynomials . [ 7 ] Ratliff et al.2014 Genericity and structural stability of non-degenerate differential Nash equilibria . Allerton . [ 8 ] Mazumdar et al.2019 IEEE CDC . \u2018 Local Nash Equilibria are Isolated , Strict Local Nash Equilibria in \u2018 Almost All \u2019 Zero-Sum Continuous Games \u2019"}], "0": {"review_id": "AWOSz_mMAPx-0", "review_text": "The paper studies the local asymptotic stability of a specific class of solutions points , referred to as strict local minmax equilibria ( or differential Stackelberg equilibria ) , in the case of Gradient Descent-Ascent Dynamics with a finite time-scale separation . The time-scale separation ( \\tau ) is being captured by the ratio of the step-sizes between the min and max agents respectively . Recently , Jin et al.showed the set of asymptotically stable critical points of gradient descent-ascent coincide with the set of differential Stackelberg equilibrium as the time separation goes to infinity . The paper shows that an infinitely large separation is not needed and some finite but large enough separation suffices . The paper provides a close analogue of another previous result by Mescheder about local stability of gradient descent dynamics in GANs under strong technical assumptions . The paper ends with GAN experiments where \\tau=1 , 2 , 4 , 8 are tested and the performance seems to peak at 4 . The paper performs a detailed theoretical analysis of the coupling between GDA and diff Stackelberg equilibria . Although this is positive , the results are not particularly surprising given the prior work . The writing of the paper could also be significantly improved . One issue that I had reading the paper is that at times and especially in the introduction the treatment of ( asymptotically stable ) , stable , unstable fixed points seem to be a little ambiguous.The paper only formally defines locally exponentially stable equilibrium in the preliminaries which is a notion that is not used in the introduction . I think it is important to set early on a clear terminology that is consistent throughout the whole paper . I am also a bit confused about some statements in the paper about which type of solution concepts are game theoretically meaningful . The paper seems to state that any critical point that does not satisfy the definitions of differential Stackelberg equilibria lack game theoretic meaning . From the paper the stable critical points of gradient descent-ascent coincide with the set of differential Stackelberg equilibrium as \\tau goes to infinity . All \u2018 bad critical points \u2019 ( critical points lacking game-theoretic meaning ) become unstable and all \u2018 good critical points \u2019 ( game-theoretically meaningful equilibria ) remain or become stable as \\tau goes to infinity . This seems like a strong statement . It seems to me that min-max solutions of bilinear zero-sum games does not satisfy the differential Stackelberg definition . Such statements would imply that min-max solutions are 1 ) bad critical points and 2 ) lack game theoretic meaning despite being the golden standard of a solution concept in game theory . Maybe I am missing something here ? [ 1 ] has recently shown that alternating GDA with fixed time-separation does not converge in the case of bilinear zero-sum games but is instead recurrent with the min-max equilibrium being stable but not asymptotically stable . This seems to be exactly the setting that you are studying . How are the results of [ 1 ] connected to yours ? I think that due to the tight match between the two settings a thorough discussion is needed . The definitions of differential/strict Nash/Stackelberg equilibria are two of several alternative definition/solution concepts that have only been recently introduced in the context of non-convex non-concave games . The paper should compare and contrast to other notions ideas ( e.g.proximal equilibria are only mentioned briefly [ 2 ] , see also [ 3 ] , [ 4 ] ) . Although one should of course not expect a global convergence as such a result would be too ambitious , the title could be interpreted as such a result by non-specialists . I think it might be better if the term local analysis is used instead . A more thorough discussion about non-convergence results for GDA and variants in zero-sum games could be also helpful [ 1,3,5-8 ] to dispel any possible confusion . In terms of the experimental results why do the simulations stop with \\tau=8 ? The theoretical results as well as the prior work by Jin et . al are supportive of arbitrary large \\tau . What happens e.g.for tau= 2^4 , 2^8 , .... It already seems that performance starts dropping for \\tau > 4 . Does this trend continue ? Does the performance have a unique peak ? or does it fluctuate ? The regularization results ( Theorem 3 ) remain true even for \\tau < < 1 e.g.\\tau = 2^ { -4 } , 2^ { -8 } , ... What would experiments show for such \\tau under regularization ? [ 1 ] Bailey et al.Finite Regret and Cycles with Fixed Step-Sizevia Alternating Gradient Descent-Ascent . COLT 2020 [ 2 ] Farnia et . al Do GANs always have Nash equilibria ? ICML 2020 [ 3 ] Vlatakis-Gkaragkounis et al.Poincar\u00e9 Recurrence , Cycles and Spurious Equilibria in Gradient-Descent-Ascent for Non-Convex Non-Concave Zero-Sum Games . NeurIPS 2019 . [ 4 ] Zhang , et al.Optimality and Stability in Non-Convex-NonConcave Min-Max Optimization . arXiv e-prints , art . arXiv:2002.11875 , February 2020 . [ 5 ] Mertikopoulos et al . `` Cycles in adversarial regularized learning . '' Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms . Society for Industrial and Applied Mathematics , 2018 . [ 6 ] Cheung et al . `` Vortices instead of equilibria in minmax optimization : Chaos and butterfly effects of online learning in zero-sum games . '' arXiv preprint arXiv:1905.08396 ( 2019 ) . [ 7 ] Letcher `` On the Impossibility of Global Convergence in Multi-Loss Optimization . '' arXiv preprint arXiv:2005.12649 ( 2020 ) . [ 8 ] Hsieh , et . al . `` The limits of min-max optimization algorithms : convergence to spurious non-critical sets . '' arXiv preprint arXiv:2006.09065 ( 2020 ) .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer 1 , We just wanted to comment in hopes that you have seen our response to your review , and we would greatly appreciate further comments from you ."}, "1": {"review_id": "AWOSz_mMAPx-1", "review_text": "The main result of the paper states that a strict local minmax point is a stable critical point of t-GDA for some large enough t , and that any non-strict local minmax can be made unstable by s-GDA if we choose s large enough . -Major issues My greatest concern is that the first part of the main result , that a strict local minmax is stable for t-GDA with all large , but finite t , is already known ( Jin et al.2020 ) .Specifically , the proof of Lemma 40 in ( Jin et al.2020 ) shows that for all large enough finite t , the Jacobian of t-GDA only has eigenvalues whose real part is smaller than 0 , which then implies the stability of t-GDA for a finite t. From what I can see , the reason why Jin et al.2020 stated their results in terms of infinite timescale separation is because they did not have a uniform bound on how large the timescale t should be , and therefore in general it can be made as large as possible ( but finite ) . The proof in the current submission has exactly the same feature : for every game , there is a finite t that makes t-GDA stable , but in general this t can be made arbitrarily large . It seems to me that the authors have not qualitatively improved over ( Jin et al.2020 ) ( although I believe the bounds in this paper are tighter ) . In the same vein , the converse statement also more or less appeared in ( Jin et al.2020 ) ; see the proof of Theorem 28 , p.24-25 therein . Due to the above , I can not see the claimed novelty of providing the first finite timescale separation for GDA , hence my rating . I 'm willing to change my score should the authors convince me that I have misunderstand something . -Minor issues 1 . The authors claimed that `` On the empirical side , it has been widely demonstrated that timescale separation in gradient descent-ascent is crucial to improving the solution quality when training generative adversarial networks . '' I believe this is an overstatement of what we currently know about GANs ; see https : //arxiv.org/pdf/1711.10337.pdf for a comprehensive empirical study of the effects on the timescale for GDA , which is not as conclusive as the authors stated . I would therefore suggest to tone down the sentence . 2.Appendix B.3 is quite weird . F ( x_k ) here should be a vector-valued mapping but the authors seem to view it as a function . Also , by F ( k ) = O ( M^k ) , did the authors mean ||x_ { k+1 } \u2212 x * || = O ( M^k ) ? - Post-revision evaluation : The authors have modified the statements of the main theorems as well as including a more detailed comparison to previous works , which clarifies my concern . I have thus increased my score . The technical contributions bring new insight into the studying of scale separation of GDA , and enables a tight characterization of many toy examples . I believe these are solid contributions and should be valued . On the down side , I 'd like to point out that the `` practical implication '' in this paper is a bit of stretch since the ImageNet experiments are run with RMSprop , whereas the analysis of this paper is highly specialized to GDA . Of course , studying adaptive algorithms in min-max games is exceedingly hard and well beyond the scope of this paper . What I recommend the authors is then : 1 . Explicitly notify the readers of the difference between RMSprop and GDA . 2.Find a nontrivial but simple example where 1-GDA provides an okay baseline ( say 7-layer CNNs for mixture of Gaussians or MNIST ) . Increase the time scale to show if it exhibits a similar behavior that a small $ \\tau $ gives the best result . This is directly verifying what the theory is saying , and hence feels more valuable to me .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Regarding minor point on empirical section : While we are happy to tone down the sentence as suggested , we would like to point out that in the cited paper it appears they always have the same learning rate and explore 1 versus 5 rollouts for the discriminator , e.g.which isn \u2019 t necessarily a contradiction of our claim . We are more suggesting that there has been numerous works touting the empirical success of different learning rates between the generator and discriminator and hence our work provides some theoretical backing for this heuristic . This is not to suggest or imply that timescale separation is strictly necessary for all GANs ( as the reference points out , not all GANs are created equal ) . Regarding appendix B.3 : Fair point . There is a conflation of the use of F here which we should not have done . On the one hand $ x_ { k+1 } =F ( x_k ) $ where F defines the dynamics and then in the next sentence F is used as a real valued function . We will change this so that $ x_ { k+1 } =h ( x_k ) $ some different function and then use F ( k ) to be a scalar value function such as the norm $ \\|x_k-x * \\| $ , e.g.The point was to define how big O , is being used in our convergence rates , but perhaps this is common enough that a reference would suffice . [ 1 ] Jin et al.arxiv 1902.00618 ( published ICML 2020 ) . What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization . [ 2 ] Kokotovic et al ( see , Chapter 3 ) . 1986.Singular Perturbation Methods in Control Analysis and Design ."}, "2": {"review_id": "AWOSz_mMAPx-2", "review_text": "Motivated by the many applications of min-max optimization problems in Machine Learning , the authors examine the effect of using different learning rates for each player in Gradient Descent Ascent ( GDA ) for non-convex non-concave optimization problems . Prior work has already established that making the learning rate of one player infinitely larger than other player 's learning rate alleviates the cycling problems of GDA and makes game-theoretically meaningful equilibria the only asymptotically stable fixed points . The main contribution of this work is that it proves that we can get the same stability guarantees while keeping the learning rates of both players finite . This is crucial for practical applications where using unbounded learning rates in not an option . The authors employ this result to prove a variety of local convergence results in both deterministic ans stochastic settings . Pros : 1 ) The finite time scale separation is necessary in order to make the theoretical intuitions in prior work applicable for practical problems like trainings GANs . 2 ) The proof techniques used for this separation results are , to the best of my knowledge , significantly different and elaborate than the ones used in prior work ( Jin et al. , 2020 ) . 3 ) The theoretical findings are complemented with empirical evaluations both on small min-max problems and on complex ones like training GAN architectures . Cons : Theorem 28 in the arxiv version of Jin et al.2020 does not explicitly reference the existence of a finite time scale that satisfies their inclusion results . However , it is clear from the proof of Theorem 28 on page 24 that such a finite time-scale separation exists even though they do not provide an explicit formula for it . At least for one of the inclusion statements they explicitly mention that it holds for $ \\epsilon < \\epsilon_0 $ for some $ \\epsilon_0 $ where $ \\epsilon $ corresponds to $ 1/\\tau $ . Of course the result of the authors gives a more direct construction of the threshold $ \\tau^ * $ by reducing the search for it to an eignenvalue problem . From a practical standpoint though , both results are existential . Neither proof approach gives particular intuition on how this time scale can be found in a computationally efficient way . The added value of leveraging an array of mathematical tools to provide this explicit construction is unclear to me . Given the above concern and that the convergence results essentially leverage the asymptotic stability properties provided by Theorems 1 and 2 , I am assigning a weak reject score . However , I am willing to substantially increase my score if the authors address the above concern .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your review . Please see the common response to you and R3 for a detailed comment regarding the primary con you have listed . We hope this can clear up your concern and make it clear that the results you refer to from past work can only be thought of in the asymptotic sense and we make a significant advance by providing a tight non-asymptotic construction . As you mentioned in the beginning of your review , this is extremely important for practical applications where using unbounded learning rates is not an option . Below we address more specific aspects of your review to hopefully provide further clarification . In your review you state : `` Of course the result of the authors gives a more direct construction of the threshold $ \\tau^ { \\ast } $ by reducing the search for it to an eigenvalue problem . From a practical standpoint though , both results are existential . '' The construction of $ \\tau^ { \\ast } $ we provide is in fact not comparable to anything from [ 1 ] . This is because there is no construction given in [ 1 ] since it is an asymptotic result and is only stating local stability for GDA when $ \\tau\\rightarrow \\infty $ . Please refer back to the general response to you and reviewer 3 for more details . Moreover , our result is not only existential , but it is also constructive . From a practical standpoint , this is major difference and is important . From an existential point of view alone , our result is useful since it is saying that a finite timescale separation , which importantly results in an implementable algorithm as opposed to a timescale separation approaching infinity , can guarantee the type of convergence we would desire . Then , from a constructive point of view , since we can exactly compute $ \\tau^ { \\ast } $ , we can explore many types of problems to gain insights into what we can generally expect as necessary or sufficient for the desired behavior . We in fact did this for the many simpler experiments we ran , and found that the theoretical construction of $ \\tau^ { \\ast } $ was also tight as the theory would suggest and furthermore $ \\tau^ { \\ast } $ is often a reasonable finite value that allows for a range of learning for the discrete time update to converge to local minmax ( which would not be feasible if the timescale separation needed to actually approach infinity ) . This is helpful because it can inform heuristics for more complicated problems such as training generative adversarial networks as well as explain the success of heuristics that are already frequently deployed . To give a concrete example , we found that the insights we gained from the simple Dirac-GAN example turned out to effectively match up with what we observed in the performance of the generative adversarial network training experiments for various hyperparameter settings . Regarding \u201c The added value of leveraging an array of mathematical tools to provide this explicit construction is unclear to me. \u201d As noted in our general response to you and reviewer 3 , the new tools in our paper expose a number of opportunities for analyzing multiple hyperparameters as we demonstrate with Theorem 3 on generative adversarial networks . Moreover , also as noted above , because of the explicit construction allowed by these tools , we are able to see that 1 ) in practice the value of $ \\tau^\\ast $ is generally not large and 2 ) we can optimize for convergence rate by exploring the tradeoff between the choice of finite $ \\tau $ and the learning rate $ \\gamma_1 $ . The review says : \u201c The convergence results essentially leverage the asymptotic stability properties provided by Theorems 1 and 2. \u201d We believe that our convergence results are actually more meaningful than just thinking of them as asymptotic convergence in the neighborhood of a asymptotically stable equilibrium . To get this result , there are in fact several steps and it does not follow trivially from Theorems 1 and 2 . This is because $ J_ { \\tau } ( x^ { \\ast } ) $ has complex eigenvalues , so to obtain rates that do not assume $ J_ { \\tau } ( x^ { \\ast } ) $ has a positive definite symmetric part ( which is required to use the normal 2 norm convergence rate analysis techniques ) , we formulate an optimization problem for finding the stepsize given $ \\tau > \\tau^ { \\ast } $ that maximizes the spectral radius of the local linearization $ I-\\gamma_1 J_ { \\tau } ( x * ) $ . Furthermore , this analysis also includes an estimate on the region of convergence . Finally , we note that we have a number of other results including specializing to generative adversarial networks in Theorem 3 , extensive numerical experiments that range from interpretable and informative to large-scale training , results on the stochastic setting where we get almost sure asymptotic convergence using less restrictive stepsize assumptions than is typical since we do not need a two-timescale sequence given $ \\tau^ { \\ast } $ . [ 1 ] Jin et al.Arxiv 1902.00618 ( published in ICML 2020 ) . What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization ."}, "3": {"review_id": "AWOSz_mMAPx-3", "review_text": "# # Summary This paper studies the stable points of gradient descent ascent with different step-sizes . Roughly , this paper 's main result is that for any fixed point for the GDA dynamics , that point is stable for GDA with a large enough timescale separation if and only if it is a local Stackelberg equilibrium . This result is quite intuitive since a similar result has been proved by Jin et al.2020 . ( the timescale had to go to infinity ) . Though , proving such a result for a * finite * timescale separation is a major improvement and is related to practical significant considerations . # # Pros and cons Strengths : the work is well motivated , and overall the paper is well written . Though if I think some of the technical aspects could be improved . The results may interest the community . The theoretical tools introduced could be used in other theoretical work . weaknesses : Some of the theory sections could be more developed to build intuitions on the phenomenon going on . It seems really hard for me to follow the current proof sketches since many notations are not properly introduced ( or at least any intuition about what they mean is proposed ) . ( see my section on questions/ comments ) The experiments are not really related to the theory . ( see my section about experiments ) I have some technical concerns and questions ( I would be glad if the authors can answer them ; see my section on questions ) The conclusion is overstating the results of the paper . # # Overall review Overall , this paper is a good paper that should be accepted if the authors fix some statements in the conclusion section and answer my questions about the theory . Also , the experimental section could be improved ( not by running more large scale experiments but by more related to the theory presented ) # # Questions and comments ( by decreasing order of importance ) : # # # technical question The most important question I have regards the guardian map you use . In the proof sketch of Theorem 1 where you state that the map $ \\nu ( \\tau ) : = det ( - ( J_\\tau \\oplus J_\\tau ) ) $ is a guardian map of $ \\mathcal { S } ( \\mathbb { C_-^\\circ } ) $ but if we look at lemma C.1 the result boils down to the fact that the eigenvalues of $ A \\oplus A $ are $ ( \\lambda_i + \\lambda_j ) $ with $ \\lambda_i , \\lambda_j \\in Sp ( A ) ) $ . However , it means that if $ A $ has a single eigenvalue in $ \\mathbb { C_-^\\circ } $ , then $ \\nu ( A ) $ is non zero . Some arguments should be added ( since $ A $ is a real matrix , the non-real eigenvalues are complex conjugates ) to justify that the only problematic case is when $ A $ has $ 0 $ as an eigenvalue . One quick fix would be to consider $ \\nu ( A ) : = det ( A ) det ( - ( A\\oplus A ) ) $ as guardian map $ . But I do not know how it would change the derivations in the proof of claim C.1 . I am quite novel with these notions , so my questions are : Am I missing something ? If yes , what ? If not , would the fix work , and will it change the results of Theorem 1 and 2 ? # # # Conclusion In the conclusion section , you write , \u201c We proves gradient descent-ascent converges to a critical point for a range of finite learning rate ratios if and only if the critical point is a differential Stackelberg equilibrium . This answers a standing open question about the convergence of first-order methods to local minimax equilibria. \u201d These two sentences may be misleading for the following reasons : - you only prove a * local * convergence result - The local distinction is important because the method can still cycle outside of these neighborhoods . ( see for instance [ Letcher 2020 ] ) - Also , the value of $ \\tau $ depends on the neighborhood . So it seems that you may have an infinite number of critical points , and the value of \\tau to globally ( max of the \\tau for each critical point ) only has local convergence to local minimax may be infinite . Do you agree with that statement ? # # # Experiments Your theory is about the nature of the stationary points found by the training dynamics ( are they theoretically meaningful ) , but you do not verify that training with different learning rates actually finds local minimax . Moreover , it is known that using different learning rates is necessary to get better empirical performances ( see , for instance [ Brock et al.2019 , Jolicoeur-Martineau et al.2020 ] or most of the SOTA results on https : //paperswithcode.com/paper/adversarial-score-matching-and-improved ) . I think that one experiment that would support your theory would be about looking at the eigenvalues of J_\\tau around the \u201c practical equilibria \u201d for different values of $ \\tau $ and see if you only get local minimax for large enough $ \\tau $ . In Assumption 1 , you suppose that $ ( w , \\theta ) $ is an equilibrium . But what kind of equilibrium ? Nash ? What do you need ? That it is a stationary point of the dynamics ? # # # About guardian maps Shouldn \u2019 t you add in the definition of a guardian map that the map is continuous ? # # # Related work Your examples 1 and 2 look very similar to the ones proposed by Zhang et al.2020 in section 5.2 . Can you comment on that ? ( I guess there is a difference , but I think this is related work that should be addressed , particularly Section 5.2 ) # # # Questions/comments on the appendix I think there is a typo that should be fixed on page 22 : you recall that $ A \\oplus B = A \\otimes B + B \\otimes A $ , which is , I think , incorrect . ( and it is the only place where I found a definition for $ \\oplus $ ) On page 24 , you mention more elegant constructions ( what are these construction ? ) . You also claim that you get the tightest bounds for $ \\tau $ . Can you compare these bounds ? Can you prove that you are tighter ? I do not understand the sentence `` we use $ A \\boxplus A $ because of its computational advantages . '' Do you mean algebraic computations ? Computational advantage usually refers to the algorithmic complexity to compute these quantities , but I guess this is not what you are talking about in the sentence . # # # Minor comments : Page 2 maybe define Schur complement Page 3 The notations $ vec $ is not introduced . Page 4 The Kronecker product and sum are not defined Proof of Lemma C.1 there is no n_1 and n_2 Refs : Brock , Andrew , Jeff Donahue , and Karen Simonyan . `` Large scale gan training for high fidelity natural image synthesis . '' arXiv preprint arXiv:1809.11096 ( 2018 ) . Zhang , Guojun , Pascal Poupart , and Yaoliang Yu . `` Optimality and Stability in Non-Convex-Non-Concave Min-Max Optimization . '' arXiv preprint arXiv:2002.11875 ( 2020 ) . Letcher , Alistair . `` On the Impossibility of Global Convergence in Multi-Loss Optimization . '' arXiv preprint arXiv:2005.12649 ( 2020 ) . Jolicoeur-Martineau , Alexia , et al . `` Adversarial score matching and improved sampling for image generation . '' arXiv preprint arXiv:2009.05475 ( 2020 ) .", "rating": "7: Good paper, accept", "reply_text": "Experiments : We do verify local minmax for a number of examples including the Dirac GAN . Moreover , we explored this in the Appendix since this is important with a number of examples which we felt were interpretable such as quadratic , polynomial , and torus games along with a simple generative adversarial network for learning a covariance matrix . Furthermore , for such examples , we confirmed our construction of $ \\tau^ { \\ast } $ was tight and in the supplementary material we included code to compute $ \\tau^ { \\ast } $ . For the generative adversarial networks with image datasets , we did not do this as they are much more computationally intensive and at present there are not great methods for this scale of problem to estimate the eigenvalues . Hence , we focused on performance for those experiments and found we could draw similar insights as from our simple examples as discussed in the experiments section . For the last point , we meant critical point , not equilibrium . We will change this in assumption 1 and in the Theorem 3 statement . Guard map : The definition [ 5 ] does not include this , however , the guard map we construct is continuous . We can add a comment about continuity . Related Work : These are just illustrative examples and not results . They have appeared in various forms across the literature including in [ 1,2,3,4 ] . We will add the citation to [ 4 ] in the paper as well . Questions on Appendix : Yes , that is a typo . It should be $ A\\oplus B=A\\otimes I+I\\otimes B $ . Thanks for the catch ! We will also move this definition up to the main , along with the definition of the vec operator . Regarding the more elegant constructions : We simply meant that you could directly compute $ \\tau^ { \\ast } $ via $ \\text { det } ( - ( J_ { \\tau } ( x^ { \\ast } ) \\oplus J_ { \\tau } ( x^ { \\ast } ) ) ) $ or even via a Lyapunov construction analogous to the approach in the instability proof ( Theorem 2 ) and these are both more \u201c interpretable \u201d than using $ \\text { det } ( - ( J_ { \\tau } ( x^ { \\ast } ) \\boxplus J_ { \\tau } ( x^ { \\ast } ) ) ) $ , since $ \\boxplus $ is not a common operator given that it uses duplication matrices to reduce the dimension of the problem . Specifically on this point , using $ \\boxplus $ actually reduces the computational complexity of finding $ \\tau^ { \\ast } $ since it removes redundancies . That is , the use of $ \\boxplus $ lets us reduce the computational complexity because it takes symmetric operators of say dimension $ n^2 $ and reduces to dimension $ n ( n+1 ) /2 $ . Specifically , the size of the matrix for which you need to solve the eigenvalue problem is of much lower dimension for $ \\boxplus $ versus $ \\oplus $ . The bound is tight because all guard maps by definition vanish for the same real values of the parameter $ \\tau $ ( see [ 6 ] , remark 2 ) , and hence $ \\tau^ { \\ast } $ is independent of the guard map and in our construction there is no approximation introduced . More specific to the question of comparison , as noted all guards by definition produces the same real roots so they would all lead to a tight construction of $ \\tau^ { \\ast } $ but potentially more computationally expensive . We will clarify/formalize this statement as it is an important point . Thanks for highlighting that . Minor comments : Thanks for the pointers . We will address each of these in our revision . [ 1 ] Fiez et al.ICML 2020 , Arxiv 2019 . Implicit Learning Dynamics in Stackelberg Games : Equilibria Characterization , Convergence Analysis , and Empirical Study , Convergence of Learning Dynamics in Stackelberg Games . [ 2 ] Jin et al.ICML 2020 . What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization . [ 3 ] Zhang et al.Arxiv 2020 . Optimality and Stability in Non-Convex-NonConcave Min-Max Optimization . [ 4 ] Mazumdar et al.SIMODS 2020 , Arxiv 2018 . On Gradient-Based Learning in Continuous Games . [ 5 ] Saydy . New stability/performance results for singularly perturbed systems . [ 6 ] Saydy et al.Guardian maps and the generalized stability of parametrized families of matrices and polynomials . [ 7 ] Ratliff et al.2014 Genericity and structural stability of non-degenerate differential Nash equilibria . Allerton . [ 8 ] Mazumdar et al.2019 IEEE CDC . \u2018 Local Nash Equilibria are Isolated , Strict Local Nash Equilibria in \u2018 Almost All \u2019 Zero-Sum Continuous Games \u2019"}}