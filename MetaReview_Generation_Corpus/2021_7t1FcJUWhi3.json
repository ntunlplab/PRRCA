{"year": "2021", "forum": "7t1FcJUWhi3", "title": "Neural Networks for Learning Counterfactual G-Invariances from Single Environments", "decision": "Accept (Poster)", "meta_review": "Pros:\n- All reviewers agreed that the idea was particularly interesting/novel. I personally appreciated the perspective of unlearning invariances that prove inconsistent with the training data, rather than learning invariances that are demonstrated by the training data.\n- The authors significantly improved clarity during the rebuttal period, and two out of three reviewers raised scores or confidence as a result.\n\nCons:\n- There were significant concerns raised by reviewers about clarity of presentation, and some concern around whether the specific instantiation of the high level idea was the most sensible. From a *lightweight* reading of the paper on my part, I also feel that the writing style is unnecessarily dense, though I believe the underlying ideas are solid.\n- One of the reviewers (AnonReviewer4) continues to have serious concerns. I believe the authors and AnonReviewer4 may have both become more entrenched in their positions during the discussion, in a way that wasn't particularly productive.\n\nThis paper is borderline score-wise. I believe it is particularly important to reward and encourage unusually novel work. Primarily for this reason I bias my decision upwards, and recommend acceptance.\n\nnit: belive --> believe", "reviews": [{"review_id": "7t1FcJUWhi3-0", "review_text": "Summary : A method is given for training neural networks in the presence of a group of transformations , such that the network weights are invariant with respect to any transformation on the inputs which does n't contradict the training data . Experiments on MNIST and toy sequence data are used to verify that this training method leads to improved extrapolation of predictions to unseen environments . Strengths : The method introduced seems promising , as it does n't require training data to exhibit symmetry , but can still verify ( or reject ) the invariance of data with respect to a collection of candidate symmetry groups . The training method also seems quite lightweight , and should n't require significant additional resources to check for the presence or absence of symmetry . Although the experiments are a bit limited , the authors include a detailed experiments section in the appendix with a larger selection of baselines and more information about choosing the magnitude of the applied CG-regularization . Critiques : The explanation of the results has a lot of room for improvement , and I would recommend the authors revise the writing to follow standard best practices , such as defining/explaining new variables when they are introduced , giving the steps associated with novel algorithms , etc . I give a few specific examples below where this lack of clarity makes the authors ' results hard to understand , but there are many other examples of this not listed . The description of the underlying causal model in section 3 ( from the end of page 3 to the start of page 5 ) is hard to follow owing to a lack of explanation in many places . For example , the overgroups $ G_D $ and $ G_I $ are introduced without any insight into the distinction between these groups , or what role they play in the context of extrapolation tasks . Similarly , the central concept of CG-invariance lacks some crucial details in its definition ( Def 2 ) , making the following material harder to follow . In particular , it is n't stated if CG-invariance is defined relative to a specific $ \\tilde { U } _I $ , or else requires Eq.6 to hold for any choice of $ \\tilde { U } _I $ ( the latent distribution which determines the counterfactual samples $ X^ { cf } $ ) . Theorem 3 is difficult to make sense of , with the subspaces $ B_M $ appearing at first glance to be circularly defined ( the projection in Eq.9 used to define the $ B_M $ is itself defined in terms of these subspaces ) . The text below and above Theorem 3 helps to interpret this circularity as an inductive algorithm for calculating these subspaces , but it would have been much clearer to define this algorithm explicitly in terms of pseudocode ( along with a runtime ) , and then reference this definition in Theorem 3 . Recommendation : Although the techniques seem like a timely and useful contribution , the poor presentation makes these techniques difficult to follow , and limits the usefulness of the paper for readers . I 'm recommending a weak accept , but this can be improved by clarifying the presentation and making the results easier for readers to understand . * * UPDATE AFTER THE REBUTTAL : * * The new material in the paper clarifies things quite a bit , especially the intuitive explanations appearing below Equation 2 and at the bottom of page 4 . Thank you for adding that , I have changed my score accordingly : )", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the constructive comments and helpful feedback . We would like to emphasize the timeliness of our contribution w.r.t.recent findings about DNNs extrapolations ( learning spurious correlations and shortcut learning ( see our Section 6 , Arjovsky et al . ( 2019 ) , D \u2019 Amour et al . ( 2020 ) , de Haan et al . ( 2019 ) , Geirhos et al . ( 2020 ) , McCoy et al . ( 2019 ) , and Sch\u00f6lkopf ( 2019 ) among many others ) ) , with a special emphasis in the large-scale study that came out this week from Google ( D \u2019 Amour et al . ( 2020 ) ) .Q1 ) \u201c The explanation of the results has a lot of room for improvement , and I would recommend the authors revise the writing to follow standard best practices , such as defining/explaining new variables when they are introduced , giving the steps associated with novel algorithms , etc . I give a few specific examples below where this lack of clarity makes the authors ' results hard to understand , but there are many other examples of this not listed. \u201d A1 . We have provided additional explanations throughout the paper . We have streamlined Section 3 and added the graph of the SCM ( Figure 1 ) . In Section 4 , we have updated the text around Theorem 3 to clarify the objectives of the theorem and present a pseudocode in the Appendix . We have also clarified the intuitions behind the regularization penalty ( Equation 12 ) and show an example computation of the penalty in Figure 6 of the Supplementary Material . We have updated Section 5 with more details about the architectures . In Section 6 , we provide a running example to clarify the experimental details . Q2 ) \u201c The description of the underlying causal model in section 3 ( from the end of page 3 to the start of page 5 ) is hard to follow owing to a lack of explanation in many places . For example , the overgroups GD and GI are introduced without any insight into the distinction between these groups , or what role they play in the context of extrapolation tasks. \u201d A2 . We have updated this section making it easier to follow and have included a graph of the structural causal model in Figure 1 . We have clarified the role of groups $ \\\\mathcal { G } \\_D $ and $ \\\\mathcal { G } \\_I $ : the target variable is defined as being invariant to the group $ \\\\mathcal { G } \\_I $ but dependent on the group $ \\\\mathcal { G } \\_D $ . Q3 ) \u201c Similarly , the central concept of CG-invariance lacks some crucial details in its definition ( Def 2 ) , making the following material harder to follow . In particular , it is n't stated if CG-invariance is defined relative to a specific U\\~I , or else requires Eq.6 to hold for any choice of U\\~I ( the latent distribution which determines the counterfactual samples Xcf ) . \u201d A3 . We have updated Definition 1 ( Counterfactual coupling ) to make it clear that $ X^\\\\text { ( cf ) } $ is obtained by counterfactually replacing $ U\\_\\\\mathcal { I } $ by any choice of $ \\\\tilde { U } \\_\\\\mathcal { I } $ in the SCM equations . Then Definition 2 ( CG-invariant representations ) is tied to that choice of $ \\\\tilde { U } \\_\\\\mathcal { I } $ from Definition 1 . Q4 ) Theorem 3 is difficult to make sense of , with the subspaces BM appearing at first glance to be circularly defined ( the projection in Eq.9 used to define the BM is itself defined in terms of these subspaces ) . The text below and above Theorem 3 helps to interpret this circularity as an inductive algorithm for calculating these subspaces , but it would have been much clearer to define this algorithm explicitly in terms of pseudocode ( along with a runtime ) , and then reference this definition in Theorem 3 . A4.We have updated the text around Theorem 3 to describe the two goals of the Theorem : We wish to construct bases $ \\\\mathcal { B } \\_M $ for all $ M \\\\subseteq \\\\ { 1 , \\\\ldots , m\\\\ } $ such that any weight vector $ \\\\mathbf { w } \\\\in \\\\mathcal { B } \\_M $ is * * ( a ) * * invariant to the groups $ \\\\mathcal { G } \\_i $ for $ i\\\\in M $ , and * * ( b ) * * not invariant to any group $ j \\\\in \\\\ { 1 , \\\\ldots , m\\\\ } \\\\setminus M $ } . $ \\\\tilde { \\\\mathcal { B } } \\_M $ contains all the vectors $ \\\\mathbf { w } $ that are invariant to $ \\\\mathcal { G } \\_M $ but could also contain vectors that are invariant to some overgroup of $ \\\\mathcal { G } \\_M $ . Thus , each step of our inductive method performs a Gram-Schmidt orthogonalization in order to satisfy condition * * ( b ) * * above : we need to remove from $ \\\\tilde { \\\\mathcal { B } } \\_M $ all weight vectors that are invariant to more groups in addition to those indexed by $ M $ ( i.e. , supersets of $ M $ ) . We also refer the reader to a pseudocode in Appendix C ."}, {"review_id": "7t1FcJUWhi3-1", "review_text": "POST REBUTTAL UPDATE : I am increasing my confidence in this paper from 2 to 3 - I still believe the paper can use some more clarity but enough points have been explained and updated in the draft for me to feel more confident in my evaluation . I think the ideas in this paper are quite interesting - for this reason I continue to recommend acceptance . Summary : This paper describes an approach to embedded invariances in learned neural networks through defining linear automorphism groups . They define a fair amount of theoretical machinery for this task , proposing a model of image generation which includes a number of transformations from these defined groups , and defining the notion of a counterfactual G-invariance for the task . They discuss a method for practically learning a useful invariance even if that exact invariance you wish to have is unknown , by ordering subspaces which may be invariant , and discusses the practicalities of embedding these into neural architectures . Some experiments are described in an MNIST setting and on simulated experiments , showing success at embedding these invariances in toy-ish settings . Recommendation : I \u2019 m recommending acceptance for the paper , since the ideas seem interesting , there appears to be theoretical contribution and empirical evidence , and it is obviously written with care . My hesitance comes on two fronts : I may be lacking some background in the relevant group theory/invariance literature , and it is hard for me to understand a number of important ideas due to the information density in the writing ( a result of ICLR restrictions but also some fault of the authors ) . Strong points : - The paper is very detailed and interesting \u2013 while I am not particularly familiar with the group theory side of the literature , it seems like a good idea from a robustness perspective and the authors lay out their ideas carefully - The notion of assuming an invariance unless contradicted is interesting at a high level , and provides some meat to the oft-discussed notion of \u201c extrapolation from a single environment \u201d - I appreciate the bridge made from the theory to the practical implementation - The experiments mostly back up the point the authors assert in their theory \u2013 larger experiments for a mostly theoretical paper like this are not necessarily required Weak points : - My sense is the authors are having a lot of trouble fitting their ideas into the 8 pages . I sympathize but I also think they can do better on this front \u2013 the first two pages can be much more compact , with more space to explicate complex ideas that get swept over quickly - Ideas which do not receive enough attention or explanation ( but should ) include : Eq 2 , Theorem 3 , the design of neural network weights , and even the bare minimum of experimental details . I know the format is short but some of this stuff is necessary , and I believe the authors can do better in terms of fitting important information in . As it is I am confused about some central ideas , even after checking the appendix - The notion of \u201c forbidding examples in the learner \u2019 s statistical model \u201d carries some intuitive weight but is not precise \u2013 what is this model for a discriminative classifier ? This can be more clearly explicated - It \u2019 s not clear how much is packed in the \u201c economical data generation \u201d assumption , or how that is really connected to the method . Please be more clear . - The definition of $ T_ { { U_D , U_I } } $ is not really clear \u2013 need another sentence on this indexing in the main body , as well as discussion of ordering ! - Def 1 : you don \u2019 t actually define what it means for 2 variables to be counterfactually coupled , you just show what a counterfactual coupling is . Please reword this definition . - Thm 3 \u2013 this is incredibly dense and I have a lot of trouble parsing this . I \u2019 m not sure how to interpret the direct sum \u2013 you \u2019 re combining all the subspaces which are supersets of M ? Also not sure about the end \u2013 this is not G_j -invariant for j \\in M-bar . What is M-bar ? Is that a Reynolds operator ? Then what does it mean for j to be an element of it ? - How should I pick my groups G_1 \u2026 m ? Not clear if this is important - Bottom of p6 : not clear how these neuron weights are specified \u2013 does it matter which layer we are in ? what does the product of B_m \\omega_M , h mean \u2013 it looks like a subspace times a real number - Sec 5 : I really am confused about the relationship between architecture and which invariances can be realizable . There \u2019 s not a lot of explanation on this . - Sec 6 : it \u2019 s very hard to interpret anything in this section without the appendix \u2013 work more to make it stand alone - Proof of Thm 1 : maybe I am missing some group theory background but I don \u2019 t understand this . For instance , there is no explanation of why this $ \\tilde { U } _I $ can always be found to couple X^cf with X^obs . - Proof of Lemma 1 : Again , may be missing some background . But neither x nor $ \\bar { T } $ is mentioned in this proof , so I don \u2019 t know where it is going \u2013 please be more verbose . Clarifications : - Middle of p3 \u2013 we can \u201c compose rotations and image flips \u201d \u2013 do you mean a union of the two sets of transformations ? That \u2019 s what is shown in the notation but I may be missing some group theory background here - Top of p4 : not clear how $ G_D \\cap G_I \\neq 0 $ is possible \u2013 is the idea that $ G_i \\cap G_j $ might be nonempty ? - Below Eq 3 : \u201c the training data may contaion on a few samples of the variable \u201d \u2013 do you mean only a few values of the variable may be observed ? - Below Eq 3 : you use the term environment without defining it , not sure how to interpret it in this context - Below Eq 7 : should the samples of $ \\hat { Y } \\ X^ { ( obs ) } $ be Y instead ? - Below Eq 7 : in ( i ) you say you don \u2019 t know the group \u2013 do you mean for which group Y should be considered invariant ? If so , state that explicitly - It \u2019 s not clear how the statistical assumption at the end of Sec 3 really fits in with the argument , if you \u2019 re going to use it need more here - Top of p6 \u2013 you say the eigenspace of the Reynolds operator gives us a way to build an invariant NN , but the Lemma is about a linear operator . Need more description here - You say the method in Thm 3 is fast but the power set should grow exponentially \u2013 is that a problem ? Other feedback : - Not sure why you define g as going to the image of the probability \u2013 can \u2019 t it just be [ 0 , 1 ] ? - Not sure \u201c unseen is forbidden \u201d is quite right \u2013 wouldn \u2019 t it be \u201c unseen is irrelevant \u201d or something ? - Specify whether Thm 1 only applies to linear automorphisms or if it is more general - The recursion at the bottom of Sec 4 is unreadable \u2013 just put this in the appendix - Bottom of p17 \u2013 describe more how the transformations are sampled . I shouldn \u2019 t have to work so hard to understand the experiments", "rating": "7: Good paper, accept", "reply_text": "Q14 ) \u201c 'the training data may contain only a few samples of the variable ' \u2013 do you mean only a few values of the variable may be observed ? '' A14.We have clarified as follows : If the support of $ U\\_\\\\mathcal { I } $ is a singleton set $ \\\\ { c\\\\ } $ for some constant $ c $ , then $ ( Y , X^\\\\text { ( obs ) } ) $ are said to be sampled using an economical data generation process . In other words , the training data can contain just one value for the variable $ U\\_\\\\mathcal { I } $ since the outputs $ Y $ do not depend on $ U\\_\\\\mathcal { I } $ . Q15 ) \u201c Below Eq 3 : you use the term environment without defining it , not sure how to interpret it in this context \u201d A15 . In our context , different environments correspond to different supports of $ U\\_\\\\mathcal { I } $ . The economical data generation process with a singleton support for $ U\\_\\\\mathcal { I } $ results in a single environment . For example , if $ Y $ is invariant to 90-degree rotations , then the set of upright images form one environment and the set of upside-down images can form another environment . Q16 ) \u201c Below Eq 7 : should the samples of $ \\\\hat { Y } | X^ { ( obs ) } $ be Y instead ? \u201d A16 . This was a typo . We have updated the notation in Section 3 : $ Y | X^\\\\text { ( tr ) } $ refers to the distribution in training and $ Y | X^\\\\text { ( te ) } $ refers to the distribution in test . Q17 ) \u201c Below Eq 7 ( new equation number ( 6 ) ) : in ( i ) you say you don \u2019 t know the group \u2013 do you mean for which group Y should be considered invariant ? \u201d A17 . Yes , we do not know $ \\\\mathcal { I } $ ( or $ \\\\mathcal { G } \\_\\\\mathcal { I } $ ) , thus we do not know which group $ Y $ should be invariant to . Q18 ) \u201c It \u2019 s not clear how the statistical assumption at the end of Sec 3 really fits in with the argument , if you \u2019 re going to use it need more here \u201d A18 . We have clarified below Definition 1 that $ \\\\tilde { U } \\_\\\\mathcal { I } $ can have very different support than $ U\\_\\\\mathcal { I } $ . Since $ \\\\tilde { U } \\_\\\\mathcal { I } $ , and thus $ X^\\\\text { ( cf ) } $ , are not observed , the statistical assumption at the end of Section 3 hinders learning of $ \\\\Gamma\\_\\\\text { true } $ . We believe that this is clear to the reader in the updated manuscript . Q19 ) `` Top of p6 \u2013 you say the eigenspace of the Reynolds operator gives us a way to build an invariant NN , but the Lemma is about a linear operator . '' A19.The Lemma describes a single neuron . If the first layer of a neural network is composed of these neurons and thus , is G-invariant , then we can use dense layers and non-linear activations on top of the first layer to obtain a G-invariant neural network . Q20 ) \u201c You say the method in Thm 3 is fast but the power set should grow exponentially \u2013 is that a problem ? \u201d A20 . Practically , this does not pose a problem for two reasons : * * ( 1 ) * * Theorem 3 will stop after finding $ \\\\text { dim } ( \\\\text { vec } ( \\\\mathcal { X } ) ) $ number of bases ( which does not depend on the number of groups ) , so it need not iterate over the entire power set . However , it is unclear whether the worst-case exponential runtime can actually happen in practice . * * ( 2 ) * * Regardless , for a collection of groups , we would only need to compute the bases once and reuse them for all experiments . We have added this to the paper . Other feedback : Q21 ) `` Not sure why you define g as going to the image of the probability \u2013 can \u2019 t it just be [ 0 , 1 ] ? '' A21. $ g $ returns a probability measure over the entire space of $ Y $ . In classification for example , $ g $ returns the probabilities for all the classes . Q22 ) \u201c Not sure \u2018 unseen is forbidden \u2019 is quite right \u2013 wouldn \u2019 t it be \u2018 unseen is irrelevant \u2019 or something ? \u201d A22 . We have replaced the phrase with \u2018 unseen-is-unknown \u2019 to represent the fact that examples not explicitly observed with infinitely many training examples have undefined/unknown outcomes in the learner \u2019 s model . Q23 ) \u201c Specify whether Thm 1 only applies to linear automorphisms or if it is more general \u201d A23 . Theorems 1 & 2 also apply to groups with non-linear automorphisms . However , to be consistent with the rest of the paper , we only discuss linear automorphisms . Q24 ) \u201c The recursion at the bottom of Sec 4 is unreadable \u2013 just put this in the appendix \u201d A24 . We have moved the differentiable approximation of the penalty to the Appendix and updated Section 4 with an intuition for the penalty instead . Q25 ) \u201c Bottom of p17 \u2013 describe more how the transformations are sampled . I shouldn \u2019 t have to work so hard to understand the experiments \u201d A25 . We have updated Appendix F.1 further clarifying how the transformations are sampled to construct the training and test datasets ."}, {"review_id": "7t1FcJUWhi3-2", "review_text": "This paper proposes an interesting and potentially quite impactful and valuable idea , which I believe is novel . The idea is : instead of specifying invariances by hand in the architecture of a network , we can instead specify a set of possible invariances , and regularize the model to favor more invariance . The authors describe how to structure and regularize a DNN in this way , and provide proof-of-concept experiments . The experiments show that the proposed method outperforms networks that are fully-invariant or non-invariant when the true data is partially-invariant . Unfortunately , there are a number of weaknesses which lead me to recommend against acceptance . In no particular order : 1 ) The crucial `` unseen is forbidden '' hypothesis is vague and seems to be a bit of a strawman . 2 ) The framing of the paper seems to oversell the method in a way that makes the contribution less clear . 3 ) The writing is not very clear . 4 ) The experiments seem to be only proof-of-concept in scenarios where the method is designed to work . 5 ) The method seems to incur an exponential cost , but this is not discussed . Elaborating : 1 ) The authors claim that , because DNN behavior is undefined on unseen datapoints , the `` unseen-is-forbidden learning hypothesis is currently preventing neural networks from assuming symmetric extrapolations without evidence . '' This claim is stated in various forms several times , but never made very precise , and it is crucial in motivating the authors ' approach . Roughly , I take the authors to be claiming that ( i ) the correct way to `` extrapolate '' is to assume that : transformations that were not observed to change the target distribution should be assumed to NOT change the target distribution , ( ii ) DNNs will not extrapolate in this way by default , and must be explicitly designed to do so . These claims ( or whatever the authors actually mean ) need ( s ) to be stated explicitly , and with appropriate modesty . After all , both ( i ) and ( ii ) seem contentious . The claim about an `` economical data generating process '' supports ( i ) , but is itself somewhat vague and dubious , and should be discussed in the introduction as motivation for ( i ) . 2 ) The authors claim that their method can discover invariances without any data supporting them . And their abstract claims : `` Any invariance to transformation groups is mandatory even without evidence , unless the learner deems it inconsistent with the training data . '' But in reality , the authors specify a small number of possible invariances which the method selects among ( in a soft way ) . And the data is used to guide this selection process . So in reality , the designer is in charge of specifying a ( restricted ) set of ( possible ) invariances . So like previous works on enforcing invariances , it places a burden on the designer to identify plausible invariances . Overall , I found the framing in the work to be `` the model discovers invariances by itself without any data ! '' whereas a more neutral version would be `` instead of enforcing a set of invariances , we propose a set of * possible * invariances , and assume that any input transformations that are not observed to affect the label should be enforced '' 3 ) Besides the above issues ( vagueness of `` unseen-is-forbidden '' and related discussion ( 1 ) , overselling ( 2 ) ) , there were several other issues of clarity . The paper is not poorly written overall , but is much harder to read and understand than it needs to be . Some specific issues are : - The results in Section 4 are presented with insufficient context or intuition . Theorems are stated without any proof intuition and should reference proofs in the appendix . The intuition for the penalty arrived at ( eqn13 ) is unclear . - The flow is sometimes unclear . For instance , `` Learning CG-invariant representations without knowledge of G_I. `` should be a subsection , not a ( latex ) paragraph , and should explain what the point of the subsection is before diving in . The authors seem to be using ( latex ) paragraphs ( i.e.beginning with bolded phrases ) as subsections and paragraphs beginning with italicized phrases as ( latex ) paragraphs . I suspect the paper was edited to fit into 8 pages without removing sufficient content . This impedes the flow and sacrifices clarity . - I think a graph showing the data generating process would be much clearer than the current explanations ( e.g.eqn4/5 ) - it is unclear what equation 7 is saying ... the text above makes it seem like a definition of a goal , but the following paragraph treats it as an assertion that the goal is possible to achieve . ... Overall , I recommend stripping out some of the mathematical details and using more words and diagrams in the main text to describe the underlying issues/motivations/methods . The overall story should be made clearer ( e.g.by addressing ( 1 ) and ( 2 ) ) , and more space should be devoted to linking each part of the paper into the overall story . 4 ) The experiments are synthetic tasks where the correct invariance group is included in the set of invariances being searched over . I do n't think that showing that this method can bring some benefits on a real task is an absolute requirement , given the novelty of the approach . But without more meaningful results , the paper is held to a much higher standard . Even for synthetic experiments , these are rather weak ; for instance , it would be interesting to see whether/how the method degrades when we consider much larger sets of possible invariances . 5 ) It seems like the method might require including a set of parameters for each of the possible 2^m invariances . Is this in fact the case ? If not , why not ? If so , it should be discussed as a limitation . - Suggestions/Questions : - In Section 4 paragraph 1 , are G-invariance and G_I-invariance used interchangeably ? This was confusing . - say what I and D are as soon as they are introduced ( top of page 4 ) . - Typo : `` a somewhat a '' - Why a `` nonpolynomial '' activation function ? - The definition of `` almost surely '' at the bottom of page 4 is not correct ( it is possible to sample probability 0 events ) , and also it should say that samples of Gamma ( X^ ( obs ) / ( cf ) ) ( not X^ ( obs ) / ( cf ) ) are equal with probability 1 ( these are not the same statement ! ) . - `` level of invariance '' and `` non-extrapolated validation accuracy '' , and several other phrases are not defined and should probably be replaced by something more clear and explicit . - It seems like you might need to assume that that different x^ ( hid ) ca n't be used to generate the same x^ ( obs ) or x^ ( cf ) . If so , this should be explicit .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Suggestions/Questions : We have updated the paper to incorporate the reviewer \u2019 s suggestions , adding clarifications wherever necessary . Q6 ) \u201c In Section 4 paragraph 1 , are G-invariance and G\\_I-invariance used interchangeably ? This was confusing. \u201d A6 . We have replaced the occurrences of $ \\\\mathcal { G } \\_\\\\mathcal { I } $ -invariance with G-invariances in Section 4 para 1 . Q7 ) \u201c say what I and D are as soon as they are introduced ( top of page 4 ) . \u201d A7 . We have clarified that the target variable will be invariant to the groups indexed by $ \\\\mathcal { I } $ but dependent on the groups indexed by $ \\\\mathcal { D } $ . Q8 ) \u201c Why a \u2018 nonpolynomial ' activation function ? \u201d A8 . The theorems that prove universal approximation power of DNNs argue that activations should be nonpolynomial ( Leshno ( 1993 ) ) , since DNNs with nonlinear polynomial activations are not expressive enough . Reference : Leshno , Moshe , et al . `` Multilayer feedforward networks with a nonpolynomial activation function can approximate any function . '' * Neural networks * 6.6 ( 1993 ) : 861-867 . Q9 ) \u201c The definition of \u2018 almost surely \u2019 at the bottom of page 4 is not correct \u201d A9 . We have changed the sentence to : \u2018 the equality is true for any sample of $ X^\\\\text { ( cf ) } $ and $ X^\\\\text { ( obs ) } $ except for a set of measure zero. \u2019 Q10 ) `` 'level of invariance ' and 'non-extrapolated validation accuracy ' , and several other phrases are not defined and should probably be replaced by something more clear and explicit . '' A10 ) We define the level of invariance of a subspace $ \\\\mathcal { B } \\_M $ as the size of $ M \\\\subseteq \\\\ { 1 , \\\\ldots , m\\\\ } $ , i.e. , the number of groups that any $ \\\\mathbf { w } \\\\in \\\\mathcal { B } \\_M $ is invariant to . We have removed the phrase `` non-extrapolated validation accuracy '' ; we now refer to it as validation accuracy on held-out training data ( sampled with no knowledge of the extrapolation task ) . Q11 ) \u201c It seems like you might need to assume that that different x^ ( hid ) ca n't be used to generate the same x^ ( obs ) or x^ ( cf ) . If so , this should be explicit. \u201d A11 . We do not need this assumption . For example , consider two different $ X^\\\\text { ( hid ) } $ corresponding to the canonical forms of the digits 6 and 9 respectively . If we transform one of them by a 90-degree rotation and the other with no rotation , then we get the same $ X^\\\\text { ( obs ) } $ for both . The task can not be perfectly solved , but this is fine as the SCM is describing the most general scenario ."}], "0": {"review_id": "7t1FcJUWhi3-0", "review_text": "Summary : A method is given for training neural networks in the presence of a group of transformations , such that the network weights are invariant with respect to any transformation on the inputs which does n't contradict the training data . Experiments on MNIST and toy sequence data are used to verify that this training method leads to improved extrapolation of predictions to unseen environments . Strengths : The method introduced seems promising , as it does n't require training data to exhibit symmetry , but can still verify ( or reject ) the invariance of data with respect to a collection of candidate symmetry groups . The training method also seems quite lightweight , and should n't require significant additional resources to check for the presence or absence of symmetry . Although the experiments are a bit limited , the authors include a detailed experiments section in the appendix with a larger selection of baselines and more information about choosing the magnitude of the applied CG-regularization . Critiques : The explanation of the results has a lot of room for improvement , and I would recommend the authors revise the writing to follow standard best practices , such as defining/explaining new variables when they are introduced , giving the steps associated with novel algorithms , etc . I give a few specific examples below where this lack of clarity makes the authors ' results hard to understand , but there are many other examples of this not listed . The description of the underlying causal model in section 3 ( from the end of page 3 to the start of page 5 ) is hard to follow owing to a lack of explanation in many places . For example , the overgroups $ G_D $ and $ G_I $ are introduced without any insight into the distinction between these groups , or what role they play in the context of extrapolation tasks . Similarly , the central concept of CG-invariance lacks some crucial details in its definition ( Def 2 ) , making the following material harder to follow . In particular , it is n't stated if CG-invariance is defined relative to a specific $ \\tilde { U } _I $ , or else requires Eq.6 to hold for any choice of $ \\tilde { U } _I $ ( the latent distribution which determines the counterfactual samples $ X^ { cf } $ ) . Theorem 3 is difficult to make sense of , with the subspaces $ B_M $ appearing at first glance to be circularly defined ( the projection in Eq.9 used to define the $ B_M $ is itself defined in terms of these subspaces ) . The text below and above Theorem 3 helps to interpret this circularity as an inductive algorithm for calculating these subspaces , but it would have been much clearer to define this algorithm explicitly in terms of pseudocode ( along with a runtime ) , and then reference this definition in Theorem 3 . Recommendation : Although the techniques seem like a timely and useful contribution , the poor presentation makes these techniques difficult to follow , and limits the usefulness of the paper for readers . I 'm recommending a weak accept , but this can be improved by clarifying the presentation and making the results easier for readers to understand . * * UPDATE AFTER THE REBUTTAL : * * The new material in the paper clarifies things quite a bit , especially the intuitive explanations appearing below Equation 2 and at the bottom of page 4 . Thank you for adding that , I have changed my score accordingly : )", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the constructive comments and helpful feedback . We would like to emphasize the timeliness of our contribution w.r.t.recent findings about DNNs extrapolations ( learning spurious correlations and shortcut learning ( see our Section 6 , Arjovsky et al . ( 2019 ) , D \u2019 Amour et al . ( 2020 ) , de Haan et al . ( 2019 ) , Geirhos et al . ( 2020 ) , McCoy et al . ( 2019 ) , and Sch\u00f6lkopf ( 2019 ) among many others ) ) , with a special emphasis in the large-scale study that came out this week from Google ( D \u2019 Amour et al . ( 2020 ) ) .Q1 ) \u201c The explanation of the results has a lot of room for improvement , and I would recommend the authors revise the writing to follow standard best practices , such as defining/explaining new variables when they are introduced , giving the steps associated with novel algorithms , etc . I give a few specific examples below where this lack of clarity makes the authors ' results hard to understand , but there are many other examples of this not listed. \u201d A1 . We have provided additional explanations throughout the paper . We have streamlined Section 3 and added the graph of the SCM ( Figure 1 ) . In Section 4 , we have updated the text around Theorem 3 to clarify the objectives of the theorem and present a pseudocode in the Appendix . We have also clarified the intuitions behind the regularization penalty ( Equation 12 ) and show an example computation of the penalty in Figure 6 of the Supplementary Material . We have updated Section 5 with more details about the architectures . In Section 6 , we provide a running example to clarify the experimental details . Q2 ) \u201c The description of the underlying causal model in section 3 ( from the end of page 3 to the start of page 5 ) is hard to follow owing to a lack of explanation in many places . For example , the overgroups GD and GI are introduced without any insight into the distinction between these groups , or what role they play in the context of extrapolation tasks. \u201d A2 . We have updated this section making it easier to follow and have included a graph of the structural causal model in Figure 1 . We have clarified the role of groups $ \\\\mathcal { G } \\_D $ and $ \\\\mathcal { G } \\_I $ : the target variable is defined as being invariant to the group $ \\\\mathcal { G } \\_I $ but dependent on the group $ \\\\mathcal { G } \\_D $ . Q3 ) \u201c Similarly , the central concept of CG-invariance lacks some crucial details in its definition ( Def 2 ) , making the following material harder to follow . In particular , it is n't stated if CG-invariance is defined relative to a specific U\\~I , or else requires Eq.6 to hold for any choice of U\\~I ( the latent distribution which determines the counterfactual samples Xcf ) . \u201d A3 . We have updated Definition 1 ( Counterfactual coupling ) to make it clear that $ X^\\\\text { ( cf ) } $ is obtained by counterfactually replacing $ U\\_\\\\mathcal { I } $ by any choice of $ \\\\tilde { U } \\_\\\\mathcal { I } $ in the SCM equations . Then Definition 2 ( CG-invariant representations ) is tied to that choice of $ \\\\tilde { U } \\_\\\\mathcal { I } $ from Definition 1 . Q4 ) Theorem 3 is difficult to make sense of , with the subspaces BM appearing at first glance to be circularly defined ( the projection in Eq.9 used to define the BM is itself defined in terms of these subspaces ) . The text below and above Theorem 3 helps to interpret this circularity as an inductive algorithm for calculating these subspaces , but it would have been much clearer to define this algorithm explicitly in terms of pseudocode ( along with a runtime ) , and then reference this definition in Theorem 3 . A4.We have updated the text around Theorem 3 to describe the two goals of the Theorem : We wish to construct bases $ \\\\mathcal { B } \\_M $ for all $ M \\\\subseteq \\\\ { 1 , \\\\ldots , m\\\\ } $ such that any weight vector $ \\\\mathbf { w } \\\\in \\\\mathcal { B } \\_M $ is * * ( a ) * * invariant to the groups $ \\\\mathcal { G } \\_i $ for $ i\\\\in M $ , and * * ( b ) * * not invariant to any group $ j \\\\in \\\\ { 1 , \\\\ldots , m\\\\ } \\\\setminus M $ } . $ \\\\tilde { \\\\mathcal { B } } \\_M $ contains all the vectors $ \\\\mathbf { w } $ that are invariant to $ \\\\mathcal { G } \\_M $ but could also contain vectors that are invariant to some overgroup of $ \\\\mathcal { G } \\_M $ . Thus , each step of our inductive method performs a Gram-Schmidt orthogonalization in order to satisfy condition * * ( b ) * * above : we need to remove from $ \\\\tilde { \\\\mathcal { B } } \\_M $ all weight vectors that are invariant to more groups in addition to those indexed by $ M $ ( i.e. , supersets of $ M $ ) . We also refer the reader to a pseudocode in Appendix C ."}, "1": {"review_id": "7t1FcJUWhi3-1", "review_text": "POST REBUTTAL UPDATE : I am increasing my confidence in this paper from 2 to 3 - I still believe the paper can use some more clarity but enough points have been explained and updated in the draft for me to feel more confident in my evaluation . I think the ideas in this paper are quite interesting - for this reason I continue to recommend acceptance . Summary : This paper describes an approach to embedded invariances in learned neural networks through defining linear automorphism groups . They define a fair amount of theoretical machinery for this task , proposing a model of image generation which includes a number of transformations from these defined groups , and defining the notion of a counterfactual G-invariance for the task . They discuss a method for practically learning a useful invariance even if that exact invariance you wish to have is unknown , by ordering subspaces which may be invariant , and discusses the practicalities of embedding these into neural architectures . Some experiments are described in an MNIST setting and on simulated experiments , showing success at embedding these invariances in toy-ish settings . Recommendation : I \u2019 m recommending acceptance for the paper , since the ideas seem interesting , there appears to be theoretical contribution and empirical evidence , and it is obviously written with care . My hesitance comes on two fronts : I may be lacking some background in the relevant group theory/invariance literature , and it is hard for me to understand a number of important ideas due to the information density in the writing ( a result of ICLR restrictions but also some fault of the authors ) . Strong points : - The paper is very detailed and interesting \u2013 while I am not particularly familiar with the group theory side of the literature , it seems like a good idea from a robustness perspective and the authors lay out their ideas carefully - The notion of assuming an invariance unless contradicted is interesting at a high level , and provides some meat to the oft-discussed notion of \u201c extrapolation from a single environment \u201d - I appreciate the bridge made from the theory to the practical implementation - The experiments mostly back up the point the authors assert in their theory \u2013 larger experiments for a mostly theoretical paper like this are not necessarily required Weak points : - My sense is the authors are having a lot of trouble fitting their ideas into the 8 pages . I sympathize but I also think they can do better on this front \u2013 the first two pages can be much more compact , with more space to explicate complex ideas that get swept over quickly - Ideas which do not receive enough attention or explanation ( but should ) include : Eq 2 , Theorem 3 , the design of neural network weights , and even the bare minimum of experimental details . I know the format is short but some of this stuff is necessary , and I believe the authors can do better in terms of fitting important information in . As it is I am confused about some central ideas , even after checking the appendix - The notion of \u201c forbidding examples in the learner \u2019 s statistical model \u201d carries some intuitive weight but is not precise \u2013 what is this model for a discriminative classifier ? This can be more clearly explicated - It \u2019 s not clear how much is packed in the \u201c economical data generation \u201d assumption , or how that is really connected to the method . Please be more clear . - The definition of $ T_ { { U_D , U_I } } $ is not really clear \u2013 need another sentence on this indexing in the main body , as well as discussion of ordering ! - Def 1 : you don \u2019 t actually define what it means for 2 variables to be counterfactually coupled , you just show what a counterfactual coupling is . Please reword this definition . - Thm 3 \u2013 this is incredibly dense and I have a lot of trouble parsing this . I \u2019 m not sure how to interpret the direct sum \u2013 you \u2019 re combining all the subspaces which are supersets of M ? Also not sure about the end \u2013 this is not G_j -invariant for j \\in M-bar . What is M-bar ? Is that a Reynolds operator ? Then what does it mean for j to be an element of it ? - How should I pick my groups G_1 \u2026 m ? Not clear if this is important - Bottom of p6 : not clear how these neuron weights are specified \u2013 does it matter which layer we are in ? what does the product of B_m \\omega_M , h mean \u2013 it looks like a subspace times a real number - Sec 5 : I really am confused about the relationship between architecture and which invariances can be realizable . There \u2019 s not a lot of explanation on this . - Sec 6 : it \u2019 s very hard to interpret anything in this section without the appendix \u2013 work more to make it stand alone - Proof of Thm 1 : maybe I am missing some group theory background but I don \u2019 t understand this . For instance , there is no explanation of why this $ \\tilde { U } _I $ can always be found to couple X^cf with X^obs . - Proof of Lemma 1 : Again , may be missing some background . But neither x nor $ \\bar { T } $ is mentioned in this proof , so I don \u2019 t know where it is going \u2013 please be more verbose . Clarifications : - Middle of p3 \u2013 we can \u201c compose rotations and image flips \u201d \u2013 do you mean a union of the two sets of transformations ? That \u2019 s what is shown in the notation but I may be missing some group theory background here - Top of p4 : not clear how $ G_D \\cap G_I \\neq 0 $ is possible \u2013 is the idea that $ G_i \\cap G_j $ might be nonempty ? - Below Eq 3 : \u201c the training data may contaion on a few samples of the variable \u201d \u2013 do you mean only a few values of the variable may be observed ? - Below Eq 3 : you use the term environment without defining it , not sure how to interpret it in this context - Below Eq 7 : should the samples of $ \\hat { Y } \\ X^ { ( obs ) } $ be Y instead ? - Below Eq 7 : in ( i ) you say you don \u2019 t know the group \u2013 do you mean for which group Y should be considered invariant ? If so , state that explicitly - It \u2019 s not clear how the statistical assumption at the end of Sec 3 really fits in with the argument , if you \u2019 re going to use it need more here - Top of p6 \u2013 you say the eigenspace of the Reynolds operator gives us a way to build an invariant NN , but the Lemma is about a linear operator . Need more description here - You say the method in Thm 3 is fast but the power set should grow exponentially \u2013 is that a problem ? Other feedback : - Not sure why you define g as going to the image of the probability \u2013 can \u2019 t it just be [ 0 , 1 ] ? - Not sure \u201c unseen is forbidden \u201d is quite right \u2013 wouldn \u2019 t it be \u201c unseen is irrelevant \u201d or something ? - Specify whether Thm 1 only applies to linear automorphisms or if it is more general - The recursion at the bottom of Sec 4 is unreadable \u2013 just put this in the appendix - Bottom of p17 \u2013 describe more how the transformations are sampled . I shouldn \u2019 t have to work so hard to understand the experiments", "rating": "7: Good paper, accept", "reply_text": "Q14 ) \u201c 'the training data may contain only a few samples of the variable ' \u2013 do you mean only a few values of the variable may be observed ? '' A14.We have clarified as follows : If the support of $ U\\_\\\\mathcal { I } $ is a singleton set $ \\\\ { c\\\\ } $ for some constant $ c $ , then $ ( Y , X^\\\\text { ( obs ) } ) $ are said to be sampled using an economical data generation process . In other words , the training data can contain just one value for the variable $ U\\_\\\\mathcal { I } $ since the outputs $ Y $ do not depend on $ U\\_\\\\mathcal { I } $ . Q15 ) \u201c Below Eq 3 : you use the term environment without defining it , not sure how to interpret it in this context \u201d A15 . In our context , different environments correspond to different supports of $ U\\_\\\\mathcal { I } $ . The economical data generation process with a singleton support for $ U\\_\\\\mathcal { I } $ results in a single environment . For example , if $ Y $ is invariant to 90-degree rotations , then the set of upright images form one environment and the set of upside-down images can form another environment . Q16 ) \u201c Below Eq 7 : should the samples of $ \\\\hat { Y } | X^ { ( obs ) } $ be Y instead ? \u201d A16 . This was a typo . We have updated the notation in Section 3 : $ Y | X^\\\\text { ( tr ) } $ refers to the distribution in training and $ Y | X^\\\\text { ( te ) } $ refers to the distribution in test . Q17 ) \u201c Below Eq 7 ( new equation number ( 6 ) ) : in ( i ) you say you don \u2019 t know the group \u2013 do you mean for which group Y should be considered invariant ? \u201d A17 . Yes , we do not know $ \\\\mathcal { I } $ ( or $ \\\\mathcal { G } \\_\\\\mathcal { I } $ ) , thus we do not know which group $ Y $ should be invariant to . Q18 ) \u201c It \u2019 s not clear how the statistical assumption at the end of Sec 3 really fits in with the argument , if you \u2019 re going to use it need more here \u201d A18 . We have clarified below Definition 1 that $ \\\\tilde { U } \\_\\\\mathcal { I } $ can have very different support than $ U\\_\\\\mathcal { I } $ . Since $ \\\\tilde { U } \\_\\\\mathcal { I } $ , and thus $ X^\\\\text { ( cf ) } $ , are not observed , the statistical assumption at the end of Section 3 hinders learning of $ \\\\Gamma\\_\\\\text { true } $ . We believe that this is clear to the reader in the updated manuscript . Q19 ) `` Top of p6 \u2013 you say the eigenspace of the Reynolds operator gives us a way to build an invariant NN , but the Lemma is about a linear operator . '' A19.The Lemma describes a single neuron . If the first layer of a neural network is composed of these neurons and thus , is G-invariant , then we can use dense layers and non-linear activations on top of the first layer to obtain a G-invariant neural network . Q20 ) \u201c You say the method in Thm 3 is fast but the power set should grow exponentially \u2013 is that a problem ? \u201d A20 . Practically , this does not pose a problem for two reasons : * * ( 1 ) * * Theorem 3 will stop after finding $ \\\\text { dim } ( \\\\text { vec } ( \\\\mathcal { X } ) ) $ number of bases ( which does not depend on the number of groups ) , so it need not iterate over the entire power set . However , it is unclear whether the worst-case exponential runtime can actually happen in practice . * * ( 2 ) * * Regardless , for a collection of groups , we would only need to compute the bases once and reuse them for all experiments . We have added this to the paper . Other feedback : Q21 ) `` Not sure why you define g as going to the image of the probability \u2013 can \u2019 t it just be [ 0 , 1 ] ? '' A21. $ g $ returns a probability measure over the entire space of $ Y $ . In classification for example , $ g $ returns the probabilities for all the classes . Q22 ) \u201c Not sure \u2018 unseen is forbidden \u2019 is quite right \u2013 wouldn \u2019 t it be \u2018 unseen is irrelevant \u2019 or something ? \u201d A22 . We have replaced the phrase with \u2018 unseen-is-unknown \u2019 to represent the fact that examples not explicitly observed with infinitely many training examples have undefined/unknown outcomes in the learner \u2019 s model . Q23 ) \u201c Specify whether Thm 1 only applies to linear automorphisms or if it is more general \u201d A23 . Theorems 1 & 2 also apply to groups with non-linear automorphisms . However , to be consistent with the rest of the paper , we only discuss linear automorphisms . Q24 ) \u201c The recursion at the bottom of Sec 4 is unreadable \u2013 just put this in the appendix \u201d A24 . We have moved the differentiable approximation of the penalty to the Appendix and updated Section 4 with an intuition for the penalty instead . Q25 ) \u201c Bottom of p17 \u2013 describe more how the transformations are sampled . I shouldn \u2019 t have to work so hard to understand the experiments \u201d A25 . We have updated Appendix F.1 further clarifying how the transformations are sampled to construct the training and test datasets ."}, "2": {"review_id": "7t1FcJUWhi3-2", "review_text": "This paper proposes an interesting and potentially quite impactful and valuable idea , which I believe is novel . The idea is : instead of specifying invariances by hand in the architecture of a network , we can instead specify a set of possible invariances , and regularize the model to favor more invariance . The authors describe how to structure and regularize a DNN in this way , and provide proof-of-concept experiments . The experiments show that the proposed method outperforms networks that are fully-invariant or non-invariant when the true data is partially-invariant . Unfortunately , there are a number of weaknesses which lead me to recommend against acceptance . In no particular order : 1 ) The crucial `` unseen is forbidden '' hypothesis is vague and seems to be a bit of a strawman . 2 ) The framing of the paper seems to oversell the method in a way that makes the contribution less clear . 3 ) The writing is not very clear . 4 ) The experiments seem to be only proof-of-concept in scenarios where the method is designed to work . 5 ) The method seems to incur an exponential cost , but this is not discussed . Elaborating : 1 ) The authors claim that , because DNN behavior is undefined on unseen datapoints , the `` unseen-is-forbidden learning hypothesis is currently preventing neural networks from assuming symmetric extrapolations without evidence . '' This claim is stated in various forms several times , but never made very precise , and it is crucial in motivating the authors ' approach . Roughly , I take the authors to be claiming that ( i ) the correct way to `` extrapolate '' is to assume that : transformations that were not observed to change the target distribution should be assumed to NOT change the target distribution , ( ii ) DNNs will not extrapolate in this way by default , and must be explicitly designed to do so . These claims ( or whatever the authors actually mean ) need ( s ) to be stated explicitly , and with appropriate modesty . After all , both ( i ) and ( ii ) seem contentious . The claim about an `` economical data generating process '' supports ( i ) , but is itself somewhat vague and dubious , and should be discussed in the introduction as motivation for ( i ) . 2 ) The authors claim that their method can discover invariances without any data supporting them . And their abstract claims : `` Any invariance to transformation groups is mandatory even without evidence , unless the learner deems it inconsistent with the training data . '' But in reality , the authors specify a small number of possible invariances which the method selects among ( in a soft way ) . And the data is used to guide this selection process . So in reality , the designer is in charge of specifying a ( restricted ) set of ( possible ) invariances . So like previous works on enforcing invariances , it places a burden on the designer to identify plausible invariances . Overall , I found the framing in the work to be `` the model discovers invariances by itself without any data ! '' whereas a more neutral version would be `` instead of enforcing a set of invariances , we propose a set of * possible * invariances , and assume that any input transformations that are not observed to affect the label should be enforced '' 3 ) Besides the above issues ( vagueness of `` unseen-is-forbidden '' and related discussion ( 1 ) , overselling ( 2 ) ) , there were several other issues of clarity . The paper is not poorly written overall , but is much harder to read and understand than it needs to be . Some specific issues are : - The results in Section 4 are presented with insufficient context or intuition . Theorems are stated without any proof intuition and should reference proofs in the appendix . The intuition for the penalty arrived at ( eqn13 ) is unclear . - The flow is sometimes unclear . For instance , `` Learning CG-invariant representations without knowledge of G_I. `` should be a subsection , not a ( latex ) paragraph , and should explain what the point of the subsection is before diving in . The authors seem to be using ( latex ) paragraphs ( i.e.beginning with bolded phrases ) as subsections and paragraphs beginning with italicized phrases as ( latex ) paragraphs . I suspect the paper was edited to fit into 8 pages without removing sufficient content . This impedes the flow and sacrifices clarity . - I think a graph showing the data generating process would be much clearer than the current explanations ( e.g.eqn4/5 ) - it is unclear what equation 7 is saying ... the text above makes it seem like a definition of a goal , but the following paragraph treats it as an assertion that the goal is possible to achieve . ... Overall , I recommend stripping out some of the mathematical details and using more words and diagrams in the main text to describe the underlying issues/motivations/methods . The overall story should be made clearer ( e.g.by addressing ( 1 ) and ( 2 ) ) , and more space should be devoted to linking each part of the paper into the overall story . 4 ) The experiments are synthetic tasks where the correct invariance group is included in the set of invariances being searched over . I do n't think that showing that this method can bring some benefits on a real task is an absolute requirement , given the novelty of the approach . But without more meaningful results , the paper is held to a much higher standard . Even for synthetic experiments , these are rather weak ; for instance , it would be interesting to see whether/how the method degrades when we consider much larger sets of possible invariances . 5 ) It seems like the method might require including a set of parameters for each of the possible 2^m invariances . Is this in fact the case ? If not , why not ? If so , it should be discussed as a limitation . - Suggestions/Questions : - In Section 4 paragraph 1 , are G-invariance and G_I-invariance used interchangeably ? This was confusing . - say what I and D are as soon as they are introduced ( top of page 4 ) . - Typo : `` a somewhat a '' - Why a `` nonpolynomial '' activation function ? - The definition of `` almost surely '' at the bottom of page 4 is not correct ( it is possible to sample probability 0 events ) , and also it should say that samples of Gamma ( X^ ( obs ) / ( cf ) ) ( not X^ ( obs ) / ( cf ) ) are equal with probability 1 ( these are not the same statement ! ) . - `` level of invariance '' and `` non-extrapolated validation accuracy '' , and several other phrases are not defined and should probably be replaced by something more clear and explicit . - It seems like you might need to assume that that different x^ ( hid ) ca n't be used to generate the same x^ ( obs ) or x^ ( cf ) . If so , this should be explicit .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Suggestions/Questions : We have updated the paper to incorporate the reviewer \u2019 s suggestions , adding clarifications wherever necessary . Q6 ) \u201c In Section 4 paragraph 1 , are G-invariance and G\\_I-invariance used interchangeably ? This was confusing. \u201d A6 . We have replaced the occurrences of $ \\\\mathcal { G } \\_\\\\mathcal { I } $ -invariance with G-invariances in Section 4 para 1 . Q7 ) \u201c say what I and D are as soon as they are introduced ( top of page 4 ) . \u201d A7 . We have clarified that the target variable will be invariant to the groups indexed by $ \\\\mathcal { I } $ but dependent on the groups indexed by $ \\\\mathcal { D } $ . Q8 ) \u201c Why a \u2018 nonpolynomial ' activation function ? \u201d A8 . The theorems that prove universal approximation power of DNNs argue that activations should be nonpolynomial ( Leshno ( 1993 ) ) , since DNNs with nonlinear polynomial activations are not expressive enough . Reference : Leshno , Moshe , et al . `` Multilayer feedforward networks with a nonpolynomial activation function can approximate any function . '' * Neural networks * 6.6 ( 1993 ) : 861-867 . Q9 ) \u201c The definition of \u2018 almost surely \u2019 at the bottom of page 4 is not correct \u201d A9 . We have changed the sentence to : \u2018 the equality is true for any sample of $ X^\\\\text { ( cf ) } $ and $ X^\\\\text { ( obs ) } $ except for a set of measure zero. \u2019 Q10 ) `` 'level of invariance ' and 'non-extrapolated validation accuracy ' , and several other phrases are not defined and should probably be replaced by something more clear and explicit . '' A10 ) We define the level of invariance of a subspace $ \\\\mathcal { B } \\_M $ as the size of $ M \\\\subseteq \\\\ { 1 , \\\\ldots , m\\\\ } $ , i.e. , the number of groups that any $ \\\\mathbf { w } \\\\in \\\\mathcal { B } \\_M $ is invariant to . We have removed the phrase `` non-extrapolated validation accuracy '' ; we now refer to it as validation accuracy on held-out training data ( sampled with no knowledge of the extrapolation task ) . Q11 ) \u201c It seems like you might need to assume that that different x^ ( hid ) ca n't be used to generate the same x^ ( obs ) or x^ ( cf ) . If so , this should be explicit. \u201d A11 . We do not need this assumption . For example , consider two different $ X^\\\\text { ( hid ) } $ corresponding to the canonical forms of the digits 6 and 9 respectively . If we transform one of them by a 90-degree rotation and the other with no rotation , then we get the same $ X^\\\\text { ( obs ) } $ for both . The task can not be perfectly solved , but this is fine as the SCM is describing the most general scenario ."}}