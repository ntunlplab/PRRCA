{"year": "2019", "forum": "H1e0-30qKm", "title": "Unlabeled Disentangling of GANs with Guided Siamese Networks", "decision": "Reject", "meta_review": "The paper received mixed reviews. It proposes a variant of Siamese network objective function, which is interesting. However, it\u2019s unclear if the performance of the unguided method is much better than other baselines (e.g., InfoGAN). The guided version of the method seems to require much domain-specific knowledge and design of the feature function, which makes the paper difficult to apply to broader cases. \n", "reviews": [{"review_id": "H1e0-30qKm-0", "review_text": "[Edit] I changed my rating from 4 to 5 based on the author responses. ======= This paper proposed a GAN that learns a disentangled factors of variations in unsupervised (or weakly-supervised) manner. To this end, the proposed method incorporates a contrastive loss together with Siamese network, which encourages the generator to output smaller variations in samples if they are drawn by varying the same latent factors. The proposed idea is evaluated on simple datasets such as MNIST and centered faces, and show that it is able to learn disentangled latent codes by incorporating some heuristics. Although the paper presents an interesting and reasonable idea, I think the paper is incomplete and in the proof-of-concept stage. In terms of method, the guidance for learning Siamese networks are designed heuristically (e.g. edges, colors, etc.) which limits its applicability over various datasets; I think that designing more principled approach to build such guidances from data should be one of the key contributions of the paper. In terms of evaluation, the authors only presented a few qualitative results on simple datasets, which is not comprehensive and convincing. In conclusion, I suggest a reject of this paper due to the lacks of comprehensive study and evaluation. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Principled Guidance ] The design of guidances is heuristic , but as illustrated in Figure 2 and in Table 2 , they are easy to design and are effective . Further , we added our unsupervised analyses to show that the method works even without explicit guidance on all tested datasets . In this paper , we propose the idea of guidance itself and show that it is imposing a desired semantics on the latent space without having labeled data . In our future work , we plan to investigate more principled ways of deciding guidances . We now address this point in our `` Discussion '' section . [ Experiments Section ] We have significantly updated qualitative and quantitative results in our `` Experiments '' section and now compare our methods against Beta-VAE , DIP-VAE , and InfoGAN ."}, {"review_id": "H1e0-30qKm-1", "review_text": "Summary The paper presents a novel approach for learning a generative model where different factors of variations can be independently manipulated. The method is build upon the GAN framework where the latent variables are divided into different subsets (chunks) which are expected to encode information about high-level factors of variation. To this end, a Siamese Network for each chunk is trained with a contrastive loss minimizing the distance between generated images sharing the same factor (the latent variables in the chunk are equal), and maximizing the distance between pairs where the latent variables differ. Given that the proposed model fails in this fully-unsupervised setting, the authors propose to add weak-supervision into the model by forcing the Siamese networks to focus only on particular aspects of generated images (e.g, color, edges, etc..). This is achieved by applying a basic transformation over the input images in order to remove specific information. The evaluation of the proposed model is carried out using the MS-Celeb dataset where the authors provide qualitative results. Methodology *Disentangling generative factors without explicit labels is a challenging and interesting problem. The idea of dividing the latent representation in different subsets and using a proxy task involving triplets of images has been already explored in [3]. However, the use of Siamese networks in this context is novel and sound. *As shown in the reported results, the proposed method fails to learn meaningful factors in the unsupervised setting. However, the authors do not provide an in-depth discussion of this phenomena. Given that previous works [1,2,3] have successfully addressed this problem using a completely unsupervised approach, it would be necessary to give more insights about: (i) why the proposed method is failing (ii) why this negative result is interesting and (iii) if the method could be useful in other potential scenarios. *The strategy proposed to introduce weak-supervision is too ad-hoc. I agree that using cues such as the average color of an image can be useful if we want to model basic factors of variation. However, it is unclear how a similar strategy could be applied if we are interested in learning variables with higher-level semantics such as the expression of a face or its pose. *As far as I understand, the transformations applied to the input images (e.g, edge detection) must be differentiable (given that it is necessary to backpropagate the gradient of the contrastive loss through the generator network). If this is the case, this should be properly discussed in the paper. Moreover, given that the amount of differentiable transformations is reduced, this also limits the application of the proposed method for more interesting scenarios. *It is not clear why the latent variables modelling the generative factors are defined using a Gaussian prior. How the case where two images have a very similar latent factor is avoided while generating pairs of images for the Siamese network? Have the authors considered to use categorical or binary variables? The use of the contrastive loss sounds more appropriate in this case. Experimental results *The experimental section is too limited. First of all, only a small number of qualitative results are reported and, therefore, it is very difficult to assess the proposed method and draw any conclusion. For example, when the edge extractor is used, what kind of information is modeled by the latent variables? Is it consistent across different samples? Moreover, it is not clear why the authors have limited the evaluation to the case where only two \u201cchunks\u201d are used. In principle, the method could be applied with many more subsets of latent variables and then manually inspect them to check it they are semantically meaningful (see [2]) *As previously mentioned, there are many recent works addressing the same problem from a fully-unsupervised perspective [1,2,3]. All these works provide quantitative results evaluating the learned representations by using them to predict real labels (e.g, attributes in the CelebA data-set). The authors could provide a similar evaluation for their method by using the feature representations learned by the siamese networks in order to evaluate how much information they convey about real factors of variation. This could clarify the advantages of the weakly-supervised strategy compared to unsupervised approaches. Review summary +The addressed problem (learning disentangled representations without explicit labeling) is challenging and interesting. +The idea of using a proxy task (contrastive loss with triplets of generated images) is somewhat novel and promising. - The authors report only negative results for the fully-unsupervised version of UD-GAN The paper lacks and in-depth discussion about why this negative result is interesting. -The strategy proposed to provide weak-supervision to the model is too ad-hoc and it is not clear how to apply it in general applications -The experimental section do not clarify the benefits of the proposed approach. In particular, the qualitative results are too limited and no quantitative evaluations is provided. [1] Variational Inference of Disentangled Latent Concepts from Unlabelled Observations (Kumar et al, ICLR 2018) [2] Beta-vae: Learning basic visual concepts with a constrained variational framework. (Higgins et. al, ICLR 2017) [3] Disentangling Factors of Variation by Mixing Them. (Hu et. al, CVPR 2018) ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Unguided Case ] Please refer to our general comment above on why our unguided case performs better now . The main usefulness of our guided approach is to directly capture some of the desired variations in the data . This is now clearer on our quantitative and visual results in the \u201c Experiments \u201d section . [ Heuristic Guidance ] The main premise behind guiding our siamese networks is to find very simple , yet effective ways to capture some of the variation in the data , through weak supervision . For more complex semantics , we discuss the possibility of using a pre-trained network as guidance . Please refer to our \u201c Discussion \u201d section for more details . [ Differentiable Guidance ] The transformations need to be differentiable in order to backpropagate the gradients into our generator . This is now pointed out and discussed in our `` Discussion '' section . Although this limits the function families , we can still use differentiable relaxations of more complicated functions . [ Gaussian Prior on Latents ] In our new experiments , we used uniform distributions to model the generative factors . We had experiments with categorical variables , however , we faced training stability issues with them . We now point this out in our `` Discussion '' section . [ Similar Latent Factors ] We now use an adaptive margin that depends on the distance between two latent samples . So , if samples are close to each other , the margin is smaller , and vice versa . [ Experiments Section ] We now compare our method against Beta-VAE , DIP-VAE , and InfoGAN , both qualitatively and quantitatively . Please refer to our updated `` Experiments '' section . [ Information of Guidance ] In Figure 3 , we visualize which part of an image was visible to a siamese network . In addition , we show how changing the corresponding guided knob affects the generated images . [ More Than Two Attributes ] We now use 32 dimensions for the CelebA dataset and 10 dimensions for the 2D shapes dataset ."}, {"review_id": "H1e0-30qKm-2", "review_text": "[EDIT]: I have updated my score after the author response and paper revision. ============================= [I was asked to step in as a reviewer last minute. I did not look at the other reviews]. ------------------------------- Summary ------------------------------- This paper proposes to learn disentangled latent states under the GAN framework. The core idea is to partition the latent states into N partitions, and correspondly have N Siamese networks that pull the generated images with the same latent partition towards each other, along with a contrastive loss which ensures generated images with different latent partitions to be different. The authors experiment with two setups: in the \"unguided setup\" training is completely unsupervised, while in the \"guided\" setup, there is some weak supervision to encourage different partitions to learn different factors. ------------------------------- Evaluation ------------------------------- While the motivation is nice, I find the results (especially in the unguided setup) underwhelming. This does not seem surprising to me, as in the unguided case, the constrative loss seems not strong enough to encourage the latent partitions to be different. Results with weak supervision (their method for injecting weak supervision was very nice) are more impressive. However, there is no comparison against existing work. Learning disentangled representations with deep generative models is very much an active area. Here are some recent papers: https://openreview.net/references/pdf?id=Sy2fzU9gl https://arxiv.org/abs/1802.05822 https://arxiv.org/abs/1802.05983 https://arxiv.org/abs/1802.04942 Importantly, there are no quantitative metrics. I do not think this work is ready for publication. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Unguided Case and Disentanglement ] Please refer to our general comment above on why our unguided case performs better now . We also updated our \u201c Probabilistic Interpretation \u201d section with analysis on how the contrastive loss helps us to learn a disentangled representation . Evidence and comparison to other methods on disentanglement is provided in Table 9 in Appendix G , where we visualize the correlations between our embedding dimensions . [ Experiments Section ] We have significantly updated qualitative and quantitative results in our `` Experiments '' section and now compare our methods against Beta-VAE , DIP-VAE , and InfoGAN ."}, {"review_id": "H1e0-30qKm-3", "review_text": "The paper proposes a framework for learning interpretable latent representations for GANs. The key idea is to use siamese networks with contrastive loss. Specifically, it decomposes the latent code to a set of knobs (sub part of the latent code). Each time it renders different images with different configurations of the knobs. For example, 1) as changing one knob while keeping the others, it expects it would only result in change of one attribute in the image, and 2) as keeping one knob while changing all the others, it expects it would result in large change of image appearances. The relative magnitude of change for 1) and 2) justifies the use of a Siamese network in addition to the image discriminator in the standard GAN framework. The paper further talks about how to use inductive bias to design the Siamese network so that it can control the semantic meaning of a particular knob. While I do like the idea, I think the paper is still in the early stage. First of all, the paper does not include any numerical evaluation. It only shows a couple of examples. It is unclear how well the proposed method works in general. In addition, the InfoGAN work is designed for the same functionality. The paper should compare the proposed work to the InfoGAN work both quantitatively and qualitatively to justify its novelty. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Experiments Section ] We have significantly updated qualitative and quantitative results in our `` Experiments '' section and now compare our methods against Beta-VAE , DIP-VAE , and InfoGAN . [ InfoGAN ] Compared to InfoGAN , our method is novel in two ways : First , we use separate networks to obtain the image embeddings , which enables us to guide some of these networks with simple functions . The guidance allows more control over the latent space , even in lack of data . Second , we use pairwise similarity/dissimilarity in order to perform disentangling , which is different from InfoGAN 's approach of maximizing the label likelihood . This point is now addressed in our `` Related Work '' section ."}], "0": {"review_id": "H1e0-30qKm-0", "review_text": "[Edit] I changed my rating from 4 to 5 based on the author responses. ======= This paper proposed a GAN that learns a disentangled factors of variations in unsupervised (or weakly-supervised) manner. To this end, the proposed method incorporates a contrastive loss together with Siamese network, which encourages the generator to output smaller variations in samples if they are drawn by varying the same latent factors. The proposed idea is evaluated on simple datasets such as MNIST and centered faces, and show that it is able to learn disentangled latent codes by incorporating some heuristics. Although the paper presents an interesting and reasonable idea, I think the paper is incomplete and in the proof-of-concept stage. In terms of method, the guidance for learning Siamese networks are designed heuristically (e.g. edges, colors, etc.) which limits its applicability over various datasets; I think that designing more principled approach to build such guidances from data should be one of the key contributions of the paper. In terms of evaluation, the authors only presented a few qualitative results on simple datasets, which is not comprehensive and convincing. In conclusion, I suggest a reject of this paper due to the lacks of comprehensive study and evaluation. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Principled Guidance ] The design of guidances is heuristic , but as illustrated in Figure 2 and in Table 2 , they are easy to design and are effective . Further , we added our unsupervised analyses to show that the method works even without explicit guidance on all tested datasets . In this paper , we propose the idea of guidance itself and show that it is imposing a desired semantics on the latent space without having labeled data . In our future work , we plan to investigate more principled ways of deciding guidances . We now address this point in our `` Discussion '' section . [ Experiments Section ] We have significantly updated qualitative and quantitative results in our `` Experiments '' section and now compare our methods against Beta-VAE , DIP-VAE , and InfoGAN ."}, "1": {"review_id": "H1e0-30qKm-1", "review_text": "Summary The paper presents a novel approach for learning a generative model where different factors of variations can be independently manipulated. The method is build upon the GAN framework where the latent variables are divided into different subsets (chunks) which are expected to encode information about high-level factors of variation. To this end, a Siamese Network for each chunk is trained with a contrastive loss minimizing the distance between generated images sharing the same factor (the latent variables in the chunk are equal), and maximizing the distance between pairs where the latent variables differ. Given that the proposed model fails in this fully-unsupervised setting, the authors propose to add weak-supervision into the model by forcing the Siamese networks to focus only on particular aspects of generated images (e.g, color, edges, etc..). This is achieved by applying a basic transformation over the input images in order to remove specific information. The evaluation of the proposed model is carried out using the MS-Celeb dataset where the authors provide qualitative results. Methodology *Disentangling generative factors without explicit labels is a challenging and interesting problem. The idea of dividing the latent representation in different subsets and using a proxy task involving triplets of images has been already explored in [3]. However, the use of Siamese networks in this context is novel and sound. *As shown in the reported results, the proposed method fails to learn meaningful factors in the unsupervised setting. However, the authors do not provide an in-depth discussion of this phenomena. Given that previous works [1,2,3] have successfully addressed this problem using a completely unsupervised approach, it would be necessary to give more insights about: (i) why the proposed method is failing (ii) why this negative result is interesting and (iii) if the method could be useful in other potential scenarios. *The strategy proposed to introduce weak-supervision is too ad-hoc. I agree that using cues such as the average color of an image can be useful if we want to model basic factors of variation. However, it is unclear how a similar strategy could be applied if we are interested in learning variables with higher-level semantics such as the expression of a face or its pose. *As far as I understand, the transformations applied to the input images (e.g, edge detection) must be differentiable (given that it is necessary to backpropagate the gradient of the contrastive loss through the generator network). If this is the case, this should be properly discussed in the paper. Moreover, given that the amount of differentiable transformations is reduced, this also limits the application of the proposed method for more interesting scenarios. *It is not clear why the latent variables modelling the generative factors are defined using a Gaussian prior. How the case where two images have a very similar latent factor is avoided while generating pairs of images for the Siamese network? Have the authors considered to use categorical or binary variables? The use of the contrastive loss sounds more appropriate in this case. Experimental results *The experimental section is too limited. First of all, only a small number of qualitative results are reported and, therefore, it is very difficult to assess the proposed method and draw any conclusion. For example, when the edge extractor is used, what kind of information is modeled by the latent variables? Is it consistent across different samples? Moreover, it is not clear why the authors have limited the evaluation to the case where only two \u201cchunks\u201d are used. In principle, the method could be applied with many more subsets of latent variables and then manually inspect them to check it they are semantically meaningful (see [2]) *As previously mentioned, there are many recent works addressing the same problem from a fully-unsupervised perspective [1,2,3]. All these works provide quantitative results evaluating the learned representations by using them to predict real labels (e.g, attributes in the CelebA data-set). The authors could provide a similar evaluation for their method by using the feature representations learned by the siamese networks in order to evaluate how much information they convey about real factors of variation. This could clarify the advantages of the weakly-supervised strategy compared to unsupervised approaches. Review summary +The addressed problem (learning disentangled representations without explicit labeling) is challenging and interesting. +The idea of using a proxy task (contrastive loss with triplets of generated images) is somewhat novel and promising. - The authors report only negative results for the fully-unsupervised version of UD-GAN The paper lacks and in-depth discussion about why this negative result is interesting. -The strategy proposed to provide weak-supervision to the model is too ad-hoc and it is not clear how to apply it in general applications -The experimental section do not clarify the benefits of the proposed approach. In particular, the qualitative results are too limited and no quantitative evaluations is provided. [1] Variational Inference of Disentangled Latent Concepts from Unlabelled Observations (Kumar et al, ICLR 2018) [2] Beta-vae: Learning basic visual concepts with a constrained variational framework. (Higgins et. al, ICLR 2017) [3] Disentangling Factors of Variation by Mixing Them. (Hu et. al, CVPR 2018) ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Unguided Case ] Please refer to our general comment above on why our unguided case performs better now . The main usefulness of our guided approach is to directly capture some of the desired variations in the data . This is now clearer on our quantitative and visual results in the \u201c Experiments \u201d section . [ Heuristic Guidance ] The main premise behind guiding our siamese networks is to find very simple , yet effective ways to capture some of the variation in the data , through weak supervision . For more complex semantics , we discuss the possibility of using a pre-trained network as guidance . Please refer to our \u201c Discussion \u201d section for more details . [ Differentiable Guidance ] The transformations need to be differentiable in order to backpropagate the gradients into our generator . This is now pointed out and discussed in our `` Discussion '' section . Although this limits the function families , we can still use differentiable relaxations of more complicated functions . [ Gaussian Prior on Latents ] In our new experiments , we used uniform distributions to model the generative factors . We had experiments with categorical variables , however , we faced training stability issues with them . We now point this out in our `` Discussion '' section . [ Similar Latent Factors ] We now use an adaptive margin that depends on the distance between two latent samples . So , if samples are close to each other , the margin is smaller , and vice versa . [ Experiments Section ] We now compare our method against Beta-VAE , DIP-VAE , and InfoGAN , both qualitatively and quantitatively . Please refer to our updated `` Experiments '' section . [ Information of Guidance ] In Figure 3 , we visualize which part of an image was visible to a siamese network . In addition , we show how changing the corresponding guided knob affects the generated images . [ More Than Two Attributes ] We now use 32 dimensions for the CelebA dataset and 10 dimensions for the 2D shapes dataset ."}, "2": {"review_id": "H1e0-30qKm-2", "review_text": "[EDIT]: I have updated my score after the author response and paper revision. ============================= [I was asked to step in as a reviewer last minute. I did not look at the other reviews]. ------------------------------- Summary ------------------------------- This paper proposes to learn disentangled latent states under the GAN framework. The core idea is to partition the latent states into N partitions, and correspondly have N Siamese networks that pull the generated images with the same latent partition towards each other, along with a contrastive loss which ensures generated images with different latent partitions to be different. The authors experiment with two setups: in the \"unguided setup\" training is completely unsupervised, while in the \"guided\" setup, there is some weak supervision to encourage different partitions to learn different factors. ------------------------------- Evaluation ------------------------------- While the motivation is nice, I find the results (especially in the unguided setup) underwhelming. This does not seem surprising to me, as in the unguided case, the constrative loss seems not strong enough to encourage the latent partitions to be different. Results with weak supervision (their method for injecting weak supervision was very nice) are more impressive. However, there is no comparison against existing work. Learning disentangled representations with deep generative models is very much an active area. Here are some recent papers: https://openreview.net/references/pdf?id=Sy2fzU9gl https://arxiv.org/abs/1802.05822 https://arxiv.org/abs/1802.05983 https://arxiv.org/abs/1802.04942 Importantly, there are no quantitative metrics. I do not think this work is ready for publication. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Unguided Case and Disentanglement ] Please refer to our general comment above on why our unguided case performs better now . We also updated our \u201c Probabilistic Interpretation \u201d section with analysis on how the contrastive loss helps us to learn a disentangled representation . Evidence and comparison to other methods on disentanglement is provided in Table 9 in Appendix G , where we visualize the correlations between our embedding dimensions . [ Experiments Section ] We have significantly updated qualitative and quantitative results in our `` Experiments '' section and now compare our methods against Beta-VAE , DIP-VAE , and InfoGAN ."}, "3": {"review_id": "H1e0-30qKm-3", "review_text": "The paper proposes a framework for learning interpretable latent representations for GANs. The key idea is to use siamese networks with contrastive loss. Specifically, it decomposes the latent code to a set of knobs (sub part of the latent code). Each time it renders different images with different configurations of the knobs. For example, 1) as changing one knob while keeping the others, it expects it would only result in change of one attribute in the image, and 2) as keeping one knob while changing all the others, it expects it would result in large change of image appearances. The relative magnitude of change for 1) and 2) justifies the use of a Siamese network in addition to the image discriminator in the standard GAN framework. The paper further talks about how to use inductive bias to design the Siamese network so that it can control the semantic meaning of a particular knob. While I do like the idea, I think the paper is still in the early stage. First of all, the paper does not include any numerical evaluation. It only shows a couple of examples. It is unclear how well the proposed method works in general. In addition, the InfoGAN work is designed for the same functionality. The paper should compare the proposed work to the InfoGAN work both quantitatively and qualitatively to justify its novelty. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank you for reviewing our paper . [ Experiments Section ] We have significantly updated qualitative and quantitative results in our `` Experiments '' section and now compare our methods against Beta-VAE , DIP-VAE , and InfoGAN . [ InfoGAN ] Compared to InfoGAN , our method is novel in two ways : First , we use separate networks to obtain the image embeddings , which enables us to guide some of these networks with simple functions . The guidance allows more control over the latent space , even in lack of data . Second , we use pairwise similarity/dissimilarity in order to perform disentangling , which is different from InfoGAN 's approach of maximizing the label likelihood . This point is now addressed in our `` Related Work '' section ."}}