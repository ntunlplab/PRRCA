{"year": "2021", "forum": "QzKDLiosEd", "title": "Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel", "decision": "Reject", "meta_review": "\nThe paper presents a side-channel attack in a scenario where the attacker is able to place a induction sensor near the power cable of the victim's GPU. The authors train a neural network to analyse the magnetic flux measured by the sensor to recover the structure (layer type and layer parameters) of the target neural network. The authors also show that for a wide range of target network structure, by training a network with the inferred structure, they produce adversarial examples as effective as a white box attack.\n\nThe points raised by the reviewers were the following: 1) the result that this type of side-channel attack works is interesting, 2) the practicality of the attack is unclear because the attacker needs hardware access to the victim's GPU, 3) the ML contribution is not really clear and a venue on cyber-security might be more appropriate. \n\nSide-channel attacks on deep neural networks can be of relevance to ICLR (as pointed to by the authors by the ICLR papers/submissions on system side-channel attacks). Nonetheless, I tend to agree with R1 and R2 that the ML contribution is limited (either in terms of application of ML or methodology), and the concerns of practicality of the approach make me lean towards rejection.", "reviews": [{"review_id": "QzKDLiosEd-0", "review_text": "# Summary : The paper presents a method for capturing the shape ( type of layers ) and their respective parameters of a neural network through the magnetic field induced as the GPU drains power . In particular , the GPU is snooped using an off-the-shelf magnetic induction sensor which is placed along the power cable of the GPU . It turns out that under some assumptions ( knowledge of GPU model and deep learning framework , knowledge of input size and ability to launch query of specific batch size ) , based on the correlation of the power consumption pattern of the GPU with the operations being performed it is possible to recognize the type of operation being performed as well as the respective hyper-parameters with very few errors . # Strengths : The paper presents a very interesting and novel method for `` spying '' on the Neural Network being executed on a GPU by capturing the magnetic signal induced by the GPU 's power consumption . A BiLSTM is employed to classify captured samplers of the magnetic signal to segments corresponding to specific steps/operations of the neural network . Then DNNs specific for each type of step are employed for estimating the hyper-parameters of each step . Consistency between the hyper-parameters is enforced by solving an integer-programming problem . The proposed method is able to recover the entire structure of various types of neural networks ( including randomly generated ones ) and the parameters of each step with very few errors . The similarity of the reconstructed networks is evaluated under various metrics , including the performance of target and reconstructed networks on a classification task . An interesting application is the use of the method to build surrogate models for performing black-box adversarial attacks with very high success rates . Possible counter-measures are proposed and the limitations of the method are also discussed . The paper is very well-written and easy to read . The evaluation is quite comprehensive showing the ability of the method to fully recover the architecture of various networks while further results and clarifications are provided in the supplemental material . # Weaknesses and Questions : Some interesting aspects are not completely covered . For example , although transferability to different hardware is discussed , still the sensitivity of the method with respect to some factors is not discussed . In particular , are there any calibration issues that should be taken into account ? How does the method perform if a sensor of different make is used with possible different sampling rate ? In what range of sampling rates/placement distances the method works ? Regarding GPU transferability , are the GPU pairs of the same make , frequency settings , etc . ? Additionally , regarding the segmentation of the samples in steps , one would expect that some over-segmentation issues would be present . Are there any measures for enforcing temporal consistency and for avoiding over-segmentation , or it is not an issue because the samples are so unambiguous ? Regarding the applicability of the proposed method , in real-world conditions it may not always be possible to define the input of the batch size . On this topic , more details can be provided on the strategy to be used to find a suitable batch size for the method to work . Additionally , the paper considers only networks acting as encoders . Would the method naturally extend to decoders or are there any difficulties/ambiguities introduced ? Also the paper focuses on the inference task , can the method be applied also for training tasks and with what adaptations ? Regarding the defenses , what happens if inference optimizers ( e.g.Tensor RT ) are used ? Is the performance of the method affected ? Also , does multi-GPU setups introduce interference ? # # Minor comments : * Figure 1 right : the abbreviations ( BN , MP ) , although common , should be explained in the text/caption . * Joint optimization paragraph : `` will generally not fully '' * page 5 before Section 4 : `` Were it that DNN '' # Rating Justification : Overall , I think that the paper is highly novel and introduces an interesting way to recover the architecture of a NN by using a cheap sensor . There are many questions that rise by this work mainly though due to its novel and intriguing nature . I am not 100 % sure that ICLR is the most suitable venue for this work , I am not considering though this aspect in my rating . # Rating and comments after the rebuttal I share the concerns of fellow reviewers regarding the practicality of the assumptions needed for launching the attack presented in the paper , however , based also on the discussion with the authors , I think that the paper is interesting regardless as it can lead to better insights regarding the development of suitable defence mechanisms for securing the architecture and the information carried by a Deep Learning model . I share also the concerns raised in the other reviews that the paper might be better appreciated by an audience focusing on cyber-security . However , I think that the subject can also be of relevance to ICLR as the paper made an effort to highlight the aspects more relevant to the ML community . Hence , leaving the aspect of relevance to the ACs ' discretion , I think that overall this is a clearly written paper based on well executed research that presents some interesting results that are potentially impactful in the aspects concerning security of systems employing Deep Learning models .", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the constructive feedback . We have updated our paper with the grammar and notation edits that were raised , and below we provide answers to your questions and concerns . > Sensitivity of Signal Extraction > > Are there any calibration issues that should be taken into account ? The only sensor calibration required is to ensure ( a ) that the sensor is within range of the electromagnetic signal and that ( b ) the sensor orientation is consistent . Since the magnetic induction signal decays inversely proportional to squared distance , we must place the sensor within 7mm of the GPU power cable . Flipping the flat sensor over will result in a sign change of the magnetic induction signal , thus a uniform orientation should be maintained to avoid having to align measurements across the dataset . We have updated the paper to include the above clarifications in Appendix C. > > How does the method perform if a sensor of different make is used with possible different sampling rate ? Previous works have attempted electromagnetic side-channel attacks with industrial probes such as the Langer RF-U 5-2 [ 1 ] . These sensors are rated to measure at higher frequencies ranging from 30MHz to 3GHz , but are far more costly ( \\\\ $ 1,500+ USD ) and require additional expensive equipment to operate . Other power side channel exploits have explored sampling at again higher rates varying from 400KHz to 2.5GHz [ 2 , 3 ] . Sampling at these frequencies allows finer capture of hardware operations that can ease network step classification , although it significantly increases the amount of feature data to be processed . By contrast , our method involves a \\\\ $ 3 USD sensor sampling at 47KHz . Sampling at lower rates than 47KHz would make it difficult to adequately capture short events on the GPU such as non-linear activation functions and small matrix multiplications that may occur . > > In what range of sampling rates/placement distances does the method work ? We were unable to vary the sampling rate of our sensor , and so all of our experiments use the factory 47KHz sampling frequency . Our measurements were taken at a distance of roughly 5mm from the GPUs power cable , although a reduced signal is still present up to 7-8mm away . > > Regarding GPU transferability , are the GPU pairs of the same make , frequency settings , etc . ? We acquired an identical make of our NVIDIA GTX-1080 GPU and used it to extract signals with the same sampling frequency of 47KHz when verifying transferability . > Signal Segmentation The segmented output of our classification network on the extracted signal is largely unambiguous . Operations that follow one another ( i.e.convolution , non-linear activation function , pooling ) are distinct in their signatures and easily captured from the context learned by the BiLSTM classifier . Issues arise for very small-sized steps , closer to the sensor \u2019 s sampling limit . In undersampled regions a non-linear activation may be over-segmented and split into two ( possibly different ) activation steps . To ensure consistency we postprocess the segmented results to ( 1 ) merge identical steps that are output in sequence , ( 2 ) cull out pooling before a non-linear activation , and ( 3 ) remove activation functions that are larger than the convolutions that precede them . We have updated the paper to include the above clarifications in Appendix A . > Determining the Batch Size > > Regarding the applicability of the proposed method , in real-world conditions it may not always be possible to define the input of the batch size . On this topic , more details can be provided on the strategy to be used to find a suitable batch size for the method to work . We are not sure that we fully understand the question , and we would appreciate a clarification . Here we provide an answer to our best interpretation of the question . To robustly recover network topology ( as opposed to hyperparameters ) , we do not require knowledge of batch size , only that the batch size is sufficiently large enough to provide a clear signal . While we used a \\\\ $ 3 sensor with limited sampling rate and signal-to-noise ratio ( SNR ) , a sensor with high sampling rate and SNR would correspondingly require a smaller minimum batch size . To estimate hyperparameters absent known batch size , others have considered fitting the proposed design with a known set of values using other heuristics or timing information [ 4 , 5 ] ; these approaches make assumptions on the family of networks within scope . On the other hand , to estimate hyperparameters for unfamiliar architectures , knowledge of input and batch size is required . We discuss two strategies here , the first of which we have tried successfully ."}, {"review_id": "QzKDLiosEd-1", "review_text": "Summary : - This paper studies the effectiveness of inferring a neural network \u2019 s layers and hyperparameters using the magnetic fields emitted from a GPU \u2019 s power cable . The results show that ( under certain assumptions ) one can reconstruct a neural network \u2019 s layers and hyperparameters accurately , and use the inferred model to launch adversarial transfer attacks . Strong points : - The idea of using magnetic side channels to infer network structure is interesting . - The paper is well-written with ideas and limitations explained clearly . - The experiment results are thorough and explained clearly Weak points : - The threat model seems impractical . Attacker assumptions include : - have physical access to the GPU - know the exact input feature dimensions and batch size . - know the deep learning framework , GPU brand and hardware/software versions . - The main innovation is demonstrating magnetic side channels from GPU cables reveal information about network structures . However , I \u2019 m not sure if ICLR is the best venue for this type of contribution . This paper could be a much stronger submission to other security and system conferences . Recommendation : - I \u2019 m inclined to recommend a reject . The main reason is that the results are based on multiple impractical assumptions , limiting the impact of this paper in reality . Comments & questions : - How do the authors imagine launching this attack in reality ? Specifically , how would one know the input dimensions and batch size of a black-box model ? A clear explanation of this will help readers understand the value of this work . - Using consistency constraints to optimize for hyperparameter estimation is interesting . How effective is this additional optimization compared with only using the initial estimation ? Minor comments - \u201c But there is \u2018 not \u2019 evidence proving \u201d - > \u2018 no \u2019 = Updates after the response = I thank the authors for answering the questions in detail . Providing an example application does help readers understand scenarios where the threat model could apply . However , I still think such scenarios are not common but agree that the findings in this paper could be helpful for future security research . I adjusted my rating based on this better understanding .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for the constructive feedback . We have updated our paper to remedy the grammar and clarification edits that were raised , and below we provide answers to your questions and concerns . > Clarification of Example Attack and Motivation > > Q : How do the authors imagine launching this attack in reality ? Specifically , how would one know the input dimensions and batch size of a black-box model ? A clear explanation of this will help readers understand the value of this work . For the specific question : Many side-channel attacks [ 1,2,3,4,5 ] involve running queries . If one can run a query , it means they can control the batch size ; it also means they know the input dimensions . Since running queries is not unusual for side-channel attacks , it follows that knowledge of input dimensions and batch size are not unusual either . Stepping back to the broader question : to set the stage , let us paint one concrete application . Imagine renting a vertically integrated internal cloud platform for ML ( e.g. , IBM Cloud Pak for Data with Watson Assistant deployed on local hardware [ 6 ] ) . Such platforms are designed to be tamper resistant : users should be able to access services via an application interface ( API ) , but not have access to easily reverse engineer details of the vendor \u2019 s proprietary design/architectures . While a user may be motivated to steal and replicate the design , their access is limited to the API and physical access , as opposed to \u201c virtual \u201d ( logic/software/programming ) access . Most broadly , the threat model presented in the paper ( page 1 ) offers interesting strengths and weaknesses compared to existing models . Because GPUs are now widespread in deep learning , having a variety of non-dominating threat models is useful . Compared to other attacking methods [ 7 , 8 ] , magnetic induction side-channel attacks do not require any code to run on the host machine in order to alter or leak logic . This makes electromagnetic side-channel attacks particularly attractive in cases where the attacker has no permission or opportunity to access software . These scenarios may lead to a false sense of security , since magnetic side channel exploits are pervasive and difficult to both detect and defeat [ 3 ] . Merely drawing power to perform operations can lead to changes in the nearby magnetic field for electricity driven hardware , making magnetic side-channel access to GPUs intrinsic . Our work explores the extent to which electromagnetic side-channels can leak network information in these settings . > Optimization vs Initial Estimate In Table S3 of the supplemental document , we show that initial hyperparameter estimates are quite accurate , when considering each in isolation . However , our goal is to recover a _valid_ architecture : layers/steps must have compatible dimensions and hyperparameters . Without optimization , we found that for all but the shallowest networks , one or more inconsistencies in the estimated hyperparameters invalidated the architecture . Therefore , the optimization is not only highly effective , but is indeed a strictly necessary step to ensure recovery of a fully valid architecture . References : 1 . Xiang et al , Open DNN Box by Power Side-Channel Attack , IEEE ToCaSII 2020 2 . Wei et al , I know What You See : Power Side-Channel Attack on Convolutional Neural Network Accelerators , ACSAC 2018 3 . Han et al , Watch Me , but Don \u2019 t Touch Me ! Contactless Control Flow Monitoring via Electromagnetic Emanations , ACM SIGSAC 2017 4 . Batina et al , CSI NN : Reverse engineering of neural network architectures through electromagnetic side channel , USENIX Security 2019 5 . Hua et al , Reverse Engineering Convolutional Neural Netowrks Through Side-channel Information Leaks , ACM DAC 2018 6 . IBM Cloud Pak for Data , https : //newsroom.ibm.com/2019-10-21-IBM-Advances-Watson-Anywhere-with-New-Clients-and-Innovations-Designed-to-Make-it-Even-Easier-to-Scale-AI-Across-Any-Cloud 7 . Hong et al , How to 0wn the NAS in Your Spare Time , ICLR 2020 8 . Hu et al , Deepsniffer : A dnn model extraction framework based on learning architectural hints , ASPLOS 2020"}, {"review_id": "QzKDLiosEd-2", "review_text": "This paper demonstrates that magnetic side channel information from a GPU ( that is processing a deep neural net ) can be snooped to recover the architecture and hyperparameters of the neural network . While the concept of side channel information snooping to recover codes/software ( including ML models ) is widely studied , the novelty claim is that recovering detailed structures of deep models is new . The paper also demonstrates that black-box attacks mounted using a recovered model is quite powerful compared to traditional black-box attacks . The paper is well-written and quite useful for the safety-critical applications community that use ML . However , there is no core ML contribution made in this paper . The authors use standard ML models to map the side channel signal to deep learning model architecture . The use of model architecture consistencies as constraints is clever , but nothing significant in terms of contributions to the ML community . So , in my opinion , this paper is better suited for other venues such as cyber security conferences .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for the constructive feedback . Below we provide answers to your concern . > Relevance to the ICLR community Our work follows recent published works in the machine learning community that investigate side-channel exploits used to recover network architectures in detail . Notably [ 1 ] , _published in ICLR 2020_ , sought to reconstruct network models from leaked side-channel information . Their approach relied entirely on non-learning computational methods to generate and prune candidate network models from their extracted trace . No novel ML method ( feature representations , layer definitions , or network compositions ) was claimed or introduced , rather , the novelty was the side-channel based reconstruction itself . Similarly , the reviews for [ 2 ] ( submitted concurrently to ICLR 2021 ) _do not question the relevance of side-channel attacks to ICLR_ ( here again the novelty is not in the ML method ) . As expressed in ICLR publications [ 1 , 2 ] , it is of great interest to the community to explore the hardware vulnerabilities of deployed deep learning systems . [ 1 ] argues that recovering network architectures is a good goal in its own right , and our method recovers more general and arbitrarily defined network specifications . We further progress their aims by tailoring an approach that specifically handles widely adopted GPU hardware , without installing or executing spyware ; we also introduce an optimization formulation for layer parameter estimation . References : 1 . Hong et al , How to 0wn the NAS in Your Spare Time , ICLR 2020 2 . Private Image Reconstruction From System Side Channels Using Generative Models , ICLR 2021 submission under review"}], "0": {"review_id": "QzKDLiosEd-0", "review_text": "# Summary : The paper presents a method for capturing the shape ( type of layers ) and their respective parameters of a neural network through the magnetic field induced as the GPU drains power . In particular , the GPU is snooped using an off-the-shelf magnetic induction sensor which is placed along the power cable of the GPU . It turns out that under some assumptions ( knowledge of GPU model and deep learning framework , knowledge of input size and ability to launch query of specific batch size ) , based on the correlation of the power consumption pattern of the GPU with the operations being performed it is possible to recognize the type of operation being performed as well as the respective hyper-parameters with very few errors . # Strengths : The paper presents a very interesting and novel method for `` spying '' on the Neural Network being executed on a GPU by capturing the magnetic signal induced by the GPU 's power consumption . A BiLSTM is employed to classify captured samplers of the magnetic signal to segments corresponding to specific steps/operations of the neural network . Then DNNs specific for each type of step are employed for estimating the hyper-parameters of each step . Consistency between the hyper-parameters is enforced by solving an integer-programming problem . The proposed method is able to recover the entire structure of various types of neural networks ( including randomly generated ones ) and the parameters of each step with very few errors . The similarity of the reconstructed networks is evaluated under various metrics , including the performance of target and reconstructed networks on a classification task . An interesting application is the use of the method to build surrogate models for performing black-box adversarial attacks with very high success rates . Possible counter-measures are proposed and the limitations of the method are also discussed . The paper is very well-written and easy to read . The evaluation is quite comprehensive showing the ability of the method to fully recover the architecture of various networks while further results and clarifications are provided in the supplemental material . # Weaknesses and Questions : Some interesting aspects are not completely covered . For example , although transferability to different hardware is discussed , still the sensitivity of the method with respect to some factors is not discussed . In particular , are there any calibration issues that should be taken into account ? How does the method perform if a sensor of different make is used with possible different sampling rate ? In what range of sampling rates/placement distances the method works ? Regarding GPU transferability , are the GPU pairs of the same make , frequency settings , etc . ? Additionally , regarding the segmentation of the samples in steps , one would expect that some over-segmentation issues would be present . Are there any measures for enforcing temporal consistency and for avoiding over-segmentation , or it is not an issue because the samples are so unambiguous ? Regarding the applicability of the proposed method , in real-world conditions it may not always be possible to define the input of the batch size . On this topic , more details can be provided on the strategy to be used to find a suitable batch size for the method to work . Additionally , the paper considers only networks acting as encoders . Would the method naturally extend to decoders or are there any difficulties/ambiguities introduced ? Also the paper focuses on the inference task , can the method be applied also for training tasks and with what adaptations ? Regarding the defenses , what happens if inference optimizers ( e.g.Tensor RT ) are used ? Is the performance of the method affected ? Also , does multi-GPU setups introduce interference ? # # Minor comments : * Figure 1 right : the abbreviations ( BN , MP ) , although common , should be explained in the text/caption . * Joint optimization paragraph : `` will generally not fully '' * page 5 before Section 4 : `` Were it that DNN '' # Rating Justification : Overall , I think that the paper is highly novel and introduces an interesting way to recover the architecture of a NN by using a cheap sensor . There are many questions that rise by this work mainly though due to its novel and intriguing nature . I am not 100 % sure that ICLR is the most suitable venue for this work , I am not considering though this aspect in my rating . # Rating and comments after the rebuttal I share the concerns of fellow reviewers regarding the practicality of the assumptions needed for launching the attack presented in the paper , however , based also on the discussion with the authors , I think that the paper is interesting regardless as it can lead to better insights regarding the development of suitable defence mechanisms for securing the architecture and the information carried by a Deep Learning model . I share also the concerns raised in the other reviews that the paper might be better appreciated by an audience focusing on cyber-security . However , I think that the subject can also be of relevance to ICLR as the paper made an effort to highlight the aspects more relevant to the ML community . Hence , leaving the aspect of relevance to the ACs ' discretion , I think that overall this is a clearly written paper based on well executed research that presents some interesting results that are potentially impactful in the aspects concerning security of systems employing Deep Learning models .", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the constructive feedback . We have updated our paper with the grammar and notation edits that were raised , and below we provide answers to your questions and concerns . > Sensitivity of Signal Extraction > > Are there any calibration issues that should be taken into account ? The only sensor calibration required is to ensure ( a ) that the sensor is within range of the electromagnetic signal and that ( b ) the sensor orientation is consistent . Since the magnetic induction signal decays inversely proportional to squared distance , we must place the sensor within 7mm of the GPU power cable . Flipping the flat sensor over will result in a sign change of the magnetic induction signal , thus a uniform orientation should be maintained to avoid having to align measurements across the dataset . We have updated the paper to include the above clarifications in Appendix C. > > How does the method perform if a sensor of different make is used with possible different sampling rate ? Previous works have attempted electromagnetic side-channel attacks with industrial probes such as the Langer RF-U 5-2 [ 1 ] . These sensors are rated to measure at higher frequencies ranging from 30MHz to 3GHz , but are far more costly ( \\\\ $ 1,500+ USD ) and require additional expensive equipment to operate . Other power side channel exploits have explored sampling at again higher rates varying from 400KHz to 2.5GHz [ 2 , 3 ] . Sampling at these frequencies allows finer capture of hardware operations that can ease network step classification , although it significantly increases the amount of feature data to be processed . By contrast , our method involves a \\\\ $ 3 USD sensor sampling at 47KHz . Sampling at lower rates than 47KHz would make it difficult to adequately capture short events on the GPU such as non-linear activation functions and small matrix multiplications that may occur . > > In what range of sampling rates/placement distances does the method work ? We were unable to vary the sampling rate of our sensor , and so all of our experiments use the factory 47KHz sampling frequency . Our measurements were taken at a distance of roughly 5mm from the GPUs power cable , although a reduced signal is still present up to 7-8mm away . > > Regarding GPU transferability , are the GPU pairs of the same make , frequency settings , etc . ? We acquired an identical make of our NVIDIA GTX-1080 GPU and used it to extract signals with the same sampling frequency of 47KHz when verifying transferability . > Signal Segmentation The segmented output of our classification network on the extracted signal is largely unambiguous . Operations that follow one another ( i.e.convolution , non-linear activation function , pooling ) are distinct in their signatures and easily captured from the context learned by the BiLSTM classifier . Issues arise for very small-sized steps , closer to the sensor \u2019 s sampling limit . In undersampled regions a non-linear activation may be over-segmented and split into two ( possibly different ) activation steps . To ensure consistency we postprocess the segmented results to ( 1 ) merge identical steps that are output in sequence , ( 2 ) cull out pooling before a non-linear activation , and ( 3 ) remove activation functions that are larger than the convolutions that precede them . We have updated the paper to include the above clarifications in Appendix A . > Determining the Batch Size > > Regarding the applicability of the proposed method , in real-world conditions it may not always be possible to define the input of the batch size . On this topic , more details can be provided on the strategy to be used to find a suitable batch size for the method to work . We are not sure that we fully understand the question , and we would appreciate a clarification . Here we provide an answer to our best interpretation of the question . To robustly recover network topology ( as opposed to hyperparameters ) , we do not require knowledge of batch size , only that the batch size is sufficiently large enough to provide a clear signal . While we used a \\\\ $ 3 sensor with limited sampling rate and signal-to-noise ratio ( SNR ) , a sensor with high sampling rate and SNR would correspondingly require a smaller minimum batch size . To estimate hyperparameters absent known batch size , others have considered fitting the proposed design with a known set of values using other heuristics or timing information [ 4 , 5 ] ; these approaches make assumptions on the family of networks within scope . On the other hand , to estimate hyperparameters for unfamiliar architectures , knowledge of input and batch size is required . We discuss two strategies here , the first of which we have tried successfully ."}, "1": {"review_id": "QzKDLiosEd-1", "review_text": "Summary : - This paper studies the effectiveness of inferring a neural network \u2019 s layers and hyperparameters using the magnetic fields emitted from a GPU \u2019 s power cable . The results show that ( under certain assumptions ) one can reconstruct a neural network \u2019 s layers and hyperparameters accurately , and use the inferred model to launch adversarial transfer attacks . Strong points : - The idea of using magnetic side channels to infer network structure is interesting . - The paper is well-written with ideas and limitations explained clearly . - The experiment results are thorough and explained clearly Weak points : - The threat model seems impractical . Attacker assumptions include : - have physical access to the GPU - know the exact input feature dimensions and batch size . - know the deep learning framework , GPU brand and hardware/software versions . - The main innovation is demonstrating magnetic side channels from GPU cables reveal information about network structures . However , I \u2019 m not sure if ICLR is the best venue for this type of contribution . This paper could be a much stronger submission to other security and system conferences . Recommendation : - I \u2019 m inclined to recommend a reject . The main reason is that the results are based on multiple impractical assumptions , limiting the impact of this paper in reality . Comments & questions : - How do the authors imagine launching this attack in reality ? Specifically , how would one know the input dimensions and batch size of a black-box model ? A clear explanation of this will help readers understand the value of this work . - Using consistency constraints to optimize for hyperparameter estimation is interesting . How effective is this additional optimization compared with only using the initial estimation ? Minor comments - \u201c But there is \u2018 not \u2019 evidence proving \u201d - > \u2018 no \u2019 = Updates after the response = I thank the authors for answering the questions in detail . Providing an example application does help readers understand scenarios where the threat model could apply . However , I still think such scenarios are not common but agree that the findings in this paper could be helpful for future security research . I adjusted my rating based on this better understanding .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for the constructive feedback . We have updated our paper to remedy the grammar and clarification edits that were raised , and below we provide answers to your questions and concerns . > Clarification of Example Attack and Motivation > > Q : How do the authors imagine launching this attack in reality ? Specifically , how would one know the input dimensions and batch size of a black-box model ? A clear explanation of this will help readers understand the value of this work . For the specific question : Many side-channel attacks [ 1,2,3,4,5 ] involve running queries . If one can run a query , it means they can control the batch size ; it also means they know the input dimensions . Since running queries is not unusual for side-channel attacks , it follows that knowledge of input dimensions and batch size are not unusual either . Stepping back to the broader question : to set the stage , let us paint one concrete application . Imagine renting a vertically integrated internal cloud platform for ML ( e.g. , IBM Cloud Pak for Data with Watson Assistant deployed on local hardware [ 6 ] ) . Such platforms are designed to be tamper resistant : users should be able to access services via an application interface ( API ) , but not have access to easily reverse engineer details of the vendor \u2019 s proprietary design/architectures . While a user may be motivated to steal and replicate the design , their access is limited to the API and physical access , as opposed to \u201c virtual \u201d ( logic/software/programming ) access . Most broadly , the threat model presented in the paper ( page 1 ) offers interesting strengths and weaknesses compared to existing models . Because GPUs are now widespread in deep learning , having a variety of non-dominating threat models is useful . Compared to other attacking methods [ 7 , 8 ] , magnetic induction side-channel attacks do not require any code to run on the host machine in order to alter or leak logic . This makes electromagnetic side-channel attacks particularly attractive in cases where the attacker has no permission or opportunity to access software . These scenarios may lead to a false sense of security , since magnetic side channel exploits are pervasive and difficult to both detect and defeat [ 3 ] . Merely drawing power to perform operations can lead to changes in the nearby magnetic field for electricity driven hardware , making magnetic side-channel access to GPUs intrinsic . Our work explores the extent to which electromagnetic side-channels can leak network information in these settings . > Optimization vs Initial Estimate In Table S3 of the supplemental document , we show that initial hyperparameter estimates are quite accurate , when considering each in isolation . However , our goal is to recover a _valid_ architecture : layers/steps must have compatible dimensions and hyperparameters . Without optimization , we found that for all but the shallowest networks , one or more inconsistencies in the estimated hyperparameters invalidated the architecture . Therefore , the optimization is not only highly effective , but is indeed a strictly necessary step to ensure recovery of a fully valid architecture . References : 1 . Xiang et al , Open DNN Box by Power Side-Channel Attack , IEEE ToCaSII 2020 2 . Wei et al , I know What You See : Power Side-Channel Attack on Convolutional Neural Network Accelerators , ACSAC 2018 3 . Han et al , Watch Me , but Don \u2019 t Touch Me ! Contactless Control Flow Monitoring via Electromagnetic Emanations , ACM SIGSAC 2017 4 . Batina et al , CSI NN : Reverse engineering of neural network architectures through electromagnetic side channel , USENIX Security 2019 5 . Hua et al , Reverse Engineering Convolutional Neural Netowrks Through Side-channel Information Leaks , ACM DAC 2018 6 . IBM Cloud Pak for Data , https : //newsroom.ibm.com/2019-10-21-IBM-Advances-Watson-Anywhere-with-New-Clients-and-Innovations-Designed-to-Make-it-Even-Easier-to-Scale-AI-Across-Any-Cloud 7 . Hong et al , How to 0wn the NAS in Your Spare Time , ICLR 2020 8 . Hu et al , Deepsniffer : A dnn model extraction framework based on learning architectural hints , ASPLOS 2020"}, "2": {"review_id": "QzKDLiosEd-2", "review_text": "This paper demonstrates that magnetic side channel information from a GPU ( that is processing a deep neural net ) can be snooped to recover the architecture and hyperparameters of the neural network . While the concept of side channel information snooping to recover codes/software ( including ML models ) is widely studied , the novelty claim is that recovering detailed structures of deep models is new . The paper also demonstrates that black-box attacks mounted using a recovered model is quite powerful compared to traditional black-box attacks . The paper is well-written and quite useful for the safety-critical applications community that use ML . However , there is no core ML contribution made in this paper . The authors use standard ML models to map the side channel signal to deep learning model architecture . The use of model architecture consistencies as constraints is clever , but nothing significant in terms of contributions to the ML community . So , in my opinion , this paper is better suited for other venues such as cyber security conferences .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for the constructive feedback . Below we provide answers to your concern . > Relevance to the ICLR community Our work follows recent published works in the machine learning community that investigate side-channel exploits used to recover network architectures in detail . Notably [ 1 ] , _published in ICLR 2020_ , sought to reconstruct network models from leaked side-channel information . Their approach relied entirely on non-learning computational methods to generate and prune candidate network models from their extracted trace . No novel ML method ( feature representations , layer definitions , or network compositions ) was claimed or introduced , rather , the novelty was the side-channel based reconstruction itself . Similarly , the reviews for [ 2 ] ( submitted concurrently to ICLR 2021 ) _do not question the relevance of side-channel attacks to ICLR_ ( here again the novelty is not in the ML method ) . As expressed in ICLR publications [ 1 , 2 ] , it is of great interest to the community to explore the hardware vulnerabilities of deployed deep learning systems . [ 1 ] argues that recovering network architectures is a good goal in its own right , and our method recovers more general and arbitrarily defined network specifications . We further progress their aims by tailoring an approach that specifically handles widely adopted GPU hardware , without installing or executing spyware ; we also introduce an optimization formulation for layer parameter estimation . References : 1 . Hong et al , How to 0wn the NAS in Your Spare Time , ICLR 2020 2 . Private Image Reconstruction From System Side Channels Using Generative Models , ICLR 2021 submission under review"}}