{"year": "2020", "forum": "HJepXaVYDr", "title": "Stochastic AUC Maximization with Deep Neural Networks", "decision": "Accept (Poster)", "meta_review": "The paper proposed using stochastic AUC for dealing with imbalanced data. This paper provides useful insights and experiments on this important problem. I recommend acceptance.", "reviews": [{"review_id": "HJepXaVYDr-0", "review_text": "This paper proposes two algorithms for the non-convex concave AUC maximization problem, along with theoretical analysis. Experiments show the proposed methods are effective, especially in data imbalanced scenarios. Strengths: This paper might be useful and interesting to related research, which overcomes some limitations in previous works such as: 1. the convex assumptions; 2. only considering simple models like linear models; 3. the need of extra memory to store/maintain samples. The proposed method extends existing works to a non-convex setting, which can be applied to deep neural networks, and is applicable for batch-learning and online learning. The proposed methods achieve better experimental results, especially in the data imbalanced scenarios, which is a real problem that may arise in many scenarios. The paper provides theoretical analysis on the proposed methods, based on Assumption 1, and inspired by the PL condition. Weaknesses: I think some comparisons with AdaGrad and related methods should be performed in experiments. Since PPD-AdaGrad is \u201cAdaGrad style\u201d. The assumptions seem a bit unclear. What does the first assumption in Assumption 1 imply? Minor Comments: 1. Since the experiments label the first 5/50 classes as negative, and the last 5/50 classes as positive for CIFAR10/CIFAR100, is it possible to provide results on experiments that label in the opposite way (or randomly label 5/50 classes) and add these results in the paper/appendix? Just to make results more convincing and reduce some potential dataset influences. 2. Is it possible to provide some results on more imbalanced positive-negative ratio like 20:1? 3. Is it possible to provide some comparison in terms of actual time, like learning curves with time as x-axis? 4. In the multi-class problems, why are the lower layers shared while last layer separated? 5. Since the extension to multi-classes problems are mentioned in the paper. I like to see some experimental results on this setting. 6. How do the proposed methods perform on models other than NN? 7. I think there is a typo on Page 4, the definition of AUC definition: the latter y should be -1. ", "rating": "6: Weak Accept", "reply_text": "Thank you for your constructive comments . Q1 : I think some comparisons with AdaGrad and related methods should be performed in experiments . Since PPD-Adagrad is \u201c Adagrad style \u201d . A : To the best of our knowledge , AdaGrad can not be directly applied to solving stochastic AUC maximization problem . So we have included the results when applying AdaGrad for minimizing cross-entropy loss . These results are included in Figure 3 on page 22 . Q2 : The assumptions seem a bit unclear . What does the first assumption in Assumption 1 imply ? A : The first assumption in Assumption 1 is PL condition on the function $ \\phi $ . It implies that when the gradient of $ \\phi $ is small , then the objective value is close to the optimal value up to a multiplicative constant $ \\mu $ . Q3 : Is it possible to provide results on experiments that label in the opposite way ( or randomly label 5/50 classes ) and add these results in the paper/appendix ? Just to make results more convincing and reduce some potential dataset influences . A : For CIFAR10 and STL10 dataset , we randomly partition the 10 classes into two labels ( i.e. , randomly select 5 classes as positive label and other 5 classes as negative label ) . For CIFAR100 dataset , we randomly partition the 100 classes into two labels ( i.e. , randomly select 50 classes as positive label and other 50 classes as negative label ) . We have added a description at Appendix A.10 on page 21 and also included the corresponding results in Figure 3 on page 22 . Q4 : Is it possible to provide some results on more imbalanced positive-negative ratio like 20:1 ? Is it possible to provide some comparison in terms of actual time , like learning curves with time as x-axis ? A : We have done more experiments for more imbalanced ratios , i.e. , 20:1 and 10:1 , and the results are plotted in Figure 3 in the supplement . In particular , in order to create the imbalanced data with 20:1 positive-negative ratio ( top four plots ) , we remove 95 % examples with negative label from the original data . The four plots on the bottom are the results with 10:1 positive-negative ratio , for which the data is created by removing 90 % examples from the original data . The plot about AUC curve versus actual time is also provided . Q5 : In the multi-class problems , why are the lower layers shared while last layer separated ? A : What we meant is that the last layer denotes the classifier and each individual class has a corresponding classifier $ h ( w_c , x ) $ . All of these classifiers are built on the same feature induced by the same lower layers . Q6 : Since the extension to multi-classes problems are mentioned in the paper . I like to see some experimental results on this setting . A : Due to time constraint , we are not able to finish this experiment during the rebuttal . We expect to include the results in the final version . Q7 : How do the proposed methods perform on models other than NN ? A : We tried linear model but it did not work very well for complex image datasets as used in the experiments . Q8 : Typo on Page 4 , the definition of AUC definition : the latter y should be -1 . A : Thank you for carefully reading our paper ! You are absolutely right and we have fixed this typo in the revision ."}, {"review_id": "HJepXaVYDr-1", "review_text": "Summary: The authors propose stochastic algorithms for AUC maximization using a deep neural network. Under the assumption that the underlying function satisfies the PL condition, they prove convergence rates of the proposed algorithms. The key insight is to use the equivalence between AUC maximization and some min-max function. Experiments results show the proposed algorithms works better than some baselines. Comments: The technical contribution is to show stochastic optimization algorithms for some kind of min-max functions converge to the optimum under the PL condition. The proposed algorithms have better convergence rates than a na\u00efve application of Rafique et al. The technical results rely on previous work on the PL condition and stochastic optimization of min-max functions. The techniques are not straightforward but not seem to be highly innovative, either. As a summary, non-trivial algorithms for AUC maximization with neural networks are presented, which could be useful in practice. Minor Comments: -How the validation data for tuning parameter are chosen in the experiments? This is absent in the descriptions for experiments. ", "rating": "6: Weak Accept", "reply_text": "Thank you for your insightful comments . We have included the description of the way we chose validation dataset . The revision has been highlighted in red . Q : How the validation data for tuning parameters are chosen in the experiments ? This is absent in the descriptions for experiments . A : We use 19k/1k , 45k/5k , 45k/5k , 4k/1k training/validation split on C2 , C10 , C100 , and STL10 respectively . We have included this description in Section 5 on page 9 ."}, {"review_id": "HJepXaVYDr-2", "review_text": "The authors propose two modifications to an algorithm from [Rafique et al 2018] for optimizing AUC under a min-max formulation, prove bounds for the two modifications, and experimentally compare the modifications against SGD and the original algorithm by varying class ratios of four datasets. The proposal builds on [Rafique et al 2018], so it may be considered incremental. However, the algorithm is carefully analyzed and resulting bounds are stronger. The experimental analysis is fairly minimal, with the proposed modifications performing similarly to the original algorithm from [Rafique et al 2018].", "rating": "6: Weak Accept", "reply_text": "Thank you for your valuable comments and constructive feedback ."}], "0": {"review_id": "HJepXaVYDr-0", "review_text": "This paper proposes two algorithms for the non-convex concave AUC maximization problem, along with theoretical analysis. Experiments show the proposed methods are effective, especially in data imbalanced scenarios. Strengths: This paper might be useful and interesting to related research, which overcomes some limitations in previous works such as: 1. the convex assumptions; 2. only considering simple models like linear models; 3. the need of extra memory to store/maintain samples. The proposed method extends existing works to a non-convex setting, which can be applied to deep neural networks, and is applicable for batch-learning and online learning. The proposed methods achieve better experimental results, especially in the data imbalanced scenarios, which is a real problem that may arise in many scenarios. The paper provides theoretical analysis on the proposed methods, based on Assumption 1, and inspired by the PL condition. Weaknesses: I think some comparisons with AdaGrad and related methods should be performed in experiments. Since PPD-AdaGrad is \u201cAdaGrad style\u201d. The assumptions seem a bit unclear. What does the first assumption in Assumption 1 imply? Minor Comments: 1. Since the experiments label the first 5/50 classes as negative, and the last 5/50 classes as positive for CIFAR10/CIFAR100, is it possible to provide results on experiments that label in the opposite way (or randomly label 5/50 classes) and add these results in the paper/appendix? Just to make results more convincing and reduce some potential dataset influences. 2. Is it possible to provide some results on more imbalanced positive-negative ratio like 20:1? 3. Is it possible to provide some comparison in terms of actual time, like learning curves with time as x-axis? 4. In the multi-class problems, why are the lower layers shared while last layer separated? 5. Since the extension to multi-classes problems are mentioned in the paper. I like to see some experimental results on this setting. 6. How do the proposed methods perform on models other than NN? 7. I think there is a typo on Page 4, the definition of AUC definition: the latter y should be -1. ", "rating": "6: Weak Accept", "reply_text": "Thank you for your constructive comments . Q1 : I think some comparisons with AdaGrad and related methods should be performed in experiments . Since PPD-Adagrad is \u201c Adagrad style \u201d . A : To the best of our knowledge , AdaGrad can not be directly applied to solving stochastic AUC maximization problem . So we have included the results when applying AdaGrad for minimizing cross-entropy loss . These results are included in Figure 3 on page 22 . Q2 : The assumptions seem a bit unclear . What does the first assumption in Assumption 1 imply ? A : The first assumption in Assumption 1 is PL condition on the function $ \\phi $ . It implies that when the gradient of $ \\phi $ is small , then the objective value is close to the optimal value up to a multiplicative constant $ \\mu $ . Q3 : Is it possible to provide results on experiments that label in the opposite way ( or randomly label 5/50 classes ) and add these results in the paper/appendix ? Just to make results more convincing and reduce some potential dataset influences . A : For CIFAR10 and STL10 dataset , we randomly partition the 10 classes into two labels ( i.e. , randomly select 5 classes as positive label and other 5 classes as negative label ) . For CIFAR100 dataset , we randomly partition the 100 classes into two labels ( i.e. , randomly select 50 classes as positive label and other 50 classes as negative label ) . We have added a description at Appendix A.10 on page 21 and also included the corresponding results in Figure 3 on page 22 . Q4 : Is it possible to provide some results on more imbalanced positive-negative ratio like 20:1 ? Is it possible to provide some comparison in terms of actual time , like learning curves with time as x-axis ? A : We have done more experiments for more imbalanced ratios , i.e. , 20:1 and 10:1 , and the results are plotted in Figure 3 in the supplement . In particular , in order to create the imbalanced data with 20:1 positive-negative ratio ( top four plots ) , we remove 95 % examples with negative label from the original data . The four plots on the bottom are the results with 10:1 positive-negative ratio , for which the data is created by removing 90 % examples from the original data . The plot about AUC curve versus actual time is also provided . Q5 : In the multi-class problems , why are the lower layers shared while last layer separated ? A : What we meant is that the last layer denotes the classifier and each individual class has a corresponding classifier $ h ( w_c , x ) $ . All of these classifiers are built on the same feature induced by the same lower layers . Q6 : Since the extension to multi-classes problems are mentioned in the paper . I like to see some experimental results on this setting . A : Due to time constraint , we are not able to finish this experiment during the rebuttal . We expect to include the results in the final version . Q7 : How do the proposed methods perform on models other than NN ? A : We tried linear model but it did not work very well for complex image datasets as used in the experiments . Q8 : Typo on Page 4 , the definition of AUC definition : the latter y should be -1 . A : Thank you for carefully reading our paper ! You are absolutely right and we have fixed this typo in the revision ."}, "1": {"review_id": "HJepXaVYDr-1", "review_text": "Summary: The authors propose stochastic algorithms for AUC maximization using a deep neural network. Under the assumption that the underlying function satisfies the PL condition, they prove convergence rates of the proposed algorithms. The key insight is to use the equivalence between AUC maximization and some min-max function. Experiments results show the proposed algorithms works better than some baselines. Comments: The technical contribution is to show stochastic optimization algorithms for some kind of min-max functions converge to the optimum under the PL condition. The proposed algorithms have better convergence rates than a na\u00efve application of Rafique et al. The technical results rely on previous work on the PL condition and stochastic optimization of min-max functions. The techniques are not straightforward but not seem to be highly innovative, either. As a summary, non-trivial algorithms for AUC maximization with neural networks are presented, which could be useful in practice. Minor Comments: -How the validation data for tuning parameter are chosen in the experiments? This is absent in the descriptions for experiments. ", "rating": "6: Weak Accept", "reply_text": "Thank you for your insightful comments . We have included the description of the way we chose validation dataset . The revision has been highlighted in red . Q : How the validation data for tuning parameters are chosen in the experiments ? This is absent in the descriptions for experiments . A : We use 19k/1k , 45k/5k , 45k/5k , 4k/1k training/validation split on C2 , C10 , C100 , and STL10 respectively . We have included this description in Section 5 on page 9 ."}, "2": {"review_id": "HJepXaVYDr-2", "review_text": "The authors propose two modifications to an algorithm from [Rafique et al 2018] for optimizing AUC under a min-max formulation, prove bounds for the two modifications, and experimentally compare the modifications against SGD and the original algorithm by varying class ratios of four datasets. The proposal builds on [Rafique et al 2018], so it may be considered incremental. However, the algorithm is carefully analyzed and resulting bounds are stronger. The experimental analysis is fairly minimal, with the proposed modifications performing similarly to the original algorithm from [Rafique et al 2018].", "rating": "6: Weak Accept", "reply_text": "Thank you for your valuable comments and constructive feedback ."}}