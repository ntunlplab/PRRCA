{"year": "2021", "forum": "BbNIbVPJ-42", "title": "The Risks of Invariant Risk Minimization", "decision": "Accept (Poster)", "meta_review": "The authors have made significant efforts to thoroughly address all the concerns. Due to the amount of discussions, I had to go through the paper myself and agree with the authors on many of the points. In my opinion, this is a solid theoretical work on the pitfalls of IRM. ", "reviews": [{"review_id": "BbNIbVPJ-42-0", "review_text": "Pros : * The work gives extended theoretical analysis on the effect of invariant risk minimization scheme , which is an increasingly popular framework for robust prediction . The work considerably extends the results in the original IRM paper . The results seem reasonable , and clarify implausible beliefs on the framework . The intuitions and proving techniques could also inspire new methods to improve the current framework . Cons ( minor issues ) : * I know the main contribution of the work is on the theoretical side , but a simple experiment or simulation for the nonlinear case to demonstrate the empirical consequence would be appreciated . * In the considered data generating model , it is assumed that $ z_c \\perp z_e | y $ ( conditional independence ) . Is it required in the proofs ? How natural/general can it be ? For one example , it is mentioned that the causation can be viewed in the other direction , i.e. $ z \\to y $ . In that case , observing $ y $ would render components of $ z $ correlated . Also , a graphical illustration of the data generating model would be helpful . * OOD generalization to an arbitrary environment in the nonlinear case ( even with the invariant optimal predictor on top of representations ) may not be possible anyway , and some recent works on OOD generalization does not expect the learned model to work well in environments out of the convex hull/combination of training environments . So I am wondering how arbitrary can the test environment be in Theorem 6.1 , e.g. , can it be out of the convex hull/combination of training environment ? The result would seem more interesting to me if the test environment can be . EDIT : post-rebuttal Thanks for the additional explanations .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review ! To address your minor concerns : * Unfortunately , the lack of existing techniques for stable training , hyperparameter choice , etc . makes informative nonlinear experiments difficult ( See the related discussion in [ 1 ] ) . We can point you to [ 2 ] for existing experimental evidence of the failure of IRM and other OOD generalization techniques in the non-linear regime . * Our proofs apply to the model we consider in the paper . While developing this work , we considered several models and achieved varying levels of success in showing similar results in each of them . It is not immediately clear to us if conditional independence is * necessary * to show such results , but our proofs in the linear case do use this fact ; in the non-linear case we do not rely on such independence . We note that such an assumption would seem to make the job of learning invariances * strictly easier * , so the fact that IRM doesn \u2019 t work in this case is even more surprising . We agree that a graphical model depiction would be helpful ; we intend to include this in the camera-ready version . * Theorem 6.1 makes no assumptions whatsoever on the test environment , other than being sufficiently far from the training environments . So it applies equally to test environments that are inside or outside the convex hull . In particular , this implies that even if some IRM-based technique * does * generalize to the convex hull of training environments in the linear case , it will not work in the non-linear case . This is because the \u201c convex hull \u201d argument typically relies upon restricting degrees of freedom and , as we discuss in section 6 , this argument does not generalize when we introduce non-linearity . Please tell us if you have any other questions or concerns ! In particular , let us know if there is anything we can clarify which would increase your confidence in the quality of this work . [ 1 ] Out-of-Distribution Generalization via Risk Extrapolation ( REx ) . Krueger et al. , 2020. https : //arxiv.org/abs/2003.00688 [ 2 ] In Search of Lost Domain Generalization . Ishaan Gulrajani and David Lopez-Paz , 2020. https : //arxiv.org/abs/2007.01434"}, {"review_id": "BbNIbVPJ-42-1", "review_text": "The paper , entitled `` The Risks of Invariant Risk Minimization '' , provides a theoretical analysis of the IRM learning objective under particular conditions . It claims to provide two theoretical results , namely : 1 ) in the linear setting ( i.e. , the optimal model is linear ) , they provide a necessary and sufficient condition for IRM to recover the optimal invariant predictor . 2 ) in the non-linear setting , they demonstrate that IRM does not perform better than ERM ( empirical risk minimization ) . Strong points of the paper : 1 ) the paper addresses an important question : what are the theoretical guarantees of the IRM objective ? 2 ) the paper provides a solid argument against the IRM objective , which is shown to be no better than ERM , in a limited but non-trivial setting 3 ) the paper tries to relate IRM to several prior works from the literature Weak points of the paper : 1 ) I believe the paper contains a major flaw : the so-called `` invariant classifier '' , which uses only invariant features , is not the optimal invariant predictor sought by IRM . As such the first claim of the authors , necessary and sufficient conditions under which IRM recovers the optimal invariant predictor in the linear setting , is wrong . 2 ) The paper suffers from a poor structure , a lack of clarity , and a general lack of rigor in the definition of the key concepts . Despite commendable efforts from the authors to study IRM theoretically , even in a limited setting , I recommend rejection for the paper . First , while it appears rather theoretical , the paper lacks rigor and clarity in the definition of the problem , the key concepts , and the assumptions . The description of the OOD generalization problem , of IRM and its assumptions , of the assumptions made by the authors in their simplified model , and of the introduced concepts ( notably the `` invariant classifier '' ) , are lacking a formal mathematical description . The main results of the paper are given in Section 3 , before the studied object , IRM , is even formally introduced in Section 4 . The authors interchangeably use the adjectives `` causal '' or `` invariant '' , without having properly defined the meaning of those concepts in the first place , and with no particular utility . Maybe IRM can be given a causal interpretation , under some assumptions , but clearly this is out of the scope of the paper . The theoretical analysis of IRM conducted in the paper does not require the notion of causality , which only brings confusion to the paper in my opinion . Second , and most importantly , I believe that one of the author 's claims ( which occupies about half the paper ) is simply wrong ( see my detailed comments below with a counter-example ) . There seems to be a misunderstanding as to what IRM actually seeks for , which is not the so-called `` invariant classifier '' that uses only invariant features . IRM does not seek to use invariant features only , but to learn those invariant features , possibly by using non-invariant ones . As such , results such as Theorem 5.1 , Corollary 5.2 , and Theorem 5.3 , have very little value I think . The second claim of the authors remains interesting , however I believe the paper requires a substantial revision and in its current state can not be accepted at ICLR . I would appreciate if the authors could formally describe what they mean by `` invariant classifier '' , and point me to the evidence where the IRM authors argue that IRM will recover such a classifier . * * Post-discussions * * : the authors have clarified the meaning of `` invariant classifier '' , which is now tied to their specific toy problem , and I now believe such a classifier is indeed the minimax OOD classifier supposedly seeked by IRM . While I still think the paper does not shine on the side of clarity , my main concern about the incorrectness of the presented theorems has been answered and I believe the paper will be of interest to the community . I therefore raise my recommendation towards acceptance . Below are my detailed comments : p.1 \u00a73 : each environment corresponds to interventions on the SEM ( Pearl , 2009 ) on just the non-causal mechanisms - > What does non-causal mechanism mean here ? If the SEM is given a causal interpretation , then all mechanisms are causal . Do you mean the mechanisms which are not causaly impacting the variable of interest Y ? p.1 \u00a73 : invariant features in the SEM - > Do you mean the causal features ? Or the invariant mechanisms ? Invariant features does not make sense . If interpreted as constant features , those are uninformative . If interpreted as having the same distribution across environments , this does not make sense either , since it does not guarantee such a feature will be causal . p.2 \u00a75 : invariance of the feature-conditioned label distribution - > I like the effort the authors put in grouping the existing works in a unified framework and notation . There is however a bit of inconsistency and ambiguity in the terminologies employed throughout the paper . Invariant distribution ? Domain-invariant representation ? Invariant features ? A proper definition would help , and enforcing consistency throughout the paper , by using the same names when those refer to the same concepts , would benefit readability . p.2 \u00a75 : The main difference [ ... ] train to test distributions . - > I like that the authors make this comparison , but I also would have liked this discussion to be further extended . There is a clear relationship indeed . If IRM looks for a representation $ \\phi ( x ) $ such that $ p ( \\phi ( x ) ) $ can change between domains , but $ p ( y|\\phi ( x ) ) $ remains the same , then this is exactly the assumption of covariate shift : $ p ( x ) $ can change , but $ p ( y|x ) $ remains the same . However , finding such a representation $ \\phi $ does not entirely solve the problem . First , the representation has to be predictive enough for $ y $ , ideally so that $ y \\perp x | \\phi ( x ) $ . Otherwise , even a constant $ \\phi $ might result in $ p ( y|\\phi ( x ) ) $ being invariant if $ p ( y ) $ is . But then marginal predictions from $ p ( y ) $ would probably be sub-optimal . Second , while in theory ( infinite model capacity , infinite data ) covariate shift is not an issue ( Bayes-optimal predictors do not need $ p ( x ) $ , only $ p ( y|x ) $ over the support of $ x $ ) , in practice it is another story , and additional methods such as sample reweighting can be beneficial . See paragraphs 3,4 from the introduction in V. Tran , and A. Aussem . A Practical Approach to Reduce the Learning Bias Under Covariate Shift . ECML/PKDD 2015. p.2 \u00a76 : whose joint distribution with the label is fixed for all environments - > this is a strong assumption which IRM , as far as I understand , does not make p.3 \u00a73 : invariant ( causal ) relationship - > I am a bit uncomfortable with the authors mixing the invariant and causal adjectives in this context . In your SCM , if given a causal interpretation , $ y $ is a cause of $ z_c $ , and $ p ( y|z_c ) \\neq p ( y|do ( z_c ) ) $ . I would suggest for the authors to stick to the concept of invariance ( which they still have not defined properly ... ) , and drop the causal interpretation , which brings nothing but confusion to the paper . Causality really is a different business , which is not required to study the capabilities of the IRM objective . p.3 \u00a74 : the causation can just as easily be viewed in the other direction - > Exactly . So why even talking about causality ? Do you want a model of $ p ( y|x ) $ , which generalize across different environments with different distributions for p ( x ) ? Or do you want a causal model of $ p ( y|do ( x ) ) $ ? Those are different objectives , and using them interchangeable really is confusing , as they do not require the same assumptions . Here , as you say , we do not care whether $ x $ causes $ y $ or $ y $ causes $ x $ . p.3 \u00a75 : a constant marginal - > Marginal of what ? Please be precise . p.3 \u00a75 : is necessary : Necessary to what ? Which assumptions of IRM would be violated as a result of not having $ y \\perp e $ your model ? The IRM assumptions were never clearly stated . Would that make finding $ \\psi $ such that $ p ( y|\\psi ( x ) ) $ is invariant impossible ? p.3 \u00a78 : whose joint or conditional distribution - > The conditional is implied by the joint . You can remove `` or conditional '' here . p.3 \u00a78 : Definition 1 - > The paper would gain a lot in clarity if this `` invariant classifier '' was given a formal , mathematical definition . For example , what do you mean by `` invariant features '' ? The same holds for you assumptions , which could be defined more clearly : $ z_c , y \\perp e $ , $ e $ uniform . According to your definition , I can think of the following : $ $ h^\\star = \\arg \\min_h \\mathbb { E } _ { ( x , y , z_c , z_e , e ) } [ l ( h ( x ) , y ) ] , \\text { subject to } h ( f ( z_c , z_e ) ) = h ( f ( z_c , z'_e ) ) , \\forall z_c , z_e , z'_e \\text { , } $ $ The `` invariant classifier '' from this definition is not the one that IRM seeks . It suffices to consider a scenario where $ f=I $ $ Z_c=\\emptyset $ , and two environments such that $ \\mu_ { e_1 } , \\sigma_ { e_1 } = ( 100 , 1 ) $ and $ \\mu_ { e_2 } , \\sigma_ { e_2 } = ( 1000 , 1 ) $ . Then $ z_e $ is not an invariant feature , but clearly the representation $ f ( z_e ) =sign ( z_e ) $ is invariant , and is very informative of $ y $ . I think this is a major confusion in the article , which becomes clear only when ones writes down this definition formally . p.4 \u00a71 : Observe that [ ... ] the invariant classifier does not . - > This is I believe the major flaw of the article . The objective in OOD generalization is to find the Bayes classifier , not the `` invariant classifier '' . Likewise , the objective of IRM is not to learn the `` invariant classifier '' . As such , showing that IRM does not recover this `` invariant classifier '' has little value . p.4 \u00a73 : Since those are informal theorems , I would rather name them differently , e.g. , Result 1 , Result 2 , Result 3. p.4 Section 4 : The definition of IRM should be presented before the Section 3 : results . p.4 Section 4 \u00a72 : The authors argue that such a function will use only invariant features - > I do not find this argument in the original IRM paper . p.5 Theorem 5 : E training environments - > and how many environments in the test distribution ? p.5 Appendic C.1 : In Appendix Figure C.1 , I believe the y axis should read $ \\eta $ , not Accuracy ? Also , I fail to understand why ERM is a flat line in this Figure . If more environments are provided , even with unlimited data , then the ERM classifier should change , and the test performance as well . Maybe I am missing something here , but the experimental setup ( such as how model parameters are chosen for each new environment ) is not clearly described . p.5 Corollary 5.2 : I am not sure what this implies . Maybe IRM does not recover the `` invariant classifier '' in that case , but what we really want for OOD generalization is the Bayes-optimal classifier . Again , it is not clearly stated what IRM wants to achieve ... p.6 Theorem 5.3 : The initial assumptions these results rely on should be stated formally . Do these results hold for any $ p ( x , y , e ) =p ( e ) p ( y ) p ( x|e , y ) $ distribution ? For any $ p ( x , y , e ) $ distribution satisfying the IRM assumptions ? Only for the specific model the authors consider ? p.6 Theorem 5.3 : feasible - > Feasible for IRM ? p.6 Figure C.2 : Some labels are missing from Figure C.2 . What do the doted horizontal lines represent ? p.8 Conclusion : the number of training environments needed to ensure good generalization under arbitrary distribution shift is linear in the number of non-invariant features - > I believe this is wrong . The Bayes classifier is the one ensuring good OOD generalization . The `` invariant classifier '' , which you prove requires a number of environments equal to the number of non-invariant features , is not the Bayes classifier .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for taking the time to review this work so thoroughly ! Your review expresses two major concerns : 1 ) Our results are incorrect and not adequately formal . 2 ) The use of the word \u2018 causal \u2019 and all related terminology . We will respond to these points first , then subsequently the more detailed points . Regarding the second point : we don \u2019 t use causality terminology in the formal parts of the paper , merely in the introductory , informal portions . In fact , the original IRM paper ( Arjovsky et al . ) copiously uses causal nomenclature\u2014a quick \u201c search \u201d returns 77 hits\u2014despite ( as you yourself noted ) nothing in the IRM formulation explicitly leveraging causality . We discuss this in more detail further down in our response . * * With regards to the first point : * * $ \\textbf { We are } \\ \\textit { absolutely certain } \\ \\ \\textbf { that this concern is due to a fundamental misunderstanding of the } $ $ \\textbf { premise and objective of both the original IRM paper and this work . We hope our detailed response below will } $ $ \\textbf { demonstrate to you that our results are both correct and meaningful . } $ We further hope that with your help , we can understand more precisely the source of this misunderstanding , which will help us rephrase parts of the work to preempt this confusion for future readers . We apologize if you found our setup difficult to understand , though we note that this sentiment was not shared by the other reviewers\u2014reviewers 2 and 4 explicitly noted an appreciation for the care we took to make the work intuitive and easy to follow . In general , especially in the introductory parts , we deliberately use expository language rather than formal math for ease of reading . This is why we have informal theorem statements first , which we make fully formal later ; we feel this helps readers who are not experts in this subarea . We don \u2019 t think our definitions are particularly informal ; we think rather a major source of confusion is the distinction between the Bayes and invariant classifiers . We will make sure to spell this out more forcefully in the next version . In the meantime , we will clarify the distinction in this rebuttal to hopefully rectify the misunderstanding . You write that \u201c the objective in OOD generalization is to find the Bayes classifier , not the `` invariant classifier '' . \u201d We assume what you mean by this is : \u201c the goal of OOD generalization is to learn a classifier which is Bayes for a new test environment \u201d . * * In the context of this paper , and also that of ( Peters et al. , Arjovsky et al . ) , this statement is not correct * * . To clarify : the Bayes classifier in a new environment would make use of all available information in $ x $ , while the invariant classifier makes use of only \u201c invariant features \u201d . Note in Arjovsky et al.there is no formal definition of \u201c invariant \u201d or \u201c causal \u201d features as the paper doesn \u2019 t assume a data model , and the objective itself doesn \u2019 t come with formal guarantees with respect to the data distribution . In fact , part of the motivation for our paper was to propose a data model which formalizes some of the intuitions behind the IRM objective and to show how solving it in fact does * not * match this intuition . Our data model , * * completely described * * by eqs ( 1 ) - ( 3 ) , explicitly defines which features are \u201c invariant \u201d and which are not ( surely these equations could not be considered informal ) . Furthermore , we think it accurately captures the intuition of Arjovsky et al . : the label-conditional distribution of the `` invariant '' features is constant across environments , whereas the label-conditional distribution of the `` non-invariant '' features can vary ; * * these definitions are provided at the beginning of Section 3 * * . Note , our setup * explicitly allows * for the existence of features which are informative of the label yet non-invariant ; the invariant classifier * intentionally ignores * these features . This is the ultimate objective of IRM ."}, {"review_id": "BbNIbVPJ-42-2", "review_text": "Main comments : This paper studies a theoretical aspect of IRM and how will it fail . Main contribution is pointing out that IRM is ineffective when the number of environments $ E $ is smaller than the dimension of environmental feature $ d_e $ . A simple but universal model assumption is built , where environmental feature $ z_e $ and causal feature $ z_c $ is sampled from Gaussian conditional on label $ y $ . The analysis is two-fold : linear regime and non-linear regime . In the former part , given the feature extractor $ \\Phi $ is linear , a constructed solution to IRM is built to demonstrate the result . For the latter part , the other show the failure of IRM via several results in Thm 6.1 / D.3 . The whole analysis is clear and easy to follow , thus the reviewer believe this submission deserves to be accepted . Main comments : The simulated experiments in Appendix C demonstrate the theoretical results . However , it 's a toy run and thus one drawback to the reviewer is that , for Colored MNIST experiments in IRM , it 's obvious that $ d_e > E $ while IRM still works . It would be great if the authors could give some explanation on this point . Analysis in the paper is more a constructed one , whereas lacks of how optimization algorithm can lead to such a solution , which is another drawback of this paper . Another minor comment : One seminal reference seems missing : Causal inference using invariant prediction : identification and confidence intervals . Jonas Peters , Peter B\u00fchlmann , Nicolai Meinshausen .", "rating": "7: Good paper, accept", "reply_text": "Thanks for your comments ! To address your minor point , we note that we do cite this work more than once in the paper , including in the abstract . ( Peters et al.2016 ) was absolutely crucial to the development of this line of work ( which we call \u201c Invariant Causal Prediction \u201d ) , so we very much agree that it deserves to be cited . To your larger concerns : * We acknowledge the limited setting for the experiments in Appendix C. However , we note that running IRM-related experiments in the non-linear regime is quite difficult and unstable ; see our comment to Reviewer 1 . Actually , there is an entire paper [ 1 ] based on running these experiments for comparisons . * The aforementioned reference [ 1 ] also addresses your other point : * * it is not actually clear that IRM works on Colored MNIST * * . In tandem with this theoretical work , several empirical works have recently demonstrated that performance of IRM and related objectives are extremely sensitive to training data , hyperparameters , etc . Further , there is increasing evidence that * none of these works outperform ERM * when it is tuned properly ( again , see [ 1 ] ) . In particular , existing reports of performance of IRM on CMNIST * use the test set as a validation set * , which violates standard testing principles by leaking information . Thus , we challenge the notion that IRM works , even empirically , when $ d_e > E $ . * We agree that analysis of the optimization trajectory would be ideal . But that is a much more difficult question and one which warrants an entirely separate paper . The intent of this work was merely to demonstrate that even if we could solve the proposed objective , the resulting classifier would not behave as expected . If the optimum of an objective does not behave as we intend , this raises questions about the validity of the objective itself , with or without an analysis of the method by which the optimum is reached . In other words , this work demonstrates that an analysis of the trajectory is not even necessary , because we are optimizing the wrong objective to begin with . Please tell us if you have any other questions or concerns ! In particular , let us know if there is anything we can clarify which would increase your confidence in the quality of this work . [ 1 ] In Search of Lost Domain Generalization . Ishaan Gulrajani and David Lopez-Paz , 2020. https : //arxiv.org/abs/2007.01434"}, {"review_id": "BbNIbVPJ-42-3", "review_text": "- pros : - The paper examined the claims of IRM thoughtfully and critically . - the exposition is clear I particularly enjoyed the informal results in section 3.1 . I applaud the authors ' effort to make the results intuitive ! - The appendix included illustrative and convincing empirical studies . - The paper brought up a failure case of IRM , which shows that there exists a nearly optimal classifier , similar to the invariant predictor in the training environment , but performs equal to the ERM solution in the testing set . - cons - There is only one DGP used in throughout the paper . In particular , the DGP has the same complexity in the y- > z_c and z_c - > y relationship . This seems counter-intuitive to me . I would be interested in learning if this phenomenon generalizes to other DGPs", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review ! We are glad to hear you appreciate the effort that went into stating the results intuitively ; we took great care to present the results of this work both formally ( with more in the appendix ) and in plain English , to make it as accessible as possible . Addressing your concerns : * We assume DGP stands for \u201c Data Generating Process \u201d ? If so , you are correct that we only used a single model in this work ; we felt the model was flexible and general enough to justify this ( e.g. , this model generalizes [ 1 ] , which also uses only one DGP ) . * We think it is quite likely that identical results could be demonstrated for the same graphical model but with Bernoulli-distributed features instead of Gaussian , but we didn \u2019 t feel that this would significantly contribute to the results , and it would have been difficult to fit in the page limit . * We actually view the mirrored $ z_c \\to y $ and $ y \\to z_c $ relationship as a * strength * , rather than a weakness . Many works on OOD generalization rely on the assumption that one or the other of these directions hold . By analyzing a model with both , we preempt future work from suggesting the other direction and claiming that our negative results do not apply . Please tell us if you have any other questions or concerns ! In particular , let us know if there is anything we can clarify which would increase your confidence in the quality of this work . [ 1 ] An investigation of why overparameterization exacerbates spurious correlations . Sagawa et al. , 2020. https : //arxiv.org/pdf/2005.04345.pdf"}], "0": {"review_id": "BbNIbVPJ-42-0", "review_text": "Pros : * The work gives extended theoretical analysis on the effect of invariant risk minimization scheme , which is an increasingly popular framework for robust prediction . The work considerably extends the results in the original IRM paper . The results seem reasonable , and clarify implausible beliefs on the framework . The intuitions and proving techniques could also inspire new methods to improve the current framework . Cons ( minor issues ) : * I know the main contribution of the work is on the theoretical side , but a simple experiment or simulation for the nonlinear case to demonstrate the empirical consequence would be appreciated . * In the considered data generating model , it is assumed that $ z_c \\perp z_e | y $ ( conditional independence ) . Is it required in the proofs ? How natural/general can it be ? For one example , it is mentioned that the causation can be viewed in the other direction , i.e. $ z \\to y $ . In that case , observing $ y $ would render components of $ z $ correlated . Also , a graphical illustration of the data generating model would be helpful . * OOD generalization to an arbitrary environment in the nonlinear case ( even with the invariant optimal predictor on top of representations ) may not be possible anyway , and some recent works on OOD generalization does not expect the learned model to work well in environments out of the convex hull/combination of training environments . So I am wondering how arbitrary can the test environment be in Theorem 6.1 , e.g. , can it be out of the convex hull/combination of training environment ? The result would seem more interesting to me if the test environment can be . EDIT : post-rebuttal Thanks for the additional explanations .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review ! To address your minor concerns : * Unfortunately , the lack of existing techniques for stable training , hyperparameter choice , etc . makes informative nonlinear experiments difficult ( See the related discussion in [ 1 ] ) . We can point you to [ 2 ] for existing experimental evidence of the failure of IRM and other OOD generalization techniques in the non-linear regime . * Our proofs apply to the model we consider in the paper . While developing this work , we considered several models and achieved varying levels of success in showing similar results in each of them . It is not immediately clear to us if conditional independence is * necessary * to show such results , but our proofs in the linear case do use this fact ; in the non-linear case we do not rely on such independence . We note that such an assumption would seem to make the job of learning invariances * strictly easier * , so the fact that IRM doesn \u2019 t work in this case is even more surprising . We agree that a graphical model depiction would be helpful ; we intend to include this in the camera-ready version . * Theorem 6.1 makes no assumptions whatsoever on the test environment , other than being sufficiently far from the training environments . So it applies equally to test environments that are inside or outside the convex hull . In particular , this implies that even if some IRM-based technique * does * generalize to the convex hull of training environments in the linear case , it will not work in the non-linear case . This is because the \u201c convex hull \u201d argument typically relies upon restricting degrees of freedom and , as we discuss in section 6 , this argument does not generalize when we introduce non-linearity . Please tell us if you have any other questions or concerns ! In particular , let us know if there is anything we can clarify which would increase your confidence in the quality of this work . [ 1 ] Out-of-Distribution Generalization via Risk Extrapolation ( REx ) . Krueger et al. , 2020. https : //arxiv.org/abs/2003.00688 [ 2 ] In Search of Lost Domain Generalization . Ishaan Gulrajani and David Lopez-Paz , 2020. https : //arxiv.org/abs/2007.01434"}, "1": {"review_id": "BbNIbVPJ-42-1", "review_text": "The paper , entitled `` The Risks of Invariant Risk Minimization '' , provides a theoretical analysis of the IRM learning objective under particular conditions . It claims to provide two theoretical results , namely : 1 ) in the linear setting ( i.e. , the optimal model is linear ) , they provide a necessary and sufficient condition for IRM to recover the optimal invariant predictor . 2 ) in the non-linear setting , they demonstrate that IRM does not perform better than ERM ( empirical risk minimization ) . Strong points of the paper : 1 ) the paper addresses an important question : what are the theoretical guarantees of the IRM objective ? 2 ) the paper provides a solid argument against the IRM objective , which is shown to be no better than ERM , in a limited but non-trivial setting 3 ) the paper tries to relate IRM to several prior works from the literature Weak points of the paper : 1 ) I believe the paper contains a major flaw : the so-called `` invariant classifier '' , which uses only invariant features , is not the optimal invariant predictor sought by IRM . As such the first claim of the authors , necessary and sufficient conditions under which IRM recovers the optimal invariant predictor in the linear setting , is wrong . 2 ) The paper suffers from a poor structure , a lack of clarity , and a general lack of rigor in the definition of the key concepts . Despite commendable efforts from the authors to study IRM theoretically , even in a limited setting , I recommend rejection for the paper . First , while it appears rather theoretical , the paper lacks rigor and clarity in the definition of the problem , the key concepts , and the assumptions . The description of the OOD generalization problem , of IRM and its assumptions , of the assumptions made by the authors in their simplified model , and of the introduced concepts ( notably the `` invariant classifier '' ) , are lacking a formal mathematical description . The main results of the paper are given in Section 3 , before the studied object , IRM , is even formally introduced in Section 4 . The authors interchangeably use the adjectives `` causal '' or `` invariant '' , without having properly defined the meaning of those concepts in the first place , and with no particular utility . Maybe IRM can be given a causal interpretation , under some assumptions , but clearly this is out of the scope of the paper . The theoretical analysis of IRM conducted in the paper does not require the notion of causality , which only brings confusion to the paper in my opinion . Second , and most importantly , I believe that one of the author 's claims ( which occupies about half the paper ) is simply wrong ( see my detailed comments below with a counter-example ) . There seems to be a misunderstanding as to what IRM actually seeks for , which is not the so-called `` invariant classifier '' that uses only invariant features . IRM does not seek to use invariant features only , but to learn those invariant features , possibly by using non-invariant ones . As such , results such as Theorem 5.1 , Corollary 5.2 , and Theorem 5.3 , have very little value I think . The second claim of the authors remains interesting , however I believe the paper requires a substantial revision and in its current state can not be accepted at ICLR . I would appreciate if the authors could formally describe what they mean by `` invariant classifier '' , and point me to the evidence where the IRM authors argue that IRM will recover such a classifier . * * Post-discussions * * : the authors have clarified the meaning of `` invariant classifier '' , which is now tied to their specific toy problem , and I now believe such a classifier is indeed the minimax OOD classifier supposedly seeked by IRM . While I still think the paper does not shine on the side of clarity , my main concern about the incorrectness of the presented theorems has been answered and I believe the paper will be of interest to the community . I therefore raise my recommendation towards acceptance . Below are my detailed comments : p.1 \u00a73 : each environment corresponds to interventions on the SEM ( Pearl , 2009 ) on just the non-causal mechanisms - > What does non-causal mechanism mean here ? If the SEM is given a causal interpretation , then all mechanisms are causal . Do you mean the mechanisms which are not causaly impacting the variable of interest Y ? p.1 \u00a73 : invariant features in the SEM - > Do you mean the causal features ? Or the invariant mechanisms ? Invariant features does not make sense . If interpreted as constant features , those are uninformative . If interpreted as having the same distribution across environments , this does not make sense either , since it does not guarantee such a feature will be causal . p.2 \u00a75 : invariance of the feature-conditioned label distribution - > I like the effort the authors put in grouping the existing works in a unified framework and notation . There is however a bit of inconsistency and ambiguity in the terminologies employed throughout the paper . Invariant distribution ? Domain-invariant representation ? Invariant features ? A proper definition would help , and enforcing consistency throughout the paper , by using the same names when those refer to the same concepts , would benefit readability . p.2 \u00a75 : The main difference [ ... ] train to test distributions . - > I like that the authors make this comparison , but I also would have liked this discussion to be further extended . There is a clear relationship indeed . If IRM looks for a representation $ \\phi ( x ) $ such that $ p ( \\phi ( x ) ) $ can change between domains , but $ p ( y|\\phi ( x ) ) $ remains the same , then this is exactly the assumption of covariate shift : $ p ( x ) $ can change , but $ p ( y|x ) $ remains the same . However , finding such a representation $ \\phi $ does not entirely solve the problem . First , the representation has to be predictive enough for $ y $ , ideally so that $ y \\perp x | \\phi ( x ) $ . Otherwise , even a constant $ \\phi $ might result in $ p ( y|\\phi ( x ) ) $ being invariant if $ p ( y ) $ is . But then marginal predictions from $ p ( y ) $ would probably be sub-optimal . Second , while in theory ( infinite model capacity , infinite data ) covariate shift is not an issue ( Bayes-optimal predictors do not need $ p ( x ) $ , only $ p ( y|x ) $ over the support of $ x $ ) , in practice it is another story , and additional methods such as sample reweighting can be beneficial . See paragraphs 3,4 from the introduction in V. Tran , and A. Aussem . A Practical Approach to Reduce the Learning Bias Under Covariate Shift . ECML/PKDD 2015. p.2 \u00a76 : whose joint distribution with the label is fixed for all environments - > this is a strong assumption which IRM , as far as I understand , does not make p.3 \u00a73 : invariant ( causal ) relationship - > I am a bit uncomfortable with the authors mixing the invariant and causal adjectives in this context . In your SCM , if given a causal interpretation , $ y $ is a cause of $ z_c $ , and $ p ( y|z_c ) \\neq p ( y|do ( z_c ) ) $ . I would suggest for the authors to stick to the concept of invariance ( which they still have not defined properly ... ) , and drop the causal interpretation , which brings nothing but confusion to the paper . Causality really is a different business , which is not required to study the capabilities of the IRM objective . p.3 \u00a74 : the causation can just as easily be viewed in the other direction - > Exactly . So why even talking about causality ? Do you want a model of $ p ( y|x ) $ , which generalize across different environments with different distributions for p ( x ) ? Or do you want a causal model of $ p ( y|do ( x ) ) $ ? Those are different objectives , and using them interchangeable really is confusing , as they do not require the same assumptions . Here , as you say , we do not care whether $ x $ causes $ y $ or $ y $ causes $ x $ . p.3 \u00a75 : a constant marginal - > Marginal of what ? Please be precise . p.3 \u00a75 : is necessary : Necessary to what ? Which assumptions of IRM would be violated as a result of not having $ y \\perp e $ your model ? The IRM assumptions were never clearly stated . Would that make finding $ \\psi $ such that $ p ( y|\\psi ( x ) ) $ is invariant impossible ? p.3 \u00a78 : whose joint or conditional distribution - > The conditional is implied by the joint . You can remove `` or conditional '' here . p.3 \u00a78 : Definition 1 - > The paper would gain a lot in clarity if this `` invariant classifier '' was given a formal , mathematical definition . For example , what do you mean by `` invariant features '' ? The same holds for you assumptions , which could be defined more clearly : $ z_c , y \\perp e $ , $ e $ uniform . According to your definition , I can think of the following : $ $ h^\\star = \\arg \\min_h \\mathbb { E } _ { ( x , y , z_c , z_e , e ) } [ l ( h ( x ) , y ) ] , \\text { subject to } h ( f ( z_c , z_e ) ) = h ( f ( z_c , z'_e ) ) , \\forall z_c , z_e , z'_e \\text { , } $ $ The `` invariant classifier '' from this definition is not the one that IRM seeks . It suffices to consider a scenario where $ f=I $ $ Z_c=\\emptyset $ , and two environments such that $ \\mu_ { e_1 } , \\sigma_ { e_1 } = ( 100 , 1 ) $ and $ \\mu_ { e_2 } , \\sigma_ { e_2 } = ( 1000 , 1 ) $ . Then $ z_e $ is not an invariant feature , but clearly the representation $ f ( z_e ) =sign ( z_e ) $ is invariant , and is very informative of $ y $ . I think this is a major confusion in the article , which becomes clear only when ones writes down this definition formally . p.4 \u00a71 : Observe that [ ... ] the invariant classifier does not . - > This is I believe the major flaw of the article . The objective in OOD generalization is to find the Bayes classifier , not the `` invariant classifier '' . Likewise , the objective of IRM is not to learn the `` invariant classifier '' . As such , showing that IRM does not recover this `` invariant classifier '' has little value . p.4 \u00a73 : Since those are informal theorems , I would rather name them differently , e.g. , Result 1 , Result 2 , Result 3. p.4 Section 4 : The definition of IRM should be presented before the Section 3 : results . p.4 Section 4 \u00a72 : The authors argue that such a function will use only invariant features - > I do not find this argument in the original IRM paper . p.5 Theorem 5 : E training environments - > and how many environments in the test distribution ? p.5 Appendic C.1 : In Appendix Figure C.1 , I believe the y axis should read $ \\eta $ , not Accuracy ? Also , I fail to understand why ERM is a flat line in this Figure . If more environments are provided , even with unlimited data , then the ERM classifier should change , and the test performance as well . Maybe I am missing something here , but the experimental setup ( such as how model parameters are chosen for each new environment ) is not clearly described . p.5 Corollary 5.2 : I am not sure what this implies . Maybe IRM does not recover the `` invariant classifier '' in that case , but what we really want for OOD generalization is the Bayes-optimal classifier . Again , it is not clearly stated what IRM wants to achieve ... p.6 Theorem 5.3 : The initial assumptions these results rely on should be stated formally . Do these results hold for any $ p ( x , y , e ) =p ( e ) p ( y ) p ( x|e , y ) $ distribution ? For any $ p ( x , y , e ) $ distribution satisfying the IRM assumptions ? Only for the specific model the authors consider ? p.6 Theorem 5.3 : feasible - > Feasible for IRM ? p.6 Figure C.2 : Some labels are missing from Figure C.2 . What do the doted horizontal lines represent ? p.8 Conclusion : the number of training environments needed to ensure good generalization under arbitrary distribution shift is linear in the number of non-invariant features - > I believe this is wrong . The Bayes classifier is the one ensuring good OOD generalization . The `` invariant classifier '' , which you prove requires a number of environments equal to the number of non-invariant features , is not the Bayes classifier .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for taking the time to review this work so thoroughly ! Your review expresses two major concerns : 1 ) Our results are incorrect and not adequately formal . 2 ) The use of the word \u2018 causal \u2019 and all related terminology . We will respond to these points first , then subsequently the more detailed points . Regarding the second point : we don \u2019 t use causality terminology in the formal parts of the paper , merely in the introductory , informal portions . In fact , the original IRM paper ( Arjovsky et al . ) copiously uses causal nomenclature\u2014a quick \u201c search \u201d returns 77 hits\u2014despite ( as you yourself noted ) nothing in the IRM formulation explicitly leveraging causality . We discuss this in more detail further down in our response . * * With regards to the first point : * * $ \\textbf { We are } \\ \\textit { absolutely certain } \\ \\ \\textbf { that this concern is due to a fundamental misunderstanding of the } $ $ \\textbf { premise and objective of both the original IRM paper and this work . We hope our detailed response below will } $ $ \\textbf { demonstrate to you that our results are both correct and meaningful . } $ We further hope that with your help , we can understand more precisely the source of this misunderstanding , which will help us rephrase parts of the work to preempt this confusion for future readers . We apologize if you found our setup difficult to understand , though we note that this sentiment was not shared by the other reviewers\u2014reviewers 2 and 4 explicitly noted an appreciation for the care we took to make the work intuitive and easy to follow . In general , especially in the introductory parts , we deliberately use expository language rather than formal math for ease of reading . This is why we have informal theorem statements first , which we make fully formal later ; we feel this helps readers who are not experts in this subarea . We don \u2019 t think our definitions are particularly informal ; we think rather a major source of confusion is the distinction between the Bayes and invariant classifiers . We will make sure to spell this out more forcefully in the next version . In the meantime , we will clarify the distinction in this rebuttal to hopefully rectify the misunderstanding . You write that \u201c the objective in OOD generalization is to find the Bayes classifier , not the `` invariant classifier '' . \u201d We assume what you mean by this is : \u201c the goal of OOD generalization is to learn a classifier which is Bayes for a new test environment \u201d . * * In the context of this paper , and also that of ( Peters et al. , Arjovsky et al . ) , this statement is not correct * * . To clarify : the Bayes classifier in a new environment would make use of all available information in $ x $ , while the invariant classifier makes use of only \u201c invariant features \u201d . Note in Arjovsky et al.there is no formal definition of \u201c invariant \u201d or \u201c causal \u201d features as the paper doesn \u2019 t assume a data model , and the objective itself doesn \u2019 t come with formal guarantees with respect to the data distribution . In fact , part of the motivation for our paper was to propose a data model which formalizes some of the intuitions behind the IRM objective and to show how solving it in fact does * not * match this intuition . Our data model , * * completely described * * by eqs ( 1 ) - ( 3 ) , explicitly defines which features are \u201c invariant \u201d and which are not ( surely these equations could not be considered informal ) . Furthermore , we think it accurately captures the intuition of Arjovsky et al . : the label-conditional distribution of the `` invariant '' features is constant across environments , whereas the label-conditional distribution of the `` non-invariant '' features can vary ; * * these definitions are provided at the beginning of Section 3 * * . Note , our setup * explicitly allows * for the existence of features which are informative of the label yet non-invariant ; the invariant classifier * intentionally ignores * these features . This is the ultimate objective of IRM ."}, "2": {"review_id": "BbNIbVPJ-42-2", "review_text": "Main comments : This paper studies a theoretical aspect of IRM and how will it fail . Main contribution is pointing out that IRM is ineffective when the number of environments $ E $ is smaller than the dimension of environmental feature $ d_e $ . A simple but universal model assumption is built , where environmental feature $ z_e $ and causal feature $ z_c $ is sampled from Gaussian conditional on label $ y $ . The analysis is two-fold : linear regime and non-linear regime . In the former part , given the feature extractor $ \\Phi $ is linear , a constructed solution to IRM is built to demonstrate the result . For the latter part , the other show the failure of IRM via several results in Thm 6.1 / D.3 . The whole analysis is clear and easy to follow , thus the reviewer believe this submission deserves to be accepted . Main comments : The simulated experiments in Appendix C demonstrate the theoretical results . However , it 's a toy run and thus one drawback to the reviewer is that , for Colored MNIST experiments in IRM , it 's obvious that $ d_e > E $ while IRM still works . It would be great if the authors could give some explanation on this point . Analysis in the paper is more a constructed one , whereas lacks of how optimization algorithm can lead to such a solution , which is another drawback of this paper . Another minor comment : One seminal reference seems missing : Causal inference using invariant prediction : identification and confidence intervals . Jonas Peters , Peter B\u00fchlmann , Nicolai Meinshausen .", "rating": "7: Good paper, accept", "reply_text": "Thanks for your comments ! To address your minor point , we note that we do cite this work more than once in the paper , including in the abstract . ( Peters et al.2016 ) was absolutely crucial to the development of this line of work ( which we call \u201c Invariant Causal Prediction \u201d ) , so we very much agree that it deserves to be cited . To your larger concerns : * We acknowledge the limited setting for the experiments in Appendix C. However , we note that running IRM-related experiments in the non-linear regime is quite difficult and unstable ; see our comment to Reviewer 1 . Actually , there is an entire paper [ 1 ] based on running these experiments for comparisons . * The aforementioned reference [ 1 ] also addresses your other point : * * it is not actually clear that IRM works on Colored MNIST * * . In tandem with this theoretical work , several empirical works have recently demonstrated that performance of IRM and related objectives are extremely sensitive to training data , hyperparameters , etc . Further , there is increasing evidence that * none of these works outperform ERM * when it is tuned properly ( again , see [ 1 ] ) . In particular , existing reports of performance of IRM on CMNIST * use the test set as a validation set * , which violates standard testing principles by leaking information . Thus , we challenge the notion that IRM works , even empirically , when $ d_e > E $ . * We agree that analysis of the optimization trajectory would be ideal . But that is a much more difficult question and one which warrants an entirely separate paper . The intent of this work was merely to demonstrate that even if we could solve the proposed objective , the resulting classifier would not behave as expected . If the optimum of an objective does not behave as we intend , this raises questions about the validity of the objective itself , with or without an analysis of the method by which the optimum is reached . In other words , this work demonstrates that an analysis of the trajectory is not even necessary , because we are optimizing the wrong objective to begin with . Please tell us if you have any other questions or concerns ! In particular , let us know if there is anything we can clarify which would increase your confidence in the quality of this work . [ 1 ] In Search of Lost Domain Generalization . Ishaan Gulrajani and David Lopez-Paz , 2020. https : //arxiv.org/abs/2007.01434"}, "3": {"review_id": "BbNIbVPJ-42-3", "review_text": "- pros : - The paper examined the claims of IRM thoughtfully and critically . - the exposition is clear I particularly enjoyed the informal results in section 3.1 . I applaud the authors ' effort to make the results intuitive ! - The appendix included illustrative and convincing empirical studies . - The paper brought up a failure case of IRM , which shows that there exists a nearly optimal classifier , similar to the invariant predictor in the training environment , but performs equal to the ERM solution in the testing set . - cons - There is only one DGP used in throughout the paper . In particular , the DGP has the same complexity in the y- > z_c and z_c - > y relationship . This seems counter-intuitive to me . I would be interested in learning if this phenomenon generalizes to other DGPs", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review ! We are glad to hear you appreciate the effort that went into stating the results intuitively ; we took great care to present the results of this work both formally ( with more in the appendix ) and in plain English , to make it as accessible as possible . Addressing your concerns : * We assume DGP stands for \u201c Data Generating Process \u201d ? If so , you are correct that we only used a single model in this work ; we felt the model was flexible and general enough to justify this ( e.g. , this model generalizes [ 1 ] , which also uses only one DGP ) . * We think it is quite likely that identical results could be demonstrated for the same graphical model but with Bernoulli-distributed features instead of Gaussian , but we didn \u2019 t feel that this would significantly contribute to the results , and it would have been difficult to fit in the page limit . * We actually view the mirrored $ z_c \\to y $ and $ y \\to z_c $ relationship as a * strength * , rather than a weakness . Many works on OOD generalization rely on the assumption that one or the other of these directions hold . By analyzing a model with both , we preempt future work from suggesting the other direction and claiming that our negative results do not apply . Please tell us if you have any other questions or concerns ! In particular , let us know if there is anything we can clarify which would increase your confidence in the quality of this work . [ 1 ] An investigation of why overparameterization exacerbates spurious correlations . Sagawa et al. , 2020. https : //arxiv.org/pdf/2005.04345.pdf"}}