{"year": "2017", "forum": "SJqaCVLxx", "title": "New Learning Approach By Genetic Algorithm In A Convolutional Neural Network For Pattern Recognition", "decision": "Reject", "meta_review": "This paper is unfortunately quite unclear and unreadable and nowhere near ready for any conference.\n I would advise the authors to 1) restructure their paper to present first some type of context and identify a problem that they are trying to solve, 2) explain what novel method they propose to solve the identified problem and why this method is promising and how it relates to existing methods, 3) explain what their experiments are trying to do and what the results of the experiments are, 4) enlist someone fluent in English to help with writing and re-reading.\n A way to do this is to find a set of well-cited papers in the same domain with similar ideas and see how they are structured, then try to follow similar outlines.", "reviews": [{"review_id": "SJqaCVLxx-0", "review_text": "The authors seems to have proposed a genetic algorithm for learning the features of a convolutional network (LeNet-5 to be precise). The algorithm is validated on some version of the MNIST dataset. Unfortunately the paper is extremely hard to understand and it is not at all clear what the exact training algorithm is. Neither do the authors ever motivate why do such a training as opposed to the standard back-prop. What are its advantages/dis-advantages? Furthermore the experimental section is equally unclear. The authors seem to have merged the training and validation set of the MNIST dataset and use only a subset of it. It is not clear why is that the case and what subset they use. In addition, to the best of my understanding, the results reported are RMSE as opposed to classification error. Why is that the case? In short, the paper is extremely hard to follow and it is not at all clear what the training algorithm is and how is it better than standard way of training. The experimental section is equally confusing and unconvincing. Other comments: -- The figures still say LeCun-5 -- The legends of the plots are not in english. Hence I'm not sure what is going on there. -- The paper is riddled with typos and hard to understand phrasing. ", "rating": "3: Clear rejection", "reply_text": "Exactly , Our proposed is the approach that used NSGA-II algorithm for updating the weights of a LeNet-5 model without having f6 layer in the LeNet-5 ( training ) in two stages with using TICA filters in Initializing population in NSGA-II . In the LeNet-5 implemented many method for learning like SGD , But they can not used in parallel processing . My motivation was to find the method that have been not back propagation ; the feed forward rendering is 5 times faster than the back propagation . Our approche in parallel can be run fast ratio with the SGD . I am studied in AI . At the opening of my research ( 2011 ) , I went to find a new way to learn a CNN for learning a few pattern like human ; The brain learn a few pattern with different type . For this , come under the chronological of my research : note : the best results selected from the iterations in practices and show average them with 5 experiments . 1 ) started Searching by reading the all of article in CNN and deep learning . 2 ) Started study about Filters and vision specially on TICA filters and filters of Mammal like rats and Macaques . 3 ) Practiced on the heuristics and evolutionary algorithms likes GA , PSO , Coco and so on . 4 ) Focused on PSO algorithm ( particle swarm organization ) for fast converge with 100 to 1000 iterations . 6 ) The main PSO tested up 1000 times with set different respective parameters but the learning failed ( Minimizing the RMSE ) ; This showed in the article that the PSO practices no help to minimizing the error ( RMSE=x Single-objective optimization ) . several functions tested in the pso ` s cost function like X power 2 and log2x end others famous . 7 ) The main GA tested like the PSO practices . And the result showed in article failed . 8 ) I have tested the PSO and GA chromosome that initialized with famous vision filters like TICE filters . And the result showed in article failed . 9 ) I am noticed that the good individual remove from population . I should maked a decision : Change the PSO code or GA for my propose or finding the other version . I decided to find an algorithm that have been in native to do not remove the good individual . 10 ) I have worked on the NSGA-II one of type of GA algorithm ( Multi-objective optimization ; RSME and MCR ) . It work good but have problem to minimize the errors despite of used the TICA filters and RMSE Single-objective optimization . 11 ) Finally , with my scholar in this fields and get the minimum and maximum value of the SGD LeNet-5 wieghts , I have used the TICA filters for initializing their chromosomes in population . 12 ) For obtaining the individuals that have minimum error I used two stage for learning with different parameters ( Discraibed in proposal section ) . At The end , I try to rewrite the article for excepting . The article can be reference by the new researcher ."}, {"review_id": "SJqaCVLxx-1", "review_text": "Unfortunately, this paper is very difficult to understand. The current version of this paper seems improved compared to the initial version, but still far from a finished level. I'd encourage the authors to keep editing over the language and presentation. I also think it would be good to also try answering some of the following questions very clearly in the paper: - What is the advantage, if any, of the proposed algorithm over SGD? What is the motivation and goal of the work beyond MNIST benchmarking? - Why are few training examples used? Is this a scenario in which the system might have an advantage? - Concretely describe the genetic algorithms terminology used in the algorithm descriptions, and what each term means in the context of the convolutional network. - Try to make sure that the method, as described, can be understood by a reader without much prior background on genetic algorithms. - A single experiment on MNIST is too small to adequately describe the algorithm performance. Consider using a second or third dataset and/or experimental application. Much work is still needed on the paper's writing before it can be understood well enough. I hope that some of this might be useful in helping to improve. I would encourage the authors to try to find outside readers, preferably fluent in English, to work with on a frequent basis before resubmitting to another venue. ", "rating": "3: Clear rejection", "reply_text": "I have supplied the chronological of my paper for better understanding . I am on improvement the writing and presentation . My purpose is to published the paper by ICLR2017 for obtaining a scholarship or grant to continue on this research and Study in Doctoral in AI ."}, {"review_id": "SJqaCVLxx-2", "review_text": "The paper is still extremely poorly written and presented despite multiple reviewers asking to address that issue. The frequent spelling mistakes and incoherent sentences and unclear presentation make reading and understanding the paper very difficult and time consuming. Consider getting help from someone with good english and presentation skills.", "rating": "2: Strong rejection", "reply_text": "I try to reconstruct the presentation to improve coherent the proposal.Please check again . Please help me to except the paper . These paper prepared in 2013 and my researching about that return to 2011 ."}], "0": {"review_id": "SJqaCVLxx-0", "review_text": "The authors seems to have proposed a genetic algorithm for learning the features of a convolutional network (LeNet-5 to be precise). The algorithm is validated on some version of the MNIST dataset. Unfortunately the paper is extremely hard to understand and it is not at all clear what the exact training algorithm is. Neither do the authors ever motivate why do such a training as opposed to the standard back-prop. What are its advantages/dis-advantages? Furthermore the experimental section is equally unclear. The authors seem to have merged the training and validation set of the MNIST dataset and use only a subset of it. It is not clear why is that the case and what subset they use. In addition, to the best of my understanding, the results reported are RMSE as opposed to classification error. Why is that the case? In short, the paper is extremely hard to follow and it is not at all clear what the training algorithm is and how is it better than standard way of training. The experimental section is equally confusing and unconvincing. Other comments: -- The figures still say LeCun-5 -- The legends of the plots are not in english. Hence I'm not sure what is going on there. -- The paper is riddled with typos and hard to understand phrasing. ", "rating": "3: Clear rejection", "reply_text": "Exactly , Our proposed is the approach that used NSGA-II algorithm for updating the weights of a LeNet-5 model without having f6 layer in the LeNet-5 ( training ) in two stages with using TICA filters in Initializing population in NSGA-II . In the LeNet-5 implemented many method for learning like SGD , But they can not used in parallel processing . My motivation was to find the method that have been not back propagation ; the feed forward rendering is 5 times faster than the back propagation . Our approche in parallel can be run fast ratio with the SGD . I am studied in AI . At the opening of my research ( 2011 ) , I went to find a new way to learn a CNN for learning a few pattern like human ; The brain learn a few pattern with different type . For this , come under the chronological of my research : note : the best results selected from the iterations in practices and show average them with 5 experiments . 1 ) started Searching by reading the all of article in CNN and deep learning . 2 ) Started study about Filters and vision specially on TICA filters and filters of Mammal like rats and Macaques . 3 ) Practiced on the heuristics and evolutionary algorithms likes GA , PSO , Coco and so on . 4 ) Focused on PSO algorithm ( particle swarm organization ) for fast converge with 100 to 1000 iterations . 6 ) The main PSO tested up 1000 times with set different respective parameters but the learning failed ( Minimizing the RMSE ) ; This showed in the article that the PSO practices no help to minimizing the error ( RMSE=x Single-objective optimization ) . several functions tested in the pso ` s cost function like X power 2 and log2x end others famous . 7 ) The main GA tested like the PSO practices . And the result showed in article failed . 8 ) I have tested the PSO and GA chromosome that initialized with famous vision filters like TICE filters . And the result showed in article failed . 9 ) I am noticed that the good individual remove from population . I should maked a decision : Change the PSO code or GA for my propose or finding the other version . I decided to find an algorithm that have been in native to do not remove the good individual . 10 ) I have worked on the NSGA-II one of type of GA algorithm ( Multi-objective optimization ; RSME and MCR ) . It work good but have problem to minimize the errors despite of used the TICA filters and RMSE Single-objective optimization . 11 ) Finally , with my scholar in this fields and get the minimum and maximum value of the SGD LeNet-5 wieghts , I have used the TICA filters for initializing their chromosomes in population . 12 ) For obtaining the individuals that have minimum error I used two stage for learning with different parameters ( Discraibed in proposal section ) . At The end , I try to rewrite the article for excepting . The article can be reference by the new researcher ."}, "1": {"review_id": "SJqaCVLxx-1", "review_text": "Unfortunately, this paper is very difficult to understand. The current version of this paper seems improved compared to the initial version, but still far from a finished level. I'd encourage the authors to keep editing over the language and presentation. I also think it would be good to also try answering some of the following questions very clearly in the paper: - What is the advantage, if any, of the proposed algorithm over SGD? What is the motivation and goal of the work beyond MNIST benchmarking? - Why are few training examples used? Is this a scenario in which the system might have an advantage? - Concretely describe the genetic algorithms terminology used in the algorithm descriptions, and what each term means in the context of the convolutional network. - Try to make sure that the method, as described, can be understood by a reader without much prior background on genetic algorithms. - A single experiment on MNIST is too small to adequately describe the algorithm performance. Consider using a second or third dataset and/or experimental application. Much work is still needed on the paper's writing before it can be understood well enough. I hope that some of this might be useful in helping to improve. I would encourage the authors to try to find outside readers, preferably fluent in English, to work with on a frequent basis before resubmitting to another venue. ", "rating": "3: Clear rejection", "reply_text": "I have supplied the chronological of my paper for better understanding . I am on improvement the writing and presentation . My purpose is to published the paper by ICLR2017 for obtaining a scholarship or grant to continue on this research and Study in Doctoral in AI ."}, "2": {"review_id": "SJqaCVLxx-2", "review_text": "The paper is still extremely poorly written and presented despite multiple reviewers asking to address that issue. The frequent spelling mistakes and incoherent sentences and unclear presentation make reading and understanding the paper very difficult and time consuming. Consider getting help from someone with good english and presentation skills.", "rating": "2: Strong rejection", "reply_text": "I try to reconstruct the presentation to improve coherent the proposal.Please check again . Please help me to except the paper . These paper prepared in 2013 and my researching about that return to 2011 ."}}