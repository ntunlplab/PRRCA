{"year": "2019", "forum": "rJxpuoCqtQ", "title": "Likelihood-based Permutation Invariant Loss Function for Probability Distributions", "decision": "Reject", "meta_review": "This paper proposes a new permutation invariant loss (where the order doesn't matter), motivated by set autoencoding settings. This is an important problem, and the authors' solution is interesting.  The reviewers, however, found the exposition to be unclear, in particular the explanation on how the loss function is derived was confusing for two of the reviewers. Reviewers also found the experimental results to be not convincing, even after the revision. This is a borderline paper: the idea is valuable and I'd encourage the authors to develop it further, improving exposition and including additional experiments as suggested by the reviewers.\n", "reviews": [{"review_id": "rJxpuoCqtQ-0", "review_text": "This paper proposes an objective function for sets autoencoders such that the loss is permutation invariant with respect to the order of reconstructed inputs. I think that the problem of autoencoding sets is important and designing custom loss functions is a good way to approach it. Thus, I quite like the idea of SCE from that point of view. However, I find the experiments not convincing for me to accept the paper. While reading Section 3, I found it hard to keep in mind that x and y are discrete probability distributions and the notation like P(x=y) is not making things easier. Actually, I\u2019ve never seen cross entropy written with P(x=y). Though is my personal opinion and I don\u2019t have a suggestion on how to improve the explanations in Eq. 1-8. However, I\u2019m glad there is an example at the end of Section 3. I have some comments on the Experiments section. * Puzzles: (1) Figure 1 could have been prettier. (2) The phrase \u201cThe purpose of this experiment is to reproduce the results from (Zaheer et al., 2017)\u201d makes little sense to me. In Deep Sets, there are many experiments and it\u2019s not clear which experiment is meant here. (3) Table 1 gives test error statistics for 10 runs. What is changed in every run? Does the test set stay the same in every run or is a kind of a cross-validation? Or is it just a different random seed for the initial weights? I could not find an explanation in the text, so there is no way I can interpret the results. * Blocksworld: the reconstructions are nice, but the numbers in Table 2 are difficult to interpret. For example, I cannot estimate how important the difference of 10 points in SH scores is. * Rule learning ILP tasks: I don\u2019t know enough about learning logic rules tasks to comment on those experiments, but Table 3 seems overwhelming and the concept of 10 runs is still unclear. --- General comment on the experiments --- I think an important goal of any autoencoder is to learn a representation that can be useful in other tasks. There is even an example in the paper: \u201cset representation of the environment is crucial in the robotic systems\u201d. Thus, the experiments I would like to see are about evaluating the quality of a representation from an SCE-trained autoencoder compared to other training methods. Without those experiments, I cannot estimate how valuable the SCE loss function is. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "> Actually , I \u2019 ve never seen cross entropy written with P ( x=y ) . The usual notation of the probability distribution , such as P ( x ) , is an abbreviation of a random variable X taking a particular value x , i.e.P ( X=x ) , following the notation in Ian Goodfellow 's Deep Learning textbook , chap.3 ( [ http : //www.deeplearningbook.org/contents/prob.html ] ) . We just kept it expanded for denoting the cross entropy . > The phrase \u201c The purpose of this experiment is to reproduce the > results from ( Zaheer et al. , 2017 ) \u201d makes little sense to me . > In Deep Sets , there are many experiments and it \u2019 s not clear which > experiment is meant here . By `` reproduce '' we did not mean we run the same experiment in the prior work ; What we did is that we confirmed their general claim ( their particular network structure is able to encode an input in a permutation invariant manner ) in * our * experimental setting . We rephrased it in the revision in order to avoid the confusion . > Table 1 gives test error statistics for 10 runs . What is changed in every run ? The purpose of running the experiments 10 times is to address the potential concern about the stability of the training . We kept the same set of training/testing data , the only difference is the random seed . In one of the 10 runs , A1H ( set average pseudo metric ) did not converge , showing that the A1H ( baseline ) could be unstable , possibly due to the issue explained in the example at the end of section 3 . # , though this is a speculation from the empirical result . This shows another empirical evidence that our proposed method is superior . We clarified these points in the revision . > Blocksworld : the reconstructions are nice , but the numbers in Table 2 are difficult to interpret . We agree with this point . To address it , we added the RMSE between the visualized pictures to give more insights . Note that these pictures are not the direct output of the neural network ; However , comparing the reconstructed pictures by RMSE should give some intuitive sense since the error directly translates to the pixel value . A new table is added in the revision . Furthermore , we compared the visualized results between the networks trained with a different loss formulation . Since we believe the same issue applies to 8-puzzles , we also added a new evaluation metric for 8-puzzles : Since we know 8 puzzle feature vectors are discrete ( a domain knowledge , not the assumption in our proposed method ) , we can directly compare the output reconstruction with the input by rounding the continuous output to 0/1 and comparing whether all elements are correctly reconstructed , and count the rate of the successful reconstructions across the dataset . Another new table is added in the revision . > Rule learning ILP tasks : the concept of 10 runs is still unclear . This is same as the previous experiments ; The only difference is the random seed . > I think an important goal of any autoencoder is to learn a > representation that can be useful in other tasks . There is even an > example in the paper : \u201c set representation of the environment is > crucial in the robotic systems \u201d . Thus , the experiments I would like > to see are about evaluating the quality of a representation from an > SCE-trained autoencoder compared to other training methods . > Without those experiments , I can not estimate how valuable the SCE > loss function is . We were surprised by this question . First , we do not focus only on the autoencoding task . In the ILP task , the neural network learns to predict a set from the single element . For example , in the last ` neighbor5 ` experiment in Table 6 , the task is to predict 5 elements from 1 element . Our contribution is the method for training a NN to output a set , not limited to autoencoding . Regarding the value of reconstructing a set , existing work ( Vinyal NIPS 2015 , ICLR 2016 ) already showed that once we can train a NN to output a set ( by whatever means ) , it allows a variety of tasks to be solved . The problem is that existing methods relied on an ad-hoc preprocessing and/or a careful tuning that depends on the domain knowledge , or a sequential process such as Gale-Shapley . Our contribution is to completely remove these assumptions motivated by the theoretical formulation , NOT by an empirical success that may occur by chance in a particualr problem setting ."}, {"review_id": "rJxpuoCqtQ-1", "review_text": "The paper is understandable and the question addressed is interesting. The use of log likelihoods to metrize distances between sets, although not new, is used quite effectively to address the issue of label switching in sets. Although the run time is O(N^2), the metric can be computed in a parallelized manner. The question of comparing sets of different sample sizes would be a valuable extension to the work. Although I think the proposed loss function addresses some important issues, would like to defer the question of acceptance/rejection to other reviewers due to lack of expertise in related areas.", "rating": "6: Marginally above acceptance threshold", "reply_text": "> The use of log likelihoods to metrize distances between sets , although not new , ... Log likelihood itself is a general notion and is not new . However , our contribution is formulating the log likelihood for sets , with a proof that it converges to the correct answer at the global minima . > The question of comparing sets of different sample sizes would be a > valuable extension to the work . See the overall reply . We added some explanations and also a new experiment that shows that it can model the sets with the different number of elements ."}, {"review_id": "rJxpuoCqtQ-2", "review_text": "In the manuscript entitled \"Likelihood-based Permutation Invariant Loss Function for Probability Distributions\" the authors propose a loss function for training against instances in which ordering within the data vector is unimportant. I do not find the proposed loss function to be well motivated, find a number of confusing points (errors?) in the manuscript, and do not easily follow what was done in the examples. First, it should be noted that this is a very restricted consideration of what it means to compare two sets since only sets of equal size are under consideration; this is fundamentally different to the ambitions of e.g. the Hausdorff measure as used in analysis. The logsumexp formulation of the proposed measure is unsatisfactory to me as it directly averages over each of the independent probabilities that a given element is a member of the target set, rather than integrating over the combinatorial set of probabilities for each set of complete possible matches. Moreover, the loss function H() is not necessarily representative of a generative distribution. The definition of the Hausdorff distance given is directional and is therefore not a metric, contrary to what is stated on page 2. I find the description of the problem domain confusing on page 3: the space [0,1]^NxF is described as binary, but then values of log y_i and log (1-y_i) are computed with y in [0,1] so we must imagine these are in fact elements in the open set of reals: (0,1). Clarity of the examples could be greatly improved, in particular by explaining precisely what is the objective of each task and what are the 'ingredients' we begin with.", "rating": "4: Ok but not good enough - rejection", "reply_text": "> only sets of equal size are under consideration ... See the overall reply . It is not only for sets of equal size . > The logsumexp formulation of the proposed measure is unsatisfactory > to me as it directly averages over each of the independent > probabilities that a given element is a member of the target set , > rather than integrating over the combinatorial set of probabilities > for each set of complete possible matches . We have shown ( the proof in page.3 , sec.3 , par.7 ) that our method guarantees that , at the global minima , every element x of the dataset X is matched by some element y of the output Y exactly once , just as in Hausdorff measure . We would like to hear more details about why it is unsatisfactory despite the guarantee . > The definition of the Hausdorff distance given is directional and is > therefore not a metric , contrary to what is stated on page 2 . We already clarified this in page 2 : `` Note that , in this work , we use the informal usage of the terms \u201c distance \u201d or \u201c metric \u201d ... '' We also only stated that Hausdorff distance is a metric , and not that the directed Hausdorff distance is a metric . We moved the clarification to the beginning of the section to avoid confusion . > the space [ 0,1 ] ^NxF is described as binary ... See the overall reply . [ 0,1 ] is a closed set of reals , not discrete values . The input is not assumed to be discrete . `` binomial distribution '' might be the more appropriate term . We rephrased them in the revision . > what is the objective of each task and what are the 'ingredients ' we begin with . The detailed descriptions are in the appendix . The first two tasks ( 8 puzzle , Blocksworld ) are the autoencoding task , but without considering the ordering in the first axis of the data point ( i.e.the order of the elements ) . In 8-puzzle , the object representation ( an element of the set ) is hand-crafted as in Fig.1 . In Blocksworld , a set of objects are extracted from the image , and the image patch and the bounding box information are compressed into 1224-D vector by a feature engineering using Conv-AE ( Appendix , 6.3 ) . The last task ( rule learning task ) is to predict a set of terms from a single term , where each term is a n-hot vector representing a first-order logic term ( Section 4.2 , Appendix 6.4 ) . We moved the description in the appendix to the main text ."}], "0": {"review_id": "rJxpuoCqtQ-0", "review_text": "This paper proposes an objective function for sets autoencoders such that the loss is permutation invariant with respect to the order of reconstructed inputs. I think that the problem of autoencoding sets is important and designing custom loss functions is a good way to approach it. Thus, I quite like the idea of SCE from that point of view. However, I find the experiments not convincing for me to accept the paper. While reading Section 3, I found it hard to keep in mind that x and y are discrete probability distributions and the notation like P(x=y) is not making things easier. Actually, I\u2019ve never seen cross entropy written with P(x=y). Though is my personal opinion and I don\u2019t have a suggestion on how to improve the explanations in Eq. 1-8. However, I\u2019m glad there is an example at the end of Section 3. I have some comments on the Experiments section. * Puzzles: (1) Figure 1 could have been prettier. (2) The phrase \u201cThe purpose of this experiment is to reproduce the results from (Zaheer et al., 2017)\u201d makes little sense to me. In Deep Sets, there are many experiments and it\u2019s not clear which experiment is meant here. (3) Table 1 gives test error statistics for 10 runs. What is changed in every run? Does the test set stay the same in every run or is a kind of a cross-validation? Or is it just a different random seed for the initial weights? I could not find an explanation in the text, so there is no way I can interpret the results. * Blocksworld: the reconstructions are nice, but the numbers in Table 2 are difficult to interpret. For example, I cannot estimate how important the difference of 10 points in SH scores is. * Rule learning ILP tasks: I don\u2019t know enough about learning logic rules tasks to comment on those experiments, but Table 3 seems overwhelming and the concept of 10 runs is still unclear. --- General comment on the experiments --- I think an important goal of any autoencoder is to learn a representation that can be useful in other tasks. There is even an example in the paper: \u201cset representation of the environment is crucial in the robotic systems\u201d. Thus, the experiments I would like to see are about evaluating the quality of a representation from an SCE-trained autoencoder compared to other training methods. Without those experiments, I cannot estimate how valuable the SCE loss function is. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "> Actually , I \u2019 ve never seen cross entropy written with P ( x=y ) . The usual notation of the probability distribution , such as P ( x ) , is an abbreviation of a random variable X taking a particular value x , i.e.P ( X=x ) , following the notation in Ian Goodfellow 's Deep Learning textbook , chap.3 ( [ http : //www.deeplearningbook.org/contents/prob.html ] ) . We just kept it expanded for denoting the cross entropy . > The phrase \u201c The purpose of this experiment is to reproduce the > results from ( Zaheer et al. , 2017 ) \u201d makes little sense to me . > In Deep Sets , there are many experiments and it \u2019 s not clear which > experiment is meant here . By `` reproduce '' we did not mean we run the same experiment in the prior work ; What we did is that we confirmed their general claim ( their particular network structure is able to encode an input in a permutation invariant manner ) in * our * experimental setting . We rephrased it in the revision in order to avoid the confusion . > Table 1 gives test error statistics for 10 runs . What is changed in every run ? The purpose of running the experiments 10 times is to address the potential concern about the stability of the training . We kept the same set of training/testing data , the only difference is the random seed . In one of the 10 runs , A1H ( set average pseudo metric ) did not converge , showing that the A1H ( baseline ) could be unstable , possibly due to the issue explained in the example at the end of section 3 . # , though this is a speculation from the empirical result . This shows another empirical evidence that our proposed method is superior . We clarified these points in the revision . > Blocksworld : the reconstructions are nice , but the numbers in Table 2 are difficult to interpret . We agree with this point . To address it , we added the RMSE between the visualized pictures to give more insights . Note that these pictures are not the direct output of the neural network ; However , comparing the reconstructed pictures by RMSE should give some intuitive sense since the error directly translates to the pixel value . A new table is added in the revision . Furthermore , we compared the visualized results between the networks trained with a different loss formulation . Since we believe the same issue applies to 8-puzzles , we also added a new evaluation metric for 8-puzzles : Since we know 8 puzzle feature vectors are discrete ( a domain knowledge , not the assumption in our proposed method ) , we can directly compare the output reconstruction with the input by rounding the continuous output to 0/1 and comparing whether all elements are correctly reconstructed , and count the rate of the successful reconstructions across the dataset . Another new table is added in the revision . > Rule learning ILP tasks : the concept of 10 runs is still unclear . This is same as the previous experiments ; The only difference is the random seed . > I think an important goal of any autoencoder is to learn a > representation that can be useful in other tasks . There is even an > example in the paper : \u201c set representation of the environment is > crucial in the robotic systems \u201d . Thus , the experiments I would like > to see are about evaluating the quality of a representation from an > SCE-trained autoencoder compared to other training methods . > Without those experiments , I can not estimate how valuable the SCE > loss function is . We were surprised by this question . First , we do not focus only on the autoencoding task . In the ILP task , the neural network learns to predict a set from the single element . For example , in the last ` neighbor5 ` experiment in Table 6 , the task is to predict 5 elements from 1 element . Our contribution is the method for training a NN to output a set , not limited to autoencoding . Regarding the value of reconstructing a set , existing work ( Vinyal NIPS 2015 , ICLR 2016 ) already showed that once we can train a NN to output a set ( by whatever means ) , it allows a variety of tasks to be solved . The problem is that existing methods relied on an ad-hoc preprocessing and/or a careful tuning that depends on the domain knowledge , or a sequential process such as Gale-Shapley . Our contribution is to completely remove these assumptions motivated by the theoretical formulation , NOT by an empirical success that may occur by chance in a particualr problem setting ."}, "1": {"review_id": "rJxpuoCqtQ-1", "review_text": "The paper is understandable and the question addressed is interesting. The use of log likelihoods to metrize distances between sets, although not new, is used quite effectively to address the issue of label switching in sets. Although the run time is O(N^2), the metric can be computed in a parallelized manner. The question of comparing sets of different sample sizes would be a valuable extension to the work. Although I think the proposed loss function addresses some important issues, would like to defer the question of acceptance/rejection to other reviewers due to lack of expertise in related areas.", "rating": "6: Marginally above acceptance threshold", "reply_text": "> The use of log likelihoods to metrize distances between sets , although not new , ... Log likelihood itself is a general notion and is not new . However , our contribution is formulating the log likelihood for sets , with a proof that it converges to the correct answer at the global minima . > The question of comparing sets of different sample sizes would be a > valuable extension to the work . See the overall reply . We added some explanations and also a new experiment that shows that it can model the sets with the different number of elements ."}, "2": {"review_id": "rJxpuoCqtQ-2", "review_text": "In the manuscript entitled \"Likelihood-based Permutation Invariant Loss Function for Probability Distributions\" the authors propose a loss function for training against instances in which ordering within the data vector is unimportant. I do not find the proposed loss function to be well motivated, find a number of confusing points (errors?) in the manuscript, and do not easily follow what was done in the examples. First, it should be noted that this is a very restricted consideration of what it means to compare two sets since only sets of equal size are under consideration; this is fundamentally different to the ambitions of e.g. the Hausdorff measure as used in analysis. The logsumexp formulation of the proposed measure is unsatisfactory to me as it directly averages over each of the independent probabilities that a given element is a member of the target set, rather than integrating over the combinatorial set of probabilities for each set of complete possible matches. Moreover, the loss function H() is not necessarily representative of a generative distribution. The definition of the Hausdorff distance given is directional and is therefore not a metric, contrary to what is stated on page 2. I find the description of the problem domain confusing on page 3: the space [0,1]^NxF is described as binary, but then values of log y_i and log (1-y_i) are computed with y in [0,1] so we must imagine these are in fact elements in the open set of reals: (0,1). Clarity of the examples could be greatly improved, in particular by explaining precisely what is the objective of each task and what are the 'ingredients' we begin with.", "rating": "4: Ok but not good enough - rejection", "reply_text": "> only sets of equal size are under consideration ... See the overall reply . It is not only for sets of equal size . > The logsumexp formulation of the proposed measure is unsatisfactory > to me as it directly averages over each of the independent > probabilities that a given element is a member of the target set , > rather than integrating over the combinatorial set of probabilities > for each set of complete possible matches . We have shown ( the proof in page.3 , sec.3 , par.7 ) that our method guarantees that , at the global minima , every element x of the dataset X is matched by some element y of the output Y exactly once , just as in Hausdorff measure . We would like to hear more details about why it is unsatisfactory despite the guarantee . > The definition of the Hausdorff distance given is directional and is > therefore not a metric , contrary to what is stated on page 2 . We already clarified this in page 2 : `` Note that , in this work , we use the informal usage of the terms \u201c distance \u201d or \u201c metric \u201d ... '' We also only stated that Hausdorff distance is a metric , and not that the directed Hausdorff distance is a metric . We moved the clarification to the beginning of the section to avoid confusion . > the space [ 0,1 ] ^NxF is described as binary ... See the overall reply . [ 0,1 ] is a closed set of reals , not discrete values . The input is not assumed to be discrete . `` binomial distribution '' might be the more appropriate term . We rephrased them in the revision . > what is the objective of each task and what are the 'ingredients ' we begin with . The detailed descriptions are in the appendix . The first two tasks ( 8 puzzle , Blocksworld ) are the autoencoding task , but without considering the ordering in the first axis of the data point ( i.e.the order of the elements ) . In 8-puzzle , the object representation ( an element of the set ) is hand-crafted as in Fig.1 . In Blocksworld , a set of objects are extracted from the image , and the image patch and the bounding box information are compressed into 1224-D vector by a feature engineering using Conv-AE ( Appendix , 6.3 ) . The last task ( rule learning task ) is to predict a set of terms from a single term , where each term is a n-hot vector representing a first-order logic term ( Section 4.2 , Appendix 6.4 ) . We moved the description in the appendix to the main text ."}}