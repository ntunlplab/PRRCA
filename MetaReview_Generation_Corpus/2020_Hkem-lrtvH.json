{"year": "2020", "forum": "Hkem-lrtvH", "title": "BayesOpt Adversarial Attack", "decision": "Accept (Poster)", "meta_review": "This paper proposes a query-efficient black-box attack that uses Bayesian optimization in combination with Bayesian model selection to optimize over the adversarial perturbation and the optimal degree of search space dimension reduction. The method can achieve comparable success rates with 2-5 times fewer queries compared to previous state-of-the-art black-box attacks. The paper should be further improved in the final version (e.g., including more results on ImageNet data).", "reviews": [{"review_id": "Hkem-lrtvH-0", "review_text": "This paper studied the problem of black-box adversarial attack generation by leveraging Bayesian optimization (BO). Merits of this paper: 1) The combination of BO and dimension reduction, which makes BO more efficient under a low-dimensional space. 2) Good experiment results. Comments/questions about this paper: 1) Comment on \"Finally, to the best of our knowledge, the only prior work that uses Bayesian optimisation is a workshop paper by...\". BO was also used for generating black-box adversarial examples at https://arxiv.org/pdf/1907.11684.pdf This is a missing related work, and please elaborate on the differences. 2) The presentation of the proposed algorithm is not clear. Please explicitly state the acquisition function. And how to tune the hyperparameter in the acquisition function? What decoder is used in experiments? Have authors tested the sensitivity of the decoder (not reduced dimension)? 3) In experiments, the authors mentioned \"we randomly select 3 correctly classified images for each class from CIFAR10 test data which sums up to 27 CIFAR10 images, and randomly select 7 correctly classified images from MNIST test data.\" I feel that the number of tested images is not sufficient. How about conducting experiments on a large number of tested images for untargeted attack? 4) In Table 1, what does 0,0,0, mean in ZOO? 5) It is known that BO has itself parameter to tune, and is not computationally efficient. It might be good to show the computation efficiency of BO for different reduced dimensions together with the corresponding attack performance. 6) The convergence of BO is usually not stable. However, Figure 3 shows that BO converges very smoothly in terms of ASR. Could authors also show the loss value of using BO-attacks against iteration numbers? Meanwhile, in Figure 3 is the best ASR (up to the current query counts) reported or the ASR at the current query number? Based on the aforementioned questions, my initial rating is weak reject. ############## Post-feedback ################ Thanks for the response. Most of my questions have been addressed. Thus, I increased my score to 6. I suggested to have a clearer presentation on the possible pros and cons of BO in attack generation, e.g., making a comparison between BO and other methods in both query efficiency and computation efficiency. ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for his helpful comments . We address the concerns below : 1 . \u201c Difference to https : //arxiv.org/pdf/1907.11684.pdf '' We thank the reviewer for pointing out this additional reference ( Zhao et al. , 2019 ) . We have cited it and highlighted the differences in Section 2 . The method proposed in that work , BO-ADMM , is effectively similar to our vanilla GP-BO but without the use of decoder to reduce the search space dimension . We propose improvements tailored to the commonly high-dimensional nature of adversarial attack problems , thus further enhancing the efficiency of BayesOpt attack for such application . Specifically , the key differences between our work and their work are : a ) BO-ADMM applies GP-based BO directly on the space of image dimension to minimise the joint objective of attack loss and distortion loss . This makes the problem much harder for BO and leads to low-quality adversarial examples ( mean L_ { \\inf } =0.62 for CIFAR10 ) . Our BayesOpt attacks minimise the attack loss under the L_ { \\inf } -norm constraint , and uses a decoder to reduce the search to a low-dimensional latent space , making the problem more amenable to GP-based BO . As a result , even our vanilla GP-BO , can find the adversarial examples with much smaller distortion ( mean L_ { \\inf } = 0.028 for CIFAR10 ) . b ) The method proposed in their work , BO-ADMM , only uses the simple Gaussian process as the BO surrogate . However , we propose a method to explicitly handle the high-dimensional search space effectively and build query efficient attacks by using an additive GP surrogate . This allows us to further decompose the reduced latent search space into low-dimensional subspaces . As shown in Table 2 of Section 5.2 , our ADDGP-BO attack achieves much higher success rate ( 14 % higher ) given the same query budget compared to previous data efficient approaches ( GP-BO ) . c ) We further propose the use of a Bayesian model selection method to learn the optimal dimensionality of the latent space in the process of optimisation/on the fly . Such Bayesian learning of the reduced dimensionality integrates naturally with a BayesOpt attack by employing the statistical surrogate but can also be applied independently with other adversarial attack methods to decide the reduced dimensionality in a principled way . We further demonstrate its effectiveness in our experiments . As shown in Table 2 of Section 5.2 , it leads to 15 % increase in ASR for GP-BO . 2. \u201c What \u2019 s the acquisition function and its hyperparameter ? What decoder is used ? The importance of the decoder ? \u201d We use the UCB and set the exploration-exploitation parameter to be a constant of 2 , which is adopted in BO packages such as GPyOpt . We briefly explored the use of different acquisition functions such as EI and found similar performance . We have added these clarifications in our paper . We adopt bilinear interpolation as the decoder . Please refer to Response 3 to Reviewer # 2 for more details . The use of the decoder is essential for the query efficiency of BayesOpt attacks because it helps reduce the BO search space significantly . For example , as shown in Table 3 in Section B of the Appendix for MNIST , the use of decoder reduces the median query count for GP-BO from 201 ( d=28x28x1 ) to 53 ( d^r =14x14x1 ) to achieve comparable attack success rate . 3. \u201c the number of tested images is not sufficient \u201d We conducted more experiments on 50 random CIFAR-10 images . Please refer Response 2 to Reviewer # 2 . 4. \u201c In Table 1 , what does 0,0,0 , mean in ZOO ? \u201d Sorry for the confusion . This means ZOO succeeds in attacking the 2 simplest image-target pairs at its first batch ( batch size of 128 ) of adversarial perturbations but fails to make successful attacks on the other cases under the budget constraints . 5. \u201c BO is not computationally efficient \u201d We update the GP hyperparameters every 5 iterations and relearn the reduced dimension or the additive decomposition every 40 iterations to reduce the computational cost . BO algorithms are indeed computationally more expensive than most adversarial methods . That \u2019 s why , as highlighted in the introduction , we focus on the adversarial setting where the cost of evaluating the target model , being it the monetary costs , computational costs or the risk of being detected , is much higher than the computational cost of BO algorithm itself and thus query efficiency is highly prioritised . 6. \u201c plot the attack loss value vs BO iterations ... Clarification on Figure 3. \u201d We have added the plots on the objective value ( the negative of loss ) against BayesOpt iterations ( query count ) for various BayesOpt methods in Section C of the Appendix . They show the case of attacking a CIFAR10 image of label class 9 and how our proposed modifications ( additive GP and Bayesian learning of d^r ) can lead to better convergence . Figure 3 in the paper shows the ASR up to the current query counts . We have clarified this in the Figure caption ."}, {"review_id": "Hkem-lrtvH-1", "review_text": "In this paper, the authors propose to use Bayesian optimization with a GP surrogate for adversarial image generation. In addition to the standard BayesOpt algorithm, the authors use a variant that exploits additive structure, as well as a variant that uses Bayesian model selection to determine an optimal dimensionality reduction. For the experimental results, I find it extremely surprising that vanilla GP-BO works at all, even downsampling e.g. to d=588 (Table 2). This is extraordinarily high dimensionality for vanilla BayesOpt, and conventional wisdom suggests that this should not work at all. I'd like to see a discussion of this, particularly as I've seen unsuccessful attempts at this in the past. What differentiating factors lead to it working here? The set of images considered is quite small, presumably because of the rather extreme wall clock expense of running hundreds of sequential BayesOpt iterations without GPU acceleration. This is particularly true for methods that require Bayesian model selection and therefore training multiple GPs in each iteration of BayesOpt. Along the same lines of dimensionality concerns, I would view a lack of results on ImageNet images as a significant weakness, particularly as these are probably much harder for general purpose blackbox optimizers, as the initial dimensionality of those images is ~150000. A decent amount of missing related literature studies transformations of ImageNet images, including the QL Attack (Ilyas et al., 2018), Bandits-TD (Ilyas et al., 2019) and others. These papers also focus specifically on query budget, so it would be hard to claim that BayesOpt is SOTA if it can't scale to images this large. Can you provide additional details on the learning mechanism for the additive decomposition? Are you learning kernel outputscales for different predefined additive components as in Duvenaud et al., 2011? Note that this is a fairly different structure than considered in Kandasamy et al., 2015 (despite both being called \"additive GPs\") -- the type of additive structure in Kandasamy et al., 2015 usually needs to be learned through approximate model selection mechanisms (usually via Metropolis-Hastings or Gibbs sampling).", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for his insightful comments . We address the concerns below : 1 . `` Need a discussion on the surprising phenomenon that vanilla GP-BO can work at all for such problem of extraordinarily high dimensionality . '' Please refer to our reply to all Reviewers for the detailed discussion . 2 . `` a lack of results on ImageNet images , which is much harder for general purpose blackbox optimizers given the initial dimensionality of those images is ~150000 '' To verify the feasibility/applicability of using our BayesOpt methods to perform `` targeted '' attacks on ImageNet , we select 50 correctly classified images from the ImageNet test data and perform random targeted attacks with a query budget of 2000 . We found that direct application of the BayesOpt attacks on the ImageNet image to do targeted attack rarely work due to the extremely high dimensionality of search space . However , we experimented a hierarchical decoding process : a ) first performance BayesOpt ( ADDGP-BO ) on a reduced dimension of d^r_1=48x48x3 or perform GP-BO-auto-dr by learning the optimal reduced dimension in the range up to d^r_1=48x48x3 and then 2 ) decode the adversarial perturbation found in d^r_1 to d^r_2=96x96x3 via bilinear upsampling . 3 ) This is followed by another bilinear decoder projecting the adversarial perturbation in d^r_2 back to image dimension of d=299x299x3 . Such hierarchical decoding leads to an ASR of 60 % by ADD-GP-BO and an ASR of 32 % by GP-BO-auto-dr , which are higher than the ASR of 12 % by GenAttack on the same image-target pairs with the same upsampling . We conduct further experiments on for our ADDGP-BO and GenAttack . ADDGP-BO achieves 60 % ASR within 1985 queries but GenAttack takes 4711 ( 2.4 times more ) queries to achieve the same ASR ( See Section E in the Appendix ) . We will update the paper with more experimental results on ImageNet . In addition , another ICLR 2020 submission titled `` Black-box Adversarial Attacks with Bayesian Optimization '' has empirically demonstrated the superior query efficiency of vanilla GP-BO on ImageNet dataset in the `` untargeted '' attack setting . 3 . `` \u2026 missing related literature studies including the QL Attack ( Ilyas et al. , 2018 ) , Bandits-TD ( Ilyas et al. , 2019 ) ... '' We thank the reviewer for the additional references . Bandits-TD ( Ilyas et al. , 2019 ) focuses on the simpler case of untargeted attacks and another ICLR 2020 submission titled Black-box Adversarial Attacks with Bayesian Optimization has demonstrated on ImageNet dataset that their simple GP-based BO attack , together with upsampling , ( which is almost the same as the GP-BO baseline in our paper ) can achieve higher attack success rate than Bandits-TD and Parsimonious attack ( Moon et al. , 2019 ) under a small query budget of 200 for the `` untargeted '' attack setting . And Du et al. , ( 2019 ) ( https : //arxiv.org/abs/1906.02398 ) has shown that our baseline method , AutoZOOM , is more query efficient than Bandits-TD for MNIST , CIFAR10 and tiny ImageNet . We didn \u2019 t compare against QL Attack ( Ilyas et al. , 2018 ) because two of our baseline methods , GenAttack and AutoZOOM , had shown to be more query efficient than QL Attack in ( Alzantot et al. , 2018 ) . In addition , both QL Attack and Bandits-TD require gradient estimation while our proposed method doesn \u2019 t . 4 . `` \u2026 additional details on learning the decomposition for the additive GP surrogate .... the additive structure in Kandasamy et al. , 2015 usually needs to be learned through Metropolis-Hastings or Gibbs sampling . '' We follow the approach proposed in ( Kandasamy et al. , 2015 ) to treat the decomposition as an additional hyperparameter and learn the optimal decomposition by maximising marginal likelihood . However , exhaustive search over all possible ( M ! d ! / ( d_s ! ^M ) ) decompositions ( i.e.decomposing d-dimensional space into M subspaces of d_s dimensions ) is expensive . We adopt a computationally cheap alternative by randomly selecting 20 decompositions and choosing the one with the largest marginal likelihood . The decomposition learning procedure is repeated every 40 BO iterations . As the reviewer mentioned , sophisticated sampling procedures can also be used to learn the decomposition and usually lead to better performance . However , they are computationally much more expensive than the maximum marginal likelihood approach . We verified the effectiveness of our way of learning decomposition by testing another alternative way to learn the decomposition ; pixels are grouped together if the magnitude of change in their pixel values over iterations are close . This is similar to importance sampling in ZOO . The performance of such pixel-value-change-based decomposition learning gives lower attack success rate than our approach of learning the decomposition via marginal likelihood . We have added this comparison as Section D in the Appendix ."}, {"review_id": "Hkem-lrtvH-2", "review_text": "The paper proposes a black-box attack method that optimises both the adversarial perturbation and the optimal dimensionaity reduction in a Bayesian Optimization framework. The formulation seem sound and the experiments show improvements wrt competitors in terms of performance and query efficiency with comparable attack success rates. * In section 4.3 the authors claim that the additive surrogate makes the GP-based BO able to deal with the problem of high dimensionality. Given that the typical dimensionality for BayesOpt is d <= 20, how are the experiments with dimensions up to 14x14x3 provided for GP-BO and GP-BO-auto-dT performed? * The image selection protocol seems arbitrary and it does not correspond to the Tu et al. protocol which selects 50 random images from CIFAR-100 and MNIST. * I feel the experiments lack some details: which is the decoder used for dimensionality reduction? ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the positive feedback and would like to address the issues raised . 1 . `` Given that the typical dimensionality for BayesOpt is d < = 20 , how are the experiments with dimensions up to 14x14x3 provided for GP-BO and GP-BO-auto-dr performed ? '' We use a GP kernel without ARD and learn the GP hyperparameters every 5 BO iterations . The optimal reduced dimension d^r is updated every 40 iterations . Please refer to our reply to all Reviewers for a more detailed discussion . 2 . `` The image selection protocol does not correspond to the Tu et al.protocol which selects 50 random images from CIFAR-10 . '' We conducted more experiments by selecting 50 random images from CIFAR-10 and attacking each image on the other 9 classes except its original class . We have updated the Table 2 and Figure 3 in Section 5.2 with new CIFAR10 results . Note that the relative ranking among different methods is the same as the original results in the paper and the magnitude of improvement in query efficiency and L_2 norm by BayesOpt attacks over competing methods also remains highly similar to , if not the same as , the original results presented . 3 . `` The experiments lack some details : which is the decoder used for dimensionality reduction ? '' As stated in the first paragraph of Section 4.1 , we adopt bilinear interpolation as the decoder , which is used in GenAttack ( Alzantot et al. , 2018 ) and Auto-ZOOM ( Tu et al. , 2018 ) . This is to ensure fair comparison . However , the approach can be combined with different decoder types ."}], "0": {"review_id": "Hkem-lrtvH-0", "review_text": "This paper studied the problem of black-box adversarial attack generation by leveraging Bayesian optimization (BO). Merits of this paper: 1) The combination of BO and dimension reduction, which makes BO more efficient under a low-dimensional space. 2) Good experiment results. Comments/questions about this paper: 1) Comment on \"Finally, to the best of our knowledge, the only prior work that uses Bayesian optimisation is a workshop paper by...\". BO was also used for generating black-box adversarial examples at https://arxiv.org/pdf/1907.11684.pdf This is a missing related work, and please elaborate on the differences. 2) The presentation of the proposed algorithm is not clear. Please explicitly state the acquisition function. And how to tune the hyperparameter in the acquisition function? What decoder is used in experiments? Have authors tested the sensitivity of the decoder (not reduced dimension)? 3) In experiments, the authors mentioned \"we randomly select 3 correctly classified images for each class from CIFAR10 test data which sums up to 27 CIFAR10 images, and randomly select 7 correctly classified images from MNIST test data.\" I feel that the number of tested images is not sufficient. How about conducting experiments on a large number of tested images for untargeted attack? 4) In Table 1, what does 0,0,0, mean in ZOO? 5) It is known that BO has itself parameter to tune, and is not computationally efficient. It might be good to show the computation efficiency of BO for different reduced dimensions together with the corresponding attack performance. 6) The convergence of BO is usually not stable. However, Figure 3 shows that BO converges very smoothly in terms of ASR. Could authors also show the loss value of using BO-attacks against iteration numbers? Meanwhile, in Figure 3 is the best ASR (up to the current query counts) reported or the ASR at the current query number? Based on the aforementioned questions, my initial rating is weak reject. ############## Post-feedback ################ Thanks for the response. Most of my questions have been addressed. Thus, I increased my score to 6. I suggested to have a clearer presentation on the possible pros and cons of BO in attack generation, e.g., making a comparison between BO and other methods in both query efficiency and computation efficiency. ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for his helpful comments . We address the concerns below : 1 . \u201c Difference to https : //arxiv.org/pdf/1907.11684.pdf '' We thank the reviewer for pointing out this additional reference ( Zhao et al. , 2019 ) . We have cited it and highlighted the differences in Section 2 . The method proposed in that work , BO-ADMM , is effectively similar to our vanilla GP-BO but without the use of decoder to reduce the search space dimension . We propose improvements tailored to the commonly high-dimensional nature of adversarial attack problems , thus further enhancing the efficiency of BayesOpt attack for such application . Specifically , the key differences between our work and their work are : a ) BO-ADMM applies GP-based BO directly on the space of image dimension to minimise the joint objective of attack loss and distortion loss . This makes the problem much harder for BO and leads to low-quality adversarial examples ( mean L_ { \\inf } =0.62 for CIFAR10 ) . Our BayesOpt attacks minimise the attack loss under the L_ { \\inf } -norm constraint , and uses a decoder to reduce the search to a low-dimensional latent space , making the problem more amenable to GP-based BO . As a result , even our vanilla GP-BO , can find the adversarial examples with much smaller distortion ( mean L_ { \\inf } = 0.028 for CIFAR10 ) . b ) The method proposed in their work , BO-ADMM , only uses the simple Gaussian process as the BO surrogate . However , we propose a method to explicitly handle the high-dimensional search space effectively and build query efficient attacks by using an additive GP surrogate . This allows us to further decompose the reduced latent search space into low-dimensional subspaces . As shown in Table 2 of Section 5.2 , our ADDGP-BO attack achieves much higher success rate ( 14 % higher ) given the same query budget compared to previous data efficient approaches ( GP-BO ) . c ) We further propose the use of a Bayesian model selection method to learn the optimal dimensionality of the latent space in the process of optimisation/on the fly . Such Bayesian learning of the reduced dimensionality integrates naturally with a BayesOpt attack by employing the statistical surrogate but can also be applied independently with other adversarial attack methods to decide the reduced dimensionality in a principled way . We further demonstrate its effectiveness in our experiments . As shown in Table 2 of Section 5.2 , it leads to 15 % increase in ASR for GP-BO . 2. \u201c What \u2019 s the acquisition function and its hyperparameter ? What decoder is used ? The importance of the decoder ? \u201d We use the UCB and set the exploration-exploitation parameter to be a constant of 2 , which is adopted in BO packages such as GPyOpt . We briefly explored the use of different acquisition functions such as EI and found similar performance . We have added these clarifications in our paper . We adopt bilinear interpolation as the decoder . Please refer to Response 3 to Reviewer # 2 for more details . The use of the decoder is essential for the query efficiency of BayesOpt attacks because it helps reduce the BO search space significantly . For example , as shown in Table 3 in Section B of the Appendix for MNIST , the use of decoder reduces the median query count for GP-BO from 201 ( d=28x28x1 ) to 53 ( d^r =14x14x1 ) to achieve comparable attack success rate . 3. \u201c the number of tested images is not sufficient \u201d We conducted more experiments on 50 random CIFAR-10 images . Please refer Response 2 to Reviewer # 2 . 4. \u201c In Table 1 , what does 0,0,0 , mean in ZOO ? \u201d Sorry for the confusion . This means ZOO succeeds in attacking the 2 simplest image-target pairs at its first batch ( batch size of 128 ) of adversarial perturbations but fails to make successful attacks on the other cases under the budget constraints . 5. \u201c BO is not computationally efficient \u201d We update the GP hyperparameters every 5 iterations and relearn the reduced dimension or the additive decomposition every 40 iterations to reduce the computational cost . BO algorithms are indeed computationally more expensive than most adversarial methods . That \u2019 s why , as highlighted in the introduction , we focus on the adversarial setting where the cost of evaluating the target model , being it the monetary costs , computational costs or the risk of being detected , is much higher than the computational cost of BO algorithm itself and thus query efficiency is highly prioritised . 6. \u201c plot the attack loss value vs BO iterations ... Clarification on Figure 3. \u201d We have added the plots on the objective value ( the negative of loss ) against BayesOpt iterations ( query count ) for various BayesOpt methods in Section C of the Appendix . They show the case of attacking a CIFAR10 image of label class 9 and how our proposed modifications ( additive GP and Bayesian learning of d^r ) can lead to better convergence . Figure 3 in the paper shows the ASR up to the current query counts . We have clarified this in the Figure caption ."}, "1": {"review_id": "Hkem-lrtvH-1", "review_text": "In this paper, the authors propose to use Bayesian optimization with a GP surrogate for adversarial image generation. In addition to the standard BayesOpt algorithm, the authors use a variant that exploits additive structure, as well as a variant that uses Bayesian model selection to determine an optimal dimensionality reduction. For the experimental results, I find it extremely surprising that vanilla GP-BO works at all, even downsampling e.g. to d=588 (Table 2). This is extraordinarily high dimensionality for vanilla BayesOpt, and conventional wisdom suggests that this should not work at all. I'd like to see a discussion of this, particularly as I've seen unsuccessful attempts at this in the past. What differentiating factors lead to it working here? The set of images considered is quite small, presumably because of the rather extreme wall clock expense of running hundreds of sequential BayesOpt iterations without GPU acceleration. This is particularly true for methods that require Bayesian model selection and therefore training multiple GPs in each iteration of BayesOpt. Along the same lines of dimensionality concerns, I would view a lack of results on ImageNet images as a significant weakness, particularly as these are probably much harder for general purpose blackbox optimizers, as the initial dimensionality of those images is ~150000. A decent amount of missing related literature studies transformations of ImageNet images, including the QL Attack (Ilyas et al., 2018), Bandits-TD (Ilyas et al., 2019) and others. These papers also focus specifically on query budget, so it would be hard to claim that BayesOpt is SOTA if it can't scale to images this large. Can you provide additional details on the learning mechanism for the additive decomposition? Are you learning kernel outputscales for different predefined additive components as in Duvenaud et al., 2011? Note that this is a fairly different structure than considered in Kandasamy et al., 2015 (despite both being called \"additive GPs\") -- the type of additive structure in Kandasamy et al., 2015 usually needs to be learned through approximate model selection mechanisms (usually via Metropolis-Hastings or Gibbs sampling).", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for his insightful comments . We address the concerns below : 1 . `` Need a discussion on the surprising phenomenon that vanilla GP-BO can work at all for such problem of extraordinarily high dimensionality . '' Please refer to our reply to all Reviewers for the detailed discussion . 2 . `` a lack of results on ImageNet images , which is much harder for general purpose blackbox optimizers given the initial dimensionality of those images is ~150000 '' To verify the feasibility/applicability of using our BayesOpt methods to perform `` targeted '' attacks on ImageNet , we select 50 correctly classified images from the ImageNet test data and perform random targeted attacks with a query budget of 2000 . We found that direct application of the BayesOpt attacks on the ImageNet image to do targeted attack rarely work due to the extremely high dimensionality of search space . However , we experimented a hierarchical decoding process : a ) first performance BayesOpt ( ADDGP-BO ) on a reduced dimension of d^r_1=48x48x3 or perform GP-BO-auto-dr by learning the optimal reduced dimension in the range up to d^r_1=48x48x3 and then 2 ) decode the adversarial perturbation found in d^r_1 to d^r_2=96x96x3 via bilinear upsampling . 3 ) This is followed by another bilinear decoder projecting the adversarial perturbation in d^r_2 back to image dimension of d=299x299x3 . Such hierarchical decoding leads to an ASR of 60 % by ADD-GP-BO and an ASR of 32 % by GP-BO-auto-dr , which are higher than the ASR of 12 % by GenAttack on the same image-target pairs with the same upsampling . We conduct further experiments on for our ADDGP-BO and GenAttack . ADDGP-BO achieves 60 % ASR within 1985 queries but GenAttack takes 4711 ( 2.4 times more ) queries to achieve the same ASR ( See Section E in the Appendix ) . We will update the paper with more experimental results on ImageNet . In addition , another ICLR 2020 submission titled `` Black-box Adversarial Attacks with Bayesian Optimization '' has empirically demonstrated the superior query efficiency of vanilla GP-BO on ImageNet dataset in the `` untargeted '' attack setting . 3 . `` \u2026 missing related literature studies including the QL Attack ( Ilyas et al. , 2018 ) , Bandits-TD ( Ilyas et al. , 2019 ) ... '' We thank the reviewer for the additional references . Bandits-TD ( Ilyas et al. , 2019 ) focuses on the simpler case of untargeted attacks and another ICLR 2020 submission titled Black-box Adversarial Attacks with Bayesian Optimization has demonstrated on ImageNet dataset that their simple GP-based BO attack , together with upsampling , ( which is almost the same as the GP-BO baseline in our paper ) can achieve higher attack success rate than Bandits-TD and Parsimonious attack ( Moon et al. , 2019 ) under a small query budget of 200 for the `` untargeted '' attack setting . And Du et al. , ( 2019 ) ( https : //arxiv.org/abs/1906.02398 ) has shown that our baseline method , AutoZOOM , is more query efficient than Bandits-TD for MNIST , CIFAR10 and tiny ImageNet . We didn \u2019 t compare against QL Attack ( Ilyas et al. , 2018 ) because two of our baseline methods , GenAttack and AutoZOOM , had shown to be more query efficient than QL Attack in ( Alzantot et al. , 2018 ) . In addition , both QL Attack and Bandits-TD require gradient estimation while our proposed method doesn \u2019 t . 4 . `` \u2026 additional details on learning the decomposition for the additive GP surrogate .... the additive structure in Kandasamy et al. , 2015 usually needs to be learned through Metropolis-Hastings or Gibbs sampling . '' We follow the approach proposed in ( Kandasamy et al. , 2015 ) to treat the decomposition as an additional hyperparameter and learn the optimal decomposition by maximising marginal likelihood . However , exhaustive search over all possible ( M ! d ! / ( d_s ! ^M ) ) decompositions ( i.e.decomposing d-dimensional space into M subspaces of d_s dimensions ) is expensive . We adopt a computationally cheap alternative by randomly selecting 20 decompositions and choosing the one with the largest marginal likelihood . The decomposition learning procedure is repeated every 40 BO iterations . As the reviewer mentioned , sophisticated sampling procedures can also be used to learn the decomposition and usually lead to better performance . However , they are computationally much more expensive than the maximum marginal likelihood approach . We verified the effectiveness of our way of learning decomposition by testing another alternative way to learn the decomposition ; pixels are grouped together if the magnitude of change in their pixel values over iterations are close . This is similar to importance sampling in ZOO . The performance of such pixel-value-change-based decomposition learning gives lower attack success rate than our approach of learning the decomposition via marginal likelihood . We have added this comparison as Section D in the Appendix ."}, "2": {"review_id": "Hkem-lrtvH-2", "review_text": "The paper proposes a black-box attack method that optimises both the adversarial perturbation and the optimal dimensionaity reduction in a Bayesian Optimization framework. The formulation seem sound and the experiments show improvements wrt competitors in terms of performance and query efficiency with comparable attack success rates. * In section 4.3 the authors claim that the additive surrogate makes the GP-based BO able to deal with the problem of high dimensionality. Given that the typical dimensionality for BayesOpt is d <= 20, how are the experiments with dimensions up to 14x14x3 provided for GP-BO and GP-BO-auto-dT performed? * The image selection protocol seems arbitrary and it does not correspond to the Tu et al. protocol which selects 50 random images from CIFAR-100 and MNIST. * I feel the experiments lack some details: which is the decoder used for dimensionality reduction? ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the positive feedback and would like to address the issues raised . 1 . `` Given that the typical dimensionality for BayesOpt is d < = 20 , how are the experiments with dimensions up to 14x14x3 provided for GP-BO and GP-BO-auto-dr performed ? '' We use a GP kernel without ARD and learn the GP hyperparameters every 5 BO iterations . The optimal reduced dimension d^r is updated every 40 iterations . Please refer to our reply to all Reviewers for a more detailed discussion . 2 . `` The image selection protocol does not correspond to the Tu et al.protocol which selects 50 random images from CIFAR-10 . '' We conducted more experiments by selecting 50 random images from CIFAR-10 and attacking each image on the other 9 classes except its original class . We have updated the Table 2 and Figure 3 in Section 5.2 with new CIFAR10 results . Note that the relative ranking among different methods is the same as the original results in the paper and the magnitude of improvement in query efficiency and L_2 norm by BayesOpt attacks over competing methods also remains highly similar to , if not the same as , the original results presented . 3 . `` The experiments lack some details : which is the decoder used for dimensionality reduction ? '' As stated in the first paragraph of Section 4.1 , we adopt bilinear interpolation as the decoder , which is used in GenAttack ( Alzantot et al. , 2018 ) and Auto-ZOOM ( Tu et al. , 2018 ) . This is to ensure fair comparison . However , the approach can be combined with different decoder types ."}}