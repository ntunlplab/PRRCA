{"year": "2019", "forum": "B1e8CsRctX", "title": "Generative Ensembles for Robust Anomaly Detection", "decision": "Reject", "meta_review": "This paper suggests the use of generative ensembles for detecting out-of-distribution samples. \n\nThe reviewers found the paper easy to read, especially after the changes made during the rebuttal. However, further elaboration in the technical descriptions (and assumptions made) could make the work seem more mature, as R2 and R1 point out. \n\nThe general feeling by reading the reviews and discussions is that this is promising work that, nevertheless, needs some more novel elements. A possible avenue for increasing the contribution of the paper is to follow R1\u2019s advice to extract more convincing insights from the results. \n", "reviews": [{"review_id": "B1e8CsRctX-0", "review_text": "Note to Area Chair: Another paper submitted to ICLR under the title \u201cDo Deep Generative Models Know What They Don\u2019t Know?\u201d shares several similarities with the current submission. This paper highlights a deficiency of current generative models in detecting out-of-distribution based samples based on likelihoods assigned by the model (in cases where the likelihoods are well-defined) or the discriminator distribution for GANs (where likelihoods are typically not defined). To remedy this deficiency, the paper proposes to use ensembles of generative models to obtain a robust WAIC criteria for anomaly detection. My main concern is with the level of technical rigor of this work. Much of this has to do with the presentation, which reads to me more like a summary blog post rather than a technical paper. - I couldn\u2019t find a formal specification of the anomaly detection setup and how generative models are used for this task anywhere in the paper. - Section 2 seems to be the major contribution of this work. But it was very hard to understand what exactly is going on. What is the notation for the generative distribution? Introduction uses p_theta. Page 2, Paragraph 1 uses q_theta (x). Eq. (1) uses p_theta and then the following paragraphs use q_theta. - In Eq. (1), is theta a random variable? - How are generative ensembles trained? All the paper says is \u201cindependently trained\u201d. Is the parameter initialization different? Is the dataset shuffling different? Is the dataset sampled with replacement (as in bootstrapping)? - \u201cBy training an ensemble of GANs we can estimate the posterior distribution over model deciscion boundaries D_theta(x), or equivalently, the posterior distribution over alternate distributions q_theta. In other words, we can use uncertainty estimation on randomly sampled discriminators to de-correlate the OoD classification errors made by a single discriminator\u201d Why is the discriminator parameterized by theta? What is an ensemble of GANs? Multiple generators or multiple discriminators or both? What are \u201crandomly sampled discriminators\u201d? What do the authors mean by \"posterior distribution over alternate distributions\"? With regards to the technical assessment, I have the following questions for the authors: - In Figure 1, how do the histograms look for the training distribution of CIFAR? If the histograms for train and test have an overlap much higher than the overlap between the train of CIFAR and test set of any other distribution, then ensembling seems unnecessary and anomaly detecting can simply be done via setting a maximum and a minimum threshold on the likelihood for a test point. In addition to the histograms, I'd be curious to see results with this baseline mechanism. - Why should the WAIC criteria weigh the mean and variance equally? - Did the authors actually try to fix the posterior collapse issue in Figure 3b using beta-VAEs as recommended? Given the simplicity of implementing beta-VAEs, this should be a rather easy experiment to include. Minor typos: - ODIN and VIB are not defined in the abstract - Page 3: \u201cdeciscion\u201d - Page 2, para 2: \u201clog_\\theta p(x)\u201d", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the detailed review and critique . We agree that \u201c Do Deep ... They Don \u2019 t Know ? \u201d shares a concurrent discovery with us in identifying how generative models assign wrong likelihood to OoD inputs , and have updated our paper to cite their contribution . Our contributions differ in that their work performs analysis of why this phenomenon occurs , while we demonstrate that this can be fixed by using uncertainty estimation and WAIC , and then apply these fixed models to the OoD problem . We agree that our paper could use more technical clarity , i.e.make this work easier to reproduce . The open-sourced code will be linked to the paper after double-blind review process , which we believe to be the highest standard of technical clarity when specifying our method and evaluation metrics . In the meantime , we \u2019 ve also done the following : 1 . We \u2019 ve clarified Section 4 to re-iterate that our anomaly detection problem specification is identical to that of Liang et al.2017 and Alemi et al.2017 , and our evaluation metric ( AUROC ) is the same . 2.Clarified the notation of our notation for p , q , p_theta , q_theta in the paper . We think that R1 \u2019 s confusion on our GAN ensemble setup can be addressed by clarifying the reasoning behind our terminology , and explaining a bit further what it means to \u201c randomly sample a discriminator from a posterior distribution over alternate distributions \u201d The choice of terminology is motivated by our GAN variant of generative ensembles . If p ( x ) is the true generative distribution , p_theta ( x ) is some generative model \u2019 s approximation of it . In Eq ( 1 ) , theta is a ( multivariate ) random variable parameterizing an abstract generative model ( e.g.weights in a neural network ) . We \u2019 ve clarified this in the intro . In the case of GANs , a subset of the variable theta parameterizes the generator and a subset of theta parameterizes the discriminator . Therefore , samples from the generator come from a generative distribution q_\\theta ( x ) . We notate a GAN generator \u2019 s distribution as q_\\theta ( x ) and not p_\\theta ( x ) ( which we use for referring to normalizing flow and VAE likelihood models ) is that in GANs , the discriminator is being optimized to learn a likelihood ratio p ( x ) / q_\\theta ( x ) . That is , separating true data samples from p ( x ) from OoD samples from q_\\theta ( x ) . Thus , q ( x ) and q_theta ( x ) always refer to OoD distributions . This also makes discussion more clear in the context of discriminative anomaly detection classifiers ( which learn p ( x ) /q ( x ) ) and GAN discriminators ( which learn p ( x ) /q_theta ( x ) ) . In Section 2.1 , we mention \u201c randomly sampled discriminators \u201d and \u201c posterior distribution over alternate distributions \u201d . Models ( theta ) trained under SGD can be assumed to be drawn randomly from some posterior distribution over p ( theta|x ) . In a GAN , random variable theta specifies the alternate distribution q_\\theta ( x ) , or equivalently , the implicit discriminator likelihood ratio p ( x ) / q_\\theta ( x ) ( when the discriminator is trained with sigmoid cross entropy , which we do ) . Our GAN ensembles samples entire GANs ( i.e.generator and discriminator ) together , by training 5 GANs independently and then combining discriminator predictions for OoD classification . It would be problematic to sample only discriminators in the training process , since that does not change q_\\theta ( x ) ( and there is the question of how feedback to the generators should be accomplished in this manner ) . Technical assessment questions : - Re : Histograms . This is a reasonable suggestion , and resembles the interpretation of likelihood predictions as a feature , rather than a scoring function . The scoring function you propose is a min/max function over the distribution of features . Another approach would be a statistical hyppothesis test using the training distribution \u2019 s likelihood predictions as the variable of interest . Unfortunately , the likelihoods of OoD distributions often overlap with the in-distribution test samples ( MNIST and Fashion MNIST VAEs ) . In training a GLOW model , you will also find a gap between train and test likelihoods . So generative models are not good enough yet to reduce the generalization gap of likelihood models zero . - We refer the reviewer to `` Understanding predictive information criteria for Bayesian models '' ( Gelman et al . ) for a motivation of the WAIC objective . In short , the variance term is a correction for how much the fitting of k parameters will increase predictive accuracy , by chance alone . K is estimated by the variance . - Re : Posterior Collapse : Good suggestion ! We went back to our VAE setup and ran a few follow-up experiments to prove this hypothesis . The short answer is that \u201c yes , decreasing Beta reduced posterior collapse and made things better \u201d . We \u2019 ve edited section 4.1 to document our findings . Minor typos : They have been fixed in the latest revision . Thank you so much for catching these !"}, {"review_id": "B1e8CsRctX-1", "review_text": "- Novelty is minimal and is well below the level required by ICLR. - The reasoning lists the problems of GANs and then the fact that GAN ensembles would target that, based on a toy example in Figure 2. - Why to choose GANs though in the first place? Given the buildup, and given the other well-known training issues about GANs, are they the right choice for the basic modeling units, i.e. the ensemble units, in such case? A GANs adversary bases its comparisons on individual data points, rather than on distribution comparisons or on groups of points like MMD, etc. I understand the reasoning behind the choice of generative models (GMs), but it is choosing GANs out of the set of GMs in this particular case that I am referring to. - The paper is quite well written. The ideas as well as the reasoning flow very smoothly. - Experiments are well prepared. Rather minor: - page 1: \"When training and test distributions differ, neural networks may provide ...\" This is true but may be a clarification here regarding the fact that the neural networks involved with several modeling problems, e.g. the ones trained for domain adaptation or meta-learning tasks, target this shift or difference in domains, and typically provide a way to tackle this problem. Uodate: Read the rebuttal. My score remains unchanged. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank Reviewer 2 for their praise and raising concerns about novelty . It is an important point worth discussing . In addition to proposing a superior method for anomaly detection , part of the novel contribution in this work involved synthesizing concepts from multiple fields likelihood estimation techniques from deep generative models , adversarial defense , model uncertainty , challenging discriminative anomaly detection methods and their relationship to GAN discriminators . We tie these disparate concepts together into a unified perspective on the OoD problem . Therefore , we took great care into making sure the motivation of our work transitions smoothly , perhaps even to the point of stating the obvious to Reviewer 2 . We emphasize that to our knowledge , our work is the first to extend our understanding of the OoD problem in context of prior work in generative modeling , Bayesian Deep Learning , and anomaly detection applications for modern generative models . These connections are not well known in the community and we hope that our paper will amend that . Additional novel aspects of this work : The observation that density estimators ( as implemented by a deep generative model ) are NOT robust to OoD inputs themselves is a novel observation , concurrent with another ICLR submission . To our knowledge , we are also the first work to leverage the modern advancements in deep generative models to perform anomaly detection on high-dimensional inputs such as images . To address R2 \u2019 s comments \u201c The reasoning lists the problems of GANs \u201d and \u201c Why to choose GANs though in the first place ? \u201d , we emphasize that we are not saying GANs shouldn \u2019 t be used for anomaly detection , only that their lack of exact likelihoods presents some challenges . We make an effort to make them work in our paper in our comparison to other generative model families . > - page 1 : `` When training and test distributions differ , neural networks may provide ... '' There are varying degrees of \u201c out-of-distribution-ness \u201d at test time . One way to carve up the problem specification is to consider inputs that ( 1 ) are different than the training set but you want the model to perform well on anyway , e.g.a subtle change in physics parameters a robot encounters when deployed . ( 2 ) inputs the model has no business classifying , i.e.showing a picture of a building to a cat/dog classifier . The first situation is what you are describing , in which methods like sim2real , domain adaptation , meta-learning can address . As we stated in Section 3.1 , our paper primarily deals with the second case , in which you don \u2019 t want the model to give bogus outputs for bogus inputs , which also may be adversarial . We appreciate the feedback that this might be confusing if the reader is assuming problem formulation ( 1 ) ; we welcome the other reviewers to chime in here if it would make things more clear to state this ."}, {"review_id": "B1e8CsRctX-2", "review_text": "The authors present an OOD detection scheme with an ensemble of generative models. When the exact likelihood is available from the generative model, the authors approximate the WAIC score. For GAN models, the authors compute the variance over the discriminators for any given input. They show that this method outperforms ODIN and VIB on image datasets and also achieves comparable performance on Kaggle Credit Fraud dataset. The paper is overall well-written and easy to follow. I only have a few comments about the work. I think the authors should address the following points in the paper. - What is the size of the ensemble for the experiments? - How does the size of the ensemble influence the measured performance? - It is Fast Gradient Sign Method (FGSM), not FSGM. See [1]. Citing [1] for FGSM would also be appropriate. Quality. The submission is technically sound. The empirical results support the claims, and the authors discuss the failure cases. Clarity. The paper is well-written and easy to follow while providing useful insight and connecting previous work to the subject of study. Originality. To the best my knowledge, the proposed approach is a novel combination of well-known techniques. Significance. The presented idea improves over the state-of-the-art. References [1] I. Goodfellow, J. Shlens, and C. Szegedy, \u201cExplaining and Harnessing Adversarial Examples,\u201d in ICLR, 2015. ------------------- Revision. The rating revised to 6 after the discussion and rebuttal. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 3 for the review and highlighting missing details from our paper . We \u2019 ve added them into the paper . > - How does the size of the ensemble influence the measured performance ? For CIFAR10 , we have found 5 ensembles to make a large difference over 3 ensembles ( about .7 AUROC ) . There seem to be diminishing returns for models > 5 . > - It is Fast Gradient Sign Method ( FGSM ) , not FSGM . See [ 1 ] .Citing [ 1 ] for FGSM would also be appropriate . Fixed , and already cited . Thanks !"}], "0": {"review_id": "B1e8CsRctX-0", "review_text": "Note to Area Chair: Another paper submitted to ICLR under the title \u201cDo Deep Generative Models Know What They Don\u2019t Know?\u201d shares several similarities with the current submission. This paper highlights a deficiency of current generative models in detecting out-of-distribution based samples based on likelihoods assigned by the model (in cases where the likelihoods are well-defined) or the discriminator distribution for GANs (where likelihoods are typically not defined). To remedy this deficiency, the paper proposes to use ensembles of generative models to obtain a robust WAIC criteria for anomaly detection. My main concern is with the level of technical rigor of this work. Much of this has to do with the presentation, which reads to me more like a summary blog post rather than a technical paper. - I couldn\u2019t find a formal specification of the anomaly detection setup and how generative models are used for this task anywhere in the paper. - Section 2 seems to be the major contribution of this work. But it was very hard to understand what exactly is going on. What is the notation for the generative distribution? Introduction uses p_theta. Page 2, Paragraph 1 uses q_theta (x). Eq. (1) uses p_theta and then the following paragraphs use q_theta. - In Eq. (1), is theta a random variable? - How are generative ensembles trained? All the paper says is \u201cindependently trained\u201d. Is the parameter initialization different? Is the dataset shuffling different? Is the dataset sampled with replacement (as in bootstrapping)? - \u201cBy training an ensemble of GANs we can estimate the posterior distribution over model deciscion boundaries D_theta(x), or equivalently, the posterior distribution over alternate distributions q_theta. In other words, we can use uncertainty estimation on randomly sampled discriminators to de-correlate the OoD classification errors made by a single discriminator\u201d Why is the discriminator parameterized by theta? What is an ensemble of GANs? Multiple generators or multiple discriminators or both? What are \u201crandomly sampled discriminators\u201d? What do the authors mean by \"posterior distribution over alternate distributions\"? With regards to the technical assessment, I have the following questions for the authors: - In Figure 1, how do the histograms look for the training distribution of CIFAR? If the histograms for train and test have an overlap much higher than the overlap between the train of CIFAR and test set of any other distribution, then ensembling seems unnecessary and anomaly detecting can simply be done via setting a maximum and a minimum threshold on the likelihood for a test point. In addition to the histograms, I'd be curious to see results with this baseline mechanism. - Why should the WAIC criteria weigh the mean and variance equally? - Did the authors actually try to fix the posterior collapse issue in Figure 3b using beta-VAEs as recommended? Given the simplicity of implementing beta-VAEs, this should be a rather easy experiment to include. Minor typos: - ODIN and VIB are not defined in the abstract - Page 3: \u201cdeciscion\u201d - Page 2, para 2: \u201clog_\\theta p(x)\u201d", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the detailed review and critique . We agree that \u201c Do Deep ... They Don \u2019 t Know ? \u201d shares a concurrent discovery with us in identifying how generative models assign wrong likelihood to OoD inputs , and have updated our paper to cite their contribution . Our contributions differ in that their work performs analysis of why this phenomenon occurs , while we demonstrate that this can be fixed by using uncertainty estimation and WAIC , and then apply these fixed models to the OoD problem . We agree that our paper could use more technical clarity , i.e.make this work easier to reproduce . The open-sourced code will be linked to the paper after double-blind review process , which we believe to be the highest standard of technical clarity when specifying our method and evaluation metrics . In the meantime , we \u2019 ve also done the following : 1 . We \u2019 ve clarified Section 4 to re-iterate that our anomaly detection problem specification is identical to that of Liang et al.2017 and Alemi et al.2017 , and our evaluation metric ( AUROC ) is the same . 2.Clarified the notation of our notation for p , q , p_theta , q_theta in the paper . We think that R1 \u2019 s confusion on our GAN ensemble setup can be addressed by clarifying the reasoning behind our terminology , and explaining a bit further what it means to \u201c randomly sample a discriminator from a posterior distribution over alternate distributions \u201d The choice of terminology is motivated by our GAN variant of generative ensembles . If p ( x ) is the true generative distribution , p_theta ( x ) is some generative model \u2019 s approximation of it . In Eq ( 1 ) , theta is a ( multivariate ) random variable parameterizing an abstract generative model ( e.g.weights in a neural network ) . We \u2019 ve clarified this in the intro . In the case of GANs , a subset of the variable theta parameterizes the generator and a subset of theta parameterizes the discriminator . Therefore , samples from the generator come from a generative distribution q_\\theta ( x ) . We notate a GAN generator \u2019 s distribution as q_\\theta ( x ) and not p_\\theta ( x ) ( which we use for referring to normalizing flow and VAE likelihood models ) is that in GANs , the discriminator is being optimized to learn a likelihood ratio p ( x ) / q_\\theta ( x ) . That is , separating true data samples from p ( x ) from OoD samples from q_\\theta ( x ) . Thus , q ( x ) and q_theta ( x ) always refer to OoD distributions . This also makes discussion more clear in the context of discriminative anomaly detection classifiers ( which learn p ( x ) /q ( x ) ) and GAN discriminators ( which learn p ( x ) /q_theta ( x ) ) . In Section 2.1 , we mention \u201c randomly sampled discriminators \u201d and \u201c posterior distribution over alternate distributions \u201d . Models ( theta ) trained under SGD can be assumed to be drawn randomly from some posterior distribution over p ( theta|x ) . In a GAN , random variable theta specifies the alternate distribution q_\\theta ( x ) , or equivalently , the implicit discriminator likelihood ratio p ( x ) / q_\\theta ( x ) ( when the discriminator is trained with sigmoid cross entropy , which we do ) . Our GAN ensembles samples entire GANs ( i.e.generator and discriminator ) together , by training 5 GANs independently and then combining discriminator predictions for OoD classification . It would be problematic to sample only discriminators in the training process , since that does not change q_\\theta ( x ) ( and there is the question of how feedback to the generators should be accomplished in this manner ) . Technical assessment questions : - Re : Histograms . This is a reasonable suggestion , and resembles the interpretation of likelihood predictions as a feature , rather than a scoring function . The scoring function you propose is a min/max function over the distribution of features . Another approach would be a statistical hyppothesis test using the training distribution \u2019 s likelihood predictions as the variable of interest . Unfortunately , the likelihoods of OoD distributions often overlap with the in-distribution test samples ( MNIST and Fashion MNIST VAEs ) . In training a GLOW model , you will also find a gap between train and test likelihoods . So generative models are not good enough yet to reduce the generalization gap of likelihood models zero . - We refer the reviewer to `` Understanding predictive information criteria for Bayesian models '' ( Gelman et al . ) for a motivation of the WAIC objective . In short , the variance term is a correction for how much the fitting of k parameters will increase predictive accuracy , by chance alone . K is estimated by the variance . - Re : Posterior Collapse : Good suggestion ! We went back to our VAE setup and ran a few follow-up experiments to prove this hypothesis . The short answer is that \u201c yes , decreasing Beta reduced posterior collapse and made things better \u201d . We \u2019 ve edited section 4.1 to document our findings . Minor typos : They have been fixed in the latest revision . Thank you so much for catching these !"}, "1": {"review_id": "B1e8CsRctX-1", "review_text": "- Novelty is minimal and is well below the level required by ICLR. - The reasoning lists the problems of GANs and then the fact that GAN ensembles would target that, based on a toy example in Figure 2. - Why to choose GANs though in the first place? Given the buildup, and given the other well-known training issues about GANs, are they the right choice for the basic modeling units, i.e. the ensemble units, in such case? A GANs adversary bases its comparisons on individual data points, rather than on distribution comparisons or on groups of points like MMD, etc. I understand the reasoning behind the choice of generative models (GMs), but it is choosing GANs out of the set of GMs in this particular case that I am referring to. - The paper is quite well written. The ideas as well as the reasoning flow very smoothly. - Experiments are well prepared. Rather minor: - page 1: \"When training and test distributions differ, neural networks may provide ...\" This is true but may be a clarification here regarding the fact that the neural networks involved with several modeling problems, e.g. the ones trained for domain adaptation or meta-learning tasks, target this shift or difference in domains, and typically provide a way to tackle this problem. Uodate: Read the rebuttal. My score remains unchanged. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank Reviewer 2 for their praise and raising concerns about novelty . It is an important point worth discussing . In addition to proposing a superior method for anomaly detection , part of the novel contribution in this work involved synthesizing concepts from multiple fields likelihood estimation techniques from deep generative models , adversarial defense , model uncertainty , challenging discriminative anomaly detection methods and their relationship to GAN discriminators . We tie these disparate concepts together into a unified perspective on the OoD problem . Therefore , we took great care into making sure the motivation of our work transitions smoothly , perhaps even to the point of stating the obvious to Reviewer 2 . We emphasize that to our knowledge , our work is the first to extend our understanding of the OoD problem in context of prior work in generative modeling , Bayesian Deep Learning , and anomaly detection applications for modern generative models . These connections are not well known in the community and we hope that our paper will amend that . Additional novel aspects of this work : The observation that density estimators ( as implemented by a deep generative model ) are NOT robust to OoD inputs themselves is a novel observation , concurrent with another ICLR submission . To our knowledge , we are also the first work to leverage the modern advancements in deep generative models to perform anomaly detection on high-dimensional inputs such as images . To address R2 \u2019 s comments \u201c The reasoning lists the problems of GANs \u201d and \u201c Why to choose GANs though in the first place ? \u201d , we emphasize that we are not saying GANs shouldn \u2019 t be used for anomaly detection , only that their lack of exact likelihoods presents some challenges . We make an effort to make them work in our paper in our comparison to other generative model families . > - page 1 : `` When training and test distributions differ , neural networks may provide ... '' There are varying degrees of \u201c out-of-distribution-ness \u201d at test time . One way to carve up the problem specification is to consider inputs that ( 1 ) are different than the training set but you want the model to perform well on anyway , e.g.a subtle change in physics parameters a robot encounters when deployed . ( 2 ) inputs the model has no business classifying , i.e.showing a picture of a building to a cat/dog classifier . The first situation is what you are describing , in which methods like sim2real , domain adaptation , meta-learning can address . As we stated in Section 3.1 , our paper primarily deals with the second case , in which you don \u2019 t want the model to give bogus outputs for bogus inputs , which also may be adversarial . We appreciate the feedback that this might be confusing if the reader is assuming problem formulation ( 1 ) ; we welcome the other reviewers to chime in here if it would make things more clear to state this ."}, "2": {"review_id": "B1e8CsRctX-2", "review_text": "The authors present an OOD detection scheme with an ensemble of generative models. When the exact likelihood is available from the generative model, the authors approximate the WAIC score. For GAN models, the authors compute the variance over the discriminators for any given input. They show that this method outperforms ODIN and VIB on image datasets and also achieves comparable performance on Kaggle Credit Fraud dataset. The paper is overall well-written and easy to follow. I only have a few comments about the work. I think the authors should address the following points in the paper. - What is the size of the ensemble for the experiments? - How does the size of the ensemble influence the measured performance? - It is Fast Gradient Sign Method (FGSM), not FSGM. See [1]. Citing [1] for FGSM would also be appropriate. Quality. The submission is technically sound. The empirical results support the claims, and the authors discuss the failure cases. Clarity. The paper is well-written and easy to follow while providing useful insight and connecting previous work to the subject of study. Originality. To the best my knowledge, the proposed approach is a novel combination of well-known techniques. Significance. The presented idea improves over the state-of-the-art. References [1] I. Goodfellow, J. Shlens, and C. Szegedy, \u201cExplaining and Harnessing Adversarial Examples,\u201d in ICLR, 2015. ------------------- Revision. The rating revised to 6 after the discussion and rebuttal. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 3 for the review and highlighting missing details from our paper . We \u2019 ve added them into the paper . > - How does the size of the ensemble influence the measured performance ? For CIFAR10 , we have found 5 ensembles to make a large difference over 3 ensembles ( about .7 AUROC ) . There seem to be diminishing returns for models > 5 . > - It is Fast Gradient Sign Method ( FGSM ) , not FSGM . See [ 1 ] .Citing [ 1 ] for FGSM would also be appropriate . Fixed , and already cited . Thanks !"}}