{"year": "2021", "forum": "EbIDjBynYJ8", "title": "Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding", "decision": "Accept (Oral)", "meta_review": "This paper proposes a model for learning disentangled representations by assuming the slowness prior over transitions between two frames. The model is well justified theoretically, and evaluated extensively experimentally. The results are good, and all reviewers agree that this paper is among the top papers they have reviewed. For this reason, I am pleased to recommend this paper for an Oral.", "reviews": [{"review_id": "EbIDjBynYJ8-0", "review_text": "This paper introduces the SlowVAE to model transitions ( of position , size , etc ) in single-object videos . A Laplace prior conditioned on the latents at the previous step is used to learn the transitions , which the authors argue are naturally sparse . My biggest concern regarding this work is the construction of datasets : the authors effectively \u201c consider pairs of images [ x_ { t-1 } , x_t ] , which differ effectively in only a few factors of variation due to the sparse prior. \u201d While the marginal distributions of factor transitions may no doubt be sparse in natural settings , I would guess the sparsity is not independent across factors . For example : a video where a camera moves sporadically will show the position factors and size of an object changing sparsely but simultaneously . Could you augment Fig 1 and appendix H to show the joint distributions in addition to the marginals ? Moreover , the LAP procedure has the following rejection rule : \u201c if all factors remain constant ( no transition ) , the sample is rejected as the pair would not result in any temporal learning signal. \u201d Surely there needs to be some static pairs if you want to be close to natural videos ? Given KITTI is the only dataset you show results on whose transitions are natural ( albeit not 3D-natural ; see caveat in question 2 below ) , it would be nice to see more evidence how the SlowVAE would generalize and cope in scenarios different from the ones you \u2019 ve constructed . If the LAP procedure indeed samples from marginal transition statistics rather than the joint distributions , I do n't believe the samples would resemble `` natural transitions '' . Learning disentangled representations from data which is engineered to show changes in one generative feature at a time seems like cheating because we usually do n't have easy access to such data ( unless an agent actively interacts with an object ) . Strengths : - Good literature review - Comparison to relevant SOTA models , linking to prior work on disentanglement as well as nonlinear ICA , on a variety of metrics . - Solid experiments and well-presented results Questions : 1 ) Have you tried working with sequences rather than pairs of images ? I assume your ELBO can be readily extended to sequential data . Are there additional challenges in working with sequences ? 2 ) Do you think there 's room for bias in the natural statistics you computed on Youtube-VOS and KITTI-MOTS ? For instance , from the fact that object masks are projections of 3D objects onto 2D frames ? Consider the bicycle example ( row 1 ) at https : //youtube-vos.org/ . In 3D , the position of the bicycle changes smoothly as the cyclist carries it . But in 2D there is a noticeable jump in the center of mass of the bicycle 's mask ( relative say to the body of the rider ) . Could this possibly explain why you found a heavier-tailed Laplace distribution to be a good fit for the transitions in Youtube-VOS and KITTI-MOTS ? 3 ) How do natural transition statistics look like in multi-object datasets ? How do you envision extending your work to tackle those ? 4 ) In 3.3 , you suggest alpha = 1 helps break the rotational symmetry of the ELBO by making axis-aligned representations optimal . Could you substantiate this claim ? Theorem 1 does not immediately suggest an identifiability advantage for alpha = 1 . 5 ) On the Natural Sprites dataset , why is it that discrete transitions give SlowVAE an advantage over PCL ( MCC score 52.6 versus 50.2 and all other metrics ) whereas continuous transitions are disadvantageous ( MCC score 49.1 versus 51.7 ) ? Why work with discrete transitions at all ?", "rating": "7: Good paper, accept", "reply_text": "Dear Reviewer 3 , Thank you for your extensive review and valuable feedback . While we will address your review in full before the end of the rebuttal period , we wanted to address some specific points you raised now to allow time to discuss additional feedback that you might have . Here , we will focus on what you named as your biggest concern : the construction of the datasets . We believe part of the concern may be because we did not completely clarify how we constructed them . You state that `` learning disentangled representations from data which is engineered to show changes in one generative feature at a time seems like cheating \u201d . We fully agree with this , which is what motivated us to extend previous work that used such artificial transitions ( Locatello et al. , 2020 ) by incorporating information from natural video data , namely with Natural Sprites ( NS ) and KITTI Masks ( KM ) . YouTube-VOS is a previously published dataset ( Xu et al.2018 ; Yang et al.2019 ) with 4,883 unique video instances computed from YouTube videos . Figure 1 shows YouTube-VOS transition statistics , which is aggregated across all 4.8k unique object instances . Therefore , our statistics are aggregated across unique objects in a multi-object dataset ( addressing the first part of your question # 3 ) . Note that this applies similarly to KITTI-MOTS . NS is constructed using the position ( x , y ) and scale information measured from YouTube-VOS masks , and thus would exhibit any natural statistical structure present for those factors . You noted the importance of considering the joint dependencies among natural generative factors . We agree that it is valuable to know both the extent of these dependencies and how much they impact our empirical disentanglement performance . To answer this , we constructed modified datasets where time-pairs of factors are shuffled per-factor ( e.g.combining the x transition from one clip with the y transition from a different clip ) . This destroys dependencies between the factors , while maintaining the sparse marginal distributions . In the attached figure ( that we also added to the manuscript ) , we show 2D marginals before ( blue ) and after ( orange ) this shuffling . The additional density on the diagonals in the unshuffled data reveals dependencies between pairs of factors on both datasets . This confirms your intuition that the observed dependency is mismatched from the theoretical assumptions of our model . Per your suggestion , we tested how robust SlowVAE is to such a mismatch by training it on the shuffled data and re-evaluating disentanglement . We found our model performed better when trained with the shuffled data than with the original data , as expected since shuffling rectifies the mismatch ( see results below , mean and s.d.across 10 random seeds ) . However , the gain is limited in size ( it isn \u2019 t statistically significant , independent T-test , p < 0.05 ) , which is in line with our discussion on empirical performance despite theoretical violations . Figure here : https : //ibb.co/R9WrPkw SlowVAE MCC on permuted Natural Sprites ( Continuous ) : 52.9 ( 4.2 ) SlowVAE MCC on unaltered Natural Sprites ( Continuous ) : 49.1 ( 4.0 )"}, {"review_id": "EbIDjBynYJ8-1", "review_text": "Summary : The paper addresses the problem of disentangling the underlying generative factors from data with a particular focus on dynamic natural data . It provides evidence that transitions of objects in natural movies can be characterised by temporally sparse distributions . A novel proof based on a sparse prior on temporally adjacent observations is provided , allowing to recover true latent variables up to permutations and sign flips , and improving the disentangling performance over existing methods . Two new datasets with measured natural dynamics are also proposed to enable evaluation on more realistic scenarios . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Strengths : - The paper addresses the important problem of unsupervised learning of disentangled representations . Overall , it is well written and easy to read . - A new framework of non-linear ICA is introduced , showing evidence to the hypothesis that natural scenes have sparse temporal transitions . - Two new benchmarks of natural and unconstrained data are presented which would enable future works on more realistic scenarios . - The paper provides extensive experiments and comparisons to relevant baselines , including both qualitative analysis and quantitative results using different metrics . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Weaknesses : - The existing datasets present in DisLib are considered unnatural since they assume data is i.i.d and define a prior on the number of factors to be changed . The datasets presented in this work represent incrementally more realistic scenarios where sparse transitions are imposed in addition to data with natural continuous generative factors and data with transitions from unstructured natural videos . In the Laplace transitions dataset , the rate of the Laplace prior \u03bb is sampled from a uniform distribution \u03bb \u223c U ( 1 , 10 ) which may result in changes in many factors ( when \u03bb is small ) . Although this allows to have fair comparison with Locatello et al. , ( 2020 ) , this setting may sometimes result in non-sparse transitions between image pairs which is not aligned with the statistics of natural transitions as discussed throughout the paper . This would not be expected if one does not read Appendix 4 . Hence , it would be good to clarify this particular point in the main paper . - In the Natural Sprites dataset , pairs are produced by only varying the position and scale ( with real transitions extracted from the YouTube measurements ) while color , shape , and orientations are fixed . While fixing the color and shape can be understood to follow natural transitions of objects , it is unclear why the orientation is not varied in this case ? - For the Kitti masks dataset , continuous natural transitions are considered in all underlying factors . Table 2 shows a clear improvement when the temporal distance between sampled frames \u2206t = 5 compared to \u2206t = 1 . What would be the effect of further varying this parameter ? - From Figure 4 , authors raised up an interesting observation for the rotation factor , where SlowVAE shows three sinusoidal oscillations with different frequencies matching the three distinct rotational symmetries of the shapes present in the dataset . However , from the MCC measurements , we can notice that all methods including SlowVAE struggle in disentangling the rotation factor . Here , it would be interesting to further discuss this limitation . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Final update : Authors addressed all my comments in the rebuttal making significant improvements to the revision . I 've increased my score .", "rating": "9: Top 15% of accepted papers, strong accept", "reply_text": "Dear Reviewer 4 , Thank you for your careful review and feedback . We appreciate your praise of the paper being \u201c well written and easy to read \u201d as well as your acknowledgement of the importance of the problem we address . Please find below responses to each of the points you suggested for further improvement . Your question regarding the Delta-t parameter in KITTI Masks was very relevant . The definition of Delta-t in the manuscript was not clear . We have changed the variable name to max ( Delta-frames ) =N , which indicates that all pairs differ by at most N frames . Choosing an upper bound of N was done because the frame rates and sequence lengths in the KITTI dataset were variable . We have added a figure ( https : //ibb.co/hgz0n5T ) to illustrate the relationship between max ( Delta-frames ) and Delta-t , in seconds . We changed all of the remaining figures and tables to be with respect to the mean time between consecutive frames in seconds ( mean Delta-t ) . We ran the experiment you requested for a large range of mean Delta-t values . We found that model performance increased initially with larger temporal separation between data points , then plateaued ( https : //ibb.co/5Wfx5Pn ) . We also tested the temporal sparsity with increasing frame spacing and noticed an increase in alpha , but that it remained sparse ( alpha < 1 , https : //ibb.co/9HgH43p ) . We agree that we did not motivate our design choice for fixing orientation in the Natural Sprites ( NS ) dataset well enough . We have corrected this in the paper . In summary , it is unclear how to accurately estimate object orientation from the masks ( we tried measuring orientation from the principal directions of the mask but encountered a variety of failure cases ) . We also did not want to introduce artificial transitions in the NS dataset . Therefore , we decided to fix the orientation across transitions . The question of proper metrics for disentanglement has been top-of-mind for us and also Reviewer 1 , who noted the failure of MCC to properly address categorical variables like shape . We do agree that it is important to bring awareness to the shortcomings of current metrics . To this end , we extended our discussion on the matter in the revised manuscript . Finally , thanks for pointing out the confusion with the lambda parameter in the LAP dataset . This phrasing was accidentally left in the paper from an earlier draft . In the current work , we use the UNI dataset to directly compare to Locatello et al. , 2020 . This alleviated the need to draw lambda from a uniform distribution , and so all of the experiments in the paper were performed with lambda=1 . The lambda parameter changes the scale , not the distribution itself . In other words , the sparsity is unchanged , as the sparsity is controlled by the shape ( alpha ) , but the scale of movements is changed . We will correct this in the revised manuscript ."}, {"review_id": "EbIDjBynYJ8-2", "review_text": "The paper starts with an observation that temporal transitions in sequences of natural images are sparse , which is supported by data collected from two big datasets ( youtube-vots and kitti-mots ) . This suggests using a sparse prior for temporal transitions of latent variables when modelling naturalistic scenes . The authors then introduce SlowVAE , a model for temporal independent component analysis ( ICA ) , that depends on such a sparsity prior , and prove that latent variables are identifiable under this model up to permutation and sign flips , which , they say , is stronger than any previous result . Additionally , this work introduces a number of datasets of increasing complexity ( and similarity to natural datasets ) for testing disentanglement as well as it performs a large scale and detailed evaluation of the introduced model . The paper is very well written and full of convincing arguments . The related work section ( # 2 ) is very well thought-through and extensively describes links to the relevant literature . The model ( sections 3.1 and 3.3 ) is well described -- I especially liked section 3.4. which describes assumption made by the theory , and how these assumptions can be violated in practice , which is then followed by extensive experimentation showing that the theory can work even when assumptions are validated . It would be of a great benefit to the community if a similar section was present in other papers . I concede that I did not understand the proof sketch in sec 3.2 nor the corresponding figure 2 , and I did not the full proof in the appendix , therefore I can not speak to the correctness of the identifiability claim . I have two remarks about eq.4.1 ) if \\gamma ! = 0 , this is not an ELBO , strictly speaking , which is contrary to what the text suggests . 2 ) We can read that the mean \\mu ( x_ { t-1 } ) is used as a `` single sample '' to approximate the last term of that equation . Strictly speaking , this can lead to biased estimates of that term , specifically when the mapping from z_ { t-1 } to the statistics of p ( z_t | . ) is non-linear . Additionally , in high-dimensional distribution , the mode itself is a very unlikely sample . Why is this ok to take the mean in the context of this equation ? The evaluation is extensive ( two baselines , one of SOTA from ICA and disentangled representations literature , and 14 datasets ) . Figure 4 , which shows plots of true generative factor vs matched latent variable , is superb . It is a really good method of visualising disentanglement -- I agree with the authors that this is a much better way then showing latent traversals . The paper seems to be very good , though I am no expert on ICA . I strongly recommend acceptance . The reason I am not giving a higher score is that the significance to the community seems not that high , but please correct me if I am wrong . Some further questions : 1 ) in sec 3.1. you write `` we assume that the noise [ in g ] is modeled indirectly as a latent variable '' . Does that mean that g is itself a latent-variable model ? 2 ) The appendix includes a `` broader impact '' statement , which strongly suggests that this paper was previously rejected from NeurIPS . May I ask what the main points of criticism were ? Some further remarks : * In the first paragraph of intro you write `` although untrue in the literal sense '' . Why is that ? It seems true to me . * `` this problem '' a few lines below the above is unclear . * Table 2 appears BEFORE Table 1 in the text . This is very confusing ! * It is unclear what `` Natural '' in Table 1 refers to . I assumed that is refers to the introduces `` Natural Sprites '' dataset , but maybe I am wrong ? * A hyphen in latex should be typed as `` '' and there should be no spaces between the hyphen and the surrounding text ; you have one e.g.in the conclusion . UPDATE : T ` he authors ' response addressed all my remarks . I 've increased the score .", "rating": "9: Top 15% of accepted papers, strong accept", "reply_text": "Dear Reviewer 2 , Thank you for your positive review of our submission and valuable feedback . We will address your review in full before the end of the rebuttal period . For now , we would like to offer a direct reply to your comment about the significance of our work . We agree that we did not stress the potential impact to the community enough , which we will rectify in the final version . We have also updated our proof sketch for your consideration and additional feedback . At a high level , disentanglement learning aims to formalize representation learning by directly comparing representations to underlying ground-truth state , as opposed to the indirect evaluation of benchmarking against heuristic downstream tasks ( e.g.object recognition ) . As evidence for its relevance to all of machine learning , we note that at ICML 2019 , the best paper award was given to the study of Locatello et al . ( 2018 ) , which was a large-scale empirical study of disentanglement learning . Additionally , the field of linear and nonlinear ICA has been a core component of unsupervised representation learning for over 30 years , with a bounty of textbooks , highly-cited papers , and applications across a wide variety of engineering and medical fields . Our paper bridges these two important areas of research . As an unbiased argument for our own paper \u2019 s significance , we would like to refer you to comments made by the other reviewers . R1 found our paper \u201c very topical \u201d and \u201c fully agree [ d ] with the authors that temporal information is essential for representation-learning , and hope this paper can help accelerate the field in that direction. \u201d R4 found that our paper \u201c addresses the important problem of unsupervised learning of disentangled representations \u201d and provides \u201c two new benchmarks of natural and unconstrained data\u2026 which would enable future works on more realistic scenarios. \u201d We also note that the reviewers were unanimous in considering the paper \u201c well-written \u201d ( R1 , R2 , R4 ) or \u201c well-presented \u201d ( R3 ) , which we believe will also increase the paper \u2019 s impact in the community . In our own opinion , our work is significant in that it takes a unique approach to solving identifiable disentanglement . Previous work has leveraged temporal information as an additional assumption that leads to identifiability/disentanglement . However , these assumptions do not cover natural video . We found that the observed sparsity in natural transitions is a sufficient assumption for disentanglement , providing the first work , to the best of our knowledge , which proposes a theoretically grounded solution that covers the observed statistics of real videos . Furthermore , we provided a stronger proof that recovers the sources up to permutations and sign flips , as opposed to arbitrary non-linear element-wise transformations . Finally , we provide an empirical contribution by leveraging large-scale natural video databases to provide datasets at the complexity of existing ones , but augmented with natural transitions . Please let us know whether this changes your assessment of the significance of our work . Regarding the clarity of the proof sketch , we modified both the description and the associated figure to give a better intuition . Please see the image in the link below . It is important to us that this section conveys the intuition to a wide audience , so we appreciate your criticism of its clarity . https : //ibb.co/ZYqyhVg"}, {"review_id": "EbIDjBynYJ8-3", "review_text": "# Summary This paper introduces a novel VAE-based model with the aim to improve unsupervised disentangling of latent factors in visual data . This model differs from previous disentangling models in that it takes short ( 2-frame ) videos as input instead of static images . The model is equipped with a Laplace prior over the dynamics of the video to help it align its representation to axes of sparse temporal dynamics . The intuition is that the temporal dynamics of natural visual stimuli vary sparsely according to some choice of factors , and that choice of factors is exactly what \u201c disentangled \u201d should refer to . The authors show that their model achieves better disentangling than previous static-image methods according to a number of metrics . # Pros * The interpretation of disentangling as a basis in which the distribution of temporal dynamics of video is sparse is valuable . Previous approaches to disentangling have been plagued by non-identifiability , and this new interpretation of disentangling is a natural and operational solution . I fully agree with the authors that temporal information is essential for representation-learning , and hope this paper can help accelerate the field in that direction . * The paper is clear and well-written . * The experiments are very thorough in terms of comparisons to previous models and evaluation with previous metrics . * The application of the Mean Correlation Coefficient ( MCC ) as a metric for disentangling is good I think it is simpler and clearer than many existing disentangling metrics . * The latent embedding plots are a nice way to visualize latent representations . While they don \u2019 t show what effects non-matched generative factors have on the latent coordinates , they offer valuable information about the latent embedding that is complementary to the commonly used latent traversals . # Cons My biggest suggestion is to include an ablation study . Aside from PCL ( which isn \u2019 t variational so lives in a different world ) , there are no existing disentangling models on videos to fairly compare the authors \u2019 model to . Consequently , it is very important to perform ablation experiments . More specifically , after reading the paper I have a burning question : How important is the Laplace prior over transitions ? In other words , can the model work with just a KL regularization between the posteriors for consecutive timesteps ? I think it \u2019 s quite possible the answer is \u201c yes \u201d simply having a KL regularization instead of the Laplace prior should disentangle better than static-image VAEs because the diagonal posterior will be pressured to align with the transition dynamics . So I wouldn \u2019 t be surprised if the model does quite well with just a KL instead of the Laplace , and that would be a simpler model with two fewer hyperparameters . So please do this experiment regardless of the outcome , the results will be very valuable for readers considering using your model . Aside from that , I have only a couple minor suggestions : * Figure 2 is a notationally confusing . You use z subscripts to indicate time in the lower part of the figure , but in the top part of the figure z subscripts indicate component index . Maybe make the component index a superscript , or at least make the z in the bottom part of the figure bold so the boldness distinguishes vector from scalar . * Perhaps make a note that the MCC metric doesn \u2019 t work well for discrete latents like shape in dSprites . For example , in Figure 4 the SlowVAE permutes the shape ordering ( e.g.as compared to PCL ) and gets a low MCC score for that , but that low score is a drawback of the metric , not the model . This isn \u2019 t unique to MCC most other metrics ( except MIG ) would fall for this too . But perhaps for discrete latents ( ones where we don \u2019 t care about the ordering of a discrete set of values ) , MCC can take the highest over all permutations . I don \u2019 t think it \u2019 s necessary to do this , but perhaps you can add a sentence that mentions it so readers understand why the shape score is low . # Conclusion : Overall , I recommend this paper to be accepted . It is very topical , since disentangling has recently been receiving increasing attention , and by incorporating temporal cues into disentangling in VAEs this paper could help steer the field in a productive new direction . I only hope the authors do the suggested ablation experiment ( I think practitioners would appreciate those results ) .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer 1 , Thank you for your review and feedback . We very much appreciate your assessment of our work as a `` topical '' , \u201c valuable \u201d , and `` well-written '' paper . We address each of your suggestions for further improvement in turn below . As comparison models , you correctly remarked that PCL isn \u2019 t variational , which makes it somewhat dissimilar . However , we also compare to Ada-GVAE ( Locatello et al.2020 ) which is VAE-based , directly applicable to videos and , therefore , a fair comparison . Nonetheless , we found your recommended ablation experiment extremely valuable . We ran a new experiment with a control model that , as you suggested , replaces the Laplace prior with the posterior of the previous time step . Hence , we minimize KL ( q ( z_t ) |q ( z_ { t-1 } ) ) , i.e.a KL-divergence term between the posterior at time-step t and time-step t-1 . We termed the model Posterior Matching-VAE ( PM-VAE ) ( see these links for results tables : https : //ibb.co/Xx7Z5hH , https : //ibb.co/kDwZQCg ; note mean delta_t=0.05s corresponds to delta_t=1 in the original submission , as well as mean delta_t=0.15s corresponds to delta_t=5 in the original submission ; this update in labelling was made for clarity and will be thoroughly explained in the paper revision , which will be released soon ) . We report several hyperparameter values for PM-VAE and also note that we continue to use the same hyperparameter values for SlowVAE as in all other experiments . Interestingly , this setting is equivalent to a Gaussian transition prior ( with variances in each direction scaled by the posterior of the previous time step ) , i.e.alpha=2 , which , according to our theory , should not be identifiable . Confirming these predictions , we found that the disentanglement scores were overall reduced for the datasets we tested , which include all natural datasets . We will include this result ( for all datasets and metrics ) among our extended results in the appendix , as it covers a valuable control condition . Thank you for pointing out the notational inconsistency in Fig.2.It is important to us that the proof sketch and figure conveys the intuition to a wide audience , so we appreciate your scrutiny . We updated the figure , as well as the associated text . Please follow this link ( https : //ibb.co/ZYqyhVg ) to see the revision . We also added an extended discussion on metrics to the manuscript , which highlights the issue with categorical variables that you mentioned . We note that properly evaluating disentanglement is an ongoing area of research , with notable results from Higgins et al . ( 2019 ) and two submissions to this ICLR submission cycle ( https : //openreview.net/forum ? id=YZ-NHPj6c6O , https : //openreview.net/forum ? id=cbdp6RLk2r7 ) . Again , thank you very much for reviewing our paper and for your valuable suggestions !"}], "0": {"review_id": "EbIDjBynYJ8-0", "review_text": "This paper introduces the SlowVAE to model transitions ( of position , size , etc ) in single-object videos . A Laplace prior conditioned on the latents at the previous step is used to learn the transitions , which the authors argue are naturally sparse . My biggest concern regarding this work is the construction of datasets : the authors effectively \u201c consider pairs of images [ x_ { t-1 } , x_t ] , which differ effectively in only a few factors of variation due to the sparse prior. \u201d While the marginal distributions of factor transitions may no doubt be sparse in natural settings , I would guess the sparsity is not independent across factors . For example : a video where a camera moves sporadically will show the position factors and size of an object changing sparsely but simultaneously . Could you augment Fig 1 and appendix H to show the joint distributions in addition to the marginals ? Moreover , the LAP procedure has the following rejection rule : \u201c if all factors remain constant ( no transition ) , the sample is rejected as the pair would not result in any temporal learning signal. \u201d Surely there needs to be some static pairs if you want to be close to natural videos ? Given KITTI is the only dataset you show results on whose transitions are natural ( albeit not 3D-natural ; see caveat in question 2 below ) , it would be nice to see more evidence how the SlowVAE would generalize and cope in scenarios different from the ones you \u2019 ve constructed . If the LAP procedure indeed samples from marginal transition statistics rather than the joint distributions , I do n't believe the samples would resemble `` natural transitions '' . Learning disentangled representations from data which is engineered to show changes in one generative feature at a time seems like cheating because we usually do n't have easy access to such data ( unless an agent actively interacts with an object ) . Strengths : - Good literature review - Comparison to relevant SOTA models , linking to prior work on disentanglement as well as nonlinear ICA , on a variety of metrics . - Solid experiments and well-presented results Questions : 1 ) Have you tried working with sequences rather than pairs of images ? I assume your ELBO can be readily extended to sequential data . Are there additional challenges in working with sequences ? 2 ) Do you think there 's room for bias in the natural statistics you computed on Youtube-VOS and KITTI-MOTS ? For instance , from the fact that object masks are projections of 3D objects onto 2D frames ? Consider the bicycle example ( row 1 ) at https : //youtube-vos.org/ . In 3D , the position of the bicycle changes smoothly as the cyclist carries it . But in 2D there is a noticeable jump in the center of mass of the bicycle 's mask ( relative say to the body of the rider ) . Could this possibly explain why you found a heavier-tailed Laplace distribution to be a good fit for the transitions in Youtube-VOS and KITTI-MOTS ? 3 ) How do natural transition statistics look like in multi-object datasets ? How do you envision extending your work to tackle those ? 4 ) In 3.3 , you suggest alpha = 1 helps break the rotational symmetry of the ELBO by making axis-aligned representations optimal . Could you substantiate this claim ? Theorem 1 does not immediately suggest an identifiability advantage for alpha = 1 . 5 ) On the Natural Sprites dataset , why is it that discrete transitions give SlowVAE an advantage over PCL ( MCC score 52.6 versus 50.2 and all other metrics ) whereas continuous transitions are disadvantageous ( MCC score 49.1 versus 51.7 ) ? Why work with discrete transitions at all ?", "rating": "7: Good paper, accept", "reply_text": "Dear Reviewer 3 , Thank you for your extensive review and valuable feedback . While we will address your review in full before the end of the rebuttal period , we wanted to address some specific points you raised now to allow time to discuss additional feedback that you might have . Here , we will focus on what you named as your biggest concern : the construction of the datasets . We believe part of the concern may be because we did not completely clarify how we constructed them . You state that `` learning disentangled representations from data which is engineered to show changes in one generative feature at a time seems like cheating \u201d . We fully agree with this , which is what motivated us to extend previous work that used such artificial transitions ( Locatello et al. , 2020 ) by incorporating information from natural video data , namely with Natural Sprites ( NS ) and KITTI Masks ( KM ) . YouTube-VOS is a previously published dataset ( Xu et al.2018 ; Yang et al.2019 ) with 4,883 unique video instances computed from YouTube videos . Figure 1 shows YouTube-VOS transition statistics , which is aggregated across all 4.8k unique object instances . Therefore , our statistics are aggregated across unique objects in a multi-object dataset ( addressing the first part of your question # 3 ) . Note that this applies similarly to KITTI-MOTS . NS is constructed using the position ( x , y ) and scale information measured from YouTube-VOS masks , and thus would exhibit any natural statistical structure present for those factors . You noted the importance of considering the joint dependencies among natural generative factors . We agree that it is valuable to know both the extent of these dependencies and how much they impact our empirical disentanglement performance . To answer this , we constructed modified datasets where time-pairs of factors are shuffled per-factor ( e.g.combining the x transition from one clip with the y transition from a different clip ) . This destroys dependencies between the factors , while maintaining the sparse marginal distributions . In the attached figure ( that we also added to the manuscript ) , we show 2D marginals before ( blue ) and after ( orange ) this shuffling . The additional density on the diagonals in the unshuffled data reveals dependencies between pairs of factors on both datasets . This confirms your intuition that the observed dependency is mismatched from the theoretical assumptions of our model . Per your suggestion , we tested how robust SlowVAE is to such a mismatch by training it on the shuffled data and re-evaluating disentanglement . We found our model performed better when trained with the shuffled data than with the original data , as expected since shuffling rectifies the mismatch ( see results below , mean and s.d.across 10 random seeds ) . However , the gain is limited in size ( it isn \u2019 t statistically significant , independent T-test , p < 0.05 ) , which is in line with our discussion on empirical performance despite theoretical violations . Figure here : https : //ibb.co/R9WrPkw SlowVAE MCC on permuted Natural Sprites ( Continuous ) : 52.9 ( 4.2 ) SlowVAE MCC on unaltered Natural Sprites ( Continuous ) : 49.1 ( 4.0 )"}, "1": {"review_id": "EbIDjBynYJ8-1", "review_text": "Summary : The paper addresses the problem of disentangling the underlying generative factors from data with a particular focus on dynamic natural data . It provides evidence that transitions of objects in natural movies can be characterised by temporally sparse distributions . A novel proof based on a sparse prior on temporally adjacent observations is provided , allowing to recover true latent variables up to permutations and sign flips , and improving the disentangling performance over existing methods . Two new datasets with measured natural dynamics are also proposed to enable evaluation on more realistic scenarios . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Strengths : - The paper addresses the important problem of unsupervised learning of disentangled representations . Overall , it is well written and easy to read . - A new framework of non-linear ICA is introduced , showing evidence to the hypothesis that natural scenes have sparse temporal transitions . - Two new benchmarks of natural and unconstrained data are presented which would enable future works on more realistic scenarios . - The paper provides extensive experiments and comparisons to relevant baselines , including both qualitative analysis and quantitative results using different metrics . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Weaknesses : - The existing datasets present in DisLib are considered unnatural since they assume data is i.i.d and define a prior on the number of factors to be changed . The datasets presented in this work represent incrementally more realistic scenarios where sparse transitions are imposed in addition to data with natural continuous generative factors and data with transitions from unstructured natural videos . In the Laplace transitions dataset , the rate of the Laplace prior \u03bb is sampled from a uniform distribution \u03bb \u223c U ( 1 , 10 ) which may result in changes in many factors ( when \u03bb is small ) . Although this allows to have fair comparison with Locatello et al. , ( 2020 ) , this setting may sometimes result in non-sparse transitions between image pairs which is not aligned with the statistics of natural transitions as discussed throughout the paper . This would not be expected if one does not read Appendix 4 . Hence , it would be good to clarify this particular point in the main paper . - In the Natural Sprites dataset , pairs are produced by only varying the position and scale ( with real transitions extracted from the YouTube measurements ) while color , shape , and orientations are fixed . While fixing the color and shape can be understood to follow natural transitions of objects , it is unclear why the orientation is not varied in this case ? - For the Kitti masks dataset , continuous natural transitions are considered in all underlying factors . Table 2 shows a clear improvement when the temporal distance between sampled frames \u2206t = 5 compared to \u2206t = 1 . What would be the effect of further varying this parameter ? - From Figure 4 , authors raised up an interesting observation for the rotation factor , where SlowVAE shows three sinusoidal oscillations with different frequencies matching the three distinct rotational symmetries of the shapes present in the dataset . However , from the MCC measurements , we can notice that all methods including SlowVAE struggle in disentangling the rotation factor . Here , it would be interesting to further discuss this limitation . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Final update : Authors addressed all my comments in the rebuttal making significant improvements to the revision . I 've increased my score .", "rating": "9: Top 15% of accepted papers, strong accept", "reply_text": "Dear Reviewer 4 , Thank you for your careful review and feedback . We appreciate your praise of the paper being \u201c well written and easy to read \u201d as well as your acknowledgement of the importance of the problem we address . Please find below responses to each of the points you suggested for further improvement . Your question regarding the Delta-t parameter in KITTI Masks was very relevant . The definition of Delta-t in the manuscript was not clear . We have changed the variable name to max ( Delta-frames ) =N , which indicates that all pairs differ by at most N frames . Choosing an upper bound of N was done because the frame rates and sequence lengths in the KITTI dataset were variable . We have added a figure ( https : //ibb.co/hgz0n5T ) to illustrate the relationship between max ( Delta-frames ) and Delta-t , in seconds . We changed all of the remaining figures and tables to be with respect to the mean time between consecutive frames in seconds ( mean Delta-t ) . We ran the experiment you requested for a large range of mean Delta-t values . We found that model performance increased initially with larger temporal separation between data points , then plateaued ( https : //ibb.co/5Wfx5Pn ) . We also tested the temporal sparsity with increasing frame spacing and noticed an increase in alpha , but that it remained sparse ( alpha < 1 , https : //ibb.co/9HgH43p ) . We agree that we did not motivate our design choice for fixing orientation in the Natural Sprites ( NS ) dataset well enough . We have corrected this in the paper . In summary , it is unclear how to accurately estimate object orientation from the masks ( we tried measuring orientation from the principal directions of the mask but encountered a variety of failure cases ) . We also did not want to introduce artificial transitions in the NS dataset . Therefore , we decided to fix the orientation across transitions . The question of proper metrics for disentanglement has been top-of-mind for us and also Reviewer 1 , who noted the failure of MCC to properly address categorical variables like shape . We do agree that it is important to bring awareness to the shortcomings of current metrics . To this end , we extended our discussion on the matter in the revised manuscript . Finally , thanks for pointing out the confusion with the lambda parameter in the LAP dataset . This phrasing was accidentally left in the paper from an earlier draft . In the current work , we use the UNI dataset to directly compare to Locatello et al. , 2020 . This alleviated the need to draw lambda from a uniform distribution , and so all of the experiments in the paper were performed with lambda=1 . The lambda parameter changes the scale , not the distribution itself . In other words , the sparsity is unchanged , as the sparsity is controlled by the shape ( alpha ) , but the scale of movements is changed . We will correct this in the revised manuscript ."}, "2": {"review_id": "EbIDjBynYJ8-2", "review_text": "The paper starts with an observation that temporal transitions in sequences of natural images are sparse , which is supported by data collected from two big datasets ( youtube-vots and kitti-mots ) . This suggests using a sparse prior for temporal transitions of latent variables when modelling naturalistic scenes . The authors then introduce SlowVAE , a model for temporal independent component analysis ( ICA ) , that depends on such a sparsity prior , and prove that latent variables are identifiable under this model up to permutation and sign flips , which , they say , is stronger than any previous result . Additionally , this work introduces a number of datasets of increasing complexity ( and similarity to natural datasets ) for testing disentanglement as well as it performs a large scale and detailed evaluation of the introduced model . The paper is very well written and full of convincing arguments . The related work section ( # 2 ) is very well thought-through and extensively describes links to the relevant literature . The model ( sections 3.1 and 3.3 ) is well described -- I especially liked section 3.4. which describes assumption made by the theory , and how these assumptions can be violated in practice , which is then followed by extensive experimentation showing that the theory can work even when assumptions are validated . It would be of a great benefit to the community if a similar section was present in other papers . I concede that I did not understand the proof sketch in sec 3.2 nor the corresponding figure 2 , and I did not the full proof in the appendix , therefore I can not speak to the correctness of the identifiability claim . I have two remarks about eq.4.1 ) if \\gamma ! = 0 , this is not an ELBO , strictly speaking , which is contrary to what the text suggests . 2 ) We can read that the mean \\mu ( x_ { t-1 } ) is used as a `` single sample '' to approximate the last term of that equation . Strictly speaking , this can lead to biased estimates of that term , specifically when the mapping from z_ { t-1 } to the statistics of p ( z_t | . ) is non-linear . Additionally , in high-dimensional distribution , the mode itself is a very unlikely sample . Why is this ok to take the mean in the context of this equation ? The evaluation is extensive ( two baselines , one of SOTA from ICA and disentangled representations literature , and 14 datasets ) . Figure 4 , which shows plots of true generative factor vs matched latent variable , is superb . It is a really good method of visualising disentanglement -- I agree with the authors that this is a much better way then showing latent traversals . The paper seems to be very good , though I am no expert on ICA . I strongly recommend acceptance . The reason I am not giving a higher score is that the significance to the community seems not that high , but please correct me if I am wrong . Some further questions : 1 ) in sec 3.1. you write `` we assume that the noise [ in g ] is modeled indirectly as a latent variable '' . Does that mean that g is itself a latent-variable model ? 2 ) The appendix includes a `` broader impact '' statement , which strongly suggests that this paper was previously rejected from NeurIPS . May I ask what the main points of criticism were ? Some further remarks : * In the first paragraph of intro you write `` although untrue in the literal sense '' . Why is that ? It seems true to me . * `` this problem '' a few lines below the above is unclear . * Table 2 appears BEFORE Table 1 in the text . This is very confusing ! * It is unclear what `` Natural '' in Table 1 refers to . I assumed that is refers to the introduces `` Natural Sprites '' dataset , but maybe I am wrong ? * A hyphen in latex should be typed as `` '' and there should be no spaces between the hyphen and the surrounding text ; you have one e.g.in the conclusion . UPDATE : T ` he authors ' response addressed all my remarks . I 've increased the score .", "rating": "9: Top 15% of accepted papers, strong accept", "reply_text": "Dear Reviewer 2 , Thank you for your positive review of our submission and valuable feedback . We will address your review in full before the end of the rebuttal period . For now , we would like to offer a direct reply to your comment about the significance of our work . We agree that we did not stress the potential impact to the community enough , which we will rectify in the final version . We have also updated our proof sketch for your consideration and additional feedback . At a high level , disentanglement learning aims to formalize representation learning by directly comparing representations to underlying ground-truth state , as opposed to the indirect evaluation of benchmarking against heuristic downstream tasks ( e.g.object recognition ) . As evidence for its relevance to all of machine learning , we note that at ICML 2019 , the best paper award was given to the study of Locatello et al . ( 2018 ) , which was a large-scale empirical study of disentanglement learning . Additionally , the field of linear and nonlinear ICA has been a core component of unsupervised representation learning for over 30 years , with a bounty of textbooks , highly-cited papers , and applications across a wide variety of engineering and medical fields . Our paper bridges these two important areas of research . As an unbiased argument for our own paper \u2019 s significance , we would like to refer you to comments made by the other reviewers . R1 found our paper \u201c very topical \u201d and \u201c fully agree [ d ] with the authors that temporal information is essential for representation-learning , and hope this paper can help accelerate the field in that direction. \u201d R4 found that our paper \u201c addresses the important problem of unsupervised learning of disentangled representations \u201d and provides \u201c two new benchmarks of natural and unconstrained data\u2026 which would enable future works on more realistic scenarios. \u201d We also note that the reviewers were unanimous in considering the paper \u201c well-written \u201d ( R1 , R2 , R4 ) or \u201c well-presented \u201d ( R3 ) , which we believe will also increase the paper \u2019 s impact in the community . In our own opinion , our work is significant in that it takes a unique approach to solving identifiable disentanglement . Previous work has leveraged temporal information as an additional assumption that leads to identifiability/disentanglement . However , these assumptions do not cover natural video . We found that the observed sparsity in natural transitions is a sufficient assumption for disentanglement , providing the first work , to the best of our knowledge , which proposes a theoretically grounded solution that covers the observed statistics of real videos . Furthermore , we provided a stronger proof that recovers the sources up to permutations and sign flips , as opposed to arbitrary non-linear element-wise transformations . Finally , we provide an empirical contribution by leveraging large-scale natural video databases to provide datasets at the complexity of existing ones , but augmented with natural transitions . Please let us know whether this changes your assessment of the significance of our work . Regarding the clarity of the proof sketch , we modified both the description and the associated figure to give a better intuition . Please see the image in the link below . It is important to us that this section conveys the intuition to a wide audience , so we appreciate your criticism of its clarity . https : //ibb.co/ZYqyhVg"}, "3": {"review_id": "EbIDjBynYJ8-3", "review_text": "# Summary This paper introduces a novel VAE-based model with the aim to improve unsupervised disentangling of latent factors in visual data . This model differs from previous disentangling models in that it takes short ( 2-frame ) videos as input instead of static images . The model is equipped with a Laplace prior over the dynamics of the video to help it align its representation to axes of sparse temporal dynamics . The intuition is that the temporal dynamics of natural visual stimuli vary sparsely according to some choice of factors , and that choice of factors is exactly what \u201c disentangled \u201d should refer to . The authors show that their model achieves better disentangling than previous static-image methods according to a number of metrics . # Pros * The interpretation of disentangling as a basis in which the distribution of temporal dynamics of video is sparse is valuable . Previous approaches to disentangling have been plagued by non-identifiability , and this new interpretation of disentangling is a natural and operational solution . I fully agree with the authors that temporal information is essential for representation-learning , and hope this paper can help accelerate the field in that direction . * The paper is clear and well-written . * The experiments are very thorough in terms of comparisons to previous models and evaluation with previous metrics . * The application of the Mean Correlation Coefficient ( MCC ) as a metric for disentangling is good I think it is simpler and clearer than many existing disentangling metrics . * The latent embedding plots are a nice way to visualize latent representations . While they don \u2019 t show what effects non-matched generative factors have on the latent coordinates , they offer valuable information about the latent embedding that is complementary to the commonly used latent traversals . # Cons My biggest suggestion is to include an ablation study . Aside from PCL ( which isn \u2019 t variational so lives in a different world ) , there are no existing disentangling models on videos to fairly compare the authors \u2019 model to . Consequently , it is very important to perform ablation experiments . More specifically , after reading the paper I have a burning question : How important is the Laplace prior over transitions ? In other words , can the model work with just a KL regularization between the posteriors for consecutive timesteps ? I think it \u2019 s quite possible the answer is \u201c yes \u201d simply having a KL regularization instead of the Laplace prior should disentangle better than static-image VAEs because the diagonal posterior will be pressured to align with the transition dynamics . So I wouldn \u2019 t be surprised if the model does quite well with just a KL instead of the Laplace , and that would be a simpler model with two fewer hyperparameters . So please do this experiment regardless of the outcome , the results will be very valuable for readers considering using your model . Aside from that , I have only a couple minor suggestions : * Figure 2 is a notationally confusing . You use z subscripts to indicate time in the lower part of the figure , but in the top part of the figure z subscripts indicate component index . Maybe make the component index a superscript , or at least make the z in the bottom part of the figure bold so the boldness distinguishes vector from scalar . * Perhaps make a note that the MCC metric doesn \u2019 t work well for discrete latents like shape in dSprites . For example , in Figure 4 the SlowVAE permutes the shape ordering ( e.g.as compared to PCL ) and gets a low MCC score for that , but that low score is a drawback of the metric , not the model . This isn \u2019 t unique to MCC most other metrics ( except MIG ) would fall for this too . But perhaps for discrete latents ( ones where we don \u2019 t care about the ordering of a discrete set of values ) , MCC can take the highest over all permutations . I don \u2019 t think it \u2019 s necessary to do this , but perhaps you can add a sentence that mentions it so readers understand why the shape score is low . # Conclusion : Overall , I recommend this paper to be accepted . It is very topical , since disentangling has recently been receiving increasing attention , and by incorporating temporal cues into disentangling in VAEs this paper could help steer the field in a productive new direction . I only hope the authors do the suggested ablation experiment ( I think practitioners would appreciate those results ) .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer 1 , Thank you for your review and feedback . We very much appreciate your assessment of our work as a `` topical '' , \u201c valuable \u201d , and `` well-written '' paper . We address each of your suggestions for further improvement in turn below . As comparison models , you correctly remarked that PCL isn \u2019 t variational , which makes it somewhat dissimilar . However , we also compare to Ada-GVAE ( Locatello et al.2020 ) which is VAE-based , directly applicable to videos and , therefore , a fair comparison . Nonetheless , we found your recommended ablation experiment extremely valuable . We ran a new experiment with a control model that , as you suggested , replaces the Laplace prior with the posterior of the previous time step . Hence , we minimize KL ( q ( z_t ) |q ( z_ { t-1 } ) ) , i.e.a KL-divergence term between the posterior at time-step t and time-step t-1 . We termed the model Posterior Matching-VAE ( PM-VAE ) ( see these links for results tables : https : //ibb.co/Xx7Z5hH , https : //ibb.co/kDwZQCg ; note mean delta_t=0.05s corresponds to delta_t=1 in the original submission , as well as mean delta_t=0.15s corresponds to delta_t=5 in the original submission ; this update in labelling was made for clarity and will be thoroughly explained in the paper revision , which will be released soon ) . We report several hyperparameter values for PM-VAE and also note that we continue to use the same hyperparameter values for SlowVAE as in all other experiments . Interestingly , this setting is equivalent to a Gaussian transition prior ( with variances in each direction scaled by the posterior of the previous time step ) , i.e.alpha=2 , which , according to our theory , should not be identifiable . Confirming these predictions , we found that the disentanglement scores were overall reduced for the datasets we tested , which include all natural datasets . We will include this result ( for all datasets and metrics ) among our extended results in the appendix , as it covers a valuable control condition . Thank you for pointing out the notational inconsistency in Fig.2.It is important to us that the proof sketch and figure conveys the intuition to a wide audience , so we appreciate your scrutiny . We updated the figure , as well as the associated text . Please follow this link ( https : //ibb.co/ZYqyhVg ) to see the revision . We also added an extended discussion on metrics to the manuscript , which highlights the issue with categorical variables that you mentioned . We note that properly evaluating disentanglement is an ongoing area of research , with notable results from Higgins et al . ( 2019 ) and two submissions to this ICLR submission cycle ( https : //openreview.net/forum ? id=YZ-NHPj6c6O , https : //openreview.net/forum ? id=cbdp6RLk2r7 ) . Again , thank you very much for reviewing our paper and for your valuable suggestions !"}}