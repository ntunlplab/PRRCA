{"year": "2019", "forum": "BJzmzn0ctX", "title": "Scalable Neural Theorem Proving on Knowledge Bases and Natural Language", "decision": "Reject", "meta_review": "This paper focuses on scaling up neural theorem provers, a link prediction system that combines backward chaining with neural embedding of facts, but does not scale to most real-world knowledge bases. The authors introduce a nearest-neighbor search-based method to reduce the time/space complexity, along with an attention mechanism that improves the training. With these extensions, they scale NTP to modern benchmarks for the task, including ones that combine text and knowledge bases, thus providing explanations for such models.\n\nThe reviewers and the AC note the following as the primary concerns of the paper: (1) the novelty of the contributions is somewhat limited, as nearest neighbor search and attention are both well-known strategies, as is embedding text+facts jointly, (2) there are several issues in the evaluation, in particular around analysis of benefits of the proposed work on new datasets. There were a number of other potential weaknesses, such the performance on some benchmarks (Fb15k) and clarity and writing quality of a few sections.\n\nThe authors provided significant revisions to the paper that addressed many of the clarity and evaluation concerns, along with providing sufficient comments to better contextualize some of the concerns. However, the concerns with novelty and analysis of the results still hold. Reviewer 3 mentions that it is still unclear in the discussion why the accuracy of the proposed approach matches/outperforms that of NTP, i.e. why is there not a tradeoff. Reviewer 4 also finds the analysis lacking, and feels that the differences between the proposed work and the single-link approaches, in terms of where each excels, are described in insufficient detail. Reviewer 4 focused more on the simplicity of the text encoding, which restricts the novelty as more sophisticated text embeddings approaches are commonplace.\n\nOverall, the reviewers raised different concerns, and although all of them appreciated the need for this work and the revisions provided by the authors, ultimately feel that the paper did not quite meet the bar.", "reviews": [{"review_id": "BJzmzn0ctX-0", "review_text": "This paper propose an extension of the Neural Theorem Provers (NTP) system that addresses the main issues of this method. The contributions of this paper allow to use this model on real-word datasets by reducing the time and space complexity of the NTP model. Pro: The paper is clear and well written and the contribution is relevant to ICLR. NTP systems by combining the advantages of neural models and symbolic reasoning are a promising research direction. Even though the results presented are lower than previous studies, they present the advantage of being interpretable. Cons: I'm not convinced by the model used to integrate textual mentions. The evaluation proposed in section 6.3 proposes to replace training triples by textual mention in order to evaluate the encoding module. However, it seems to me that, in this particular case, these mentions are very short sentences. This could explained why such a simplistic model that simply average word embeddings is sufficient. I wonder if this would still work for more realistic (and thus longer) sentences. Minor issues: -Page 1: In particular [...] (NLU) and [...] (MR) in particular, ... ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you very much for taking time to help bring our paper to a higher standard with your constructive feedback . > I 'm not convinced by the model used to integrate textual mentions . These mentions are very short sentences . This could explained why such a simplistic model that simply average word embeddings is sufficient . Thank you for pointing this out . We used a very simple reading model for showing that , even with an extremely simple approach , it is possible to integrate textual mentions while effectively improving results . This was a proof-of-concept demonstration on how a scalable end-to-end differentiable reasoning model enables reasoning over text while providing interpretable explanations for any given prediction ( Sect.6.3 and 6.4 ) . It is true that , for Countries , textual mentions tend to be short , but it \u2019 s not the case for FB15k-237 . Another motivation for using a simpler model is that it can perform on par or better than more complex model , thanks to a lower tendency to overfit to training data [ 1 , 2 ] - we will emphasize this in the paper . We leave exploring more elaborate reading models to future work . [ 1 ] Arora et al , 2016 , A simple but tough-to-beat baseline for sentence embeddings [ 2 ] White et al , 2015 , How Well Sentence Embeddings Capture Meaning"}, {"review_id": "BJzmzn0ctX-1", "review_text": "[Summary] This paper scales NTPs by using approximate nearest neighbour search over facts and rules during unification. Additionally, the paper incorporates mentions as additional facts where the predicate is the text that the entities of the mention are contained in. The paper also suggests parameterizing predicates using attention over known predicates. The increments presented are reasonable and justified, but the experimental results, specifically on the larger datasets, warrant further investigation. [Pros] - Reasonable and interesting increments on top of NTP. - Scaling the approach to larger datasets is well motivated. - Utilizing text is an interesting direction for NTP in terms of integrating it with past work on KG completion. [Cons] - Empirical performance on larger datasets needs further investigation. - No ablation study is performed so the effect of incorporating mentions and attention are unclear. - Baseline performance on FB15k-237 seems weak compared to the original papers as well as more recent papers re-examining baselines for KG completion (http://aclweb.org/anthology/W17-2609). Is this due to the d=100 restriction, or were pretrained embeddings not used? Without further explanation, the claim that scores are competitive with SOTA seems unjustified, at least for FB15k-237 since the model performs significantly worse than the baselines which seem to be worse than previously reported. [Comments] - For reproducibility: it is unclear whether evaluation in FB15k-237 is carried out on the KB+Text, KB, or Text portions of the dataset. [Overall] It\u2019s great that NTP was scaled up to handle larger datasets, however further analysis is needed. The argument that performance is given up for interpretability needs more discussion, and the effect of each addition to the system should be discussed as well. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your constructive feedback . It is great to hear that you find this line of work interesting . > Empirical performance on larger datasets needs further investigation . First and foremost , we would like to highlight that the main focus of this paper is not climbing the link prediction leaderboards , but rather pushing NTP ( a promising but until now computationally infeasible model ) into practice by scaling it to large datasets , yielding results comparable with standard Neural Link Predictors , a class of models that was studied for nearly a decade now [ 1 , 2 ] . Unlike Neural Link Predictors , NaNTPs can learn interpretable rules , as well as provide explanations for a given prediction , as we demonstrate in the experimental section . Moreover , they allow incorporating domain knowledge in the form of logic rules . > No ablation study is performed so the effect of incorporating mentions and attention are unclear . Following your advice on in-depth evaluation , we ran additional ablation studies for both the benchmark datasets and the large datasets . Table 6 in the Appendix shows that using attention in NaNTP for learning rule representations yields higher average ranking accuracy and lower variance on Countries S1-3 and Kinship , while yielding comparable results on Nations and UMLS . In Table 7 , we report the ablation results on two larger datasets - WN18 ( 141k facts ) and WN18RR ( 87k facts ) . In the case of WordNet , using attention for learning rules greatly increases the ranking accuracy . For instance , hits @ 10 increases from 83 % to 94 % in the case of WN18 , and from 25 % to 43 % in the case of WN18RR . We hypothesise that this is because the attention has a constraining effect , regularising representations of the rules inside the convex hull of the representations of predicates . Furthermore , Figure 2 shows the ablation study of both the effect of attention and the added textual mentions . Consistently with Table 6 , NaNTP with attention yields higher ranking accuracy and lower variance for Countries S1-3 . As for the effect of reasoning over text , using distinct encoders for predicates and mentions consistently improves the ranking accuracy in comparison of simply using mentions as additional relation types . > Baseline performance on FB15k-237 seems weak compared to the original papers The lower baseline performance difference in neural link prediction baselines is mainly due to limiting the embedding size to 100 ( d=100 ) , and the number of training epochs to 100 . These hyperparameters were used in the original NTP paper [ 3 ] and , for the sake of comparison to the original model , we decided to keep them fixed to the same values . Furthermore , exploring different embedding sizes for NaNTP was prohibitive due to a lack of computation resources . In NaNTPs after the ANNS index construction , the complexity of inference ( and thus learning ) grows logarithmically in the size of the Knowledge Base , and evaluating the ranking of each single test triple requires scoring all its possible corruptions ( i.e.82k triples on WN18 ) : this is a very computationally expensive procedure even for neural link predictors . In the case of FB15k-237 , the experiment also involved the textual mentions proposed in [ 3 ] . We corrected this in the revised version of the paper . [ 1 ] Paccanaro et al. , Learning Distributed Representations of Concepts using Linear Relational Embedding , IEEE Transactions on Knowledge and Data Engineering 2000 [ 2 ] Bordes et al. , Translating Embeddings for Modeling Multi-relational Data , NIPS 2013 [ 3 ] Rocktaschel et al. , End-to-end Differentiable Proving , NIPS 2017 [ 4 ] Toutanova et al. , Representing text for joint embedding of text and knowledge bases , EMNLP 2015"}, {"review_id": "BJzmzn0ctX-2", "review_text": "The authors propose several techniques to speed up the previously proposed Neural Theorem Prover approach. The techniques are evaluated via empirical results on several benchmark datasets. Learning interpretable models is an important topic and the results here are interesting and valuable to the community. However, I feel that the paper in its current form is not yet ready for publication in ICLR, for the following reasons: 1) The authors propose three improvements. The first is a speed-up through nearest neighbor search instead of a brute-force search. This is the most elaborated section out of the three, yet seems like the most trivial -- unless the authors can provide an analytical bound on the loss in ntp score w.r.t the neighborhood size. It is a standard and well-known technique to restrict the search to a neighborhood, widely used in any applications of word embedding (e.g. in Khot et el's Markov Logic Networks for Natural Language Question Answering). The attention mechanism (essentially reducing the model capacity) is also well-known but its effect in this particular framework is not properly elaborated. The same can be said for the use of mentions. 2) The section on experiment results seems a bit rushed -- the authors did mention some last-minute discovery that may affect some of the presented results. The section can be a little hard to parse. In particular, it would be useful for the authors to focus on providing more insights on how the proposed techniques improve the results, and in what ways. 3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning). For a reader that has done so, the section feels redundant. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Many thanks for your constructive criticism - we greatly appreciate your efforts . > The first is a speed-up through nearest neighbor search instead of a brute-force search . This is the most elaborated section out of the three , yet seems like the most trivial The main focus of this work is making inference and learning in NTPs tractable . Previous to this work , training NTPs on large datasets simply unfeasible . Although it seems conceptually simple , we respectfully disagree that it is trivial to make NTPs \u2019 end-to-end differentiable proving mechanism efficient by dynamically exploring only the most promising part of the proof space by means of dynamically pruning the computation graph at construction time , while still retaining computational efficiency superior to the original model . Furthermore , we extensively tested our improvements , and supported them with a large experimental assay . Importantly , this change enabled us to drastically increase the speed ( more than two orders of magnitude in the case of Kinship and UMLS , and many more for larger datasets ) while significantly decreasing the memory footprint of the model . Consequently , this enabled the application of explainable NTPs on large-scale text-enriched data - something that was simply not possible beforehand . This work is fundamentally different from Khot et al. \u2019 s paper . Although they use contextual similarities as a pre-processing step for defining the structure of a Markov Logic Network , they do not make use of embeddings . In contrast , we use ANNS on the embedding representations of facts and rules for identifying the most promising proof paths during the dynamic computation graph construction ( forward pass ) . As for the word embedding search restriction to neighbourhoods , that is never utilised for for building the computation graph , but for the post-hoc analysis . The most related paper is [ 1 ] , where Rae et al.use ANNS for computing a sparse attention distribution over memory entries . Their approach retains the representational power of the original memory networks , whilst training efficiently with very large memories . Similarly , our approach retains the expressiveness and the end-to-end differentiability of NTPs , while scaling to Knowledge Bases with millions of facts . [ 1 ] Rae et al. , Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes , 2016 > [ .. ] unless the authors can provide an analytical bound on the loss in ntp score w.r.t the neighborhood size . It is not trivial to provide an analytical bound on NaNTP : its derivation would depend on the characterisation of the approximation introduced by ANNS ( still an open problem ) , and the greedy proof path selection , which may not yield to a globally optimal solution . NTPs follow a two-step process : i ) given a query , they enumerate all possible proof paths , and ii ) they compute a proof score for each proof path , returning the maximum proof score . After the proof path associated with the highest score is identified , the final score -- - and ts gradient wrt . the model parameters -- - can be computed exactly , since \\nabla_\\theta max ( \\rho_1 , \\ldots , \\rho_n ) = \\nabla_\\theta \\rho_i , where \\rho_i = max ( \\rho_1 , \\ldots , \\rho_n ) . We clarify this in the paper . Exploring all possible proof paths is infeasible for large datasets , hence we propose using ANNS for greedily expanding only the most promising proof paths . This is motivated by observing that the proof score is given by the similarity between a goal and a fact or rule head : the higher the similarity , the higher the proof score . We can also see this problem in relation to the exploration vs exploitation trade-off : in Reinforcement Learning and optimisation it is fairly common to limit exploration to the most promising areas in the search space - instead of uniformly searching in the whole search space - at the risk of missing out high-reward regions . We analyse the cost of such a trade-off in our experiments , finding that our results are on par - or sometimes better than - the original model . Furthermore , we added an analysis on the impact of using ANNS in comparison with exact NNS and random neighbour selection , finding that ANNS is directly comparable with exact NNS but significantly faster . We added this characterisation to Table 8 in the Appendix ."}], "0": {"review_id": "BJzmzn0ctX-0", "review_text": "This paper propose an extension of the Neural Theorem Provers (NTP) system that addresses the main issues of this method. The contributions of this paper allow to use this model on real-word datasets by reducing the time and space complexity of the NTP model. Pro: The paper is clear and well written and the contribution is relevant to ICLR. NTP systems by combining the advantages of neural models and symbolic reasoning are a promising research direction. Even though the results presented are lower than previous studies, they present the advantage of being interpretable. Cons: I'm not convinced by the model used to integrate textual mentions. The evaluation proposed in section 6.3 proposes to replace training triples by textual mention in order to evaluate the encoding module. However, it seems to me that, in this particular case, these mentions are very short sentences. This could explained why such a simplistic model that simply average word embeddings is sufficient. I wonder if this would still work for more realistic (and thus longer) sentences. Minor issues: -Page 1: In particular [...] (NLU) and [...] (MR) in particular, ... ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you very much for taking time to help bring our paper to a higher standard with your constructive feedback . > I 'm not convinced by the model used to integrate textual mentions . These mentions are very short sentences . This could explained why such a simplistic model that simply average word embeddings is sufficient . Thank you for pointing this out . We used a very simple reading model for showing that , even with an extremely simple approach , it is possible to integrate textual mentions while effectively improving results . This was a proof-of-concept demonstration on how a scalable end-to-end differentiable reasoning model enables reasoning over text while providing interpretable explanations for any given prediction ( Sect.6.3 and 6.4 ) . It is true that , for Countries , textual mentions tend to be short , but it \u2019 s not the case for FB15k-237 . Another motivation for using a simpler model is that it can perform on par or better than more complex model , thanks to a lower tendency to overfit to training data [ 1 , 2 ] - we will emphasize this in the paper . We leave exploring more elaborate reading models to future work . [ 1 ] Arora et al , 2016 , A simple but tough-to-beat baseline for sentence embeddings [ 2 ] White et al , 2015 , How Well Sentence Embeddings Capture Meaning"}, "1": {"review_id": "BJzmzn0ctX-1", "review_text": "[Summary] This paper scales NTPs by using approximate nearest neighbour search over facts and rules during unification. Additionally, the paper incorporates mentions as additional facts where the predicate is the text that the entities of the mention are contained in. The paper also suggests parameterizing predicates using attention over known predicates. The increments presented are reasonable and justified, but the experimental results, specifically on the larger datasets, warrant further investigation. [Pros] - Reasonable and interesting increments on top of NTP. - Scaling the approach to larger datasets is well motivated. - Utilizing text is an interesting direction for NTP in terms of integrating it with past work on KG completion. [Cons] - Empirical performance on larger datasets needs further investigation. - No ablation study is performed so the effect of incorporating mentions and attention are unclear. - Baseline performance on FB15k-237 seems weak compared to the original papers as well as more recent papers re-examining baselines for KG completion (http://aclweb.org/anthology/W17-2609). Is this due to the d=100 restriction, or were pretrained embeddings not used? Without further explanation, the claim that scores are competitive with SOTA seems unjustified, at least for FB15k-237 since the model performs significantly worse than the baselines which seem to be worse than previously reported. [Comments] - For reproducibility: it is unclear whether evaluation in FB15k-237 is carried out on the KB+Text, KB, or Text portions of the dataset. [Overall] It\u2019s great that NTP was scaled up to handle larger datasets, however further analysis is needed. The argument that performance is given up for interpretability needs more discussion, and the effect of each addition to the system should be discussed as well. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your constructive feedback . It is great to hear that you find this line of work interesting . > Empirical performance on larger datasets needs further investigation . First and foremost , we would like to highlight that the main focus of this paper is not climbing the link prediction leaderboards , but rather pushing NTP ( a promising but until now computationally infeasible model ) into practice by scaling it to large datasets , yielding results comparable with standard Neural Link Predictors , a class of models that was studied for nearly a decade now [ 1 , 2 ] . Unlike Neural Link Predictors , NaNTPs can learn interpretable rules , as well as provide explanations for a given prediction , as we demonstrate in the experimental section . Moreover , they allow incorporating domain knowledge in the form of logic rules . > No ablation study is performed so the effect of incorporating mentions and attention are unclear . Following your advice on in-depth evaluation , we ran additional ablation studies for both the benchmark datasets and the large datasets . Table 6 in the Appendix shows that using attention in NaNTP for learning rule representations yields higher average ranking accuracy and lower variance on Countries S1-3 and Kinship , while yielding comparable results on Nations and UMLS . In Table 7 , we report the ablation results on two larger datasets - WN18 ( 141k facts ) and WN18RR ( 87k facts ) . In the case of WordNet , using attention for learning rules greatly increases the ranking accuracy . For instance , hits @ 10 increases from 83 % to 94 % in the case of WN18 , and from 25 % to 43 % in the case of WN18RR . We hypothesise that this is because the attention has a constraining effect , regularising representations of the rules inside the convex hull of the representations of predicates . Furthermore , Figure 2 shows the ablation study of both the effect of attention and the added textual mentions . Consistently with Table 6 , NaNTP with attention yields higher ranking accuracy and lower variance for Countries S1-3 . As for the effect of reasoning over text , using distinct encoders for predicates and mentions consistently improves the ranking accuracy in comparison of simply using mentions as additional relation types . > Baseline performance on FB15k-237 seems weak compared to the original papers The lower baseline performance difference in neural link prediction baselines is mainly due to limiting the embedding size to 100 ( d=100 ) , and the number of training epochs to 100 . These hyperparameters were used in the original NTP paper [ 3 ] and , for the sake of comparison to the original model , we decided to keep them fixed to the same values . Furthermore , exploring different embedding sizes for NaNTP was prohibitive due to a lack of computation resources . In NaNTPs after the ANNS index construction , the complexity of inference ( and thus learning ) grows logarithmically in the size of the Knowledge Base , and evaluating the ranking of each single test triple requires scoring all its possible corruptions ( i.e.82k triples on WN18 ) : this is a very computationally expensive procedure even for neural link predictors . In the case of FB15k-237 , the experiment also involved the textual mentions proposed in [ 3 ] . We corrected this in the revised version of the paper . [ 1 ] Paccanaro et al. , Learning Distributed Representations of Concepts using Linear Relational Embedding , IEEE Transactions on Knowledge and Data Engineering 2000 [ 2 ] Bordes et al. , Translating Embeddings for Modeling Multi-relational Data , NIPS 2013 [ 3 ] Rocktaschel et al. , End-to-end Differentiable Proving , NIPS 2017 [ 4 ] Toutanova et al. , Representing text for joint embedding of text and knowledge bases , EMNLP 2015"}, "2": {"review_id": "BJzmzn0ctX-2", "review_text": "The authors propose several techniques to speed up the previously proposed Neural Theorem Prover approach. The techniques are evaluated via empirical results on several benchmark datasets. Learning interpretable models is an important topic and the results here are interesting and valuable to the community. However, I feel that the paper in its current form is not yet ready for publication in ICLR, for the following reasons: 1) The authors propose three improvements. The first is a speed-up through nearest neighbor search instead of a brute-force search. This is the most elaborated section out of the three, yet seems like the most trivial -- unless the authors can provide an analytical bound on the loss in ntp score w.r.t the neighborhood size. It is a standard and well-known technique to restrict the search to a neighborhood, widely used in any applications of word embedding (e.g. in Khot et el's Markov Logic Networks for Natural Language Question Answering). The attention mechanism (essentially reducing the model capacity) is also well-known but its effect in this particular framework is not properly elaborated. The same can be said for the use of mentions. 2) The section on experiment results seems a bit rushed -- the authors did mention some last-minute discovery that may affect some of the presented results. The section can be a little hard to parse. In particular, it would be useful for the authors to focus on providing more insights on how the proposed techniques improve the results, and in what ways. 3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning). For a reader that has done so, the section feels redundant. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Many thanks for your constructive criticism - we greatly appreciate your efforts . > The first is a speed-up through nearest neighbor search instead of a brute-force search . This is the most elaborated section out of the three , yet seems like the most trivial The main focus of this work is making inference and learning in NTPs tractable . Previous to this work , training NTPs on large datasets simply unfeasible . Although it seems conceptually simple , we respectfully disagree that it is trivial to make NTPs \u2019 end-to-end differentiable proving mechanism efficient by dynamically exploring only the most promising part of the proof space by means of dynamically pruning the computation graph at construction time , while still retaining computational efficiency superior to the original model . Furthermore , we extensively tested our improvements , and supported them with a large experimental assay . Importantly , this change enabled us to drastically increase the speed ( more than two orders of magnitude in the case of Kinship and UMLS , and many more for larger datasets ) while significantly decreasing the memory footprint of the model . Consequently , this enabled the application of explainable NTPs on large-scale text-enriched data - something that was simply not possible beforehand . This work is fundamentally different from Khot et al. \u2019 s paper . Although they use contextual similarities as a pre-processing step for defining the structure of a Markov Logic Network , they do not make use of embeddings . In contrast , we use ANNS on the embedding representations of facts and rules for identifying the most promising proof paths during the dynamic computation graph construction ( forward pass ) . As for the word embedding search restriction to neighbourhoods , that is never utilised for for building the computation graph , but for the post-hoc analysis . The most related paper is [ 1 ] , where Rae et al.use ANNS for computing a sparse attention distribution over memory entries . Their approach retains the representational power of the original memory networks , whilst training efficiently with very large memories . Similarly , our approach retains the expressiveness and the end-to-end differentiability of NTPs , while scaling to Knowledge Bases with millions of facts . [ 1 ] Rae et al. , Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes , 2016 > [ .. ] unless the authors can provide an analytical bound on the loss in ntp score w.r.t the neighborhood size . It is not trivial to provide an analytical bound on NaNTP : its derivation would depend on the characterisation of the approximation introduced by ANNS ( still an open problem ) , and the greedy proof path selection , which may not yield to a globally optimal solution . NTPs follow a two-step process : i ) given a query , they enumerate all possible proof paths , and ii ) they compute a proof score for each proof path , returning the maximum proof score . After the proof path associated with the highest score is identified , the final score -- - and ts gradient wrt . the model parameters -- - can be computed exactly , since \\nabla_\\theta max ( \\rho_1 , \\ldots , \\rho_n ) = \\nabla_\\theta \\rho_i , where \\rho_i = max ( \\rho_1 , \\ldots , \\rho_n ) . We clarify this in the paper . Exploring all possible proof paths is infeasible for large datasets , hence we propose using ANNS for greedily expanding only the most promising proof paths . This is motivated by observing that the proof score is given by the similarity between a goal and a fact or rule head : the higher the similarity , the higher the proof score . We can also see this problem in relation to the exploration vs exploitation trade-off : in Reinforcement Learning and optimisation it is fairly common to limit exploration to the most promising areas in the search space - instead of uniformly searching in the whole search space - at the risk of missing out high-reward regions . We analyse the cost of such a trade-off in our experiments , finding that our results are on par - or sometimes better than - the original model . Furthermore , we added an analysis on the impact of using ANNS in comparison with exact NNS and random neighbour selection , finding that ANNS is directly comparable with exact NNS but significantly faster . We added this characterisation to Table 8 in the Appendix ."}}