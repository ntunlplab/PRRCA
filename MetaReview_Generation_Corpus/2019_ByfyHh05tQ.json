{"year": "2019", "forum": "ByfyHh05tQ", "title": "Learning to Design RNA", "decision": "Accept (Poster)", "meta_review": "After a healthy discussion between reviewers and authors, the reviewers' consensus is to recommend acceptance to ICLR. The authors thoroughly addressed reviewer concerns, and all reviewers noted the quality of the paper, methodological innovations and SotA results.", "reviews": [{"review_id": "ByfyHh05tQ-0", "review_text": "General comment ============== The authors used policy gradient optimization for generating RNA sequences that fold into a target secondary structure, reporting clear accuracy and runtime improvements over the previous state-of-the-art. The authors used BOHR for optimizing hyper-parameters and present a new dataset for evaluating RNA design methods. The paper is well motivated and mostly clearly written. However, the methodological contributions are limited and I have some important concerns about their evaluation. Overall, I feel it\u2019s a good paper for an ICLR workshop or biological journal if the authors address the outstanding comments. Major comments ============= 1. The methodological contributions are limited. The authors used existing approaches (policy gradient optimization and BOHR for hyperparameter optimization) but do not report new methods, e.g. for sequence modeling. Performing hyper-parameter optimization is in my eyes not novel, but common practice in the field. It would me more informative if the authors compared reinforcement learning to other approaches for (conditional) sequence generations, e.g. RNNs, autoregressive models, VAEs, or GANs, which have been previously reported for biological sequence generation (e.g. http://arxiv.org/abs/1804.01694). 2. Did the authors split all three datasets (Eterna, Rfam-Taneda, Rfam-learn-test) into train, eval, and test set, trained their method on the training set, optimized hyper-parameters on the eval set, and measured generalization and runtime on the test set? This is not described clearly enough in section 5. I suggest to summarize the number of sequences for each dataset and split in a table. 3. Did the authors also optimize the most important hyperparameters of RL-LS and other methods? Otherwise it is unclear if the performance gain is due to hyperparameter optimization or the method itself. 4. The time measurement (x-axis figure 3) is unclear. Is it the time that methods were given to solve a particular target structure and does figure 3 show the average number of solved structures in the test for a the time shown on the x-axis? 5. Were all methods compared on the same hardware (section 5; 20 cores; Broadwell E5-2630v4 2.2 GHz CPUs) and can they be parallelized over multiple CPU or GPU cores? This is essential for a fair runtime comparison. 6. The term \u2018run\u2019 (\u201cunreliable outcomes in single runs\u201d, section 4) is unclear. Is it a single sample from the model (one rollout), a particular hyperparameter configuration, or training the model once for a single target structure? This must be clarified for understanding the evaluation. 7. How does the accuracy and runtime or LEARNA scale depending on the sequence (structure) length? 8. How sensitive is the model performance depending on the context size k for representing the current state? Did the authors try to encode the entire target structure with, e.g. recurrent models, instead of using a window centered on the current position? 9. The authors should more clearly describe the local optimization step (section 3.1; reward). Were all nucleotides that differ mutated independently, or enumerated exhaustively? The latter would have a high runtime of O(3^d), where d is the number of nucleotides that differ. When do the authors start with the local optimization? Minor comments ============= 10. The authors should replace \u2018450x\u2019 faster in the abstract by \u2018clearly\u2019 faster since the evaluation does not show that LEARNA is 450x faster than all other methods. 11. Does \u201cAt its most basic form\u201d (introduction) mean that alternative RNA nucleotides exist? If so, this should be cited. 12. The authors should more clearly motive in the introduction why they created a new dataset. 13. The authors should mention in section 2.1 that the dot-bracket notation is not the only notation for representing RNA structures (https://www.tbi.univie.ac.at/RNA/ViennaRNA/doc/html/rna_structure_notations.html). 14. The authors should define the hamming distance (section 2.1). Do other distance metrics exist? 15. For the Traveling Salesman Problem (section 2.2) should the reward be the *negative* tour length? 16. The authors should more clearly describe the embedding layer (section 4). Are nucleotides one-hot encoded or represented as integers (0, 1 for \u2018(\u2018 and \u2018.\u2019)?", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "\u201c 8.How sensitive is the model performance depending on the context size \\kappa for representing the current state ? Did the authors try to encode the entire target structure with , e.g.recurrent models , instead of using a window centered on the current position ? \u201d -- > Thanks for the suggestion . An RNN is already included in our search space , and was indeed selected by our joint architecture search and hyperparameter optimization . We have not yet experimented with encoding the entire target structure with an RNN , since having to backpropagate through that RNN at each time step of our agent would lead to a substantial increase of computational cost , be harder to train and increase the number of hyperparameters . Having said that , we do think this is a good idea if it can be made computationally efficient , e.g. , by learning the embedding offline ( although the training signal for that would need to be defined first ) ; since this is not straightforward we leave it to future work . In terms of the importance of the context size , our new hyperparameter importance in Appendix I indicates that the context size ( state space radius ) \\kappa does not appear to be very important . \u201c 9.The authors should more clearly describe the local optimization step ( section 3.1 ; reward ) . Were all nucleotides that differ mutated independently , or enumerated exhaustively ? The latter would have a high runtime of O ( 3^d ) , where d is the number of nucleotides that differ . When do the authors start with the local optimization ? \u201d -- > We agree that the local improvement step should be described more clearly : we revised the reward paragraph and included pseudocode for computing the reward using the local improvement step ( Appendix A ) . It works as follows : After the policy rollout we fold the candidate solution and compare it to the target structure , if less than \\xi sites differ we perform this local improvement step in order to compute the reward . The value of \\xi is not part of the hyperparameter optimization and based on the runtime costs and preliminary experiments we set xi=5 , i.e. , we used the local improvement step if the number of differing sites was at most 4 . Keeping this number low was indeed important because of the computational complexity mentioned by the reviewer ( it \u2019 s actually O ( 4^d ) , with d < =4 ) . \u201c 10.The authors should replace \u2018 450x \u2019 faster in the abstract by \u2018 clearly \u2019 faster since the evaluation does not show that LEARNA is 450x faster than all other methods. \u201d -- > Thank you for the comment , we changed the abstract to say that our approach achieves new state-of-the-art performance on all benchmarks while also being orders of magnitudes faster in reaching the previous state-of-the-art performance . We note that these speedups ( including the 450x one on the Eterna100 benchmark , Figure 3 ( top ) ) can clearly be seen in the evaluation plots . \u201c 11.Does \u201c At its most basic form \u201d ( introduction ) mean that alternative RNA nucleotides exist ? If so , this should be cited. \u201d -- > Thanks for this question . With \u201c At its most basic form \u201d we refer to the most basic structural form of RNA , which is a sequence of nucleotides . We have since clarified the phrasing to \u201c At its most basic structural form \u201d . \u201c 13.The authors should mention in section 2.1 that the dot-bracket notation is not the only notation for representing RNA structures ( https : //www.tbi.univie.ac.at/RNA/ViennaRNA/doc/html/rna_structure_notations.html ) . \u201d and \u201c 14a . The authors should define the hamming distance ( section 2.1 ) . \u201d -- > We have included references , thank you for your comments . \u201c 14b.Do other distance metrics [ than the hamming distance ] exist ? \u201d -- > While not formally metrics , we have experimented with the paired-unpaired-ratio and derivatives of the hamming distance . While also not a metric , the GC-content ( which is the ratio of G and C nucleotides to the U and A nucleotides ) has been used in the RNA Design literature ( e.g.by antaRNA ) as an additional objective . \u201c 15.For the Traveling Salesman Problem ( section 2.2 ) should the reward be the * negative * tour length ? \u201d -- > You are of course right , thank you for reading our paper carefully and bringing this to our attention ; we fixed it . \u201c 16.The authors should more clearly describe the embedding layer ( section 4 ) . Are nucleotides one-hot encoded or represented as integers ( 0 , 1 for \u2018 ( \u2018 and \u2018 . \u2019 ) ? \u201d -- > Thank you for this comment ; we agree and have included a clearer description . For representing nucleotides , our automated reinforcement learning approach includes the choice between : 1 ) a binary encoding differentiating between paired and unpaired sites , and 2 ) a learned embedding layer whose dimension is a hyperparameter ( only active if the learned embedding is selected ) . Thanks again for all your comments ! If we cleared up some of your concerns , we would kindly ask you to update your assessment ."}, {"review_id": "ByfyHh05tQ-1", "review_text": "I'm happy with the revisions the authors have made, as I find that they call out the novel contributions a bit more explicitly. Specifically I see some novel work in the area of simultaneous multi-task/meta-RL and black box optimization of the policy net architectures. I don't think calling this NAS is justified; calling it bayesopt or black box opt is fair. NAS uses a neural net to propose experiments over structured graphs of computation nodes. This work appears to be simpler hyperparameter optimization. ==== Quality: The work is well done, and the experiments are reasonable/competitive, showcasing other recent work and outperforming. Clarity: I thought the presentation was tolerable. I was a bit confused by Table 1 until reading the prose at the bottom of page 7 indicated Table 1 is presenting percentages, not integer quantities. The local improvement step is not very clearly explained. Are all combos tried across all mismatched positions, or do we try each mismatched position independently holding the others to their predicted values? What value of zeta did you end up using? It seems like this is essential to getting good performance. It is completely unclear to me what the 'restart option' does. Originality: Using RL in this specific application setting seems relatively new (though also explored by RL-LS in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6029810/). On the other hand, the approach used doesn't seem to be substantially different than anything else typically used for policy gradient RL. The meta-learning approach is interesting, though again not too different from multi-task approaches (though these are perhaps less common in RL than in general deep learning). Significance: Likely to be of practical utility in the inverse design space, specifically therapeutics, CRISPR guide RNA design, etc. Interesting to ICLR as an application area but probably not much theory/methods interest. On balance I lean slightly against accepting and think this is a better fit to either a workshop or a more domain-specific venue (MLHC http://mucmd.org/ for example).", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your helpful comments and questions . Thanks also for your positive feedback on our work in general , our experiments , the significance of our approach for therapeutics and other practical use cases and for characterizing our work as interesting to ICLR as an application area . We would like to comment on your suggestions , comments and questions in the following . \u201c 1.I was a bit confused by Table 1 until reading the prose at the bottom of page 7 indicated Table 1 is presenting percentages , not integer quantities. \u201d -- > Reviewing Table 1 , we agree that it could be confusing -- its caption did mention that all entries represent percentages and not total values , but this was unnecessarily indirect , and we now reworked the tables to include a percentage symbol to make it clearer . \u201c 2.The local improvement step is not very clearly explained . Are all combos tried across all mismatched positions , or do we try each mismatched position independently holding the others to their predicted values ? What value of \\xi did you end up using ? It seems like this is essential to getting good performance. \u201d -- > Thanks , we agree that the local improvement step should be described more clearly and that it is an important part of our approach ( as the empirical evidence in our ablation study suggests ) . We have since reworked the corresponding paragraph and included pseudocode ( Appendix A ) . It works as follows : we exhaustively try all possible nucleotide assignments for the mismatched positions which takes at most 4^|differing_sites| additional folds . The value of \\xi we used was 5 , i.e. , we used the local improvement step if the number of differing sites was at most 4 . This was set early on based on runtime considerations and preliminary experiments and was not part of our hyperparameter optimization ; thank you for the detailed reading of our paper and pointing out this missing value , we have added it now . \u201c 3.It is completely unclear to me what the 'restart option ' does. \u201d -- > Thanks for pointing out this missing information . Since RL algorithms are prone to getting stuck in local minima , we decided to employ occasional restarts ( i.e. , reinitialization ) in our strategies . We now describe this in the revised version in Section 5 . For LEARNA and for Meta-LEARNA-Adapt , this makes a difference , whereas for Meta-LEARNA it does not since Meta-LEARNA is directly sampling from the model without updating it ( which is equivalent to restarting at each step ) \u201c 4 . Using RL in this specific application setting seems relatively new ( though also explored by RL-LS in https : //www.ncbi.nlm.nih.gov/pmc/articles/PMC6029810/ ) . \u201d -- > Thanks for this comment ! Indeed , the reinforcement learning guided local search ( RL-LS ) was developed in parallel and independently from LEARNA ( as mentioned in our discussion on RL-LS in Section 2.2 of our initial submission ; now discussed in Section 3 ) . However , the two approaches differ a lot : although both approaches employ RL to RNA Design , Eastman et al.follows the common approach of using a local search strategy for solving the RNA Design problem , while we try to tackle the problem with a generative model . \u201c 5.On the other hand , the approach used does n't seem to be substantially different than anything else typically used for policy gradient RL . The meta-learning approach is interesting , though again not too different from multi-task approaches ( though these are perhaps less common in RL than in general deep learning ) . \u201d -- > We agree that the policy gradient approach we use is standard , but that using meta-learning in this context is already less common . We would also like to repeat the point concerning novelty of our joint optimization we made in the general reply to all reviewers . We copied this here for convenience : < \u201c To the best of our knowledge , our paper is the first case study on the joint optimization of the architecture of the policy network ( including both recurrent connections and convolutions in a single search space ) , the state representation , and the hyperparameters of an RL algorithm . In fact , we are not even aware of * any * other previous work on neural architecture search ( NAS ) for RL . Also , while there is of course a lot of work on NAS for CNNs and NAS for RNNs individually , we are not aware of any other previous NAS work that tackles a search space including both convolutions and recurrent units at the same time ( i.e. , with NAS choosing the best combination of the two ) . Finally , we are not aware of any previous work on NAS for meta-learning ( other than learning a cell architecture and transferring that cell to a different dataset ) . We do believe that these are clear points in favor of our paper \u2019 s novelty , and we should have made these clearer in the submitted version of our paper ; we \u2019 ve fixed this now in Section 5 and in the introduction. \u201d > Thanks again for your comments ! If we cleared up some of your concerns , we would kindly ask you to update your assessment ."}, {"review_id": "ByfyHh05tQ-2", "review_text": "This work tackles the difficult RNA design problem, i.e. that of finding a RNA primary sequence that is going to fold into a secondary/tertiary structure able to perform a desired biological function. More specifically, it used Reinforcement Learning (RL) to find the best sequence that will fold into a target secondary structure, using the Zuker algorithm and designing a new primary sequence 'from scratch'. A new benchmark data set is also introduced in the paper along . Questions/remarks: - I struggle with your notations as soon as section 2.1. What is the star (*) superscript for? Was expecting the length of the RNA sequence instead. Same on p4, when introducing the notation of your decision process $ D_w $, explicitly introduce all the ingredients. - in Equation (2) on p4, maybe clarify the notation with '.', '(' and ')' for example as the reader could really struggle. - I didn't really understand the message in Section 4, not being an expert in the field. Could you clarify your contribution here? - your 'Ablation study' in Section 5.2; does it correspond to true uncertainty/noise that could be observed in real data? - why a new benchmark data set, when there exist good ones to compare your method to, e.g. in competitions like CASP for proteins? - do you make your implementation available? - quite like the clarification of the relationship of your work to that of Eastman et al. 2018. Could you also include discussions to other papers, e.g. Chuai et al. 2018 Genome Biol and Shi et al. 2018 SentRNA on arXiv? Altogether the paper reads well, seems to have adequate references, motivates and proposes 3 variations of a new algorithm for a difficult learning problem. Not being an expert in the field, I just can't judge about the novelty of the appraoch.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the suggested improvements , the insightful comments and questions ! Thanks also for the positive feedback on the text of the paper , references and motivation . In the following we provide detailed replies : \u201c 1 . What is the star ( * ) superscript for ? Was expecting the length of the RNA sequence instead. \u201d -- > Thank you for pointing out this undefined and potentially confusing use of notation . The Kleene Operator ( * ) applied to a set M yields a set of all finite-length sequences based on M , and we used it since RNA Structures have variable length . But we do agree that this can be confusing and made changes to talk about a specific structure w and then use N^|w| as you suggested . \u201c 2.Same on p4 , when introducing the notation of your decision process $ D_w $ , explicitly introduce all the ingredients. \u201d -- > We agree with you and revised the definition of the undiscounted decision process . We now explicitly name the components of the quadruple D_w and also refer to the specifics in the paragraphs following the definition of D_w . \u201c 3.in Equation ( 2 ) on p4 , maybe clarify the notation with ' . ' , ' ( ' and ' ) ' for example as the reader could really struggle. \u201d -- > We have looked at this again and changed the equation , making it easier to parse for the reader . We have also included a verbatim \u201c dot \u201d and \u201c opening bracket \u201d to not confuse the reader by the notation . \u201c 4.I did n't really understand the message in Section 4 , not being an expert in the field . Could you clarify your contribution here ? \u201d -- > Thanks for asking about this ! As detailed in our general reply to all reviewers , this section breaks novel ground concerning the joint optimization of neural architectures and hyperparameters , joint search over combinations of recurrent and convolutional layers in the same search space , neural architecture search for RL , and neural architecture search for meta-learning . In the interest of brevity , we refer to the detailed reply to all reviewers above . \u201c 5.your 'Ablation study ' in Section 5.2 ; does it correspond to true uncertainty/noise that could be observed in real data ? \u201d -- > In our ablation study , we disable one functional component of our approach at a time in order to study its influence ; incorporating ablations in empirically evaluated work is important to find out whether all proposed components are necessary and contribute to the final performance . Our ablation study is performed on the test split of our introduced dataset , which as we point out in the heading of Section 5 of our initial submission , has been generated from sequences observed in living organisms as listed in the Rfam 13.0 database ; it is not used to optimize hyperparameters but is a post hoc evaluation . \u201c 6.why a new benchmark data set , when there exist good ones to compare your method to , e.g.in competitions like CASP for proteins ? \u201d -- > We report our results on two widely used benchmarks which were also used in the work we compare to but unfortunately only provide test sets ( no training/validation/test split ) . To the best of our knowledge , we introduce the first benchmark with an explicit training/validation/test split . The reviewer is right in that there exist other and good data sources , but to the best of our knowledge not in the form of competitions . To mention two databases by name : * the STRAND database ( http : //www.rnasoft.ca/strand/ ) that currently holds 4666 known RNA secondary structures * the FRABASE 2.0 database ( https : //bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-231 ) with 2753 entries of fragments of secondary structures Both databases have not been used by the publications we compare to and can not satisfy the size and sequence diversity requirements for our meta-learning approach and future research ( especially for methods needing a large training set ) . The Rfam 13.0 database we use here for generating our new training- , validation- and test set is large enough to yield three distinct datasets of meaningful sizes and diversity . \u201c 7.do you make your implementation available ? \u201d -- > Thanks for the question , indeed , we strongly believe in sharing code ( as well as data ) to reproduce scientific findings . To stand by this opinion , we had included a note in the conclusion of our initial submission that we will make all of our code and data available upon acceptance of our paper . \u201c 8.quite like the clarification of the relationship of your work to that of Eastman et al.2018.Could you also include discussions to other papers , e.g.Chuai et al.2018 Genome Biol and Shi et al.2018 SentRNA on arXiv \u201d -- > Thanks for the positive feedback regarding our discussion of the relationship of our work to that of Eastman et al.2018 , and for bringing the related work to our attention . We included discussions in our related work section . Thanks again for all your comments ! If we cleared up some of your concerns , we would kindly ask you to update your assessment ."}], "0": {"review_id": "ByfyHh05tQ-0", "review_text": "General comment ============== The authors used policy gradient optimization for generating RNA sequences that fold into a target secondary structure, reporting clear accuracy and runtime improvements over the previous state-of-the-art. The authors used BOHR for optimizing hyper-parameters and present a new dataset for evaluating RNA design methods. The paper is well motivated and mostly clearly written. However, the methodological contributions are limited and I have some important concerns about their evaluation. Overall, I feel it\u2019s a good paper for an ICLR workshop or biological journal if the authors address the outstanding comments. Major comments ============= 1. The methodological contributions are limited. The authors used existing approaches (policy gradient optimization and BOHR for hyperparameter optimization) but do not report new methods, e.g. for sequence modeling. Performing hyper-parameter optimization is in my eyes not novel, but common practice in the field. It would me more informative if the authors compared reinforcement learning to other approaches for (conditional) sequence generations, e.g. RNNs, autoregressive models, VAEs, or GANs, which have been previously reported for biological sequence generation (e.g. http://arxiv.org/abs/1804.01694). 2. Did the authors split all three datasets (Eterna, Rfam-Taneda, Rfam-learn-test) into train, eval, and test set, trained their method on the training set, optimized hyper-parameters on the eval set, and measured generalization and runtime on the test set? This is not described clearly enough in section 5. I suggest to summarize the number of sequences for each dataset and split in a table. 3. Did the authors also optimize the most important hyperparameters of RL-LS and other methods? Otherwise it is unclear if the performance gain is due to hyperparameter optimization or the method itself. 4. The time measurement (x-axis figure 3) is unclear. Is it the time that methods were given to solve a particular target structure and does figure 3 show the average number of solved structures in the test for a the time shown on the x-axis? 5. Were all methods compared on the same hardware (section 5; 20 cores; Broadwell E5-2630v4 2.2 GHz CPUs) and can they be parallelized over multiple CPU or GPU cores? This is essential for a fair runtime comparison. 6. The term \u2018run\u2019 (\u201cunreliable outcomes in single runs\u201d, section 4) is unclear. Is it a single sample from the model (one rollout), a particular hyperparameter configuration, or training the model once for a single target structure? This must be clarified for understanding the evaluation. 7. How does the accuracy and runtime or LEARNA scale depending on the sequence (structure) length? 8. How sensitive is the model performance depending on the context size k for representing the current state? Did the authors try to encode the entire target structure with, e.g. recurrent models, instead of using a window centered on the current position? 9. The authors should more clearly describe the local optimization step (section 3.1; reward). Were all nucleotides that differ mutated independently, or enumerated exhaustively? The latter would have a high runtime of O(3^d), where d is the number of nucleotides that differ. When do the authors start with the local optimization? Minor comments ============= 10. The authors should replace \u2018450x\u2019 faster in the abstract by \u2018clearly\u2019 faster since the evaluation does not show that LEARNA is 450x faster than all other methods. 11. Does \u201cAt its most basic form\u201d (introduction) mean that alternative RNA nucleotides exist? If so, this should be cited. 12. The authors should more clearly motive in the introduction why they created a new dataset. 13. The authors should mention in section 2.1 that the dot-bracket notation is not the only notation for representing RNA structures (https://www.tbi.univie.ac.at/RNA/ViennaRNA/doc/html/rna_structure_notations.html). 14. The authors should define the hamming distance (section 2.1). Do other distance metrics exist? 15. For the Traveling Salesman Problem (section 2.2) should the reward be the *negative* tour length? 16. The authors should more clearly describe the embedding layer (section 4). Are nucleotides one-hot encoded or represented as integers (0, 1 for \u2018(\u2018 and \u2018.\u2019)?", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "\u201c 8.How sensitive is the model performance depending on the context size \\kappa for representing the current state ? Did the authors try to encode the entire target structure with , e.g.recurrent models , instead of using a window centered on the current position ? \u201d -- > Thanks for the suggestion . An RNN is already included in our search space , and was indeed selected by our joint architecture search and hyperparameter optimization . We have not yet experimented with encoding the entire target structure with an RNN , since having to backpropagate through that RNN at each time step of our agent would lead to a substantial increase of computational cost , be harder to train and increase the number of hyperparameters . Having said that , we do think this is a good idea if it can be made computationally efficient , e.g. , by learning the embedding offline ( although the training signal for that would need to be defined first ) ; since this is not straightforward we leave it to future work . In terms of the importance of the context size , our new hyperparameter importance in Appendix I indicates that the context size ( state space radius ) \\kappa does not appear to be very important . \u201c 9.The authors should more clearly describe the local optimization step ( section 3.1 ; reward ) . Were all nucleotides that differ mutated independently , or enumerated exhaustively ? The latter would have a high runtime of O ( 3^d ) , where d is the number of nucleotides that differ . When do the authors start with the local optimization ? \u201d -- > We agree that the local improvement step should be described more clearly : we revised the reward paragraph and included pseudocode for computing the reward using the local improvement step ( Appendix A ) . It works as follows : After the policy rollout we fold the candidate solution and compare it to the target structure , if less than \\xi sites differ we perform this local improvement step in order to compute the reward . The value of \\xi is not part of the hyperparameter optimization and based on the runtime costs and preliminary experiments we set xi=5 , i.e. , we used the local improvement step if the number of differing sites was at most 4 . Keeping this number low was indeed important because of the computational complexity mentioned by the reviewer ( it \u2019 s actually O ( 4^d ) , with d < =4 ) . \u201c 10.The authors should replace \u2018 450x \u2019 faster in the abstract by \u2018 clearly \u2019 faster since the evaluation does not show that LEARNA is 450x faster than all other methods. \u201d -- > Thank you for the comment , we changed the abstract to say that our approach achieves new state-of-the-art performance on all benchmarks while also being orders of magnitudes faster in reaching the previous state-of-the-art performance . We note that these speedups ( including the 450x one on the Eterna100 benchmark , Figure 3 ( top ) ) can clearly be seen in the evaluation plots . \u201c 11.Does \u201c At its most basic form \u201d ( introduction ) mean that alternative RNA nucleotides exist ? If so , this should be cited. \u201d -- > Thanks for this question . With \u201c At its most basic form \u201d we refer to the most basic structural form of RNA , which is a sequence of nucleotides . We have since clarified the phrasing to \u201c At its most basic structural form \u201d . \u201c 13.The authors should mention in section 2.1 that the dot-bracket notation is not the only notation for representing RNA structures ( https : //www.tbi.univie.ac.at/RNA/ViennaRNA/doc/html/rna_structure_notations.html ) . \u201d and \u201c 14a . The authors should define the hamming distance ( section 2.1 ) . \u201d -- > We have included references , thank you for your comments . \u201c 14b.Do other distance metrics [ than the hamming distance ] exist ? \u201d -- > While not formally metrics , we have experimented with the paired-unpaired-ratio and derivatives of the hamming distance . While also not a metric , the GC-content ( which is the ratio of G and C nucleotides to the U and A nucleotides ) has been used in the RNA Design literature ( e.g.by antaRNA ) as an additional objective . \u201c 15.For the Traveling Salesman Problem ( section 2.2 ) should the reward be the * negative * tour length ? \u201d -- > You are of course right , thank you for reading our paper carefully and bringing this to our attention ; we fixed it . \u201c 16.The authors should more clearly describe the embedding layer ( section 4 ) . Are nucleotides one-hot encoded or represented as integers ( 0 , 1 for \u2018 ( \u2018 and \u2018 . \u2019 ) ? \u201d -- > Thank you for this comment ; we agree and have included a clearer description . For representing nucleotides , our automated reinforcement learning approach includes the choice between : 1 ) a binary encoding differentiating between paired and unpaired sites , and 2 ) a learned embedding layer whose dimension is a hyperparameter ( only active if the learned embedding is selected ) . Thanks again for all your comments ! If we cleared up some of your concerns , we would kindly ask you to update your assessment ."}, "1": {"review_id": "ByfyHh05tQ-1", "review_text": "I'm happy with the revisions the authors have made, as I find that they call out the novel contributions a bit more explicitly. Specifically I see some novel work in the area of simultaneous multi-task/meta-RL and black box optimization of the policy net architectures. I don't think calling this NAS is justified; calling it bayesopt or black box opt is fair. NAS uses a neural net to propose experiments over structured graphs of computation nodes. This work appears to be simpler hyperparameter optimization. ==== Quality: The work is well done, and the experiments are reasonable/competitive, showcasing other recent work and outperforming. Clarity: I thought the presentation was tolerable. I was a bit confused by Table 1 until reading the prose at the bottom of page 7 indicated Table 1 is presenting percentages, not integer quantities. The local improvement step is not very clearly explained. Are all combos tried across all mismatched positions, or do we try each mismatched position independently holding the others to their predicted values? What value of zeta did you end up using? It seems like this is essential to getting good performance. It is completely unclear to me what the 'restart option' does. Originality: Using RL in this specific application setting seems relatively new (though also explored by RL-LS in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6029810/). On the other hand, the approach used doesn't seem to be substantially different than anything else typically used for policy gradient RL. The meta-learning approach is interesting, though again not too different from multi-task approaches (though these are perhaps less common in RL than in general deep learning). Significance: Likely to be of practical utility in the inverse design space, specifically therapeutics, CRISPR guide RNA design, etc. Interesting to ICLR as an application area but probably not much theory/methods interest. On balance I lean slightly against accepting and think this is a better fit to either a workshop or a more domain-specific venue (MLHC http://mucmd.org/ for example).", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your helpful comments and questions . Thanks also for your positive feedback on our work in general , our experiments , the significance of our approach for therapeutics and other practical use cases and for characterizing our work as interesting to ICLR as an application area . We would like to comment on your suggestions , comments and questions in the following . \u201c 1.I was a bit confused by Table 1 until reading the prose at the bottom of page 7 indicated Table 1 is presenting percentages , not integer quantities. \u201d -- > Reviewing Table 1 , we agree that it could be confusing -- its caption did mention that all entries represent percentages and not total values , but this was unnecessarily indirect , and we now reworked the tables to include a percentage symbol to make it clearer . \u201c 2.The local improvement step is not very clearly explained . Are all combos tried across all mismatched positions , or do we try each mismatched position independently holding the others to their predicted values ? What value of \\xi did you end up using ? It seems like this is essential to getting good performance. \u201d -- > Thanks , we agree that the local improvement step should be described more clearly and that it is an important part of our approach ( as the empirical evidence in our ablation study suggests ) . We have since reworked the corresponding paragraph and included pseudocode ( Appendix A ) . It works as follows : we exhaustively try all possible nucleotide assignments for the mismatched positions which takes at most 4^|differing_sites| additional folds . The value of \\xi we used was 5 , i.e. , we used the local improvement step if the number of differing sites was at most 4 . This was set early on based on runtime considerations and preliminary experiments and was not part of our hyperparameter optimization ; thank you for the detailed reading of our paper and pointing out this missing value , we have added it now . \u201c 3.It is completely unclear to me what the 'restart option ' does. \u201d -- > Thanks for pointing out this missing information . Since RL algorithms are prone to getting stuck in local minima , we decided to employ occasional restarts ( i.e. , reinitialization ) in our strategies . We now describe this in the revised version in Section 5 . For LEARNA and for Meta-LEARNA-Adapt , this makes a difference , whereas for Meta-LEARNA it does not since Meta-LEARNA is directly sampling from the model without updating it ( which is equivalent to restarting at each step ) \u201c 4 . Using RL in this specific application setting seems relatively new ( though also explored by RL-LS in https : //www.ncbi.nlm.nih.gov/pmc/articles/PMC6029810/ ) . \u201d -- > Thanks for this comment ! Indeed , the reinforcement learning guided local search ( RL-LS ) was developed in parallel and independently from LEARNA ( as mentioned in our discussion on RL-LS in Section 2.2 of our initial submission ; now discussed in Section 3 ) . However , the two approaches differ a lot : although both approaches employ RL to RNA Design , Eastman et al.follows the common approach of using a local search strategy for solving the RNA Design problem , while we try to tackle the problem with a generative model . \u201c 5.On the other hand , the approach used does n't seem to be substantially different than anything else typically used for policy gradient RL . The meta-learning approach is interesting , though again not too different from multi-task approaches ( though these are perhaps less common in RL than in general deep learning ) . \u201d -- > We agree that the policy gradient approach we use is standard , but that using meta-learning in this context is already less common . We would also like to repeat the point concerning novelty of our joint optimization we made in the general reply to all reviewers . We copied this here for convenience : < \u201c To the best of our knowledge , our paper is the first case study on the joint optimization of the architecture of the policy network ( including both recurrent connections and convolutions in a single search space ) , the state representation , and the hyperparameters of an RL algorithm . In fact , we are not even aware of * any * other previous work on neural architecture search ( NAS ) for RL . Also , while there is of course a lot of work on NAS for CNNs and NAS for RNNs individually , we are not aware of any other previous NAS work that tackles a search space including both convolutions and recurrent units at the same time ( i.e. , with NAS choosing the best combination of the two ) . Finally , we are not aware of any previous work on NAS for meta-learning ( other than learning a cell architecture and transferring that cell to a different dataset ) . We do believe that these are clear points in favor of our paper \u2019 s novelty , and we should have made these clearer in the submitted version of our paper ; we \u2019 ve fixed this now in Section 5 and in the introduction. \u201d > Thanks again for your comments ! If we cleared up some of your concerns , we would kindly ask you to update your assessment ."}, "2": {"review_id": "ByfyHh05tQ-2", "review_text": "This work tackles the difficult RNA design problem, i.e. that of finding a RNA primary sequence that is going to fold into a secondary/tertiary structure able to perform a desired biological function. More specifically, it used Reinforcement Learning (RL) to find the best sequence that will fold into a target secondary structure, using the Zuker algorithm and designing a new primary sequence 'from scratch'. A new benchmark data set is also introduced in the paper along . Questions/remarks: - I struggle with your notations as soon as section 2.1. What is the star (*) superscript for? Was expecting the length of the RNA sequence instead. Same on p4, when introducing the notation of your decision process $ D_w $, explicitly introduce all the ingredients. - in Equation (2) on p4, maybe clarify the notation with '.', '(' and ')' for example as the reader could really struggle. - I didn't really understand the message in Section 4, not being an expert in the field. Could you clarify your contribution here? - your 'Ablation study' in Section 5.2; does it correspond to true uncertainty/noise that could be observed in real data? - why a new benchmark data set, when there exist good ones to compare your method to, e.g. in competitions like CASP for proteins? - do you make your implementation available? - quite like the clarification of the relationship of your work to that of Eastman et al. 2018. Could you also include discussions to other papers, e.g. Chuai et al. 2018 Genome Biol and Shi et al. 2018 SentRNA on arXiv? Altogether the paper reads well, seems to have adequate references, motivates and proposes 3 variations of a new algorithm for a difficult learning problem. Not being an expert in the field, I just can't judge about the novelty of the appraoch.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the suggested improvements , the insightful comments and questions ! Thanks also for the positive feedback on the text of the paper , references and motivation . In the following we provide detailed replies : \u201c 1 . What is the star ( * ) superscript for ? Was expecting the length of the RNA sequence instead. \u201d -- > Thank you for pointing out this undefined and potentially confusing use of notation . The Kleene Operator ( * ) applied to a set M yields a set of all finite-length sequences based on M , and we used it since RNA Structures have variable length . But we do agree that this can be confusing and made changes to talk about a specific structure w and then use N^|w| as you suggested . \u201c 2.Same on p4 , when introducing the notation of your decision process $ D_w $ , explicitly introduce all the ingredients. \u201d -- > We agree with you and revised the definition of the undiscounted decision process . We now explicitly name the components of the quadruple D_w and also refer to the specifics in the paragraphs following the definition of D_w . \u201c 3.in Equation ( 2 ) on p4 , maybe clarify the notation with ' . ' , ' ( ' and ' ) ' for example as the reader could really struggle. \u201d -- > We have looked at this again and changed the equation , making it easier to parse for the reader . We have also included a verbatim \u201c dot \u201d and \u201c opening bracket \u201d to not confuse the reader by the notation . \u201c 4.I did n't really understand the message in Section 4 , not being an expert in the field . Could you clarify your contribution here ? \u201d -- > Thanks for asking about this ! As detailed in our general reply to all reviewers , this section breaks novel ground concerning the joint optimization of neural architectures and hyperparameters , joint search over combinations of recurrent and convolutional layers in the same search space , neural architecture search for RL , and neural architecture search for meta-learning . In the interest of brevity , we refer to the detailed reply to all reviewers above . \u201c 5.your 'Ablation study ' in Section 5.2 ; does it correspond to true uncertainty/noise that could be observed in real data ? \u201d -- > In our ablation study , we disable one functional component of our approach at a time in order to study its influence ; incorporating ablations in empirically evaluated work is important to find out whether all proposed components are necessary and contribute to the final performance . Our ablation study is performed on the test split of our introduced dataset , which as we point out in the heading of Section 5 of our initial submission , has been generated from sequences observed in living organisms as listed in the Rfam 13.0 database ; it is not used to optimize hyperparameters but is a post hoc evaluation . \u201c 6.why a new benchmark data set , when there exist good ones to compare your method to , e.g.in competitions like CASP for proteins ? \u201d -- > We report our results on two widely used benchmarks which were also used in the work we compare to but unfortunately only provide test sets ( no training/validation/test split ) . To the best of our knowledge , we introduce the first benchmark with an explicit training/validation/test split . The reviewer is right in that there exist other and good data sources , but to the best of our knowledge not in the form of competitions . To mention two databases by name : * the STRAND database ( http : //www.rnasoft.ca/strand/ ) that currently holds 4666 known RNA secondary structures * the FRABASE 2.0 database ( https : //bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-231 ) with 2753 entries of fragments of secondary structures Both databases have not been used by the publications we compare to and can not satisfy the size and sequence diversity requirements for our meta-learning approach and future research ( especially for methods needing a large training set ) . The Rfam 13.0 database we use here for generating our new training- , validation- and test set is large enough to yield three distinct datasets of meaningful sizes and diversity . \u201c 7.do you make your implementation available ? \u201d -- > Thanks for the question , indeed , we strongly believe in sharing code ( as well as data ) to reproduce scientific findings . To stand by this opinion , we had included a note in the conclusion of our initial submission that we will make all of our code and data available upon acceptance of our paper . \u201c 8.quite like the clarification of the relationship of your work to that of Eastman et al.2018.Could you also include discussions to other papers , e.g.Chuai et al.2018 Genome Biol and Shi et al.2018 SentRNA on arXiv \u201d -- > Thanks for the positive feedback regarding our discussion of the relationship of our work to that of Eastman et al.2018 , and for bringing the related work to our attention . We included discussions in our related work section . Thanks again for all your comments ! If we cleared up some of your concerns , we would kindly ask you to update your assessment ."}}