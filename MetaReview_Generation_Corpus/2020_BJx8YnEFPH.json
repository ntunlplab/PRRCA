{"year": "2020", "forum": "BJx8YnEFPH", "title": "Data Valuation using Reinforcement Learning", "decision": "Reject", "meta_review": "The paper suggests an RL-based approach to design a data valuation estimator. The reviewers agree that the proposed method is new and promising, but they also raised concerns about the empirical evaluations, including not comparing with other approaches of data valuation and limited ablation study.\nThe authors provided a rebuttal to address these concerns. It improves the evaluation of one of the reviewers, but it is difficult to recommend acceptance given that we did not have a champion for this paper and the overall score is not high enough.", "reviews": [{"review_id": "BJx8YnEFPH-0", "review_text": "This paper proposes a method for assigning values to each datum. For example, data with incorrect labels, data of low quality, or data from off-the-target distributions should be assigned low values. The main method involves training a neural network to predict the value for each training datum. The reward is based on performance on a small validation set. To make gradient flow through data sampling, REINFORCE is used. The method is evaluated on multiple datasets. The results show that the proposed method outperforms a number of existing approaches. I think the proposed method is reasonable, and the results look promising. However, I'm concerned that there's limited ablation study provided to show how each design choice impacts the performance. (After all, the proposed has many differences from existing methods.) Without proper ablation study, it's hard for the community to learn conclusively from the proposed techniques. In addition, as pointed out by the comments by Abubakar Abid, there is a model that is trained on the clean validation data used during training. But this is not discussed in paper. How does it impact performance? Also, all the image datasets studied in this paper are small, and this paper only considers fine-tuning the final layer from an ImageNet-pre-trained model. It'll be more convincing to show results on more relevant datasets or tasks in the community. Overall I think this paper is slightly below the bar for publication in its current form, and will benefit from additional experiments. -------after rebuttal-------- Thanks for providing additional results and explanations. I found the new ablations in C.6 helpful for understanding the impact of each of the design choices. The rebuttal also addresses my concerns regarding datasets, and my concerns regarding implementation details of \u2018y_train_hat\u2019, as now it's included in sec 4. Overall, after rebuttal, I'd like to recommend \"weak accept\" for this paper. ", "rating": "6: Weak Accept", "reply_text": "Thank you for finding our work promising and providing constructive comments that have improved the quality of our paper . Answer 1 : Thanks for this suggestion ! We have conducted additional ablation studies for three distinct cases and added to Appendix C.6 of the revised manuscript : ( 1 ) Discrete representations of data value estimator , ( 2 ) Baseline for stabilizing the RL training , ( 3 ) Output ( y_train_hat ) of the model trained on the clean validation set as the additional input ( validation model ) . The table below shows the fraction of discovered corrupted samples ( the same setting in Figure 4 ) after inspecting 20 % of the samples with multiple variants of DVRL ( higher is better ) . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Models / Datasets | Blog | HAM-10000 | CIFAR-10 | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - DVRL | 47.3 % | 60.2 % | 68.1 % | DVRL without sampler | 44.9 % | 58.3 % | 63.7 % | DVRL without baseline | 45.8 % | 56.6 % | 62.9 % | DVRL without y_train_hat | 43.7 % | 57.1 % | 64.4 % | y_train_hat only | 43.1 % | 55.9 % | 62.3 % | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - As can be seen from the above table , each distinct component provides an additional gain in DVRL . Our intuitions for these improvements are as follows : - The sampler ( discrete representation of DVE for data selection ) encourages exploration of an extremely large action space that helps DVRL to converge to the better optimal solution . - Baseline stabilizes the convergence of RL training , thus yielding higher gains on complex datasets . - The output of the validation model ( y_train_hat ) has an informative signal that helps DVRL , especially in the noisy sample discovery use case . Please see the next answer for further details . Answer 2 : Thanks for this suggestion \u2013 we agree that it would be helpful to discuss that in the paper . We have added the details of how we use the output ( y_train_hat ) of the model trained on the clean validation set to Section 4 of the revised paper ( see \u201c Experimental details \u201d ) . \u2018 y_train_hat \u2019 is defined as the difference between the predictions of a separate predictive model ( fined-tuned or trained from scratch on the validation set ) for the training samples and the original training labels . We use it as an additional input to the DVE model to further improve the performance of DVRL . To demonstrate the impact of this model empirically , we include an ablation study to show the performance comparison ( 1 ) using \u2018 y_train_hat \u2019 only , ( 2 ) DVRL without using \u2018 y_train_hat \u2019 , ( 3 ) DVRL with using \u2018 y_train_hat \u2019 in the Appendix C.6 of the revised manuscript . As can be seen in the above table ( in Answer 1 ) , y_train_hat has an informative signal to identify the noisy sample ( y_train_hat alone achieves high performances ) . DVRL without y_train_hat performs worse than DVRL but still achieves competitive performance . We also observe that we would need to use a larger DVE model ( with more iterations ) to estimate the data value in the absence of the informative signal y_train_hat . y_train_hat is highly informative in the noisy sample discovery application but not that significant in other applications such as domain adaptation or performance improvement by low-value data removal in standard supervised learning setting . Answer 3 : Thanks for this comment \u2013 we understand that selecting relevant and complex enough datasets and tasks is important . The main reason that we included results on small-scale datasets and fine-tuning the final layer from an ImageNet-pretrained model is to compare DVRL with Data Shapley and LOO which are not scalable to large-scale datasets and complex models . In addition to considering small datasets ( results in Figures 2-4 ) , we evaluated DVRL on two relatively large-scale image datasets ( CIFAR-10 and CIFAR-100 ) that are commonly used in the academic community ( see Table 1 ) . We also evaluated DVRL not only with fine-tuning the final layer from an ImageNet-pretrained model ( in Figure 2-4 ) but also with more complex models when trained from scratch ( ResNet-32 , WideResNet-28-10 ) in Table 1 . In addition we report results with a very large-scale tabular dataset ( Rossmann ) in Table 3 that contains 844k samples . We feel that these results demonstrate well the promise for scalability and generality of DVRL for both large-scale datasets and complex models for image and other data types . We hope this clarification is helpful . We hope that we have fully addressed your questions and concerns . Please let us know if you have further comments ."}, {"review_id": "BJx8YnEFPH-1", "review_text": "This paper proposes a meta learning approach based on data valuation for reinforcement learning tasks. The core idea is to train a second network (the data value estimator) in conjunction to a regular predictor network. The predictor is then trained with samples chosen via the data value estimation. The authors motivate this construction with the goal to filter out unreliable and corrupted data. It's well established that RL poses a difficult learning problem, and as such the goal to improve the RL process is definitely a good one. To the best of my knowledge the approach proposed here is new. The exposition of the paper is also quite clear, and all parts of the approach are explained nicely. In addition, the submission contains a thorough evaluation of the method. A central point for the method seems to be the validation data set which is used to train the data value estimator. The text emphasizes that this data set can be \"small\" several times, and the discussion and results of section 4.5 try to shed light here. However, Figure 5 indicates that a fairly large fraction of samples is needed to identify, e.g., more than 50% of the corrupted samples. Another cricital aspect for meta-learning approaches such as this one is also the training time. RL is already expensive, so if the meta learning introduces a large factor, the training could quickly become infeasible. Here, the text gives a factor of about 3, which is noticeable, but not overly big. This still seems practical. Potentially, the estimator could also be reused (at least partially) for repeated training runs. The tests in figure 2 are somewhat unituitive at first - I was expecting results of models trained on datasets with different samples being removed beforehand, rather than removing samples based on a trained estimator. However, this test makes sense on second sight, and e.g., the significant drop in performance after removing the most important samples indicates that the estimator was able to correctly identify a certain portion of data that is actually important for successful predictions. In addition to the noisy label and domain adaptation tests, this paints a positive picture. The method seems to yield useful (be it somewhat small) improvements in terms of learning performance. One aspect that could be justified better in my opinion is the choise for a discrete representation for the data value estimator. Shouldn't the method likewise work with a continuous representation here? The paper explain how the discrete model is trained with quite some detail, but the choice itself could be motivated more clearly. However, overall I think the method is interesting and yields nice performance improvements. It is described and evaluated in detail, so I think the paper could me included in the ICLR program.", "rating": "6: Weak Accept", "reply_text": "We appreciate your positive comments and thank you for the various thoughtful comments that have helped us to improve the quality of our paper . Please see our answers to the questions below . Answer 1 : Thanks for pointing this out \u2013 we agree that this could be misunderstood . In Figure 5 , the x-axis represents the fraction of inspected data ( not the validation data ) and y-axis is the fraction of discovered corrupted samples . In this example , 20 % of the samples are corrupted ; thus , even in the optimal case , 10 % of the samples are needed to be inspected to identify 50 % of the corrupted samples . On Adult and Fashion-MNIST datasets , DVRL needs 13 % and 14 % of inspected samples to identify 50 % of the corrupted samples respectively - merely 3 % and 4 % more than the optimal cases . We have clarified this in the figure legend . Answer 2 : We also feel that the overhead of DVRL compared to conventional training is practically feasible , and consider this one of the major benefits of our method compared to previous work . We include a computational complexity analysis for DVRL in Section 3 and Appendix B to provide detailed comparisons . Using the pre-trained model as the initialization of the predictor network to reduce the computational overhead of DVRL is a great idea and is actually what we did ( see the end of Section 3 ) . Answer 3 : This is a great question . We use the sampler in DVRL to obtain the discrete representation for the data values to encourage DVE model to efficiently explore the extremely large action ( sample selection ) space . To quantitatively show the advantage of this design choice , we conducted an ablation study ( see Appendix C.6 of the revised manuscript or the table below ) with a variant of DVRL without using the sampler , and instead directly using the continuous outputs of the data value estimator . DVRL with discrete representation of the data values outperforms DVRL without the sampler ( continuous representation of the data values ) ; for example , for corrupted sample discovery with the CIFAR-10 dataset , the performance gap is 4.4 % . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Models / Datasets | Blog | HAM-10000 | CIFAR-10 | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - DVRL | 47.3 % | 60.2 % | 68.1 % | DVRL without sampler | 44.9 % | 58.3 % | 63.7 % | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We hope that we have fully addressed your questions and concerns . Please let us know if you have further comments ."}, {"review_id": "BJx8YnEFPH-2", "review_text": "This article present an approach to assign an importance value to an observation, that quantifies its usefulness for a specific objective task. This is useful in many contexts, such as domain adaptation, corrupted sample discovery or robust learning. The importance values may also be used to improve the performance of a model for the task. The importance values are learned jointly with that model. A small neural network called by the authors a Data Value Estimator (DVE) is learnt by the authors to estimate sample selection probabilities, which will dictate which instances will be used for the main model that tackles the objective task. While the main model is trained through usual mini-batch gradient descent, the DVE can not be, since the sampling process is not differentiable. It follows that the DVE is trained with a RL signal, that follows the variation of the loss throughout the learning process. The method proposed by the authors is new and show very significant results over existing methods. It is scalable, while many of the presented approaches are not. It is said to have a much lower computational burden than some existing methods, e.g. LOO or Data Shapley. The paper is very well written, and the method is illustrated on several datasets, from different domains. However, it seems that many approaches that did not suffer from the same complexity drawbacks of LOO and Data Shapley were not compared to this work. While some of the presented approaches are recent, e.g. ChoiceNet (2018), others are more established, e.g. domain adversarial networks (DANs, Ganin et al 2016) and are not compared for domain adaptation tasks. Given that the contributions of the authors are solely empirical, it is necessary to compare their approach to other scalable domain adaptation approaches. The approach proposed by the authors also features many hyperparameters, with fixed chosen values, and the architecture of the DVE is not precised, which may impair the reproducibility of the paper. The authors should provide code if not already provided. There is a mistake on the legends of Figure 2 and Figure 3, since accuracy should increase when removing the least important samples.", "rating": "3: Weak Reject", "reply_text": "We appreciate that you find our method is new , that our results are very significant , and that our manuscript is well-written . Thank you for your helpful suggestions that helped us to more strongly demonstrate the impact of our method for domain adaptation . Please see below for answers to the questions as well as additional requested experiments . Answer 1 : Thanks for the suggestion ! We would like to emphasize that domain adaptation is one of the many applications of data valuation framework and the mentioned established domain adaptation methods ( e.g. , DANN ) can not be generalized to other applications of data valuation in a straightforward way . Therefore , we mainly focused on Data Shapley and LOO as our main benchmarks to various data valuation applications in our manuscript . However , we do agree that it would be valuable to compare DVRL to other scalable domain adaptation methods . We have added Adversarial Discriminative Domain Adaptation ( ADDA ) and Domain Adversarial Neural Networks ( DANN ) as additional benchmarks in Appendix C.5 of the revised manuscript to compare with DVRL . The table below represents the domain adaptation results on \u2018 Train on all \u2019 and \u2018 Train on Rest \u2019 settings with neural network as the predictor model , similar to Table 3 in the manuscript . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Settings | Train on all | Train on Rest | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Methods | Baseline | DVRL | ADDA | DANN | Baseline | DVRL | ADDA | DANN | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- A | 0.1531 | 0.1428 | 0.1465 | 0.1491 | 0.3124 | 0.2014 | 0.2119 | 0.2305 | B | 0.1529 | 0.0979 | 0.1193 | 0.1201 | 0.8071 | 0.5460 | 0.5444 | 0.5898 | C | 0.1620 | 0.1437 In addition , for robust learning with noisy samples ( Section 4.3 ) , we already compare with other scalable models such as Learning to Reweight and MentorNet in Table 1 . Answer 2 : We agree that reproducibility is very important . In the experimental details subsection ( at the beginning of Section 4 ) , we had the details of the experimental hyper-parameters that are important for reproducing the reported results . We have added further details to this Section which should help clarifying architecture-related ambiguities : \u201c As the DVE architecture , for tabular datasets , we use 5-layer perceptrons with 100 hidden units and ReLU ; and for image datasets , we use 5-layer perceptrons with 100 hidden units and ReLU on top of the CNN-based architecture used for the predictor network ( such as ResNet-32 or WideResNet-28-10 in Table 1 ) as DVE architecture. \u201d In addition , as answered below , we also published the source codes when we submitted the manuscript ( 9/25/2019 ) via OpenReview website which should ensure reproducibility . Answer 3 : We published the code when we submitted the manuscript ( 9/25/2019 ) via the OpenReview website . Answer 4 : Thank you for pointing this typo out . We have fixed the typo as follows : \u201c Prediction performance after removing the most ( marked with cross ) and least ( marked with circle ) important samples \u201d - please see the revised manuscript . We hope that we have fully addressed your reproducibility and comparison concerns . Please let us know if you have further comments ."}], "0": {"review_id": "BJx8YnEFPH-0", "review_text": "This paper proposes a method for assigning values to each datum. For example, data with incorrect labels, data of low quality, or data from off-the-target distributions should be assigned low values. The main method involves training a neural network to predict the value for each training datum. The reward is based on performance on a small validation set. To make gradient flow through data sampling, REINFORCE is used. The method is evaluated on multiple datasets. The results show that the proposed method outperforms a number of existing approaches. I think the proposed method is reasonable, and the results look promising. However, I'm concerned that there's limited ablation study provided to show how each design choice impacts the performance. (After all, the proposed has many differences from existing methods.) Without proper ablation study, it's hard for the community to learn conclusively from the proposed techniques. In addition, as pointed out by the comments by Abubakar Abid, there is a model that is trained on the clean validation data used during training. But this is not discussed in paper. How does it impact performance? Also, all the image datasets studied in this paper are small, and this paper only considers fine-tuning the final layer from an ImageNet-pre-trained model. It'll be more convincing to show results on more relevant datasets or tasks in the community. Overall I think this paper is slightly below the bar for publication in its current form, and will benefit from additional experiments. -------after rebuttal-------- Thanks for providing additional results and explanations. I found the new ablations in C.6 helpful for understanding the impact of each of the design choices. The rebuttal also addresses my concerns regarding datasets, and my concerns regarding implementation details of \u2018y_train_hat\u2019, as now it's included in sec 4. Overall, after rebuttal, I'd like to recommend \"weak accept\" for this paper. ", "rating": "6: Weak Accept", "reply_text": "Thank you for finding our work promising and providing constructive comments that have improved the quality of our paper . Answer 1 : Thanks for this suggestion ! We have conducted additional ablation studies for three distinct cases and added to Appendix C.6 of the revised manuscript : ( 1 ) Discrete representations of data value estimator , ( 2 ) Baseline for stabilizing the RL training , ( 3 ) Output ( y_train_hat ) of the model trained on the clean validation set as the additional input ( validation model ) . The table below shows the fraction of discovered corrupted samples ( the same setting in Figure 4 ) after inspecting 20 % of the samples with multiple variants of DVRL ( higher is better ) . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Models / Datasets | Blog | HAM-10000 | CIFAR-10 | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - DVRL | 47.3 % | 60.2 % | 68.1 % | DVRL without sampler | 44.9 % | 58.3 % | 63.7 % | DVRL without baseline | 45.8 % | 56.6 % | 62.9 % | DVRL without y_train_hat | 43.7 % | 57.1 % | 64.4 % | y_train_hat only | 43.1 % | 55.9 % | 62.3 % | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - As can be seen from the above table , each distinct component provides an additional gain in DVRL . Our intuitions for these improvements are as follows : - The sampler ( discrete representation of DVE for data selection ) encourages exploration of an extremely large action space that helps DVRL to converge to the better optimal solution . - Baseline stabilizes the convergence of RL training , thus yielding higher gains on complex datasets . - The output of the validation model ( y_train_hat ) has an informative signal that helps DVRL , especially in the noisy sample discovery use case . Please see the next answer for further details . Answer 2 : Thanks for this suggestion \u2013 we agree that it would be helpful to discuss that in the paper . We have added the details of how we use the output ( y_train_hat ) of the model trained on the clean validation set to Section 4 of the revised paper ( see \u201c Experimental details \u201d ) . \u2018 y_train_hat \u2019 is defined as the difference between the predictions of a separate predictive model ( fined-tuned or trained from scratch on the validation set ) for the training samples and the original training labels . We use it as an additional input to the DVE model to further improve the performance of DVRL . To demonstrate the impact of this model empirically , we include an ablation study to show the performance comparison ( 1 ) using \u2018 y_train_hat \u2019 only , ( 2 ) DVRL without using \u2018 y_train_hat \u2019 , ( 3 ) DVRL with using \u2018 y_train_hat \u2019 in the Appendix C.6 of the revised manuscript . As can be seen in the above table ( in Answer 1 ) , y_train_hat has an informative signal to identify the noisy sample ( y_train_hat alone achieves high performances ) . DVRL without y_train_hat performs worse than DVRL but still achieves competitive performance . We also observe that we would need to use a larger DVE model ( with more iterations ) to estimate the data value in the absence of the informative signal y_train_hat . y_train_hat is highly informative in the noisy sample discovery application but not that significant in other applications such as domain adaptation or performance improvement by low-value data removal in standard supervised learning setting . Answer 3 : Thanks for this comment \u2013 we understand that selecting relevant and complex enough datasets and tasks is important . The main reason that we included results on small-scale datasets and fine-tuning the final layer from an ImageNet-pretrained model is to compare DVRL with Data Shapley and LOO which are not scalable to large-scale datasets and complex models . In addition to considering small datasets ( results in Figures 2-4 ) , we evaluated DVRL on two relatively large-scale image datasets ( CIFAR-10 and CIFAR-100 ) that are commonly used in the academic community ( see Table 1 ) . We also evaluated DVRL not only with fine-tuning the final layer from an ImageNet-pretrained model ( in Figure 2-4 ) but also with more complex models when trained from scratch ( ResNet-32 , WideResNet-28-10 ) in Table 1 . In addition we report results with a very large-scale tabular dataset ( Rossmann ) in Table 3 that contains 844k samples . We feel that these results demonstrate well the promise for scalability and generality of DVRL for both large-scale datasets and complex models for image and other data types . We hope this clarification is helpful . We hope that we have fully addressed your questions and concerns . Please let us know if you have further comments ."}, "1": {"review_id": "BJx8YnEFPH-1", "review_text": "This paper proposes a meta learning approach based on data valuation for reinforcement learning tasks. The core idea is to train a second network (the data value estimator) in conjunction to a regular predictor network. The predictor is then trained with samples chosen via the data value estimation. The authors motivate this construction with the goal to filter out unreliable and corrupted data. It's well established that RL poses a difficult learning problem, and as such the goal to improve the RL process is definitely a good one. To the best of my knowledge the approach proposed here is new. The exposition of the paper is also quite clear, and all parts of the approach are explained nicely. In addition, the submission contains a thorough evaluation of the method. A central point for the method seems to be the validation data set which is used to train the data value estimator. The text emphasizes that this data set can be \"small\" several times, and the discussion and results of section 4.5 try to shed light here. However, Figure 5 indicates that a fairly large fraction of samples is needed to identify, e.g., more than 50% of the corrupted samples. Another cricital aspect for meta-learning approaches such as this one is also the training time. RL is already expensive, so if the meta learning introduces a large factor, the training could quickly become infeasible. Here, the text gives a factor of about 3, which is noticeable, but not overly big. This still seems practical. Potentially, the estimator could also be reused (at least partially) for repeated training runs. The tests in figure 2 are somewhat unituitive at first - I was expecting results of models trained on datasets with different samples being removed beforehand, rather than removing samples based on a trained estimator. However, this test makes sense on second sight, and e.g., the significant drop in performance after removing the most important samples indicates that the estimator was able to correctly identify a certain portion of data that is actually important for successful predictions. In addition to the noisy label and domain adaptation tests, this paints a positive picture. The method seems to yield useful (be it somewhat small) improvements in terms of learning performance. One aspect that could be justified better in my opinion is the choise for a discrete representation for the data value estimator. Shouldn't the method likewise work with a continuous representation here? The paper explain how the discrete model is trained with quite some detail, but the choice itself could be motivated more clearly. However, overall I think the method is interesting and yields nice performance improvements. It is described and evaluated in detail, so I think the paper could me included in the ICLR program.", "rating": "6: Weak Accept", "reply_text": "We appreciate your positive comments and thank you for the various thoughtful comments that have helped us to improve the quality of our paper . Please see our answers to the questions below . Answer 1 : Thanks for pointing this out \u2013 we agree that this could be misunderstood . In Figure 5 , the x-axis represents the fraction of inspected data ( not the validation data ) and y-axis is the fraction of discovered corrupted samples . In this example , 20 % of the samples are corrupted ; thus , even in the optimal case , 10 % of the samples are needed to be inspected to identify 50 % of the corrupted samples . On Adult and Fashion-MNIST datasets , DVRL needs 13 % and 14 % of inspected samples to identify 50 % of the corrupted samples respectively - merely 3 % and 4 % more than the optimal cases . We have clarified this in the figure legend . Answer 2 : We also feel that the overhead of DVRL compared to conventional training is practically feasible , and consider this one of the major benefits of our method compared to previous work . We include a computational complexity analysis for DVRL in Section 3 and Appendix B to provide detailed comparisons . Using the pre-trained model as the initialization of the predictor network to reduce the computational overhead of DVRL is a great idea and is actually what we did ( see the end of Section 3 ) . Answer 3 : This is a great question . We use the sampler in DVRL to obtain the discrete representation for the data values to encourage DVE model to efficiently explore the extremely large action ( sample selection ) space . To quantitatively show the advantage of this design choice , we conducted an ablation study ( see Appendix C.6 of the revised manuscript or the table below ) with a variant of DVRL without using the sampler , and instead directly using the continuous outputs of the data value estimator . DVRL with discrete representation of the data values outperforms DVRL without the sampler ( continuous representation of the data values ) ; for example , for corrupted sample discovery with the CIFAR-10 dataset , the performance gap is 4.4 % . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Models / Datasets | Blog | HAM-10000 | CIFAR-10 | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - DVRL | 47.3 % | 60.2 % | 68.1 % | DVRL without sampler | 44.9 % | 58.3 % | 63.7 % | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We hope that we have fully addressed your questions and concerns . Please let us know if you have further comments ."}, "2": {"review_id": "BJx8YnEFPH-2", "review_text": "This article present an approach to assign an importance value to an observation, that quantifies its usefulness for a specific objective task. This is useful in many contexts, such as domain adaptation, corrupted sample discovery or robust learning. The importance values may also be used to improve the performance of a model for the task. The importance values are learned jointly with that model. A small neural network called by the authors a Data Value Estimator (DVE) is learnt by the authors to estimate sample selection probabilities, which will dictate which instances will be used for the main model that tackles the objective task. While the main model is trained through usual mini-batch gradient descent, the DVE can not be, since the sampling process is not differentiable. It follows that the DVE is trained with a RL signal, that follows the variation of the loss throughout the learning process. The method proposed by the authors is new and show very significant results over existing methods. It is scalable, while many of the presented approaches are not. It is said to have a much lower computational burden than some existing methods, e.g. LOO or Data Shapley. The paper is very well written, and the method is illustrated on several datasets, from different domains. However, it seems that many approaches that did not suffer from the same complexity drawbacks of LOO and Data Shapley were not compared to this work. While some of the presented approaches are recent, e.g. ChoiceNet (2018), others are more established, e.g. domain adversarial networks (DANs, Ganin et al 2016) and are not compared for domain adaptation tasks. Given that the contributions of the authors are solely empirical, it is necessary to compare their approach to other scalable domain adaptation approaches. The approach proposed by the authors also features many hyperparameters, with fixed chosen values, and the architecture of the DVE is not precised, which may impair the reproducibility of the paper. The authors should provide code if not already provided. There is a mistake on the legends of Figure 2 and Figure 3, since accuracy should increase when removing the least important samples.", "rating": "3: Weak Reject", "reply_text": "We appreciate that you find our method is new , that our results are very significant , and that our manuscript is well-written . Thank you for your helpful suggestions that helped us to more strongly demonstrate the impact of our method for domain adaptation . Please see below for answers to the questions as well as additional requested experiments . Answer 1 : Thanks for the suggestion ! We would like to emphasize that domain adaptation is one of the many applications of data valuation framework and the mentioned established domain adaptation methods ( e.g. , DANN ) can not be generalized to other applications of data valuation in a straightforward way . Therefore , we mainly focused on Data Shapley and LOO as our main benchmarks to various data valuation applications in our manuscript . However , we do agree that it would be valuable to compare DVRL to other scalable domain adaptation methods . We have added Adversarial Discriminative Domain Adaptation ( ADDA ) and Domain Adversarial Neural Networks ( DANN ) as additional benchmarks in Appendix C.5 of the revised manuscript to compare with DVRL . The table below represents the domain adaptation results on \u2018 Train on all \u2019 and \u2018 Train on Rest \u2019 settings with neural network as the predictor model , similar to Table 3 in the manuscript . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Settings | Train on all | Train on Rest | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Methods | Baseline | DVRL | ADDA | DANN | Baseline | DVRL | ADDA | DANN | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- A | 0.1531 | 0.1428 | 0.1465 | 0.1491 | 0.3124 | 0.2014 | 0.2119 | 0.2305 | B | 0.1529 | 0.0979 | 0.1193 | 0.1201 | 0.8071 | 0.5460 | 0.5444 | 0.5898 | C | 0.1620 | 0.1437 In addition , for robust learning with noisy samples ( Section 4.3 ) , we already compare with other scalable models such as Learning to Reweight and MentorNet in Table 1 . Answer 2 : We agree that reproducibility is very important . In the experimental details subsection ( at the beginning of Section 4 ) , we had the details of the experimental hyper-parameters that are important for reproducing the reported results . We have added further details to this Section which should help clarifying architecture-related ambiguities : \u201c As the DVE architecture , for tabular datasets , we use 5-layer perceptrons with 100 hidden units and ReLU ; and for image datasets , we use 5-layer perceptrons with 100 hidden units and ReLU on top of the CNN-based architecture used for the predictor network ( such as ResNet-32 or WideResNet-28-10 in Table 1 ) as DVE architecture. \u201d In addition , as answered below , we also published the source codes when we submitted the manuscript ( 9/25/2019 ) via OpenReview website which should ensure reproducibility . Answer 3 : We published the code when we submitted the manuscript ( 9/25/2019 ) via the OpenReview website . Answer 4 : Thank you for pointing this typo out . We have fixed the typo as follows : \u201c Prediction performance after removing the most ( marked with cross ) and least ( marked with circle ) important samples \u201d - please see the revised manuscript . We hope that we have fully addressed your reproducibility and comparison concerns . Please let us know if you have further comments ."}}