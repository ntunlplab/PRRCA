{"year": "2018", "forum": "SkZxCk-0Z", "title": "Can Neural Networks Understand Logical Entailment?", "decision": "Accept (Poster)", "meta_review": "This paper studies the problem of modeling logical structure in a neural model.  It introduces a data set for probing various existing models and proposes a new model that addresses shortcomings in existing ones.  The reviewers point out that there is a bit of a tautology in introducing a new task and a new model that solves it.  The revised version addresses some of those concerns.  Overall, it is a thought-provoking and well-written study that will be interesting to discuss at ICLR.", "reviews": [{"review_id": "SkZxCk-0Z-0", "review_text": "Overall, the paper is well-written and the proposed model is quite intuitive. Specifically, the idea is to represent entailment as a product of continuous functions over possible worlds. Specifically, the idea is to generate possible worlds, and compute the functions that encode entailment in those worlds. The functions themselves are designed as tree neural networks to take advantage of logical structure. Several different encoding benchmarks of the entailment task are designed to compare against the performance of the proposed model, using a newly created dataset. The results seem very impressive with > 99% accuracy on tests sets. One weakness with the paper was that it was only tested on 1 dataset. Also, should some form of cross-validation be applied to smooth out variance in the evaluation results. I am not sure if there are standard \"shared\" datasets for this task, which would make the results much stronger. Also how about the tradeoff, i.e., does training time significantly increase when we \"imagine\" more worlds. Also, in general, a discussion on the efficiency of training the proposed model as compared to TreeNN would be helpful. The size of the world vectors, I would believe is quite important, so maybe a more detailed analysis on how this was chosen is important to replicate the results. This problem, I think, is quite related to model counting. There has been a lot of work on model counting. a discussion on how this relates to those lines of work would be interesting. After revision I think the authors have improved the experiments substantially.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your comments and fair criticisms . We have run substantial further evaluation of the previously trained models , which we hope will strengthen the case for this paper . We reply to some of the points you made in your review below , and hope you will find that the empirical evidence satisfactorily addressed the concerns you have raised . \u201c One weakness with the paper was that it was only tested on 1 dataset . Also , should some form of cross-validation be applied to smooth out variance in the evaluation results . I am not sure if there are standard `` shared '' datasets for this task , which would make the results much stronger . This is a good point . To address this question , we have generated two other test sets . The first one , Test ( big ) has 1-20 variables and 10-30 operators per formula . The second , Test ( massive ) has 20-26 variables with 20-30 operators per formula . Finally , we collected a `` real world '' test set , Test ( exam ) from formulas found in textbook and exam questions , pruning sequents from the training set that were alpha-equivalent to sequents found in exam data . See the updated Table 1 for the new test-sets , and Table 2 for the updated results . In particular , there is still a gap between what is achieved by our best models and what is theoretically possible ( > 25 % accuracy gap ) for the massive dataset , showing that further research on this topic is needed , and is hopefully enabled by this dataset . \u201c Also how about the tradeoff , i.e. , does training time significantly increase when we `` imagine '' more worlds . \u201c Yes , the model takes longer to run ( in terms of time ) as we increase the number of worlds , since we need to evaluate the formulas in every world . But in terms of the number of training epochs , it does not take longer to run . One of the interesting things about the PossibleWorldNet is that the number of parameters ( trainable variables ) does not increase as we increase the number of worlds , nor does the model see more data . It just does more parallel computation per data point . \u201c This problem , I think , is quite related to model counting . There has been a lot of work on model counting . a discussion on how this relates to those lines of work would be interesting. \u201d Thanks , this is a good suggestion . We will certainly look into this for the final version ."}, {"review_id": "SkZxCk-0Z-1", "review_text": "SUMMARY The paper is fairly broad in what it is trying to achieve, but the approach is well thought out. The purpose of the paper is to investigate the effectiveness of prior machine learning methods with predicting logical entailment and then provide a new model designed for the task. Explicitly, the paper asks the following questions: \"Can neural networks understand logical formula well enough to detect entailment?\", and \"Which architectures are best at inferring, encoding, and relating features in a purely structural sequence-based problem?\". The goals of the paper is to understand the learning bias of current architectures when they are tasked with learning logical entailment. The proposed network architecture, PossibleWorldNet, is then viewed as an improvement on an earlier architecture TreeNet. POSITIVES The structure of this paper was very well done. The paper attempts to do a lot, and succeeds on most fronts. The generated dataset used for testing logical entailment is given a constructive description which allows for future replication. The baseline benchmark networks are covered in depth and the reader is provided with a deep understanding on the limitations of some networks with regard to exploiting structure in data. The PossibleWorldNets is also given good coverage, and the equations provided show the means by which it operates. \u2022 A clear methodological approach to the research. The paper covers how they created a dataset which can be used for logical entailment learning, and then explains clearly all the previous network models which will be used in testing as well as their proposed model. \u2022 The background information regarding each model was exceptionally thorough. The paper went into great depth describing the pros and cons of earlier network models and why they may struggle with recognizing logical entailment. \u2022 The section describing the creation of a dataset captures the basis for the research, learning logical entailment. They describe the creation of the data, as well as the means by which they increase the difficulty for learning. \u2022 The paper provides an in depth description of their PossibleWorldNet model, and during experimentation we see clear evidence of the models capabilities. NEGATIVES One issue I had with the paper is regarding the creation of the logical entailment dataset. Not so much for how they explained the process of creating the dataset, that was very thorough, but the fact that this dataset was the only means to test the previous network models and their new proposed network model. I wonder if it would be better to find non-generated datasets which may contain data that have entailment relationships. It is questionable if their hand crafted network model is learned best on their hand crafted dataset. The use of a singular dataset for learning logical entailment. The dataset was also created by the researchers for the express purpose of testing neural network capacity to learn logical entailment. I am hesitant to say their proposed network is an incredible achievement since PossibleWorldNet effectively beat out other methods on a dataset that they created expressly for it. RELATED WORK The paper has an extensive section dedicated to covering related work. I would say the research involved was very thorough and the researchers understood how their method was different as well as how it was improving on earlier approaches. CONCLUSION Given the thorough investigation into previous networks\u2019 capabilities in logical entailment learning, I would accept this paper as a valid scientific contribution. The paper performs a thorough analysis on the limitations that previous networks face with regard to exploiting structure from data. The paper also covers results of the experiments by not only pointing out their proposed network\u2019s success, but by analyzing why certain earlier network models were able to achieve competitive learning results. The structure of the PossibleWorldNet was also explained well, and during ex- perimentation demonstrated its ability to learn structure from data. The paper would have been improved through testing of multiple datasets, and not just on there self generated dataset, but the contribution of their research on their network and older networks is still justification enough for this paper.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your supportive review and your kind comments . Based on questions you have raised with other reviewers , we have run further tests which we hope confirms your positive sentiment about the paper , and addressed any concerns you had about the testing regime used in the paper . We address here your specific , and very fair , criticism of our paper . \u201c One issue I had with the paper is regarding the creation of the logical entailment dataset . Not so much for how they explained the process of creating the dataset , that was very thorough , but the fact that this dataset was the only means to test the previous network models and their new proposed network model . I wonder if it would be better to find non-generated datasets which may contain data that have entailment relationships . It is questionable if their hand crafted network model is learned best on their hand crafted dataset. \u201d This is a good point . Since the initial submission , we have run a number of further experiments . In particular , we mined standard logic textbooks ( e.g. , Holbach \u2019 s \u201c The Logic Manual \u201d , Mendelson \u2019 s \u201c Introduction to Mathematical Logic \u201d ) to find a set of entailment questions that were not produced from our synthetic generative process . We then held-out these entailments ( and all entailments that were equivalent up to variable-renaming ) from the training sets . The new test-set is called \u201c Test ( Exam ) \u201d in the revised Table 1 on page 3 . We were gratified that our model achieved 96 % on this \u201c real-world \u201d test-set . See the updated Table 2 , reproduced below , including a variety of new larger test sets also described in this revision . + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | | | test | test | test | test | test | | model | valid|easy | hard | big | mass . | exam| + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | Linear BoW | 52.6 | 51.4 | 50.0 | 49.7 | 50.0 | 52.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | MLP BoW | 57.8 | 57.1 | 51.0 | 55.8 | 49.9 | 56.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | ConvNet Enc . | 59.3 | 59.7 | 52.6 |54.9 | 50.4 | 54.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | LSTM Enc . | 68.3 | 68.3 | 58.1 | 61.1 | 52.7 | 70.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | BiLSTM Enc . | 66.6 | 65.8 | 58.2 | 61.5 | 51.6 | 78.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | TreeNet Enc . | 72.7 | 72.2 | 69.7 | 67.9 | 56.6 | 85.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | TreeLSTM Enc| 79.1 | 77.8 | 74.2 | 74.2 | 59.3 | 75.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | LSTM Trav . | 62.5 | 61.8 | 56.2 | 57.3 | 50.6 | 61.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | TreeLSTM Tr . | 63.3 | 64.0 | 55.0 | 57.9 | 50.5 | 66.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | PWN | 98.7 | 98.6 | 96.7 | 93.9 | 73.4 | 96.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- +"}, {"review_id": "SkZxCk-0Z-2", "review_text": "This is a wonderful and a self-contained paper. In fact, it introduces a very important problem and it solves it. The major point of the paper is demonstrating that it is possible to model logical entailment in neural networks. Hence, a corpus and a NN model are introduced. The corpus is used to demonstrate that the model, named PossibleWorld, is nearly perfect for the task. A comparative analysis is done with respect to state of the art recurrent NN. So far, so good. Yet, what is the take home message? In my opinion, the message is that generic NN should not be used for specific formal tasks whereas specific neural networks that model the task are desirable. This seems to be a trivial claim, but, since the PossibleWorld nearly completely solves the task, it is worth to be investigated. The point that the paper leaves unexplained is: what is in the PossibleWorld Network that captures what we need? The description of the network is in fact very criptic. No examples are given and a major effort is required to the reader. Can you provide examples and insights on why this is THE needed model? Finally, the paper does not discuss a large body of research that has been done in the past by Plate. Plate has investigated how symbolic predicates can be described in distributed representations. This is strictly related to the problem this paper investigates. As discussed in \"Symbolic, Distributed and Distributional Representations for Natural Language Processing in the Era of Deep Learning: a Survey\", 2017, the link between symbolic and distributed representations has to be better investigated in order to propose innovative NN models. Your paper can be one of the first NN model that takes advantage of this strict link.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your kind words at the beginning of the review , and for your excellent questions and comments . We find the topics addressed in your questions , and your critical points are\u2013we think\u2013fair ones . We confess we were a little surprised by the low score given , considering the generally positive tone of the first half of the review , but this ( along with the comments of other reviewers ) has prompted us to rethink the evaluation of the models in order to address your specific points and hopefully assuage your concerns . We have made revisions to the manuscript to include further tests of our already-trained models , and we respond to parts of your review below . \u201c The point that the paper leaves unexplained is : what is in the PossibleWorld Network that captures what we need ? The description of the network is in fact very criptic . No examples are given and a major effort is required to the reader . \u201c Limitations of space prevented us providing examples in the body of the text . Here is a simple example from propositional logic . To check whether p \u2228 q entails p , we consider all possible truth-value assignments to the variables p and q . We get four assignments : p \u2192 \u22a5 , q \u2192 \u22a5 p \u2192 \u22a5 , q \u2192 \u22a4 p \u2192 \u22a4 , q \u2192 \u22a5 p \u2192 \u22a4 , q \u2192 \u22a4 Now p \u2228 q entails p if , for each of these assignments , if the assignment satisfies p \u2228 q , then it also satisfies p. In this example , the entailment is false , since the second assignment ( p \u2192 \u22a5 , q \u2192 \u22a4 ) satisfies p \u2228 q but does not satisfy p. We will endeavour to add such examples to the appendix if the paper is accepted . \u201c Can you provide examples and insights on why this is THE needed model ? \u201d Consider the standard model-theoretic definition of entailment : A entails B if , for every possible world w , if sat ( w , A ) then sat ( w , B ) : A \u22a7 B iff for every world w \u2208 W , sat ( w , A ) implies sat ( w , B ) We replace possible worlds with random vectors , transform the universal quantification into a product , and provide a neural network that implements sat ( w , A ) . The reason we believe this is * the * needed model is that it is a continuous relaxation of the standard model-theoretic definition of entailment . `` In my opinion , the message is that generic NN should not be used for specific formal tasks whereas specific neural networks that model the task are desirable . This seems to be a trivial claim . '' At this high level of generality , the claim is , indeed , trivial . But our claim is more specific . We provide implementation details of a particular model that outperforms other models on this task . This model is also applicable outside the particular domain of logic . The PossibleWorldNet was inspired by the model-theoretic definition of entailment , in terms of truth in all possible worlds . But it is not a specific model that is only useful for this particular task . It is a general model based on the following simple idea : first , evaluate the same model multiple times using different vectors of random noise as inputs ; second , combine the results from these multiple runs using a product . This general model is applicable outside the domain of logical entailment ; it could be useful for building robust image classifiers , for example . Since the initial submission , we have run a number of experiments that are significantly more ambitious . See the updated Table 1 on page 3 . In the \u201c Big \u201d and \u201c Massive \u201d test sets , the expected number of truth-table rows needed to exhaustively verify entailment is 3000 and 800,000 . Our PossibleWorldNet continues to out-perform the other models on these harder test-sets , but it does not completely solve the task . In particular , in the massive test set , it achieves 73 % . This score is significantly better than the other models , but it is not a complete solution . We hope that these explanations , which have been integrated into the revised manuscript , alongside the inclusion of further tests , without need to change the training protocol or model definitions , on significantly more complex logic problems and `` real-world '' exam data , will help convince you that this work merits publication . If you persist in your assessment , we will understand , but would be grateful if you could highlight what is lacking given this further empirical evidence provided in this revision , so that we may continue to improve the paper ."}], "0": {"review_id": "SkZxCk-0Z-0", "review_text": "Overall, the paper is well-written and the proposed model is quite intuitive. Specifically, the idea is to represent entailment as a product of continuous functions over possible worlds. Specifically, the idea is to generate possible worlds, and compute the functions that encode entailment in those worlds. The functions themselves are designed as tree neural networks to take advantage of logical structure. Several different encoding benchmarks of the entailment task are designed to compare against the performance of the proposed model, using a newly created dataset. The results seem very impressive with > 99% accuracy on tests sets. One weakness with the paper was that it was only tested on 1 dataset. Also, should some form of cross-validation be applied to smooth out variance in the evaluation results. I am not sure if there are standard \"shared\" datasets for this task, which would make the results much stronger. Also how about the tradeoff, i.e., does training time significantly increase when we \"imagine\" more worlds. Also, in general, a discussion on the efficiency of training the proposed model as compared to TreeNN would be helpful. The size of the world vectors, I would believe is quite important, so maybe a more detailed analysis on how this was chosen is important to replicate the results. This problem, I think, is quite related to model counting. There has been a lot of work on model counting. a discussion on how this relates to those lines of work would be interesting. After revision I think the authors have improved the experiments substantially.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your comments and fair criticisms . We have run substantial further evaluation of the previously trained models , which we hope will strengthen the case for this paper . We reply to some of the points you made in your review below , and hope you will find that the empirical evidence satisfactorily addressed the concerns you have raised . \u201c One weakness with the paper was that it was only tested on 1 dataset . Also , should some form of cross-validation be applied to smooth out variance in the evaluation results . I am not sure if there are standard `` shared '' datasets for this task , which would make the results much stronger . This is a good point . To address this question , we have generated two other test sets . The first one , Test ( big ) has 1-20 variables and 10-30 operators per formula . The second , Test ( massive ) has 20-26 variables with 20-30 operators per formula . Finally , we collected a `` real world '' test set , Test ( exam ) from formulas found in textbook and exam questions , pruning sequents from the training set that were alpha-equivalent to sequents found in exam data . See the updated Table 1 for the new test-sets , and Table 2 for the updated results . In particular , there is still a gap between what is achieved by our best models and what is theoretically possible ( > 25 % accuracy gap ) for the massive dataset , showing that further research on this topic is needed , and is hopefully enabled by this dataset . \u201c Also how about the tradeoff , i.e. , does training time significantly increase when we `` imagine '' more worlds . \u201c Yes , the model takes longer to run ( in terms of time ) as we increase the number of worlds , since we need to evaluate the formulas in every world . But in terms of the number of training epochs , it does not take longer to run . One of the interesting things about the PossibleWorldNet is that the number of parameters ( trainable variables ) does not increase as we increase the number of worlds , nor does the model see more data . It just does more parallel computation per data point . \u201c This problem , I think , is quite related to model counting . There has been a lot of work on model counting . a discussion on how this relates to those lines of work would be interesting. \u201d Thanks , this is a good suggestion . We will certainly look into this for the final version ."}, "1": {"review_id": "SkZxCk-0Z-1", "review_text": "SUMMARY The paper is fairly broad in what it is trying to achieve, but the approach is well thought out. The purpose of the paper is to investigate the effectiveness of prior machine learning methods with predicting logical entailment and then provide a new model designed for the task. Explicitly, the paper asks the following questions: \"Can neural networks understand logical formula well enough to detect entailment?\", and \"Which architectures are best at inferring, encoding, and relating features in a purely structural sequence-based problem?\". The goals of the paper is to understand the learning bias of current architectures when they are tasked with learning logical entailment. The proposed network architecture, PossibleWorldNet, is then viewed as an improvement on an earlier architecture TreeNet. POSITIVES The structure of this paper was very well done. The paper attempts to do a lot, and succeeds on most fronts. The generated dataset used for testing logical entailment is given a constructive description which allows for future replication. The baseline benchmark networks are covered in depth and the reader is provided with a deep understanding on the limitations of some networks with regard to exploiting structure in data. The PossibleWorldNets is also given good coverage, and the equations provided show the means by which it operates. \u2022 A clear methodological approach to the research. The paper covers how they created a dataset which can be used for logical entailment learning, and then explains clearly all the previous network models which will be used in testing as well as their proposed model. \u2022 The background information regarding each model was exceptionally thorough. The paper went into great depth describing the pros and cons of earlier network models and why they may struggle with recognizing logical entailment. \u2022 The section describing the creation of a dataset captures the basis for the research, learning logical entailment. They describe the creation of the data, as well as the means by which they increase the difficulty for learning. \u2022 The paper provides an in depth description of their PossibleWorldNet model, and during experimentation we see clear evidence of the models capabilities. NEGATIVES One issue I had with the paper is regarding the creation of the logical entailment dataset. Not so much for how they explained the process of creating the dataset, that was very thorough, but the fact that this dataset was the only means to test the previous network models and their new proposed network model. I wonder if it would be better to find non-generated datasets which may contain data that have entailment relationships. It is questionable if their hand crafted network model is learned best on their hand crafted dataset. The use of a singular dataset for learning logical entailment. The dataset was also created by the researchers for the express purpose of testing neural network capacity to learn logical entailment. I am hesitant to say their proposed network is an incredible achievement since PossibleWorldNet effectively beat out other methods on a dataset that they created expressly for it. RELATED WORK The paper has an extensive section dedicated to covering related work. I would say the research involved was very thorough and the researchers understood how their method was different as well as how it was improving on earlier approaches. CONCLUSION Given the thorough investigation into previous networks\u2019 capabilities in logical entailment learning, I would accept this paper as a valid scientific contribution. The paper performs a thorough analysis on the limitations that previous networks face with regard to exploiting structure from data. The paper also covers results of the experiments by not only pointing out their proposed network\u2019s success, but by analyzing why certain earlier network models were able to achieve competitive learning results. The structure of the PossibleWorldNet was also explained well, and during ex- perimentation demonstrated its ability to learn structure from data. The paper would have been improved through testing of multiple datasets, and not just on there self generated dataset, but the contribution of their research on their network and older networks is still justification enough for this paper.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your supportive review and your kind comments . Based on questions you have raised with other reviewers , we have run further tests which we hope confirms your positive sentiment about the paper , and addressed any concerns you had about the testing regime used in the paper . We address here your specific , and very fair , criticism of our paper . \u201c One issue I had with the paper is regarding the creation of the logical entailment dataset . Not so much for how they explained the process of creating the dataset , that was very thorough , but the fact that this dataset was the only means to test the previous network models and their new proposed network model . I wonder if it would be better to find non-generated datasets which may contain data that have entailment relationships . It is questionable if their hand crafted network model is learned best on their hand crafted dataset. \u201d This is a good point . Since the initial submission , we have run a number of further experiments . In particular , we mined standard logic textbooks ( e.g. , Holbach \u2019 s \u201c The Logic Manual \u201d , Mendelson \u2019 s \u201c Introduction to Mathematical Logic \u201d ) to find a set of entailment questions that were not produced from our synthetic generative process . We then held-out these entailments ( and all entailments that were equivalent up to variable-renaming ) from the training sets . The new test-set is called \u201c Test ( Exam ) \u201d in the revised Table 1 on page 3 . We were gratified that our model achieved 96 % on this \u201c real-world \u201d test-set . See the updated Table 2 , reproduced below , including a variety of new larger test sets also described in this revision . + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | | | test | test | test | test | test | | model | valid|easy | hard | big | mass . | exam| + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | Linear BoW | 52.6 | 51.4 | 50.0 | 49.7 | 50.0 | 52.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | MLP BoW | 57.8 | 57.1 | 51.0 | 55.8 | 49.9 | 56.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | ConvNet Enc . | 59.3 | 59.7 | 52.6 |54.9 | 50.4 | 54.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | LSTM Enc . | 68.3 | 68.3 | 58.1 | 61.1 | 52.7 | 70.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | BiLSTM Enc . | 66.6 | 65.8 | 58.2 | 61.5 | 51.6 | 78.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | TreeNet Enc . | 72.7 | 72.2 | 69.7 | 67.9 | 56.6 | 85.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | TreeLSTM Enc| 79.1 | 77.8 | 74.2 | 74.2 | 59.3 | 75.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | LSTM Trav . | 62.5 | 61.8 | 56.2 | 57.3 | 50.6 | 61.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | TreeLSTM Tr . | 63.3 | 64.0 | 55.0 | 57.9 | 50.5 | 66.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- + | PWN | 98.7 | 98.6 | 96.7 | 93.9 | 73.4 | 96.0 | + -- -- -- -- -- -- -- -- -- -- + -- -- -- -+ -- -- -- -- + -- -- -- -- + -- -- -- -+ -- -- -- -- -- -+ -- -- -- -- +"}, "2": {"review_id": "SkZxCk-0Z-2", "review_text": "This is a wonderful and a self-contained paper. In fact, it introduces a very important problem and it solves it. The major point of the paper is demonstrating that it is possible to model logical entailment in neural networks. Hence, a corpus and a NN model are introduced. The corpus is used to demonstrate that the model, named PossibleWorld, is nearly perfect for the task. A comparative analysis is done with respect to state of the art recurrent NN. So far, so good. Yet, what is the take home message? In my opinion, the message is that generic NN should not be used for specific formal tasks whereas specific neural networks that model the task are desirable. This seems to be a trivial claim, but, since the PossibleWorld nearly completely solves the task, it is worth to be investigated. The point that the paper leaves unexplained is: what is in the PossibleWorld Network that captures what we need? The description of the network is in fact very criptic. No examples are given and a major effort is required to the reader. Can you provide examples and insights on why this is THE needed model? Finally, the paper does not discuss a large body of research that has been done in the past by Plate. Plate has investigated how symbolic predicates can be described in distributed representations. This is strictly related to the problem this paper investigates. As discussed in \"Symbolic, Distributed and Distributional Representations for Natural Language Processing in the Era of Deep Learning: a Survey\", 2017, the link between symbolic and distributed representations has to be better investigated in order to propose innovative NN models. Your paper can be one of the first NN model that takes advantage of this strict link.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your kind words at the beginning of the review , and for your excellent questions and comments . We find the topics addressed in your questions , and your critical points are\u2013we think\u2013fair ones . We confess we were a little surprised by the low score given , considering the generally positive tone of the first half of the review , but this ( along with the comments of other reviewers ) has prompted us to rethink the evaluation of the models in order to address your specific points and hopefully assuage your concerns . We have made revisions to the manuscript to include further tests of our already-trained models , and we respond to parts of your review below . \u201c The point that the paper leaves unexplained is : what is in the PossibleWorld Network that captures what we need ? The description of the network is in fact very criptic . No examples are given and a major effort is required to the reader . \u201c Limitations of space prevented us providing examples in the body of the text . Here is a simple example from propositional logic . To check whether p \u2228 q entails p , we consider all possible truth-value assignments to the variables p and q . We get four assignments : p \u2192 \u22a5 , q \u2192 \u22a5 p \u2192 \u22a5 , q \u2192 \u22a4 p \u2192 \u22a4 , q \u2192 \u22a5 p \u2192 \u22a4 , q \u2192 \u22a4 Now p \u2228 q entails p if , for each of these assignments , if the assignment satisfies p \u2228 q , then it also satisfies p. In this example , the entailment is false , since the second assignment ( p \u2192 \u22a5 , q \u2192 \u22a4 ) satisfies p \u2228 q but does not satisfy p. We will endeavour to add such examples to the appendix if the paper is accepted . \u201c Can you provide examples and insights on why this is THE needed model ? \u201d Consider the standard model-theoretic definition of entailment : A entails B if , for every possible world w , if sat ( w , A ) then sat ( w , B ) : A \u22a7 B iff for every world w \u2208 W , sat ( w , A ) implies sat ( w , B ) We replace possible worlds with random vectors , transform the universal quantification into a product , and provide a neural network that implements sat ( w , A ) . The reason we believe this is * the * needed model is that it is a continuous relaxation of the standard model-theoretic definition of entailment . `` In my opinion , the message is that generic NN should not be used for specific formal tasks whereas specific neural networks that model the task are desirable . This seems to be a trivial claim . '' At this high level of generality , the claim is , indeed , trivial . But our claim is more specific . We provide implementation details of a particular model that outperforms other models on this task . This model is also applicable outside the particular domain of logic . The PossibleWorldNet was inspired by the model-theoretic definition of entailment , in terms of truth in all possible worlds . But it is not a specific model that is only useful for this particular task . It is a general model based on the following simple idea : first , evaluate the same model multiple times using different vectors of random noise as inputs ; second , combine the results from these multiple runs using a product . This general model is applicable outside the domain of logical entailment ; it could be useful for building robust image classifiers , for example . Since the initial submission , we have run a number of experiments that are significantly more ambitious . See the updated Table 1 on page 3 . In the \u201c Big \u201d and \u201c Massive \u201d test sets , the expected number of truth-table rows needed to exhaustively verify entailment is 3000 and 800,000 . Our PossibleWorldNet continues to out-perform the other models on these harder test-sets , but it does not completely solve the task . In particular , in the massive test set , it achieves 73 % . This score is significantly better than the other models , but it is not a complete solution . We hope that these explanations , which have been integrated into the revised manuscript , alongside the inclusion of further tests , without need to change the training protocol or model definitions , on significantly more complex logic problems and `` real-world '' exam data , will help convince you that this work merits publication . If you persist in your assessment , we will understand , but would be grateful if you could highlight what is lacking given this further empirical evidence provided in this revision , so that we may continue to improve the paper ."}}