{"year": "2020", "forum": "HkxWXkStDB", "title": "Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation", "decision": "Reject", "meta_review": "The paper in its current form was just not well enough received by the reviewers to warrant an acceptance rating. It seems this work may have promise and the authors are encouraged to continue with this line of work.\n", "reviews": [{"review_id": "HkxWXkStDB-0", "review_text": "This paper proposes a hybrid approach for adding noise to training images of an image classification model. Instead of either cutting out a patch or adding gaussian noise, the authors propose to adding a patch of gaussian noise to the images. Although possibly useful practically, this proposal lacks theoretical base on how and why it would be better, besides the claim that hopefully the combination will combine the benefit and subtract the weakness. The experiments are rather limitted to support the claim.", "rating": "3: Weak Reject", "reply_text": "> Although possibly useful practically We thank the reviewer for pointing out the practical applications of our method . Indeed , because it is so simple , \u201c the approach could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer , \u201d as R1 puts it . > this proposal lacks theoretical base on how and why it would be better We grant that our work started from an empirical observation . However , we provided an experimental analysis to gain a better understanding of why it works . In particular , Section 5.1 shows that Patch Gaussian seems to allow high-frequency information through at lower layers , but still encourages relatively lower test error sensitivity at high frequencies . Indeed , when we measure accuracy on images filtered with a high-pass filter , we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout , where Gaussian fails to . See Figure 5 for full results . R1 and R2 agree that our Fourier-theoretic analysis is intuitive . In addition , many practically useful techniques , such as Cutout , do not have completely rigorous mathematical analysis . > The experiments are rather limited to support the claim We show extensive experiments highlighting how Patch Gaussian is the only method that retains the benefits of Cutout and Gaussian : * We characterize a trade-off between robustness and accuracy among two standard data augmentations - Cutout and Gaussian ( Section 2.1 ) . Specifically , Cutout improves accuracy on clean test data . Despite this , we find it does not lead to increased robustness . Conversely , training with higher sigma of Gaussian can lead to increased robustness to Gaussian noise , but it also leads to decreased accuracy on clean data . Therefore , any robustness gains are offset by poor overall performance . * We show that our method ( Patch Gaussian ) allows us to interpolate between the two augmentations above ( Section 3.1 ) , and to overcome the observed trade-off , yielding models that are robust to unseen corruptions , while also maintaining clean accuracy ( Figure 1 , Section 4.1 ) . In doing so , it achieves a new state of the art in the Common Corruptions benchmark on CIFAR-C and ImageNet-C. ( Section 4.2 ) , which highlights that simple methods such as ours are competitive with complex training schemes designed for robustness . * We demonstrate that Patch Gaussian can be combined with other regularization strategies ( Section 4.3 ) and data augmentation policies ( Section 4.4 ) , and can improve COCO object detection performance as well ( Section 4.5 ) . * We perform a frequency-based analysis of models trained with Patch Gaussian and find that they can better leverage high-frequency information in lower layers , while not being too sensitive to them at later ones ( Section 5.1 ) We are open to suggestions of further experiment proposals that could convince the reviewer of this ."}, {"review_id": "HkxWXkStDB-1", "review_text": "This paper proposes a data augmentation method that interpolates between two existing methods (Cutout and Gaussian), for training robust models towards Gaussian and naturally occurring corruptions. The method is shown to improve robustness without sacrificing accuracy on clean data. Pros: The proposed method, despite being simple, seems to empirically work well in terms of the mCE criterion evaluated in the experiments. This does support the authors\u2019 claim that current methods haven\u2019t reached the robustness/accuracy tradeoff boundary yet. Cons: I\u2019m a bit concerned about the significance of the work though. The method is a straight-forward combination of existing methods, so methodologically the novelty is kind of limited. Hence, I\u2019m expecting more insights from the analysis of the results, to gain more understanding of why it works so well. However, the presentation of the experiments just seems to aim for the best numbers one can get (I\u2019m not certain how significant the numbers are to this field though). A few examples/pictures of success cases (when the method works) and failure cases (when the method doesn\u2019t work), may help readers (I\u2019m not an expert) to better understand the approach and get more intuitions? The frequency analysis seems quite intuitive. It\u2019s obvious that Gaussian filter blocks high-frequency components, and Cutout keeps some original parts of the image which allow high-freq details to be captured. But, considering CIFAR image size is only 32x32, a patch of size 25 is quite large, how much is the method different from plain whole image Gaussian then? ", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for the thoughtful comments . We provide some answers to the concerns raised below : > I \u2019 m a bit concerned about the significance of the work though . The method is a straight-forward combination of existing methods , so methodologically the novelty is kind of limited . We agree that the method presented is very simple . However , we \u2019 d like to emphasize that this was done by design . In showing that such a simple method can be competitive with state-of-the-art methods in the robustness literature , we show that complex training schemes may not be necessary for training models robust to unseen distributions . This is , we believe , where the significance of the work stems . Indeed , R1 mentioned that our method \u201c could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer , \u201d especially since it \u2019 s so easy to try . > I \u2019 m expecting more insights from the analysis of the results , to gain more understanding of why it works so well . In Section 5.1 , we provide an extensive frequency-based analysis and discussion of why Patch Gaussian works well : Patch Gaussian seems to allow high-frequency information through at lower layers , but still encourages relatively lower test error sensitivity at high frequencies . Indeed , when we measure accuracy on images filtered with a high-pass filter , we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout , where Gaussian fails to . See Figure 5 for full results . We will re-word this section to clarify these insights to future readers . > A few examples/pictures of success cases ( when the method works ) and failure cases ( when the method doesn \u2019 t work ) , may help readers ( I \u2019 m not an expert ) to better understand the approach and get more intuitions ? We thank the reviewer for the suggestion . We have not examined this but we hope to include it in camera-ready . In particular , we expect that images with higher Brightness will be among the most common errors , since Patch Gaussian slightly increases error ( mCE 0.592 ) in these corruptions with respect to the Baseline ( mCE 0.582 ) . ( see Table 7 in Appendix ) . > It \u2019 s obvious that Gaussian filter blocks high-frequency components , and Cutout keeps some original parts of the image which allow high-freq details to be captured We agree with the reviewer that these insights make intuitive sense . Our work provides a quantitative evaluation of this phenomenon to confirm this intuition . Further , through rigorous frequency-based sensitivity analysis we show that Patch Gaussian is able to retain both the high frequency sensitivity of Cutout and robustness gains of Gaussian augmentation . > a patch of size 25 is quite large , how much is the method different from plain whole image Gaussian then ? We remind the reviewer that , while the center of the patch needs to be inside the image , the edges can be outside . This means that , with a patch of size 25 , 39.55 % of the space is covered in expectation for an image of size 32 . Depending on the location of the patch , 16.50 % the space is covered ( minimum ) and other 61.04 % is covered ( maximum ) . In addition , our experimental results clearly show that patch Gaussian performs significantly differently from adding Gaussian noise to the whole image . For example , as shown in Table 1 in our paper , for a Resnet-50 model on ImageNet ( -C ) , Patch Gaussian gets a clean test accuracy of 76 % and mCE of 0.714 , whereas Gaussian data augmentation gets a clean test accuracy of 75.6 % and mCE of 0.739 ."}, {"review_id": "HkxWXkStDB-2", "review_text": "The paper proposes a novel data augmentations approach that improves the robustness of a model on the CIFAR-10 and ImageNet Common Corruptions benchmarks while maintaining training accuracy on clean data. To achieve this, the paper proposes a rather simple augmentation mechanism that is inspired by CutOut (DeVries & Taylor 2017) and Gaussian (Grandvalet & Kanu, 1997): adding Gaussian noise to random patches in the image. This simple approach is shown to work surprisingly well on the corruption benchmarks. It seems reasonable that while adding Gaussian noise makes the model robust to high frequency noise, since Gaussian noise is not added everywhere, the model is able to exploit high frequency signal when available in the input. The paper is reasonably well written and the experimental validation is convincing. Overall, the approach could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer. ", "rating": "8: Accept", "reply_text": "We thank the reviewer for the positive comments and helpful summary of our contributions . In particular , we appreciate the summary of the insights demonstrated with the frequency-based analysis ( Section 5.1 ) . We hope to incorporate a version of this summary in the camera-ready version as we believe it will be valuable to future readers ."}], "0": {"review_id": "HkxWXkStDB-0", "review_text": "This paper proposes a hybrid approach for adding noise to training images of an image classification model. Instead of either cutting out a patch or adding gaussian noise, the authors propose to adding a patch of gaussian noise to the images. Although possibly useful practically, this proposal lacks theoretical base on how and why it would be better, besides the claim that hopefully the combination will combine the benefit and subtract the weakness. The experiments are rather limitted to support the claim.", "rating": "3: Weak Reject", "reply_text": "> Although possibly useful practically We thank the reviewer for pointing out the practical applications of our method . Indeed , because it is so simple , \u201c the approach could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer , \u201d as R1 puts it . > this proposal lacks theoretical base on how and why it would be better We grant that our work started from an empirical observation . However , we provided an experimental analysis to gain a better understanding of why it works . In particular , Section 5.1 shows that Patch Gaussian seems to allow high-frequency information through at lower layers , but still encourages relatively lower test error sensitivity at high frequencies . Indeed , when we measure accuracy on images filtered with a high-pass filter , we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout , where Gaussian fails to . See Figure 5 for full results . R1 and R2 agree that our Fourier-theoretic analysis is intuitive . In addition , many practically useful techniques , such as Cutout , do not have completely rigorous mathematical analysis . > The experiments are rather limited to support the claim We show extensive experiments highlighting how Patch Gaussian is the only method that retains the benefits of Cutout and Gaussian : * We characterize a trade-off between robustness and accuracy among two standard data augmentations - Cutout and Gaussian ( Section 2.1 ) . Specifically , Cutout improves accuracy on clean test data . Despite this , we find it does not lead to increased robustness . Conversely , training with higher sigma of Gaussian can lead to increased robustness to Gaussian noise , but it also leads to decreased accuracy on clean data . Therefore , any robustness gains are offset by poor overall performance . * We show that our method ( Patch Gaussian ) allows us to interpolate between the two augmentations above ( Section 3.1 ) , and to overcome the observed trade-off , yielding models that are robust to unseen corruptions , while also maintaining clean accuracy ( Figure 1 , Section 4.1 ) . In doing so , it achieves a new state of the art in the Common Corruptions benchmark on CIFAR-C and ImageNet-C. ( Section 4.2 ) , which highlights that simple methods such as ours are competitive with complex training schemes designed for robustness . * We demonstrate that Patch Gaussian can be combined with other regularization strategies ( Section 4.3 ) and data augmentation policies ( Section 4.4 ) , and can improve COCO object detection performance as well ( Section 4.5 ) . * We perform a frequency-based analysis of models trained with Patch Gaussian and find that they can better leverage high-frequency information in lower layers , while not being too sensitive to them at later ones ( Section 5.1 ) We are open to suggestions of further experiment proposals that could convince the reviewer of this ."}, "1": {"review_id": "HkxWXkStDB-1", "review_text": "This paper proposes a data augmentation method that interpolates between two existing methods (Cutout and Gaussian), for training robust models towards Gaussian and naturally occurring corruptions. The method is shown to improve robustness without sacrificing accuracy on clean data. Pros: The proposed method, despite being simple, seems to empirically work well in terms of the mCE criterion evaluated in the experiments. This does support the authors\u2019 claim that current methods haven\u2019t reached the robustness/accuracy tradeoff boundary yet. Cons: I\u2019m a bit concerned about the significance of the work though. The method is a straight-forward combination of existing methods, so methodologically the novelty is kind of limited. Hence, I\u2019m expecting more insights from the analysis of the results, to gain more understanding of why it works so well. However, the presentation of the experiments just seems to aim for the best numbers one can get (I\u2019m not certain how significant the numbers are to this field though). A few examples/pictures of success cases (when the method works) and failure cases (when the method doesn\u2019t work), may help readers (I\u2019m not an expert) to better understand the approach and get more intuitions? The frequency analysis seems quite intuitive. It\u2019s obvious that Gaussian filter blocks high-frequency components, and Cutout keeps some original parts of the image which allow high-freq details to be captured. But, considering CIFAR image size is only 32x32, a patch of size 25 is quite large, how much is the method different from plain whole image Gaussian then? ", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for the thoughtful comments . We provide some answers to the concerns raised below : > I \u2019 m a bit concerned about the significance of the work though . The method is a straight-forward combination of existing methods , so methodologically the novelty is kind of limited . We agree that the method presented is very simple . However , we \u2019 d like to emphasize that this was done by design . In showing that such a simple method can be competitive with state-of-the-art methods in the robustness literature , we show that complex training schemes may not be necessary for training models robust to unseen distributions . This is , we believe , where the significance of the work stems . Indeed , R1 mentioned that our method \u201c could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer , \u201d especially since it \u2019 s so easy to try . > I \u2019 m expecting more insights from the analysis of the results , to gain more understanding of why it works so well . In Section 5.1 , we provide an extensive frequency-based analysis and discussion of why Patch Gaussian works well : Patch Gaussian seems to allow high-frequency information through at lower layers , but still encourages relatively lower test error sensitivity at high frequencies . Indeed , when we measure accuracy on images filtered with a high-pass filter , we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout , where Gaussian fails to . See Figure 5 for full results . We will re-word this section to clarify these insights to future readers . > A few examples/pictures of success cases ( when the method works ) and failure cases ( when the method doesn \u2019 t work ) , may help readers ( I \u2019 m not an expert ) to better understand the approach and get more intuitions ? We thank the reviewer for the suggestion . We have not examined this but we hope to include it in camera-ready . In particular , we expect that images with higher Brightness will be among the most common errors , since Patch Gaussian slightly increases error ( mCE 0.592 ) in these corruptions with respect to the Baseline ( mCE 0.582 ) . ( see Table 7 in Appendix ) . > It \u2019 s obvious that Gaussian filter blocks high-frequency components , and Cutout keeps some original parts of the image which allow high-freq details to be captured We agree with the reviewer that these insights make intuitive sense . Our work provides a quantitative evaluation of this phenomenon to confirm this intuition . Further , through rigorous frequency-based sensitivity analysis we show that Patch Gaussian is able to retain both the high frequency sensitivity of Cutout and robustness gains of Gaussian augmentation . > a patch of size 25 is quite large , how much is the method different from plain whole image Gaussian then ? We remind the reviewer that , while the center of the patch needs to be inside the image , the edges can be outside . This means that , with a patch of size 25 , 39.55 % of the space is covered in expectation for an image of size 32 . Depending on the location of the patch , 16.50 % the space is covered ( minimum ) and other 61.04 % is covered ( maximum ) . In addition , our experimental results clearly show that patch Gaussian performs significantly differently from adding Gaussian noise to the whole image . For example , as shown in Table 1 in our paper , for a Resnet-50 model on ImageNet ( -C ) , Patch Gaussian gets a clean test accuracy of 76 % and mCE of 0.714 , whereas Gaussian data augmentation gets a clean test accuracy of 75.6 % and mCE of 0.739 ."}, "2": {"review_id": "HkxWXkStDB-2", "review_text": "The paper proposes a novel data augmentations approach that improves the robustness of a model on the CIFAR-10 and ImageNet Common Corruptions benchmarks while maintaining training accuracy on clean data. To achieve this, the paper proposes a rather simple augmentation mechanism that is inspired by CutOut (DeVries & Taylor 2017) and Gaussian (Grandvalet & Kanu, 1997): adding Gaussian noise to random patches in the image. This simple approach is shown to work surprisingly well on the corruption benchmarks. It seems reasonable that while adding Gaussian noise makes the model robust to high frequency noise, since Gaussian noise is not added everywhere, the model is able to exploit high frequency signal when available in the input. The paper is reasonably well written and the experimental validation is convincing. Overall, the approach could become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer. ", "rating": "8: Accept", "reply_text": "We thank the reviewer for the positive comments and helpful summary of our contributions . In particular , we appreciate the summary of the insights demonstrated with the frequency-based analysis ( Section 5.1 ) . We hope to incorporate a version of this summary in the camera-ready version as we believe it will be valuable to future readers ."}}