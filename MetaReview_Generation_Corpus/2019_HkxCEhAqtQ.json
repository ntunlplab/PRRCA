{"year": "2019", "forum": "HkxCEhAqtQ", "title": "Accelerated Gradient Flow for Probability Distributions", "decision": "Reject", "meta_review": "This paper developed an accelerated gradient flow in the space of probability measures. Unfortunately, the reviewers think the practical usefulness of the proposed approach is not sufficiently supported by realistic experiments, and the clarity of the paper need to be significantly improved. The authors' rebuttal resolved some of the confusion the reviewers had, but we believe further substantial improvement will make this work a much stronger contribution. ", "reviews": [{"review_id": "HkxCEhAqtQ-0", "review_text": "This paper derives accelerated gradient flow formula in the space of probability measures from the view of optimal control formalism. The generalization of variational formulation from finite space to the space of probability measures seems new, but the resulting PDE seems to be a known result, which is the Fokker-Planck equation (with some minor modifications) for the 2nd order Langevin dynamic. From this point of view, the resulting algorithm from the derived PDE seems not having much practical advantage over SGHMC (a stochastic version of 2nd order Langevin dynamics). Actually, I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary. One can get the same formula by deriving it from Wasserstein gradient flows. When considering the functional as relative entropy, one can derive the formula simply from the Fokker-Planck equation of 2nd order Langevin dynamics. As a result, the proposed methods seems to be a new way to derive the Wasserstein gradient flow (or Fokker-Planck equation), which does not make impact the algorithm, e.g., both ways result in the same algorithm. Besides, I found the writing needs to be improved. There are a lot of background missing, or the descriptions are not clear enough. For example: 1. Page 2: the divergence operator is not defined, though I think it is a standard concept, but would be better to define it. 2. Page 2: the Wasserstein gradient and Gateaux derivative are not defined, what are the specific meanings of \\nabla_\\rho F(\\rho) and \\partial F / \\partial \\rho? 3. 1st line in Section 2: convex function f of d real variables seems odd, I guess the author means argument of f is d-dimensional variable. 4. Section 2, the authors directly start with the variational problem (3) without introducing the problem. Why do we need to variational problem? It would be hard to follow for some one who does not have such background. 5. Similarly, what is the role of Lyapunov function here in (6)? Why do we need it? 6. Why do you define the Lagrangian L in the form of (10)? What is the relation between (10) and (2)? 7. It is not clear what \"The stochastic process (X_t, Y_t) is Gaussian\" means in Proposition 1? It might need to be rephrased. 8. Second last line in page 5: I guess \\nabla \\log(\\rho) should be \\nabla\\log(\\rho_t). For the theory, I think eq.15 only applies when the PDE, e.g. (13), is solved exactly, thus there is not too much practical impact, as it is well known from the Wasserstein gradient theory that the PDE decays exponentially, as stated in the theorem. When considering numerical solutions, I think this results is useless. For the relation with SGHMC, let's look at eq.16. Actually, the derivative of the log term \\nabla \\log \\rho_t(X_t)) is equivalent to a brownian motion term. This can be seen by considering the Fokker-Planck equation for Brownian motion, which is exactly d \\rho_t = \\Delta \\rho_t. Consequently, instead of using the numerical approximations proposed later, one cane simply replacing this term with a Brownian motion term, which reduces to SGHMC (with some constant multipliers in front). The authors then shows empirically that the proposed method is better than SGHMC, which I think only comes from the numerical methods. For the kernel approximation, it makes the particles in the algorithm interactive. This resembles other particle optimization based algorithms such as SVGD, or the latest particle interactive SGLD proposed in [1] or [2[. I think these methods need to be compared. [1] Chen et al (2018), A Unified Particle-Optimization Framework for Scalable Bayesian Sampling. [2] Liu et al (2018), https://arxiv.org/pdf/1807.01750.pdf To sum up, though the derivation of accelerated gradient flow formula seems interesting, the resulting algorithm does not seem benefit from this derivation. The algorithm seems to be able to derived from a more direct way of using Wasserstein gradient flows, which results in a Wasserstein gradient flow for 2nd order Langevin dynamics, and is thus well known. The experiments are not convincing, and fail to show the advantage of the proposed method. The proposed method needs to be compared with other related methods.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for reviewing the paper and for providing several helpful comments . \u201c .. the resulting PDE seems to be a known result , which is the Fokker-Planck equation for the 2nd order Langevin dynamic. \u201d It appears that the main concern of the reviewer is that the accelerated gradient flow proposed in our paper is the same as the second order Langevin equation or SGHMC ? We would like to clarify that this is not the case for the second order equation considered in this paper . For a first order Langevin equation , it is indeed true that the Brownian motion and $ \\nabla log ( p ) $ yield the same distribution . In other words , if one replaces the Brownian motion with $ \\nabla log ( p ) $ in the first order Langevin equation , the resulting Fokker-Planck equation and thus the distribution remains the same . However , this property does not hold for the second order Langevin equation considered in this paper . In the second order system , we are dealing with the joint distribution on position and momentum . If one replaces the Brownian motion ( in the momentum update ) with $ \\nabla log ( p ) $ where $ p $ is the marginal on the position , the resulting Fokker-Planck equations are different . Consequently , the distributions are also different . Since this is an important point , we have included a new section ( Appendix D ) as part of the supplementary material in the paper to show the difference between the first order and the second order cases . \u201c .. Actually , I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary .. \u201d Variational formulation of fundamental equations is a cornerstone of Mathematics . 1.Lagrangian mechanics is a variational formulation of Newtonian mechanics ; 2 . Feynman \u2019 s path integral formulation of quantum mechanics ; 3 . For the Fokker-Planck equation , the celebrated gradient flow construction of the Jordan- Kinderlehrer-Otto ; 4 . Finally , Wibisono et . al.is itself a variational formulation of the Nesterov ode ( which has been known since 1980-s ) . ` 5.As noted in the introduction , the objective of this paper is to generalize Wibisono el . al . ( 2016 ) .So a variational construction is natural . In all these cases 1-4 , variational formulations have been worthy of study not only for numerical reasons but also because of their rich mathematical structure , geometric aspects which makes the derivation of models and algorithms independent of the choice of coordinates , first integrals and Lyapunov function which provides insights into conserved quantities and convergence analysis etc . Variational formulations have also been useful for numerics , e.g. , development of symplectic integrators . \u201c \u2026 One can get the same formula by deriving it from Wasserstein gradient flows . \u201d We disagree that the proposed accelerated algorithm can be derived using Wasserstein gradient flows . Or at least , we are not aware of how to do that. `` ... though the derivation of accelerated gradient flow formula seems interesting , the resulting algorithm does not seem benefit from this derivation '' The concern of the reviewer is justified . The numerical algorithm is obtained from discretizing the Hamilton \u2019 s equations ( 16 ) . These equations are directly derived from the variational formulation . One may try to obtain the numerical algorithm directly from the variational formulation by discretizing ( in both time and space ) the Lagrangian directly . For example , the symplectic integration is the result of such a time discretization . We believe that it is possible express the variational problem in terms of particles in the Gaussian setting with the solution given by the proposed numerical algorithm in the Gaussian settings . However , doing so in more general setting is beyond the scope of this paper . \u201c The authors then shows empirically that the proposed method is better than SGHMC , which I think only comes from the numerical methods. \u201d Regarding the numerical comparison , the revised version of the paper includes comparison to MCMC , HMCMC ( which is the same as the second order Langevin equation ) , and a method based on the density estimation . Please note that , as clearly described in the Introduction , the main contribution of the paper is the variational formulation and the generalization of the Wibisono et . al.and not the numerical algorithm in of itself . The numerical experiments are included to illustrate the theoretical results ( e.g. , accelerated convergence rates ) , show the potential and limitations of the proposed algorithm ( e.g. , bias-variance tradeoff depicted in Fig.3 ( d ) and computational complexity depicted in Fig.3 ( c ) , and provide some preliminary comparisons with MCMC and HMCMC ( Fig.3 ) .We do not claim that the proposed algorithm is better than all the existing algorithms . Such a claim will require extensive numerical experiments which are outside the scope of this paper ."}, {"review_id": "HkxCEhAqtQ-1", "review_text": "The articles adapt the framework developed in Wibisono & al to the (infinite dimensional) setting consisting in carrying out gradient descent in the space of probability distributions. PROS: - the text is well written, with clear references to the literature and a high-level description of the current state-of-the-art. - there is a good balance between mathematical details and high-level descriptions of the methods - although I have not been able to check all the details of the proofs, the results appear to be correct. CONS: - while I think that this type of article is interesting, I was really frustrated to discover at the end that the proposed methods either rely on strong Gaussian assumptions, or \"density estimations\". In other words, no \"practical\" method is really proposed. - no comparison with other existing method is provided. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for reviewing the paper and for providing insightful comments . \u201c No comparison with other existing method is provided. \u201d The paper has been revised to now include a comparison with the MCMC and Hamiltonian MCMC algorithms . The comparison is described in Sec 4.3 and the results of the comparison ( accuracy and computational time ) are depicted in Figure 3 . \u201c \u2026 the proposed methods either rely on strong Gaussian assumptions or density estimation. \u201d We would like to clarify that the proposed kernel algorithm does not involve explicit estimation of the density as an intermediate step . 1.We have included Remark 3 which clarifies the difference between the proposed kernel algorithm and an algorithm based on an explicit density estimation . 2.We have included results of numerical experiments comparing the kernel algorithm and the density estimation-based algorithm . Results appear in Figure-3- ( a ) - ( d ) in Sec.4.3.3.In order to avoid the confusion with the density estimation , we now refer to the kernel approximation as the diffusion-map approximation . The algorithm based on Gaussian approximation is included because of its relationship to the Nesterov ode ( see Remark 2 ) . Also , the algorithm may be useful in the cases where the density is unimodal ( see the discussion following equation ( 18 ) in the paper ) . Finally , we note that the proposed form of the interaction term arises as a solution of the variational problem ( which is the main contribution of our paper ) . The theoretical results together with the positive preliminary numerical comparisons are likely to spur future work to develop more computationally efficient algorithms to approximate the interaction term ."}, {"review_id": "HkxCEhAqtQ-2", "review_text": "Summary: This paper introduces a functional extension of the Bregman Lagrangian framework of Wibisono et al. 2016. The basic idea is to define accelerated gradient flows on the space of probability distribution. Because the defined flows include a term depending on the current distribution of the system, which is difficult to compute in general, the authors introduce an interacting particle approximation as a practical numerical approximation. The experiments are a proof-of-concept on simple illustrative toy examples. Quality: The ideas are generally of high quality, but I think there might some typos (or at least some notation I did not understand). In particular - tilde{F} is not defined for Table 1 - the lyapunov function for the vector column of table one includes a term referring to the functional over rho. I think this is a typo and should be f(x) - f(xmin) instead. Clarity: The paper is generally clear throughout. Originality & Significance: The paper is original to my knowledge, and a valuable extension to the interesting literature on the Bregman Lagrangian. The problem of simulating from probability distributions is an important one and this is an interesting connection between that problem and optimization. Pros: - An interesting extension that may fuel future study. Cons: - This algorithm appears naively to have an O(n^2) complexity per iteration, which is very expensive in terms of the number of particles. Most MCMC algorithms would have only O(n) complexity in the number of particles. This limits its applicability. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for reviewing the paper and for providing insightful comments . \u201c This algorithm appears naively to have an O ( n^2 ) complexity per iteration , which is very expensive in terms of the number of particles. \u201d This is an important criticism . As part of comparison with MCMC , we have included figure-3- ( c ) which highlights the O ( n^2 ) complexity of the proposed algorithm compared to O ( n ) complexity of MCMC . In the revised version of the paper , we have now included text on the algorithm complexity and some approaches to ameliorate it : ( i ) exploiting the sparsity structure of the NxN matrix ; ( ii ) sub-sampling the particles in computing the empirical averages ; ( iii ) adaptively updating the NxN matrix according to a certain error criteria . The notational issues in Table-1 have been fixed in the revised version of the paper ."}], "0": {"review_id": "HkxCEhAqtQ-0", "review_text": "This paper derives accelerated gradient flow formula in the space of probability measures from the view of optimal control formalism. The generalization of variational formulation from finite space to the space of probability measures seems new, but the resulting PDE seems to be a known result, which is the Fokker-Planck equation (with some minor modifications) for the 2nd order Langevin dynamic. From this point of view, the resulting algorithm from the derived PDE seems not having much practical advantage over SGHMC (a stochastic version of 2nd order Langevin dynamics). Actually, I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary. One can get the same formula by deriving it from Wasserstein gradient flows. When considering the functional as relative entropy, one can derive the formula simply from the Fokker-Planck equation of 2nd order Langevin dynamics. As a result, the proposed methods seems to be a new way to derive the Wasserstein gradient flow (or Fokker-Planck equation), which does not make impact the algorithm, e.g., both ways result in the same algorithm. Besides, I found the writing needs to be improved. There are a lot of background missing, or the descriptions are not clear enough. For example: 1. Page 2: the divergence operator is not defined, though I think it is a standard concept, but would be better to define it. 2. Page 2: the Wasserstein gradient and Gateaux derivative are not defined, what are the specific meanings of \\nabla_\\rho F(\\rho) and \\partial F / \\partial \\rho? 3. 1st line in Section 2: convex function f of d real variables seems odd, I guess the author means argument of f is d-dimensional variable. 4. Section 2, the authors directly start with the variational problem (3) without introducing the problem. Why do we need to variational problem? It would be hard to follow for some one who does not have such background. 5. Similarly, what is the role of Lyapunov function here in (6)? Why do we need it? 6. Why do you define the Lagrangian L in the form of (10)? What is the relation between (10) and (2)? 7. It is not clear what \"The stochastic process (X_t, Y_t) is Gaussian\" means in Proposition 1? It might need to be rephrased. 8. Second last line in page 5: I guess \\nabla \\log(\\rho) should be \\nabla\\log(\\rho_t). For the theory, I think eq.15 only applies when the PDE, e.g. (13), is solved exactly, thus there is not too much practical impact, as it is well known from the Wasserstein gradient theory that the PDE decays exponentially, as stated in the theorem. When considering numerical solutions, I think this results is useless. For the relation with SGHMC, let's look at eq.16. Actually, the derivative of the log term \\nabla \\log \\rho_t(X_t)) is equivalent to a brownian motion term. This can be seen by considering the Fokker-Planck equation for Brownian motion, which is exactly d \\rho_t = \\Delta \\rho_t. Consequently, instead of using the numerical approximations proposed later, one cane simply replacing this term with a Brownian motion term, which reduces to SGHMC (with some constant multipliers in front). The authors then shows empirically that the proposed method is better than SGHMC, which I think only comes from the numerical methods. For the kernel approximation, it makes the particles in the algorithm interactive. This resembles other particle optimization based algorithms such as SVGD, or the latest particle interactive SGLD proposed in [1] or [2[. I think these methods need to be compared. [1] Chen et al (2018), A Unified Particle-Optimization Framework for Scalable Bayesian Sampling. [2] Liu et al (2018), https://arxiv.org/pdf/1807.01750.pdf To sum up, though the derivation of accelerated gradient flow formula seems interesting, the resulting algorithm does not seem benefit from this derivation. The algorithm seems to be able to derived from a more direct way of using Wasserstein gradient flows, which results in a Wasserstein gradient flow for 2nd order Langevin dynamics, and is thus well known. The experiments are not convincing, and fail to show the advantage of the proposed method. The proposed method needs to be compared with other related methods.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for reviewing the paper and for providing several helpful comments . \u201c .. the resulting PDE seems to be a known result , which is the Fokker-Planck equation for the 2nd order Langevin dynamic. \u201d It appears that the main concern of the reviewer is that the accelerated gradient flow proposed in our paper is the same as the second order Langevin equation or SGHMC ? We would like to clarify that this is not the case for the second order equation considered in this paper . For a first order Langevin equation , it is indeed true that the Brownian motion and $ \\nabla log ( p ) $ yield the same distribution . In other words , if one replaces the Brownian motion with $ \\nabla log ( p ) $ in the first order Langevin equation , the resulting Fokker-Planck equation and thus the distribution remains the same . However , this property does not hold for the second order Langevin equation considered in this paper . In the second order system , we are dealing with the joint distribution on position and momentum . If one replaces the Brownian motion ( in the momentum update ) with $ \\nabla log ( p ) $ where $ p $ is the marginal on the position , the resulting Fokker-Planck equations are different . Consequently , the distributions are also different . Since this is an important point , we have included a new section ( Appendix D ) as part of the supplementary material in the paper to show the difference between the first order and the second order cases . \u201c .. Actually , I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary .. \u201d Variational formulation of fundamental equations is a cornerstone of Mathematics . 1.Lagrangian mechanics is a variational formulation of Newtonian mechanics ; 2 . Feynman \u2019 s path integral formulation of quantum mechanics ; 3 . For the Fokker-Planck equation , the celebrated gradient flow construction of the Jordan- Kinderlehrer-Otto ; 4 . Finally , Wibisono et . al.is itself a variational formulation of the Nesterov ode ( which has been known since 1980-s ) . ` 5.As noted in the introduction , the objective of this paper is to generalize Wibisono el . al . ( 2016 ) .So a variational construction is natural . In all these cases 1-4 , variational formulations have been worthy of study not only for numerical reasons but also because of their rich mathematical structure , geometric aspects which makes the derivation of models and algorithms independent of the choice of coordinates , first integrals and Lyapunov function which provides insights into conserved quantities and convergence analysis etc . Variational formulations have also been useful for numerics , e.g. , development of symplectic integrators . \u201c \u2026 One can get the same formula by deriving it from Wasserstein gradient flows . \u201d We disagree that the proposed accelerated algorithm can be derived using Wasserstein gradient flows . Or at least , we are not aware of how to do that. `` ... though the derivation of accelerated gradient flow formula seems interesting , the resulting algorithm does not seem benefit from this derivation '' The concern of the reviewer is justified . The numerical algorithm is obtained from discretizing the Hamilton \u2019 s equations ( 16 ) . These equations are directly derived from the variational formulation . One may try to obtain the numerical algorithm directly from the variational formulation by discretizing ( in both time and space ) the Lagrangian directly . For example , the symplectic integration is the result of such a time discretization . We believe that it is possible express the variational problem in terms of particles in the Gaussian setting with the solution given by the proposed numerical algorithm in the Gaussian settings . However , doing so in more general setting is beyond the scope of this paper . \u201c The authors then shows empirically that the proposed method is better than SGHMC , which I think only comes from the numerical methods. \u201d Regarding the numerical comparison , the revised version of the paper includes comparison to MCMC , HMCMC ( which is the same as the second order Langevin equation ) , and a method based on the density estimation . Please note that , as clearly described in the Introduction , the main contribution of the paper is the variational formulation and the generalization of the Wibisono et . al.and not the numerical algorithm in of itself . The numerical experiments are included to illustrate the theoretical results ( e.g. , accelerated convergence rates ) , show the potential and limitations of the proposed algorithm ( e.g. , bias-variance tradeoff depicted in Fig.3 ( d ) and computational complexity depicted in Fig.3 ( c ) , and provide some preliminary comparisons with MCMC and HMCMC ( Fig.3 ) .We do not claim that the proposed algorithm is better than all the existing algorithms . Such a claim will require extensive numerical experiments which are outside the scope of this paper ."}, "1": {"review_id": "HkxCEhAqtQ-1", "review_text": "The articles adapt the framework developed in Wibisono & al to the (infinite dimensional) setting consisting in carrying out gradient descent in the space of probability distributions. PROS: - the text is well written, with clear references to the literature and a high-level description of the current state-of-the-art. - there is a good balance between mathematical details and high-level descriptions of the methods - although I have not been able to check all the details of the proofs, the results appear to be correct. CONS: - while I think that this type of article is interesting, I was really frustrated to discover at the end that the proposed methods either rely on strong Gaussian assumptions, or \"density estimations\". In other words, no \"practical\" method is really proposed. - no comparison with other existing method is provided. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for reviewing the paper and for providing insightful comments . \u201c No comparison with other existing method is provided. \u201d The paper has been revised to now include a comparison with the MCMC and Hamiltonian MCMC algorithms . The comparison is described in Sec 4.3 and the results of the comparison ( accuracy and computational time ) are depicted in Figure 3 . \u201c \u2026 the proposed methods either rely on strong Gaussian assumptions or density estimation. \u201d We would like to clarify that the proposed kernel algorithm does not involve explicit estimation of the density as an intermediate step . 1.We have included Remark 3 which clarifies the difference between the proposed kernel algorithm and an algorithm based on an explicit density estimation . 2.We have included results of numerical experiments comparing the kernel algorithm and the density estimation-based algorithm . Results appear in Figure-3- ( a ) - ( d ) in Sec.4.3.3.In order to avoid the confusion with the density estimation , we now refer to the kernel approximation as the diffusion-map approximation . The algorithm based on Gaussian approximation is included because of its relationship to the Nesterov ode ( see Remark 2 ) . Also , the algorithm may be useful in the cases where the density is unimodal ( see the discussion following equation ( 18 ) in the paper ) . Finally , we note that the proposed form of the interaction term arises as a solution of the variational problem ( which is the main contribution of our paper ) . The theoretical results together with the positive preliminary numerical comparisons are likely to spur future work to develop more computationally efficient algorithms to approximate the interaction term ."}, "2": {"review_id": "HkxCEhAqtQ-2", "review_text": "Summary: This paper introduces a functional extension of the Bregman Lagrangian framework of Wibisono et al. 2016. The basic idea is to define accelerated gradient flows on the space of probability distribution. Because the defined flows include a term depending on the current distribution of the system, which is difficult to compute in general, the authors introduce an interacting particle approximation as a practical numerical approximation. The experiments are a proof-of-concept on simple illustrative toy examples. Quality: The ideas are generally of high quality, but I think there might some typos (or at least some notation I did not understand). In particular - tilde{F} is not defined for Table 1 - the lyapunov function for the vector column of table one includes a term referring to the functional over rho. I think this is a typo and should be f(x) - f(xmin) instead. Clarity: The paper is generally clear throughout. Originality & Significance: The paper is original to my knowledge, and a valuable extension to the interesting literature on the Bregman Lagrangian. The problem of simulating from probability distributions is an important one and this is an interesting connection between that problem and optimization. Pros: - An interesting extension that may fuel future study. Cons: - This algorithm appears naively to have an O(n^2) complexity per iteration, which is very expensive in terms of the number of particles. Most MCMC algorithms would have only O(n) complexity in the number of particles. This limits its applicability. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for reviewing the paper and for providing insightful comments . \u201c This algorithm appears naively to have an O ( n^2 ) complexity per iteration , which is very expensive in terms of the number of particles. \u201d This is an important criticism . As part of comparison with MCMC , we have included figure-3- ( c ) which highlights the O ( n^2 ) complexity of the proposed algorithm compared to O ( n ) complexity of MCMC . In the revised version of the paper , we have now included text on the algorithm complexity and some approaches to ameliorate it : ( i ) exploiting the sparsity structure of the NxN matrix ; ( ii ) sub-sampling the particles in computing the empirical averages ; ( iii ) adaptively updating the NxN matrix according to a certain error criteria . The notational issues in Table-1 have been fixed in the revised version of the paper ."}}