{"year": "2019", "forum": "HJehSnCcFX", "title": "Inference of unobserved event streams with neural Hawkes particle smoothing", "decision": "Reject", "meta_review": "All reviewers agree to reject. While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance.", "reviews": [{"review_id": "HJehSnCcFX-0", "review_text": "This paper tackles a very important and practical problem in event stream planning. The problem is very interesting and the approach taken is standard. The presentation of the paper is not clear enough. The notations and definitions and methods are presented in a complicated way. It's difficult to follows. From the contribution point of view the paper looks like to be a combination of several existing and well developed approach: Neural Hawkes Process + particle smoothing + minimum bayes risk + alignment. It's not very surprising to see these elements together. It would have helped if the authors made it clear why each part is chosen and clearly state what is the novelty and contributed of the paper to the field. The paper in its current format is not ready for publication. But it's a good paper and can be turned to a good paper for the next venue.", "rating": "5: Marginally below acceptance threshold", "reply_text": "> It 's difficult to follows . Thanks for acknowledging the importance of the problem . We are sorry to hear that you found the paper too difficult to read in the limited time that you had available to review it . We worked quite hard on the exposition . If you have specific suggestions that could reduce the difficulty , we will be happy to consider them for the camera-ready version . > But it 's a good paper and can be turned to a good paper for the next venue . Thank you . We agree that \u201c it \u2019 s a good paper \u201d already . : ) You provide few comments about how it could be \u201c turned into a good paper for the next venue , \u201d so we are not sure of your reasons for wanting to delay its publication . > It would have helped if the authors made it clear why each part is chosen and clearly state what is the novelty and contributed of the paper to the field . Yes , this is why we wrote section 6 , \u201c Discussion. \u201d Could you please reread that section ? It begins : \u201c Our technical contribution is threefold , \u201d and goes on to clearly describe each contribution and its novelty and importance . > several existing and well developed approach : Neural Hawkes Process + particle smoothing + minimum bayes risk + alignment Actually , we are further developing methods that are still in their infancy and are under current investigation . NHP was first published in December 2017 and is being picked up by the community . Neural methods for particle smoothing were first published in June 2018 . Our alignment method required developing a new metric and alignment algorithm ( section 4 and Appendix C , including Algorithm 2 ) . These are not groundbreaking but they did require some thought . Our MBR method required developing a new approximate search method ( section 4 including Theorem 1 , and Appendix D including Algorithm 3 ) . We believe that the novel contributions of this paper are above threshold for publication in ICLR . There is a lot of material in this paper . The paper also includes strong experimental results that should be of interest to the ML community and that demonstrate the potential of our methods for applied work . We provided extensive pseudocode and will release our implementation ."}, {"review_id": "HJehSnCcFX-1", "review_text": "The authors propose a particle smoothing approach with an approximate minimum Bayes risk decoder to impute missing events in the Neural Hawkes Process (NHP). The main goal is to address the missing events problem in continuous-time event analysis, which is an important problem in practice. The core idea is within the framework of particle smoothing. To formulate the posterior distribution of the missing event, the authors consider both the left-to-right past events and the right-to-left future events. The paper first applies the NHP to capture both the observed and inferred missing events to learn a representation of the past events, and then uses a similar NHP to learn the representation of the observed events from the future. Based on the two representations, it then formulates the intensity function of the missing events and uses the thinning algorithm to sample different particles. Based on the proposed distribution, the paper also considers to decode a single prediction achieving the Minimum Bayes Risk. Experiments on synthetic datasets with 10 different initializations and two real datasets show that the proposed smoothing approach is better than the filtering baseline. In general, this paper considers an important problem which is under active research in literature recently. However, there are a few weaknesses of the paper that should be addressed. 1. The proposed technique is tightly connected to NHP, which could limit the applicability of the approach to other temporal point processes. The essential idea is similar to Bi-LSTM to learn the representation from both ends of a sequence of asynchronous temporal events. There are several different ways to represent the inter-event time to feed into the network other than NHP. Can the proposed method also be applied to other processes? 2. Within the particle filtering framework, each particle (hypothesis) is weighted by the likelihood of the sequence of observed events under that hypothesis. It turns out that the integral part of Equation 5 does not have an obvious analytical solution under NHP. Then, we first need a set of samples to approximate the likelihood evaluation. Later, we also need to sample particles. I am not quite convinced the computational efficiency of this approach in real applications of practice. Also, there is no analysis either empirically or analytically about the impact of the accumulative sampling errors on the inference performance. Furthermore, to learn the proposed distribution, the paper applies the REINFORCE algorithm under the proposed distribution q. But REINFORCE is known for large variance issue. Given that we already need lots of samples for the likelihood, it is unclear to me how stable the algorithm could be in practice. 3. The experimental evaluation is weak. For particle filtering and smoothing, it is known that the filtering techniques are candidates for solving the smoothing problem but perform poorly when T is large. That's why it is necessary to develop more sophisticated strategies for good smoothing algorithms. As a result, it is unfair to only compare the smoothing approach with the filtering baseline. Actually, what people really care about is how different techniques can behave in real data to impute realistic missing events. From this perspective, I suggest to use the QQ-plot to evaluate the goodness of fitting on the synthetic dataset. For example, given a sequence of events generated from an independent temporal point process, we can randomly delete events, and then apply different techniques, including Linderman et al. (2017), Shelton et al.(2018), to impute missing events. Finally, we can compare the imputed sequence of events with the groundtruth. In addition, sequential monte carlo approach often suffers from skewed particle issue where one particle gradually dominates all the other particles with no diversity. It is unclear how the proposed approach is able to handle this. One missing related paper is \"Learning Hawkes Processes from Short Doubly-Censored Event Sequences\" Section 5.2 can be significantly strengthened if comparing with at least one of these approaches. 4. The paper is fairly written. I had some trouble reading back and forth for understanding Figure 1 since it has long caption that is not self-contained. The annotation of Section 2 is also too heavy to quickly skim through to memorize. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "> it is unfair to only compare the smoothing approach with the filtering baseline . Well , what other baseline do you think we should compare with ? There is not a lot of previous work on this problem . We can see that Metropolis-Hastings would be a possible alternative , where the transition kernel proposes a single-event change ( insert , delete , or move ) . Unfortunately , this would be quite slow for a neural model like ours . The reason is that a proposed change early in the sequence will affect the LSTM state and hence the probability of all subsequent events . Thus , a single move takes O ( length of proposed complete sequence ) time to evaluate . Furthermore the Markov chain may mix slowly because a move that changes only one event may often lead to an incoherent sequence that will be rejected . The point of particle smoothing is essentially to avoid this kind of rejection by proposing a * coherent sequence of events * from an approximation q to the true posterior . We can ensure that it is coherent because we build it up from left to right ( taking the future into account ) . We \u2019 d be happy of course to propose Metropolis-Hastings as future work . It could even build on our present work by using a variant of our current proposal distribution as the core of a Metropolis-Hastings kernel -- which would resample the latent events on a given * interval * . However , we would be wary of developing this nontrivial extension within the current paper ; it is not an established baseline and would take a few additional pages to develop . The current submission already has too much material -- there are a lot of appendices , and the other reviewers seem to have found the submission to be overwhelming already . Another good piece of future work would be particle Gibbs or other particle MCMC algorithms , which would also build on our present work . > sequential monte carlo approach often suffers from skewed particle issue where one particle gradually dominates all the other particles with no diversity . This is indeed a danger in SMC approaches . But surely you don \u2019 t think that all SMC papers should be rejected just because they use SMC ? There are several techniques in the SMC community for \u201c rejuvenating \u201d a skewed ensemble , such as multinomial resampling , other forms of resampling , and the \u201c particle cascade. \u201d Any of these techniques could be combined with ours , and this is orthogonal to the technical contributions of our paper . > It is unclear how the proposed approach is able to handle this . In fact , our particle smoothing method is also intended to alleviate this issue . As you know , if we could achieve a perfect proposal distribution q that was proportional to p , then the particle weight p/q would be constant across all particles , completely eliminating the skew issue . So our paper shows how to improve the proposal distribution . Specifically , the reason that an SMC ensemble becomes skewed over time is that some of the proposed particles turn out to be less compatible with the future , and are reweighted to have a weight near 0 . Particle smoothing tries to incorporate the future into the proposal distribution so that this will not happen as badly . > what people really care about is how different techniques can behave in real data to impute realistic missing events . We certainly agree ! Which is why our section 4 ( backed by appendices C-D , including Algorithm 2 ) gives a sophisticated method for doing exactly that . Results from applying this method to impute missing events on real data are reported in section 5.2 , including the carefully designed Figure 3 . Could you please reread that material , and raise your score as appropriate to recognize the work that we did there ? You suggest Linderman et al . ( 2017 ) and Shelton et al . ( 2018 ) as if they would be appropriate baselines for this imputation task . However , those papers only apply to Hawkes processes . Please note that we did discuss them carefully in section 6 . ( Specifically : Our particle filtering baseline is already the SAME as Linderman et al . ( 2017 ) , just extended from the Hawkes process to the * neural * Hawkes process . Shelton et al . ( 2018 ) use MCMC , but their MCMC algorithm takes advantage of special properties of the Hawkes process . Unfortunately , those special properties no longer hold for the * neural * Hawkes process , which would therefore require a much slower MCMC algorithm , as noted above ; we haven \u2019 t tried that . ) ( You also suggest that Xu et al . ( 2017 ) is relevant . We are happy to cite it in the final version , but note that that paper focuses on quite a different kind of missing data -- \u201c short reads \u201d where a long sequence has been broken up and it is not known which pieces go together . The first author of that paper agreed that his paper isn \u2019 t directly comparable to our setting , when we corresponded with him before submission . )"}, {"review_id": "HJehSnCcFX-2", "review_text": "The paper presents an inference method (implicit distribution particle smoothing) for neural Hawkes processes that accounts for latent sequences of events that influence the observed trajectories. Quality + The paper combines ideas from multiple areas of machine learning to tackle a challenging task of inference in multivariate continuous-time settings. - The figures reported from the paper are comparative graphs with respect to particle filtering, and so the absolute level of performance of the methods is not characterized. Reporting of distribution of sample weights and or run-times/complexity would strengthen the paper. Clarity - notation is complex replete with symbols \"@\" and text in math formulas - It's not clear what p (\"the data model\") and p_miss (\"the missingness mechanism\") represent, and therefore why in equation 1: p(x,z) = p(xvz)p_miss(z| xvz) where v is the union symbol. In addition, how it's related to MAR and MNAR is unclear. If e.g. following Murphy, one writes MAR as: p(r|x_u, x_o) = p(r|x_o), r is a missingness vector, x_u is x unobserved, and x_o is x observed, then r corresponds to observation or not, whereas in the manuscript p_miss is on the values themselves, i.e. on the space where z={k_{i,j}@t_{i,j}} resides. We know, from the definition of MNAR that we can't use only the observed data to correctly infer the distributions of the missing values, and so while one can probabilistically predict in MNAR setting, their quality remains unknown. If none of the experiments touch upon MNAR data, perhaps it is possible to omit this part. Originality + the work is rich, complex, original, and uses leading methods from multiple areas of ML. Significance + the significance of this work could be high, as it may provide a way to conduct difficult inference in an effective way to produce increasingly flexible modeling of trajectories amidst partial observation. - however the exposition (particularly the experiments) does not fully demonstrate this.", "rating": "5: Marginally below acceptance threshold", "reply_text": "> We know , from the definition of MNAR that we ca n't use only the observed data to correctly infer the distributions of the missing values , and so while one can probabilistically predict in MNAR setting , their quality remains unknown . Sure , working with MNAR data is impossible without additional knowledge . But in our setting , we have that additional knowledge . The problem with MNAR is that JOINTLY identifying p and p_miss is impossible . If you observe few 50-year-olds on your survey , you ca n't know ( beyond your prior ) whether that \u2019 s because there are few 50-year-olds , or because 50-year-olds are very likely to omit their age . But joint identification is unnecessary if either ( 1 ) one has separate knowledge of the missingness distribution p_miss ( 2 ) one has separate knowledge of the complete-data distribution p That is : If we know at least one of the distributions , then we can still infer the other . Actually , both ( 1 ) and ( 2 ) hold in our present experiments . The E step of EM uses the current guess of p and p_miss to infer the posterior distribution of the missing values . That posterior is uncontroversially defined by the simple Bayesian formula ( 3 ) . ( 1 ) If p_miss is known and fixed , this gives a minor variant of ordinary EM . Ordinary EM makes the MAR assumption that the p_miss factor of ( 3 ) can be ignored . But we do n't need to ignore p_miss if we actually know it ! In our experiments , p_miss is MNAR but we do know it : we know that events of some types are always observed and events of other types are never observed . So , no problem ! ( 2 ) Conversely , if p is known because we estimated it FROM SOME COMPLETE DATA , then we can use incomplete data to learn the MNAR missingness distribution p_miss . This setting even lets us learn a fancy missingness mechanism , e.g. , some BiLSTM model that uses the context of an event to determine the probability of censoring it . We relegated this EM discussion to Appendix F since it is not used in our experiments . Appendix F says : \u201c In the more general MNAR scenario , we can extend the E-step to consider the not-at-random missingness mechanism ( see equation ( 7b ) below ) , but then we need both complete and incomplete sequences at training time in order to fit the parameters of the missingness mechanism ( unless these parameters are already known ) jointly with those of the neural Hawkes process . ... we describe the methods and provide MCEM pseudocode. \u201d > If none of the experiments touch upon MNAR data , perhaps it is possible to omit this part . Alas ( as we mentioned in the \u201c presentation of MAR and MNAR \u201d response ) , for missing data in event streams , nearly * every * setting is MNAR ! That is , the probability that z would be selected for censorship depends on the number and type of events in z . In particular , the second factor of ( 3 ) typically decreases exponentially in the number of missing events |z| , so it is not constant in z as required for MAR . In particular , our experimental setting is MNAR in a sense described at the end of this response . Because it happens to be a special case of MNAR , it would be possible through a notational trick to gloss over the MNAR issue and not call the reader \u2019 s attention to it . However , we thought this would be dangerous , so we would prefer to clarify this aspect of the exposition rather than deleting it . ( We did relegate part of the discussion to an appendix . ) Why dangerous ? We imagine that a reader might try to apply our method to a fairly simple situation where each event of type k has independent probability c_k of being censored . We fear that the reader might carelessly omit the p_miss factor if we don \u2019 t talk about it . However , that factor is necessary to avoid proposing too many missing events of those types that would NOT tend to be censored . E.g. , proposing 100 missing events of type k means that p_miss includes a factor of c_k ^ 100 . Thus , for c_k < 1 and especially for c_k < < 1 , the system should prefer -- other things equal -- to posit only 50 missing events . Intuitively , for 50 events to all have gone missing is not as improbable as for 100 events to have gone missing . It \u2019 s true that our reported experiments happen to have c_k = 1 ( that is , events of type k are * deterministically * missing ) , so this exponential decay does not occur : c_k ^ 100 == c_k ^50 . Nonetheless , to ensure that a future reader would handle the general case correctly , we prefer to give it some discussion . We can also add experiments with c_k = 0.5 to cement the expository point . Even our deterministic setting should still be regarded as MNAR , because c_k isn \u2019 t * always * 1 in our experiments . Rather , c_k = 1 or 0 depending on k. Thus , our p_miss factor can be either 1 or 0 ( making us MNAR ) . More precisely , p_miss = 0 if z includes events of a type k that would never go missing . This is the technical reason that our code never proposes such events \u2014 as explained at the bottom of page 14 ."}], "0": {"review_id": "HJehSnCcFX-0", "review_text": "This paper tackles a very important and practical problem in event stream planning. The problem is very interesting and the approach taken is standard. The presentation of the paper is not clear enough. The notations and definitions and methods are presented in a complicated way. It's difficult to follows. From the contribution point of view the paper looks like to be a combination of several existing and well developed approach: Neural Hawkes Process + particle smoothing + minimum bayes risk + alignment. It's not very surprising to see these elements together. It would have helped if the authors made it clear why each part is chosen and clearly state what is the novelty and contributed of the paper to the field. The paper in its current format is not ready for publication. But it's a good paper and can be turned to a good paper for the next venue.", "rating": "5: Marginally below acceptance threshold", "reply_text": "> It 's difficult to follows . Thanks for acknowledging the importance of the problem . We are sorry to hear that you found the paper too difficult to read in the limited time that you had available to review it . We worked quite hard on the exposition . If you have specific suggestions that could reduce the difficulty , we will be happy to consider them for the camera-ready version . > But it 's a good paper and can be turned to a good paper for the next venue . Thank you . We agree that \u201c it \u2019 s a good paper \u201d already . : ) You provide few comments about how it could be \u201c turned into a good paper for the next venue , \u201d so we are not sure of your reasons for wanting to delay its publication . > It would have helped if the authors made it clear why each part is chosen and clearly state what is the novelty and contributed of the paper to the field . Yes , this is why we wrote section 6 , \u201c Discussion. \u201d Could you please reread that section ? It begins : \u201c Our technical contribution is threefold , \u201d and goes on to clearly describe each contribution and its novelty and importance . > several existing and well developed approach : Neural Hawkes Process + particle smoothing + minimum bayes risk + alignment Actually , we are further developing methods that are still in their infancy and are under current investigation . NHP was first published in December 2017 and is being picked up by the community . Neural methods for particle smoothing were first published in June 2018 . Our alignment method required developing a new metric and alignment algorithm ( section 4 and Appendix C , including Algorithm 2 ) . These are not groundbreaking but they did require some thought . Our MBR method required developing a new approximate search method ( section 4 including Theorem 1 , and Appendix D including Algorithm 3 ) . We believe that the novel contributions of this paper are above threshold for publication in ICLR . There is a lot of material in this paper . The paper also includes strong experimental results that should be of interest to the ML community and that demonstrate the potential of our methods for applied work . We provided extensive pseudocode and will release our implementation ."}, "1": {"review_id": "HJehSnCcFX-1", "review_text": "The authors propose a particle smoothing approach with an approximate minimum Bayes risk decoder to impute missing events in the Neural Hawkes Process (NHP). The main goal is to address the missing events problem in continuous-time event analysis, which is an important problem in practice. The core idea is within the framework of particle smoothing. To formulate the posterior distribution of the missing event, the authors consider both the left-to-right past events and the right-to-left future events. The paper first applies the NHP to capture both the observed and inferred missing events to learn a representation of the past events, and then uses a similar NHP to learn the representation of the observed events from the future. Based on the two representations, it then formulates the intensity function of the missing events and uses the thinning algorithm to sample different particles. Based on the proposed distribution, the paper also considers to decode a single prediction achieving the Minimum Bayes Risk. Experiments on synthetic datasets with 10 different initializations and two real datasets show that the proposed smoothing approach is better than the filtering baseline. In general, this paper considers an important problem which is under active research in literature recently. However, there are a few weaknesses of the paper that should be addressed. 1. The proposed technique is tightly connected to NHP, which could limit the applicability of the approach to other temporal point processes. The essential idea is similar to Bi-LSTM to learn the representation from both ends of a sequence of asynchronous temporal events. There are several different ways to represent the inter-event time to feed into the network other than NHP. Can the proposed method also be applied to other processes? 2. Within the particle filtering framework, each particle (hypothesis) is weighted by the likelihood of the sequence of observed events under that hypothesis. It turns out that the integral part of Equation 5 does not have an obvious analytical solution under NHP. Then, we first need a set of samples to approximate the likelihood evaluation. Later, we also need to sample particles. I am not quite convinced the computational efficiency of this approach in real applications of practice. Also, there is no analysis either empirically or analytically about the impact of the accumulative sampling errors on the inference performance. Furthermore, to learn the proposed distribution, the paper applies the REINFORCE algorithm under the proposed distribution q. But REINFORCE is known for large variance issue. Given that we already need lots of samples for the likelihood, it is unclear to me how stable the algorithm could be in practice. 3. The experimental evaluation is weak. For particle filtering and smoothing, it is known that the filtering techniques are candidates for solving the smoothing problem but perform poorly when T is large. That's why it is necessary to develop more sophisticated strategies for good smoothing algorithms. As a result, it is unfair to only compare the smoothing approach with the filtering baseline. Actually, what people really care about is how different techniques can behave in real data to impute realistic missing events. From this perspective, I suggest to use the QQ-plot to evaluate the goodness of fitting on the synthetic dataset. For example, given a sequence of events generated from an independent temporal point process, we can randomly delete events, and then apply different techniques, including Linderman et al. (2017), Shelton et al.(2018), to impute missing events. Finally, we can compare the imputed sequence of events with the groundtruth. In addition, sequential monte carlo approach often suffers from skewed particle issue where one particle gradually dominates all the other particles with no diversity. It is unclear how the proposed approach is able to handle this. One missing related paper is \"Learning Hawkes Processes from Short Doubly-Censored Event Sequences\" Section 5.2 can be significantly strengthened if comparing with at least one of these approaches. 4. The paper is fairly written. I had some trouble reading back and forth for understanding Figure 1 since it has long caption that is not self-contained. The annotation of Section 2 is also too heavy to quickly skim through to memorize. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "> it is unfair to only compare the smoothing approach with the filtering baseline . Well , what other baseline do you think we should compare with ? There is not a lot of previous work on this problem . We can see that Metropolis-Hastings would be a possible alternative , where the transition kernel proposes a single-event change ( insert , delete , or move ) . Unfortunately , this would be quite slow for a neural model like ours . The reason is that a proposed change early in the sequence will affect the LSTM state and hence the probability of all subsequent events . Thus , a single move takes O ( length of proposed complete sequence ) time to evaluate . Furthermore the Markov chain may mix slowly because a move that changes only one event may often lead to an incoherent sequence that will be rejected . The point of particle smoothing is essentially to avoid this kind of rejection by proposing a * coherent sequence of events * from an approximation q to the true posterior . We can ensure that it is coherent because we build it up from left to right ( taking the future into account ) . We \u2019 d be happy of course to propose Metropolis-Hastings as future work . It could even build on our present work by using a variant of our current proposal distribution as the core of a Metropolis-Hastings kernel -- which would resample the latent events on a given * interval * . However , we would be wary of developing this nontrivial extension within the current paper ; it is not an established baseline and would take a few additional pages to develop . The current submission already has too much material -- there are a lot of appendices , and the other reviewers seem to have found the submission to be overwhelming already . Another good piece of future work would be particle Gibbs or other particle MCMC algorithms , which would also build on our present work . > sequential monte carlo approach often suffers from skewed particle issue where one particle gradually dominates all the other particles with no diversity . This is indeed a danger in SMC approaches . But surely you don \u2019 t think that all SMC papers should be rejected just because they use SMC ? There are several techniques in the SMC community for \u201c rejuvenating \u201d a skewed ensemble , such as multinomial resampling , other forms of resampling , and the \u201c particle cascade. \u201d Any of these techniques could be combined with ours , and this is orthogonal to the technical contributions of our paper . > It is unclear how the proposed approach is able to handle this . In fact , our particle smoothing method is also intended to alleviate this issue . As you know , if we could achieve a perfect proposal distribution q that was proportional to p , then the particle weight p/q would be constant across all particles , completely eliminating the skew issue . So our paper shows how to improve the proposal distribution . Specifically , the reason that an SMC ensemble becomes skewed over time is that some of the proposed particles turn out to be less compatible with the future , and are reweighted to have a weight near 0 . Particle smoothing tries to incorporate the future into the proposal distribution so that this will not happen as badly . > what people really care about is how different techniques can behave in real data to impute realistic missing events . We certainly agree ! Which is why our section 4 ( backed by appendices C-D , including Algorithm 2 ) gives a sophisticated method for doing exactly that . Results from applying this method to impute missing events on real data are reported in section 5.2 , including the carefully designed Figure 3 . Could you please reread that material , and raise your score as appropriate to recognize the work that we did there ? You suggest Linderman et al . ( 2017 ) and Shelton et al . ( 2018 ) as if they would be appropriate baselines for this imputation task . However , those papers only apply to Hawkes processes . Please note that we did discuss them carefully in section 6 . ( Specifically : Our particle filtering baseline is already the SAME as Linderman et al . ( 2017 ) , just extended from the Hawkes process to the * neural * Hawkes process . Shelton et al . ( 2018 ) use MCMC , but their MCMC algorithm takes advantage of special properties of the Hawkes process . Unfortunately , those special properties no longer hold for the * neural * Hawkes process , which would therefore require a much slower MCMC algorithm , as noted above ; we haven \u2019 t tried that . ) ( You also suggest that Xu et al . ( 2017 ) is relevant . We are happy to cite it in the final version , but note that that paper focuses on quite a different kind of missing data -- \u201c short reads \u201d where a long sequence has been broken up and it is not known which pieces go together . The first author of that paper agreed that his paper isn \u2019 t directly comparable to our setting , when we corresponded with him before submission . )"}, "2": {"review_id": "HJehSnCcFX-2", "review_text": "The paper presents an inference method (implicit distribution particle smoothing) for neural Hawkes processes that accounts for latent sequences of events that influence the observed trajectories. Quality + The paper combines ideas from multiple areas of machine learning to tackle a challenging task of inference in multivariate continuous-time settings. - The figures reported from the paper are comparative graphs with respect to particle filtering, and so the absolute level of performance of the methods is not characterized. Reporting of distribution of sample weights and or run-times/complexity would strengthen the paper. Clarity - notation is complex replete with symbols \"@\" and text in math formulas - It's not clear what p (\"the data model\") and p_miss (\"the missingness mechanism\") represent, and therefore why in equation 1: p(x,z) = p(xvz)p_miss(z| xvz) where v is the union symbol. In addition, how it's related to MAR and MNAR is unclear. If e.g. following Murphy, one writes MAR as: p(r|x_u, x_o) = p(r|x_o), r is a missingness vector, x_u is x unobserved, and x_o is x observed, then r corresponds to observation or not, whereas in the manuscript p_miss is on the values themselves, i.e. on the space where z={k_{i,j}@t_{i,j}} resides. We know, from the definition of MNAR that we can't use only the observed data to correctly infer the distributions of the missing values, and so while one can probabilistically predict in MNAR setting, their quality remains unknown. If none of the experiments touch upon MNAR data, perhaps it is possible to omit this part. Originality + the work is rich, complex, original, and uses leading methods from multiple areas of ML. Significance + the significance of this work could be high, as it may provide a way to conduct difficult inference in an effective way to produce increasingly flexible modeling of trajectories amidst partial observation. - however the exposition (particularly the experiments) does not fully demonstrate this.", "rating": "5: Marginally below acceptance threshold", "reply_text": "> We know , from the definition of MNAR that we ca n't use only the observed data to correctly infer the distributions of the missing values , and so while one can probabilistically predict in MNAR setting , their quality remains unknown . Sure , working with MNAR data is impossible without additional knowledge . But in our setting , we have that additional knowledge . The problem with MNAR is that JOINTLY identifying p and p_miss is impossible . If you observe few 50-year-olds on your survey , you ca n't know ( beyond your prior ) whether that \u2019 s because there are few 50-year-olds , or because 50-year-olds are very likely to omit their age . But joint identification is unnecessary if either ( 1 ) one has separate knowledge of the missingness distribution p_miss ( 2 ) one has separate knowledge of the complete-data distribution p That is : If we know at least one of the distributions , then we can still infer the other . Actually , both ( 1 ) and ( 2 ) hold in our present experiments . The E step of EM uses the current guess of p and p_miss to infer the posterior distribution of the missing values . That posterior is uncontroversially defined by the simple Bayesian formula ( 3 ) . ( 1 ) If p_miss is known and fixed , this gives a minor variant of ordinary EM . Ordinary EM makes the MAR assumption that the p_miss factor of ( 3 ) can be ignored . But we do n't need to ignore p_miss if we actually know it ! In our experiments , p_miss is MNAR but we do know it : we know that events of some types are always observed and events of other types are never observed . So , no problem ! ( 2 ) Conversely , if p is known because we estimated it FROM SOME COMPLETE DATA , then we can use incomplete data to learn the MNAR missingness distribution p_miss . This setting even lets us learn a fancy missingness mechanism , e.g. , some BiLSTM model that uses the context of an event to determine the probability of censoring it . We relegated this EM discussion to Appendix F since it is not used in our experiments . Appendix F says : \u201c In the more general MNAR scenario , we can extend the E-step to consider the not-at-random missingness mechanism ( see equation ( 7b ) below ) , but then we need both complete and incomplete sequences at training time in order to fit the parameters of the missingness mechanism ( unless these parameters are already known ) jointly with those of the neural Hawkes process . ... we describe the methods and provide MCEM pseudocode. \u201d > If none of the experiments touch upon MNAR data , perhaps it is possible to omit this part . Alas ( as we mentioned in the \u201c presentation of MAR and MNAR \u201d response ) , for missing data in event streams , nearly * every * setting is MNAR ! That is , the probability that z would be selected for censorship depends on the number and type of events in z . In particular , the second factor of ( 3 ) typically decreases exponentially in the number of missing events |z| , so it is not constant in z as required for MAR . In particular , our experimental setting is MNAR in a sense described at the end of this response . Because it happens to be a special case of MNAR , it would be possible through a notational trick to gloss over the MNAR issue and not call the reader \u2019 s attention to it . However , we thought this would be dangerous , so we would prefer to clarify this aspect of the exposition rather than deleting it . ( We did relegate part of the discussion to an appendix . ) Why dangerous ? We imagine that a reader might try to apply our method to a fairly simple situation where each event of type k has independent probability c_k of being censored . We fear that the reader might carelessly omit the p_miss factor if we don \u2019 t talk about it . However , that factor is necessary to avoid proposing too many missing events of those types that would NOT tend to be censored . E.g. , proposing 100 missing events of type k means that p_miss includes a factor of c_k ^ 100 . Thus , for c_k < 1 and especially for c_k < < 1 , the system should prefer -- other things equal -- to posit only 50 missing events . Intuitively , for 50 events to all have gone missing is not as improbable as for 100 events to have gone missing . It \u2019 s true that our reported experiments happen to have c_k = 1 ( that is , events of type k are * deterministically * missing ) , so this exponential decay does not occur : c_k ^ 100 == c_k ^50 . Nonetheless , to ensure that a future reader would handle the general case correctly , we prefer to give it some discussion . We can also add experiments with c_k = 0.5 to cement the expository point . Even our deterministic setting should still be regarded as MNAR , because c_k isn \u2019 t * always * 1 in our experiments . Rather , c_k = 1 or 0 depending on k. Thus , our p_miss factor can be either 1 or 0 ( making us MNAR ) . More precisely , p_miss = 0 if z includes events of a type k that would never go missing . This is the technical reason that our code never proposes such events \u2014 as explained at the bottom of page 14 ."}}