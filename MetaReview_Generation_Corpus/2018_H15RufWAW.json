{"year": "2018", "forum": "H15RufWAW", "title": "GraphGAN: Generating Graphs via Random Walks", "decision": "Reject", "meta_review": "This paper proposes an implicit model of graphs, trained adversarially using the Gumbel-softmax trick.  The main idea of feeding random walks to the discriminator is interesting and novel.  However,\n1) The task of generating 'sibling graphs', for some sort of bootstrap analysis, isn't well-motivated.\n2) The method is complicated and presumably hard to tune, with two separate early-stopping thresholds that need to be tuned\n3) There is not even a mention of a large existing literature on generative models of graphs using variational autoencoders.", "reviews": [{"review_id": "H15RufWAW-0", "review_text": "I am overall positive about the work but I would like to see some questions addressed. Quality: The paper is good but does not address some important issues. The paper proposes a GAN model to generate graphs with non-trivial properties. This is possibly one of the best papers on graph generation using GANs currently in the literature. However, there are a number of statistical issues that should be addressed. I fear the paper is not ready yet, but I am not opposed to publication as long as there are warnings in the paper about the shortcomings. Originality: This is an original approach. Random walks sometimes are overused in the graph literature, but they seem justified in this work. But it also requires extra work to ensure they are generating meaningful graphs. Significance: The problem is important. Learn to generate graphs is a key task in drug discovery, relational learning, and knowledge discovery. Evaluation: The link prediction task is too easy, as links are missing at random. It would be more useful to predict links that are removed with an unknown bias. The graph (wedge, claw, etc) characteristics are good (but simple) metrics; however, it is unclear how a random graph with the same size and degree distribution (configuration model) would generate for the same metrics (it is not shown for comparison). Issues that I wish were addressed in the paper: a) How is the method learning a generator from a single graph? What are the conditions under which the method is likely to perform well? It seems to rely on some mixing RW conditions to model the distinct graph communities. What are these mixing conditions? These are important questions that should have at least an empirical exploration. b) What is the spatial independence assumption needed for such a generator? c) Would this approach be able to generate a lattice? Would it be able to generate an expander graph? What about a graph with poorly connect communities? Is there any difficulties with power law graphs? d) How is the RW statistically addressing the generation of high-order (subgraph) features? e) Can this approach be used with multiple i.i.d. graphs? f) Isn\u2019t learning the random walk sample path a much harder / higher-dimensional task than it is necessary? Again, the short walk may be capturing the communities but the high-dimensional random walk sample path seems like a high price to pay to learn community structure. g) Clearly, with a large T (number of RW steps), the RW is not modeling just a single community. Is there a way to choose T? How larger values of T to better model inter-community links? Would different communities have different choices of T? h) And a related question, how well can the method generate the inter-community links? i) The RW model is actually similar to an HMM. Would learning a mixture of HMMs (one per community) have similar performance? ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and constructive feedback . We noticed that several of your questions ( a , c , f , g , h , i ) revolve around community structure . We would like to highlight that our model does not have access to community information at any point and more importantly does not have the goal of explicitly modeling communities . We address all your concerns below and additionally as you requested , we extended the discussion section to clearly highlight the model limitations ( see Section 5 in the revised manuscript ) . 1 ) Link prediction We replicated the experimental setup for link prediction that is standard in recent works ( [ 1 , 2 , 3 ] ) . We agree that different test set sampling strategies could provide a more in-depth analysis of our link prediction performance . However , our main goal is to demonstrate the feasibility and utility of implicit generative modeling for graphs , and not to develop a new state-of-the-art method for link prediction . This experiment mainly serves the purpose of demonstrating the generalization properties of the proposed method . On a related note , since implicit models for graph generation have not been studied so far , effective methods for their evaluation are yet to be developed . Therefore , we use the link prediction task as one possible way to evaluate our implicit model . This , together with the other experiments , gives us insight into the graph properties that our model is able to capture . 2 ) Configuration model Thank you for this suggestion . We have added results for the configuration model to Table 2 in the revised version , as well as to Table 6 in the appendix . Some properties of the graphs generated by the configuration model ( e.g. , degree distribution ) are identical to the input graph statistics by the definition of the configuration model . However , the random edge shuffling performed by the configuration model completely destroys the community structure , which makes the resulting graph very different from the original . Additionally , we have performed experiments , where only a fraction of edges are rewired by the configuration model , such that the edge overlap ( EO ) score of the rewired graph matches the EO score of GraphGAN . Still , even in such a scenario , the configuration model significantly alters the community structure . You can see the quantitative results in Table 2 of the revised version of the paper . Regarding your questions ( a ) - ( c ) ( questions ( d ) - ( i ) are in pt . 2 ) a ) Indeed , learning graph generators from a single graph is one of the key challenges tackled in our paper . In fact , part of our motivation for using RWs was precisely to solve this challenge ( see also ( f ) ) . Given the nature of the GAN framework we required multiple samples to train the generator . Thus we turn to using RWs since they naturally represent our single input graph with multiple samples . In this first foundational work we explored connected graphs ( by extracting the largest connected component as a preprocessing step ) . We did not investigate the behaviour of GraphGAN when we have e.g.many disconnected components . This could be considered as one condition for GraphGAN to perform well . Furthermore , the focus of this paper was to show that implicit graph generators are able to capture properties of the graph without manually specifying them . While our goal is not to determine the stationary distribution of RWs ( for which mixing conditions are relevant ) , we agree that drawing theoretical connections between GraphGAN and the established results is an exciting direction for future work . Please note that some empirical exploration of this aspect is already included ( Figure 4 , where we analyze the effect of RW length on link prediction performance ) . See also our answer to ( g ) . b ) Our model does not make * any * spatial dependence assumptions about the adjacency matrix , assuming you are referring to our discussion in paragraph 2 of Section 2 . The main point in the paper is that one should not naively treat the adjacency matrix as a binary image and apply standard CNN-based GAN architectures to it . Such architectures for images contain the built-in assumption that pixels located closely ( within the same receptive field ) are in some way correlated . Clearly , when talking about an adjacency matrix such assumption is not sensible , as permutations of rows/columns correspond to the exact same graph but very different receptive fields . Our model addresses this issue by operating on the random walks . c ) We are indeed able to generate graphs with power-law degree distributions and sparse connectivity . We can conclude this since our model was evaluated and shows good performance on real-world graphs , that all exhibit exactly those patterns ( see Table 6 ) . Since our focus is on complex real-world networks , we felt that experiments on toy graphs ( lattice , expander ) would distract from the main story ."}, {"review_id": "H15RufWAW-1", "review_text": "The authors proposed a generative model of random walks on graphs. Using GAN, the architecture allows for model-agnostic learning, controllable fitting, ensemble graph generation. It also produces meaningful node embeddings with semi-interpretable latent spaces. The overall framework could be relevant to multiple areas in graph analytics, including graph comparison, graph sampling, graph embedding and relational feature selection. The draft is well written with convincing experiments. I support the acceptances of this paper. I do have a few questions that might help further improve the draft. More baseline besides DC-SBM could better illustrate the power of GAN in learning longer random walk trajectories. DC-SBM, while a generative model, inherently can only capture first order random walks with target degree biases, and generally over-fits into degree sequences. Are there existing generative models based on walk paths? The choice of early stopping is a very interesting problem especially for the EO-creitenrion. In Fig3 (b), it seems assortativity is over-fitted beyond 40k iterations. It might be helpful to discuss more about the over-fitting of different graph properties. The node classification experiment could use a bit more refinement. The curves in Fig. 5(a) are not well explained. What is the \"combined\"? The claim of competitive performance needs better justification according to the presentation of the F1 scores. The Latent variable interpolation experiment could also use more explanations. How is the 2d subspace chosen? What is the intuition behind the random walks and graphs of Fig 6? Can you provide visualizations of the communities of the interpolated graphs in Fig 7? ", "rating": "7: Good paper, accept", "reply_text": "Thank you for comments . Based on your comments , we have a uploaded a revised version of our paper . See the details below . 1 ) Baselines Since our main goal is to develop an implicit model for graph generation the focus of the experimental evaluation was to show that the implicitly generated graphs are useful , rather than outperforming existing explicit generators ( most of which are designed with specific graph patterns in mind ) . Thus , we chose the well established DC-SBM as a baseline . In the revised version we have added new baselines ( on the suggestions of the reviewers ) such as the configuration model and ERGM . You can find the results for these in Table 2 . We are open to suggestions about further graph generation models we could compare to in order to highlight the properties and limitations of GraphGAN . 2 ) Generative models based on RWs The only remotely related model we are aware of that involves random walks is the Butterfly model ( McGlohon et al. , \u201c Weighted graphs and disconnected components : patterns and a generator '' , KDD \u2019 08 ) . However , it is a variant of the preferential attachment principle , and focuses on networks that grow over time . It uses first-order random walks , and thus can not capture higher-order interactions . Moreover , it is not applicable to our task since it generates the random walks on the fly ( i.e. , is not based on a set of random walks as input ) . 3 ) EO-criterion This is an interesting point , and we briefly talk about it in Section 3.2 . We can view the VAL and EO criteria as a trade-off between better generalization ( in terms of link prediction ) and more accurate reconstruction of the graph . Thus , as the EO score increases , our model approximates the distribution of random walks in the original graph more closely , which leads to constructing graphs more similar to the input , up to the point of overfitting the input graph . The EO criterion gives us control over this . 4 ) Node `` embeddings '' ( Figure 5 ) Thank you for pointing this out . We have updated this section and will briefly summarize the changes in the following . Using the term \u2018 embedding \u2019 was unfortunate in the figure . We were referring to W_down , i.e.the weight matrix projecting down the one-hot node vectors into low-dimensional space . The term \u2018 context \u2019 , on the other hand , was referring to W_up , which projects up the low-dimensional LSTM output . \u2018 Combined \u2019 was the concatenation of the W_up and W_down , which gave an additional small improvement over only using W_up . When using the term \u2018 competitive \u2019 we were referring to the link prediction performance , and not node classification ; we have made this distinction more clear in the revised version ( see , e.g. , the updated abstract ) . 5 ) Latent space interpolation ( Figures 6 , 7 ) We improved the wording in the revised paper . To summarize : The generator takes as input a noise vector z , drawn from a d-dimensional standard normal distribution . For the latent space interpolation experiment we set d=2 . That is , the generator receives samples drawn from a bivariate Gaussian distribution and transforms these into random walks . By using the inverse of the cumulative distribution of this 2D Gaussian distribution we can divide the input domain ( i.e.R^2 ) into bins of equal probability mass , and group the generated random walks into their respective bins based on the noise samples that were used to generate them . Based on these random walks , we construct the score matrix and assemble a graph using the procedure described in Section 3.3 . We can now measure the properties of the random walks coming from each of the latent space bins ( e.g.the average degree of the first node in the random walks : Figure 6a ) as well as the graphs constructed from the random walks ( e.g.Gini coefficient : Figure 6c ) and observe how these properties smoothly change when interpolating in the latent space . To better visualize the latent space interpolation performed in Figure 7 , we have compiled a short animation ( https : //figshare.com/articles/GraphGAN_Latent_Space_Interpolation/5684137 ) . In the bottom-right section , you can observe how the generated graphs \u2019 structure changes when interpolating along a trajectory in the latent space ."}, {"review_id": "H15RufWAW-2", "review_text": "This paper proposes a WGAN formulation for generating graphs based on random walks. The proposed generator model combines node embeddings, with an LSTM architecture for modeling the sequence of nodes visited in a random walk; the discriminator distinguishes real from fake walks. The model is learned from a single large input graph (for three real-world networks) and evaluated against one baseline generative graph model: degree-corrected stochastic block models. The primary claims of the paper are as follows: i) The proposed approach is a generative model of graphs, specifically producing \"sibling\" graphs ii) The learned latent representation provides an interpretation of generated graph properties iii) The model generalizes well in terms of link and node classification The proposed method is novel and the incorporated ideas are quite interesting (e.g., discriminating real from fake random walks, generating random walks from node embeddings and LSTMs). However, from a graph generation perspective, the problem formulation and evaluation do not sufficiently demonstrate the utility of proposed method. First, wrt claim (i) the problem of generating \"sibling\" graphs is ill-posed. Statistical graph models are typically designed to generate a probability distribution over all graphs with N nodes and, as such, are evaluated based on how well they model that distribution. The notion of a \"sibling\" graph used in this paper is not clearly defined, but it seems to only be useful if the sibling graphs are likely under the distribution. Unfortunately, the likelihood of the sampled graphs is not explicitly evaluated. On the other hand, since many of the edges are shared the \"siblings\" may be nearly isomorphic to the input graph, which is not useful from a graph modeling perspective. For claim (i), the comparison to related work is far from sufficient to demonstrate its utility as a graph generation model. There are many graph models that are superior to DC-SBM, including KPGMs, BETR, ERGMs, hierarchical random graph models and latent space models. Moreover, a very simple baseline to assess the LSTM component of the model, would be to produce a graph by sampling links repeatedly from the latent space of node embeddings. Next, the evaluation wrt to claim (ii) is novel and may help developers understand the model characteristics. However, since the properties are measured based on a set of random walks it is still difficult to interpret the impact on the generated graphs (since an arbitrary node in the final graph will have some structure determined from each of the regions). Do the various regions generate different parts of the final graph structure (i.e., focusing on only a subset of the nodes)? Lastly, the authors evaluate the learned model on link and node prediction tasks and state that the model's so-so performance supports the claim that the model can generalize. This is the weakest claim of the paper. The learned node embeddings appear to do significantly worse than node2vec, and the full model is worse than DC-SBM. Given that the proposed model is transductive (when there is significant edge overlap) it should do far better than DC-SBM which is inductive. Overall, while the paper includes a wide range of experimental evaluation, they are aimed too broadly (and the results are too weak) to support any specific claim of the work. If the goal is to generate transductively (with many similar edges), then it would be better to compare more extensively to alternative node embedding and matrix factorization approaches, and assess the utility of the various modeling choices (e.g., LSTM, in/out embedding). If the goal is to generate inductively, over the full distribution of graphs, then it would be better to (i) assess whether the sampled graphs are isomorphic, and (ii) compare more extensively to alternative graph models (many of which have been published since 2010). ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . We would like to clarify some important points that might have been a source of misunderstanding . As this is the first work of its kind ( implicit generative model for graphs ) , we neither expect nor claim that GraphGAN in its current form is superior to every existing explicit model in every possible regard . Rather , our goal is to lay a foundation for the study of implicit models for graph generation . Such models will let us capture important properties of real-world graphs , without having to manually specify them in our models . We are convinced that the results already confirm this statement , and show the feasibility and utility of implicit models . Still , based on your suggestions , we added a comparison with more baselines . As expected , and reinforcing our previous point , all properties which these approaches explicitly model are preserved , while the rest deviate significantly from the input graph . This highlights the need for implicit models , such as the one proposed in our paper . Furthermore , there exist properties not captured by any of the existing models as shown in [ 1 ] , which again emphasizes the need for implicit models . We have already analyzed the reconstructive ( graph statistics ) and generalization ( link prediction ) properties of our model . As you mentioned , because of the likelihood-free nature of the model , we can not evaluate the likelihood of the held-out edges or an entire sampled graph . We are not aware of other experimental protocols applicable to this novel problem setting . If you think that some important aspects are not evaluated , please let us know . Using your terminology GraphGAN would be considered inductive . In the revised version we include comparison with more baselines . However , we do not completely agree that \u201c high edge overlap \u201d = > \u201c transductive \u201d ( above which EO threshold does a model qualify ? ) . This definition would mean that ERGM , which has high edge overlap ( see Table 2 ) , should be considered transductive , which it isn \u2019 t . We would also like to clarify , that our model is * not * generating random walks from node embeddings , and is not yet another method for learning node embeddings . Please , see our discussion on embeddings below . In the following comment we address your other concerns ."}], "0": {"review_id": "H15RufWAW-0", "review_text": "I am overall positive about the work but I would like to see some questions addressed. Quality: The paper is good but does not address some important issues. The paper proposes a GAN model to generate graphs with non-trivial properties. This is possibly one of the best papers on graph generation using GANs currently in the literature. However, there are a number of statistical issues that should be addressed. I fear the paper is not ready yet, but I am not opposed to publication as long as there are warnings in the paper about the shortcomings. Originality: This is an original approach. Random walks sometimes are overused in the graph literature, but they seem justified in this work. But it also requires extra work to ensure they are generating meaningful graphs. Significance: The problem is important. Learn to generate graphs is a key task in drug discovery, relational learning, and knowledge discovery. Evaluation: The link prediction task is too easy, as links are missing at random. It would be more useful to predict links that are removed with an unknown bias. The graph (wedge, claw, etc) characteristics are good (but simple) metrics; however, it is unclear how a random graph with the same size and degree distribution (configuration model) would generate for the same metrics (it is not shown for comparison). Issues that I wish were addressed in the paper: a) How is the method learning a generator from a single graph? What are the conditions under which the method is likely to perform well? It seems to rely on some mixing RW conditions to model the distinct graph communities. What are these mixing conditions? These are important questions that should have at least an empirical exploration. b) What is the spatial independence assumption needed for such a generator? c) Would this approach be able to generate a lattice? Would it be able to generate an expander graph? What about a graph with poorly connect communities? Is there any difficulties with power law graphs? d) How is the RW statistically addressing the generation of high-order (subgraph) features? e) Can this approach be used with multiple i.i.d. graphs? f) Isn\u2019t learning the random walk sample path a much harder / higher-dimensional task than it is necessary? Again, the short walk may be capturing the communities but the high-dimensional random walk sample path seems like a high price to pay to learn community structure. g) Clearly, with a large T (number of RW steps), the RW is not modeling just a single community. Is there a way to choose T? How larger values of T to better model inter-community links? Would different communities have different choices of T? h) And a related question, how well can the method generate the inter-community links? i) The RW model is actually similar to an HMM. Would learning a mixture of HMMs (one per community) have similar performance? ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and constructive feedback . We noticed that several of your questions ( a , c , f , g , h , i ) revolve around community structure . We would like to highlight that our model does not have access to community information at any point and more importantly does not have the goal of explicitly modeling communities . We address all your concerns below and additionally as you requested , we extended the discussion section to clearly highlight the model limitations ( see Section 5 in the revised manuscript ) . 1 ) Link prediction We replicated the experimental setup for link prediction that is standard in recent works ( [ 1 , 2 , 3 ] ) . We agree that different test set sampling strategies could provide a more in-depth analysis of our link prediction performance . However , our main goal is to demonstrate the feasibility and utility of implicit generative modeling for graphs , and not to develop a new state-of-the-art method for link prediction . This experiment mainly serves the purpose of demonstrating the generalization properties of the proposed method . On a related note , since implicit models for graph generation have not been studied so far , effective methods for their evaluation are yet to be developed . Therefore , we use the link prediction task as one possible way to evaluate our implicit model . This , together with the other experiments , gives us insight into the graph properties that our model is able to capture . 2 ) Configuration model Thank you for this suggestion . We have added results for the configuration model to Table 2 in the revised version , as well as to Table 6 in the appendix . Some properties of the graphs generated by the configuration model ( e.g. , degree distribution ) are identical to the input graph statistics by the definition of the configuration model . However , the random edge shuffling performed by the configuration model completely destroys the community structure , which makes the resulting graph very different from the original . Additionally , we have performed experiments , where only a fraction of edges are rewired by the configuration model , such that the edge overlap ( EO ) score of the rewired graph matches the EO score of GraphGAN . Still , even in such a scenario , the configuration model significantly alters the community structure . You can see the quantitative results in Table 2 of the revised version of the paper . Regarding your questions ( a ) - ( c ) ( questions ( d ) - ( i ) are in pt . 2 ) a ) Indeed , learning graph generators from a single graph is one of the key challenges tackled in our paper . In fact , part of our motivation for using RWs was precisely to solve this challenge ( see also ( f ) ) . Given the nature of the GAN framework we required multiple samples to train the generator . Thus we turn to using RWs since they naturally represent our single input graph with multiple samples . In this first foundational work we explored connected graphs ( by extracting the largest connected component as a preprocessing step ) . We did not investigate the behaviour of GraphGAN when we have e.g.many disconnected components . This could be considered as one condition for GraphGAN to perform well . Furthermore , the focus of this paper was to show that implicit graph generators are able to capture properties of the graph without manually specifying them . While our goal is not to determine the stationary distribution of RWs ( for which mixing conditions are relevant ) , we agree that drawing theoretical connections between GraphGAN and the established results is an exciting direction for future work . Please note that some empirical exploration of this aspect is already included ( Figure 4 , where we analyze the effect of RW length on link prediction performance ) . See also our answer to ( g ) . b ) Our model does not make * any * spatial dependence assumptions about the adjacency matrix , assuming you are referring to our discussion in paragraph 2 of Section 2 . The main point in the paper is that one should not naively treat the adjacency matrix as a binary image and apply standard CNN-based GAN architectures to it . Such architectures for images contain the built-in assumption that pixels located closely ( within the same receptive field ) are in some way correlated . Clearly , when talking about an adjacency matrix such assumption is not sensible , as permutations of rows/columns correspond to the exact same graph but very different receptive fields . Our model addresses this issue by operating on the random walks . c ) We are indeed able to generate graphs with power-law degree distributions and sparse connectivity . We can conclude this since our model was evaluated and shows good performance on real-world graphs , that all exhibit exactly those patterns ( see Table 6 ) . Since our focus is on complex real-world networks , we felt that experiments on toy graphs ( lattice , expander ) would distract from the main story ."}, "1": {"review_id": "H15RufWAW-1", "review_text": "The authors proposed a generative model of random walks on graphs. Using GAN, the architecture allows for model-agnostic learning, controllable fitting, ensemble graph generation. It also produces meaningful node embeddings with semi-interpretable latent spaces. The overall framework could be relevant to multiple areas in graph analytics, including graph comparison, graph sampling, graph embedding and relational feature selection. The draft is well written with convincing experiments. I support the acceptances of this paper. I do have a few questions that might help further improve the draft. More baseline besides DC-SBM could better illustrate the power of GAN in learning longer random walk trajectories. DC-SBM, while a generative model, inherently can only capture first order random walks with target degree biases, and generally over-fits into degree sequences. Are there existing generative models based on walk paths? The choice of early stopping is a very interesting problem especially for the EO-creitenrion. In Fig3 (b), it seems assortativity is over-fitted beyond 40k iterations. It might be helpful to discuss more about the over-fitting of different graph properties. The node classification experiment could use a bit more refinement. The curves in Fig. 5(a) are not well explained. What is the \"combined\"? The claim of competitive performance needs better justification according to the presentation of the F1 scores. The Latent variable interpolation experiment could also use more explanations. How is the 2d subspace chosen? What is the intuition behind the random walks and graphs of Fig 6? Can you provide visualizations of the communities of the interpolated graphs in Fig 7? ", "rating": "7: Good paper, accept", "reply_text": "Thank you for comments . Based on your comments , we have a uploaded a revised version of our paper . See the details below . 1 ) Baselines Since our main goal is to develop an implicit model for graph generation the focus of the experimental evaluation was to show that the implicitly generated graphs are useful , rather than outperforming existing explicit generators ( most of which are designed with specific graph patterns in mind ) . Thus , we chose the well established DC-SBM as a baseline . In the revised version we have added new baselines ( on the suggestions of the reviewers ) such as the configuration model and ERGM . You can find the results for these in Table 2 . We are open to suggestions about further graph generation models we could compare to in order to highlight the properties and limitations of GraphGAN . 2 ) Generative models based on RWs The only remotely related model we are aware of that involves random walks is the Butterfly model ( McGlohon et al. , \u201c Weighted graphs and disconnected components : patterns and a generator '' , KDD \u2019 08 ) . However , it is a variant of the preferential attachment principle , and focuses on networks that grow over time . It uses first-order random walks , and thus can not capture higher-order interactions . Moreover , it is not applicable to our task since it generates the random walks on the fly ( i.e. , is not based on a set of random walks as input ) . 3 ) EO-criterion This is an interesting point , and we briefly talk about it in Section 3.2 . We can view the VAL and EO criteria as a trade-off between better generalization ( in terms of link prediction ) and more accurate reconstruction of the graph . Thus , as the EO score increases , our model approximates the distribution of random walks in the original graph more closely , which leads to constructing graphs more similar to the input , up to the point of overfitting the input graph . The EO criterion gives us control over this . 4 ) Node `` embeddings '' ( Figure 5 ) Thank you for pointing this out . We have updated this section and will briefly summarize the changes in the following . Using the term \u2018 embedding \u2019 was unfortunate in the figure . We were referring to W_down , i.e.the weight matrix projecting down the one-hot node vectors into low-dimensional space . The term \u2018 context \u2019 , on the other hand , was referring to W_up , which projects up the low-dimensional LSTM output . \u2018 Combined \u2019 was the concatenation of the W_up and W_down , which gave an additional small improvement over only using W_up . When using the term \u2018 competitive \u2019 we were referring to the link prediction performance , and not node classification ; we have made this distinction more clear in the revised version ( see , e.g. , the updated abstract ) . 5 ) Latent space interpolation ( Figures 6 , 7 ) We improved the wording in the revised paper . To summarize : The generator takes as input a noise vector z , drawn from a d-dimensional standard normal distribution . For the latent space interpolation experiment we set d=2 . That is , the generator receives samples drawn from a bivariate Gaussian distribution and transforms these into random walks . By using the inverse of the cumulative distribution of this 2D Gaussian distribution we can divide the input domain ( i.e.R^2 ) into bins of equal probability mass , and group the generated random walks into their respective bins based on the noise samples that were used to generate them . Based on these random walks , we construct the score matrix and assemble a graph using the procedure described in Section 3.3 . We can now measure the properties of the random walks coming from each of the latent space bins ( e.g.the average degree of the first node in the random walks : Figure 6a ) as well as the graphs constructed from the random walks ( e.g.Gini coefficient : Figure 6c ) and observe how these properties smoothly change when interpolating in the latent space . To better visualize the latent space interpolation performed in Figure 7 , we have compiled a short animation ( https : //figshare.com/articles/GraphGAN_Latent_Space_Interpolation/5684137 ) . In the bottom-right section , you can observe how the generated graphs \u2019 structure changes when interpolating along a trajectory in the latent space ."}, "2": {"review_id": "H15RufWAW-2", "review_text": "This paper proposes a WGAN formulation for generating graphs based on random walks. The proposed generator model combines node embeddings, with an LSTM architecture for modeling the sequence of nodes visited in a random walk; the discriminator distinguishes real from fake walks. The model is learned from a single large input graph (for three real-world networks) and evaluated against one baseline generative graph model: degree-corrected stochastic block models. The primary claims of the paper are as follows: i) The proposed approach is a generative model of graphs, specifically producing \"sibling\" graphs ii) The learned latent representation provides an interpretation of generated graph properties iii) The model generalizes well in terms of link and node classification The proposed method is novel and the incorporated ideas are quite interesting (e.g., discriminating real from fake random walks, generating random walks from node embeddings and LSTMs). However, from a graph generation perspective, the problem formulation and evaluation do not sufficiently demonstrate the utility of proposed method. First, wrt claim (i) the problem of generating \"sibling\" graphs is ill-posed. Statistical graph models are typically designed to generate a probability distribution over all graphs with N nodes and, as such, are evaluated based on how well they model that distribution. The notion of a \"sibling\" graph used in this paper is not clearly defined, but it seems to only be useful if the sibling graphs are likely under the distribution. Unfortunately, the likelihood of the sampled graphs is not explicitly evaluated. On the other hand, since many of the edges are shared the \"siblings\" may be nearly isomorphic to the input graph, which is not useful from a graph modeling perspective. For claim (i), the comparison to related work is far from sufficient to demonstrate its utility as a graph generation model. There are many graph models that are superior to DC-SBM, including KPGMs, BETR, ERGMs, hierarchical random graph models and latent space models. Moreover, a very simple baseline to assess the LSTM component of the model, would be to produce a graph by sampling links repeatedly from the latent space of node embeddings. Next, the evaluation wrt to claim (ii) is novel and may help developers understand the model characteristics. However, since the properties are measured based on a set of random walks it is still difficult to interpret the impact on the generated graphs (since an arbitrary node in the final graph will have some structure determined from each of the regions). Do the various regions generate different parts of the final graph structure (i.e., focusing on only a subset of the nodes)? Lastly, the authors evaluate the learned model on link and node prediction tasks and state that the model's so-so performance supports the claim that the model can generalize. This is the weakest claim of the paper. The learned node embeddings appear to do significantly worse than node2vec, and the full model is worse than DC-SBM. Given that the proposed model is transductive (when there is significant edge overlap) it should do far better than DC-SBM which is inductive. Overall, while the paper includes a wide range of experimental evaluation, they are aimed too broadly (and the results are too weak) to support any specific claim of the work. If the goal is to generate transductively (with many similar edges), then it would be better to compare more extensively to alternative node embedding and matrix factorization approaches, and assess the utility of the various modeling choices (e.g., LSTM, in/out embedding). If the goal is to generate inductively, over the full distribution of graphs, then it would be better to (i) assess whether the sampled graphs are isomorphic, and (ii) compare more extensively to alternative graph models (many of which have been published since 2010). ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . We would like to clarify some important points that might have been a source of misunderstanding . As this is the first work of its kind ( implicit generative model for graphs ) , we neither expect nor claim that GraphGAN in its current form is superior to every existing explicit model in every possible regard . Rather , our goal is to lay a foundation for the study of implicit models for graph generation . Such models will let us capture important properties of real-world graphs , without having to manually specify them in our models . We are convinced that the results already confirm this statement , and show the feasibility and utility of implicit models . Still , based on your suggestions , we added a comparison with more baselines . As expected , and reinforcing our previous point , all properties which these approaches explicitly model are preserved , while the rest deviate significantly from the input graph . This highlights the need for implicit models , such as the one proposed in our paper . Furthermore , there exist properties not captured by any of the existing models as shown in [ 1 ] , which again emphasizes the need for implicit models . We have already analyzed the reconstructive ( graph statistics ) and generalization ( link prediction ) properties of our model . As you mentioned , because of the likelihood-free nature of the model , we can not evaluate the likelihood of the held-out edges or an entire sampled graph . We are not aware of other experimental protocols applicable to this novel problem setting . If you think that some important aspects are not evaluated , please let us know . Using your terminology GraphGAN would be considered inductive . In the revised version we include comparison with more baselines . However , we do not completely agree that \u201c high edge overlap \u201d = > \u201c transductive \u201d ( above which EO threshold does a model qualify ? ) . This definition would mean that ERGM , which has high edge overlap ( see Table 2 ) , should be considered transductive , which it isn \u2019 t . We would also like to clarify , that our model is * not * generating random walks from node embeddings , and is not yet another method for learning node embeddings . Please , see our discussion on embeddings below . In the following comment we address your other concerns ."}}