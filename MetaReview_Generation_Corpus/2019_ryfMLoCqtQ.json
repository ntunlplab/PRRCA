{"year": "2019", "forum": "ryfMLoCqtQ", "title": "An analytic theory of generalization dynamics and transfer learning in deep linear networks", "decision": "Accept (Poster)", "meta_review": "The authors provide a new analysis of generalization in deep linear networks, provide new insight through the role of \"task structure\". Empirical findings are used to cast light on the general case. This work seems interesting and worthy of publication.", "reviews": [{"review_id": "ryfMLoCqtQ-0", "review_text": "Pros: The paper tackles an interesting problem of generalization and transfer learning in deep networks. They start from a linear network to derive the theory, identifying phases in the learning, and relating learning rates to task structure and SNR. The theory is thorough and backed up by numerical simulations, including qualitative comparisons to nonlinear networks. The intuition behind alignment of tasks Cons: Most of the theory is developed on a linear network in an abstracted teacher/student/TA framework, where the analysis revolves around the the SVD of the weights. It's unclear to what extent the theory would generalize not only to deep, nonlinear networks (which the paper addresses empirically) but also different structures in the task that are not well approximated by the SVD.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for the helpful and positive comments . Nonlinear networks : Our hope is that most the understanding here will actually ( qualitatively ) generalize to the case of nonlinear networks learning nonlinear structure ( i.e.structure which is not captured by the SVD ) . We hope that therefore the present results will not only be useful analytically , but will also provide insights into the puzzles in the nonlinear case that may yield new directions for research in nonlinear generalization and regularization . We maybe should have communicated this more clearly , and have made some minor revisions in order to do so , since both you and reviewer 3 seemed to want more clarification of this issue . In particular : a ) We have combined the qualitative comparison with nonlinear networks with the rest of the theory verification section , both because of the aesthetic issue you noted , and to avoid the appearance that this was the only portion of the paper that is relevant to the nonlinear case . b ) The issues about memorization capacity vs. observed generalization were observed in nonlinear networks originally . We explain this in the linear case in terms of task structure in the data being stronger than noise structure , and therefore being learned first . We suggest that the phenomenon has similar causes in nonlinear networks , and this motivates the argument that the many data-agnostic bounds will be very loose in the nonlinear case ( as we have shown they are in the linear case , and as they have been observed to be in the nonlinear case ) . c ) The related issue about memorizing randomized labels taking longer than learning the real data also are similar in nonlinear networks , in fact that was our inspiration for exploring this . d ) Our results on transfer qualitatively generalize to the nonlinear case , as shown in the supplementary material ( Appendix F ) . In particular , we observe the same pattern of interference between weakly aligned tasks and benefits between well-aligned ones , modulated in similar ways by the relative SNRs of the tasks . We reworded part of the transfer section in an attempt to highlight this further . e ) While our non-gradient optimal learning algorithm will clearly not work in the nonlinear case , we think it suggests a useful direction for future research : more structure-sensitive regularization strategies may substantially outperform relatively naive ones like Lp penalties . f ) We have edited the discussion section to highlight some of the above points ."}, {"review_id": "ryfMLoCqtQ-1", "review_text": "Most theoretical work on understanding generalization in deep learning provides very loose bounds and does not adequately explain this phenomena. Moreover, their is also a gap in our understanding of knowledge transfer across tasks. The authors study a simple model of linear networks. They give analytic bounds on train/test error of linear networks as a function of training time, number of examples, network size, initialization, task structure and SNR. They argue that their results indicate that deep networks progressively learn the most important task structure first, so the generalization at the early stopping primarily depends on task structure and is independent of network size. This explains previous observations about real data being learned faster than random data. Interestingly, they show a learning algorithm that provably out-performs gradient-descent training. They show that how knowledge transfer in their model depends on SNRs and input feature alignments of task-pairs. The theoretical framework of low-rank noisy teachers using a more complex (e.g., wider or deeper) student network is simple and allows them to use random matrix theory to understand and interpret interesting scenarios such as random initialization vs. training-aligned initialization. Fig. 5 shows that even though the theoretical framework is for linear networks, many of the observations hold even for non-linear (leaky ReLU) networks. They also offer a reasonable explanation for learning random vs. real data in terms of how the signal singular values get diluted or spread over many modes. I do not think that the generalization bounds given by the authors are any tighter than previous attempts. However, I think their theoretical and experimental contributions to provide quantitative and qualitative explainations of various interesting phenomena in deep learning are both solid enough to merit acceptance.", "rating": "7: Good paper, accept", "reply_text": "Thank you for the positive comments . We think this provides a useful synopsis of the contributions of our paper . With respect to the tightness of generalization bounds , nobody to the best of our knowledge has given exact analytic estimates for optimal stopping error in the linear case with rank > 1 ( asymptotic is easier , since it is simply the least-squares solution ) . Thus this is a new ( and tighter ) bound in the limited setting we consider . However , we primarily see this work as providing more general insights into why naive generalization bounds are loose \u2014 if the structure of the data is a primary factor driving generalization performance in the nonlinear case ( as we have shown it is for linear networks ) , then bounds based solely on architecture are likely to be useless ( as they have generally been observed to be for deep learning models ) . This is also related to the memorization time issue we discuss ."}, {"review_id": "ryfMLoCqtQ-2", "review_text": "This paper builds on the long recent tradition of analyzing deep linear neural networks. In addition to an ample appendix bringing the page total to 20, the authors went over the recommended eight pages, hitting the hard limit of 10 and thus per reviewing directions will be held to a higher standard than the other (mostly 8-page) papers. The recent literature on deep linear networks has explored many paths with the hope of producing insights that might help explain the performance of deep neural networks. A recent line of papers by Soudry and Srebro among others focuses on the behavior of stochastic gradient descent. This paper\u2019s analysis comes from a different angle, following the work by Saxe et al (2013) whose analysis considers a (classic one hidden layer) linear teacher network that generates labels and a corresponding student trained to match those labels. The analysis hinges on the singular value decomposition of the composite weight matrix USV^T = W = W^{32} W^{21}. One aim of the present work, that appears to be a unique contribution above the prior work is to focus on the role played by task structure, suggesting that certain notions of task structure may play a more significant role than architecture and that any bounds which consider architecture but not task structure are doomed to be excessively loose. To facilitate their analysis, the authors consider an artificial setup that requires some specific properties. For example, the number of inputs are equal to the input dimension of the network, with the inputs themselves being orthonormal. The labeling function includes a noise term and the singular values of the teacher model admit an interpretation as signal to noise ratios. Given their setup, the authors can express the train and test errors analytically in terms of the weight matrices of the teacher and student and the input-output covariance matrix. The authors then analyze the gradient descent dynamics in what appears to follow the work of Saxe 2013 although I am not an expert on that paper. The analysis focuses on the time dependent evolution of the singular values of the student model, characterized via a set of differential equations. The next analysis explores a condition that the authors dub \u201ctraining aligned\u201d initial conditions. This involves initializing the student weights to have the same singular vectors as the training data input-output covariance but with all singular values equal to some amount epsilon. The authors show that the learning dynamics give rise to what they characterize as a singular value \u201cdetection wave\u201d. Detecting the modes in descending order by their corresponding singular values. A set of synthetic experiments show close alignment between theory and experiment. Section 3.5 offers just one paragraph on a \u201cqualitative comparison to nonlinear networks\u201d. A few issues here are that aesthetically, one-paragraph subsections are not ideal. More problematic is that this theory presumably is building towards insights that might actually be useful towards understanding deep non-linear networks. Since the present material is only interesting as an analytic instrument, I would have hoped for greater emphasis on these connections, with perhaps some hypotheses about the behavior of nonlinear nets driven by this analysis that might subsequently be confirmed or refuted. The paper concludes with two sections discussing what happens when nets are trained on randomly labeled data and knowledge transfer across related tasks respectively. Overall I think the paper is well-written and interesting, and while I haven\u2019t independently verified every proof, the technical analysis appears to be interesting and sound. The biggest weaknesses of this paper---for this audience, which skews empirical---concern the extent to which the work addresses or provides insight about real neural networks. One potential weakness in this line of work may be that it appears to rely heavily on the linearity of the deep net. While some other recent theories seem more plausibly generalized to more general architectures, it\u2019s not clear to me how this analysis, which hinges so crucially on the entire mapping being expressible as a linear operator, can generalize. On the other hand, I am personally of the opinion that the field is in the unusual position of possessing too many tools that \u201cwork\u201d and too few new ideas. So I\u2019m inclined to give the authors some license, even if I\u2019m unsure of the eventual utility of the work. One challenge in reviewing this paper is that it builds tightly on a number of recent papers and without being an authority on the other works, while it\u2019s possible to assess the insights in this paper, it\u2019s difficult to say conclusively which among them can rightly be considered the present paper\u2019s contributions (vs those of the prior work). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for the thorough and helpful comments . We appreciate the time and care you took reviewing this paper . We have responded to a few points below . \u201c One aim of the present work , that appears to be a unique contribution above the prior work is to focus on the role played by task structure , suggesting that certain notions of task structure may play a more significant role than architecture and that any bounds which consider architecture but not task structure are doomed to be excessively loose. \u201d \u2014 Thank you for highlighting this , because we think it is important for thinking about developing better generalization bounds for deep learning systems . Nonlinear networks : Our hope is that most the understanding here will actually ( qualitatively ) generalize to the nonlinear case . We hope that therefore the present results will not only be useful analytically , but will also provide insights into the puzzles in the nonlinear case that may yield new directions for research in nonlinear generalization and regularization . We maybe should have communicated this more clearly , and have made some minor revisions in order to do so . In particular : a ) We have combined the qualitative comparison with nonlinear networks with the rest of the theory verification section , both because of the aesthetic issue you noted , and to avoid the appearance that this was the only portion of the paper that is relevant to the nonlinear case . b ) The issues about memorization capacity vs. observed generalization were observed in nonlinear networks originally . We explain this in the linear case in terms of task structure in the data being stronger than noise structure , and therefore being learned first . We suggest that the phenomenon has similar causes in nonlinear networks , and this motivates the argument that the many data-agnostic bounds will be very loose in the nonlinear case ( as we have shown they are in the linear case , and as they have been observed to be in the nonlinear case ) . c ) The related issue about memorizing randomized labels taking longer than learning the real data also are similar in nonlinear networks , in fact that was our inspiration for exploring this . d ) Our results on transfer qualitatively generalize to the nonlinear case , as shown in the supplementary material ( Appendix F ) . In particular , we observe the same pattern of interference between weakly aligned tasks and benefits between well-aligned ones , modulated in similar ways by the relative SNRs of the tasks . We reworded part of the transfer section in an attempt to highlight this further . e ) While our non-gradient optimal learning algorithm will clearly not work in the nonlinear case , we think it suggests a useful direction for future research : more structure-sensitive regularization strategies may substantially outperform relatively naive ones like Lp penalties . f ) We have edited the discussion section to highlight some of the above points . Finally , regarding the comment that `` the number of inputs are equal to the input dimension of the network , with the inputs themselves being orthonormal . '' In the original paper we actually showed how to handle situations where the number of inputs is both less than and greater than the input dimension of the network in Appendix G and we verified the match between our theory and experimental results in Figure 13 . We mentioned this briefly in the main paper in Sec.2.1 , and we apologize if it was n't clear . Thanks again for your comments !"}], "0": {"review_id": "ryfMLoCqtQ-0", "review_text": "Pros: The paper tackles an interesting problem of generalization and transfer learning in deep networks. They start from a linear network to derive the theory, identifying phases in the learning, and relating learning rates to task structure and SNR. The theory is thorough and backed up by numerical simulations, including qualitative comparisons to nonlinear networks. The intuition behind alignment of tasks Cons: Most of the theory is developed on a linear network in an abstracted teacher/student/TA framework, where the analysis revolves around the the SVD of the weights. It's unclear to what extent the theory would generalize not only to deep, nonlinear networks (which the paper addresses empirically) but also different structures in the task that are not well approximated by the SVD.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for the helpful and positive comments . Nonlinear networks : Our hope is that most the understanding here will actually ( qualitatively ) generalize to the case of nonlinear networks learning nonlinear structure ( i.e.structure which is not captured by the SVD ) . We hope that therefore the present results will not only be useful analytically , but will also provide insights into the puzzles in the nonlinear case that may yield new directions for research in nonlinear generalization and regularization . We maybe should have communicated this more clearly , and have made some minor revisions in order to do so , since both you and reviewer 3 seemed to want more clarification of this issue . In particular : a ) We have combined the qualitative comparison with nonlinear networks with the rest of the theory verification section , both because of the aesthetic issue you noted , and to avoid the appearance that this was the only portion of the paper that is relevant to the nonlinear case . b ) The issues about memorization capacity vs. observed generalization were observed in nonlinear networks originally . We explain this in the linear case in terms of task structure in the data being stronger than noise structure , and therefore being learned first . We suggest that the phenomenon has similar causes in nonlinear networks , and this motivates the argument that the many data-agnostic bounds will be very loose in the nonlinear case ( as we have shown they are in the linear case , and as they have been observed to be in the nonlinear case ) . c ) The related issue about memorizing randomized labels taking longer than learning the real data also are similar in nonlinear networks , in fact that was our inspiration for exploring this . d ) Our results on transfer qualitatively generalize to the nonlinear case , as shown in the supplementary material ( Appendix F ) . In particular , we observe the same pattern of interference between weakly aligned tasks and benefits between well-aligned ones , modulated in similar ways by the relative SNRs of the tasks . We reworded part of the transfer section in an attempt to highlight this further . e ) While our non-gradient optimal learning algorithm will clearly not work in the nonlinear case , we think it suggests a useful direction for future research : more structure-sensitive regularization strategies may substantially outperform relatively naive ones like Lp penalties . f ) We have edited the discussion section to highlight some of the above points ."}, "1": {"review_id": "ryfMLoCqtQ-1", "review_text": "Most theoretical work on understanding generalization in deep learning provides very loose bounds and does not adequately explain this phenomena. Moreover, their is also a gap in our understanding of knowledge transfer across tasks. The authors study a simple model of linear networks. They give analytic bounds on train/test error of linear networks as a function of training time, number of examples, network size, initialization, task structure and SNR. They argue that their results indicate that deep networks progressively learn the most important task structure first, so the generalization at the early stopping primarily depends on task structure and is independent of network size. This explains previous observations about real data being learned faster than random data. Interestingly, they show a learning algorithm that provably out-performs gradient-descent training. They show that how knowledge transfer in their model depends on SNRs and input feature alignments of task-pairs. The theoretical framework of low-rank noisy teachers using a more complex (e.g., wider or deeper) student network is simple and allows them to use random matrix theory to understand and interpret interesting scenarios such as random initialization vs. training-aligned initialization. Fig. 5 shows that even though the theoretical framework is for linear networks, many of the observations hold even for non-linear (leaky ReLU) networks. They also offer a reasonable explanation for learning random vs. real data in terms of how the signal singular values get diluted or spread over many modes. I do not think that the generalization bounds given by the authors are any tighter than previous attempts. However, I think their theoretical and experimental contributions to provide quantitative and qualitative explainations of various interesting phenomena in deep learning are both solid enough to merit acceptance.", "rating": "7: Good paper, accept", "reply_text": "Thank you for the positive comments . We think this provides a useful synopsis of the contributions of our paper . With respect to the tightness of generalization bounds , nobody to the best of our knowledge has given exact analytic estimates for optimal stopping error in the linear case with rank > 1 ( asymptotic is easier , since it is simply the least-squares solution ) . Thus this is a new ( and tighter ) bound in the limited setting we consider . However , we primarily see this work as providing more general insights into why naive generalization bounds are loose \u2014 if the structure of the data is a primary factor driving generalization performance in the nonlinear case ( as we have shown it is for linear networks ) , then bounds based solely on architecture are likely to be useless ( as they have generally been observed to be for deep learning models ) . This is also related to the memorization time issue we discuss ."}, "2": {"review_id": "ryfMLoCqtQ-2", "review_text": "This paper builds on the long recent tradition of analyzing deep linear neural networks. In addition to an ample appendix bringing the page total to 20, the authors went over the recommended eight pages, hitting the hard limit of 10 and thus per reviewing directions will be held to a higher standard than the other (mostly 8-page) papers. The recent literature on deep linear networks has explored many paths with the hope of producing insights that might help explain the performance of deep neural networks. A recent line of papers by Soudry and Srebro among others focuses on the behavior of stochastic gradient descent. This paper\u2019s analysis comes from a different angle, following the work by Saxe et al (2013) whose analysis considers a (classic one hidden layer) linear teacher network that generates labels and a corresponding student trained to match those labels. The analysis hinges on the singular value decomposition of the composite weight matrix USV^T = W = W^{32} W^{21}. One aim of the present work, that appears to be a unique contribution above the prior work is to focus on the role played by task structure, suggesting that certain notions of task structure may play a more significant role than architecture and that any bounds which consider architecture but not task structure are doomed to be excessively loose. To facilitate their analysis, the authors consider an artificial setup that requires some specific properties. For example, the number of inputs are equal to the input dimension of the network, with the inputs themselves being orthonormal. The labeling function includes a noise term and the singular values of the teacher model admit an interpretation as signal to noise ratios. Given their setup, the authors can express the train and test errors analytically in terms of the weight matrices of the teacher and student and the input-output covariance matrix. The authors then analyze the gradient descent dynamics in what appears to follow the work of Saxe 2013 although I am not an expert on that paper. The analysis focuses on the time dependent evolution of the singular values of the student model, characterized via a set of differential equations. The next analysis explores a condition that the authors dub \u201ctraining aligned\u201d initial conditions. This involves initializing the student weights to have the same singular vectors as the training data input-output covariance but with all singular values equal to some amount epsilon. The authors show that the learning dynamics give rise to what they characterize as a singular value \u201cdetection wave\u201d. Detecting the modes in descending order by their corresponding singular values. A set of synthetic experiments show close alignment between theory and experiment. Section 3.5 offers just one paragraph on a \u201cqualitative comparison to nonlinear networks\u201d. A few issues here are that aesthetically, one-paragraph subsections are not ideal. More problematic is that this theory presumably is building towards insights that might actually be useful towards understanding deep non-linear networks. Since the present material is only interesting as an analytic instrument, I would have hoped for greater emphasis on these connections, with perhaps some hypotheses about the behavior of nonlinear nets driven by this analysis that might subsequently be confirmed or refuted. The paper concludes with two sections discussing what happens when nets are trained on randomly labeled data and knowledge transfer across related tasks respectively. Overall I think the paper is well-written and interesting, and while I haven\u2019t independently verified every proof, the technical analysis appears to be interesting and sound. The biggest weaknesses of this paper---for this audience, which skews empirical---concern the extent to which the work addresses or provides insight about real neural networks. One potential weakness in this line of work may be that it appears to rely heavily on the linearity of the deep net. While some other recent theories seem more plausibly generalized to more general architectures, it\u2019s not clear to me how this analysis, which hinges so crucially on the entire mapping being expressible as a linear operator, can generalize. On the other hand, I am personally of the opinion that the field is in the unusual position of possessing too many tools that \u201cwork\u201d and too few new ideas. So I\u2019m inclined to give the authors some license, even if I\u2019m unsure of the eventual utility of the work. One challenge in reviewing this paper is that it builds tightly on a number of recent papers and without being an authority on the other works, while it\u2019s possible to assess the insights in this paper, it\u2019s difficult to say conclusively which among them can rightly be considered the present paper\u2019s contributions (vs those of the prior work). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for the thorough and helpful comments . We appreciate the time and care you took reviewing this paper . We have responded to a few points below . \u201c One aim of the present work , that appears to be a unique contribution above the prior work is to focus on the role played by task structure , suggesting that certain notions of task structure may play a more significant role than architecture and that any bounds which consider architecture but not task structure are doomed to be excessively loose. \u201d \u2014 Thank you for highlighting this , because we think it is important for thinking about developing better generalization bounds for deep learning systems . Nonlinear networks : Our hope is that most the understanding here will actually ( qualitatively ) generalize to the nonlinear case . We hope that therefore the present results will not only be useful analytically , but will also provide insights into the puzzles in the nonlinear case that may yield new directions for research in nonlinear generalization and regularization . We maybe should have communicated this more clearly , and have made some minor revisions in order to do so . In particular : a ) We have combined the qualitative comparison with nonlinear networks with the rest of the theory verification section , both because of the aesthetic issue you noted , and to avoid the appearance that this was the only portion of the paper that is relevant to the nonlinear case . b ) The issues about memorization capacity vs. observed generalization were observed in nonlinear networks originally . We explain this in the linear case in terms of task structure in the data being stronger than noise structure , and therefore being learned first . We suggest that the phenomenon has similar causes in nonlinear networks , and this motivates the argument that the many data-agnostic bounds will be very loose in the nonlinear case ( as we have shown they are in the linear case , and as they have been observed to be in the nonlinear case ) . c ) The related issue about memorizing randomized labels taking longer than learning the real data also are similar in nonlinear networks , in fact that was our inspiration for exploring this . d ) Our results on transfer qualitatively generalize to the nonlinear case , as shown in the supplementary material ( Appendix F ) . In particular , we observe the same pattern of interference between weakly aligned tasks and benefits between well-aligned ones , modulated in similar ways by the relative SNRs of the tasks . We reworded part of the transfer section in an attempt to highlight this further . e ) While our non-gradient optimal learning algorithm will clearly not work in the nonlinear case , we think it suggests a useful direction for future research : more structure-sensitive regularization strategies may substantially outperform relatively naive ones like Lp penalties . f ) We have edited the discussion section to highlight some of the above points . Finally , regarding the comment that `` the number of inputs are equal to the input dimension of the network , with the inputs themselves being orthonormal . '' In the original paper we actually showed how to handle situations where the number of inputs is both less than and greater than the input dimension of the network in Appendix G and we verified the match between our theory and experimental results in Figure 13 . We mentioned this briefly in the main paper in Sec.2.1 , and we apologize if it was n't clear . Thanks again for your comments !"}}