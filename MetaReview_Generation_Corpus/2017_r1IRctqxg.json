{"year": "2017", "forum": "r1IRctqxg", "title": "Sample Importance in Training Deep Neural Networks", "decision": "Reject", "meta_review": "The reviewers provided detailed, confident reviews and there was significant discussion between the parties. \n \n Reviewer 2 and 3 felt quite strongly that the paper was a clear reject. Reviewer 1 thought the paper should be accepted.\n \n I was concerned with the two points raised by R3 and don't feel they were adequately addressed by the author's comments:\n \n - Dependence of the criteria on the learning rate (this does not make sense to me); and\n - Really really poor results on CIFAR-10 (and this is not being too picky, like asking them to be state-of-the-art; they are just way off)\n \n I engaged R1 to see how they felt about this. In reflection, I side with the majority opinion that the paper needs re-work to meet the ICLR acceptance bar.", "reviews": [{"review_id": "r1IRctqxg-0", "review_text": "The paper proposes a new criterion (sample importance) to study the impact of samples during the training of deep neural networks. This criterion is not clearly defined (the term \\phi^t_{i,j} is never defined, only \\phi^t_i is defined; Despite the unclear definition, it is understood that sample importance is the squared l2 norm of the gradient for a sample i and at time t strangely scaled by the squared learning rate (the learning rate should have nothing to do with the importance of a sample in this context). The paper presents experiments on the well known MNIST and CIFAR datasets with correspondingly appropriate network architectures and choice of hyper-parameters and initialisations. The size of the hidden layers is a bit small for Mnist and very small for CIFAR (this could explain the very poor performance in figure 6: 50% error on CIFAR) The study of the evolution of sample importance during training depending on layers seems to lead to trivial conclusions - \u201cthe overall sample importance is different under different epochs\u201d => yes the norm of the gradient is expected to vary - \u201cOutput layer always has the largest average sample importance per parameter, and its contribution reaches the maximum in the early training stage and then drops\u201d => 1. yes since the gradient flows backwards, the gradient is expected to be stronger for the output layer and it is expected to become more diffuse as it propagates to lower layers which are not stable. As learning progresses one would expect the output layer to have progressively smaller gradients. 2. the norm of the gradient depends on the scaling of the variables The question of Figure 4 is absurd \u201cIs Sample Importance the same as Negative log-likelihood of a sample?\u201d. Of course not. The results are very bad on CIFAR which discredits the applicability of those results. On Mnist performance is not readable (figure 7): Error rate should only be presented between 0 and 10 or 20% Despite these important issues (there are others), the paper manages to raises some interesting things: the so-called easy samples and hard samples do seem to correspond (although the study is very preliminary in this regard) to what would intuitively be considered easy (the most representative/canonical samples) and hard (edge cases) samples. Also the experiments are very well presented.", "rating": "2: Strong rejection", "reply_text": "\\phi^t_ { i } is a vector of parameter affectability , which is the contribution of ith sample to the change to all the parameters in iteration t. Specifically , \\phi^t_ { i , j } is the parameter affectibility to the jth parameter in the network from sample i . We are sorry for this unclear definition and we have revised this in the new version . Q_d has already been defined in the original text in page 3 line 6 , \u201c where Q_d is a set consists of the indexes of all parameters in layer d. \u201d We defined the sample importance as the l2-norm of the change in the parameters contributed from a sample at a specific iteration , of course , the sample importance is affected by learning rate as it reflects that change in parameters at a particular iteration from the sample . In order to make the SI between different training stages comparable , we used fixed learning rate . Hence , the different behaviors of SI in different training stages are not affected by learning rate . In order to make the analysis comparable between MNIST and CIFAR , we only use feed forward neural network for analysis , as feed forward neural network is the most basic and general structure for deep learning . We will generalize our results and findings further for other architectures like convolutional networks . These are two direct observations in our paper . However , they are not the focus of our paper . We focused more on the samples that contribute more to different layers and different training stages . For example , in Fig.5 and Fig.6 we found that \u201c easy \u201d samples contributes more to the early stage of training and \u201c hard \u201d samples contributes more to the late stage of the training . These observations are not easily obtained without our experiments . The sample importance is not the same as the NLL of a sample , but it becomes more correlated during late stage as we shown in Figure 4 . Intuitively , if the NLL of a sample is large , there is much room for the network to adjust its parameters to reduce the NLL of this sample , while if the NLL is small or close to zero , there is a very tiny room for network to fit this sample as it is already perfectly trained . Hence , such question is not intuitively obvious , like the first question raised by AnonReviewer1 , which demands an example for the case where SI can be not related to NLL . Thanks for your suggestion . We have revised the Fig.7 to the new scale in the new version ."}, {"review_id": "r1IRctqxg-1", "review_text": "This paper examines the so called \"Sample Importance\" of each sample of a training data set, and its effect to the overall learning process. The paper shows empirical results that shows different training cases induces bigger gradients at different stages of learning and different layers. The paper shows some interesting results contrary to the common curriculum learning ideas of using easy training samples first. However, it is unclear how one should define \"Easy\" training cases. In addition, the experiments demonstrating ordering either NLL or SI is worse than mixed or random batch construction to be insightful. Possible Improvements: It would be nice to factor out the magnitudes of the gradients to the contribution of \"sample importance\". Higher gradient (as a function of a particular weight vector) can be affected weight/initialization, thereby introducing noise to the model. It would also be interesting if improvements based on \"Sample importance\" could be made to the batch selection algorithm to beat the baseline of random batch selection. Overall this paper is a good paper with various experiments examining how various samples in SGD influences the various aspect of training.", "rating": "7: Good paper, accept", "reply_text": "The \u201c Easy \u201d vs \u201c Hard \u201d samples have been discussed in Curriculum Learning ( CL ) [ 1 ] and Self-paced Learning ( SPL ) [ 2 ] . In CL , \u201c easy \u201d and \u201c hard \u201d samples are defined manually , or by the classification error on a pre-trained classifier . In SPL , \u201c easy \u201d and \u201c hard \u201d samples are defined based on their training error at each training step . Most of the previous methods defined the \u201c easy \u201d and \u201c hard \u201d based on an error-based metric . In our paper , we made a comparison between the samples with similar sample importance pattern over the training and their training error . We treat the samples with small training NLL as \u201c easy \u201d samples and large training NLL as \u201c hard \u201d samples . We found that \u201c easy \u201d samples contributes more during early stages and in higher layers while \u201c hard \u201d samples contribute more during late stages and in lower layers . Sample importance is the square of the parameter change contributes from a particular sample . It directly measures how much the parameters are changed due to the existence of a sample at a particular iteration . In FIg.1 we showed that Sample importance is preserved between initializations of the network . The noise introduced to the model from different initialization is very small . [ 1 ] Yoshua Bengio , Jerome Louradour , Ronan Collobert , and Jason Weston . Curriculum learning . In Proceedings of the 26th annual international conference on machine learning , pp . 41\u201348.ACM , 2009 . [ 2 ] M Pawan Kumar , Benjamin Packer , and Daphne Koller . Self-paced learning for latent variable models . In Advances in Neural Information Processing Systems , pp . 1189\u20131197 , 2010 ."}, {"review_id": "r1IRctqxg-2", "review_text": "(paper summary) The authors introduce the notion of \u201csample importance\u201d, meant to measure the influence of a particular training example on the training of a deep neural network. This quantity is closely related to the squared L2 norm of the gradient, where the summation is performed over (i) parameters of a given layer or (ii) across all parameters. Summing this quantity across time gives the \u201coverall importance\u201d, used to tease apart easy from hard examples. From this quantity, the authors illustrate the impact of [easy,hard] example during training, and their impact on layer depth. (detailed review) I have several objections to this paper. First and foremost, I am not convinced of the \u201csample importance\u201d as a meaningful metric. As previously mentioned, the magnitude of gradients will change significantly during learning, and I am not sure what conclusions one can draw from \\sum_t g_i^t vs \\sum_t g_j^t. For example, gradients tend to have higher norms early in training than at convergence, in which case weighting each gradient equally seems problematic. I tried illustrating the above with a small thought experiment during the question period: \u201cif\u201d the learning rate were too high, training may not even converge in which case sample importance would be ill-defined. Having a measure which depends on the learning rate seems problematic to me, as does the use of the L2 norm. The \u201cinput Fisher\u201d norm, \\mathbb{E} \\frac{\\partial \\log p} {\\partial x} (for a given time-step) may be better suited, as it speaks directly to the sensitivity of the classifier to the input x (and is insensitive to changes in the mean gradient norm). But again summing Fisher norms across time may not be meaningful. The experimental analysis also seems problematic. The authors claim from Fig. 2 that output layers are primarily learnt in the early stage of training. However, this is definitely not the case for CIFAR-10 and is debatable for MNIST: sample importance remains high for all layers during training, despite a small spike early on the output layer. Fig 2. (lower, middle) and Fig. 6 also seems to highlight an issue with the SI measure: the SI is dominated by the input layer which has the most parameters, and can thus more readily impact the gradient norm. Different model architectures may have yielded different conclusions. Had the authors managed to use the SI to craft a better curriculum, this would have given significant weight to the measure. Unfortunately, these results are negative. PROS: + extensive experiments CONS: - sample importance is a heuristic, not entirely well justified - SI yields limited insight into training of neural nets - SI does not inform curriculum learning ", "rating": "3: Clear rejection", "reply_text": "Sample importance is a direct measurement of parameter changes that contributed from a sample at a specific iteration during training . The reviewer claims that \u201c gradients tend to have higher norms early in training than at convergence \u201d , which is true for \u201c easy \u201d samples , but not for \u201c hard \u201d samples . Summing the gradients norm across time is just one of several the measurements we use and it is not the focus of our paper . To study the different contribution from samples to different parameters at different training stages , we measured the stage-wise , layer-wise sample importance . For example , one of the most important findings is that the parameters in lower-level layers are changed more by \u201c hard \u201d samples during late stage . The \u201c input Fisher \u201d norm suggested by the reviewer , is related to the saliency [ 1 ] in computer vision . It speaks directly to the sensitivity of the classifier to the input features rather than the existence of an input . In our paper , we care about how the change in the network parameters depends on the contribution of input during training . However , the sensitivity of the network output with regard to the input reveals only the current state of the network , but nothing about the network training . The average sample importance of output layer reach maximum during early stage and keeps dropping as training goes on ( Fig 2 , left figures ) . Hence , we have the argument of parameters in output layers are primarily learned in the early stage of training . We can see that the later in the training stage , the smaller the average sample importance in output layer parameters . For SI measure in Fig.6 , we care more about the layer-wise , stage-wise specific sample importance rather than overall sample importance . The most important message from the Fig.6 is that the sample importance has different stage-wise patterns in different sample groups . [ 1 ] Simonyan , Karen , Andrea Vedaldi , and Andrew Zisserman . `` Deep inside convolutional networks : Visualising image classification models and saliency maps . '' arXiv preprint arXiv:1312.6034 ( 2013 ) ."}], "0": {"review_id": "r1IRctqxg-0", "review_text": "The paper proposes a new criterion (sample importance) to study the impact of samples during the training of deep neural networks. This criterion is not clearly defined (the term \\phi^t_{i,j} is never defined, only \\phi^t_i is defined; Despite the unclear definition, it is understood that sample importance is the squared l2 norm of the gradient for a sample i and at time t strangely scaled by the squared learning rate (the learning rate should have nothing to do with the importance of a sample in this context). The paper presents experiments on the well known MNIST and CIFAR datasets with correspondingly appropriate network architectures and choice of hyper-parameters and initialisations. The size of the hidden layers is a bit small for Mnist and very small for CIFAR (this could explain the very poor performance in figure 6: 50% error on CIFAR) The study of the evolution of sample importance during training depending on layers seems to lead to trivial conclusions - \u201cthe overall sample importance is different under different epochs\u201d => yes the norm of the gradient is expected to vary - \u201cOutput layer always has the largest average sample importance per parameter, and its contribution reaches the maximum in the early training stage and then drops\u201d => 1. yes since the gradient flows backwards, the gradient is expected to be stronger for the output layer and it is expected to become more diffuse as it propagates to lower layers which are not stable. As learning progresses one would expect the output layer to have progressively smaller gradients. 2. the norm of the gradient depends on the scaling of the variables The question of Figure 4 is absurd \u201cIs Sample Importance the same as Negative log-likelihood of a sample?\u201d. Of course not. The results are very bad on CIFAR which discredits the applicability of those results. On Mnist performance is not readable (figure 7): Error rate should only be presented between 0 and 10 or 20% Despite these important issues (there are others), the paper manages to raises some interesting things: the so-called easy samples and hard samples do seem to correspond (although the study is very preliminary in this regard) to what would intuitively be considered easy (the most representative/canonical samples) and hard (edge cases) samples. Also the experiments are very well presented.", "rating": "2: Strong rejection", "reply_text": "\\phi^t_ { i } is a vector of parameter affectability , which is the contribution of ith sample to the change to all the parameters in iteration t. Specifically , \\phi^t_ { i , j } is the parameter affectibility to the jth parameter in the network from sample i . We are sorry for this unclear definition and we have revised this in the new version . Q_d has already been defined in the original text in page 3 line 6 , \u201c where Q_d is a set consists of the indexes of all parameters in layer d. \u201d We defined the sample importance as the l2-norm of the change in the parameters contributed from a sample at a specific iteration , of course , the sample importance is affected by learning rate as it reflects that change in parameters at a particular iteration from the sample . In order to make the SI between different training stages comparable , we used fixed learning rate . Hence , the different behaviors of SI in different training stages are not affected by learning rate . In order to make the analysis comparable between MNIST and CIFAR , we only use feed forward neural network for analysis , as feed forward neural network is the most basic and general structure for deep learning . We will generalize our results and findings further for other architectures like convolutional networks . These are two direct observations in our paper . However , they are not the focus of our paper . We focused more on the samples that contribute more to different layers and different training stages . For example , in Fig.5 and Fig.6 we found that \u201c easy \u201d samples contributes more to the early stage of training and \u201c hard \u201d samples contributes more to the late stage of the training . These observations are not easily obtained without our experiments . The sample importance is not the same as the NLL of a sample , but it becomes more correlated during late stage as we shown in Figure 4 . Intuitively , if the NLL of a sample is large , there is much room for the network to adjust its parameters to reduce the NLL of this sample , while if the NLL is small or close to zero , there is a very tiny room for network to fit this sample as it is already perfectly trained . Hence , such question is not intuitively obvious , like the first question raised by AnonReviewer1 , which demands an example for the case where SI can be not related to NLL . Thanks for your suggestion . We have revised the Fig.7 to the new scale in the new version ."}, "1": {"review_id": "r1IRctqxg-1", "review_text": "This paper examines the so called \"Sample Importance\" of each sample of a training data set, and its effect to the overall learning process. The paper shows empirical results that shows different training cases induces bigger gradients at different stages of learning and different layers. The paper shows some interesting results contrary to the common curriculum learning ideas of using easy training samples first. However, it is unclear how one should define \"Easy\" training cases. In addition, the experiments demonstrating ordering either NLL or SI is worse than mixed or random batch construction to be insightful. Possible Improvements: It would be nice to factor out the magnitudes of the gradients to the contribution of \"sample importance\". Higher gradient (as a function of a particular weight vector) can be affected weight/initialization, thereby introducing noise to the model. It would also be interesting if improvements based on \"Sample importance\" could be made to the batch selection algorithm to beat the baseline of random batch selection. Overall this paper is a good paper with various experiments examining how various samples in SGD influences the various aspect of training.", "rating": "7: Good paper, accept", "reply_text": "The \u201c Easy \u201d vs \u201c Hard \u201d samples have been discussed in Curriculum Learning ( CL ) [ 1 ] and Self-paced Learning ( SPL ) [ 2 ] . In CL , \u201c easy \u201d and \u201c hard \u201d samples are defined manually , or by the classification error on a pre-trained classifier . In SPL , \u201c easy \u201d and \u201c hard \u201d samples are defined based on their training error at each training step . Most of the previous methods defined the \u201c easy \u201d and \u201c hard \u201d based on an error-based metric . In our paper , we made a comparison between the samples with similar sample importance pattern over the training and their training error . We treat the samples with small training NLL as \u201c easy \u201d samples and large training NLL as \u201c hard \u201d samples . We found that \u201c easy \u201d samples contributes more during early stages and in higher layers while \u201c hard \u201d samples contribute more during late stages and in lower layers . Sample importance is the square of the parameter change contributes from a particular sample . It directly measures how much the parameters are changed due to the existence of a sample at a particular iteration . In FIg.1 we showed that Sample importance is preserved between initializations of the network . The noise introduced to the model from different initialization is very small . [ 1 ] Yoshua Bengio , Jerome Louradour , Ronan Collobert , and Jason Weston . Curriculum learning . In Proceedings of the 26th annual international conference on machine learning , pp . 41\u201348.ACM , 2009 . [ 2 ] M Pawan Kumar , Benjamin Packer , and Daphne Koller . Self-paced learning for latent variable models . In Advances in Neural Information Processing Systems , pp . 1189\u20131197 , 2010 ."}, "2": {"review_id": "r1IRctqxg-2", "review_text": "(paper summary) The authors introduce the notion of \u201csample importance\u201d, meant to measure the influence of a particular training example on the training of a deep neural network. This quantity is closely related to the squared L2 norm of the gradient, where the summation is performed over (i) parameters of a given layer or (ii) across all parameters. Summing this quantity across time gives the \u201coverall importance\u201d, used to tease apart easy from hard examples. From this quantity, the authors illustrate the impact of [easy,hard] example during training, and their impact on layer depth. (detailed review) I have several objections to this paper. First and foremost, I am not convinced of the \u201csample importance\u201d as a meaningful metric. As previously mentioned, the magnitude of gradients will change significantly during learning, and I am not sure what conclusions one can draw from \\sum_t g_i^t vs \\sum_t g_j^t. For example, gradients tend to have higher norms early in training than at convergence, in which case weighting each gradient equally seems problematic. I tried illustrating the above with a small thought experiment during the question period: \u201cif\u201d the learning rate were too high, training may not even converge in which case sample importance would be ill-defined. Having a measure which depends on the learning rate seems problematic to me, as does the use of the L2 norm. The \u201cinput Fisher\u201d norm, \\mathbb{E} \\frac{\\partial \\log p} {\\partial x} (for a given time-step) may be better suited, as it speaks directly to the sensitivity of the classifier to the input x (and is insensitive to changes in the mean gradient norm). But again summing Fisher norms across time may not be meaningful. The experimental analysis also seems problematic. The authors claim from Fig. 2 that output layers are primarily learnt in the early stage of training. However, this is definitely not the case for CIFAR-10 and is debatable for MNIST: sample importance remains high for all layers during training, despite a small spike early on the output layer. Fig 2. (lower, middle) and Fig. 6 also seems to highlight an issue with the SI measure: the SI is dominated by the input layer which has the most parameters, and can thus more readily impact the gradient norm. Different model architectures may have yielded different conclusions. Had the authors managed to use the SI to craft a better curriculum, this would have given significant weight to the measure. Unfortunately, these results are negative. PROS: + extensive experiments CONS: - sample importance is a heuristic, not entirely well justified - SI yields limited insight into training of neural nets - SI does not inform curriculum learning ", "rating": "3: Clear rejection", "reply_text": "Sample importance is a direct measurement of parameter changes that contributed from a sample at a specific iteration during training . The reviewer claims that \u201c gradients tend to have higher norms early in training than at convergence \u201d , which is true for \u201c easy \u201d samples , but not for \u201c hard \u201d samples . Summing the gradients norm across time is just one of several the measurements we use and it is not the focus of our paper . To study the different contribution from samples to different parameters at different training stages , we measured the stage-wise , layer-wise sample importance . For example , one of the most important findings is that the parameters in lower-level layers are changed more by \u201c hard \u201d samples during late stage . The \u201c input Fisher \u201d norm suggested by the reviewer , is related to the saliency [ 1 ] in computer vision . It speaks directly to the sensitivity of the classifier to the input features rather than the existence of an input . In our paper , we care about how the change in the network parameters depends on the contribution of input during training . However , the sensitivity of the network output with regard to the input reveals only the current state of the network , but nothing about the network training . The average sample importance of output layer reach maximum during early stage and keeps dropping as training goes on ( Fig 2 , left figures ) . Hence , we have the argument of parameters in output layers are primarily learned in the early stage of training . We can see that the later in the training stage , the smaller the average sample importance in output layer parameters . For SI measure in Fig.6 , we care more about the layer-wise , stage-wise specific sample importance rather than overall sample importance . The most important message from the Fig.6 is that the sample importance has different stage-wise patterns in different sample groups . [ 1 ] Simonyan , Karen , Andrea Vedaldi , and Andrew Zisserman . `` Deep inside convolutional networks : Visualising image classification models and saliency maps . '' arXiv preprint arXiv:1312.6034 ( 2013 ) ."}}