{"year": "2017", "forum": "Hyq4yhile", "title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "decision": "Accept (Poster)", "meta_review": "pros:\n - tackles a fundamental problem of interest to many\n - novel approach\n \n cons:\n - originally not evaluated against some reasonable benchmarks. Note: now added or addressed\n - little theoretical development cf MDP theory\n - some remaining questions about the necessity (and ability) to find good time alignments\n \n I personally found the ideas to be quite compelling, and believe that this is likely to inspire future work.\n The experiments represent interesting scenarios for transfer, with the caveat that they are just in simulation.", "reviews": [{"review_id": "Hyq4yhile-0", "review_text": "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pixels (5.4). They exhibit transfer from arms with different number of links, and from a torque-driven arm to a tendon-driven arm. One limitation of the paper is that the authors suppose that time alignment is trivial, because the tasks are all episodic and in the same domain. Time alignment is one form of domain adaptation / transfer that is not dealt with in the paper, that could be dealt with through subsampling, dynamic time warping, or learning a matching function (e.g. neural network). General remarks: The approach is compared to CCA, which is a relevant baseline. However, as the paper is purely experimental, another baseline (worse than CCA) would be to just have the random projections for \"f\" and \"g\" (the embedding functions on the two domains), to check that the bad performance of the \"no transfer\" version of the model is due to over-specialisation of these embeddings. I would also add (for information) that the problem of learning invariant feature spaces is also linked to metric learning (e.g. [Xing et al. 2002]). More generally, no parallel is drawn with multi-task learning in ML. In the case of knowledge transfer (4.1.1), it may make sense to anneal \\alpha. The experiments feel a bit rushed. In particular, the performance of the baseline being always 0 (no transfer at all) is uninformative, at least a much bigger sample budget should be tested. Also, why does Figure 7.b contain no \"CCA\" nor \"direct mapping\" results? Another concern that I have with the experiments: (if/how) did the author control for the fact that the embeddings were trained with more iterations in the case of doing transfer? Overall, the study of transfer is most welcomed in RL. The experiments in this paper are interesting enough for publication, but the paper could have been more thorough.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review . We agree that assuming a trivial time alignment is somewhat unsatisfying , and to address this we have formulated an alternating optimization to learn the alignment jointly with the embeddings , described in Section 3.3.2 . The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space , as described in Section 3.3.2 . Results using this method can be found in Figure 5 , Figure 7a . Using this approach usually works better than just assuming timestep correspondences , or as well in the case of well aligned data . As per the suggestion of comparing with random projections , we have added a comparison using random projections as feature embeddings . As shown in Figures 5 and 7a , this method achieves a low level of performance in between the CCA method and no transfer . Also , as pointed out in the review we do indeed anneal \\alpha over the course of learning in all our experiments . As shown in Table 1 , we have run the \u201c No Transfer \u201d method for 75 iterations ( seeing 3 times more samples ) . A likely reason the no transfer baseline doesn \u2019 t work even with this greater sample budget is that the exploration is insufficiently coherent for any reward to be obtained at all , leading to the behavior seen . Finally , we have added a connection to metric learning in the last paragraph of Section 2 , as well as a paragraph on multitask learning ( the third paragraph in Section 2 ) . Figure 7b does not yet contain the comparisons with CCA and direct mapping because we have been adding these comparisons over the course of the response period . This figure will contain all comparisons for the final version . Thanks !"}, {"review_id": "Hyq4yhile-1", "review_text": " This paper explores transfer in reinforcement learning between agents that may be morphologically distinct. The key idea is for the source and target agent to have learned a shared skill, and then to use this to construct abstract feature spaces to enable the transfer of a new unshared skill in the source agent to the target agent. The paper is related to much other work on transfer that uses shared latent spaces, such as CCA and its variants, including manifold alignment and kernel CCA. The paper reports on experiments using a simple physics simulator between robot arms consisting of three vs. four links. For comparison, a simple CCA based approach is shown, although it would have been preferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA. A three layer neural net is used to construct the latent feature spaces. The problem of transfer in RL is extremely important, and receives less attention than it should. This work uses an interesting hypothesis of trying to construct transfer based on shared skills between source and target agent. This is a promising approach. However, the comparisons to related approaches is not very up to date, and the domains are fairly simplistic. There is little by way of theoretical development of the ideas using MDP theory. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for bringing up several important points in the review . We have added several more comparisons to our results in Figures 5 and 7a . The first is using random projections , which performs slightly better than no transfer . The second is kernel CCA , and the last is unsupervised manifold learning , using the method presented in ( Wang and Mahadevan 2009 ) and ( Ammar et al 2015 ) . Please see the response to Reviewer 3 for more details on why we believe this last method performs poorly in our settings . Additionally , we have formulated a method to find the state alignment jointly with the feature embedding as described in Section 3.3.2 , allowing us to remove the assumption that the states are aligned by timestep . The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space . Figure 5 shows that this method actually provides better results than just assuming correspondences by time-step ."}, {"review_id": "Hyq4yhile-2", "review_text": "The paper considers the problem of transferring skills between robots with different morphologies, in the context of agents that have to perform several tasks. A core component of the proposed approach is to use a task-invariant future space, which can be shared between tasks & between agents. Compared to previous work (Ammar et al. 2015), it seems the main contribution here is to \u201cassume that good correspondences in episodic tasks can be extracted through time alignment\u201d (Sec. 2). This is an interesting hypothesis. There is also similarity to work by Raimalwala et al (2016), but the authors argue their method is better equipped to handle non-linear dynamics. These are two interesting hypotheses, however I don\u2019t see that they have been verified in the presented empirical results. In particular, the question of the pairing correspondence seems crucial. What happens when the time alignment is not suitable. Is it possible to use dynamic time warping (or similar method) to achieve reasonable results? Robustness to misspecification of the pairing correspondence P seems a major concern. In general, more comparison to other transfer methods, including those listed in Sec.2, would be very valuable. The addition of Sec.5.1 is definitely a right step in this direction, but represents a small portion of the recent work on transfer learning. I appreciate that other methods transfer other pieces of information (e.g. the policy), but still if the end goal is better performance, what is worth transferring (in addition to how to do the transfer) should be a reasonable question to explore. Overall, the paper tackles an important problem, but this is a very active area of research, and further comparison to other methods would be worthwhile. The method proposed of transferring the representation is well motivated, cleanly described, and conceptually sound. The assumption that time alignment can be used for the state pairing seems problematic, and should be further validated.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for pointing out the highly related work by ( Ammar et al.2015 ) .In order to ensure a fair comparison we use the Matlab code provided by Chang Wang ( https : //sites.google.com/site/changwangnk/home/ma-html ) . We find that the unsupervised manifold learning method described in ( Wang and Mahadevan 2009 ) and ( Ammar et al.2015 ) performs poorly . We suspect that this is because the method relies on pairwise distance and the raw state spaces do not provide a meaningful metric space . Ammar et al use a hand-specified feature mapping phi that provides a good metric space for the method . As we assume no prior knowledge about the state space , we do not have a hand-specific feature mapping in our experiments . We would like to clarify that our primary contribution is to learn a feature space in which the source and target states can be compared . This differs from prior work because we do not reconstruct the source states from target states , allowing the embeddings to discard information that is not common . This is more suitable for transferring between robots with varying morphologies . To address your comment about assuming correspondences , we have formulated an alternating optimization , alternating between establishing common feature space using current correspondences , and reestablishing correspondences using current feature space and dynamic time warping . This is described in detail in Section 3.3.2 , and results are seen in Fig 5 , Fig 7a . As suggested , we have also run comparisons with several prior methods such as ( Ammar et al.2015 ) , kernel CCA , random projections , CCA and using state mappings instead of embeddings . These results are shown in Figures 5 and 7a , and show the advantage of using our proposed method over several prior methods . Although kernel CCA is quite competitive with our method on the tendon task , it performs very poorly on the button task while our method is able to achieve excellent performance on both . Unfortunately we could not compare to the work in Raimalwala et al ( 2016 ) because it is quite specific to systems which have a single input , a single output , and can be modeled as linear time invariant . Our tasks are nonlinear and have multidimensional states ."}], "0": {"review_id": "Hyq4yhile-0", "review_text": "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pixels (5.4). They exhibit transfer from arms with different number of links, and from a torque-driven arm to a tendon-driven arm. One limitation of the paper is that the authors suppose that time alignment is trivial, because the tasks are all episodic and in the same domain. Time alignment is one form of domain adaptation / transfer that is not dealt with in the paper, that could be dealt with through subsampling, dynamic time warping, or learning a matching function (e.g. neural network). General remarks: The approach is compared to CCA, which is a relevant baseline. However, as the paper is purely experimental, another baseline (worse than CCA) would be to just have the random projections for \"f\" and \"g\" (the embedding functions on the two domains), to check that the bad performance of the \"no transfer\" version of the model is due to over-specialisation of these embeddings. I would also add (for information) that the problem of learning invariant feature spaces is also linked to metric learning (e.g. [Xing et al. 2002]). More generally, no parallel is drawn with multi-task learning in ML. In the case of knowledge transfer (4.1.1), it may make sense to anneal \\alpha. The experiments feel a bit rushed. In particular, the performance of the baseline being always 0 (no transfer at all) is uninformative, at least a much bigger sample budget should be tested. Also, why does Figure 7.b contain no \"CCA\" nor \"direct mapping\" results? Another concern that I have with the experiments: (if/how) did the author control for the fact that the embeddings were trained with more iterations in the case of doing transfer? Overall, the study of transfer is most welcomed in RL. The experiments in this paper are interesting enough for publication, but the paper could have been more thorough.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review . We agree that assuming a trivial time alignment is somewhat unsatisfying , and to address this we have formulated an alternating optimization to learn the alignment jointly with the embeddings , described in Section 3.3.2 . The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space , as described in Section 3.3.2 . Results using this method can be found in Figure 5 , Figure 7a . Using this approach usually works better than just assuming timestep correspondences , or as well in the case of well aligned data . As per the suggestion of comparing with random projections , we have added a comparison using random projections as feature embeddings . As shown in Figures 5 and 7a , this method achieves a low level of performance in between the CCA method and no transfer . Also , as pointed out in the review we do indeed anneal \\alpha over the course of learning in all our experiments . As shown in Table 1 , we have run the \u201c No Transfer \u201d method for 75 iterations ( seeing 3 times more samples ) . A likely reason the no transfer baseline doesn \u2019 t work even with this greater sample budget is that the exploration is insufficiently coherent for any reward to be obtained at all , leading to the behavior seen . Finally , we have added a connection to metric learning in the last paragraph of Section 2 , as well as a paragraph on multitask learning ( the third paragraph in Section 2 ) . Figure 7b does not yet contain the comparisons with CCA and direct mapping because we have been adding these comparisons over the course of the response period . This figure will contain all comparisons for the final version . Thanks !"}, "1": {"review_id": "Hyq4yhile-1", "review_text": " This paper explores transfer in reinforcement learning between agents that may be morphologically distinct. The key idea is for the source and target agent to have learned a shared skill, and then to use this to construct abstract feature spaces to enable the transfer of a new unshared skill in the source agent to the target agent. The paper is related to much other work on transfer that uses shared latent spaces, such as CCA and its variants, including manifold alignment and kernel CCA. The paper reports on experiments using a simple physics simulator between robot arms consisting of three vs. four links. For comparison, a simple CCA based approach is shown, although it would have been preferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA. A three layer neural net is used to construct the latent feature spaces. The problem of transfer in RL is extremely important, and receives less attention than it should. This work uses an interesting hypothesis of trying to construct transfer based on shared skills between source and target agent. This is a promising approach. However, the comparisons to related approaches is not very up to date, and the domains are fairly simplistic. There is little by way of theoretical development of the ideas using MDP theory. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for bringing up several important points in the review . We have added several more comparisons to our results in Figures 5 and 7a . The first is using random projections , which performs slightly better than no transfer . The second is kernel CCA , and the last is unsupervised manifold learning , using the method presented in ( Wang and Mahadevan 2009 ) and ( Ammar et al 2015 ) . Please see the response to Reviewer 3 for more details on why we believe this last method performs poorly in our settings . Additionally , we have formulated a method to find the state alignment jointly with the feature embedding as described in Section 3.3.2 , allowing us to remove the assumption that the states are aligned by timestep . The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space . Figure 5 shows that this method actually provides better results than just assuming correspondences by time-step ."}, "2": {"review_id": "Hyq4yhile-2", "review_text": "The paper considers the problem of transferring skills between robots with different morphologies, in the context of agents that have to perform several tasks. A core component of the proposed approach is to use a task-invariant future space, which can be shared between tasks & between agents. Compared to previous work (Ammar et al. 2015), it seems the main contribution here is to \u201cassume that good correspondences in episodic tasks can be extracted through time alignment\u201d (Sec. 2). This is an interesting hypothesis. There is also similarity to work by Raimalwala et al (2016), but the authors argue their method is better equipped to handle non-linear dynamics. These are two interesting hypotheses, however I don\u2019t see that they have been verified in the presented empirical results. In particular, the question of the pairing correspondence seems crucial. What happens when the time alignment is not suitable. Is it possible to use dynamic time warping (or similar method) to achieve reasonable results? Robustness to misspecification of the pairing correspondence P seems a major concern. In general, more comparison to other transfer methods, including those listed in Sec.2, would be very valuable. The addition of Sec.5.1 is definitely a right step in this direction, but represents a small portion of the recent work on transfer learning. I appreciate that other methods transfer other pieces of information (e.g. the policy), but still if the end goal is better performance, what is worth transferring (in addition to how to do the transfer) should be a reasonable question to explore. Overall, the paper tackles an important problem, but this is a very active area of research, and further comparison to other methods would be worthwhile. The method proposed of transferring the representation is well motivated, cleanly described, and conceptually sound. The assumption that time alignment can be used for the state pairing seems problematic, and should be further validated.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for pointing out the highly related work by ( Ammar et al.2015 ) .In order to ensure a fair comparison we use the Matlab code provided by Chang Wang ( https : //sites.google.com/site/changwangnk/home/ma-html ) . We find that the unsupervised manifold learning method described in ( Wang and Mahadevan 2009 ) and ( Ammar et al.2015 ) performs poorly . We suspect that this is because the method relies on pairwise distance and the raw state spaces do not provide a meaningful metric space . Ammar et al use a hand-specified feature mapping phi that provides a good metric space for the method . As we assume no prior knowledge about the state space , we do not have a hand-specific feature mapping in our experiments . We would like to clarify that our primary contribution is to learn a feature space in which the source and target states can be compared . This differs from prior work because we do not reconstruct the source states from target states , allowing the embeddings to discard information that is not common . This is more suitable for transferring between robots with varying morphologies . To address your comment about assuming correspondences , we have formulated an alternating optimization , alternating between establishing common feature space using current correspondences , and reestablishing correspondences using current feature space and dynamic time warping . This is described in detail in Section 3.3.2 , and results are seen in Fig 5 , Fig 7a . As suggested , we have also run comparisons with several prior methods such as ( Ammar et al.2015 ) , kernel CCA , random projections , CCA and using state mappings instead of embeddings . These results are shown in Figures 5 and 7a , and show the advantage of using our proposed method over several prior methods . Although kernel CCA is quite competitive with our method on the tendon task , it performs very poorly on the button task while our method is able to achieve excellent performance on both . Unfortunately we could not compare to the work in Raimalwala et al ( 2016 ) because it is quite specific to systems which have a single input , a single output , and can be modeled as linear time invariant . Our tasks are nonlinear and have multidimensional states ."}}