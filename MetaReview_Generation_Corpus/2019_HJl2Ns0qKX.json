{"year": "2019", "forum": "HJl2Ns0qKX", "title": "Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourages convex latent distributions", "decision": "Reject", "meta_review": "The idea of the paper -- imposing a GAN type loss on the latent interpolations of an autoencoder -- is interesting. However there are strong concerns from R2 and R3 about limited experimental evaluation of the proposed method which falls short of demonstrating its advantages over latent spaces learned by existing GANs. Another point of concern was the use of only one real dataset (CelebA). Authors made substantial revisions to the paper in addressing many of the reviewers' points but these core concerns still persist with the current draft and it's not ready for publication at ICLR. Authors are encouraged to address these concerns and resubmit to another venue. ", "reviews": [{"review_id": "HJl2Ns0qKX-0", "review_text": " Update: I\u2019d like to thank the authors for their thoroughness in responding to the issues I raised. I will echo my fellow reviewers in saying that I would encourage the authors to submit to another venue, given the substantial modifications made to the original submission. The updated version provides a clearer context for the proposed approach (phychophysical experimentation) and avoids mischaracterizing GAIA as a generative model. Despite more emphasis being put on mentioning the existence of bidirectional variants of GANs, I still feel that the paper does not adequately address the following question: \u201cWhat does GAIA offer that is not already achievable by models such as ALI, BiGAN, ALICE, and IAE, which equip GANs with an inference mechanism and can be used to perform interpolations between data points and produce sharp interpolates?\u201d To be clear, I do think that the above models are inadequate for the paper\u2019s intended use (because their reconstructions tend to be semantically similar but noticeably different perceptually), but I believe this is a question that is likely to be raised by many readers. To answer the authors\u2019 questions: - Flow-based generative models such as RealNVP relate to gaussian latent spaces in that they learn to map from the data distribution to a simple base distribution (usually a Gaussian distribution) in a way that is invertible (and which makes the computation of the Jacobian\u2019s determinant tractable). The base distribution can be seen as a Gaussian latent space which has the same dimensionality as the data space. - Papers on building more flexible approximate posteriors in VAEs: in addition to the inverse autoregressive flow paper already cited in the submission, I would point the authors to Rezende and Mohamed\u2019s \u201cVariational Inference with Normalizing Flows\u201d, Huang et al.\u2019s \u201cNeural Autoregressive Flows\u201d, and van den Berg et al.\u2019s \u201cSylvester Normalizing Flows for Variational Inference\u201d. ----- The paper title summarizes the main claim of the paper: \"adversarial training on latent space interpolations encourage[s] convex latent distributions\". A convex latent space is defined as a space in which a linear interpolation between latent codes obtained by encoding a pair of points from some data distribution yields latent codes whose decoding also belongs to the same data distribution. The authors argue that current leading approaches fall short of producing convex latent spaces while preserving the \"high-dimensional structure of the original distribution\". They propose a GAN-AE hybrid, called GAIA, which they claim addresses this issue. The proposed approach turns the GAN generator and discriminator into autoencoders, and the adversarial game is framed in terms of minimizing/maximizing the discriminator\u2019s reconstruction error. In addition to that, interpolations between pairs of data points are computed in the generator\u2019s latent space, and the interpolations are decoded and treated as generator samples. A regularization term is introduced to encourage distances between pairs of data points to be mirrored by their representation in the generator\u2019s latent space. The proposed approach is evaluated through qualitative inspection of latent space interpolations, attribute manipulations, attribute vectors, and generator reconstructions. Overall I feel like the problem presented in the paper is well-justified, but the paper itself does not build a sufficiently strong argument in favor of the proposed approach for me to recommend its acceptance. I do think there is a case to be made for a model which exhibits sharp reconstructions and which allows realistic latent space manipulations -- and this is in some ways put forward in the introduction -- but I don\u2019t feel that the way in which the paper is currently cast highlights this very well. Here is a detailed breakdown of why, and where I think it should be improved, roughly ordered by importance: - The main reason for my reluctance to accept the paper is the fact that its main subject is convex latent spaces, yet I don\u2019t see that reflected in the evaluation. The authors do not address how to evaluate (quantitatively or qualitatively) whether a certain model exhibits a convex latent space, and how to compare competing approaches with respect to latent space convexity. Figure 2 does present latent space interpolations which help get a sense of the extent to which interpolates also belong to the data distribution, however in the absence of a comparison to competing approaches it\u2019s impossible for me to tell whether the proposed approach yields more convex latent spaces. - I don\u2019t agree with the premise that current approaches are insufficient. The authors claim that autoencoders produce blurry reconstructions; while this may be true for factorized decoders, autoregressive decoders should alleviate this issue. They also claim that GANs lack bidirectionality but fail to mention the existing line of work in that direction (ALI, BiGAN, ALICE, and more recently Implicit Autoencoders). Finally, although flow-based generative models are mentioned later in the paper, they are not discussed in Section 1.2 when potential approaches to building convex latent spaces are enumerated and declared insufficient. As a result, the paper feels a little disconnected from the current state of the generative modeling literature. - The necessity for latent spaces to \"respect the high-dimensional structure of the [data] distribution\" is stated as a fact but not well-justified. How do we determine whether a marginal posterior is \"a suboptimal representation of the high-dimensional dataset\"? I think a more nuanced statement would be necessary. For instance, many recent approaches have been proposed to build more flexible approximate posteriors in VAEs; would that go some way towards embedding the data distribution in a more natural way? - I also question whether latent space convexity is a property that should always hold. In the case of face images a reasonable argument can be made, but in a dataset such as CIFAR10 how should we linearly interpolate between a horse and a car? - The proposed model is presented in the abstract as an \"AE which produces non-blurry samples\", but it\u2019s not clear to me how one would sample from such a model. The generator is defined as a mapping from data points to their reconstruction; does this mean that the sampling procedure requires access to training examples? Alternatively one could fit a prior distribution on top of the latent codes and their interpolations, but as far as I can tell this is not discussed in the paper. I would like to see a more thorough discussion on the subject. - When comparing reconstructions with competing approaches there are several confounding factors, like the resolution at which the models were trained and the fact that they all reconstruct different inputs. Removing those confounding factors by comparing models trained at the same resolution and reconstructing the same inputs would help a great deal in comparing each approach. - The structure-preserving regularization term compares distances in X and Z space, but I doubt that pixelwise Euclidian distances are good at capturing an intuitive notion of distance: for example, if we translate an image by a few pixels the result is perceptually very similar but its Euclidian distance to the original image is likely to be high. As far as I can tell, the paper does not present evidence backing up the claim that the regularization term does indeed preserve local structure. - Figures 2 and 3 are never referenced in the main text, and I am left to draw my own conclusions as to what claim they are supporting. As far as I can tell they showcase the general capabilities of the proposed approach, but I would have liked to see a discussion of whether and how they improve on results that can be achieved by competing approaches. - The decision of making the discriminator an autoencoder is briefly justified when discussing related work; I would have liked to see a more upfront and explicit justification when first introducing the model architecture. - When discussing feature vectors it would be appropriate to also mention Tom White\u2019s paper on Sampling Generative Networks.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , We thank you for your comprehensive list of issues raised with the initial submission of our article . We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission . In response to each reviewer , we have divided each review into a point-by-point list of each issue raised followed by our response , pointing to where that issue was addressed in the text . We have made several major revisions , listed below , as well as a number of other revisions which are addressed point-by-point in response to reviewers . Major revisions : As requested by all three reviewers , we added a set of quantitative and ablation experiments on a low dimensional dataset . These experiments can be seen in Figures 2 and 6 , as well as Table 1 . We added an experiments section to the text and rearranged the text for structure . We rewrote sections of the introduction to better motivate our research . We added a number of relevant references and extended our discussion of related works . We edited the entire document for consistent notation both internally and to other related papers . We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input . ________________________________________ `` - The main reason for my reluctance to accept the paper is the fact that its main subject is convex latent spaces , yet I don \u2019 t see that reflected in the evaluation . The authors do not address how to evaluate ( quantitatively or qualitatively ) whether a certain model exhibits a convex latent space , and how to compare competing approaches with respect to latent space convexity . Figure 2 does present latent space interpolations which help get a sense of the extent to which interpolates also belong to the data distribution , however in the absence of a comparison to competing approaches it \u2019 s impossible for me to tell whether the proposed approach yields more convex latent spaces . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We added an experiment section in which we trained GAIA , and AE , and a VAE on 2D several distributions ( Section 3.1 ) . In this experiment , we show qualitative and quantitative results which confirm that GAIA is learning to yield interpolated samples which more directly model the true data distribution in X . ________________________________________ `` - I don \u2019 t agree with the premise that current approaches are insufficient . The authors claim that autoencoders produce blurry reconstructions ; while this may be true for factorized decoders , autoregressive decoders should alleviate this issue . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We have specified that we are referring to certain subsets of autoencoders . We expanded upon our discussions in related works as well as the introduction about alternative approaches ."}, {"review_id": "HJl2Ns0qKX-1", "review_text": "Update: I appreciate the effort put by the authors into improving the paper. The revised draft is much better than the initial one. But I agree to AnonReviewer2 in that the degree to which this paper has to be modified goes beyond what the review process (even at ICLR) assumes. It is wrong to submit a very unfinished paper and then use the review period to polish it and add results. This incurs unnecessary extra load on the review process. The added 2D results are toy-ish and somewhat confusing (I am not sure I understand what the meshgrids are and what do they tell us). Generally, some toy examples are good to illustrate the method, but they are not enough as a serious evaluation. The paper should have more results on complex datasets, like for instance ImageNet or LSUN or CIFAR or so, and should have comparisons to existing VAE-GAN hybrids, like VAE-GAN. Also, since a lot of the authors\u2019 motivation seems to come from psychophysics, showing some application to that might be a good way to showcase the value of the method (although this may not go well if submitting to machine learning conferences). I encourage the authors to further strengthen the paper and resubmit to another venue. ----- The paper proposes a model for image generation that combines an autoencoder with a generative adversarial network (GAN). The GAN is used to enforce that interpolations between latent vectors of two samples from the training set are decoded to realistic images. The method is applied to attribute manipulation and interpolation of face images. Pros: 1) A simple and reasonable formulation 2) Visually good reconstruction of samples and convincing interpolation between samples on the CelebA-HQ dataset. 3) Good qualitative facial attribute manipulation results on the CelebA-HQ dataset. Cons: 1) Experimental evaluation is very limited. There is just one dataset and only qualitative results. This is unacceptable: the method should be evaluated on more datasets and there should be quantitative results. I do realize it is not trivial to get quantitative, but it is possible. For instance, a user study can always be performed. But I believe one could also come up with simpler-to-measure metrics for at least some of the reported tasks. There is no comparison to other methods for facial attribute manipulation (for instance, StarGAN). 2) There is no ablation study. To which extent is each of the model components important? For instance, the interpolation adversarial loss, the discriminator/generator balancing term, the network architecture (autoencoder discriminator)? 3) As I understand, it is impossible to randomly sample directly from the model, only interpolate/modify existing images. This is a difference from most of prior work. It should be discussed clearly. 4) Related work discussion is quite brief and misses some relevant work, for instance Adversarial Autoencoders (Makhazani et al., ICLR 2016, somewhat related) or Adversarially Constrained Autoencoder Interpolations (Berthelot et al., arxiv 2018, it\u2019s concurrent, but could be good to discuss). 5) Writing is not of very high quality. There are typos, grammatical issues, and questionable statements. The manuscript should be significantly improved. Specific comments: - The structure is quite strange. There is no separation between the method and the experiments, the related work comes in very late and is very brief. This is all not critical, but confusing. - A typo in the title: should be \u201cencourages\u201d - Second sentence of the introduction should be supported with evidence (for instance references) - \u201cTwo unsupervised neural network based algorithms, the Autoencoder (AE; Hinton & Salakhutdinov 2006) and Generative Adversarial Network (GAN; Goodfellow et al. 2014), are at present the most popular tools in generative modeling.\u201d - Vanilla autoencoders are not very popular tools for generative modeling. Variational autoencoders and some other flavors are. - \u201cUnsupervised neural network approaches are often ideal generative models because they require little or no tweaking of network architectures to handle entirely new datasets.\u201d I do not really get this sentence. What is the alternative to unsupervised generative models? Why do unsupervised approaches not require tweaking? (In my experience, they very well benefit from tweaking.) - \u201c\u2026 a lack of certain constraints on the generative capacity of current neural-network based generative models make it challenging to infer structure from their latent generative representations.\u201d What does \u201ca lack of certain constraints\u201d mean? There are some constraints, for instance the latent space is usually forced to correspond to a fixed distribution. Moreover, there is a lot of work on disentangling that also aims to find structure in latent spaces (for instance, InfoGAN). - \u201cand promotes convexity in the model\u2019s generative capacity.\u201d What is convexity in the capacity? I do not think this is grammatical. - In 1.1 the mathematical notation seems wrong. Does X really denote a set? In what follows it seems that X is used interchangeably for three different things: a sample from the dataset, the set of training samples, and the space the samples come from. - \u201cbidirectionality of adversarially generated data.\u201d What is bidirectional data? - \u201cAEs tend to produce blurry images due to their pixel-wise error functions (Larsen et al., 2015)\u201d Perhaps this was intended to refer to VAEs. AEs can generate perfectly sharp images if given enough capacity. - \u201cmethod more greatly resembles the original data than other GAN-based methods\u201d Method does not resemble data - \u201cDue to their exact latent-variable inference, these architectures may also provide a useful direction for developing generative models to explore latent-spaces of data for generating datasets for psychophysical experiments.\u201d This is mentioned a few times, but never supported - Acknowledgements should not be in the review version (can violate anonymity) 5) Minor: Why is a Gaussian around the midpoint used for interpolations? Why not all convex combinations of two, or possibly more, samples? To conclude, the paper presents quite good qualitative results on the CelebA-HQ dataset, but has problems with the thoroughness of the experimental evaluation, discussion of the related work, and presentation. The paper cannot be published in its current form. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Dear reviewer , We thank you for your comprehensive list of issues raised with the initial submission of our article . We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission . In response to each reviewer , we have divided each review into a point-by-point list of each issue raised followed by our response , pointing to where that issue was addressed in the text . We have made several major revisions , listed below , as well as a number of other revisions which are addressed point-by-point in response to reviewers . Major revisions : As requested by all three reviewers , we added a set of quantitative and ablation experiments on a low dimensional dataset . These experiments can be seen in Figures 2 and 6 , as well as Table 1 . We added an experiments section to the text and rearranged the text for structure . We rewrote sections of the introduction to better motivate our research . We added a number of relevant references and extended our discussion of related works . We edited the entire document for consistent notation both internally and to other related papers . We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input . ________________________________________ `` 1 ) Experimental evaluation is very limited . There is just one dataset and only qualitative results . This is unacceptable : the method should be evaluated on more datasets and there should be quantitative results . I do realize it is not trivial to get quantitative , but it is possible . For instance , a user study can always be performed . But I believe one could also come up with simpler-to-measure metrics for at least some of the reported tasks. `` -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We have performed additional experiments on lower-dimensional ( 2D ) datasets comparing our results to vanilla autoencoders and variational autoencoders . These experiments were added to section 3.1 , see Figures 2 and 6 , as well as and Table 1 . ________________________________________ `` There is no comparison to other methods for facial attribute manipulation ( for instance , StarGAN ) . '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We added a discussion to section 3.2.1 about prior work on attribute manipulation . We discuss models which utilize feature information during learning ( e.g.StarGAN , CycleGAN , etc ) and models in which latent features are not part of learning . ________________________________________ `` 2 ) There is no ablation study . To which extent is each of the model components important ? For instance , the interpolation adversarial loss , the discriminator/generator balancing term , the network architecture ( autoencoder discriminator ) ? '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have added ablation studies of the lower-dimensional datasets . In particular , we ablate ( 1 ) the multidimensional scaling error function and find that pairwise distance in Z vs X is impacted , and we able ( 2 ) we effectively ablate the adversarial loss function from GAIA ( by comparing a vanilla AE ) . We find the generated likelihood of generated latent interpolations in both cases decreases ( Table 1 ) . ________________________________________ `` 3 ) As I understand , it is impossible to randomly sample directly from the model , only interpolate/modify existing images . This is a difference from most of the prior work . It should be discussed clearly . '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We added a discussion in section 1.1 about the difference between generative and non-generative models . We now state explicitly that GAIA is not a generative model , and discuss the implications for random sampling . ________________________________________ `` 4 ) Related work discussion is quite brief and misses some relevant work , for instance , Adversarial Autoencoders ( Makhazani et al. , ICLR 2016 , somewhat related ) or Adversarially Constrained Autoencoder Interpolations ( Berthelot et al. , arXiv 2018 , it \u2019 s concurrent , but could be good to discuss ) . '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We significantly expanded upon our discussion of related work such as Makhazani et al ( 2016 ) in section 3.3 . We also Adversarial Autoencoders and Adversarially Constrained Autoencoder Interpolations ( ACAI ) . ________________________________________ `` 5 ) Writing is not of very high quality . There are typos , grammatical issues , and questionable statements . The manuscript should be significantly improved. `` -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have performed a significant rewrite of our paper to improve the clarity and organization of the writing ."}, {"review_id": "HJl2Ns0qKX-2", "review_text": "This paper proposes an autoencoder architecture and training procedure for producing high-quality reconstructions and realistic interpolations. A \"generator\" autoencoder is trained to fool a \"discriminator\" autoencoder. The generator tries to minimize its own reconstruction error and minimize the reconstruction error of the discriminator when fed with interpolated latent vectors of real datapoints. The discriminator autoencoder has three losses, corresponding to minimizing reconstruction error on real datapoints and maximizing reconstruction error on the generator's output on both real datapoints and interpolated outputs. The authors also propose a loss which encourages the distances between real datapoints and their corresponding latent vectors to be similar, as well as a heuristic procedure for stabilizing GAN training. Qualitative results are shown on CelebA. While the results look nice, the paper is not fit for publication in its current form. At a high level, the issues include a lack of convincing experimental verification of the method, a generally contradictory and confusing description of the methods, and frequent factual errors or mischaracterizations. Here I will try to describe many of the issues I found while reading the paper: - Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure. The experimental results are completely qualitative. No effort is made to provide a quantitative proof of claims such as \"the reconstructions are less blurry\" or \"the interpolations are higher quality\"; only a few examples are shown. The experiments are not even described in the text, and many of the figures are unreferenced. No ablation studies are done to determine the importance of different loss terms, such as L_dist. No mention is given to how hyperparameters like alpha should be chosen (and in fact, the value given for it \"1^{-4}/2\" is nonsense; 1^{-4} is just 1). No results for a baseline autoencoder (i.e., just optimizing reconstruction loss) are given. - At a higher level, no effort is given to argue why interpolation is a useful characteristic to try to encourage. There are no downstream applications proposed or tested. Earlier models, such as VAEGAN, also give reasonable reconstructions and good interpolations. Why is GAIA better? On what problem would I use GAIA and achieve better results apart from making nice-looking interpolations of people's faces? - Definitions are often unclear or contradictory. For example, the generator autoencoder is alternatingly treating as taking input X and taking input Z. I believe what is meant is that the generator consists of two networks which compute Z = encoder(X) and X = decoder(Z). Instead, the paper just switches between G(Z) and G(X) wherever convenient. Similarly, the equation for \\delta_Disc is different in Algorithm 1 and in the equation in 2.2. Interpolation, arguably one of the core parts of the model, is described as \"interpolations are Euclidean interpolations between pairs of points in Z, sampled from a Gaussian distribution around the midpoint between Zg1en and Zg2en.\" I assume the mean of this Gaussian is the midpoint; what is its covariance? Etc. - All autoencoders are not generative models, and in particular GAIA is not a generative model. There is no generative process. It does not estimate a data distribution. A VAE is a generative model which an autoencoder-like structure, but this does not make all autoencoders generative models. - GAIA is described as encouraging \"convex latent distributions\" and a convex set is defined in the text as \"A convex set of points is defined as a set in which the line connecting any pair of points will fall within the rest of the set.\" A convex set is not defined in terms of lines; it's defined in terms of convex combinations of points within the set. In the paper, only lines between points are considered. Claiming that the latent space is \"convex\" in the sense of purple blobs in B is not done - you would need to take a convex combination of multiple latent vectors and decode the results. This is an incomplete list of the issues with this paper. The paper would need significant changes before publication.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , We thank you for your comprehensive list of issues raised with the initial submission of our article . We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission . In response to each reviewer , we have divided each review into a point-by-point list of each issue raised followed by our response , pointing to where that issue was addressed in the text . We have made several major revisions , listed below , as well as a number of other revisions which are addressed point-by-point in response to reviewers . Major revisions : As requested by all three reviewers , we added a set of quantitative and ablation experiments on a low dimensional dataset . These experiments can be seen in Figures 2 and 6 , as well as Table 1 . We added an experiments section to the text and rearranged the text for structure . We rewrote sections of the introduction to better motivate our research . We added a number of relevant references and extended our discussion of related works . We edited the entire document for consistent notation both internally and to other related papers . We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input . ________________________________________ `` - Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure . The experimental results are completely qualitative . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We added a low dimensional dataset example ( Figure 2 , Table 1 , Figure 6 ) , and a quantitative assessment of the likelihood of interpolations and reconstructions , the correlation between latent structure and structure in high dimensional space , and the KL divergence between data and interpolations , as well as data and reconstructions . We compared a VAE , and AE , and GAIA ( both with and without the pairwise-distance loss term ) . ________________________________________ `` No effort is made to provide a quantitative proof of claims such as `` the reconstructions are less blurry '' or `` the interpolations are higher quality '' ; only a few examples are shown . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We edited these section and sentences to not make comparative claims . We now show examples in the appendix of reconstructions on several low dimensional datasets . We can add additional interpolation and attribute vector figures in the appendix as well if the reviewer finds it important . ________________________________________ `` The experiments are not even described in the text , and many of the figures are unreferenced . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We added an experiments section to the text which now includes subsections for both datasets , describing each measure . ________________________________________ `` No ablation studies are done to determine the importance of different loss terms , such as L_dist . No mention is given to how hyperparameters like alpha should be chosen -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We now perform an ablation study by comparing our autoencoder with adversarial regularization , to an autoencoder of the same architecture without regularization . We also ablate L_dist ."}], "0": {"review_id": "HJl2Ns0qKX-0", "review_text": " Update: I\u2019d like to thank the authors for their thoroughness in responding to the issues I raised. I will echo my fellow reviewers in saying that I would encourage the authors to submit to another venue, given the substantial modifications made to the original submission. The updated version provides a clearer context for the proposed approach (phychophysical experimentation) and avoids mischaracterizing GAIA as a generative model. Despite more emphasis being put on mentioning the existence of bidirectional variants of GANs, I still feel that the paper does not adequately address the following question: \u201cWhat does GAIA offer that is not already achievable by models such as ALI, BiGAN, ALICE, and IAE, which equip GANs with an inference mechanism and can be used to perform interpolations between data points and produce sharp interpolates?\u201d To be clear, I do think that the above models are inadequate for the paper\u2019s intended use (because their reconstructions tend to be semantically similar but noticeably different perceptually), but I believe this is a question that is likely to be raised by many readers. To answer the authors\u2019 questions: - Flow-based generative models such as RealNVP relate to gaussian latent spaces in that they learn to map from the data distribution to a simple base distribution (usually a Gaussian distribution) in a way that is invertible (and which makes the computation of the Jacobian\u2019s determinant tractable). The base distribution can be seen as a Gaussian latent space which has the same dimensionality as the data space. - Papers on building more flexible approximate posteriors in VAEs: in addition to the inverse autoregressive flow paper already cited in the submission, I would point the authors to Rezende and Mohamed\u2019s \u201cVariational Inference with Normalizing Flows\u201d, Huang et al.\u2019s \u201cNeural Autoregressive Flows\u201d, and van den Berg et al.\u2019s \u201cSylvester Normalizing Flows for Variational Inference\u201d. ----- The paper title summarizes the main claim of the paper: \"adversarial training on latent space interpolations encourage[s] convex latent distributions\". A convex latent space is defined as a space in which a linear interpolation between latent codes obtained by encoding a pair of points from some data distribution yields latent codes whose decoding also belongs to the same data distribution. The authors argue that current leading approaches fall short of producing convex latent spaces while preserving the \"high-dimensional structure of the original distribution\". They propose a GAN-AE hybrid, called GAIA, which they claim addresses this issue. The proposed approach turns the GAN generator and discriminator into autoencoders, and the adversarial game is framed in terms of minimizing/maximizing the discriminator\u2019s reconstruction error. In addition to that, interpolations between pairs of data points are computed in the generator\u2019s latent space, and the interpolations are decoded and treated as generator samples. A regularization term is introduced to encourage distances between pairs of data points to be mirrored by their representation in the generator\u2019s latent space. The proposed approach is evaluated through qualitative inspection of latent space interpolations, attribute manipulations, attribute vectors, and generator reconstructions. Overall I feel like the problem presented in the paper is well-justified, but the paper itself does not build a sufficiently strong argument in favor of the proposed approach for me to recommend its acceptance. I do think there is a case to be made for a model which exhibits sharp reconstructions and which allows realistic latent space manipulations -- and this is in some ways put forward in the introduction -- but I don\u2019t feel that the way in which the paper is currently cast highlights this very well. Here is a detailed breakdown of why, and where I think it should be improved, roughly ordered by importance: - The main reason for my reluctance to accept the paper is the fact that its main subject is convex latent spaces, yet I don\u2019t see that reflected in the evaluation. The authors do not address how to evaluate (quantitatively or qualitatively) whether a certain model exhibits a convex latent space, and how to compare competing approaches with respect to latent space convexity. Figure 2 does present latent space interpolations which help get a sense of the extent to which interpolates also belong to the data distribution, however in the absence of a comparison to competing approaches it\u2019s impossible for me to tell whether the proposed approach yields more convex latent spaces. - I don\u2019t agree with the premise that current approaches are insufficient. The authors claim that autoencoders produce blurry reconstructions; while this may be true for factorized decoders, autoregressive decoders should alleviate this issue. They also claim that GANs lack bidirectionality but fail to mention the existing line of work in that direction (ALI, BiGAN, ALICE, and more recently Implicit Autoencoders). Finally, although flow-based generative models are mentioned later in the paper, they are not discussed in Section 1.2 when potential approaches to building convex latent spaces are enumerated and declared insufficient. As a result, the paper feels a little disconnected from the current state of the generative modeling literature. - The necessity for latent spaces to \"respect the high-dimensional structure of the [data] distribution\" is stated as a fact but not well-justified. How do we determine whether a marginal posterior is \"a suboptimal representation of the high-dimensional dataset\"? I think a more nuanced statement would be necessary. For instance, many recent approaches have been proposed to build more flexible approximate posteriors in VAEs; would that go some way towards embedding the data distribution in a more natural way? - I also question whether latent space convexity is a property that should always hold. In the case of face images a reasonable argument can be made, but in a dataset such as CIFAR10 how should we linearly interpolate between a horse and a car? - The proposed model is presented in the abstract as an \"AE which produces non-blurry samples\", but it\u2019s not clear to me how one would sample from such a model. The generator is defined as a mapping from data points to their reconstruction; does this mean that the sampling procedure requires access to training examples? Alternatively one could fit a prior distribution on top of the latent codes and their interpolations, but as far as I can tell this is not discussed in the paper. I would like to see a more thorough discussion on the subject. - When comparing reconstructions with competing approaches there are several confounding factors, like the resolution at which the models were trained and the fact that they all reconstruct different inputs. Removing those confounding factors by comparing models trained at the same resolution and reconstructing the same inputs would help a great deal in comparing each approach. - The structure-preserving regularization term compares distances in X and Z space, but I doubt that pixelwise Euclidian distances are good at capturing an intuitive notion of distance: for example, if we translate an image by a few pixels the result is perceptually very similar but its Euclidian distance to the original image is likely to be high. As far as I can tell, the paper does not present evidence backing up the claim that the regularization term does indeed preserve local structure. - Figures 2 and 3 are never referenced in the main text, and I am left to draw my own conclusions as to what claim they are supporting. As far as I can tell they showcase the general capabilities of the proposed approach, but I would have liked to see a discussion of whether and how they improve on results that can be achieved by competing approaches. - The decision of making the discriminator an autoencoder is briefly justified when discussing related work; I would have liked to see a more upfront and explicit justification when first introducing the model architecture. - When discussing feature vectors it would be appropriate to also mention Tom White\u2019s paper on Sampling Generative Networks.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , We thank you for your comprehensive list of issues raised with the initial submission of our article . We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission . In response to each reviewer , we have divided each review into a point-by-point list of each issue raised followed by our response , pointing to where that issue was addressed in the text . We have made several major revisions , listed below , as well as a number of other revisions which are addressed point-by-point in response to reviewers . Major revisions : As requested by all three reviewers , we added a set of quantitative and ablation experiments on a low dimensional dataset . These experiments can be seen in Figures 2 and 6 , as well as Table 1 . We added an experiments section to the text and rearranged the text for structure . We rewrote sections of the introduction to better motivate our research . We added a number of relevant references and extended our discussion of related works . We edited the entire document for consistent notation both internally and to other related papers . We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input . ________________________________________ `` - The main reason for my reluctance to accept the paper is the fact that its main subject is convex latent spaces , yet I don \u2019 t see that reflected in the evaluation . The authors do not address how to evaluate ( quantitatively or qualitatively ) whether a certain model exhibits a convex latent space , and how to compare competing approaches with respect to latent space convexity . Figure 2 does present latent space interpolations which help get a sense of the extent to which interpolates also belong to the data distribution , however in the absence of a comparison to competing approaches it \u2019 s impossible for me to tell whether the proposed approach yields more convex latent spaces . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We added an experiment section in which we trained GAIA , and AE , and a VAE on 2D several distributions ( Section 3.1 ) . In this experiment , we show qualitative and quantitative results which confirm that GAIA is learning to yield interpolated samples which more directly model the true data distribution in X . ________________________________________ `` - I don \u2019 t agree with the premise that current approaches are insufficient . The authors claim that autoencoders produce blurry reconstructions ; while this may be true for factorized decoders , autoregressive decoders should alleviate this issue . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We have specified that we are referring to certain subsets of autoencoders . We expanded upon our discussions in related works as well as the introduction about alternative approaches ."}, "1": {"review_id": "HJl2Ns0qKX-1", "review_text": "Update: I appreciate the effort put by the authors into improving the paper. The revised draft is much better than the initial one. But I agree to AnonReviewer2 in that the degree to which this paper has to be modified goes beyond what the review process (even at ICLR) assumes. It is wrong to submit a very unfinished paper and then use the review period to polish it and add results. This incurs unnecessary extra load on the review process. The added 2D results are toy-ish and somewhat confusing (I am not sure I understand what the meshgrids are and what do they tell us). Generally, some toy examples are good to illustrate the method, but they are not enough as a serious evaluation. The paper should have more results on complex datasets, like for instance ImageNet or LSUN or CIFAR or so, and should have comparisons to existing VAE-GAN hybrids, like VAE-GAN. Also, since a lot of the authors\u2019 motivation seems to come from psychophysics, showing some application to that might be a good way to showcase the value of the method (although this may not go well if submitting to machine learning conferences). I encourage the authors to further strengthen the paper and resubmit to another venue. ----- The paper proposes a model for image generation that combines an autoencoder with a generative adversarial network (GAN). The GAN is used to enforce that interpolations between latent vectors of two samples from the training set are decoded to realistic images. The method is applied to attribute manipulation and interpolation of face images. Pros: 1) A simple and reasonable formulation 2) Visually good reconstruction of samples and convincing interpolation between samples on the CelebA-HQ dataset. 3) Good qualitative facial attribute manipulation results on the CelebA-HQ dataset. Cons: 1) Experimental evaluation is very limited. There is just one dataset and only qualitative results. This is unacceptable: the method should be evaluated on more datasets and there should be quantitative results. I do realize it is not trivial to get quantitative, but it is possible. For instance, a user study can always be performed. But I believe one could also come up with simpler-to-measure metrics for at least some of the reported tasks. There is no comparison to other methods for facial attribute manipulation (for instance, StarGAN). 2) There is no ablation study. To which extent is each of the model components important? For instance, the interpolation adversarial loss, the discriminator/generator balancing term, the network architecture (autoencoder discriminator)? 3) As I understand, it is impossible to randomly sample directly from the model, only interpolate/modify existing images. This is a difference from most of prior work. It should be discussed clearly. 4) Related work discussion is quite brief and misses some relevant work, for instance Adversarial Autoencoders (Makhazani et al., ICLR 2016, somewhat related) or Adversarially Constrained Autoencoder Interpolations (Berthelot et al., arxiv 2018, it\u2019s concurrent, but could be good to discuss). 5) Writing is not of very high quality. There are typos, grammatical issues, and questionable statements. The manuscript should be significantly improved. Specific comments: - The structure is quite strange. There is no separation between the method and the experiments, the related work comes in very late and is very brief. This is all not critical, but confusing. - A typo in the title: should be \u201cencourages\u201d - Second sentence of the introduction should be supported with evidence (for instance references) - \u201cTwo unsupervised neural network based algorithms, the Autoencoder (AE; Hinton & Salakhutdinov 2006) and Generative Adversarial Network (GAN; Goodfellow et al. 2014), are at present the most popular tools in generative modeling.\u201d - Vanilla autoencoders are not very popular tools for generative modeling. Variational autoencoders and some other flavors are. - \u201cUnsupervised neural network approaches are often ideal generative models because they require little or no tweaking of network architectures to handle entirely new datasets.\u201d I do not really get this sentence. What is the alternative to unsupervised generative models? Why do unsupervised approaches not require tweaking? (In my experience, they very well benefit from tweaking.) - \u201c\u2026 a lack of certain constraints on the generative capacity of current neural-network based generative models make it challenging to infer structure from their latent generative representations.\u201d What does \u201ca lack of certain constraints\u201d mean? There are some constraints, for instance the latent space is usually forced to correspond to a fixed distribution. Moreover, there is a lot of work on disentangling that also aims to find structure in latent spaces (for instance, InfoGAN). - \u201cand promotes convexity in the model\u2019s generative capacity.\u201d What is convexity in the capacity? I do not think this is grammatical. - In 1.1 the mathematical notation seems wrong. Does X really denote a set? In what follows it seems that X is used interchangeably for three different things: a sample from the dataset, the set of training samples, and the space the samples come from. - \u201cbidirectionality of adversarially generated data.\u201d What is bidirectional data? - \u201cAEs tend to produce blurry images due to their pixel-wise error functions (Larsen et al., 2015)\u201d Perhaps this was intended to refer to VAEs. AEs can generate perfectly sharp images if given enough capacity. - \u201cmethod more greatly resembles the original data than other GAN-based methods\u201d Method does not resemble data - \u201cDue to their exact latent-variable inference, these architectures may also provide a useful direction for developing generative models to explore latent-spaces of data for generating datasets for psychophysical experiments.\u201d This is mentioned a few times, but never supported - Acknowledgements should not be in the review version (can violate anonymity) 5) Minor: Why is a Gaussian around the midpoint used for interpolations? Why not all convex combinations of two, or possibly more, samples? To conclude, the paper presents quite good qualitative results on the CelebA-HQ dataset, but has problems with the thoroughness of the experimental evaluation, discussion of the related work, and presentation. The paper cannot be published in its current form. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Dear reviewer , We thank you for your comprehensive list of issues raised with the initial submission of our article . We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission . In response to each reviewer , we have divided each review into a point-by-point list of each issue raised followed by our response , pointing to where that issue was addressed in the text . We have made several major revisions , listed below , as well as a number of other revisions which are addressed point-by-point in response to reviewers . Major revisions : As requested by all three reviewers , we added a set of quantitative and ablation experiments on a low dimensional dataset . These experiments can be seen in Figures 2 and 6 , as well as Table 1 . We added an experiments section to the text and rearranged the text for structure . We rewrote sections of the introduction to better motivate our research . We added a number of relevant references and extended our discussion of related works . We edited the entire document for consistent notation both internally and to other related papers . We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input . ________________________________________ `` 1 ) Experimental evaluation is very limited . There is just one dataset and only qualitative results . This is unacceptable : the method should be evaluated on more datasets and there should be quantitative results . I do realize it is not trivial to get quantitative , but it is possible . For instance , a user study can always be performed . But I believe one could also come up with simpler-to-measure metrics for at least some of the reported tasks. `` -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We have performed additional experiments on lower-dimensional ( 2D ) datasets comparing our results to vanilla autoencoders and variational autoencoders . These experiments were added to section 3.1 , see Figures 2 and 6 , as well as and Table 1 . ________________________________________ `` There is no comparison to other methods for facial attribute manipulation ( for instance , StarGAN ) . '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We added a discussion to section 3.2.1 about prior work on attribute manipulation . We discuss models which utilize feature information during learning ( e.g.StarGAN , CycleGAN , etc ) and models in which latent features are not part of learning . ________________________________________ `` 2 ) There is no ablation study . To which extent is each of the model components important ? For instance , the interpolation adversarial loss , the discriminator/generator balancing term , the network architecture ( autoencoder discriminator ) ? '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have added ablation studies of the lower-dimensional datasets . In particular , we ablate ( 1 ) the multidimensional scaling error function and find that pairwise distance in Z vs X is impacted , and we able ( 2 ) we effectively ablate the adversarial loss function from GAIA ( by comparing a vanilla AE ) . We find the generated likelihood of generated latent interpolations in both cases decreases ( Table 1 ) . ________________________________________ `` 3 ) As I understand , it is impossible to randomly sample directly from the model , only interpolate/modify existing images . This is a difference from most of the prior work . It should be discussed clearly . '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We added a discussion in section 1.1 about the difference between generative and non-generative models . We now state explicitly that GAIA is not a generative model , and discuss the implications for random sampling . ________________________________________ `` 4 ) Related work discussion is quite brief and misses some relevant work , for instance , Adversarial Autoencoders ( Makhazani et al. , ICLR 2016 , somewhat related ) or Adversarially Constrained Autoencoder Interpolations ( Berthelot et al. , arXiv 2018 , it \u2019 s concurrent , but could be good to discuss ) . '' -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We significantly expanded upon our discussion of related work such as Makhazani et al ( 2016 ) in section 3.3 . We also Adversarial Autoencoders and Adversarially Constrained Autoencoder Interpolations ( ACAI ) . ________________________________________ `` 5 ) Writing is not of very high quality . There are typos , grammatical issues , and questionable statements . The manuscript should be significantly improved. `` -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have performed a significant rewrite of our paper to improve the clarity and organization of the writing ."}, "2": {"review_id": "HJl2Ns0qKX-2", "review_text": "This paper proposes an autoencoder architecture and training procedure for producing high-quality reconstructions and realistic interpolations. A \"generator\" autoencoder is trained to fool a \"discriminator\" autoencoder. The generator tries to minimize its own reconstruction error and minimize the reconstruction error of the discriminator when fed with interpolated latent vectors of real datapoints. The discriminator autoencoder has three losses, corresponding to minimizing reconstruction error on real datapoints and maximizing reconstruction error on the generator's output on both real datapoints and interpolated outputs. The authors also propose a loss which encourages the distances between real datapoints and their corresponding latent vectors to be similar, as well as a heuristic procedure for stabilizing GAN training. Qualitative results are shown on CelebA. While the results look nice, the paper is not fit for publication in its current form. At a high level, the issues include a lack of convincing experimental verification of the method, a generally contradictory and confusing description of the methods, and frequent factual errors or mischaracterizations. Here I will try to describe many of the issues I found while reading the paper: - Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure. The experimental results are completely qualitative. No effort is made to provide a quantitative proof of claims such as \"the reconstructions are less blurry\" or \"the interpolations are higher quality\"; only a few examples are shown. The experiments are not even described in the text, and many of the figures are unreferenced. No ablation studies are done to determine the importance of different loss terms, such as L_dist. No mention is given to how hyperparameters like alpha should be chosen (and in fact, the value given for it \"1^{-4}/2\" is nonsense; 1^{-4} is just 1). No results for a baseline autoencoder (i.e., just optimizing reconstruction loss) are given. - At a higher level, no effort is given to argue why interpolation is a useful characteristic to try to encourage. There are no downstream applications proposed or tested. Earlier models, such as VAEGAN, also give reasonable reconstructions and good interpolations. Why is GAIA better? On what problem would I use GAIA and achieve better results apart from making nice-looking interpolations of people's faces? - Definitions are often unclear or contradictory. For example, the generator autoencoder is alternatingly treating as taking input X and taking input Z. I believe what is meant is that the generator consists of two networks which compute Z = encoder(X) and X = decoder(Z). Instead, the paper just switches between G(Z) and G(X) wherever convenient. Similarly, the equation for \\delta_Disc is different in Algorithm 1 and in the equation in 2.2. Interpolation, arguably one of the core parts of the model, is described as \"interpolations are Euclidean interpolations between pairs of points in Z, sampled from a Gaussian distribution around the midpoint between Zg1en and Zg2en.\" I assume the mean of this Gaussian is the midpoint; what is its covariance? Etc. - All autoencoders are not generative models, and in particular GAIA is not a generative model. There is no generative process. It does not estimate a data distribution. A VAE is a generative model which an autoencoder-like structure, but this does not make all autoencoders generative models. - GAIA is described as encouraging \"convex latent distributions\" and a convex set is defined in the text as \"A convex set of points is defined as a set in which the line connecting any pair of points will fall within the rest of the set.\" A convex set is not defined in terms of lines; it's defined in terms of convex combinations of points within the set. In the paper, only lines between points are considered. Claiming that the latent space is \"convex\" in the sense of purple blobs in B is not done - you would need to take a convex combination of multiple latent vectors and decode the results. This is an incomplete list of the issues with this paper. The paper would need significant changes before publication.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , We thank you for your comprehensive list of issues raised with the initial submission of our article . We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission . In response to each reviewer , we have divided each review into a point-by-point list of each issue raised followed by our response , pointing to where that issue was addressed in the text . We have made several major revisions , listed below , as well as a number of other revisions which are addressed point-by-point in response to reviewers . Major revisions : As requested by all three reviewers , we added a set of quantitative and ablation experiments on a low dimensional dataset . These experiments can be seen in Figures 2 and 6 , as well as Table 1 . We added an experiments section to the text and rearranged the text for structure . We rewrote sections of the introduction to better motivate our research . We added a number of relevant references and extended our discussion of related works . We edited the entire document for consistent notation both internally and to other related papers . We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input . ________________________________________ `` - Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure . The experimental results are completely qualitative . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We added a low dimensional dataset example ( Figure 2 , Table 1 , Figure 6 ) , and a quantitative assessment of the likelihood of interpolations and reconstructions , the correlation between latent structure and structure in high dimensional space , and the KL divergence between data and interpolations , as well as data and reconstructions . We compared a VAE , and AE , and GAIA ( both with and without the pairwise-distance loss term ) . ________________________________________ `` No effort is made to provide a quantitative proof of claims such as `` the reconstructions are less blurry '' or `` the interpolations are higher quality '' ; only a few examples are shown . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We edited these section and sentences to not make comparative claims . We now show examples in the appendix of reconstructions on several low dimensional datasets . We can add additional interpolation and attribute vector figures in the appendix as well if the reviewer finds it important . ________________________________________ `` The experiments are not even described in the text , and many of the figures are unreferenced . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We added an experiments section to the text which now includes subsections for both datasets , describing each measure . ________________________________________ `` No ablation studies are done to determine the importance of different loss terms , such as L_dist . No mention is given to how hyperparameters like alpha should be chosen -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - We now perform an ablation study by comparing our autoencoder with adversarial regularization , to an autoencoder of the same architecture without regularization . We also ablate L_dist ."}}