{"year": "2021", "forum": "T3kmOP_cMFB", "title": "Boosting One-Point Derivative-Free Online Optimization via Residual Feedback", "decision": "Reject", "meta_review": "The paper generated a lot of discussion. After reviewing all of the opinions, and my own reading of the paper, we have concluded that the theoretical innovation is too incremental for ICLR. It is possible that the idea of \"residual feedback\" could be helpful, but for this to be demonstrated effectively one would need to consider concrete models where the assumptions are verified.", "reviews": [{"review_id": "T3kmOP_cMFB-0", "review_text": "This manuscript considers online zeroth order optimization and it develops a gradient estimator based on one query per function . In particular , the proposed method mimics two-point estimators by evaluating two consecutive functions at perturbations of an iterate , as shown in equation ( 3 ) . Although one-point gradient estimates are possible , they have impractically large variances . Given this limitation and the wide need of zeroth order optimization ( in particular in RL ) , the study of two-point estimators is important . While this manuscript has many strengths , there are several issues that need to be clarified before it can be accepted for publication . Pros : - This work offers a simple solution . - Also , the authors offer guarantees for this solution under several sets of assumptions on the functions . Cons : - The theoretical results can be cleaned to offer better guarantees and make them more interpretable . I think the regret bounds offered in Theorem 3.2 , 3.3 , 4.2 , and 4.3 are difficult to parse , but they can be improved . For example , there should n't be a dependence on the inverse of the Lipschitz parameters L_0 and L_1 ( it does n't make sense to get a worse bound when the functions are smoother ) . The dependence on the inverse arises because the chosen step sizes go to infinity as the Lipschitz constants go to zero . With a better choice of step sizes the regret bounds would be better . - Assumptions 3.1 and 4.1 are stated in terms of expectations , but it is not clear what the expectations are over . From the proofs it seems that the expectations are over the perturbation directions u , but these are not introduced in the assumptions . Also , is Assumption 4.1.1 really intended as is ? I 'm asking because it reduces to E f_T < = W_T + E f_0 . - Finally , it seems like in the LQR example the different functions f_t correspond to different transition parameters ( A_t , B_t ) . How are the parameters A_t , B_t chosen ? I think a clear discussion of the choice is important to both understand the difficulty of the problem and to understand whether Assumptions 3.1 and 4.1 hold . -- Update after rebuttal : I appreciate the detailed answers to my questions and the authors ' revisions . I also read the other reviewers ' comments . While the new assumptions address my initial concerns , the new versions depend on the algorithm being implemented . As far as I can tell the assumptions might be satisfied for one choice of step-size while not being satisfied for another . Also , I agree with the other reviewers that generally in OCO one considers a worst case sequence of functions . A discussion of this issue in the main body of the paper seems appropriate . After addressing these issues , I think this work would warrant acceptance to ICLR . For now , however , I am not changing my score .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for providing valuable feedback that helps us improve the quality of this paper . Below is a point-to-point response to the reviewer \u2019 s concerns . Q1 : Dependence on the inverse of the Lipschitz parameters in main results . With a better choice of step sizes the regret bounds would be better . A : Thanks for pointing out this . In general , one can choose a different step size $ \\eta $ and parameter $ \\delta $ to change the dependence of the complexity on the Lipschitz parameters $ L_0 , L_1 $ . However , the best complexity bound will depend on the values of $ L_0 , L_1 $ , as we explain below . First , we want to clarify that the step size choices we make already result in the best dependence of the complexity on the parameters $ L_0 $ and $ L_1 $ . To elaborate , take Theorem 3.2 as an example . Note that the right hand side of eq . ( 24 ) involves the terms $ O ( \\eta^ { -1 } ) $ and $ O ( \\eta L_0^2 ) $ , which motivate our optimized step size choice $ \\eta=O ( L_0^ { -1 } ) $ . Then , we can remove the dependence of the complexity bound on $ L_0^ { -1 } $ by properly choosing $ \\delta $ . Again , take Theorem 3.2 as an example . For the last two terms in eq . ( 24 ) , we can choose $ \\delta = O ( { L_0 } ^ { -1 } ) $ and obtain the final complexity bound $ O ( ( L_0 + L_0V_f^2 ) T^ { 3/4 } ) $ . This bound matches the desired intuition pointed out by the reviewer . However , if the problem has $ L_0 > 1 $ , this new bound will be worse than our current bound in Theorem 3.2 . In Remark 3.3 after Theorem 3.2 , we optimize the dependence of the bound on the Lipschitz parameter by choosing $ \\delta=O ( 1/L_0^q ) $ with $ q $ being fine-tuned accordingly to the value of the Lipschitz parameter . The approach in this discussion can also be applied to optimize the dependence of the complexity bounds in the other Theorems . Q2 : Clarification on Assumption 3.1 and 4.1 . A : We apologize for the confusion . We agree that it is better and more clear to just assume the conditions that are used in the proof . To clarify , we have updated the conditions of these assumptions in the revision . To elaborate on the randomness , in the revised Assumption 3.1 , the expectation is taken with respect to $ x_ { t-1 } $ , the random vector $ u_ { t-1 } $ and the randomness of the objective functions $ f_t , f_ { t-1 } $ . In the revised Assumption 4.1.1 , the expectation in the summation is taken with respect to $ x_t $ and the randomness of the smoothed objective functions $ f_ { \\delta , t } , f_ { \\delta , t-1 } $ . In the revised Assumption 4.1.2 , the expectation in the summation is taken with respect to $ x_ { t-1 } $ , the random vector $ u_ { t-1 } $ and the randomness of the objective functions $ f_ { t } , f_ { t-1 } $ . The Assumptions 5.1 and 5.3 are updated in a similar way , please refer to the revision for the details . Q3 : Clarification on numerical examples . A : The construction of the matrices $ A_t , B_t $ is specified in section A of the supplementary material . Specifically , $ A_t $ is generated according to $ A_t = A_ { t-1 } + 0.01 * M_t $ , where $ M_t $ is a random matrix with entries being uniformly sampled from $ [ 0,1 ] $ . Matrix $ B_t $ is generated in a similar way . We have clarified these details in Section 6.1 ."}, {"review_id": "T3kmOP_cMFB-1", "review_text": "This paper proposes a zeroth-order ( derivative-free ) algorithm for online stochastic optimization problems . The objective is to find a sequence of actions $ x_0 , \\dots , x_ { T-1 } $ minimizing the expected regret $ $ \\mathbb { E } [ \\sum_ { t=0 } ^ { T-1 } f_t ( x_t ) - \\min_ { x\\in\\mathcal { X } } \\sum_ { t=0 } ^ { T-1 } f_t ( x ) ] , $ $ where the ( sub- ) gradients of unknown cost functions $ f_t $ are not available , and only measurements $ f_t ( x_t ) $ of the values of the functions at tests points $ x_t $ can be obtained . The submission builds on the zeroth-order techniques developed by Nesterov & Spokoiny in [ 1 ] for derivative-free , non-smooth , convex and non-convex optimization , where similar gradient estimation techniques based on sampling and Gaussian smoothing are used , with the difference that two values of an identical noisy instance of the cost function are needed in [ 1 ] at each iteration . By requiring only one noisy function value per iteration and recalling the function value collected during the previous iteration ( in the submission this technique is called `` residual feedback '' ) , the proposed algorithm extends convergence results of the two-point approach [ 1 ] to regret bounds in stochastic/bandit settings where the function is changing after every new value observed , on condition that the differences between two consecutive instances of the cost function are bounded in variance . The regret bounds derived in the paper match those obtained for recent 'one-point ' zeroth-order methods for online optimization ( e.g . [ 2 ] ) .A specificity of the algorithm proposed in the paper , compared to other 'one-point ' methods , is that the algorithm does not depend on the absolute function levels , only on differences between two function instances , which may improve the performance in practice , as shown in the numerical experiments . This property was also shared by the approach of Bach and Perchet [ 4 ] , which serves as a benchmark algorithm in the numerical experiments of the submission . These experiments are carried out on a nonstationary LQR control algorithm , and on a nonstationary resource allocation problem . The paper is technically sound and the developments are clear . The regret bounds derived for online non-convex optimization are interesting . The contributions to the online convex optimization framework are less obvious , due to the abundant literature on the topic . See my concerns below and my questions to the authors . I look forward to the authors ' answers . My recommendation will be amended after their rebuttal . Pros : The paper is technically sound and well written . The regret bounds derived in the non-convex online optimization framework are of particular interest . Since the proposed algorithm does not depend on the function levels , it may perform better than the basic 'one-point ' methods in practice . Concerns and questions : The presentation of the results leaves a mixed impression . I agree that regret bounds in non-convex online learning are a contribution to the field . The claims of novelty made by the authors for the convex case , on the other hand , look somewhat overstated . They write , for instance : `` it is also the first time that a one-point gradient estimator demonstrates comparable performance to that of the two-point method '' . This sounds optimistic to me , in the sense that the authors ' argument is mostly empirical ( numerical experiments for a particular problem ) , whereas the regret bounds derived in the paper do not compare with the regret bounds that two-point methods would achieve . Moreover , there exist more recent approaches to convex zeroth-order online learning which claim the conjectured $ \\Omega ( \\sqrt { T } ) $ regret bound [ 3,5 ] . These new trends in zeroth-order online learning are not discussed in the submission . I do n't see a clear distinction between the settings 'online bandit optimization ' ( Sections 3 and 4 ) and 'online stochastic optimization ' ( Section 5 ) , because the regret criterion ( 6 ) , the assumptions of the cost function sequences ( 3.1 , 4.1 / 5.1 , 5.2 ) , the algorithms , and the regret bounds are apparently the same for the two settings . The only specificity of the Section 5 model seems to be the existence of a mean cost function $ \\mathbb { E } [ f_t ] $ , if we set $ f_t ( \\cdot ) \\equiv F ( \\cdot ; \\xi_t ) $ \u2014 assumption which is not exploited . Also , I found Section 5 slightly redundant . I thought it could easily be replaced by a discussion on all the frameworks covered by Assumptions 3.1 and 4.1 and on the possible interpretations given to the model . In the submission , an algorithm developed by Bach and Perchet in [ 4 ] , was classified by the authors as a two-point zeroth-order optimization algorithm and used in the numerical experiments as a benchmark for comparison . In my recollection of [ 4 ] , the algorithm relies on a gradient estimator which considers the difference between two noisy functions values affected by two independent noises , with the assumption that the noises are uniformly bounded in variance or satisfy a martingale property . To me , these assumptions are similar ( if not identical ) to those made in Section 5 and in Sections 3,4,6 , respectively . Could the authors clarify the differences between the noise model of [ 4 ] and the one they use , and why the algorithm [ 4 ] is impractical and can not be used in online settings ? Why was it treated differently in the numerical experiments ? Another feature that was not discussed in the paper is the feasibility of the algorithm in terms of the availability of the function queries . The problem stated in Equation ( P ) is a constrained online optimization problem over a convex set . However , since the test points are sampled over the entire state space from Gaussian distributions , the proposed algorithm will query function values outside the feasible set , and these function values are not available in many learning applications . Note that it is possible to combine Gaussian sampling with constrained online optimization [ 5 ] , and that feasible zeroth-order optimization algorithms based on residual feedback have been developed [ 6 ] . Typos : p.2 such an one-point derivative-free setting = > such a p.7 nonstatinoary = > nonstationary [ 1 ] Yurii Nesterov and Vladimir Spokoiny . Random gradient-free minimization of convex functions . Foundations of Computational Mathematics , 17 ( 2 ) :527\u2013566 , 2017 . [ 2 ] Alexander V Gasnikov , Ekaterina A Krymova , Anastasia A Lagunovskaya , Ilnura N Usmanova , and Fedor A Fedorenko . Stochastic online optimization . single-point and multipoint non-linear multi-armed bandits . convex and strongly-convex case . Automation and remote control , 78 ( 2 ) :224\u2013234 , 2017 . [ 3 ] https : //arxiv.org/abs/1603.04350 [ 4 ] Francis Bach and Vianney Perchet . Highly-smooth zero-th order online optimization . In Conference on Learning Theory , pp . 257\u2013283 , 2016 . [ 5 ] https : //arxiv.org/abs/1607.03084 [ 6 ] https : //arxiv.org/abs/2006.05445 __________ Update after the discussions : I would like to thank the author ( s ) for all their comments . Although most of my concerns have been addressed , some questions remain topics of contention . Before discussing these topics , I will first append to this review my answer to the author ( s ) ' last comments , as it was their wish to keep hearing from me after closing of the discussions : $ \\ \\ \\ $ The assumptions ( 3.1 , 4.1 , 5.1 , 5.3 ) made on the function sequence $ f_t $ for convergence of the proposed algorithm are unconventional as they require that the expected absolute variations of two function values at the points visited by the algorithm be bounded , or that the squared variations of two function values obtained by Gaussian sampling from points visited by the algorithm be bounded . So formulated , the conditions for convergence involve the algorithm 's trajectory $ x_t $ as much as the function sequence $ f_t $ , and they are difficult to verify . In an attempt to identify sufficient conditions for these assumptions to hold true , I made three suggestions : ( i ) and ( ii ) were concerned with the boundedness of the sequence of points generated by the algorithm , and ( iii ) was the case of bounded incremental variations of the sequence $ f_t $ , e.g.martingales . In their reply , the author ( s ) were right to rule out ( i ) and ( ii ) , which indeed were unrelated . This leaves us with ( iii ) as a possible setting for the proposed algorithm . $ \\ \\ \\ $ In my last comment I argued that the case ( iii ) , where the sequence $ f_t $ undergoes incremental variations uniformly bounded in expectation , was covered by the approach taken in Bach & Perchet ( 2016 ) , where two function queries obtained from perturbations around the same iterate are processed at each step . The Bach/Perchet approach is cited in the paper for comparison , but it is called impractical as it would not apply when $ f_t $ varies over time $ - $ argument I disagree with and that I attempted to refute in a brief discussion involving martingale-like variations for $ f_t $ . When the author ( s ) of the submission object to my regret analysis in the case of martingale-like noise on the basis that the assumptions they make also cover non-zero-mean variations with similar uniform upper bounds on the moments , they do not address the main point of my comment . My intention was to show that it does not take much effort to consider the approach used in Bach & Perchet ( 2016 ) in settings where the cost function is changing over time , for as long as the cost variations are incremental with bounded moments . This can be seen by noting that the convergence result derived in the revised version of the supplementary material for the residual-feedback algorithm with unit-sphere sampling can be reproduced for the Bach/Perchet approach under the considered assumptions . I take it that the author ( s ) , who excel at deriving the convergence rates for such algorithms , will not disagree . Although the assumptions used in Bach & Perchet ( 2016 ) ( uniform zero-mean increments ) may look somewhat stricter , they have the merit of being clear and simple , as opposed to Assumptions 3.1 , 4.1 , 5.1 , 5.3 , which involve the trajectory of the algorithm and ca n't be verified easily . They are also sufficient to improve the convergence rates for higher degrees of smoothness compared to the early algorithm by Flaxman et al . ( 2005 ) , which was the objective of that paper . Higher degrees of smoothness failing which it is difficult to improve the convergence rates , as confirmed by the convergence rates given in the submission . In my sense , one important message conveyed by the submission is that the approaches proposed in the submission and in Bach & Perchet ( 2016 ) can both handle bounded additive noise , and both fail in the more general framework of adversarial learning . By calling the Bach/Perchet algorithm impractical for their setting , I believe the author ( s ) of the submission missed to chance to compare the two approaches from a fair perspective and to answer the simple question that comes to mind when reading their paper : is the residual feedback technique really useful in the stochastic learning framework , or is n't convergence just as fast when the function queries are processed by pairs as in Bach & Perchet ( 2016 ) , or in the reference paper by Nesterov & Spokoiny ( 2017 ) ? - That being said , the following issues remain in this submission : $ \\bullet $ The assumptions ( 3.1 , 4.1 , 5.1 , 5.3 ) made on the function sequence $ f_t $ for convergence of the proposed algorithm are unconventional and difficult to verify , because they consist in properties of the iterates of the algorithm . $ \\bullet $ In our discussions , only incremental sequences $ f_t $ with variations uniformly bounded in expectation have been identified to meet those assumptions . In my sense , this particular setting is also covered by the approach taken in Bach & Perchet ( 2016 ) , where the function queries are handled by pairs obtained from perturbations around the same iterate . Also , I still find it unfair to call the latter approach impractical for the considered setting . $ \\bullet $ Since the convergence rates derived in the paper show no clear improvement , compared to the early approach of Flaxman et al . ( 2005 ) , the arguments of the submission lie in the experimental results , where I do n't think the algorithm by Bach & Perchet ( 2016 ) is given a fair treatment ( for the reason explained in the previous paragraph ) . Besides , the application considered in Section 6.1 reduces to the unconstrained minimization of a polynomial of high degree that is neither Lipschitz nor smooth , which is a basic requirement for the convergence algorithms . This makes the convergence of the algorithms highly dependent on the initial point , unless optimization is done over a compact set , but I do n't think the projection step was implemented for the algorithms . $ \\bullet $ In constrained optimization , the problem that the proposed algorithm samples function values outside the feasible set has been partly addressed by the author ( s ) , who provided a variant of the algorithm based no longer on Gaussian sampling , but on sampling over a sphere . Partly because only one convergence result for a particular setting was derived , and it remains unclear ( as pointed out by Reviewer 4 ) if all the benefits of Gaussian smoothing and all convergence results would also extend to spheric smoothing . This discussion is missing . In my opinion , the extension to settings where the functions ca n't be sampled outside the feasible set is not absolutely imperative in all frameworks ( the author ( s ) have provided counter-examples ) , but it would be useful to know the limits of the proposed technique . All things considered , I would not recommend the submission for presentation at the conference . Independently of the final decision , I hope the author ( s ) will make the most from the discussions with all the reviewers . I would like to make a last comment about the submission and the discussions that followed . It is natural that the author ( s ) give the best picture of the algorithm they propose . Yet in the paper the contrast is particularly strong between , on the one hand , the haziness surrounding the assumptions made on the function sequence $ f_t $ , or the negligence with which the algorithms were applied in Section 6.1 to a problem not actually meeting the conditions for convergence , and on the other hand the severity with which the Bach/Perchet approach was disqualified as a possible method of solution . This contrast gives the reader an overall feeling of partiality , which makes the reviewing task an intricate , contradictory , and unappreciative one .", "rating": "4: Ok but not good enough - rejection", "reply_text": "Q6 : Discussion on the ability to query function values outside the constraint set . A : We thank the reviewer for raising this question . In this paper , we follow the existing literature and assume that $ f_t $ can be evaluated outside the constraint set . This assumption is widely adopted , e.g. , in the following literature [ A-E ] . In particular , we note that the constraint set only restricts the final optimization solution , and it does not restrict the feasibility of the function evaluations . On the other hand , we also want to mention that with minor modifications we can guarantee the feasibility of the perturbed points . We elaborate on these modifications in the Section H in the supplementary material . In short , we can use unit sphere sampling instead of Gaussian sampling , and perform the projection onto a shrinked constraint set $ ( 1-\\xi ) \\mathcal { X } $ for some small $ \\xi > 0 $ ( see eq . ( 48 ) ) , where the shrinkage coefficient $ ( 1-\\xi ) $ is to make sure that the perturbed point is within the original set $ \\mathcal { X } $ . [ A ] Duchi , et al , A . ( 2015 ) .Optimal rates for zero-order convex optimization : The power of two function evaluations . [ B ] Bach , F. , & Perchet , V. ( 2016 ) . Highly-smooth zero-th order online optimization . [ C ] Liu , et al , ( 2018 ) . Zeroth-order stochastic projected gradient descent for nonconvex optimization . [ D ] Balasubramanian , K. , & Ghadimi , S. ( 2018 ) . Zeroth-order nonconvex stochastic optimization : Handling constraints , high-dimensionality and saddle-points . [ E ] Sahu , A. K. , & Kar , S. ( 2020 ) . Decentralized Zeroth-Order Constrained Stochastic Optimization Algorithms : Frank-Wolfe and Variants With Applications to Black-Box Adversarial Attacks . We also thank the reviewer for pointing out the solutions in [ 5,6 ] . The discussion of [ 5 ] is included in our response to Q3 . In [ 6 ] , the authors studied a similar oracle for a static convex optimization problem with objective and constraint functions of specific forms . The above discussion and the related works mentioned by the reviewer have been included in the revision under update ( 4 ) ."}, {"review_id": "T3kmOP_cMFB-2", "review_text": "1.Paper contribution summary This paper proposes a new one-point zeroth-order gradient estimation method for online optimization . Comparing to previous methods in the same scenario , this paper 's method is shown to have smaller variance , which can improve the learning rate in certain cases including classes of convex Lipschitz functions , convex smooth functions , non-convex Lipschitz functions , as well as non-convex smooth functions . 2.Strong and weak points of the paper 1 ) Strong points : The paper 's focus is on one-point zeroth-order gradient estimate , which is a more realistic setting in non-stationary online optimization problems as compared to most popular two-point estimator due to the queried function is time-varying . The new estimate method is based on residual feedback from previous time 's perturbed objective value , which can help improve the regret order when function variation is small . It also extends the finding to online non-convex optimization problems with different regret definitions . And the proposed new one-point zeroth-order gradient estimation method is shown to have smaller variance and improved performance in the two numerical examples . 2 ) Weak points : The proposed zeroth-order update rule for constrained convex case in Eq . ( 4 ) is problematic . For the constrained case , it uses a projection to make sure x_ { t+1 } is feasible . However , when doing gradient estimation , it actually uses the perturbed x_ { t+1 } + \\delta u_ { t+1 } , which may violate the constraint , making this update rule not feasible sometimes . The claimed improvement for convex cases is only in the constant order instead of the order of T even under this problematic update rule . The regret metrics used in the two online non-convex cases : non-convex Lipschitz , non-convex smooth are different from each other , which is very weird . 3.My recommendation I would suggest a rejection due to the problematic update rule in Eq . ( 4 ) and the constant order improvement . 4.Supporting arguments for my recommendation . First , the problematic update rule as discussed above . Second , the only constant order improvement of regret in convex cases . Third , the weird different regret metrics used in non-convex cases . 5.Questions 1 ) Can the author/s confirm if the update in Eq . ( 4 ) is problematic ? 2 ) Why using two different regret metric in non-convex problems ? 3 ) For the example used in the paragraph under Eq . ( 8 ) to show that the assumption 3.1 is weaker than previous works ' uniform boundedness , i feel that the uniform boundedness assumption in prior works can be improved to have only bounded first or second order expectation . Then the example 's statement wo n't hold anymore . Can the author/s make any comments on this ?", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for providing valuable feedback that helps us improve the quality of this paper . Below is a point-to-point response to the reviewer \u2019 s concerns . Q1 : Concerns on the correctness of the update in ( 4 ) . A : We thank the reviewer for raising this question . We want to first emphasize that the feasibility of update ( 4 ) pointed out by the reviewer is not a concern for our method and the same update has been widely adopted in the existing literature , e.g. , see the papers [ A-E ] given below . This literature allows the function to be evaluated outside the constraint set . For example , in the update ( 3 ) and gradient estimate ( 6 ) in [ A ] and in the update ( 6 ) in [ B ] , the authors first obtain the next iterate by projecting onto the constraint set and then perturb this new iterate and evaluate its function value to estimate the zeroth-order gradient . Our update ( 4 ) adopts the same idea . On the other hand , we also want to mention that with minor modifications we can guarantee the feasibility of the perturbed points . We elaborate on these modifications in Section H in the supplementary material . In short , we can use unit sphere sampling instead of Gaussian sampling , and perform the projection onto a shrinked constraint set $ ( 1-\\xi ) \\mathcal { X } $ for some small $ \\xi > 0 $ ( see eq . ( 48 ) ) , where the shrinkage coefficient $ ( 1-\\xi ) $ is to make sure that the perturbed point is within the original set $ \\mathcal { X } $ . To summarize , the update ( 4 ) is not problematic . To satisfy the additional requirement that the objective function can only be queried at feasible points , we \u2019 ve modified the algorithm so that the iterates can be guaranteed to lie within the feasible set and the related analysis is also provided . This discussion is added to the revised manuscript under ( 4 ) . [ A ] Duchi et.al . ( 2015 ) .Optimal rates for zero-order convex optimization : The power of two function evaluations . [ B ] Bach , F. , & Perchet , V. ( 2016 , June ) . Highly-smooth zero-th order online optimization . [ C ] Liu et.al . ( 2018 , November ) . Zeroth-order stochastic projected gradient descent for nonconvex optimization . [ D ] Balasubramanian , K. , & Ghadimi , S. ( 2018 ) . Zeroth-order nonconvex stochastic optimization : Handling constraints , high-dimensionality and saddle-points . [ E ] Sahu , A. K. , & Kar , S. ( 2020 ) . Decentralized Zeroth-Order Constrained Stochastic Optimization Algorithms : Frank-Wolfe and Variants With Applications to Black-Box Adversarial Attacks . Q2 : Explain the reason for using two different regret metrics in non-convex problems . A : Thanks for raising this question . We want to point out that these are standard metrics used for non-smooth & non-convex zeroth-order optimization , see Section 7 in the seminal work [ Nesterov & Spokoiny , 2017 ] . To elaborate , in non-smooth non-convex optimization , the gradient of the objective function $ \\nabla f_t $ does not exist and hence the regret $ R^T_g $ is not well-defined . In this case , we define a smoothed regret $ R^T_ { g , \\delta } $ based on the smoothed objective function $ f_ { \\delta , t } $ . At the same time , we should not smooth the function too much , as otherwise $ f_ { \\delta , t } $ can be very different from $ f_t $ . Thus , we control the smoothing parameter $ \\delta $ to enforce that $ |f_ { \\delta , t } - f_t| \\le \\epsilon_f $ . This discussion is presented above Theorem 4.2 . Q3 : I feel that the uniform boundedness assumption in prior works can be improved to have only bounded first or second order expectation . A : We agree that the one-point method can be analyzed using these relaxed conditions . For example , in the following paper [ F ] , the analysis of the one-point method is based on bounded second moment of the objective function , i.e. , $ E [ |f_t ( x ; \\xi_t ) |^2 ] \\le B $ . However , we note that our assumption only requires the second moment of the function variation to be bounded , which is less strict than the assumption that the objective function has bounded second moment . As an example , consider the time-varying functions defined by $ f_0 = 1/2x^2 $ and $ f_t = f_ { t-1 } + n_t $ , where $ n_t\\sim \\mathcal { N } ( 0,1 ) $ . Then , the second moment of $ f_t $ increases linearly over time and is not bounded , but the variation $ f_t - f_ { t-1 } $ has bounded second moment . We have included this example in the revised manuscript . [ F ] Gasnikov et.al . ( 2017 ) .Stochastic online optimization . Single-point and multi-point non-linear multi-armed bandits . Convex and strongly-convex case . Q4 : Constant order improvement . A : The constant-order improvement is expected , as our method is a one-point method and must not exceed the information theoretic limit of one-point methods . However , we think our one-point residual feedback has its own merit . It provides a more effective zero-order algorithm for solving online problems where two-point methods are not applicable , and resolves the large variance issue of the conventional one-point feedback ."}, {"review_id": "T3kmOP_cMFB-3", "review_text": "Summary : The paper considers online optimization with zero-order oracle . Motivated by nonstationarity of the objective function , impracticality is underlined for the two-point feedback approach . Instead , staying in the one-point setting , the proposed approach reuses the objective value from the previous round of observations , which is called as residual feedback . The variance of the corresponding proxy for the subgradient is estimated under more relaxed assumptions than existing in the literature . The proposed approach leads to smaller variance and better regret bounds . Regret bounds are proved for smooth/non-smooth convex/non-convex cases , the non-convex case being analyzed for the first time in the literature . Numerical experiments show that the practical performance of the proposed gradient estimator is better than that of the existing one-point feedback methods and is close to the performance of the one-point approach with two observations per round . The latter approach can be impractical for some applications . Evaluation : I believe that the paper contains new interesting results on zero-order methods with one-point feedback , which are supported both theoretically and numerically . So , I suggest accepting the paper . Pros : 1.New theoretical results which are significant for optimization and learning literature , as well as for applications . 2.Numerical results support theoretical findings . 3.The paper is overall clearly written and motivated . Cons : 1.There are several minor comments mainly on the clarity of presentation . See below . Minor comments 1 . Some related work seems to be missing http : //proceedings.mlr.press/v48/hazanb16.pdf ( non-convex optimization with one-point feedback ) https : //link.springer.com/article/10.1007 % 2Fs10107-014-0846-1 ( non-convex stochastic optimization ) http : //papers.nips.cc/paper/5377-bandit-convex-optimization-towards-tight-bounds.pdf http : //papers.nips.cc/paper/4475-stochastic-convex-optimization-with-bandit-feedback.pdf 2 . Please consider writing explicitly on p.7 that Bach & Perchet ( 2016 ) use two function evaluations in each round . Also it would be nice to explain in more details , why their approach is impractical . For example , in the considered in Sect . 6.1 example , why one can not observe x_ { k+1 } two times ( with different values w_k ) , and the evaluate the loss twice ? 3.The proof of Lemma 2.5 does not completely correspond to the statement of the Lemma . In the proof more is derived than stated in the Lemma , but under additional assumptions . 4.In the first line of Appendix F , did you mean that $ f_ { \\delta , t } \\in C^ { 1,1 } $ ? Also here Assumption 3.1 is used , which should be mentioned .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank the reviewer for providing valuable feedback that helps us improve the quality of this paper . Below is a point-to-point response to the reviewer \u2019 s concerns . Q1 : Related works missing . A : We thank the reviewer for referring us to these works . These works study the two-point method , conventional one-point method or the ellipsoid method in static convex or non-convex optimization problems . We agree that they are also related and will be added to our discussion . Q2 : Clarification on why the two-point method is impractical . A : Thanks for this comment . We will add the comment on [ Bach & Perchet , 2016 ] according to the reviewer \u2019 s suggestion . If one wants to use the two-point gradient estimator ( 7 ) in [ Bach & Perchet , 2016 ] to solve the non-stationary RL problem in Section 6.1 , at episode $ t $ with dynamical matrices $ ( A_t , B_t ) $ , ( 7 ) requires to evaluate two different policy parameters $ K_t + \\delta U_t $ and $ K_t \u2013 \\delta U_t $ . However , in a practical non-stationary system , evaluation of each policy parameter requires one episode . For example , if we evaluate $ K_t + \\delta U_t $ at episode $ t $ , then the non-stationary environment evolves to episode $ t+1 $ with new dynamical matrices $ ( A_ { t+1 } , B_ { t+1 } ) $ . Therefore , $ K_t \u2013 \\delta U_t $ can not be evaluated in the environment with $ ( A_t , B_t ) $ anymore . This violates the assumption in ( 7 ) in [ Bach & Perchet , 2016 ] . Therefore , the two-point method ( 7 ) in [ Bach & Perchet , 2016 ] can not be implemented in a practical non-stationary system . Q3 : Proof of Lemma 2.5 . A : Thanks for this comment . Without Assumption 3.1 , we can directly replace all $ V_f^2 $ in inequalities after ( 15 ) with $ E [ ( f_t ( z ) \u2013 f_ { t-1 } ( z ) ) ^2 ] $ , where $ z = x_ { t-1 } + \\delta u_ { t-1 } $ , and get the results in Lemma 2.5 . This issue has been fixed in our revised supplementary material . Q4 : Clarification on the proof in Appendix F A : Thanks for this comment . In the first line of Appendix F , we meant that when $ f_t \\in C^ { 1,1 } $ with Lipschitz constant $ L_1 $ , we have that $ f_ { \\delta , t } \\in C^ { 1,1 } $ also with constant $ L_1 $ . And the reviewer is correct that to get inequality ( 41 ) , we also use Assumption 3.1 . We have clarified this in the revised draft ."}], "0": {"review_id": "T3kmOP_cMFB-0", "review_text": "This manuscript considers online zeroth order optimization and it develops a gradient estimator based on one query per function . In particular , the proposed method mimics two-point estimators by evaluating two consecutive functions at perturbations of an iterate , as shown in equation ( 3 ) . Although one-point gradient estimates are possible , they have impractically large variances . Given this limitation and the wide need of zeroth order optimization ( in particular in RL ) , the study of two-point estimators is important . While this manuscript has many strengths , there are several issues that need to be clarified before it can be accepted for publication . Pros : - This work offers a simple solution . - Also , the authors offer guarantees for this solution under several sets of assumptions on the functions . Cons : - The theoretical results can be cleaned to offer better guarantees and make them more interpretable . I think the regret bounds offered in Theorem 3.2 , 3.3 , 4.2 , and 4.3 are difficult to parse , but they can be improved . For example , there should n't be a dependence on the inverse of the Lipschitz parameters L_0 and L_1 ( it does n't make sense to get a worse bound when the functions are smoother ) . The dependence on the inverse arises because the chosen step sizes go to infinity as the Lipschitz constants go to zero . With a better choice of step sizes the regret bounds would be better . - Assumptions 3.1 and 4.1 are stated in terms of expectations , but it is not clear what the expectations are over . From the proofs it seems that the expectations are over the perturbation directions u , but these are not introduced in the assumptions . Also , is Assumption 4.1.1 really intended as is ? I 'm asking because it reduces to E f_T < = W_T + E f_0 . - Finally , it seems like in the LQR example the different functions f_t correspond to different transition parameters ( A_t , B_t ) . How are the parameters A_t , B_t chosen ? I think a clear discussion of the choice is important to both understand the difficulty of the problem and to understand whether Assumptions 3.1 and 4.1 hold . -- Update after rebuttal : I appreciate the detailed answers to my questions and the authors ' revisions . I also read the other reviewers ' comments . While the new assumptions address my initial concerns , the new versions depend on the algorithm being implemented . As far as I can tell the assumptions might be satisfied for one choice of step-size while not being satisfied for another . Also , I agree with the other reviewers that generally in OCO one considers a worst case sequence of functions . A discussion of this issue in the main body of the paper seems appropriate . After addressing these issues , I think this work would warrant acceptance to ICLR . For now , however , I am not changing my score .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for providing valuable feedback that helps us improve the quality of this paper . Below is a point-to-point response to the reviewer \u2019 s concerns . Q1 : Dependence on the inverse of the Lipschitz parameters in main results . With a better choice of step sizes the regret bounds would be better . A : Thanks for pointing out this . In general , one can choose a different step size $ \\eta $ and parameter $ \\delta $ to change the dependence of the complexity on the Lipschitz parameters $ L_0 , L_1 $ . However , the best complexity bound will depend on the values of $ L_0 , L_1 $ , as we explain below . First , we want to clarify that the step size choices we make already result in the best dependence of the complexity on the parameters $ L_0 $ and $ L_1 $ . To elaborate , take Theorem 3.2 as an example . Note that the right hand side of eq . ( 24 ) involves the terms $ O ( \\eta^ { -1 } ) $ and $ O ( \\eta L_0^2 ) $ , which motivate our optimized step size choice $ \\eta=O ( L_0^ { -1 } ) $ . Then , we can remove the dependence of the complexity bound on $ L_0^ { -1 } $ by properly choosing $ \\delta $ . Again , take Theorem 3.2 as an example . For the last two terms in eq . ( 24 ) , we can choose $ \\delta = O ( { L_0 } ^ { -1 } ) $ and obtain the final complexity bound $ O ( ( L_0 + L_0V_f^2 ) T^ { 3/4 } ) $ . This bound matches the desired intuition pointed out by the reviewer . However , if the problem has $ L_0 > 1 $ , this new bound will be worse than our current bound in Theorem 3.2 . In Remark 3.3 after Theorem 3.2 , we optimize the dependence of the bound on the Lipschitz parameter by choosing $ \\delta=O ( 1/L_0^q ) $ with $ q $ being fine-tuned accordingly to the value of the Lipschitz parameter . The approach in this discussion can also be applied to optimize the dependence of the complexity bounds in the other Theorems . Q2 : Clarification on Assumption 3.1 and 4.1 . A : We apologize for the confusion . We agree that it is better and more clear to just assume the conditions that are used in the proof . To clarify , we have updated the conditions of these assumptions in the revision . To elaborate on the randomness , in the revised Assumption 3.1 , the expectation is taken with respect to $ x_ { t-1 } $ , the random vector $ u_ { t-1 } $ and the randomness of the objective functions $ f_t , f_ { t-1 } $ . In the revised Assumption 4.1.1 , the expectation in the summation is taken with respect to $ x_t $ and the randomness of the smoothed objective functions $ f_ { \\delta , t } , f_ { \\delta , t-1 } $ . In the revised Assumption 4.1.2 , the expectation in the summation is taken with respect to $ x_ { t-1 } $ , the random vector $ u_ { t-1 } $ and the randomness of the objective functions $ f_ { t } , f_ { t-1 } $ . The Assumptions 5.1 and 5.3 are updated in a similar way , please refer to the revision for the details . Q3 : Clarification on numerical examples . A : The construction of the matrices $ A_t , B_t $ is specified in section A of the supplementary material . Specifically , $ A_t $ is generated according to $ A_t = A_ { t-1 } + 0.01 * M_t $ , where $ M_t $ is a random matrix with entries being uniformly sampled from $ [ 0,1 ] $ . Matrix $ B_t $ is generated in a similar way . We have clarified these details in Section 6.1 ."}, "1": {"review_id": "T3kmOP_cMFB-1", "review_text": "This paper proposes a zeroth-order ( derivative-free ) algorithm for online stochastic optimization problems . The objective is to find a sequence of actions $ x_0 , \\dots , x_ { T-1 } $ minimizing the expected regret $ $ \\mathbb { E } [ \\sum_ { t=0 } ^ { T-1 } f_t ( x_t ) - \\min_ { x\\in\\mathcal { X } } \\sum_ { t=0 } ^ { T-1 } f_t ( x ) ] , $ $ where the ( sub- ) gradients of unknown cost functions $ f_t $ are not available , and only measurements $ f_t ( x_t ) $ of the values of the functions at tests points $ x_t $ can be obtained . The submission builds on the zeroth-order techniques developed by Nesterov & Spokoiny in [ 1 ] for derivative-free , non-smooth , convex and non-convex optimization , where similar gradient estimation techniques based on sampling and Gaussian smoothing are used , with the difference that two values of an identical noisy instance of the cost function are needed in [ 1 ] at each iteration . By requiring only one noisy function value per iteration and recalling the function value collected during the previous iteration ( in the submission this technique is called `` residual feedback '' ) , the proposed algorithm extends convergence results of the two-point approach [ 1 ] to regret bounds in stochastic/bandit settings where the function is changing after every new value observed , on condition that the differences between two consecutive instances of the cost function are bounded in variance . The regret bounds derived in the paper match those obtained for recent 'one-point ' zeroth-order methods for online optimization ( e.g . [ 2 ] ) .A specificity of the algorithm proposed in the paper , compared to other 'one-point ' methods , is that the algorithm does not depend on the absolute function levels , only on differences between two function instances , which may improve the performance in practice , as shown in the numerical experiments . This property was also shared by the approach of Bach and Perchet [ 4 ] , which serves as a benchmark algorithm in the numerical experiments of the submission . These experiments are carried out on a nonstationary LQR control algorithm , and on a nonstationary resource allocation problem . The paper is technically sound and the developments are clear . The regret bounds derived for online non-convex optimization are interesting . The contributions to the online convex optimization framework are less obvious , due to the abundant literature on the topic . See my concerns below and my questions to the authors . I look forward to the authors ' answers . My recommendation will be amended after their rebuttal . Pros : The paper is technically sound and well written . The regret bounds derived in the non-convex online optimization framework are of particular interest . Since the proposed algorithm does not depend on the function levels , it may perform better than the basic 'one-point ' methods in practice . Concerns and questions : The presentation of the results leaves a mixed impression . I agree that regret bounds in non-convex online learning are a contribution to the field . The claims of novelty made by the authors for the convex case , on the other hand , look somewhat overstated . They write , for instance : `` it is also the first time that a one-point gradient estimator demonstrates comparable performance to that of the two-point method '' . This sounds optimistic to me , in the sense that the authors ' argument is mostly empirical ( numerical experiments for a particular problem ) , whereas the regret bounds derived in the paper do not compare with the regret bounds that two-point methods would achieve . Moreover , there exist more recent approaches to convex zeroth-order online learning which claim the conjectured $ \\Omega ( \\sqrt { T } ) $ regret bound [ 3,5 ] . These new trends in zeroth-order online learning are not discussed in the submission . I do n't see a clear distinction between the settings 'online bandit optimization ' ( Sections 3 and 4 ) and 'online stochastic optimization ' ( Section 5 ) , because the regret criterion ( 6 ) , the assumptions of the cost function sequences ( 3.1 , 4.1 / 5.1 , 5.2 ) , the algorithms , and the regret bounds are apparently the same for the two settings . The only specificity of the Section 5 model seems to be the existence of a mean cost function $ \\mathbb { E } [ f_t ] $ , if we set $ f_t ( \\cdot ) \\equiv F ( \\cdot ; \\xi_t ) $ \u2014 assumption which is not exploited . Also , I found Section 5 slightly redundant . I thought it could easily be replaced by a discussion on all the frameworks covered by Assumptions 3.1 and 4.1 and on the possible interpretations given to the model . In the submission , an algorithm developed by Bach and Perchet in [ 4 ] , was classified by the authors as a two-point zeroth-order optimization algorithm and used in the numerical experiments as a benchmark for comparison . In my recollection of [ 4 ] , the algorithm relies on a gradient estimator which considers the difference between two noisy functions values affected by two independent noises , with the assumption that the noises are uniformly bounded in variance or satisfy a martingale property . To me , these assumptions are similar ( if not identical ) to those made in Section 5 and in Sections 3,4,6 , respectively . Could the authors clarify the differences between the noise model of [ 4 ] and the one they use , and why the algorithm [ 4 ] is impractical and can not be used in online settings ? Why was it treated differently in the numerical experiments ? Another feature that was not discussed in the paper is the feasibility of the algorithm in terms of the availability of the function queries . The problem stated in Equation ( P ) is a constrained online optimization problem over a convex set . However , since the test points are sampled over the entire state space from Gaussian distributions , the proposed algorithm will query function values outside the feasible set , and these function values are not available in many learning applications . Note that it is possible to combine Gaussian sampling with constrained online optimization [ 5 ] , and that feasible zeroth-order optimization algorithms based on residual feedback have been developed [ 6 ] . Typos : p.2 such an one-point derivative-free setting = > such a p.7 nonstatinoary = > nonstationary [ 1 ] Yurii Nesterov and Vladimir Spokoiny . Random gradient-free minimization of convex functions . Foundations of Computational Mathematics , 17 ( 2 ) :527\u2013566 , 2017 . [ 2 ] Alexander V Gasnikov , Ekaterina A Krymova , Anastasia A Lagunovskaya , Ilnura N Usmanova , and Fedor A Fedorenko . Stochastic online optimization . single-point and multipoint non-linear multi-armed bandits . convex and strongly-convex case . Automation and remote control , 78 ( 2 ) :224\u2013234 , 2017 . [ 3 ] https : //arxiv.org/abs/1603.04350 [ 4 ] Francis Bach and Vianney Perchet . Highly-smooth zero-th order online optimization . In Conference on Learning Theory , pp . 257\u2013283 , 2016 . [ 5 ] https : //arxiv.org/abs/1607.03084 [ 6 ] https : //arxiv.org/abs/2006.05445 __________ Update after the discussions : I would like to thank the author ( s ) for all their comments . Although most of my concerns have been addressed , some questions remain topics of contention . Before discussing these topics , I will first append to this review my answer to the author ( s ) ' last comments , as it was their wish to keep hearing from me after closing of the discussions : $ \\ \\ \\ $ The assumptions ( 3.1 , 4.1 , 5.1 , 5.3 ) made on the function sequence $ f_t $ for convergence of the proposed algorithm are unconventional as they require that the expected absolute variations of two function values at the points visited by the algorithm be bounded , or that the squared variations of two function values obtained by Gaussian sampling from points visited by the algorithm be bounded . So formulated , the conditions for convergence involve the algorithm 's trajectory $ x_t $ as much as the function sequence $ f_t $ , and they are difficult to verify . In an attempt to identify sufficient conditions for these assumptions to hold true , I made three suggestions : ( i ) and ( ii ) were concerned with the boundedness of the sequence of points generated by the algorithm , and ( iii ) was the case of bounded incremental variations of the sequence $ f_t $ , e.g.martingales . In their reply , the author ( s ) were right to rule out ( i ) and ( ii ) , which indeed were unrelated . This leaves us with ( iii ) as a possible setting for the proposed algorithm . $ \\ \\ \\ $ In my last comment I argued that the case ( iii ) , where the sequence $ f_t $ undergoes incremental variations uniformly bounded in expectation , was covered by the approach taken in Bach & Perchet ( 2016 ) , where two function queries obtained from perturbations around the same iterate are processed at each step . The Bach/Perchet approach is cited in the paper for comparison , but it is called impractical as it would not apply when $ f_t $ varies over time $ - $ argument I disagree with and that I attempted to refute in a brief discussion involving martingale-like variations for $ f_t $ . When the author ( s ) of the submission object to my regret analysis in the case of martingale-like noise on the basis that the assumptions they make also cover non-zero-mean variations with similar uniform upper bounds on the moments , they do not address the main point of my comment . My intention was to show that it does not take much effort to consider the approach used in Bach & Perchet ( 2016 ) in settings where the cost function is changing over time , for as long as the cost variations are incremental with bounded moments . This can be seen by noting that the convergence result derived in the revised version of the supplementary material for the residual-feedback algorithm with unit-sphere sampling can be reproduced for the Bach/Perchet approach under the considered assumptions . I take it that the author ( s ) , who excel at deriving the convergence rates for such algorithms , will not disagree . Although the assumptions used in Bach & Perchet ( 2016 ) ( uniform zero-mean increments ) may look somewhat stricter , they have the merit of being clear and simple , as opposed to Assumptions 3.1 , 4.1 , 5.1 , 5.3 , which involve the trajectory of the algorithm and ca n't be verified easily . They are also sufficient to improve the convergence rates for higher degrees of smoothness compared to the early algorithm by Flaxman et al . ( 2005 ) , which was the objective of that paper . Higher degrees of smoothness failing which it is difficult to improve the convergence rates , as confirmed by the convergence rates given in the submission . In my sense , one important message conveyed by the submission is that the approaches proposed in the submission and in Bach & Perchet ( 2016 ) can both handle bounded additive noise , and both fail in the more general framework of adversarial learning . By calling the Bach/Perchet algorithm impractical for their setting , I believe the author ( s ) of the submission missed to chance to compare the two approaches from a fair perspective and to answer the simple question that comes to mind when reading their paper : is the residual feedback technique really useful in the stochastic learning framework , or is n't convergence just as fast when the function queries are processed by pairs as in Bach & Perchet ( 2016 ) , or in the reference paper by Nesterov & Spokoiny ( 2017 ) ? - That being said , the following issues remain in this submission : $ \\bullet $ The assumptions ( 3.1 , 4.1 , 5.1 , 5.3 ) made on the function sequence $ f_t $ for convergence of the proposed algorithm are unconventional and difficult to verify , because they consist in properties of the iterates of the algorithm . $ \\bullet $ In our discussions , only incremental sequences $ f_t $ with variations uniformly bounded in expectation have been identified to meet those assumptions . In my sense , this particular setting is also covered by the approach taken in Bach & Perchet ( 2016 ) , where the function queries are handled by pairs obtained from perturbations around the same iterate . Also , I still find it unfair to call the latter approach impractical for the considered setting . $ \\bullet $ Since the convergence rates derived in the paper show no clear improvement , compared to the early approach of Flaxman et al . ( 2005 ) , the arguments of the submission lie in the experimental results , where I do n't think the algorithm by Bach & Perchet ( 2016 ) is given a fair treatment ( for the reason explained in the previous paragraph ) . Besides , the application considered in Section 6.1 reduces to the unconstrained minimization of a polynomial of high degree that is neither Lipschitz nor smooth , which is a basic requirement for the convergence algorithms . This makes the convergence of the algorithms highly dependent on the initial point , unless optimization is done over a compact set , but I do n't think the projection step was implemented for the algorithms . $ \\bullet $ In constrained optimization , the problem that the proposed algorithm samples function values outside the feasible set has been partly addressed by the author ( s ) , who provided a variant of the algorithm based no longer on Gaussian sampling , but on sampling over a sphere . Partly because only one convergence result for a particular setting was derived , and it remains unclear ( as pointed out by Reviewer 4 ) if all the benefits of Gaussian smoothing and all convergence results would also extend to spheric smoothing . This discussion is missing . In my opinion , the extension to settings where the functions ca n't be sampled outside the feasible set is not absolutely imperative in all frameworks ( the author ( s ) have provided counter-examples ) , but it would be useful to know the limits of the proposed technique . All things considered , I would not recommend the submission for presentation at the conference . Independently of the final decision , I hope the author ( s ) will make the most from the discussions with all the reviewers . I would like to make a last comment about the submission and the discussions that followed . It is natural that the author ( s ) give the best picture of the algorithm they propose . Yet in the paper the contrast is particularly strong between , on the one hand , the haziness surrounding the assumptions made on the function sequence $ f_t $ , or the negligence with which the algorithms were applied in Section 6.1 to a problem not actually meeting the conditions for convergence , and on the other hand the severity with which the Bach/Perchet approach was disqualified as a possible method of solution . This contrast gives the reader an overall feeling of partiality , which makes the reviewing task an intricate , contradictory , and unappreciative one .", "rating": "4: Ok but not good enough - rejection", "reply_text": "Q6 : Discussion on the ability to query function values outside the constraint set . A : We thank the reviewer for raising this question . In this paper , we follow the existing literature and assume that $ f_t $ can be evaluated outside the constraint set . This assumption is widely adopted , e.g. , in the following literature [ A-E ] . In particular , we note that the constraint set only restricts the final optimization solution , and it does not restrict the feasibility of the function evaluations . On the other hand , we also want to mention that with minor modifications we can guarantee the feasibility of the perturbed points . We elaborate on these modifications in the Section H in the supplementary material . In short , we can use unit sphere sampling instead of Gaussian sampling , and perform the projection onto a shrinked constraint set $ ( 1-\\xi ) \\mathcal { X } $ for some small $ \\xi > 0 $ ( see eq . ( 48 ) ) , where the shrinkage coefficient $ ( 1-\\xi ) $ is to make sure that the perturbed point is within the original set $ \\mathcal { X } $ . [ A ] Duchi , et al , A . ( 2015 ) .Optimal rates for zero-order convex optimization : The power of two function evaluations . [ B ] Bach , F. , & Perchet , V. ( 2016 ) . Highly-smooth zero-th order online optimization . [ C ] Liu , et al , ( 2018 ) . Zeroth-order stochastic projected gradient descent for nonconvex optimization . [ D ] Balasubramanian , K. , & Ghadimi , S. ( 2018 ) . Zeroth-order nonconvex stochastic optimization : Handling constraints , high-dimensionality and saddle-points . [ E ] Sahu , A. K. , & Kar , S. ( 2020 ) . Decentralized Zeroth-Order Constrained Stochastic Optimization Algorithms : Frank-Wolfe and Variants With Applications to Black-Box Adversarial Attacks . We also thank the reviewer for pointing out the solutions in [ 5,6 ] . The discussion of [ 5 ] is included in our response to Q3 . In [ 6 ] , the authors studied a similar oracle for a static convex optimization problem with objective and constraint functions of specific forms . The above discussion and the related works mentioned by the reviewer have been included in the revision under update ( 4 ) ."}, "2": {"review_id": "T3kmOP_cMFB-2", "review_text": "1.Paper contribution summary This paper proposes a new one-point zeroth-order gradient estimation method for online optimization . Comparing to previous methods in the same scenario , this paper 's method is shown to have smaller variance , which can improve the learning rate in certain cases including classes of convex Lipschitz functions , convex smooth functions , non-convex Lipschitz functions , as well as non-convex smooth functions . 2.Strong and weak points of the paper 1 ) Strong points : The paper 's focus is on one-point zeroth-order gradient estimate , which is a more realistic setting in non-stationary online optimization problems as compared to most popular two-point estimator due to the queried function is time-varying . The new estimate method is based on residual feedback from previous time 's perturbed objective value , which can help improve the regret order when function variation is small . It also extends the finding to online non-convex optimization problems with different regret definitions . And the proposed new one-point zeroth-order gradient estimation method is shown to have smaller variance and improved performance in the two numerical examples . 2 ) Weak points : The proposed zeroth-order update rule for constrained convex case in Eq . ( 4 ) is problematic . For the constrained case , it uses a projection to make sure x_ { t+1 } is feasible . However , when doing gradient estimation , it actually uses the perturbed x_ { t+1 } + \\delta u_ { t+1 } , which may violate the constraint , making this update rule not feasible sometimes . The claimed improvement for convex cases is only in the constant order instead of the order of T even under this problematic update rule . The regret metrics used in the two online non-convex cases : non-convex Lipschitz , non-convex smooth are different from each other , which is very weird . 3.My recommendation I would suggest a rejection due to the problematic update rule in Eq . ( 4 ) and the constant order improvement . 4.Supporting arguments for my recommendation . First , the problematic update rule as discussed above . Second , the only constant order improvement of regret in convex cases . Third , the weird different regret metrics used in non-convex cases . 5.Questions 1 ) Can the author/s confirm if the update in Eq . ( 4 ) is problematic ? 2 ) Why using two different regret metric in non-convex problems ? 3 ) For the example used in the paragraph under Eq . ( 8 ) to show that the assumption 3.1 is weaker than previous works ' uniform boundedness , i feel that the uniform boundedness assumption in prior works can be improved to have only bounded first or second order expectation . Then the example 's statement wo n't hold anymore . Can the author/s make any comments on this ?", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for providing valuable feedback that helps us improve the quality of this paper . Below is a point-to-point response to the reviewer \u2019 s concerns . Q1 : Concerns on the correctness of the update in ( 4 ) . A : We thank the reviewer for raising this question . We want to first emphasize that the feasibility of update ( 4 ) pointed out by the reviewer is not a concern for our method and the same update has been widely adopted in the existing literature , e.g. , see the papers [ A-E ] given below . This literature allows the function to be evaluated outside the constraint set . For example , in the update ( 3 ) and gradient estimate ( 6 ) in [ A ] and in the update ( 6 ) in [ B ] , the authors first obtain the next iterate by projecting onto the constraint set and then perturb this new iterate and evaluate its function value to estimate the zeroth-order gradient . Our update ( 4 ) adopts the same idea . On the other hand , we also want to mention that with minor modifications we can guarantee the feasibility of the perturbed points . We elaborate on these modifications in Section H in the supplementary material . In short , we can use unit sphere sampling instead of Gaussian sampling , and perform the projection onto a shrinked constraint set $ ( 1-\\xi ) \\mathcal { X } $ for some small $ \\xi > 0 $ ( see eq . ( 48 ) ) , where the shrinkage coefficient $ ( 1-\\xi ) $ is to make sure that the perturbed point is within the original set $ \\mathcal { X } $ . To summarize , the update ( 4 ) is not problematic . To satisfy the additional requirement that the objective function can only be queried at feasible points , we \u2019 ve modified the algorithm so that the iterates can be guaranteed to lie within the feasible set and the related analysis is also provided . This discussion is added to the revised manuscript under ( 4 ) . [ A ] Duchi et.al . ( 2015 ) .Optimal rates for zero-order convex optimization : The power of two function evaluations . [ B ] Bach , F. , & Perchet , V. ( 2016 , June ) . Highly-smooth zero-th order online optimization . [ C ] Liu et.al . ( 2018 , November ) . Zeroth-order stochastic projected gradient descent for nonconvex optimization . [ D ] Balasubramanian , K. , & Ghadimi , S. ( 2018 ) . Zeroth-order nonconvex stochastic optimization : Handling constraints , high-dimensionality and saddle-points . [ E ] Sahu , A. K. , & Kar , S. ( 2020 ) . Decentralized Zeroth-Order Constrained Stochastic Optimization Algorithms : Frank-Wolfe and Variants With Applications to Black-Box Adversarial Attacks . Q2 : Explain the reason for using two different regret metrics in non-convex problems . A : Thanks for raising this question . We want to point out that these are standard metrics used for non-smooth & non-convex zeroth-order optimization , see Section 7 in the seminal work [ Nesterov & Spokoiny , 2017 ] . To elaborate , in non-smooth non-convex optimization , the gradient of the objective function $ \\nabla f_t $ does not exist and hence the regret $ R^T_g $ is not well-defined . In this case , we define a smoothed regret $ R^T_ { g , \\delta } $ based on the smoothed objective function $ f_ { \\delta , t } $ . At the same time , we should not smooth the function too much , as otherwise $ f_ { \\delta , t } $ can be very different from $ f_t $ . Thus , we control the smoothing parameter $ \\delta $ to enforce that $ |f_ { \\delta , t } - f_t| \\le \\epsilon_f $ . This discussion is presented above Theorem 4.2 . Q3 : I feel that the uniform boundedness assumption in prior works can be improved to have only bounded first or second order expectation . A : We agree that the one-point method can be analyzed using these relaxed conditions . For example , in the following paper [ F ] , the analysis of the one-point method is based on bounded second moment of the objective function , i.e. , $ E [ |f_t ( x ; \\xi_t ) |^2 ] \\le B $ . However , we note that our assumption only requires the second moment of the function variation to be bounded , which is less strict than the assumption that the objective function has bounded second moment . As an example , consider the time-varying functions defined by $ f_0 = 1/2x^2 $ and $ f_t = f_ { t-1 } + n_t $ , where $ n_t\\sim \\mathcal { N } ( 0,1 ) $ . Then , the second moment of $ f_t $ increases linearly over time and is not bounded , but the variation $ f_t - f_ { t-1 } $ has bounded second moment . We have included this example in the revised manuscript . [ F ] Gasnikov et.al . ( 2017 ) .Stochastic online optimization . Single-point and multi-point non-linear multi-armed bandits . Convex and strongly-convex case . Q4 : Constant order improvement . A : The constant-order improvement is expected , as our method is a one-point method and must not exceed the information theoretic limit of one-point methods . However , we think our one-point residual feedback has its own merit . It provides a more effective zero-order algorithm for solving online problems where two-point methods are not applicable , and resolves the large variance issue of the conventional one-point feedback ."}, "3": {"review_id": "T3kmOP_cMFB-3", "review_text": "Summary : The paper considers online optimization with zero-order oracle . Motivated by nonstationarity of the objective function , impracticality is underlined for the two-point feedback approach . Instead , staying in the one-point setting , the proposed approach reuses the objective value from the previous round of observations , which is called as residual feedback . The variance of the corresponding proxy for the subgradient is estimated under more relaxed assumptions than existing in the literature . The proposed approach leads to smaller variance and better regret bounds . Regret bounds are proved for smooth/non-smooth convex/non-convex cases , the non-convex case being analyzed for the first time in the literature . Numerical experiments show that the practical performance of the proposed gradient estimator is better than that of the existing one-point feedback methods and is close to the performance of the one-point approach with two observations per round . The latter approach can be impractical for some applications . Evaluation : I believe that the paper contains new interesting results on zero-order methods with one-point feedback , which are supported both theoretically and numerically . So , I suggest accepting the paper . Pros : 1.New theoretical results which are significant for optimization and learning literature , as well as for applications . 2.Numerical results support theoretical findings . 3.The paper is overall clearly written and motivated . Cons : 1.There are several minor comments mainly on the clarity of presentation . See below . Minor comments 1 . Some related work seems to be missing http : //proceedings.mlr.press/v48/hazanb16.pdf ( non-convex optimization with one-point feedback ) https : //link.springer.com/article/10.1007 % 2Fs10107-014-0846-1 ( non-convex stochastic optimization ) http : //papers.nips.cc/paper/5377-bandit-convex-optimization-towards-tight-bounds.pdf http : //papers.nips.cc/paper/4475-stochastic-convex-optimization-with-bandit-feedback.pdf 2 . Please consider writing explicitly on p.7 that Bach & Perchet ( 2016 ) use two function evaluations in each round . Also it would be nice to explain in more details , why their approach is impractical . For example , in the considered in Sect . 6.1 example , why one can not observe x_ { k+1 } two times ( with different values w_k ) , and the evaluate the loss twice ? 3.The proof of Lemma 2.5 does not completely correspond to the statement of the Lemma . In the proof more is derived than stated in the Lemma , but under additional assumptions . 4.In the first line of Appendix F , did you mean that $ f_ { \\delta , t } \\in C^ { 1,1 } $ ? Also here Assumption 3.1 is used , which should be mentioned .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank the reviewer for providing valuable feedback that helps us improve the quality of this paper . Below is a point-to-point response to the reviewer \u2019 s concerns . Q1 : Related works missing . A : We thank the reviewer for referring us to these works . These works study the two-point method , conventional one-point method or the ellipsoid method in static convex or non-convex optimization problems . We agree that they are also related and will be added to our discussion . Q2 : Clarification on why the two-point method is impractical . A : Thanks for this comment . We will add the comment on [ Bach & Perchet , 2016 ] according to the reviewer \u2019 s suggestion . If one wants to use the two-point gradient estimator ( 7 ) in [ Bach & Perchet , 2016 ] to solve the non-stationary RL problem in Section 6.1 , at episode $ t $ with dynamical matrices $ ( A_t , B_t ) $ , ( 7 ) requires to evaluate two different policy parameters $ K_t + \\delta U_t $ and $ K_t \u2013 \\delta U_t $ . However , in a practical non-stationary system , evaluation of each policy parameter requires one episode . For example , if we evaluate $ K_t + \\delta U_t $ at episode $ t $ , then the non-stationary environment evolves to episode $ t+1 $ with new dynamical matrices $ ( A_ { t+1 } , B_ { t+1 } ) $ . Therefore , $ K_t \u2013 \\delta U_t $ can not be evaluated in the environment with $ ( A_t , B_t ) $ anymore . This violates the assumption in ( 7 ) in [ Bach & Perchet , 2016 ] . Therefore , the two-point method ( 7 ) in [ Bach & Perchet , 2016 ] can not be implemented in a practical non-stationary system . Q3 : Proof of Lemma 2.5 . A : Thanks for this comment . Without Assumption 3.1 , we can directly replace all $ V_f^2 $ in inequalities after ( 15 ) with $ E [ ( f_t ( z ) \u2013 f_ { t-1 } ( z ) ) ^2 ] $ , where $ z = x_ { t-1 } + \\delta u_ { t-1 } $ , and get the results in Lemma 2.5 . This issue has been fixed in our revised supplementary material . Q4 : Clarification on the proof in Appendix F A : Thanks for this comment . In the first line of Appendix F , we meant that when $ f_t \\in C^ { 1,1 } $ with Lipschitz constant $ L_1 $ , we have that $ f_ { \\delta , t } \\in C^ { 1,1 } $ also with constant $ L_1 $ . And the reviewer is correct that to get inequality ( 41 ) , we also use Assumption 3.1 . We have clarified this in the revised draft ."}}