{"year": "2017", "forum": "Hk4_qw5xe", "title": "Towards Principled Methods for Training Generative Adversarial Networks", "decision": "Accept (Oral)", "meta_review": "The paper provides a detailed analysis of the instability issues surrounding the training of GANs. They demonstrate how perturbations can help with improving stability. Given the popularity of GANs, this paper is expected to have a significant impact.", "reviews": [{"review_id": "Hk4_qw5xe-0", "review_text": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. With the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. I am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed. Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison? ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks for the review ! The perturbation trick definitely seems like a good direction , and we are already starting to see empirical evidence in other groups using it successfully ( e.g : https : //openreview.net/pdf ? id=S1RP6GLle in image super resolution and http : //mrdrozdov.com/papers/infogan.pdf in infogan variants ) . That being said , the variance of the noise can be important , since too little noise will likely not be enough to ameliorate all issues , and too much noise will likely lead to high variance of the gradients . The structure of the noise can be quite important as well , since the covariance matrix of images is quite complex ( even if it is known ) , so N ( 0 , sigma * I ) noise is probably not the best we can do . We 'd like to get a more complete understanding of how different types of noise behave , and in the end finish the story by properly stabilizing GANs , but due to time constraints and the paper already being quite long we chose to keep this for further research . This way we also give the possibility to other researchers to start experimenting on this issues ( with some understanding ) right away , which we in the end considered more valuable . The connection with dropout seems quite interesting ! In fact , adding noise at higher layers ( similar to dropout ) could be quite a good idea , since as the factors of variations get disentangled , a more simple noise will have the right metric structure on hidden unit space . We 'll be glad to continue exploring this direction in future work : ) If you have more questions or comments please let us know ! Best , Martin"}, {"review_id": "Hk4_qw5xe-1", "review_text": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor. ", "rating": "10: Top 5% of accepted papers, seminal paper", "reply_text": "Thank you for the amazing review ! ! ! If you have any questions please send them our way and we 'll be glad to answer them : ) Best ! Martin"}, {"review_id": "Hk4_qw5xe-2", "review_text": "SUMMARY This paper addresses important questions about the difficulties in training generative adversarial networks. It discusses consequences of using an asymmetric divergence function and sources of instability in training GANs. Then it proposes an alternative using a smoothening approach. PROS Theory, good questions, nice answers. Makes an interesting use of concepts form analysis and differential topology. Proposes avenues to avoid instability in GANs. CONS A bit too long, technical. Some parts and consequences still need to be further developed (which is perfectly fine for future work). MINOR COMMENTS - Section 2.1 Maybe shorten this section a bit. E.g., move all proofs to the appendix. - Section 3 provides a nice, intuitive, simple solution. - On page 2 second bullet. This also means that P_g is smaller than the data distribution in some other x, which in turn will make the KL divergence non zero. - On page 2, \"for not generating plausibly looking pictures\" should be \"for generating not plausibly looking pictures\". - Lemma 1 would also hold in more generality. - Theorem 2.1 seems to be basic analysis. (In other words, a reference could spare the proof). - In Theorem 2.4, it would be good to remind the reader about p(z). - Lemma 2 seems to be basic analysis. (In other words, a reference could spare the proof). Specify the domain of the random variables. - relly - > rely - Theorem 2.2 the closed manifolds have boundary or not? (already in the questions) - Corollary 2.1, \"assumptions of Theorem 1.3\". I could not find Theorem 1.3. - Theorem 2.5 \"Therefore\" -> `Then'? - Theorem 2.6 \"Is a... \" -> `is a' ? - The number of the theorems is confusing. ", "rating": "7: Good paper, accept", "reply_text": "Thanks for the review ! We agree with everything said . We did however choose to leave some of the proofs in the main text . We think it may be helpful for people that do n't have such a strong analytical background to get acquainted with the ideas so that it does n't appear as a black box result . - We extended the definitions in section 2 and the statements and proofs of Lemmas 2 and 3 to cover manifolds with and without boundary . - We would love to get a more general version of Lemma 1 , but we could n't come up with one . If you have any pointers on directions or a reference to look into that would be super helpful ! - We fixed all the typos and the numbering of the theorems : ) If you have any more suggestions or questions please let us know ! Best , Martin"}], "0": {"review_id": "Hk4_qw5xe-0", "review_text": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. With the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. I am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed. Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison? ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks for the review ! The perturbation trick definitely seems like a good direction , and we are already starting to see empirical evidence in other groups using it successfully ( e.g : https : //openreview.net/pdf ? id=S1RP6GLle in image super resolution and http : //mrdrozdov.com/papers/infogan.pdf in infogan variants ) . That being said , the variance of the noise can be important , since too little noise will likely not be enough to ameliorate all issues , and too much noise will likely lead to high variance of the gradients . The structure of the noise can be quite important as well , since the covariance matrix of images is quite complex ( even if it is known ) , so N ( 0 , sigma * I ) noise is probably not the best we can do . We 'd like to get a more complete understanding of how different types of noise behave , and in the end finish the story by properly stabilizing GANs , but due to time constraints and the paper already being quite long we chose to keep this for further research . This way we also give the possibility to other researchers to start experimenting on this issues ( with some understanding ) right away , which we in the end considered more valuable . The connection with dropout seems quite interesting ! In fact , adding noise at higher layers ( similar to dropout ) could be quite a good idea , since as the factors of variations get disentangled , a more simple noise will have the right metric structure on hidden unit space . We 'll be glad to continue exploring this direction in future work : ) If you have more questions or comments please let us know ! Best , Martin"}, "1": {"review_id": "Hk4_qw5xe-1", "review_text": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor. ", "rating": "10: Top 5% of accepted papers, seminal paper", "reply_text": "Thank you for the amazing review ! ! ! If you have any questions please send them our way and we 'll be glad to answer them : ) Best ! Martin"}, "2": {"review_id": "Hk4_qw5xe-2", "review_text": "SUMMARY This paper addresses important questions about the difficulties in training generative adversarial networks. It discusses consequences of using an asymmetric divergence function and sources of instability in training GANs. Then it proposes an alternative using a smoothening approach. PROS Theory, good questions, nice answers. Makes an interesting use of concepts form analysis and differential topology. Proposes avenues to avoid instability in GANs. CONS A bit too long, technical. Some parts and consequences still need to be further developed (which is perfectly fine for future work). MINOR COMMENTS - Section 2.1 Maybe shorten this section a bit. E.g., move all proofs to the appendix. - Section 3 provides a nice, intuitive, simple solution. - On page 2 second bullet. This also means that P_g is smaller than the data distribution in some other x, which in turn will make the KL divergence non zero. - On page 2, \"for not generating plausibly looking pictures\" should be \"for generating not plausibly looking pictures\". - Lemma 1 would also hold in more generality. - Theorem 2.1 seems to be basic analysis. (In other words, a reference could spare the proof). - In Theorem 2.4, it would be good to remind the reader about p(z). - Lemma 2 seems to be basic analysis. (In other words, a reference could spare the proof). Specify the domain of the random variables. - relly - > rely - Theorem 2.2 the closed manifolds have boundary or not? (already in the questions) - Corollary 2.1, \"assumptions of Theorem 1.3\". I could not find Theorem 1.3. - Theorem 2.5 \"Therefore\" -> `Then'? - Theorem 2.6 \"Is a... \" -> `is a' ? - The number of the theorems is confusing. ", "rating": "7: Good paper, accept", "reply_text": "Thanks for the review ! We agree with everything said . We did however choose to leave some of the proofs in the main text . We think it may be helpful for people that do n't have such a strong analytical background to get acquainted with the ideas so that it does n't appear as a black box result . - We extended the definitions in section 2 and the statements and proofs of Lemmas 2 and 3 to cover manifolds with and without boundary . - We would love to get a more general version of Lemma 1 , but we could n't come up with one . If you have any pointers on directions or a reference to look into that would be super helpful ! - We fixed all the typos and the numbering of the theorems : ) If you have any more suggestions or questions please let us know ! Best , Martin"}}