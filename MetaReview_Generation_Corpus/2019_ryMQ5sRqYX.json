{"year": "2019", "forum": "ryMQ5sRqYX", "title": "Finding Mixed Nash Equilibria of Generative Adversarial Networks", "decision": "Reject", "meta_review": "While the authors made a strong rebuttal, none of the reviewers were particularly enthusiastic about the contributions of this paper and we unfortunately have to reject borderline papers. Concerns were expressed about the presentation, as well as the scalability of the approach. The AC encourages the authors to \"revise and resubmit\".", "reviews": [{"review_id": "ryMQ5sRqYX-0", "review_text": "This paper uses a mixed strategy perspective for GANs. With this formulation the non-convex game formulation of GANs can be transformed into a infinite dimensional problem analog to a finite dimensional bilinear problem. I really like this approach, that tries to find methods that converge globally to (mixed) Nash equilibriums. However I have some concerns. - I'm concerned about the definition of a $O(T^{-1})-NE$. Actually, this merit function is not standard for game. It can be 0 even if $x_t,y_t$ is far from the equilibrium (for instance for the problem $\\min_{x \\in \\Delta_d}\\max_{y \\in \\Delta_d} x^\\top y$ with $x_t = (1,0,\\ldots,0)$ and $y_t= (F(x_{NE},y_{NE}),1-F(x_{NE},y_{NE}),0,\\ldots,0)$ we have $F(x_t,y_t) = F(x_{NE},y_{NE})$ but $x_{NE} = y_{NE} =(1/d,\\ldots,1/d)$). One merit function that could be considered is $\\max_{y} F(x,y_t) - \\min_{y} F(x_t,y)$. - There is a gap between the theory and the practical method that could be bridged. Actually Theorem 2 assume that the stochastic derivatives are unbiased but since your Langevin dynamics gives you an *approximate* of the next distribution an analysis taking into account this bias would provide much stronger results. More precisely, it would be interesting to have a result similar as Theorem 2 with conditions on $\\epsilon_t$ and $K_t$. For instance, if the theoretical $K_t$ is too large it would reduce the interest of your algorithm. I think this analysis is key since it allows to claim that you can properly approximate the distributions of interest. If you are able to ease these concerns I'm eager to increase my grade. - \"(5) is exactly the infinite-dimensional analogue of (1):\" Actually it is not exactly the analogue since $<.,.>$ is not a scalar product anymore (particularly, $<g,\\mu>$ is not defined) but the canonical pairing between a space and its dual (we are loosing something going to infinite dimension). I think it should be clarified somewhere. Minor comments: - on the updates rules of $\\theta$ and $\\omega$ (Page 6) the Gaussian noises are missing. - On algorithm 3,4,5 and 6 the Gaussian noise is too wide and causes an Overfull. === After Authors response === The authors fixed some major issues. That is why I improved my grade. However I'm still concerned about the scalability of this algorithm ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Minor comments are incorporated in the revision . \u201c I 'm concerned about the definition of a $ O ( T^ { -1 } ) -NE $ ... \u201d Thank you for noting this ; we have fixed the definition . As Reviewer3 mentioned , This was an oversight of the definition , and our convergence guarantees are for the correct definition . \u201c ... an analysis taking into account this bias would provide much stronger results. \u201d Thank you for the very illuminating idea ; we now have bounds that explicitly take the bias into account in Theorem 2 . However , we note that quantifying conditions on eps_t and K_t is equivalent to proving non-asymptotic bounds for sampling from distributions over neural nets , a task that is more difficult than proving convergence to global optima , and hence is well beyond the scope of our work . However , under fairly mild conditions , it is known that at least asymptotically , SGLD converges at rate t^ { -1/3 } ; see [ * ] . \u201c ... Actually it is not exactly the analogue since $ < . , . > $ is not a scalar product\u2026 Thanks for pointing this out . We have added a footnote to clarify this point . [ * ] Consistency and fluctuations for stochastic gradient Langevin dynamics by Teh et al. , JMLR 2016 ."}, {"review_id": "ryMQ5sRqYX-1", "review_text": "This paper proposes to consider the mixed equilibrium objective function for GANS. The authors generalize the mirror descent/mirror prox to handle continuous games. The technical challenge is to write those algorithms in infinite dimensional spaces. This reviewer finds this however to be a mere technicality, and there seems to be no conceptual obstruction. In fact other paper have already written this, see for example \"Mirror Descent Learning in Continuous Games\" by Zhou et al. at CDC 2017 (I'm sure there are other references too). While the theory part is not particularly exciting, the paper could be saved by the experiments. However as far I can tell the authors are only able to reproduce the results obtained with more classical approaches. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "We have addressed all of your concerns and we look forward to further correspondence with you . \u201c The technical challenge is to write those algorithms in infinite dimensional spaces . This reviewer finds this however to be a mere technicality , and there seems to be no conceptual obstruction. \u201d Please see the * * * * Novelty and significance * * * * part of the general response . The conceptual leap here is not the infinite dimensional algorithm ; rather , it is the infinite dimensional re-formulation of the GAN problem via the Riesz representation . We do know the entropic mirror descent solves the problem in finite dimension , however it is surprising to see that the mirror-prox along with Langevin dynamics handle the GAN problem in a simple fashion , which this paper brings to the table . Our results are not some theory dressing to motivate a method that already works in practice . Our formulation , the algorithm ( a fusion of entropic mirror descent and Langevin dynamics ) , and the practical results , to our knowledge , is a solid contribution to the literature . Without the infinite dimensional characterization , we felt like we would be criticized for lack of rigor . \u201c In fact other paper have already written this , see for example `` Mirror Descent Learning in Continuous Games \u2019 \u2019 by Zhou et al.at CDC 2017 ( I 'm sure there are other references too ) . \u201d The paper , as explained in the general response , is not relevant to this work . Regarding algorithms for solving infinite-dimensional games , the reference ( Balandat et al. , 2016 ) is the most appropriate to our knowledge . We would appreciate if you can point out some references that are closer to our work than ( Grnarova et al.2018 ) or ( Balandat et al. , 2016 ) , which we might have possibly missed . \u201c While the theory part is not particularly exciting , the paper could be saved by the experiments . However as far I can tell the authors are only able to reproduce the results obtained with more classical approaches. \u201d We now have a comparison to the most contemporary algorithm ; please see the general response above and the revision ."}, {"review_id": "ryMQ5sRqYX-2", "review_text": "This paper extends the mirror-descent and mirror-prox algorithms to infinite dimensional Banach spaces so that they can be applied to solve the mixed Nash equilibrium of the popular generative adversarial networks. The main technical results appear to be formal but straightforward extensions of existing techniques in finite dimensional spaces. A sample-based practical algorithm is proposed so that the infinite dimensional algorithms can still be computed. Experiments are a bit disappointing as the authors only used visual appeal as an evaluation criterion. (I understand why the authors chose to do so but as an algorithmic paper, resorting to an evaluation based on visual appeal is almost always unsatisfactory.) Quality: The quality of this work is moderate. Quite strangely, the authors made a fundamental mistake at the very beginning: their definition of approximate mixed equilibrium (page 2, Notation) is bizarre and different from those in previous work (such as Nemirovski's MP paper). Fortunately, this is perhaps only an oversight on the definition; the algorithms and theorems are for the correct definition anyways. Example: consider min_{-1<= x <= 1} max_{-1<=y<=1} xy. Should we call (x, 0) an (approximate) NE for any x?? Another major issue with this work is its relaxation into mixed NE. The \"bilinarization\" trick in Eq (5) goes back to Kantorovich (who perhaps deserves to be mentioned), and is a relaxation in general: we now have to use a mixture of generators. Since MD/MP is not sparse, in the end we must use a large number of mixtures of generators. This certainly will create some computational issues, and make comparison to pure NE methods unfair. Clarity: The writing of this work is mostly easily to follow. However, the presentation of the technical results suffers from a real dilemma: On one hand, the authors completely ignored the technical difference between infinite dimensional Banach spaces and finite dimensional spaces. In fact, the authors never even formally defined the underlying Banach spaces. Another example, is the mapping G on page 3 continuous? wrt what topology? without such discussion what do you mean by Frechet derivative on page 4? when is the entropy function well-defined? when is the integral of exponential well-defined? Part of me totally understand that these technicalities are daunting and perhaps should not appear in the main text. On the other hand, aren't these technicalities the only \"interesting and nontrivial\" part of the extension to infinite dimensional spaces? If we do not care about such technicalities and can safely \"assume they can be taken care of,\" then why is this work nontrivial? I do not see a way to resolve this dilemma here but suggest the authors consider maybe a different venue for such type of results. Originality: The novelty of this work is limited. The extension of MD/MP to infinite dimensional spaces is mostly formal but straightforward. In fact I believe previous authors such as Nemirovski deliberately restrict to finite dimensional spaces not because of technical incapability but to avoid uninspiring technicalities. Some very related previous works were not mentioned at all: -- Mirror Descent Learning in Continuous Games -- Convex Games in Banach Spaces -- On the Universality of Online Mirror Descent The sample based algorithms are more interesting because they make the infinite dimensional extensions implementable. However, one can not say much about their convergence behavior at the moment. Significance: The main results, although not difficult to obtain, can potentially be very useful in broadening our arsenal of tools for training GANs. The claim \"resolving the longstanding problem that no provably convergent algorithm exists for general GAN\" in the Abstract is disturbing, because the authors changed the definition of GAN and because the technical contributions of this work do not live up to that strong claim. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Comments that were already addressed in the general response are omitted . We are more than happy to engage in any further discussion regarding below . \u201c ... the authors made a fundamental mistake \u2026 \u201d Thank you for pointing this out ; we have fixed it . \u201c The `` bilinarization '' trick in Eq ( 5 ) goes back to Kantorovich\u2026 \u201d You might be referring to the Kantorovich \u2019 s Duality ( KD ) for relaxed Monge \u2019 s problem . It seems that Kantorovich himself never used any such trick when he derived KD in the classic \u201c On the translocation of masses 1942 \u201d . Instead , he directly started with the relaxed problem and used a limit argument . Another potentially related paper is \u201c On a problem of Monge 1948 \u201d , which we can only find the Russian version and therefore are unable to check . As a result , we would appreciate if the reviewer can further clarify upon this comment . In any case , we agree with the reviewer that it is worth mentioning KD ; see the new first paragraph in Section 2.2 . \u201c Since MD/MP is not sparse , in the end we must use a large number of mixtures of generators. \u201d This is precisely why we resort to the averaging scheme ; see Section 4.2 . \u201c This certainly will create some computational issues , and make comparison to pure NE methods unfair. \u201d With our averaging scheme , there are no computational issues . Our comparison to pure NE methods is entirely fair since we are comparing the final output images under similar computational resources , which is ultimately what people care about for GANs . \u201c Clarity : The writing of this work \u2026 \u201d This paragraph warrants a sentence-by-sentence reply ; we have addressed all your concerns in the revision . \u201c \u201d On one hand , the authors completely ignored the technical ... \u201d \u201d This comment is perhaps unfair , as we have spent a full section in Appendix A on technical details of inf-dim MD . Even though the presentation in the main text is heuristic , we did refer the readers to Appendix A for precise statements . We are sure that the purpose is well-understood by the reviewer . \u201c In fact , the authors never even formally defined the underlying Banach spaces. \u201d We purposely avoided the term \u201c Banach space \u201d for general audience , but an expert should find no difficulty in checking the details of Appendix A . It is easier to start with Banach spaces , but would make the paper less accessible . We are willing to change the presentation if the reviewer feels that the term is necessary . \u201c \u201d is the mapping G on page 3 continuous ... when is the integral of exponential well-defined ? \u201d \u201d Thanks for pointing out these missing pieces . We have incorporated them all with two new paragraphs in Appendix A . \u201c \u201d Part of me totally understand ... If we do not care about such technicalities and can safely `` assume they can be taken care of , '' then why is this work nontrivial ? \u201d \u201d As explained in the general response , we have never claimed that the inf-dim MD is the main contribution . We also handled all the technical details in Appendix A which , thanks to your review , have become more complete in the revision ( we also fixed an issue in the definition of our function class ) . \u201c Originality : The novelty of this work is limited ... In fact I believe previous authors such as Nemirovski deliberately restrict to finite dimensional spaces ... \u201d Let us reiterate that the technicality is not the major goal of our paper , and we knew that inf-dim MD is folklore among experts ; see general response . \u201c The sample based algorithms are more interesting ... However , one can not say much about their convergence behavior at the moment. \u201d Please see the general response above ; our framework provides , to our knowledge , the strongest theoretical claim for training GANs . For the efficient algorithms with averaging , we did admit that it is heuristic , but it works well in practice and is derived on the guidance provided by the theoretical foundations . \u201c The claim ... is disturbing , because the authors changed the definition of GAN ... \u201d We agree that the sentence can be misleading and we have removed it . But we argue that the GAN framework is not married to the classical pure strategy formulation so it is perfectly fine to change the definition of GAN ."}], "0": {"review_id": "ryMQ5sRqYX-0", "review_text": "This paper uses a mixed strategy perspective for GANs. With this formulation the non-convex game formulation of GANs can be transformed into a infinite dimensional problem analog to a finite dimensional bilinear problem. I really like this approach, that tries to find methods that converge globally to (mixed) Nash equilibriums. However I have some concerns. - I'm concerned about the definition of a $O(T^{-1})-NE$. Actually, this merit function is not standard for game. It can be 0 even if $x_t,y_t$ is far from the equilibrium (for instance for the problem $\\min_{x \\in \\Delta_d}\\max_{y \\in \\Delta_d} x^\\top y$ with $x_t = (1,0,\\ldots,0)$ and $y_t= (F(x_{NE},y_{NE}),1-F(x_{NE},y_{NE}),0,\\ldots,0)$ we have $F(x_t,y_t) = F(x_{NE},y_{NE})$ but $x_{NE} = y_{NE} =(1/d,\\ldots,1/d)$). One merit function that could be considered is $\\max_{y} F(x,y_t) - \\min_{y} F(x_t,y)$. - There is a gap between the theory and the practical method that could be bridged. Actually Theorem 2 assume that the stochastic derivatives are unbiased but since your Langevin dynamics gives you an *approximate* of the next distribution an analysis taking into account this bias would provide much stronger results. More precisely, it would be interesting to have a result similar as Theorem 2 with conditions on $\\epsilon_t$ and $K_t$. For instance, if the theoretical $K_t$ is too large it would reduce the interest of your algorithm. I think this analysis is key since it allows to claim that you can properly approximate the distributions of interest. If you are able to ease these concerns I'm eager to increase my grade. - \"(5) is exactly the infinite-dimensional analogue of (1):\" Actually it is not exactly the analogue since $<.,.>$ is not a scalar product anymore (particularly, $<g,\\mu>$ is not defined) but the canonical pairing between a space and its dual (we are loosing something going to infinite dimension). I think it should be clarified somewhere. Minor comments: - on the updates rules of $\\theta$ and $\\omega$ (Page 6) the Gaussian noises are missing. - On algorithm 3,4,5 and 6 the Gaussian noise is too wide and causes an Overfull. === After Authors response === The authors fixed some major issues. That is why I improved my grade. However I'm still concerned about the scalability of this algorithm ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Minor comments are incorporated in the revision . \u201c I 'm concerned about the definition of a $ O ( T^ { -1 } ) -NE $ ... \u201d Thank you for noting this ; we have fixed the definition . As Reviewer3 mentioned , This was an oversight of the definition , and our convergence guarantees are for the correct definition . \u201c ... an analysis taking into account this bias would provide much stronger results. \u201d Thank you for the very illuminating idea ; we now have bounds that explicitly take the bias into account in Theorem 2 . However , we note that quantifying conditions on eps_t and K_t is equivalent to proving non-asymptotic bounds for sampling from distributions over neural nets , a task that is more difficult than proving convergence to global optima , and hence is well beyond the scope of our work . However , under fairly mild conditions , it is known that at least asymptotically , SGLD converges at rate t^ { -1/3 } ; see [ * ] . \u201c ... Actually it is not exactly the analogue since $ < . , . > $ is not a scalar product\u2026 Thanks for pointing this out . We have added a footnote to clarify this point . [ * ] Consistency and fluctuations for stochastic gradient Langevin dynamics by Teh et al. , JMLR 2016 ."}, "1": {"review_id": "ryMQ5sRqYX-1", "review_text": "This paper proposes to consider the mixed equilibrium objective function for GANS. The authors generalize the mirror descent/mirror prox to handle continuous games. The technical challenge is to write those algorithms in infinite dimensional spaces. This reviewer finds this however to be a mere technicality, and there seems to be no conceptual obstruction. In fact other paper have already written this, see for example \"Mirror Descent Learning in Continuous Games\" by Zhou et al. at CDC 2017 (I'm sure there are other references too). While the theory part is not particularly exciting, the paper could be saved by the experiments. However as far I can tell the authors are only able to reproduce the results obtained with more classical approaches. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "We have addressed all of your concerns and we look forward to further correspondence with you . \u201c The technical challenge is to write those algorithms in infinite dimensional spaces . This reviewer finds this however to be a mere technicality , and there seems to be no conceptual obstruction. \u201d Please see the * * * * Novelty and significance * * * * part of the general response . The conceptual leap here is not the infinite dimensional algorithm ; rather , it is the infinite dimensional re-formulation of the GAN problem via the Riesz representation . We do know the entropic mirror descent solves the problem in finite dimension , however it is surprising to see that the mirror-prox along with Langevin dynamics handle the GAN problem in a simple fashion , which this paper brings to the table . Our results are not some theory dressing to motivate a method that already works in practice . Our formulation , the algorithm ( a fusion of entropic mirror descent and Langevin dynamics ) , and the practical results , to our knowledge , is a solid contribution to the literature . Without the infinite dimensional characterization , we felt like we would be criticized for lack of rigor . \u201c In fact other paper have already written this , see for example `` Mirror Descent Learning in Continuous Games \u2019 \u2019 by Zhou et al.at CDC 2017 ( I 'm sure there are other references too ) . \u201d The paper , as explained in the general response , is not relevant to this work . Regarding algorithms for solving infinite-dimensional games , the reference ( Balandat et al. , 2016 ) is the most appropriate to our knowledge . We would appreciate if you can point out some references that are closer to our work than ( Grnarova et al.2018 ) or ( Balandat et al. , 2016 ) , which we might have possibly missed . \u201c While the theory part is not particularly exciting , the paper could be saved by the experiments . However as far I can tell the authors are only able to reproduce the results obtained with more classical approaches. \u201d We now have a comparison to the most contemporary algorithm ; please see the general response above and the revision ."}, "2": {"review_id": "ryMQ5sRqYX-2", "review_text": "This paper extends the mirror-descent and mirror-prox algorithms to infinite dimensional Banach spaces so that they can be applied to solve the mixed Nash equilibrium of the popular generative adversarial networks. The main technical results appear to be formal but straightforward extensions of existing techniques in finite dimensional spaces. A sample-based practical algorithm is proposed so that the infinite dimensional algorithms can still be computed. Experiments are a bit disappointing as the authors only used visual appeal as an evaluation criterion. (I understand why the authors chose to do so but as an algorithmic paper, resorting to an evaluation based on visual appeal is almost always unsatisfactory.) Quality: The quality of this work is moderate. Quite strangely, the authors made a fundamental mistake at the very beginning: their definition of approximate mixed equilibrium (page 2, Notation) is bizarre and different from those in previous work (such as Nemirovski's MP paper). Fortunately, this is perhaps only an oversight on the definition; the algorithms and theorems are for the correct definition anyways. Example: consider min_{-1<= x <= 1} max_{-1<=y<=1} xy. Should we call (x, 0) an (approximate) NE for any x?? Another major issue with this work is its relaxation into mixed NE. The \"bilinarization\" trick in Eq (5) goes back to Kantorovich (who perhaps deserves to be mentioned), and is a relaxation in general: we now have to use a mixture of generators. Since MD/MP is not sparse, in the end we must use a large number of mixtures of generators. This certainly will create some computational issues, and make comparison to pure NE methods unfair. Clarity: The writing of this work is mostly easily to follow. However, the presentation of the technical results suffers from a real dilemma: On one hand, the authors completely ignored the technical difference between infinite dimensional Banach spaces and finite dimensional spaces. In fact, the authors never even formally defined the underlying Banach spaces. Another example, is the mapping G on page 3 continuous? wrt what topology? without such discussion what do you mean by Frechet derivative on page 4? when is the entropy function well-defined? when is the integral of exponential well-defined? Part of me totally understand that these technicalities are daunting and perhaps should not appear in the main text. On the other hand, aren't these technicalities the only \"interesting and nontrivial\" part of the extension to infinite dimensional spaces? If we do not care about such technicalities and can safely \"assume they can be taken care of,\" then why is this work nontrivial? I do not see a way to resolve this dilemma here but suggest the authors consider maybe a different venue for such type of results. Originality: The novelty of this work is limited. The extension of MD/MP to infinite dimensional spaces is mostly formal but straightforward. In fact I believe previous authors such as Nemirovski deliberately restrict to finite dimensional spaces not because of technical incapability but to avoid uninspiring technicalities. Some very related previous works were not mentioned at all: -- Mirror Descent Learning in Continuous Games -- Convex Games in Banach Spaces -- On the Universality of Online Mirror Descent The sample based algorithms are more interesting because they make the infinite dimensional extensions implementable. However, one can not say much about their convergence behavior at the moment. Significance: The main results, although not difficult to obtain, can potentially be very useful in broadening our arsenal of tools for training GANs. The claim \"resolving the longstanding problem that no provably convergent algorithm exists for general GAN\" in the Abstract is disturbing, because the authors changed the definition of GAN and because the technical contributions of this work do not live up to that strong claim. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Comments that were already addressed in the general response are omitted . We are more than happy to engage in any further discussion regarding below . \u201c ... the authors made a fundamental mistake \u2026 \u201d Thank you for pointing this out ; we have fixed it . \u201c The `` bilinarization '' trick in Eq ( 5 ) goes back to Kantorovich\u2026 \u201d You might be referring to the Kantorovich \u2019 s Duality ( KD ) for relaxed Monge \u2019 s problem . It seems that Kantorovich himself never used any such trick when he derived KD in the classic \u201c On the translocation of masses 1942 \u201d . Instead , he directly started with the relaxed problem and used a limit argument . Another potentially related paper is \u201c On a problem of Monge 1948 \u201d , which we can only find the Russian version and therefore are unable to check . As a result , we would appreciate if the reviewer can further clarify upon this comment . In any case , we agree with the reviewer that it is worth mentioning KD ; see the new first paragraph in Section 2.2 . \u201c Since MD/MP is not sparse , in the end we must use a large number of mixtures of generators. \u201d This is precisely why we resort to the averaging scheme ; see Section 4.2 . \u201c This certainly will create some computational issues , and make comparison to pure NE methods unfair. \u201d With our averaging scheme , there are no computational issues . Our comparison to pure NE methods is entirely fair since we are comparing the final output images under similar computational resources , which is ultimately what people care about for GANs . \u201c Clarity : The writing of this work \u2026 \u201d This paragraph warrants a sentence-by-sentence reply ; we have addressed all your concerns in the revision . \u201c \u201d On one hand , the authors completely ignored the technical ... \u201d \u201d This comment is perhaps unfair , as we have spent a full section in Appendix A on technical details of inf-dim MD . Even though the presentation in the main text is heuristic , we did refer the readers to Appendix A for precise statements . We are sure that the purpose is well-understood by the reviewer . \u201c In fact , the authors never even formally defined the underlying Banach spaces. \u201d We purposely avoided the term \u201c Banach space \u201d for general audience , but an expert should find no difficulty in checking the details of Appendix A . It is easier to start with Banach spaces , but would make the paper less accessible . We are willing to change the presentation if the reviewer feels that the term is necessary . \u201c \u201d is the mapping G on page 3 continuous ... when is the integral of exponential well-defined ? \u201d \u201d Thanks for pointing out these missing pieces . We have incorporated them all with two new paragraphs in Appendix A . \u201c \u201d Part of me totally understand ... If we do not care about such technicalities and can safely `` assume they can be taken care of , '' then why is this work nontrivial ? \u201d \u201d As explained in the general response , we have never claimed that the inf-dim MD is the main contribution . We also handled all the technical details in Appendix A which , thanks to your review , have become more complete in the revision ( we also fixed an issue in the definition of our function class ) . \u201c Originality : The novelty of this work is limited ... In fact I believe previous authors such as Nemirovski deliberately restrict to finite dimensional spaces ... \u201d Let us reiterate that the technicality is not the major goal of our paper , and we knew that inf-dim MD is folklore among experts ; see general response . \u201c The sample based algorithms are more interesting ... However , one can not say much about their convergence behavior at the moment. \u201d Please see the general response above ; our framework provides , to our knowledge , the strongest theoretical claim for training GANs . For the efficient algorithms with averaging , we did admit that it is heuristic , but it works well in practice and is derived on the guidance provided by the theoretical foundations . \u201c The claim ... is disturbing , because the authors changed the definition of GAN ... \u201d We agree that the sentence can be misleading and we have removed it . But we argue that the GAN framework is not married to the classical pure strategy formulation so it is perfectly fine to change the definition of GAN ."}}