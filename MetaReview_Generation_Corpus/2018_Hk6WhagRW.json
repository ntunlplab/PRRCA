{"year": "2018", "forum": "Hk6WhagRW", "title": "Emergent Communication through Negotiation", "decision": "Accept (Poster)", "meta_review": "All reviewers agree the paper proposes an interesting setup and the main finding that \"prosocial agents are able to learn to ground symbols using RL, but self-interested agents are not\" progresses work in this area. R3 asked a number of detail-oriented questions and while they did not update their review based on the author response, I am satisfied by the answers. ", "reviews": [{"review_id": "Hk6WhagRW-0", "review_text": "The authors describe a variant of the negotiation game in which agents of different type, selfish or prosocial, and with different preferences. The central feature is the consideration of a secondary communication (linguistic) channel for the purpose of cheap talk, i.e. talk whose semantics are not laid out a priori. The essential findings include that prosociality is a prerequisite for effective communication (i.e. formation of meaningful communication on the linguistic channel), and furthermore, that the secondary channel helps improve the negotiation outcomes. The paper is well-structured and incrementally introduces the added features and includes staged evaluations for the individual additions, starting with the differentiation of agent characteristics, explored with combination of linguistic and proposal channel. Finally, agent societies are represented by injecting individuals' ID into the input representation. The positive: - The authors attack the challenging task of given agents a means to develop communication patterns without apriori knowledge. - The paper presents the problem in a well-structured manner and sufficient clarity to retrace the essential contribution (minor points for improvement). - The quality of the text is very high and error-free. - The background and results are well-contextualised with relevant related work. The problematic: - By the very nature of the employed learning mechanisms, the provided solution provides little insight into what the emerging communication is really about. In my view, the lack of interpretable semantics hardly warrants a reference to 'cheap talk'. As such the expectations set by the well-developed introduction and background sections are moderated over the course of the paper. - The goal of providing agents with richer communicative ability without providing prior grounding is challenging, since agents need to learn about communication partners at runtime. But it appears as of the main contribution of the paper can be reduced to the decomposition of the learnable feature space into two communication channels. The implicit relationship of linguistic channel on proposal channel input based on the time information (Page 4, top) provides agents with extended inputs, thus enabling a more nuanced learning based on the relationship of proposal and linguistic channel. As such the well-defined semantics of the proposal channel effectively act as the grounding for the linguistic channel. This, then, could have been equally achieved by providing agents with a richer input structure mediated by a single channel. From this perspective, the solution offers limited surprises. The improvement of accuracy in the context of agent societies based on provided ID follows the same pattern of extending the input features. - One of the motivating factors of using cheap talk is the exploitation of lying on the part of the agents. However, apart from this initial statement, this feature is not explicitly picked up. In combination with the previous point, the necessity/value of the additional communication channel is unclear. Concrete suggestions for improvement: - Providing exemplified communication traces would help the reader appreciate the complexity of the problem addressed by the paper. - Figure 3 is really hard to read/interpret. The same applies to Figure 4 (although less critical in this case). - Input parameters could have been made explicit in order to facilitate a more comprehensive understanding of technicalities (e.g. in appendix). - Emergent communication is effectively unidirectional, with one agent as listener. Have you observed other outcomes in your evaluation? In summary, the paper presents an interesting approach to combine unsupervised learning with multiple communication channels to improve learning of preferences in a well-established negotiation game. The problem is addressed systematically and well-presented, but can leave the reader with the impression that the secondary channel, apart from decomposing the model, does not provide conceptual benefit over introducing a richer feature space that can be exploited by the learning mechanisms. Combined with the lack of specific cheap talk features, the use of actual cheap talk is rather abstract. Those aspects warrant justification.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to emphasize that the linguistic/utterance channel and the proposal channel are completely separate , and there is no a priori link in the messages in the proposal channel and the messages in the linguistic channel . When the agents are forced to use the linguistic channel exclusively , they must learn from scratch how to use the linguistic channel to communicate effectively to solve the negotiation task and thus the proposal channel is never communicated to the opponent . In short , LINGUISTIC refers to negotiating using ONLY the linguistic channel , PROPOSAL only the preference and BOTH using the combination . > By the very nature of the employed learning mechanisms , the provided solution provides little insight into what the emerging communication is really about . It is difficult to quantify precisely what communication is about , especially in our bottom-up approach starting from arbitrary symbols . Despite this , in our post-processing analyses of the communication analyses , we show : ( i ) agents partition themselves into speaker and listener , ( ii ) elements of natural language are found in the protocols that emerged , and ( iii ) the content of the messages indicate that the agents are encoding their utilities in the language channel . > In my view , the lack of interpretable semantics hardly warrants a reference to 'cheap talk ' . As such the expectations set by the well-developed introduction and background sections are moderated over the course of the paper . We did not intend to suggest that the lack of interpretable semantics warrants a reference to cheap talk . We refer to cheap talk due to the fact that the exchanges in the linguistic channel have no effect on the resulting payoff , which follows directly from the definition . The lack of interpretable semantics is orthogonal to any references to cheap talk : it simply motivates the research question of whether communication can emerge among learning agents . We will clarify this . > Providing exemplified communication traces would help the reader appreciate the complexity of the problem addressed by the paper . In our most recent revision , we have added an appendix showing what sample games with each of the communication channels open look like . > Figure 3 is really hard to read/interpret . The same applies to Figure 4 ( although less critical in this case ) . We have made the figures larger , and added more explanation in the text . > Input parameters could have been made explicit in order to facilitate a more comprehensive understanding of technicalities ( e.g.in appendix ) . We have added an appendix showing the values of the hyperparameters we used . We would also like to thank the public comments that acted as additional motivation to help reproducibility . > Emergent communication is effectively unidirectional , with one agent as listener . Have you observed other outcomes in your evaluation ? In our experiments , we consistently see the agents separating into speaker-listener roles , as mentioned in the paper ."}, {"review_id": "Hk6WhagRW-1", "review_text": "This paper explores how agents can learn to communicate to solve a negotiation task. They explore several settings: grounded vs. ungrounded communication, and self-interested vs. prosocial agents. The main findings are that prosocial agents are able to learn to ground symbols using RL, but self-interested agents are not. The work is interesting and clearly described, and I think this is an interesting setting for studying emergent communication. My only major comment is that I\u2019m a bit skeptical about the claim that \u201cself-interested agents cannot ground cheap talk to exchange meaningful information\u201d. Given that the agents\u2019 rewards would be improved if they were able to make agreements, and humans can use \u2018cheap talk\u2019 to negotiate, surely the inability to do so here shows a failure of the learning algorithm (rather than a general property of self-interested agents)? I am also concerned about the dangers posed by robots inventing their own language, perhap the authors should shut this down :-) ", "rating": "7: Good paper, accept", "reply_text": "> My only major comment is that I \u2019 m a bit skeptical about the claim that \u201c self-interested agents can not ground cheap talk to exchange meaningful information \u201d . Given that the agents \u2019 rewards would be improved if they were able to make agreements , and humans can use \u2018 cheap talk \u2019 to negotiate , surely the inability to do so here shows a failure of the learning algorithm ( rather than a general property of self-interested agents ) ? We agree ; we believe this is the the main reason that the bottom-up approach is particularly challenging . Humans ( and to a lesser extent , the demonstration data in top-down approaches ) benefit by having a priori semantics on the symbols in the linguistic channel . We used the term \u2018 self-interested agents \u2019 mainly to separate them from the prosocial ones , but we do indeed mean in the context of the standard RL learning algorithms used in the paper , not more generally to mean \u2018 any possible self-interested agent \u2019 . We will clarify this . In future work , we will explore more sophisticated RL learning techniques that allow self-interested to negotiate using a \u2018 cheap-talk \u2019 channel ( which due to its unbinding and unverifiable nature poses a challenge for the current RL algorithms ) ."}, {"review_id": "Hk6WhagRW-2", "review_text": "The experimental setup is clear, although the length of the utterances and the number of symbols in them is not explicitly stated in the text (only the diagrams). Experiment 1 confirms that agents who seek only to maximise their own rewards fail to coordinate over a non-binding communication channel. The exposition of the experiments, however, is unclear. In Fig 1, it is not clear what Agent 1 and Agent 2 are. Do they correspond to arbitrary labels or the turns that the agent takes in the game? Why is Agent 1 the one who triumphs in the no-communication channel game? Is there any advantage to going first generally? Where are the tests of robustness on the curves demonstrated in Figure 2a? Has figure 2b been cherry picked? This should be demonstrated over many different negotiations with error bars. In the discussion of the agents being unable to ground cheap talk, the symbolic nature of the linguistic channel clouds the fact that it is not the symbolic, ungrounded aspect but the non-binding nature of communication on this channel. This would be more clearly demonstrated and parsimonious by using a non-binding version of the proposal channel and saving the linguistic discussion for later. Experiment 2 shows that by making the agents prosocial, they are able to learn to communicate on the linguistic channel to achieve pretty much optimal rewards, a very nice result. The agents are not able to reach the same levels of cooperation on the proposal channel, in fact performing worse than the no-communication baseline. Protocols could be designed that would allow the agents to communicate their utilities over this channel (within 4 turns), so the fact they don't suggests it is the learning procedure that is not able to find this optimum. Presenting this as a result about the superiority of communication over the linguistic channel is not well supported. Why do they do worse with random termination than 10 turns in the proposal channel? 4 proposals should contain enough information to determine the utilities. Why are the 10 turn games even included in this table? It seems that this was dismissed in the environment setup section, due to the first mover advantage. Why do no-communication baselines change so much between random termination and 10 turns in the prosocial case? Why do self-interested agents for 10 turns on the linguistic channel terminate early? Table 1 might be better represented using the median and quartiles, since the data is skewed. Analysis of the communication, i.e. what is actually sent, is interesting and the division into speaker and listener suggests that this is a simple protocol that is easy for agents to learn. Experiment 3 aims to determine whether an agent is able to negotiate against a community of other agents with mixed levels of prosociality. It is shown that if the fixed agent is able to identify who they are playing against they can do better than not knowing, in the case where the fixed agent is self interested. The pca plot of agent id embeddings related is good. Both Figure 4 and Table 3 use Agent 1 and Agent 2 rather than Agent A and Agent B and is not clear whether this is a mistake or Agent 1 is different from Agent A. The no-communication baseline is referred to in the text but the results are not shown in the table. There are no estimates of the uncertainty of the results in table 3, how robust are these results to different initial conditions? This section seems like a bit of an add-on to address criticisms that might arise about the initial experiment being only two agents. Overall, the paper has some nice results and an interesting ideas but could do with some tightening up of the results to make it really good. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "> In Fig 1 , it is not clear what Agent 1 and Agent 2 are . Do they correspond to arbitrary labels or the turns that the agent takes in the game ? We have clarified that Agent 1 is the agent who consistently goes first in negotiation . > Why is Agent 1 the one who triumphs in the no-communication channel game ? Is there any advantage to going first generally ? Actually , Agent 2 typically triumphs in the no-communication setup . We do not believe there is any significant advantages to either going first or second , as demonstrated by the fact that self-interested agents seem to be able to negotiate fairly in this environment . > Where are the tests of robustness on the curves demonstrated in Figure 2a ? We have re-run the experiments with 20 different random seeds , and have updated Figure 2a to show their averaged results . The uncertainty estimates are unfortunately only visible in the linguistic communication setup , as the other communication protocols seem to give rise to very stable training . > Has figure 2b been cherry picked ? This should be demonstrated over many different negotiations with error bars . Figure 2b shows the average reward per turn over 1000 different negotiations . We present results from training 20 seeds ( 1280 test negotiations per seed ) . We have added interquartile ranges at every timestep , and clarified that they are averaged results in the text . > Protocols could be designed that would allow the agents to communicate their utilities over this channel ( within 4 turns ) , so the fact they do n't suggests it is the learning procedure that is not able to find this optimum . We agree.However , discovering the optimal protocol through self-play RL is a significantly harder problem than designing one with knowledge of the optimal structure . For example , the pre-grounded nature of the proposal channel , combined with its lower information bandwidth , means that random exploration is less likely to find the optimal communication protocol . > Why are the 10 turn games even included in this table ? It seems that this was dismissed in the environment setup section , due to the first mover advantage . We include the 10 turn results so that we can include the key self-interested and prosocial results in the same table . We also wanted to demonstrate how strong the first mover advantage was . We have moved these results to the appendix however in the new draft . We have also changed both tables to return mean and interquartile range as suggested . > Why do self-interested agents for 10 turns on the linguistic channel terminate early ? We believe that when enough information is exchanged , the agents make effective proposals and thus do not need to negotiate further . > Both Figure 4 and Table 3 use Agent 1 and Agent 2 rather than Agent A and Agent B and is not clear whether this is a mistake or Agent 1 is different from Agent A . We have corrected this . > The no-communication baseline is referred to in the text but the results are not shown in the table . We have added the no-communication baseline figure to the text . > There are no estimates of the uncertainty of the results in table 3 , how robust are these results to different initial conditions ? These results are averaged across 10 batches of 128 games in each batch . We have clarified this , and added standard deviations to the table ."}], "0": {"review_id": "Hk6WhagRW-0", "review_text": "The authors describe a variant of the negotiation game in which agents of different type, selfish or prosocial, and with different preferences. The central feature is the consideration of a secondary communication (linguistic) channel for the purpose of cheap talk, i.e. talk whose semantics are not laid out a priori. The essential findings include that prosociality is a prerequisite for effective communication (i.e. formation of meaningful communication on the linguistic channel), and furthermore, that the secondary channel helps improve the negotiation outcomes. The paper is well-structured and incrementally introduces the added features and includes staged evaluations for the individual additions, starting with the differentiation of agent characteristics, explored with combination of linguistic and proposal channel. Finally, agent societies are represented by injecting individuals' ID into the input representation. The positive: - The authors attack the challenging task of given agents a means to develop communication patterns without apriori knowledge. - The paper presents the problem in a well-structured manner and sufficient clarity to retrace the essential contribution (minor points for improvement). - The quality of the text is very high and error-free. - The background and results are well-contextualised with relevant related work. The problematic: - By the very nature of the employed learning mechanisms, the provided solution provides little insight into what the emerging communication is really about. In my view, the lack of interpretable semantics hardly warrants a reference to 'cheap talk'. As such the expectations set by the well-developed introduction and background sections are moderated over the course of the paper. - The goal of providing agents with richer communicative ability without providing prior grounding is challenging, since agents need to learn about communication partners at runtime. But it appears as of the main contribution of the paper can be reduced to the decomposition of the learnable feature space into two communication channels. The implicit relationship of linguistic channel on proposal channel input based on the time information (Page 4, top) provides agents with extended inputs, thus enabling a more nuanced learning based on the relationship of proposal and linguistic channel. As such the well-defined semantics of the proposal channel effectively act as the grounding for the linguistic channel. This, then, could have been equally achieved by providing agents with a richer input structure mediated by a single channel. From this perspective, the solution offers limited surprises. The improvement of accuracy in the context of agent societies based on provided ID follows the same pattern of extending the input features. - One of the motivating factors of using cheap talk is the exploitation of lying on the part of the agents. However, apart from this initial statement, this feature is not explicitly picked up. In combination with the previous point, the necessity/value of the additional communication channel is unclear. Concrete suggestions for improvement: - Providing exemplified communication traces would help the reader appreciate the complexity of the problem addressed by the paper. - Figure 3 is really hard to read/interpret. The same applies to Figure 4 (although less critical in this case). - Input parameters could have been made explicit in order to facilitate a more comprehensive understanding of technicalities (e.g. in appendix). - Emergent communication is effectively unidirectional, with one agent as listener. Have you observed other outcomes in your evaluation? In summary, the paper presents an interesting approach to combine unsupervised learning with multiple communication channels to improve learning of preferences in a well-established negotiation game. The problem is addressed systematically and well-presented, but can leave the reader with the impression that the secondary channel, apart from decomposing the model, does not provide conceptual benefit over introducing a richer feature space that can be exploited by the learning mechanisms. Combined with the lack of specific cheap talk features, the use of actual cheap talk is rather abstract. Those aspects warrant justification.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to emphasize that the linguistic/utterance channel and the proposal channel are completely separate , and there is no a priori link in the messages in the proposal channel and the messages in the linguistic channel . When the agents are forced to use the linguistic channel exclusively , they must learn from scratch how to use the linguistic channel to communicate effectively to solve the negotiation task and thus the proposal channel is never communicated to the opponent . In short , LINGUISTIC refers to negotiating using ONLY the linguistic channel , PROPOSAL only the preference and BOTH using the combination . > By the very nature of the employed learning mechanisms , the provided solution provides little insight into what the emerging communication is really about . It is difficult to quantify precisely what communication is about , especially in our bottom-up approach starting from arbitrary symbols . Despite this , in our post-processing analyses of the communication analyses , we show : ( i ) agents partition themselves into speaker and listener , ( ii ) elements of natural language are found in the protocols that emerged , and ( iii ) the content of the messages indicate that the agents are encoding their utilities in the language channel . > In my view , the lack of interpretable semantics hardly warrants a reference to 'cheap talk ' . As such the expectations set by the well-developed introduction and background sections are moderated over the course of the paper . We did not intend to suggest that the lack of interpretable semantics warrants a reference to cheap talk . We refer to cheap talk due to the fact that the exchanges in the linguistic channel have no effect on the resulting payoff , which follows directly from the definition . The lack of interpretable semantics is orthogonal to any references to cheap talk : it simply motivates the research question of whether communication can emerge among learning agents . We will clarify this . > Providing exemplified communication traces would help the reader appreciate the complexity of the problem addressed by the paper . In our most recent revision , we have added an appendix showing what sample games with each of the communication channels open look like . > Figure 3 is really hard to read/interpret . The same applies to Figure 4 ( although less critical in this case ) . We have made the figures larger , and added more explanation in the text . > Input parameters could have been made explicit in order to facilitate a more comprehensive understanding of technicalities ( e.g.in appendix ) . We have added an appendix showing the values of the hyperparameters we used . We would also like to thank the public comments that acted as additional motivation to help reproducibility . > Emergent communication is effectively unidirectional , with one agent as listener . Have you observed other outcomes in your evaluation ? In our experiments , we consistently see the agents separating into speaker-listener roles , as mentioned in the paper ."}, "1": {"review_id": "Hk6WhagRW-1", "review_text": "This paper explores how agents can learn to communicate to solve a negotiation task. They explore several settings: grounded vs. ungrounded communication, and self-interested vs. prosocial agents. The main findings are that prosocial agents are able to learn to ground symbols using RL, but self-interested agents are not. The work is interesting and clearly described, and I think this is an interesting setting for studying emergent communication. My only major comment is that I\u2019m a bit skeptical about the claim that \u201cself-interested agents cannot ground cheap talk to exchange meaningful information\u201d. Given that the agents\u2019 rewards would be improved if they were able to make agreements, and humans can use \u2018cheap talk\u2019 to negotiate, surely the inability to do so here shows a failure of the learning algorithm (rather than a general property of self-interested agents)? I am also concerned about the dangers posed by robots inventing their own language, perhap the authors should shut this down :-) ", "rating": "7: Good paper, accept", "reply_text": "> My only major comment is that I \u2019 m a bit skeptical about the claim that \u201c self-interested agents can not ground cheap talk to exchange meaningful information \u201d . Given that the agents \u2019 rewards would be improved if they were able to make agreements , and humans can use \u2018 cheap talk \u2019 to negotiate , surely the inability to do so here shows a failure of the learning algorithm ( rather than a general property of self-interested agents ) ? We agree ; we believe this is the the main reason that the bottom-up approach is particularly challenging . Humans ( and to a lesser extent , the demonstration data in top-down approaches ) benefit by having a priori semantics on the symbols in the linguistic channel . We used the term \u2018 self-interested agents \u2019 mainly to separate them from the prosocial ones , but we do indeed mean in the context of the standard RL learning algorithms used in the paper , not more generally to mean \u2018 any possible self-interested agent \u2019 . We will clarify this . In future work , we will explore more sophisticated RL learning techniques that allow self-interested to negotiate using a \u2018 cheap-talk \u2019 channel ( which due to its unbinding and unverifiable nature poses a challenge for the current RL algorithms ) ."}, "2": {"review_id": "Hk6WhagRW-2", "review_text": "The experimental setup is clear, although the length of the utterances and the number of symbols in them is not explicitly stated in the text (only the diagrams). Experiment 1 confirms that agents who seek only to maximise their own rewards fail to coordinate over a non-binding communication channel. The exposition of the experiments, however, is unclear. In Fig 1, it is not clear what Agent 1 and Agent 2 are. Do they correspond to arbitrary labels or the turns that the agent takes in the game? Why is Agent 1 the one who triumphs in the no-communication channel game? Is there any advantage to going first generally? Where are the tests of robustness on the curves demonstrated in Figure 2a? Has figure 2b been cherry picked? This should be demonstrated over many different negotiations with error bars. In the discussion of the agents being unable to ground cheap talk, the symbolic nature of the linguistic channel clouds the fact that it is not the symbolic, ungrounded aspect but the non-binding nature of communication on this channel. This would be more clearly demonstrated and parsimonious by using a non-binding version of the proposal channel and saving the linguistic discussion for later. Experiment 2 shows that by making the agents prosocial, they are able to learn to communicate on the linguistic channel to achieve pretty much optimal rewards, a very nice result. The agents are not able to reach the same levels of cooperation on the proposal channel, in fact performing worse than the no-communication baseline. Protocols could be designed that would allow the agents to communicate their utilities over this channel (within 4 turns), so the fact they don't suggests it is the learning procedure that is not able to find this optimum. Presenting this as a result about the superiority of communication over the linguistic channel is not well supported. Why do they do worse with random termination than 10 turns in the proposal channel? 4 proposals should contain enough information to determine the utilities. Why are the 10 turn games even included in this table? It seems that this was dismissed in the environment setup section, due to the first mover advantage. Why do no-communication baselines change so much between random termination and 10 turns in the prosocial case? Why do self-interested agents for 10 turns on the linguistic channel terminate early? Table 1 might be better represented using the median and quartiles, since the data is skewed. Analysis of the communication, i.e. what is actually sent, is interesting and the division into speaker and listener suggests that this is a simple protocol that is easy for agents to learn. Experiment 3 aims to determine whether an agent is able to negotiate against a community of other agents with mixed levels of prosociality. It is shown that if the fixed agent is able to identify who they are playing against they can do better than not knowing, in the case where the fixed agent is self interested. The pca plot of agent id embeddings related is good. Both Figure 4 and Table 3 use Agent 1 and Agent 2 rather than Agent A and Agent B and is not clear whether this is a mistake or Agent 1 is different from Agent A. The no-communication baseline is referred to in the text but the results are not shown in the table. There are no estimates of the uncertainty of the results in table 3, how robust are these results to different initial conditions? This section seems like a bit of an add-on to address criticisms that might arise about the initial experiment being only two agents. Overall, the paper has some nice results and an interesting ideas but could do with some tightening up of the results to make it really good. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "> In Fig 1 , it is not clear what Agent 1 and Agent 2 are . Do they correspond to arbitrary labels or the turns that the agent takes in the game ? We have clarified that Agent 1 is the agent who consistently goes first in negotiation . > Why is Agent 1 the one who triumphs in the no-communication channel game ? Is there any advantage to going first generally ? Actually , Agent 2 typically triumphs in the no-communication setup . We do not believe there is any significant advantages to either going first or second , as demonstrated by the fact that self-interested agents seem to be able to negotiate fairly in this environment . > Where are the tests of robustness on the curves demonstrated in Figure 2a ? We have re-run the experiments with 20 different random seeds , and have updated Figure 2a to show their averaged results . The uncertainty estimates are unfortunately only visible in the linguistic communication setup , as the other communication protocols seem to give rise to very stable training . > Has figure 2b been cherry picked ? This should be demonstrated over many different negotiations with error bars . Figure 2b shows the average reward per turn over 1000 different negotiations . We present results from training 20 seeds ( 1280 test negotiations per seed ) . We have added interquartile ranges at every timestep , and clarified that they are averaged results in the text . > Protocols could be designed that would allow the agents to communicate their utilities over this channel ( within 4 turns ) , so the fact they do n't suggests it is the learning procedure that is not able to find this optimum . We agree.However , discovering the optimal protocol through self-play RL is a significantly harder problem than designing one with knowledge of the optimal structure . For example , the pre-grounded nature of the proposal channel , combined with its lower information bandwidth , means that random exploration is less likely to find the optimal communication protocol . > Why are the 10 turn games even included in this table ? It seems that this was dismissed in the environment setup section , due to the first mover advantage . We include the 10 turn results so that we can include the key self-interested and prosocial results in the same table . We also wanted to demonstrate how strong the first mover advantage was . We have moved these results to the appendix however in the new draft . We have also changed both tables to return mean and interquartile range as suggested . > Why do self-interested agents for 10 turns on the linguistic channel terminate early ? We believe that when enough information is exchanged , the agents make effective proposals and thus do not need to negotiate further . > Both Figure 4 and Table 3 use Agent 1 and Agent 2 rather than Agent A and Agent B and is not clear whether this is a mistake or Agent 1 is different from Agent A . We have corrected this . > The no-communication baseline is referred to in the text but the results are not shown in the table . We have added the no-communication baseline figure to the text . > There are no estimates of the uncertainty of the results in table 3 , how robust are these results to different initial conditions ? These results are averaged across 10 batches of 128 games in each batch . We have clarified this , and added standard deviations to the table ."}}