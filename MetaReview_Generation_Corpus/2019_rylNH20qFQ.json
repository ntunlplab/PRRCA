{"year": "2019", "forum": "rylNH20qFQ", "title": "Learning to Infer and Execute 3D Shape Programs", "decision": "Accept (Poster)", "meta_review": "This paper presents a method whereby a model learns to describe 3D shapes as programs which generate said shapes. Beyond introducing some new techniques in neural program synthesis through the use of loops, this method also produces disentangled representations of the shapes by deconstructing them into the program that produced them, thereby introducing an interesting and useful level of abstraction that could be exploited by models, agents, and other learning algorithms.\n\nDespite some slightly aggressive anonymous comments by a third party, the reviewers agree that this paper is solid and publishable, and I have no qualms in recommending it from inclusion in the proceedings.", "reviews": [{"review_id": "rylNH20qFQ-0", "review_text": "This paper presents an approach to infer shape programs given 3D models. The programs include placing and arranging predefined primitives in layouts and can be written as a program over a domain-specific language (DSL). The architecture consists of a recurrent network that encodes a 3D shape represented as a voxel grid and outputs the instructions using a LSTM decoder. The generation is two-step where the first step predicts a program ID and the second step predicts instructions within the program ID. This aspect wasn't completely clear to me, see questions below. A second module that renders the program to 3D is also implemented as a neural network in order to optimize the model parameter in a end-to-end manner by minimizing a reconstruction loss. The method is evaluated on 3D shape reconstruction tasks for chairs and tables categories of the ShapeNet dataset. The approach compares favorably to Tulsiani et al., which considers a shape to be composed of a fixed number of cuboids. The paper is well written and investigates an important problem. But it is hard to tease of the contributions and the relative importance of various steps in the paper: 1. Structure search vs. prediction. How does the model perform relative to a search-based approach for program generation. That would be slower but perhaps more accurate. The prediction model can be thought of an amortized inference procedure for search problems. What advantages does the approach offer? 2. Choice of the DSL. Compared to CSG modeling instructions of Sharma et al. the proposed DSL is more targeted to the shape categories. While this restricts the space of programs (e.g., no intersection, subtraction operations are used) leading to better generation of chairs and tables, it also limits the range and generalization of the learned models to new categories. Some discussion and comparison with the choice of DSL would be useful. 3. Is the neural render necessary -- Wouldn't it be easier to simply use automatic differentiation to compute gradients of the rendering engine? 4. It is also not clear to me how having a differentiable renderer allows training in an end-to-end manner since the output space is discrete and variable length. In CSGNet (Sharma et al.) policy-gradient techniques were used to optimize the LSTM parameters. The details of the guided adaptation were unclear to me (Section 4.3). 5. Is the neural renderer reliable -- Is is not clear if the neural renderer can provide accurate gradients when the generated programs are incorrect since the model is trained on a clean samples. In practice this means that the encoder has to initialized well. Since the renderer is also learned, would it generalize to new programs within the same DSL but different distribution over primitives -- e.g., a set of tables that have many more legs. Some visualizations of the generated shapes from execution traces could be added, sampling programs from within and outside the program distributions used to train. 6. All the above points give an impression that the choice of DSL and careful initialization are important to get the model to work. Some discussion on how robust the model is to these choices would be useful. In other words how meaningful is the generalization from the supervised training set of templates chairs and tables? 7. Missing baselines: The model is trained on 100,000 chairs and tables with full supervision. What is the performance of a nearest neighbor prediction algorithm? This is an important baseline that is missing. A comparison with a simplified CSGNet with shape primitives and union operations is also important. Tulsiani et al. consider unions but constrain that all instances have the same number of primitives which can lead to poor reconstruction results. Furthermore the training sets are likely different making evaluations unclear. I suggest training the following decoders on the same training set used in this approach (1) fixed set of cuboids (e.g., Tulsiani et al.), (2) A recurrent decoder with cuboids, (3) CSGNet (different primitives and operations), (4) a nearest neighbor predictor with the Hamming or Chamfer distance metric. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "4.Data-efficiency , initialization , and robustness Our model is data-efficient . It \u2019 s trained on 100K chairs and tables , but without supervision . The only supervision it requires is the small number of shape templates , which are used for initializing the program generator . We agree with the reviewer that such initialization is essential : we observe that without bootstrapping the model can not converge to a meaningful point . They however can be very simple : e.g. , 10 simple table templates ( Fig.A1 ) are sufficient to initialize the model , which later achieves good performance under execution-guided adaptation . Our model is also robust : it works well after pre-training on these 10 simple templates , with and without the semantic meaning of DSL . It also generalizes to shapes from unseen categories , as shown in Sec 5.4 . We have also listed all other planned changes in our general response above . Please don \u2019 t hesitate to let us know for any additional comments on the paper or on the planned changes ."}, {"review_id": "rylNH20qFQ-1", "review_text": "This paper introduces a high-level semantic description for 3D shapes. The description is given by the so-called ShapeProgram, Each shape program consists of several program statements. A program statement can be either Draw, which describes a shape primitive as well as its geometric and semantic attributes, or For, which contains a sub-program and parameters specifying how the sub-program should be repeatedly executed. The ShapeProgram is connected with an input through two networks, the program generator (encoder) and a neural program executor (decoder). Both encoder/decoder are implemented using LSTM. The key ML contribution is on the decoder, which leverages a parametrization to make the decoder differentiable. The major advantage of the proposed technique is that it does not need to specify the ShapeProgram in advance. In the same spriit of training an auto-encoder. It can be learned in a semi-supervised manner. However, in practice, one has to start with a reasonably good initial program. In the paper, this initial program was learned from synthetic data. The paper presents many experimental results, including evaluation on synthetic datasets, guided adaptation on ShapeNet, analysis of stability, connectivity measurement, and generalization, and application in shape completion. The presented evaluations, from the perspective of proposed experiments, is satisfactory. On the downside, this paper does not present any baseline evaluation, party due to the fact that the proposed problem is new. In fact, existing inverse procedural modeling techniques require the users to specify the program. However, the proposed approach could be even more convincing if it evaluates the performance of semantic understanding. For example, would it be possible to evaluate the performance on shape segmentation? Additional comments: 1. How important is the initial program? 2. The interactions among shape parts usually form a graph, not necessarily hierarchical. This should be discussed. 3. What is the difference between 3D shapes and 3D scenes? Does this approach require a front/up-right orientation? 4. It would be interesting to visualize/analyze the intermediate representations of the neural shape generator. Does it encode meaningful distributions among shape parts? Overall, it is a good paper, and I would like to see it at ICLR 2019. ", "rating": "7: Good paper, accept", "reply_text": "Thank you very much for the constructive comments . 1.Baselines We agree that it \u2019 s important to add more baselines . In the revision , we will include comparisons with the following three algorithms : 1 ) Nearest neighbors . For a given test shape , we search its nearest neighbor in the training set . 2 ) CSGNet-original ( the original model released by the authors of CSGNet ) 3 ) CSGNet-augmented ( the augmented CSGNet model trained on our dataset with additional shape primitives we introduced ) . Evaluating on shape segmentation is definitely an interesting direction . We \u2019 ve started working on it . As data processing takes additional time , we \u2019 ll either include the results into the revision by Nov 23 or , if it \u2019 s not done by then , into a later revision . 2.Specific Questions ( 1 ) Initial programs The initial synthetic programs provide supervised bootstrapping to initialize the program synthesis network . These programs are essential : we observe that without bootstrapping the model can not converge to a meaningful point . They , however , can be very simple : e.g. , 10 simple table templates ( Fig.A1 ) are sufficient to initialize the model , which later achieves good performance under execution-guided adaptation . ( 2 ) Interaction Thanks ! We agree that the graphs are a more general representation for object parts and can be important next steps . We \u2019 ll include this into discussion as suggested . ( 3 ) Shapes vs scenes Compared with scenes , 3D shapes more frequently have program-like regularities , such as repetition and symmetry . An interesting future direction is to explore how programs can be used to explain scenes . Our current model requires a front and up-right orientation . ( 4 ) Visualization As suggested , we will manipulate the representation after the LSTM to see how different dimensions affect the generated shape primitives . We have also listed all other planned changes in our general response above . Please don \u2019 t hesitate to let us know for any additional comments on the paper or on the planned changes ."}, {"review_id": "rylNH20qFQ-2", "review_text": "This paper presents a methodology to infer shape programs that can describe 3D objects. The key intuition of the shape programs is to integrate bottom-up low-level feature recognition with symbolic high-level program structure, which allows the shape programs to capture both high-level structure and the low-level geometry of the shapes. The paper proposes a domain-specific language for 3D shapes that consists of \u201cFor\u201d loops for capturing high-level regularity, and associates objects with both their geometric and semantic attributes. It then proposes an end-to-end differentiable architecture to learn such 3D programs from shapes using an interesting self-supervised mechanism. The neural program generator proposes a program in the DSL that is executed by a neural program execution module to render the corresponding output shape, which is then compared with the original shape and the difference loss is back-propagated to improve the program distribution. The technique is evaluated on both synthetic and ShapeNet tasks, and leads to significant improvements compared to Tulsiani et al. that embed a prior structure on learning shape representations as a composition of primitive abstractions. In addition, the technique is also paired with MarrNet to allow for a better 3D reconstruction from 2D images. Overall, this paper presents an elegant idea to describe 3D shapes as a DSL program that captures both geometric and spatial abstractions, and at the same time captures regularities using loops. CSGNet [Sharma et al. 2018] also uses programs to describe 2D and 3D shapes, but the DSL used here is richer as it captures more high-level regularities using loops and also semantic relationships such as top, support etc. The idea of training a neural program executor and using it for self-supervised training is quite elegant. I also liked the idea of guided adaption to make the program generator generalize beyond the synthetic template programs. Finally, the results show impressive improvements and generalization capability of the model. Can the authors comment on some notion of completeness of the proposed DSL? In other words, is this the only set of operators, shapes, and semantics needed to represent all of ShapeNet objects? Also, it might be interesting to comment more on how this particular DSL was derived. Some of the semantics operator such as \u201cSupport\u201d, \u201cLocker\u201d, etc. look overly specific to chair and tables. Is there a way to possibly learn such abstractions automatically? What is the total search space of programs in this DSL? How would a naive random search perform in this synthesis task? I also particularly liked the decomposition of programs into draw and compound statements, and the corresponding program generator decomposition into 2 steps BlockLSTM and StepLSTM. At inference time, does the model use some form of beam search to sample block programs or are the results corresponding to top-1 prediction? Would it be possible to compare the results to the technique presented in CSGNet [Sharma et al. 2018]? There are some key differences in terms of using lower-level DSL primitives and using REINFORCE for training the program generator, but it would be good to measure how well having higher-level primitives improve the results. I presume the neural program executor module was trained using a manually-written shape program interpreter. How difficult is it to write such an interpreter? Also, how easy/difficult is to extend the DSL with new semantics operator and then write the corresponding interpreter extension? Minor typos: page 3: consists a variable \u2192 consists of a variable page 5: We executes \u2192 We execute page 6: synthetica dataset \u2192 synthetic dataset ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the very constructive comments . 1.DSL The current DSL is designed to represent furnitures . Representing all ShapeNet objects needs a richer set of primitives , e.g. , curved cylinders for mug handles . When we design such DSL , the main challenge is on semantics . For humans , some semantics are shared across different object categories , e.g. , \u201c top \u201d can be shared by tables and bed , while some are just category-specific , \u201c armrest \u201d is mainly for chairs . Following this spirit , we include both category-specific and shared semantics for the instantialization of furnitures . Learning a primitive library from data is a natural research direction , and we are working on it as follow-up . 2.Baselines We agree that it \u2019 s important to add more baselines . In the revision , we will include comparisons with the following three algorithms : 1 ) Nearest neighbors . For a given test shape , we search its nearest neighbor in the training set . 2 ) CSGNet-original ( the original model released by the authors of CSGNet ) 3 ) CSGNet-augmented ( the augmented CSGNet model trained on our dataset with additional shape primitives we introduced ) . Amortized inference is essential for our task due to its large search space . Our model takes 5 ms to infer a shape program with a Titan X GPU . There are two possible approaches for a structured search over the space of programs , both of which will be too slow for our task : 1 ) Constraint solving : we would have to use an SMT solver . Ellis et al [ 1 ] used SMT solvers to infer 2D graphics programs , and takes on the order of 5-20 minutes per program . As 3D shapes have a much larger search space , such an approach would not be able to find a solution in reasonable time . 2 ) Stochastic search : Here the problem would be at least as tough as doing inverse graphics , so we can safely assume that this would work no better than MCMC for inverse graphics . In Picture ( Kulkarni et al . [ 2 ] ) , their approach takes minutes for a 2D image with simple contours . We have contacted the authors of these two papers , who confirmed our estimates of the efficiency of their methods . [ 1 ] Ellis , Kevin , Armando Solar-Lezama , and Josh Tenenbaum . `` Unsupervised learning by program synthesis . '' NIPS 2015 . [ 2 ] Kulkarni , Tejas D. , et al . `` Picture : A probabilistic programming language for scene perception . '' CVPR 2015 . 3.Decomposition Thanks for the positive comment on the decomposition . The results just correspond to top-1 predictions . 4.Interpreter Our semantic operators correspond to simple geometric primitives . Therefore , it \u2019 s quite straightforward to write an interpreter for them . The programs in our DSL are tokenized vectors and can be directly feed into the neural program executor . Adding new semantic operator to the DSL is thus easy . We just need to re-train or finetune the current program executor with the new semantic operator included . We have also listed all other planned changes in our general response above . Please don \u2019 t hesitate to let us know for any additional comments on the paper or on the planned changes ."}], "0": {"review_id": "rylNH20qFQ-0", "review_text": "This paper presents an approach to infer shape programs given 3D models. The programs include placing and arranging predefined primitives in layouts and can be written as a program over a domain-specific language (DSL). The architecture consists of a recurrent network that encodes a 3D shape represented as a voxel grid and outputs the instructions using a LSTM decoder. The generation is two-step where the first step predicts a program ID and the second step predicts instructions within the program ID. This aspect wasn't completely clear to me, see questions below. A second module that renders the program to 3D is also implemented as a neural network in order to optimize the model parameter in a end-to-end manner by minimizing a reconstruction loss. The method is evaluated on 3D shape reconstruction tasks for chairs and tables categories of the ShapeNet dataset. The approach compares favorably to Tulsiani et al., which considers a shape to be composed of a fixed number of cuboids. The paper is well written and investigates an important problem. But it is hard to tease of the contributions and the relative importance of various steps in the paper: 1. Structure search vs. prediction. How does the model perform relative to a search-based approach for program generation. That would be slower but perhaps more accurate. The prediction model can be thought of an amortized inference procedure for search problems. What advantages does the approach offer? 2. Choice of the DSL. Compared to CSG modeling instructions of Sharma et al. the proposed DSL is more targeted to the shape categories. While this restricts the space of programs (e.g., no intersection, subtraction operations are used) leading to better generation of chairs and tables, it also limits the range and generalization of the learned models to new categories. Some discussion and comparison with the choice of DSL would be useful. 3. Is the neural render necessary -- Wouldn't it be easier to simply use automatic differentiation to compute gradients of the rendering engine? 4. It is also not clear to me how having a differentiable renderer allows training in an end-to-end manner since the output space is discrete and variable length. In CSGNet (Sharma et al.) policy-gradient techniques were used to optimize the LSTM parameters. The details of the guided adaptation were unclear to me (Section 4.3). 5. Is the neural renderer reliable -- Is is not clear if the neural renderer can provide accurate gradients when the generated programs are incorrect since the model is trained on a clean samples. In practice this means that the encoder has to initialized well. Since the renderer is also learned, would it generalize to new programs within the same DSL but different distribution over primitives -- e.g., a set of tables that have many more legs. Some visualizations of the generated shapes from execution traces could be added, sampling programs from within and outside the program distributions used to train. 6. All the above points give an impression that the choice of DSL and careful initialization are important to get the model to work. Some discussion on how robust the model is to these choices would be useful. In other words how meaningful is the generalization from the supervised training set of templates chairs and tables? 7. Missing baselines: The model is trained on 100,000 chairs and tables with full supervision. What is the performance of a nearest neighbor prediction algorithm? This is an important baseline that is missing. A comparison with a simplified CSGNet with shape primitives and union operations is also important. Tulsiani et al. consider unions but constrain that all instances have the same number of primitives which can lead to poor reconstruction results. Furthermore the training sets are likely different making evaluations unclear. I suggest training the following decoders on the same training set used in this approach (1) fixed set of cuboids (e.g., Tulsiani et al.), (2) A recurrent decoder with cuboids, (3) CSGNet (different primitives and operations), (4) a nearest neighbor predictor with the Hamming or Chamfer distance metric. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "4.Data-efficiency , initialization , and robustness Our model is data-efficient . It \u2019 s trained on 100K chairs and tables , but without supervision . The only supervision it requires is the small number of shape templates , which are used for initializing the program generator . We agree with the reviewer that such initialization is essential : we observe that without bootstrapping the model can not converge to a meaningful point . They however can be very simple : e.g. , 10 simple table templates ( Fig.A1 ) are sufficient to initialize the model , which later achieves good performance under execution-guided adaptation . Our model is also robust : it works well after pre-training on these 10 simple templates , with and without the semantic meaning of DSL . It also generalizes to shapes from unseen categories , as shown in Sec 5.4 . We have also listed all other planned changes in our general response above . Please don \u2019 t hesitate to let us know for any additional comments on the paper or on the planned changes ."}, "1": {"review_id": "rylNH20qFQ-1", "review_text": "This paper introduces a high-level semantic description for 3D shapes. The description is given by the so-called ShapeProgram, Each shape program consists of several program statements. A program statement can be either Draw, which describes a shape primitive as well as its geometric and semantic attributes, or For, which contains a sub-program and parameters specifying how the sub-program should be repeatedly executed. The ShapeProgram is connected with an input through two networks, the program generator (encoder) and a neural program executor (decoder). Both encoder/decoder are implemented using LSTM. The key ML contribution is on the decoder, which leverages a parametrization to make the decoder differentiable. The major advantage of the proposed technique is that it does not need to specify the ShapeProgram in advance. In the same spriit of training an auto-encoder. It can be learned in a semi-supervised manner. However, in practice, one has to start with a reasonably good initial program. In the paper, this initial program was learned from synthetic data. The paper presents many experimental results, including evaluation on synthetic datasets, guided adaptation on ShapeNet, analysis of stability, connectivity measurement, and generalization, and application in shape completion. The presented evaluations, from the perspective of proposed experiments, is satisfactory. On the downside, this paper does not present any baseline evaluation, party due to the fact that the proposed problem is new. In fact, existing inverse procedural modeling techniques require the users to specify the program. However, the proposed approach could be even more convincing if it evaluates the performance of semantic understanding. For example, would it be possible to evaluate the performance on shape segmentation? Additional comments: 1. How important is the initial program? 2. The interactions among shape parts usually form a graph, not necessarily hierarchical. This should be discussed. 3. What is the difference between 3D shapes and 3D scenes? Does this approach require a front/up-right orientation? 4. It would be interesting to visualize/analyze the intermediate representations of the neural shape generator. Does it encode meaningful distributions among shape parts? Overall, it is a good paper, and I would like to see it at ICLR 2019. ", "rating": "7: Good paper, accept", "reply_text": "Thank you very much for the constructive comments . 1.Baselines We agree that it \u2019 s important to add more baselines . In the revision , we will include comparisons with the following three algorithms : 1 ) Nearest neighbors . For a given test shape , we search its nearest neighbor in the training set . 2 ) CSGNet-original ( the original model released by the authors of CSGNet ) 3 ) CSGNet-augmented ( the augmented CSGNet model trained on our dataset with additional shape primitives we introduced ) . Evaluating on shape segmentation is definitely an interesting direction . We \u2019 ve started working on it . As data processing takes additional time , we \u2019 ll either include the results into the revision by Nov 23 or , if it \u2019 s not done by then , into a later revision . 2.Specific Questions ( 1 ) Initial programs The initial synthetic programs provide supervised bootstrapping to initialize the program synthesis network . These programs are essential : we observe that without bootstrapping the model can not converge to a meaningful point . They , however , can be very simple : e.g. , 10 simple table templates ( Fig.A1 ) are sufficient to initialize the model , which later achieves good performance under execution-guided adaptation . ( 2 ) Interaction Thanks ! We agree that the graphs are a more general representation for object parts and can be important next steps . We \u2019 ll include this into discussion as suggested . ( 3 ) Shapes vs scenes Compared with scenes , 3D shapes more frequently have program-like regularities , such as repetition and symmetry . An interesting future direction is to explore how programs can be used to explain scenes . Our current model requires a front and up-right orientation . ( 4 ) Visualization As suggested , we will manipulate the representation after the LSTM to see how different dimensions affect the generated shape primitives . We have also listed all other planned changes in our general response above . Please don \u2019 t hesitate to let us know for any additional comments on the paper or on the planned changes ."}, "2": {"review_id": "rylNH20qFQ-2", "review_text": "This paper presents a methodology to infer shape programs that can describe 3D objects. The key intuition of the shape programs is to integrate bottom-up low-level feature recognition with symbolic high-level program structure, which allows the shape programs to capture both high-level structure and the low-level geometry of the shapes. The paper proposes a domain-specific language for 3D shapes that consists of \u201cFor\u201d loops for capturing high-level regularity, and associates objects with both their geometric and semantic attributes. It then proposes an end-to-end differentiable architecture to learn such 3D programs from shapes using an interesting self-supervised mechanism. The neural program generator proposes a program in the DSL that is executed by a neural program execution module to render the corresponding output shape, which is then compared with the original shape and the difference loss is back-propagated to improve the program distribution. The technique is evaluated on both synthetic and ShapeNet tasks, and leads to significant improvements compared to Tulsiani et al. that embed a prior structure on learning shape representations as a composition of primitive abstractions. In addition, the technique is also paired with MarrNet to allow for a better 3D reconstruction from 2D images. Overall, this paper presents an elegant idea to describe 3D shapes as a DSL program that captures both geometric and spatial abstractions, and at the same time captures regularities using loops. CSGNet [Sharma et al. 2018] also uses programs to describe 2D and 3D shapes, but the DSL used here is richer as it captures more high-level regularities using loops and also semantic relationships such as top, support etc. The idea of training a neural program executor and using it for self-supervised training is quite elegant. I also liked the idea of guided adaption to make the program generator generalize beyond the synthetic template programs. Finally, the results show impressive improvements and generalization capability of the model. Can the authors comment on some notion of completeness of the proposed DSL? In other words, is this the only set of operators, shapes, and semantics needed to represent all of ShapeNet objects? Also, it might be interesting to comment more on how this particular DSL was derived. Some of the semantics operator such as \u201cSupport\u201d, \u201cLocker\u201d, etc. look overly specific to chair and tables. Is there a way to possibly learn such abstractions automatically? What is the total search space of programs in this DSL? How would a naive random search perform in this synthesis task? I also particularly liked the decomposition of programs into draw and compound statements, and the corresponding program generator decomposition into 2 steps BlockLSTM and StepLSTM. At inference time, does the model use some form of beam search to sample block programs or are the results corresponding to top-1 prediction? Would it be possible to compare the results to the technique presented in CSGNet [Sharma et al. 2018]? There are some key differences in terms of using lower-level DSL primitives and using REINFORCE for training the program generator, but it would be good to measure how well having higher-level primitives improve the results. I presume the neural program executor module was trained using a manually-written shape program interpreter. How difficult is it to write such an interpreter? Also, how easy/difficult is to extend the DSL with new semantics operator and then write the corresponding interpreter extension? Minor typos: page 3: consists a variable \u2192 consists of a variable page 5: We executes \u2192 We execute page 6: synthetica dataset \u2192 synthetic dataset ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the very constructive comments . 1.DSL The current DSL is designed to represent furnitures . Representing all ShapeNet objects needs a richer set of primitives , e.g. , curved cylinders for mug handles . When we design such DSL , the main challenge is on semantics . For humans , some semantics are shared across different object categories , e.g. , \u201c top \u201d can be shared by tables and bed , while some are just category-specific , \u201c armrest \u201d is mainly for chairs . Following this spirit , we include both category-specific and shared semantics for the instantialization of furnitures . Learning a primitive library from data is a natural research direction , and we are working on it as follow-up . 2.Baselines We agree that it \u2019 s important to add more baselines . In the revision , we will include comparisons with the following three algorithms : 1 ) Nearest neighbors . For a given test shape , we search its nearest neighbor in the training set . 2 ) CSGNet-original ( the original model released by the authors of CSGNet ) 3 ) CSGNet-augmented ( the augmented CSGNet model trained on our dataset with additional shape primitives we introduced ) . Amortized inference is essential for our task due to its large search space . Our model takes 5 ms to infer a shape program with a Titan X GPU . There are two possible approaches for a structured search over the space of programs , both of which will be too slow for our task : 1 ) Constraint solving : we would have to use an SMT solver . Ellis et al [ 1 ] used SMT solvers to infer 2D graphics programs , and takes on the order of 5-20 minutes per program . As 3D shapes have a much larger search space , such an approach would not be able to find a solution in reasonable time . 2 ) Stochastic search : Here the problem would be at least as tough as doing inverse graphics , so we can safely assume that this would work no better than MCMC for inverse graphics . In Picture ( Kulkarni et al . [ 2 ] ) , their approach takes minutes for a 2D image with simple contours . We have contacted the authors of these two papers , who confirmed our estimates of the efficiency of their methods . [ 1 ] Ellis , Kevin , Armando Solar-Lezama , and Josh Tenenbaum . `` Unsupervised learning by program synthesis . '' NIPS 2015 . [ 2 ] Kulkarni , Tejas D. , et al . `` Picture : A probabilistic programming language for scene perception . '' CVPR 2015 . 3.Decomposition Thanks for the positive comment on the decomposition . The results just correspond to top-1 predictions . 4.Interpreter Our semantic operators correspond to simple geometric primitives . Therefore , it \u2019 s quite straightforward to write an interpreter for them . The programs in our DSL are tokenized vectors and can be directly feed into the neural program executor . Adding new semantic operator to the DSL is thus easy . We just need to re-train or finetune the current program executor with the new semantic operator included . We have also listed all other planned changes in our general response above . Please don \u2019 t hesitate to let us know for any additional comments on the paper or on the planned changes ."}}