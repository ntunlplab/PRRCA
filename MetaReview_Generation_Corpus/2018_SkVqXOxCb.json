{"year": "2018", "forum": "SkVqXOxCb", "title": "Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields", "decision": "Accept (Poster)", "meta_review": "The paper provides an interesting take on GAN training based on Coulomb dynamics. The proposed formulation is theoretically well motivated and authors provide guarantees for convergence. Reviewers agree that the theoretical analysis is interesting but are not completely impressed by the results. The method addresses mode collapse issue but still lacks in sample quality. Nevertheless, reviewers agree that this is a good step towards the understanding of GAN training. ", "reviews": [{"review_id": "SkVqXOxCb-0", "review_text": " In this paper, the authors interpret the training of GAN by potential field and inspired from which to provide new training procedure for GAN. They claim that under the condition that global optima are achieved for discriminator and generator in each iteration, the Coulomb GAN converges to the global solution. I think there are several points need to be addressed. 1, I agree that the \"model collapsing\" is due to converging to a local Nash Equilibrium. However, there are more reasons besides the drawback of the loss function, which is emphasized in the paper. Leave the stochastic gradient descent optimization algorithm apart (since most of the neural networks are trained in this way), the parametrization and the richness of discriminator family play a vital role in the model collapsing issue. In fact, even with KL-divergence in which log operation is involved, if one can select reasonable parametrization, e.g., directly handling in function space, the saddle point optimization is convex-concave, which means under the same assumption made in the paper, there is only one global Nash Equilibrium. On the other hand, the richness of the discriminator also important in the training of GAN. I did not get the point about the drawback of III. If indeed as the paper considered in the ideal case, the discriminator is rich enough, III cannot happen. The model collapsing is not just because loss function in training GAN. It is caused by the twist of these three issues listed above. Modifying the loss can avoid partially model collapsing, however, it is not appropriate to claim that the proposed algorithm is 'provable'. The assumption in this paper is too restricted, and the discussion is unfair to the existing variants of GAN, e.g., GMMN or Wasserstein GAN, which under some assumptions, there is also only one global Nash Equilibrium. 2, In the training procedure, the discriminator family is important as we discussed. The paper claims that the reason to introduce the extra discriminator is reducing variance. However, such parametrization will introduce bias too. The bias and variance tradeoff should be explicitly discussed here. Ideally, it should contain all the functions formed with Plummer kernel, but not too large (otherwise, it will increase the sample complexity.). Which function family used in the paper is not clear. 3, As the authors already realized, the GMMN is one closely related model. It will be more convincing to add the comparison with GMMN. In sum, this paper provides an interesting perspective modeling GAN from the potential field, however, there are several issues need to be addressed. I expect to see the reply of the authors regarding the mentioned issues. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We 'd like to thank the reviewer for this in-depth and constructive review , it was a great help in improving our manuscript . The major changes in the new version of the text are : * Clarified notion of Nash Equilibria : reformulated Theorem 2 in function space ( your point 1 ) * Clarified bias/variance issues ( your point 2 ) * Added comparison to MMD GAN ( your point 3 ) In hindsight , we did n't outline the contribution that Coulomb GANs make as clear as we could have . As a result of this review , we have rewritten large portions of Section 2 and strongly clarified some of our main statements . We were able to reformulate Theorem 2 in a much more precise way . We think that the new version of the text is much improved , and we hope it clears up the items you mentioned . To your specific points : 1 . Thank you , this comment was very helpful , and lead us to reformulate some of our claims in a clearer way . We agree that loss functions are not the only culprit for unsuccessful GAN learning , and that all practical learning approaches - where generator/discriminator are parametrized models and learned by SGD - introduce a whole lot of convergence and local optimality problems in GANs . But more fundamentally the choice of the loss function might introduce bad local Nash equlibria already in the `` theoretical '' function space . This fundamental issue is - to the best of our knowledge - not explored in the current literature , neither in the context of Wasserstein GANs nor in GMMN losses and we are not sure if the absence of local Nash equilibria in function space could be proven for those cases . This issue has fundamental implications for all GAN architectures . Therefore our work aims to be more than `` just another cool GAN \u201c , but hopefully furthers the theoretical understanding of GANs in general . We think that the main contribution of Coulomb GANs is to provide a loss function for GAN learning with the mathematically rigorous guarantee that no such local Nash Equlibria * IN FUNCTION SPACE * exist . We think this is a crucial issue that has not received proper attention yet in order to put scientific GAN research on a solid rigorous ground . We are not aware of any other paper that provides such a strong claim as our Theorem 2 . Neither WGAN nor MMD-based approaches have made this claim and we are not sure that a corresponding claim for them would be provable at all . We hope you will appreciate our newly written section 2.1 , where we discuss in more depth and mathematical precision what we mean by `` local nash equlibrium in function space '' , and how it differs from looking at things in probability-distribution space or parameter space . With that said , we fully agree that for all practical purposes the choice of rich discriminators ( and the parametrization in general ) is highly important for good empirical performance . However , that topic is not the main point we are trying to investigate . 2.You are right , thank you for this head 's up ! There are two kinds of approximation here : First , we approximate the potential Phi using a mini-batch specific \\hat { Phi } . The newer version of the paper discusses the properties of this approximation . Concretely , we show in the appendix that the estimate is unbiased , and explicitly mention the drawback of its high variance in the main text ( Section 2.4 ) . Secondly , as you correctly stated , we learn Phi with a neural network ( the discriminator ) to reduce the high variance of the mini-batch \\hat { Phi } . With this , we run into the usual the bias/variance tradeoff of Machine Learning : trading overfitting against underfitting . And we absolutely agree that finding a good discriminator ( that is able to learn the potential field correctly ) is vital . Thankfully , in GAN learning we can always sample new generator data in each mini-batch , so overfitting on those is not too much of an issue , but we could still overfit on the real-world training data . This could lead to local Nash equilibria in parameter space . Therefore , we tried to be more explicit in the new version of the text that our analysis focuses on the space of functions , and we explicitly mention that neural network learning is vulnerable to issues such as over/underfitting ( again in Section 2.4 ) . 3.Thank you for the suggestion , we have added this comparison : The original GMMN approach is computationally very expensive to run on the typical GAN datasets , and was recently improved upon by the MMD-GAN model [ Li et al , NIPS 2017 ] . Most importantly , MMD GAN extends the GMMN approach to a learnable discriminator , which makes the approach better and feasible for larger datasets ( & very similar to Coulomb GAN 's discriminator , presumably with the same advantage of reducing variance ) . In their paper , Li et al.show that MMD GAN outperforms GMMN on all tested datasets . We thus added a comparison to MMD-GAN to the current revision of the manuscript ."}, {"review_id": "SkVqXOxCb-1", "review_text": "The authors draw from electrical field dynamics and propose to formulate the GAN learning problem in a way such that generated samples are attracted to training set samples, but repel each other. Optimizing this formulation using gradient descent can be proven to yield only one optimal global Nash equilibrium, which the authors claim allows Coulomb GANs to overcome the \"mode collapse\" issue. Experimental results are reported on image and language modeling tasks, and show that the model can produce very diverse samples, although some samples can consist of somewhat nonsensical interpolations. This is a good, well-written paper. It is technically rigorous and empirically convincing. Overall, it presents an interesting approach to overcome the mode collapse problem with GANs. The image samples presented -- although of high variability -- are not of very high quality, though, and I somewhat disagree with the claim that \"Coulomb GAN was able to efficiently learn the whole distribution\" (Sec 3.1). At best, it seems to me that the new objective does in fact force the generator to concentrate efforts on learning over the full support of the data distribution, but the lower quality samples and sometimes somewhat bad interpolations seem to suggest to me that it is *not* yet doing so very \"efficiently\". Nonetheless, I think this is an important step forward in improving GANs, and should be accepted for publication. Note: I did not check all the proofs in the appendix.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review , and thanks for the \u201e important step forward in improving GANs \u201c . We appreciate your positive feedback . We agree with your assessment that our objective forces the generator to concentrate efforts on learning over the full support at the cost of somewhat bad interpolations , and toned down the statement about learning `` efficiently '' in the new update of the paper . To see how Coulomb GANs perform when contrasted with similar approaches that aim to learn the full support of the distribution , we added a new comparison with MMD approaches . It turns out that Coulomb GANs are more efficient than MMD GANs ."}, {"review_id": "SkVqXOxCb-2", "review_text": "The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potential for addressing the learning problem. It is also well written with a clear presentation of the motivation of the problems it is trying to address, the background and proves the optimality of the suggested solution. My understanding and validity of the proof is still an educated guess. I have been through section A.2 , but I'm unfamiliar with the earlier literature on the similar topics so I would not be able to comment on it. Overall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs. I just had a couple of points in the paper that I would like some clarification on : * In section 2.2.1 : The notion of the generated a_i not disappearing is something I did not follow. What does it mean for a generated sample to \"not disappear\" ? and this directly extends to the continuity equation in (2). * In section 1 : in the explanation of the 3rd problem that GANs exhibit i.e. the generator not being able to generalize the distribution of the input samples, I was hoping if you could give a bit more motivation as to why this happens. I don't think this needs to be included in the paper, but would like to have it for a personal clarification. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their encouraging review , appreciate the positive feedback . For your questions : * Thanks for pointing out that our explanation was not clear enough . An a_i is associated with a particular random variable z_i of the generator which is mapped by the generator to a_i . If the generator changes , then the same random variable z_i is mapped to another a_i ' . That is a_i moved to a_i ' . We have explained this more clearly in the current revision . * We have tried to explain this better in the new version of the text ( even if you said it was n't necessary ) . Informally speaking , we meant the following : in typical GAN learning ( e.g.Goodfellow 's original formulation ) the discriminator is able to say `` in this region of space A , the probability of a sample being fake is x % '' . Which provides the generator with the information of how well it does in said region . However , the discriminator has usually no way of telling the generator `` you should move probability mass over to this region B which is far , far away from A , because there is a lack of generated density there '' . Thus , the discriminator can not tell the generator how to globally move its mass ( it just gets local gradient information at the points where it currently generates ) . In particular , the generator can not move samples across regions where the real world data has no support . As soon as generator samples appear at the border of such regions , they are penalized and move back to regions with real world support where they come from . Moving again means that samples `` a '' are associated with random variables `` z '' , and small changes in the generator lead to small changes of `` a '' ( `` z '' is mapped to a slightly different `` a '' ) . Thus , it is impossible to move samples from one island of real world support to another island of real world support ."}], "0": {"review_id": "SkVqXOxCb-0", "review_text": " In this paper, the authors interpret the training of GAN by potential field and inspired from which to provide new training procedure for GAN. They claim that under the condition that global optima are achieved for discriminator and generator in each iteration, the Coulomb GAN converges to the global solution. I think there are several points need to be addressed. 1, I agree that the \"model collapsing\" is due to converging to a local Nash Equilibrium. However, there are more reasons besides the drawback of the loss function, which is emphasized in the paper. Leave the stochastic gradient descent optimization algorithm apart (since most of the neural networks are trained in this way), the parametrization and the richness of discriminator family play a vital role in the model collapsing issue. In fact, even with KL-divergence in which log operation is involved, if one can select reasonable parametrization, e.g., directly handling in function space, the saddle point optimization is convex-concave, which means under the same assumption made in the paper, there is only one global Nash Equilibrium. On the other hand, the richness of the discriminator also important in the training of GAN. I did not get the point about the drawback of III. If indeed as the paper considered in the ideal case, the discriminator is rich enough, III cannot happen. The model collapsing is not just because loss function in training GAN. It is caused by the twist of these three issues listed above. Modifying the loss can avoid partially model collapsing, however, it is not appropriate to claim that the proposed algorithm is 'provable'. The assumption in this paper is too restricted, and the discussion is unfair to the existing variants of GAN, e.g., GMMN or Wasserstein GAN, which under some assumptions, there is also only one global Nash Equilibrium. 2, In the training procedure, the discriminator family is important as we discussed. The paper claims that the reason to introduce the extra discriminator is reducing variance. However, such parametrization will introduce bias too. The bias and variance tradeoff should be explicitly discussed here. Ideally, it should contain all the functions formed with Plummer kernel, but not too large (otherwise, it will increase the sample complexity.). Which function family used in the paper is not clear. 3, As the authors already realized, the GMMN is one closely related model. It will be more convincing to add the comparison with GMMN. In sum, this paper provides an interesting perspective modeling GAN from the potential field, however, there are several issues need to be addressed. I expect to see the reply of the authors regarding the mentioned issues. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We 'd like to thank the reviewer for this in-depth and constructive review , it was a great help in improving our manuscript . The major changes in the new version of the text are : * Clarified notion of Nash Equilibria : reformulated Theorem 2 in function space ( your point 1 ) * Clarified bias/variance issues ( your point 2 ) * Added comparison to MMD GAN ( your point 3 ) In hindsight , we did n't outline the contribution that Coulomb GANs make as clear as we could have . As a result of this review , we have rewritten large portions of Section 2 and strongly clarified some of our main statements . We were able to reformulate Theorem 2 in a much more precise way . We think that the new version of the text is much improved , and we hope it clears up the items you mentioned . To your specific points : 1 . Thank you , this comment was very helpful , and lead us to reformulate some of our claims in a clearer way . We agree that loss functions are not the only culprit for unsuccessful GAN learning , and that all practical learning approaches - where generator/discriminator are parametrized models and learned by SGD - introduce a whole lot of convergence and local optimality problems in GANs . But more fundamentally the choice of the loss function might introduce bad local Nash equlibria already in the `` theoretical '' function space . This fundamental issue is - to the best of our knowledge - not explored in the current literature , neither in the context of Wasserstein GANs nor in GMMN losses and we are not sure if the absence of local Nash equilibria in function space could be proven for those cases . This issue has fundamental implications for all GAN architectures . Therefore our work aims to be more than `` just another cool GAN \u201c , but hopefully furthers the theoretical understanding of GANs in general . We think that the main contribution of Coulomb GANs is to provide a loss function for GAN learning with the mathematically rigorous guarantee that no such local Nash Equlibria * IN FUNCTION SPACE * exist . We think this is a crucial issue that has not received proper attention yet in order to put scientific GAN research on a solid rigorous ground . We are not aware of any other paper that provides such a strong claim as our Theorem 2 . Neither WGAN nor MMD-based approaches have made this claim and we are not sure that a corresponding claim for them would be provable at all . We hope you will appreciate our newly written section 2.1 , where we discuss in more depth and mathematical precision what we mean by `` local nash equlibrium in function space '' , and how it differs from looking at things in probability-distribution space or parameter space . With that said , we fully agree that for all practical purposes the choice of rich discriminators ( and the parametrization in general ) is highly important for good empirical performance . However , that topic is not the main point we are trying to investigate . 2.You are right , thank you for this head 's up ! There are two kinds of approximation here : First , we approximate the potential Phi using a mini-batch specific \\hat { Phi } . The newer version of the paper discusses the properties of this approximation . Concretely , we show in the appendix that the estimate is unbiased , and explicitly mention the drawback of its high variance in the main text ( Section 2.4 ) . Secondly , as you correctly stated , we learn Phi with a neural network ( the discriminator ) to reduce the high variance of the mini-batch \\hat { Phi } . With this , we run into the usual the bias/variance tradeoff of Machine Learning : trading overfitting against underfitting . And we absolutely agree that finding a good discriminator ( that is able to learn the potential field correctly ) is vital . Thankfully , in GAN learning we can always sample new generator data in each mini-batch , so overfitting on those is not too much of an issue , but we could still overfit on the real-world training data . This could lead to local Nash equilibria in parameter space . Therefore , we tried to be more explicit in the new version of the text that our analysis focuses on the space of functions , and we explicitly mention that neural network learning is vulnerable to issues such as over/underfitting ( again in Section 2.4 ) . 3.Thank you for the suggestion , we have added this comparison : The original GMMN approach is computationally very expensive to run on the typical GAN datasets , and was recently improved upon by the MMD-GAN model [ Li et al , NIPS 2017 ] . Most importantly , MMD GAN extends the GMMN approach to a learnable discriminator , which makes the approach better and feasible for larger datasets ( & very similar to Coulomb GAN 's discriminator , presumably with the same advantage of reducing variance ) . In their paper , Li et al.show that MMD GAN outperforms GMMN on all tested datasets . We thus added a comparison to MMD-GAN to the current revision of the manuscript ."}, "1": {"review_id": "SkVqXOxCb-1", "review_text": "The authors draw from electrical field dynamics and propose to formulate the GAN learning problem in a way such that generated samples are attracted to training set samples, but repel each other. Optimizing this formulation using gradient descent can be proven to yield only one optimal global Nash equilibrium, which the authors claim allows Coulomb GANs to overcome the \"mode collapse\" issue. Experimental results are reported on image and language modeling tasks, and show that the model can produce very diverse samples, although some samples can consist of somewhat nonsensical interpolations. This is a good, well-written paper. It is technically rigorous and empirically convincing. Overall, it presents an interesting approach to overcome the mode collapse problem with GANs. The image samples presented -- although of high variability -- are not of very high quality, though, and I somewhat disagree with the claim that \"Coulomb GAN was able to efficiently learn the whole distribution\" (Sec 3.1). At best, it seems to me that the new objective does in fact force the generator to concentrate efforts on learning over the full support of the data distribution, but the lower quality samples and sometimes somewhat bad interpolations seem to suggest to me that it is *not* yet doing so very \"efficiently\". Nonetheless, I think this is an important step forward in improving GANs, and should be accepted for publication. Note: I did not check all the proofs in the appendix.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review , and thanks for the \u201e important step forward in improving GANs \u201c . We appreciate your positive feedback . We agree with your assessment that our objective forces the generator to concentrate efforts on learning over the full support at the cost of somewhat bad interpolations , and toned down the statement about learning `` efficiently '' in the new update of the paper . To see how Coulomb GANs perform when contrasted with similar approaches that aim to learn the full support of the distribution , we added a new comparison with MMD approaches . It turns out that Coulomb GANs are more efficient than MMD GANs ."}, "2": {"review_id": "SkVqXOxCb-2", "review_text": "The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potential for addressing the learning problem. It is also well written with a clear presentation of the motivation of the problems it is trying to address, the background and proves the optimality of the suggested solution. My understanding and validity of the proof is still an educated guess. I have been through section A.2 , but I'm unfamiliar with the earlier literature on the similar topics so I would not be able to comment on it. Overall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs. I just had a couple of points in the paper that I would like some clarification on : * In section 2.2.1 : The notion of the generated a_i not disappearing is something I did not follow. What does it mean for a generated sample to \"not disappear\" ? and this directly extends to the continuity equation in (2). * In section 1 : in the explanation of the 3rd problem that GANs exhibit i.e. the generator not being able to generalize the distribution of the input samples, I was hoping if you could give a bit more motivation as to why this happens. I don't think this needs to be included in the paper, but would like to have it for a personal clarification. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their encouraging review , appreciate the positive feedback . For your questions : * Thanks for pointing out that our explanation was not clear enough . An a_i is associated with a particular random variable z_i of the generator which is mapped by the generator to a_i . If the generator changes , then the same random variable z_i is mapped to another a_i ' . That is a_i moved to a_i ' . We have explained this more clearly in the current revision . * We have tried to explain this better in the new version of the text ( even if you said it was n't necessary ) . Informally speaking , we meant the following : in typical GAN learning ( e.g.Goodfellow 's original formulation ) the discriminator is able to say `` in this region of space A , the probability of a sample being fake is x % '' . Which provides the generator with the information of how well it does in said region . However , the discriminator has usually no way of telling the generator `` you should move probability mass over to this region B which is far , far away from A , because there is a lack of generated density there '' . Thus , the discriminator can not tell the generator how to globally move its mass ( it just gets local gradient information at the points where it currently generates ) . In particular , the generator can not move samples across regions where the real world data has no support . As soon as generator samples appear at the border of such regions , they are penalized and move back to regions with real world support where they come from . Moving again means that samples `` a '' are associated with random variables `` z '' , and small changes in the generator lead to small changes of `` a '' ( `` z '' is mapped to a slightly different `` a '' ) . Thus , it is impossible to move samples from one island of real world support to another island of real world support ."}}