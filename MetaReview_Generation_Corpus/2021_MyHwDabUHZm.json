{"year": "2021", "forum": "MyHwDabUHZm", "title": "Beyond Categorical Label Representations for Image Classification", "decision": "Accept (Poster)", "meta_review": "This paper proposes to use high dimensional representation for labels to strengthen the adversarial robustness of deep neural networks. Experimental results demonstrate that the proposed method improve adversarial robustness. All reviewer agree that the authors propose an interesting idea and this direction deserves further exploration. On the other hand, the reviewers also raise a serious question: There is a lack of explanation of why high dimensional representation of labels improve adversarial robustness. Therefore, it is not clear if the proposed method can defend refined attacks tailored to such dimensional label representation. The authors are highly encouraged to conduct deeper analysis, especially on the robustness against finer attacks.", "reviews": [{"review_id": "MyHwDabUHZm-0", "review_text": "The paper proposed to use other high-dimensional representation instead of direct one-hot class labels in image classification problem . They used spectrogram of the pronunciations ( TTS-based generated speech ) of class labels as a high-dimensional representation . Then , they performed regression using the spectrogram as a label . The evaluation is conducted in nearest-neighbor way , measuring the distance between the image embedding feature and groundtruth high-dimensional representation ( spectrogram ) and decide the predicted class label . Then , they compared it with traditional classification model with cross-entropy loss . The results showed that the proposed approach are more robust in adversarial attack and feature effectiveness . However , overall , I think one important related direction is somewhat missing which is zero-shot learning . In zero-shot learning , the primary goal is to make a prediction on unseen class labels . On the other hand , zero-shot learning has characteristics in that it uses an additional information to learn the embedding space . I think the proposed approach in this paper is somewhat related with it . Since TTS system is utilized to generate pronunciation of label , such other information is naturally used in high-dimensional labels ( the information used in the TTS system ) . Also , the author argues that audio labels is special , but in the paper , other type of high-dimensional representation of labels that uses external information are not explored , such as word2vec . I think two factors are somewhat mixed . One is about the usefulness of high-dimensional representation ( without external information , constant comparison is working at here ) and the other is use of the external information . So , to verify the former factor , I think high-dimensional version of class label that does not use the external information should be added , such as after running topic modeling algorithm within the image classification data , and use them as a high-dimensional representation of a class label . Second , to verify the specialness of the audio label , other external data can also be compared , such as general word2vec , ... In page 4 , how the various length of audio produce the spectrogram of the same size ? ( the length difference is really small ? ) The traditional classification is conducted in classification , while the high-dimensional label experiment is conducted in regression . I think the author can explore classification type loss for the latter experiments also ( measuring the distance between the two matrices and put softmax over these similarity scores ) .", "rating": "7: Good paper, accept", "reply_text": "# # # # # BERT Attack Results : | ResNet32 | Epsilon 0 | Epsilon 0.05 | Epsilon 0.1 | Epsilon 0.15 | Epsilon 0.2 | Epsilon 0.25 | Epsilon 0.3 | |-| : -- : | : :| : -- : | : :| : -- : | : :| : -- : | | FSGM MEAN | 0.927733333 | 0.690766667 | 0.607433333 | 0.51736667 | 0.42313333 | 0.33553333 | 0.26746667 | | FSGM STD | 0.001625833 | 0.015631165 | 0.0345558 | 0.04923437 | 0.05716374 | 0.05364516 | 0.04588489 | | FSGM Targeted MEAN | 0.927733333 | 0.738366667 | 0.670866667 | 0.5776 | 0.46483333 | 0.36613333 | 0.2873 | | FSGM Targeted STD | 0.001625833 | 0.012159907 | 0.025550408 | 0.04388633 | 0.05841955 | 0.05822837 | 0.0491692 | | Iterative MEAN | 0.927733333 | 0.616066667 | 0.4877 | 0.40496667 | 0.34303333 | 0.2986 | 0.25896667 | | Iterative STD | 0.001625833 | 0.029737574 | 0.048071925 | 0.05809392 | 0.06387256 | 0.06849299 | 0.066176 | | Iterative Targeted MEAN | 0.927733333 | 0.711233333 | 0.631633333"}, {"review_id": "MyHwDabUHZm-1", "review_text": "This work suggests an alternative training method where the ground truth label is given as speech signal . The authors hypothesize the labels with high-dimensionality & high entropy will help the network learn better feature representation . The hypothesis is empirically examined by the authors using commonly used CIFAR-10 and CIFAR-100 datasets . The experiment results show that the proposed approach is effective in terms of adversarial robustness and data efficiency . Strength : The idea of giving speech signal as a proxy for categorical label is interesting . Weakness : Unclear source of performance for data efficiency and robustness on adversarial attack The proposed claim in this work seems quite bold and is mostly built on empirical observation . Also , I think the proposed approach is somewhat similar to the popular multi-modal representation learning schemes , which is quite common these days . The main difference is that the authors train the network by targeting speech signals itself . I recommend the authors to compare the proposed method with previous multi-modal learning training schemes such as [ 1 , 2 ] and many more . Ratings : Although the paper shows some interesting research direction , the way the authors show the effectiveness of the proposed method is mostly built on empirical results , which is not enough to claim such a bold argument . For this reason , I recommend rejection . References [ 1 ] Look , Listen and Learn ( https : //arxiv.org/abs/1705.08168 ) [ 2 ] Objects that Sound ( https : //arxiv.org/abs/1712.06651 )", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your constructive feedback . We hope that we can clarify and address your concerns with the point response below . - \u201c The proposed claim in this work seems quite bold and is mostly built on empirical observation \u201d We argue that empirical observation is an important research practice in deep learning and representation learning which has historically been responsible for many major milestones . We have made sure to provide strong evidence through thorough and systematic experiments . Moreover , since the direction we are studying in this paper is relatively underexplored , we believe that our research can serve as an important reference for future theoretical work . - \u201c I think the proposed approach is somewhat similar to the popular multi-modal representation learning schemes , which is quite common these days . The main difference is that the authors train the network by targeting speech signals itself . I recommend the authors to compare the proposed method with previous multi-modal learning training schemes such as [ 1 , 2 ] and many more. \u201d We will add a section in our related works to discuss multi-modal representation learning . Our focus and training scheme are not directly comparable with multi-modal representation learning : ( 1 ) The label representations used in our paper are very different from the data used in multi-modal learning such as captions , sound , and videos . The extra modalities used in multi-modal learning mostly come with rich extra information that can not be directly extracted from the image or video representation . However , our contribution is to suggest that underexplored label representations , especially \u201c high-dimensional high-entropy \u201d label representations can serve as strong alternatives to traditional categorical labels with more robust features and more efficient learning in the image classification setting . In addition to speech labels , our paper also covers uniform-random matrix , shuffled speech label , composition of Gaussian patterns , constant matrix , and categorical label with label smoothing . ( 2 ) The focus is also different . The recommended works from the reviewer aim at learning the correspondence between a video and audio clip in a self-supervised manner . Specifically , the main idea is to train a network to distinguish if the given video and audio clip is well corresponded . Both the video and audio are input . The learned feature representation can then be used to train other linear classifiers on downstream tasks such as sound classification , acoustic scene classification , and image classification . The learning paradigm falls well into the visual-audio correspondence self-supervised learning . However , our approach does not aim at self-supervised learning and multi-modal learning . Our task is the traditional image classification task . Instead of learning effective feature representations for the downstream task , our goal is to study underexplored label representations and their effectiveness . The speech modality only serves as a variant of the categorical label representation . Other label representations in our paper do not count a different modality . Importantly , the input of our network only contains the raw images without other modalities . ( 3 ) The training procedure differs from our paper and the works recommended by the reviewer . Our training procedure follows the standard supervised learning image classification task . Given an image input , the network is optimized to generate the correct label . In the works recommended by the reviewer , a network is first pre-trained on a predefined pretext task . A second network is then trained in a supervised manner on a different downstream task with the learned features from the first network . Since our approach does not assume a pretext task or a pre-training procedure , the training methods are not directly comparable . Please kindly let us know if we address your concerns . Thank you !"}, {"review_id": "MyHwDabUHZm-2", "review_text": "The authors study the effect of data labels on the quality of trained models . More specifically , the authors use audio labels rather than traditional categorical probabilities for model training and get surprising and interesting results . The results show that high dimensional and high entropy label representations are more useful , which is observed in the experiments related to robustness and a limited amount of training data . Such a result is very interesting and suggests that the label representation can be further explored and potentially plan an important role . This paper starts an interesting direction and conducts nice experiments . The paper is easy to follow and well written . The hypothesis about the relationship between high entropy and training effectiveness is also a good observation . I am also interested in that if the audio signal is replaced by pre-trained embeddings , like glove or BERT , as label representation , how the effectiveness of labels is compared with the audio signals ?", "rating": "7: Good paper, accept", "reply_text": "# # # # # BERT Attack Results : | ResNet32 | Epsilon 0 | Epsilon 0.05 | Epsilon 0.1 | Epsilon 0.15 | Epsilon 0.2 | Epsilon 0.25 | Epsilon 0.3 | |-| : -- : | : :| : -- : | : :| : -- : | : :| : -- : | | FSGM MEAN | 0.927733333 | 0.690766667 | 0.607433333 | 0.51736667 | 0.42313333 | 0.33553333 | 0.26746667 | | FSGM STD | 0.001625833 | 0.015631165 | 0.0345558 | 0.04923437 | 0.05716374 | 0.05364516 | 0.04588489 | | FSGM Targeted MEAN | 0.927733333 | 0.738366667 | 0.670866667 | 0.5776 | 0.46483333 | 0.36613333 | 0.2873 | | FSGM Targeted STD | 0.001625833 | 0.012159907 | 0.025550408 | 0.04388633 | 0.05841955 | 0.05822837 | 0.0491692 | | Iterative MEAN | 0.927733333 | 0.616066667 | 0.4877 | 0.40496667 | 0.34303333 | 0.2986 | 0.25896667 | | Iterative STD | 0.001625833 | 0.029737574 | 0.048071925 | 0.05809392 | 0.06387256 | 0.06849299 | 0.066176 | | Iterative Targeted MEAN | 0.927733333 | 0.711233333 | 0.631633333"}, {"review_id": "MyHwDabUHZm-3", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : This paper presents a novel approach/perspective for improving data efficiency and robustness , other than existing research progress achieved by scientists , from model , optimizer and data perspective . In particular , it proposes to introduce high dimensional and high entropy label representations for group truth , to improve image classification performance from two practical matters Robustness and data efficiency , while achieving comparable accuracy to text labels as the standard representation . To valid its findings , the authors develop designed a set of comprehensive experiments for evaluation and comparison purposes , while making the best effort to not introducing variations from other angles , such as keeping the same data for training and testing and introducing adversary information consistently among all labeling representations . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Reasons for score : Overall , I vote for accepting . I like the idea of approaching image classification problem from a new angle that are not well explored yet . My major concerns are : 1 . The clarity of the study on the underline true set of characteristics that contribute to the improvement , from speech label , shuffled-speech label , Gaussian-composition label , besides high dimension and high entropy . 2.The logic behind the adversary image generation , target vs non-target . 3.And the evidence/thinking process behind the pre-selected threshold of 3.5 Hopefully the authors can address my concern in the rebuttal period . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper provides a novel perspective for classification performance improvement , rather than from data , algorithms , or optimizers perspective . It shows the importance of label for supervised learning problems , can also come from the ways that we represent them , just only label quality . For me , this approach is new and potentially expend to other applications , besides image classification 2 . The experiment design is also quite comprehensive as it covers all potential perspectives and variations . 3.This inspiration of the idea to me is also quite natural and understandable , as for most of us , when recognizing an image , we express it not just in writing and can also in speech format . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : Although the proposed representations have shown better performance in image classification problem , with evidence to support its out-performed robustness to adversarial attack and data efficiency -- achieving comparable accuracy with less data in training , I would still suggest the authors to conduct the following studies to enhance the quality of the paper : 1 . It could be valuable to future investigate the inherent property that contributes to the improvement , besides high dimensionality and high entropy . 2.What \u2019 s the performance with high dimensional and high entropy label representations , comparing to text label , for other kind of the classification problems , such as NLP problems . 3.For speech label , in model evaluation , what \u2019 s the performance for the model , if we choose a speech to text process to obtain its ground truth , beside the two approaches mentioned in the paper -- \u201c nearest neighbor \u201d and a validated loss threshold . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Questions during rebuttal period : Please address and clarify the cons above", "rating": "7: Good paper, accept", "reply_text": "# # # # # BERT Attack Results : | ResNet32 | Epsilon 0 | Epsilon 0.05 | Epsilon 0.1 | Epsilon 0.15 | Epsilon 0.2 | Epsilon 0.25 | Epsilon 0.3 | |-| : -- : | : :| : -- : | : :| : -- : | : :| : -- : | | FSGM MEAN | 0.927733333 | 0.690766667 | 0.607433333 | 0.51736667 | 0.42313333 | 0.33553333 | 0.26746667 | | FSGM STD | 0.001625833 | 0.015631165 | 0.0345558 | 0.04923437 | 0.05716374 | 0.05364516 | 0.04588489 | | FSGM Targeted MEAN | 0.927733333 | 0.738366667 | 0.670866667 | 0.5776 | 0.46483333 | 0.36613333 | 0.2873 | | FSGM Targeted STD | 0.001625833 | 0.012159907 | 0.025550408 | 0.04388633 | 0.05841955 | 0.05822837 | 0.0491692 | | Iterative MEAN | 0.927733333 | 0.616066667 | 0.4877 | 0.40496667 | 0.34303333 | 0.2986 | 0.25896667 | | Iterative STD | 0.001625833 | 0.029737574 | 0.048071925 | 0.05809392 | 0.06387256 | 0.06849299 | 0.066176 | | Iterative Targeted MEAN | 0.927733333 | 0.711233333 | 0.631633333"}], "0": {"review_id": "MyHwDabUHZm-0", "review_text": "The paper proposed to use other high-dimensional representation instead of direct one-hot class labels in image classification problem . They used spectrogram of the pronunciations ( TTS-based generated speech ) of class labels as a high-dimensional representation . Then , they performed regression using the spectrogram as a label . The evaluation is conducted in nearest-neighbor way , measuring the distance between the image embedding feature and groundtruth high-dimensional representation ( spectrogram ) and decide the predicted class label . Then , they compared it with traditional classification model with cross-entropy loss . The results showed that the proposed approach are more robust in adversarial attack and feature effectiveness . However , overall , I think one important related direction is somewhat missing which is zero-shot learning . In zero-shot learning , the primary goal is to make a prediction on unseen class labels . On the other hand , zero-shot learning has characteristics in that it uses an additional information to learn the embedding space . I think the proposed approach in this paper is somewhat related with it . Since TTS system is utilized to generate pronunciation of label , such other information is naturally used in high-dimensional labels ( the information used in the TTS system ) . Also , the author argues that audio labels is special , but in the paper , other type of high-dimensional representation of labels that uses external information are not explored , such as word2vec . I think two factors are somewhat mixed . One is about the usefulness of high-dimensional representation ( without external information , constant comparison is working at here ) and the other is use of the external information . So , to verify the former factor , I think high-dimensional version of class label that does not use the external information should be added , such as after running topic modeling algorithm within the image classification data , and use them as a high-dimensional representation of a class label . Second , to verify the specialness of the audio label , other external data can also be compared , such as general word2vec , ... In page 4 , how the various length of audio produce the spectrogram of the same size ? ( the length difference is really small ? ) The traditional classification is conducted in classification , while the high-dimensional label experiment is conducted in regression . I think the author can explore classification type loss for the latter experiments also ( measuring the distance between the two matrices and put softmax over these similarity scores ) .", "rating": "7: Good paper, accept", "reply_text": "# # # # # BERT Attack Results : | ResNet32 | Epsilon 0 | Epsilon 0.05 | Epsilon 0.1 | Epsilon 0.15 | Epsilon 0.2 | Epsilon 0.25 | Epsilon 0.3 | |-| : -- : | : :| : -- : | : :| : -- : | : :| : -- : | | FSGM MEAN | 0.927733333 | 0.690766667 | 0.607433333 | 0.51736667 | 0.42313333 | 0.33553333 | 0.26746667 | | FSGM STD | 0.001625833 | 0.015631165 | 0.0345558 | 0.04923437 | 0.05716374 | 0.05364516 | 0.04588489 | | FSGM Targeted MEAN | 0.927733333 | 0.738366667 | 0.670866667 | 0.5776 | 0.46483333 | 0.36613333 | 0.2873 | | FSGM Targeted STD | 0.001625833 | 0.012159907 | 0.025550408 | 0.04388633 | 0.05841955 | 0.05822837 | 0.0491692 | | Iterative MEAN | 0.927733333 | 0.616066667 | 0.4877 | 0.40496667 | 0.34303333 | 0.2986 | 0.25896667 | | Iterative STD | 0.001625833 | 0.029737574 | 0.048071925 | 0.05809392 | 0.06387256 | 0.06849299 | 0.066176 | | Iterative Targeted MEAN | 0.927733333 | 0.711233333 | 0.631633333"}, "1": {"review_id": "MyHwDabUHZm-1", "review_text": "This work suggests an alternative training method where the ground truth label is given as speech signal . The authors hypothesize the labels with high-dimensionality & high entropy will help the network learn better feature representation . The hypothesis is empirically examined by the authors using commonly used CIFAR-10 and CIFAR-100 datasets . The experiment results show that the proposed approach is effective in terms of adversarial robustness and data efficiency . Strength : The idea of giving speech signal as a proxy for categorical label is interesting . Weakness : Unclear source of performance for data efficiency and robustness on adversarial attack The proposed claim in this work seems quite bold and is mostly built on empirical observation . Also , I think the proposed approach is somewhat similar to the popular multi-modal representation learning schemes , which is quite common these days . The main difference is that the authors train the network by targeting speech signals itself . I recommend the authors to compare the proposed method with previous multi-modal learning training schemes such as [ 1 , 2 ] and many more . Ratings : Although the paper shows some interesting research direction , the way the authors show the effectiveness of the proposed method is mostly built on empirical results , which is not enough to claim such a bold argument . For this reason , I recommend rejection . References [ 1 ] Look , Listen and Learn ( https : //arxiv.org/abs/1705.08168 ) [ 2 ] Objects that Sound ( https : //arxiv.org/abs/1712.06651 )", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your constructive feedback . We hope that we can clarify and address your concerns with the point response below . - \u201c The proposed claim in this work seems quite bold and is mostly built on empirical observation \u201d We argue that empirical observation is an important research practice in deep learning and representation learning which has historically been responsible for many major milestones . We have made sure to provide strong evidence through thorough and systematic experiments . Moreover , since the direction we are studying in this paper is relatively underexplored , we believe that our research can serve as an important reference for future theoretical work . - \u201c I think the proposed approach is somewhat similar to the popular multi-modal representation learning schemes , which is quite common these days . The main difference is that the authors train the network by targeting speech signals itself . I recommend the authors to compare the proposed method with previous multi-modal learning training schemes such as [ 1 , 2 ] and many more. \u201d We will add a section in our related works to discuss multi-modal representation learning . Our focus and training scheme are not directly comparable with multi-modal representation learning : ( 1 ) The label representations used in our paper are very different from the data used in multi-modal learning such as captions , sound , and videos . The extra modalities used in multi-modal learning mostly come with rich extra information that can not be directly extracted from the image or video representation . However , our contribution is to suggest that underexplored label representations , especially \u201c high-dimensional high-entropy \u201d label representations can serve as strong alternatives to traditional categorical labels with more robust features and more efficient learning in the image classification setting . In addition to speech labels , our paper also covers uniform-random matrix , shuffled speech label , composition of Gaussian patterns , constant matrix , and categorical label with label smoothing . ( 2 ) The focus is also different . The recommended works from the reviewer aim at learning the correspondence between a video and audio clip in a self-supervised manner . Specifically , the main idea is to train a network to distinguish if the given video and audio clip is well corresponded . Both the video and audio are input . The learned feature representation can then be used to train other linear classifiers on downstream tasks such as sound classification , acoustic scene classification , and image classification . The learning paradigm falls well into the visual-audio correspondence self-supervised learning . However , our approach does not aim at self-supervised learning and multi-modal learning . Our task is the traditional image classification task . Instead of learning effective feature representations for the downstream task , our goal is to study underexplored label representations and their effectiveness . The speech modality only serves as a variant of the categorical label representation . Other label representations in our paper do not count a different modality . Importantly , the input of our network only contains the raw images without other modalities . ( 3 ) The training procedure differs from our paper and the works recommended by the reviewer . Our training procedure follows the standard supervised learning image classification task . Given an image input , the network is optimized to generate the correct label . In the works recommended by the reviewer , a network is first pre-trained on a predefined pretext task . A second network is then trained in a supervised manner on a different downstream task with the learned features from the first network . Since our approach does not assume a pretext task or a pre-training procedure , the training methods are not directly comparable . Please kindly let us know if we address your concerns . Thank you !"}, "2": {"review_id": "MyHwDabUHZm-2", "review_text": "The authors study the effect of data labels on the quality of trained models . More specifically , the authors use audio labels rather than traditional categorical probabilities for model training and get surprising and interesting results . The results show that high dimensional and high entropy label representations are more useful , which is observed in the experiments related to robustness and a limited amount of training data . Such a result is very interesting and suggests that the label representation can be further explored and potentially plan an important role . This paper starts an interesting direction and conducts nice experiments . The paper is easy to follow and well written . The hypothesis about the relationship between high entropy and training effectiveness is also a good observation . I am also interested in that if the audio signal is replaced by pre-trained embeddings , like glove or BERT , as label representation , how the effectiveness of labels is compared with the audio signals ?", "rating": "7: Good paper, accept", "reply_text": "# # # # # BERT Attack Results : | ResNet32 | Epsilon 0 | Epsilon 0.05 | Epsilon 0.1 | Epsilon 0.15 | Epsilon 0.2 | Epsilon 0.25 | Epsilon 0.3 | |-| : -- : | : :| : -- : | : :| : -- : | : :| : -- : | | FSGM MEAN | 0.927733333 | 0.690766667 | 0.607433333 | 0.51736667 | 0.42313333 | 0.33553333 | 0.26746667 | | FSGM STD | 0.001625833 | 0.015631165 | 0.0345558 | 0.04923437 | 0.05716374 | 0.05364516 | 0.04588489 | | FSGM Targeted MEAN | 0.927733333 | 0.738366667 | 0.670866667 | 0.5776 | 0.46483333 | 0.36613333 | 0.2873 | | FSGM Targeted STD | 0.001625833 | 0.012159907 | 0.025550408 | 0.04388633 | 0.05841955 | 0.05822837 | 0.0491692 | | Iterative MEAN | 0.927733333 | 0.616066667 | 0.4877 | 0.40496667 | 0.34303333 | 0.2986 | 0.25896667 | | Iterative STD | 0.001625833 | 0.029737574 | 0.048071925 | 0.05809392 | 0.06387256 | 0.06849299 | 0.066176 | | Iterative Targeted MEAN | 0.927733333 | 0.711233333 | 0.631633333"}, "3": {"review_id": "MyHwDabUHZm-3", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : This paper presents a novel approach/perspective for improving data efficiency and robustness , other than existing research progress achieved by scientists , from model , optimizer and data perspective . In particular , it proposes to introduce high dimensional and high entropy label representations for group truth , to improve image classification performance from two practical matters Robustness and data efficiency , while achieving comparable accuracy to text labels as the standard representation . To valid its findings , the authors develop designed a set of comprehensive experiments for evaluation and comparison purposes , while making the best effort to not introducing variations from other angles , such as keeping the same data for training and testing and introducing adversary information consistently among all labeling representations . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Reasons for score : Overall , I vote for accepting . I like the idea of approaching image classification problem from a new angle that are not well explored yet . My major concerns are : 1 . The clarity of the study on the underline true set of characteristics that contribute to the improvement , from speech label , shuffled-speech label , Gaussian-composition label , besides high dimension and high entropy . 2.The logic behind the adversary image generation , target vs non-target . 3.And the evidence/thinking process behind the pre-selected threshold of 3.5 Hopefully the authors can address my concern in the rebuttal period . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper provides a novel perspective for classification performance improvement , rather than from data , algorithms , or optimizers perspective . It shows the importance of label for supervised learning problems , can also come from the ways that we represent them , just only label quality . For me , this approach is new and potentially expend to other applications , besides image classification 2 . The experiment design is also quite comprehensive as it covers all potential perspectives and variations . 3.This inspiration of the idea to me is also quite natural and understandable , as for most of us , when recognizing an image , we express it not just in writing and can also in speech format . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : Although the proposed representations have shown better performance in image classification problem , with evidence to support its out-performed robustness to adversarial attack and data efficiency -- achieving comparable accuracy with less data in training , I would still suggest the authors to conduct the following studies to enhance the quality of the paper : 1 . It could be valuable to future investigate the inherent property that contributes to the improvement , besides high dimensionality and high entropy . 2.What \u2019 s the performance with high dimensional and high entropy label representations , comparing to text label , for other kind of the classification problems , such as NLP problems . 3.For speech label , in model evaluation , what \u2019 s the performance for the model , if we choose a speech to text process to obtain its ground truth , beside the two approaches mentioned in the paper -- \u201c nearest neighbor \u201d and a validated loss threshold . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Questions during rebuttal period : Please address and clarify the cons above", "rating": "7: Good paper, accept", "reply_text": "# # # # # BERT Attack Results : | ResNet32 | Epsilon 0 | Epsilon 0.05 | Epsilon 0.1 | Epsilon 0.15 | Epsilon 0.2 | Epsilon 0.25 | Epsilon 0.3 | |-| : -- : | : :| : -- : | : :| : -- : | : :| : -- : | | FSGM MEAN | 0.927733333 | 0.690766667 | 0.607433333 | 0.51736667 | 0.42313333 | 0.33553333 | 0.26746667 | | FSGM STD | 0.001625833 | 0.015631165 | 0.0345558 | 0.04923437 | 0.05716374 | 0.05364516 | 0.04588489 | | FSGM Targeted MEAN | 0.927733333 | 0.738366667 | 0.670866667 | 0.5776 | 0.46483333 | 0.36613333 | 0.2873 | | FSGM Targeted STD | 0.001625833 | 0.012159907 | 0.025550408 | 0.04388633 | 0.05841955 | 0.05822837 | 0.0491692 | | Iterative MEAN | 0.927733333 | 0.616066667 | 0.4877 | 0.40496667 | 0.34303333 | 0.2986 | 0.25896667 | | Iterative STD | 0.001625833 | 0.029737574 | 0.048071925 | 0.05809392 | 0.06387256 | 0.06849299 | 0.066176 | | Iterative Targeted MEAN | 0.927733333 | 0.711233333 | 0.631633333"}}