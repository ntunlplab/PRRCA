{"year": "2019", "forum": "SkfMWhAqYQ", "title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "decision": "Accept (Poster)", "meta_review": "This paper presents an approach that relies on DNNs and bags of features that are fed into them, towards object recognition.  The strength of the papers lie in the strong performance of these simple and interpretable models compared to more complex architectures.  The authors stress on the interpretability of the results that is indeed a strength of this paper.\n\nThere is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns.\n\nOverall, after the long discussion, there is enough consensus for this paper to be accepted to the conference.", "reviews": [{"review_id": "SkfMWhAqYQ-0", "review_text": "The idea of image classification based on patch-level deep feature in the BoF model has been studied extensively. Just list few of them: Wei et al. HCP: A Flexible CNN Framework for Multi-label Image Classification, IEEE TPAMI 2016 Tang et al. Deep Patch Learning for Weakly Supervised Object Classification and Discovery, Pattern Recognition 2017 Tang et al. Deep FisherNet for Object Classification, IEEE TNNLS Arandjelovi\u0107 et al. NetVLAD: CNN Architecture for Weakly Supervised Place Recognition, CVPR 2016 The above papers are not cited in this paper. There are some unique points. This work does not use RoIPooling layer and has results on ImageNet. But, the previous works use RoIPooling layer to save computations and works on scene understanding images, such as PASCAL. Besides, the paper uses the smallest patch among all the patch-based deep networks. It is interesting. I highly encourage the authors to finetune the ImageNet pre-trained BagNet on PASCAL VOC and compare to the previous patch-based deep networks. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for reviewing our paper . We would like to make a quick clarification right away , which we hope will change your assessment . All works you cite use non-linear BoF encodings on top of pretrained VGG ( or AlexNet ) features ; the effective patch size of individual features is thus large and will generally encompass the whole object of interest . In contrast , our BagNets are constrained to very small image patches ( much smaller than the typical object size in ImageNet ) , use no region proposals ( all patches are treated equally ) and employ a very simple and transparent average pooling of local features ( no non-linear dependence between features and regions ) . That \u2019 s why BagNets ( 1 ) substantially increase interpretability of the decision making process ( see e.g.heatmaps ) , ( 2 ) highlight what features and length-scales are necessary for object recognition and ( 3 ) shed light on the classification strategy followed by modern high performance CNNs . None of the cited papers addresses any of these contributions . PS : We do cite similar approaches in our paper , see first paragraph of related literature . We will add your references there ."}, {"review_id": "SkfMWhAqYQ-1", "review_text": "This paper suggests a novel and compact neural network architecture which uses the information within bag-of-words features. The proposed algorithm only uses the patch information independently and performs majority voting using independently classified patches. The proposed method provides the state-of-the-art prediction accuracy unexpectedly, and several additional experiments show the state-of-the-art neural networks mainly learn without association between information in different patches. The proposed algorithm is simple and does not provide completely new idea, but this paper has a clear contribution connecting the previous main idea of feature extraction, bag-of-words, and the prevailing blackbox algorithm, CNN. The results in the paper are worth to be shared in the community and need further investigated. The presented experiments look fair and reasonable to show the importance of the independent patch information (without association between them), and the presented experimental results show some state-of-the-art methods also perform with independent patch information. Comparison with attention models is necessary to compare the important patches obtained from conventional networks. ", "rating": "7: Good paper, accept", "reply_text": "Thanks a lot for appreciating our contribution ! > Comparison with attention models is necessary to compare the important patches obtained from conventional networks . In the paper ( section 4.3 ) we quantitatively show that the patches important to BagNets are also important for standard CNNs . Is that the direction you were thinking about ? If you have a different experiment in mind we would like to kindly ask you for more details ."}, {"review_id": "SkfMWhAqYQ-2", "review_text": "This is an experimental paper that investigates how spatial ordering of patches influences the classification performances of CNNs. To do so, the authors design CNNs close to ResNets that almost only consist in a simple cascade of 1x1 convolutions, obtaining relatively small receptive field. It is an interesting read, and I recommend it as a valuable contribution to ICLR, that might lead to nice future works. I have however several comments and questions, that I would like to be addressed. 1) First I think a reference is missing. Indeed, to my knowledge, it is not the first work to use this kind of techniques. Cf [1]. This does not alterate however the novelty of the approach. 2) \u00ab We construct a linear DNN-based BoF \u00bb : I do not like this formulation. Here, you assume that you build a ResNet-50 with 1x1 as a representation and have a last final linear layer as a classifier. One could also claim it is a ResNet-48 as a representation followed by 2 layers of 1x1 as a classifier. 3) \u00ab our proposed model architecture is simpler \u00bb this is very subjective because for instance the FV models are learned in a layer-wise fashion, which makes their learning procedure more interpretable because each layer objective is specified. Furthermore, analyzing these models is now equivalent to analyze a cascade of fully connected layers, which is not simple at all. 4) Again, the interpretability mentioned in Sec. 3 is in term of spatial localization, not mapping. I think it is important to make clear this consideration. Indeed, this work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs. 5) The graphic of the Appendix A is a bit misleading : it seems 13 downsampling are performed whereas it is not the case, because the first element of each group of block is actually only done once.(if I understood correctly) 6) I think the word feature is sometimes mis-used: sometimes it seems it can refer to a patch, sometimes to the code for a patch. (\u00ab Surprisingly, feature sizes assmall as 17 \u00d7 17 pixels \u00bb) I got also few questions: Q1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ? Q2 : Is there a batch normalization in the FC or a normalization? Did you try to threshold the heat maps before feeding them to the linear layer? I'm wondering indeed if the amplitude of those heatmaps is really key. Q3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ? Finally, I find very positive the amount of experiments to test the similarity with standard CNNs. Of course, it\u2019s far from being a formal proof, but I think it is a very nice first step. [1] Oyallon, Edouard, Eugene Belilovsky, and Sergey Zagoruyko. \"Scaling the scattering transform: Deep hybrid networks.\" International Conference on Computer Vision (ICCV). 2017.", "rating": "7: Good paper, accept", "reply_text": "Please excuse our late response and thanks for your insightful feedback and your positive assessment ! We are in the middle of the thresholding experiment you suggested . We report on the results later today or tomorrow and would like to respond to the rest of your comments and suggestions : 1 ) Reference to scattering network [ 1 ] That \u2019 s indeed an interesting and related reference with respect to spatially constrained network architectures that we \u2019 ll add to the manuscript . The scattering network extracts patches of size 14 x 14 pixels and employs an additional two-layer fully connected network ( or a ResNet-10 ) on top of those features . That unfortunately makes the spatial aggregation again harder to pinpoint ( compared to BagNets ) but the work is nonetheless an important precursor . We 'll add the reference to the manuscript . 2 ) \u00ab We construct a linear DNN-based BoF \u00bb Thanks for pointing this out , we have to sharpen the related definitions . For us , the * classifier * is the part of the model _after_ the spatial aggregation ( spatial average ) . The distinction of a linear vs a non-linear classifier is important because only the first is interchangeable with the spatial aggregation , which means that we can interpret the model as extracting evidence from each patch , which is then averaged across all patches . This guarantees that we can exactly attribute how important each patch is for the final model decision . This is not true if the classifier is non-linear . We will clarify this definition and its importance in the manuscript and hope that this sufficiently addresses your concern . 3 ) simplicity is subjective We agree that one should add a more specific qualifier on \u201c simpler \u201d and \u201c more interpretable \u201d as these terms can refer to different concepts . Thanks for pointing this out . What we mean is that the decision making process is more transparent : whereas CNNs take the whole image and somehow churn out a final label , the BagNets linearly accumulate evidence from very small patches to make a decision . This restricts the decision making to features of small size ( e.g.BagNets can not use shape ) , which makes it easier to understand how certain decisions have been reached ( in terms of which image parts have been used ) . We will clarify this in the manuscript . 4 ) \u201c this work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs \u201d In terms of the evidence extraction from local patches you are right : our paper has nothing to add here . However , from the perspective of the whole image the decision making is more transparent ( in terms of which image features are being used for classification ) than for general CNNs . In addition , the MLPs now only look at small image patches , which means that the input distribution has much lower entropy . This makes it potentially easier to analyse what evidence is extracted by the MLPs . We will add a clarifying sentence into the manuscript . 5 ) Network depiction in Appendix A Thanks for pointing this out , indeed it looks as if the down pooling is performed in each block whereas in reality it \u2019 s only used in the first . We \u2019 ll add an arrow with a description saying \u201c downsampling is only performed in the first block \u201d in each group . 6 ) Usage of word \u201c features \u201d Thanks for pointing this out , we \u2019 ll go through the manuscript and change the usage to \u201c image feature \u201d ( for small patches ) or \u201c feature embedding \u201d ( to refer to the feature vector extracted by the DNN ) . Q1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ? That \u2019 s an excellent question that we have not yet explored . We have some ideas in that direction ( unsupervised learning of low-level image features ) but no results to support or refute this idea . Q2 : Is there a batch normalization in the FC or a normalization ? Did you try to threshold the heat maps before feeding them to the linear layer ? I 'm wondering indeed if the amplitude of those heatmaps is really key . There is no normalisation between the average pooling and the linear classifier . We report back on the thresholding experiment today or tomorrow . Q3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ? That \u2019 s a good point , indeed that would be possible . One could simply cut an image into smaller parts ( e.g.into 128 x 128 patches that overlap by q pixels on the borders where q is the RF size of the BagNet ) , then run each through the BagNets on separate GPUs and then sum the output of the linear classifier ( before the softmax ) from each part/GPU ."}], "0": {"review_id": "SkfMWhAqYQ-0", "review_text": "The idea of image classification based on patch-level deep feature in the BoF model has been studied extensively. Just list few of them: Wei et al. HCP: A Flexible CNN Framework for Multi-label Image Classification, IEEE TPAMI 2016 Tang et al. Deep Patch Learning for Weakly Supervised Object Classification and Discovery, Pattern Recognition 2017 Tang et al. Deep FisherNet for Object Classification, IEEE TNNLS Arandjelovi\u0107 et al. NetVLAD: CNN Architecture for Weakly Supervised Place Recognition, CVPR 2016 The above papers are not cited in this paper. There are some unique points. This work does not use RoIPooling layer and has results on ImageNet. But, the previous works use RoIPooling layer to save computations and works on scene understanding images, such as PASCAL. Besides, the paper uses the smallest patch among all the patch-based deep networks. It is interesting. I highly encourage the authors to finetune the ImageNet pre-trained BagNet on PASCAL VOC and compare to the previous patch-based deep networks. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for reviewing our paper . We would like to make a quick clarification right away , which we hope will change your assessment . All works you cite use non-linear BoF encodings on top of pretrained VGG ( or AlexNet ) features ; the effective patch size of individual features is thus large and will generally encompass the whole object of interest . In contrast , our BagNets are constrained to very small image patches ( much smaller than the typical object size in ImageNet ) , use no region proposals ( all patches are treated equally ) and employ a very simple and transparent average pooling of local features ( no non-linear dependence between features and regions ) . That \u2019 s why BagNets ( 1 ) substantially increase interpretability of the decision making process ( see e.g.heatmaps ) , ( 2 ) highlight what features and length-scales are necessary for object recognition and ( 3 ) shed light on the classification strategy followed by modern high performance CNNs . None of the cited papers addresses any of these contributions . PS : We do cite similar approaches in our paper , see first paragraph of related literature . We will add your references there ."}, "1": {"review_id": "SkfMWhAqYQ-1", "review_text": "This paper suggests a novel and compact neural network architecture which uses the information within bag-of-words features. The proposed algorithm only uses the patch information independently and performs majority voting using independently classified patches. The proposed method provides the state-of-the-art prediction accuracy unexpectedly, and several additional experiments show the state-of-the-art neural networks mainly learn without association between information in different patches. The proposed algorithm is simple and does not provide completely new idea, but this paper has a clear contribution connecting the previous main idea of feature extraction, bag-of-words, and the prevailing blackbox algorithm, CNN. The results in the paper are worth to be shared in the community and need further investigated. The presented experiments look fair and reasonable to show the importance of the independent patch information (without association between them), and the presented experimental results show some state-of-the-art methods also perform with independent patch information. Comparison with attention models is necessary to compare the important patches obtained from conventional networks. ", "rating": "7: Good paper, accept", "reply_text": "Thanks a lot for appreciating our contribution ! > Comparison with attention models is necessary to compare the important patches obtained from conventional networks . In the paper ( section 4.3 ) we quantitatively show that the patches important to BagNets are also important for standard CNNs . Is that the direction you were thinking about ? If you have a different experiment in mind we would like to kindly ask you for more details ."}, "2": {"review_id": "SkfMWhAqYQ-2", "review_text": "This is an experimental paper that investigates how spatial ordering of patches influences the classification performances of CNNs. To do so, the authors design CNNs close to ResNets that almost only consist in a simple cascade of 1x1 convolutions, obtaining relatively small receptive field. It is an interesting read, and I recommend it as a valuable contribution to ICLR, that might lead to nice future works. I have however several comments and questions, that I would like to be addressed. 1) First I think a reference is missing. Indeed, to my knowledge, it is not the first work to use this kind of techniques. Cf [1]. This does not alterate however the novelty of the approach. 2) \u00ab We construct a linear DNN-based BoF \u00bb : I do not like this formulation. Here, you assume that you build a ResNet-50 with 1x1 as a representation and have a last final linear layer as a classifier. One could also claim it is a ResNet-48 as a representation followed by 2 layers of 1x1 as a classifier. 3) \u00ab our proposed model architecture is simpler \u00bb this is very subjective because for instance the FV models are learned in a layer-wise fashion, which makes their learning procedure more interpretable because each layer objective is specified. Furthermore, analyzing these models is now equivalent to analyze a cascade of fully connected layers, which is not simple at all. 4) Again, the interpretability mentioned in Sec. 3 is in term of spatial localization, not mapping. I think it is important to make clear this consideration. Indeed, this work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs. 5) The graphic of the Appendix A is a bit misleading : it seems 13 downsampling are performed whereas it is not the case, because the first element of each group of block is actually only done once.(if I understood correctly) 6) I think the word feature is sometimes mis-used: sometimes it seems it can refer to a patch, sometimes to the code for a patch. (\u00ab Surprisingly, feature sizes assmall as 17 \u00d7 17 pixels \u00bb) I got also few questions: Q1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ? Q2 : Is there a batch normalization in the FC or a normalization? Did you try to threshold the heat maps before feeding them to the linear layer? I'm wondering indeed if the amplitude of those heatmaps is really key. Q3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ? Finally, I find very positive the amount of experiments to test the similarity with standard CNNs. Of course, it\u2019s far from being a formal proof, but I think it is a very nice first step. [1] Oyallon, Edouard, Eugene Belilovsky, and Sergey Zagoruyko. \"Scaling the scattering transform: Deep hybrid networks.\" International Conference on Computer Vision (ICCV). 2017.", "rating": "7: Good paper, accept", "reply_text": "Please excuse our late response and thanks for your insightful feedback and your positive assessment ! We are in the middle of the thresholding experiment you suggested . We report on the results later today or tomorrow and would like to respond to the rest of your comments and suggestions : 1 ) Reference to scattering network [ 1 ] That \u2019 s indeed an interesting and related reference with respect to spatially constrained network architectures that we \u2019 ll add to the manuscript . The scattering network extracts patches of size 14 x 14 pixels and employs an additional two-layer fully connected network ( or a ResNet-10 ) on top of those features . That unfortunately makes the spatial aggregation again harder to pinpoint ( compared to BagNets ) but the work is nonetheless an important precursor . We 'll add the reference to the manuscript . 2 ) \u00ab We construct a linear DNN-based BoF \u00bb Thanks for pointing this out , we have to sharpen the related definitions . For us , the * classifier * is the part of the model _after_ the spatial aggregation ( spatial average ) . The distinction of a linear vs a non-linear classifier is important because only the first is interchangeable with the spatial aggregation , which means that we can interpret the model as extracting evidence from each patch , which is then averaged across all patches . This guarantees that we can exactly attribute how important each patch is for the final model decision . This is not true if the classifier is non-linear . We will clarify this definition and its importance in the manuscript and hope that this sufficiently addresses your concern . 3 ) simplicity is subjective We agree that one should add a more specific qualifier on \u201c simpler \u201d and \u201c more interpretable \u201d as these terms can refer to different concepts . Thanks for pointing this out . What we mean is that the decision making process is more transparent : whereas CNNs take the whole image and somehow churn out a final label , the BagNets linearly accumulate evidence from very small patches to make a decision . This restricts the decision making to features of small size ( e.g.BagNets can not use shape ) , which makes it easier to understand how certain decisions have been reached ( in terms of which image parts have been used ) . We will clarify this in the manuscript . 4 ) \u201c this work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs \u201d In terms of the evidence extraction from local patches you are right : our paper has nothing to add here . However , from the perspective of the whole image the decision making is more transparent ( in terms of which image features are being used for classification ) than for general CNNs . In addition , the MLPs now only look at small image patches , which means that the input distribution has much lower entropy . This makes it potentially easier to analyse what evidence is extracted by the MLPs . We will add a clarifying sentence into the manuscript . 5 ) Network depiction in Appendix A Thanks for pointing this out , indeed it looks as if the down pooling is performed in each block whereas in reality it \u2019 s only used in the first . We \u2019 ll add an arrow with a description saying \u201c downsampling is only performed in the first block \u201d in each group . 6 ) Usage of word \u201c features \u201d Thanks for pointing this out , we \u2019 ll go through the manuscript and change the usage to \u201c image feature \u201d ( for small patches ) or \u201c feature embedding \u201d ( to refer to the feature vector extracted by the DNN ) . Q1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ? That \u2019 s an excellent question that we have not yet explored . We have some ideas in that direction ( unsupervised learning of low-level image features ) but no results to support or refute this idea . Q2 : Is there a batch normalization in the FC or a normalization ? Did you try to threshold the heat maps before feeding them to the linear layer ? I 'm wondering indeed if the amplitude of those heatmaps is really key . There is no normalisation between the average pooling and the linear classifier . We report back on the thresholding experiment today or tomorrow . Q3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ? That \u2019 s a good point , indeed that would be possible . One could simply cut an image into smaller parts ( e.g.into 128 x 128 patches that overlap by q pixels on the borders where q is the RF size of the BagNet ) , then run each through the BagNets on separate GPUs and then sum the output of the linear classifier ( before the softmax ) from each part/GPU ."}}