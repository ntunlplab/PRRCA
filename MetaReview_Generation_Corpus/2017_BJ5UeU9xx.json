{"year": "2017", "forum": "BJ5UeU9xx", "title": "Visualizing Deep Neural Network Decisions: Prediction Difference Analysis", "decision": "Accept (Poster)", "meta_review": "Reviewers felt the paper was clearly written with necessary details given, leading to a paper that was pleasant to read. The differences with prior art raised by one of the reviewers were adequately addressed by the authors in a revision. The paper presents results on both ImageNet and medical imagery, an aspect of the paper that was appreciated by reviewers.", "reviews": [{"review_id": "BJ5UeU9xx-0", "review_text": "The paper presents a theoretically well motivated for visualizing what parts of the input feature map are responsible for the output decision. The key insight is that features that maximally change the output and are simultaneously more unpredictable from other features are the most important ones. Most previous work has focused on finding features that maximally change the output without accounting for their predictability from other features. Authors build upon ideas presented in the work of Robnik-\u0160ikonja & Kononenko (2008). The results indicate that the proposed visualization mechanism based on modeling conditional distribution identifies more salient regions as compared to a mechanism based on modeling marginal distribution. I like that authors have presented visualization results for a single image across multiple networks and multiple classes. There results show that the proposed method indeed picks up on class-discriminative features. Authors have provided a link to visualizations for a random sample of images in a comment \u2013 I encourage the authors to include this in the appendix of the paper. My one concern with the paper is \u2013 Zeiler et al., proposed a visualization method by greying small square regions in the image. This is similar to computing the visualization using the marginal distribution. Authors compute the marginal visualization using 10 samples, however in the limit of infinite samples the image region would be gray. The conditional distribution is computed using a normal distribution that provides some regularization and therefore estimating the conditional and marginal distributions using 10 samples each is not justified. I would like to see the comparison when grey image patches (akin to Zeiler et al.) are used for visualization against the approach based on the conditional distribution. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your review . The method of Zeiler et al.is indeed similar to our method in that they also remove information in of the image ( by occluding parts of it with a grey patch ) to evaluate how important image regions are ( by looking at the correct class probability as a function of the grey patch , whereas we look at the difference in output probabilities ) . However we think that when using this grey patch , there is not only information removed/occluded from the image , but also new information introduced - a grey patch looks like * something * to the classifier ( e.g. , the sky on a rainy day , the carrosserie of a grey car ) and we therefore think that by just replacing pixels with their mean value ( which is approx grey for ImageNet ) could bias the results depending on what the classifier learned about which images usually contain grey areas . The output of the classifier would therefore always shift towards the classes that frequently contain a lot of grey . By instead using patches from all classes ( like in the marginal distribution ) and averaging the class scores , this bias can be removed ( and even further by using the conditional distribution ) . We ran some more experiments , and you can see the results when using a grey patch instead of conditional sampling here : https : //www.dropbox.com/s/af5n8frrn0g0mh6/comparison_graySquare.png For many examples the difference is not very large , but for example in the `` dam '' or `` scuba diver '' image we can see how the method assigns too much relevance to rather uniform ( and uninformative ) regions like the sky . Given this and our theoretical reasoning , we believe that using conditional sampling is in general more sensible . However , an interesting subject of future research is to use more sophisticated models for conditional sampling , which might also include more information from the whole image ( as another reviewer suggested ) . We believe that unimportant regions that are easily predictable by other ( neighbouring ) pixels could then be downweighed even more which would lead to even more interpretable results . The reason we used 10 samples for both marginal and conditional sampling were that on the one hand we did n't see a significant difference when using more samples , and also we wanted to have comparable computation times ( conditional sampling takes just slightly longer due to the sampling procedure ) . Also , marginal sampling in the limit does not correspond to just using one sample of the mean pixel value ( i.e. , approx grey ) , since the expectation can not just be pushed into the computation of the class probabilities . We have included the visualisations for random images ( comparing to the method of Simonyan et al . ) in the appendix of a revised version of the paper ."}, {"review_id": "BJ5UeU9xx-1", "review_text": "The authors propose a way to visualize which areas of an image provide mostly influence a certain DNN response mostly. They apply some very elegant and convincing improvements to the basic method by Robnik-Sikonja and Konononko from 2008 to DNNs, thus improving it's analysis and making it usable for images and DNNs. The authors provide a very thorough analysis of their methods and show very convincing examples (which they however handpicked. It would be very nice to have maybe at least one figure showing the analysis on e.g. 24 random picks from ImageNet). One thing I would like to see is how their method compares to some other methods they mention in the introduction (like gradient-based ones or deconvolution based ones). They paper is very clearly written, all necessary details are given and the paper is very nice to read. Alltogether: The problem of understanding how DNNs function and how they draw their conclusions is discussed a lot. The author's method provides a clear contribution that can lead to further progress in this field (E.g. I like figure 8 showing how AlexNet, GoogLeNet and VGG differ in where they collect evidence from). I can think of several potential applications of the method and therefore consider it of high significance. Update: The authors did a great job of adopting all of my suggestions. Therefore I improve the rating from 8 to 9.", "rating": "9: Top 15% of accepted papers, strong accept", "reply_text": "Thank you very much for your review . We understand that for the reader it would make a convincing point to see results on random picks , and therefore ran additional experiments on 34 randomly selected ImageNet images . We also added the results of the method from Simonyan et al . ( 2013 ) for direct comparison . Please see https : //www.dropbox.com/s/0eoe1krqg4m6gv8/results_random_legend.png for the results ( we will add them to the appendix of the paper in a revised version ) . Further , we made our code publicly available , see https : //github.com/lmzintgraf/DeepVis-PredDiff ."}, {"review_id": "BJ5UeU9xx-2", "review_text": "The authors of this work propose an interesting approach to visualizing the predictions made by a deep neural network. The manuscript is well written is provides good insight into the problem. I also appreciate the application to medical images, as simply illustrating the point on ImageNet isn't interesting enough. I do have some questions and comments. 1. As the authors correctly point out in 3.1, approximating the conditional probability of a feature x_i by the marginal distribution p(x_i) is not realistic. They advocate for translation invariance, i.e. the position of the pixel in the image shouldn't affect the probability, and suggest that the pixels appearance depends on the small neighborhood around it. However, it is well known that global context makes an big impact on the semantics of pixels. In \"Objects in Contexts\", authors show that a given neighborhood of pixels can take different semantic meanings based on the global context in the image. In the context of deep neural networks, works such as \"ParseNet\" also illustrate the importance of global context on the spatial label distribution. This does not necessarily invalidate this approach, but is a significant limitation. It would be great if the authors provided a modification to (4) and empirically verified the change. 2. Figure 7 shows the distribution over top 3 predictions before and after softmax. It is expected that even fairly uniform distributions will transform toward delta functions after softmax normalization. Is there an additional insight here? 4. Finally, in 4.1, the authors state that it takes 30 minutes to analyze a single image with GooLeNet on a GPU? Why is this so computationally expensive? Such complexity seems to make the algorithm impractical and analyzing datasets of statistical relevance seems prohibitive. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your review and input . We are going to address the comments/questions below . -- -- -- -- -- -- -- -- -- -- -- -- -- - 1 . Ideally , we would condition on the full image to sample individual pixels , i.e. , p ( x_i | x_\\i ) . Since it is computationally infeasible to model such a probability distribution , we resort to an approximation and in this case decided to make the simplification of assuming translation invariance ( equation 4 ) and conditioning only on a small neighborhood around the pixel . However , as the reviewer points out , the pixel probability could also depend on the context of the larger image ( an illustrative example in `` Objects in Contexts '' is that a yellow blob can be a lemon or a tennis ball , depending on the scene in the image ) . We still think that given a small enough patch ( k in alg.1 ) that is marginalized , the pixel values ( which are somewhat but not entirely coupled to their semantic meaning ) are mostly dependent on their neighborhood . Having said that , we can try to think of ways to modify ( 4 ) to get an even better approximation by using a conditional distribution that takes more information about the whole image into account . This does not necessarily have to be all the raw pixels , but could be ( as pointed at by the reviewer ) more semantic information , like scene labels . In fact , for the MRI scans we also performed experiments where we split up the 3D image into a 20x20x20 grid and also provide the Gaussian distribution with the index in that grid , i.e. , instead of ( 4 ) we use p ( x_i | x^_\\i , grid_index ) , since the distribution of pixel values in the special case of MRI scans does depend on spacial location as well . We found that this slightly improves the interpretability of the results . It would be an interesting next step to analyze in more detail how a modification of ( 4 ) , or a stronger probabilistic model , influences the results . -- -- -- -- -- -- -- -- -- -- -- -- -- - 2 . What we observed in our experiments is that usually the explanations for the first and second highest classes after softmax are pretty much complementary ( i.e. , what speaks for one class does not speak for the other and vice-versa ) and that the prediction difference for the lower classes has a much lower magnitude and is also less visually expressive . As the reviewer points out , the softmax tends to enlarge differences in its inputs , so we expect that for a given pixel , the intensities of the output across classes is close to a 1-hot-vector . We think this explains why when having many classes ( 1000 for the ImageNet dataset ) for the majority of low-scoring output classes , the visualizations are not very meaningful . Still , for the top 2-3 scoring classes the outputs of the softmax are sensitive enough to small changes in input space , and Figure 7 nicely illustrates how the classifier uses the softmax to weigh the top scoring classes against each other , and ultimately decides for one of the classes ( even though they are very similar , like different dog breeds ) . -- -- -- -- -- -- -- -- -- -- -- -- -- - 4 . Given our default settings , for each ImageNet image , we have to roughly make 227x227x10 ( around 17,000 ) evaluations - i.e. , for each patch ( ~227x227 patches ) take samples ( 10 ) from the multivariate Gaussian and forward pass the image through the network ( it 's a bit less than this , depending on the actual input size of the network and the k in algorithm 1 ) . Analyzing one image therefore depends strongly on how fast we can sample pixel values , and even more on how fast we can evaluate the classifier . We agree with the reviewer that for some datasets , this makes this approach less practical than other methods . E.g. , the sensitivity map from Simonyan et al . ( 2013 ) requires only a single backward pass through the network and is therefore very fast compared to our method . However we also believe that there are many cases where a longer waiting time is worth having a more expressive explanation ( given that we can provide signed information w.r.t.the support for/against single classes compared to the sensitivity map ) . For example in a medical setting we believe it would be acceptable to even wait 1-2 days for a very insightful analysis and explanation of the individual patient 's data ( e.g. , an MRI scan ) . For datasets like ImageNet , other methods are generally more practical for a quick analysis ( or live analysis of videos like in Yosinski 's deepvis toolbox ) . Still , compared to the training time these DCNNs usually take we think that it might be feasible to use our method to get additional insight into how the DCNN makes decisions ( e.g. , let it run for a week and have around 300 images analyzed ) ."}], "0": {"review_id": "BJ5UeU9xx-0", "review_text": "The paper presents a theoretically well motivated for visualizing what parts of the input feature map are responsible for the output decision. The key insight is that features that maximally change the output and are simultaneously more unpredictable from other features are the most important ones. Most previous work has focused on finding features that maximally change the output without accounting for their predictability from other features. Authors build upon ideas presented in the work of Robnik-\u0160ikonja & Kononenko (2008). The results indicate that the proposed visualization mechanism based on modeling conditional distribution identifies more salient regions as compared to a mechanism based on modeling marginal distribution. I like that authors have presented visualization results for a single image across multiple networks and multiple classes. There results show that the proposed method indeed picks up on class-discriminative features. Authors have provided a link to visualizations for a random sample of images in a comment \u2013 I encourage the authors to include this in the appendix of the paper. My one concern with the paper is \u2013 Zeiler et al., proposed a visualization method by greying small square regions in the image. This is similar to computing the visualization using the marginal distribution. Authors compute the marginal visualization using 10 samples, however in the limit of infinite samples the image region would be gray. The conditional distribution is computed using a normal distribution that provides some regularization and therefore estimating the conditional and marginal distributions using 10 samples each is not justified. I would like to see the comparison when grey image patches (akin to Zeiler et al.) are used for visualization against the approach based on the conditional distribution. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your review . The method of Zeiler et al.is indeed similar to our method in that they also remove information in of the image ( by occluding parts of it with a grey patch ) to evaluate how important image regions are ( by looking at the correct class probability as a function of the grey patch , whereas we look at the difference in output probabilities ) . However we think that when using this grey patch , there is not only information removed/occluded from the image , but also new information introduced - a grey patch looks like * something * to the classifier ( e.g. , the sky on a rainy day , the carrosserie of a grey car ) and we therefore think that by just replacing pixels with their mean value ( which is approx grey for ImageNet ) could bias the results depending on what the classifier learned about which images usually contain grey areas . The output of the classifier would therefore always shift towards the classes that frequently contain a lot of grey . By instead using patches from all classes ( like in the marginal distribution ) and averaging the class scores , this bias can be removed ( and even further by using the conditional distribution ) . We ran some more experiments , and you can see the results when using a grey patch instead of conditional sampling here : https : //www.dropbox.com/s/af5n8frrn0g0mh6/comparison_graySquare.png For many examples the difference is not very large , but for example in the `` dam '' or `` scuba diver '' image we can see how the method assigns too much relevance to rather uniform ( and uninformative ) regions like the sky . Given this and our theoretical reasoning , we believe that using conditional sampling is in general more sensible . However , an interesting subject of future research is to use more sophisticated models for conditional sampling , which might also include more information from the whole image ( as another reviewer suggested ) . We believe that unimportant regions that are easily predictable by other ( neighbouring ) pixels could then be downweighed even more which would lead to even more interpretable results . The reason we used 10 samples for both marginal and conditional sampling were that on the one hand we did n't see a significant difference when using more samples , and also we wanted to have comparable computation times ( conditional sampling takes just slightly longer due to the sampling procedure ) . Also , marginal sampling in the limit does not correspond to just using one sample of the mean pixel value ( i.e. , approx grey ) , since the expectation can not just be pushed into the computation of the class probabilities . We have included the visualisations for random images ( comparing to the method of Simonyan et al . ) in the appendix of a revised version of the paper ."}, "1": {"review_id": "BJ5UeU9xx-1", "review_text": "The authors propose a way to visualize which areas of an image provide mostly influence a certain DNN response mostly. They apply some very elegant and convincing improvements to the basic method by Robnik-Sikonja and Konononko from 2008 to DNNs, thus improving it's analysis and making it usable for images and DNNs. The authors provide a very thorough analysis of their methods and show very convincing examples (which they however handpicked. It would be very nice to have maybe at least one figure showing the analysis on e.g. 24 random picks from ImageNet). One thing I would like to see is how their method compares to some other methods they mention in the introduction (like gradient-based ones or deconvolution based ones). They paper is very clearly written, all necessary details are given and the paper is very nice to read. Alltogether: The problem of understanding how DNNs function and how they draw their conclusions is discussed a lot. The author's method provides a clear contribution that can lead to further progress in this field (E.g. I like figure 8 showing how AlexNet, GoogLeNet and VGG differ in where they collect evidence from). I can think of several potential applications of the method and therefore consider it of high significance. Update: The authors did a great job of adopting all of my suggestions. Therefore I improve the rating from 8 to 9.", "rating": "9: Top 15% of accepted papers, strong accept", "reply_text": "Thank you very much for your review . We understand that for the reader it would make a convincing point to see results on random picks , and therefore ran additional experiments on 34 randomly selected ImageNet images . We also added the results of the method from Simonyan et al . ( 2013 ) for direct comparison . Please see https : //www.dropbox.com/s/0eoe1krqg4m6gv8/results_random_legend.png for the results ( we will add them to the appendix of the paper in a revised version ) . Further , we made our code publicly available , see https : //github.com/lmzintgraf/DeepVis-PredDiff ."}, "2": {"review_id": "BJ5UeU9xx-2", "review_text": "The authors of this work propose an interesting approach to visualizing the predictions made by a deep neural network. The manuscript is well written is provides good insight into the problem. I also appreciate the application to medical images, as simply illustrating the point on ImageNet isn't interesting enough. I do have some questions and comments. 1. As the authors correctly point out in 3.1, approximating the conditional probability of a feature x_i by the marginal distribution p(x_i) is not realistic. They advocate for translation invariance, i.e. the position of the pixel in the image shouldn't affect the probability, and suggest that the pixels appearance depends on the small neighborhood around it. However, it is well known that global context makes an big impact on the semantics of pixels. In \"Objects in Contexts\", authors show that a given neighborhood of pixels can take different semantic meanings based on the global context in the image. In the context of deep neural networks, works such as \"ParseNet\" also illustrate the importance of global context on the spatial label distribution. This does not necessarily invalidate this approach, but is a significant limitation. It would be great if the authors provided a modification to (4) and empirically verified the change. 2. Figure 7 shows the distribution over top 3 predictions before and after softmax. It is expected that even fairly uniform distributions will transform toward delta functions after softmax normalization. Is there an additional insight here? 4. Finally, in 4.1, the authors state that it takes 30 minutes to analyze a single image with GooLeNet on a GPU? Why is this so computationally expensive? Such complexity seems to make the algorithm impractical and analyzing datasets of statistical relevance seems prohibitive. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for your review and input . We are going to address the comments/questions below . -- -- -- -- -- -- -- -- -- -- -- -- -- - 1 . Ideally , we would condition on the full image to sample individual pixels , i.e. , p ( x_i | x_\\i ) . Since it is computationally infeasible to model such a probability distribution , we resort to an approximation and in this case decided to make the simplification of assuming translation invariance ( equation 4 ) and conditioning only on a small neighborhood around the pixel . However , as the reviewer points out , the pixel probability could also depend on the context of the larger image ( an illustrative example in `` Objects in Contexts '' is that a yellow blob can be a lemon or a tennis ball , depending on the scene in the image ) . We still think that given a small enough patch ( k in alg.1 ) that is marginalized , the pixel values ( which are somewhat but not entirely coupled to their semantic meaning ) are mostly dependent on their neighborhood . Having said that , we can try to think of ways to modify ( 4 ) to get an even better approximation by using a conditional distribution that takes more information about the whole image into account . This does not necessarily have to be all the raw pixels , but could be ( as pointed at by the reviewer ) more semantic information , like scene labels . In fact , for the MRI scans we also performed experiments where we split up the 3D image into a 20x20x20 grid and also provide the Gaussian distribution with the index in that grid , i.e. , instead of ( 4 ) we use p ( x_i | x^_\\i , grid_index ) , since the distribution of pixel values in the special case of MRI scans does depend on spacial location as well . We found that this slightly improves the interpretability of the results . It would be an interesting next step to analyze in more detail how a modification of ( 4 ) , or a stronger probabilistic model , influences the results . -- -- -- -- -- -- -- -- -- -- -- -- -- - 2 . What we observed in our experiments is that usually the explanations for the first and second highest classes after softmax are pretty much complementary ( i.e. , what speaks for one class does not speak for the other and vice-versa ) and that the prediction difference for the lower classes has a much lower magnitude and is also less visually expressive . As the reviewer points out , the softmax tends to enlarge differences in its inputs , so we expect that for a given pixel , the intensities of the output across classes is close to a 1-hot-vector . We think this explains why when having many classes ( 1000 for the ImageNet dataset ) for the majority of low-scoring output classes , the visualizations are not very meaningful . Still , for the top 2-3 scoring classes the outputs of the softmax are sensitive enough to small changes in input space , and Figure 7 nicely illustrates how the classifier uses the softmax to weigh the top scoring classes against each other , and ultimately decides for one of the classes ( even though they are very similar , like different dog breeds ) . -- -- -- -- -- -- -- -- -- -- -- -- -- - 4 . Given our default settings , for each ImageNet image , we have to roughly make 227x227x10 ( around 17,000 ) evaluations - i.e. , for each patch ( ~227x227 patches ) take samples ( 10 ) from the multivariate Gaussian and forward pass the image through the network ( it 's a bit less than this , depending on the actual input size of the network and the k in algorithm 1 ) . Analyzing one image therefore depends strongly on how fast we can sample pixel values , and even more on how fast we can evaluate the classifier . We agree with the reviewer that for some datasets , this makes this approach less practical than other methods . E.g. , the sensitivity map from Simonyan et al . ( 2013 ) requires only a single backward pass through the network and is therefore very fast compared to our method . However we also believe that there are many cases where a longer waiting time is worth having a more expressive explanation ( given that we can provide signed information w.r.t.the support for/against single classes compared to the sensitivity map ) . For example in a medical setting we believe it would be acceptable to even wait 1-2 days for a very insightful analysis and explanation of the individual patient 's data ( e.g. , an MRI scan ) . For datasets like ImageNet , other methods are generally more practical for a quick analysis ( or live analysis of videos like in Yosinski 's deepvis toolbox ) . Still , compared to the training time these DCNNs usually take we think that it might be feasible to use our method to get additional insight into how the DCNN makes decisions ( e.g. , let it run for a week and have around 300 images analyzed ) ."}}