{"year": "2021", "forum": "CLYe1Yke1r", "title": "Box-To-Box Transformation for Modeling Joint Hierarchies", "decision": "Reject", "meta_review": "The paper is concerned with modeling multi-relational data with joint hierarchical structure. For this purpose, the authors extend box embeddings to multi-relational settings, supporting the modeling of cross-hierarchy edges and generalizing from a subset of the transitive reduction. The reviewers highlight that the paper is, overall, well-written and organized, relevant to the ICLR community, and that the proposed method offers promising experimental results. Furthermore, the author's rebuttal clarified some concerns of the initial reviews (e.g., relation to GumbelBox, comparison to additional baselines etc.) and improved the manuscript.\n\nHowever, after rebuttal there exist still concerns regarding the current version. Reviewers raised concerns regarding novelty, clarity, and the empirical evaluation (importantly modeling more than 2 relations; it would also be good to understand more clearly why some of the newly added multi-relational hyperbolic baselines perform worse than uni-relational Poincare embeddings). While the paper and the proposed method clearly have promise, I agree with reviewers that the manuscript would require an additional revision to clarify these points. Given the positive aspects of the paper, I'd strongly encourage the authors to revise and resubmit their work given this feedback.", "reviews": [{"review_id": "CLYe1Yke1r-0", "review_text": "This work proposes to model multiple hierarchical relations using box embeddings , motivated by the natural transitivity property of the containment between regions in region-based representations . The proposed model is evaluated on a dataset containing two relations ( is-a and has-part ) . Although the proposed model shows promise by outperforming several baselines on the above mentioned dataset , I believe that the paper is not ready for publication in its current form , mainly due to ( i ) missing comparison to the highly relevant line of work on hyperbolic embeddings of hierarchical multi-relational data ; and ( ii ) lacking additional experiments on a dataset with more than 2 relations . Detailed comments and questions for the authors : Sec.2 1.I find the claim that `` Modeling joint hierarchies is not quite the same as knowledge base completion . '' to be unsubstantiated . This is true to an extent , since the ultimate goal of KB completion is inferring which other facts are true based on existing ones . However , to achieve this goal , KG completion models need to learn entity and relation representations which capture various properties of entities ( e.g.semantics ) and relations ( e.g.transitivity , symmetry , etc . ) , which is very similar to the main idea of this work . 2.A whole line of very relevant work on hyperbolic embeddings of hierarchical relations in knowledge bases is missing [ 1 , 2 ] . Sec.3\\ If I understood Definition 2 correctly , the meet ( i.e.union ) of two boxes will be another box which in most cases contains an area that is not part of either boxes ( since a union of two boxes is not necessarily a box ) . Does n't this introduce errors into box embeddings which increase with increasing the dimensionality of the embeddings ? Sec.4\\ It is not clear to me why the lack of a transformation on f_1 ( b ) encourages the containment in figure 1 . Could you please explain this point further ? Sec.5 1.While the achieved results seem impressive , as mentioned above , a highly relevant comparison to [ 1 ] and [ 2 ] is missing . Both missing works are embedding models that represent multiple simultaneous hierarchies in hyperbolic space and where entity embeddings are shared across relations , which should lead to better generalisation on missing edges ( as claimed by the authors ) . 2.The authors evaluate the proposed model on a single dataset with only 2 relations . The proposed model should be evaluated on at least one more dataset , e.g.WN18RR [ 3 ] , since [ 1 ] show several relations in that dataset to be hierarchical . 3.I 'm surprised that the improvement over the TWO-BOX model is lower when testing for generalisation capability ( 5 % ) than in the original setup ( 8.5 % ) , given the original premise that the proposed model should benefit from sharing information across hierarchies . 4.It would be nice to see a visualisation of the learned embeddings . Minor comments : \\ Background section should be made shorter , especially the part regarding the probabilistic box model training , which is not that relevant to the overall goal of this work . This space could be used for additional experiments proposed above . [ 1 ] Balazevic et al.Multi-relational Poincar\u00e9 Graph Embeddings , NeurIPS 2019\\ [ 2 ] Chami et al.Low-Dimensional Hyperbolic Knowledge Graph Embeddings , ACL 2020\\ [ 3 ] Dettmers et al.Convolutional 2D Knowledge Graph Embeddings , AAAI 2018", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your detailed comments , we will address them invidividually below . Sec 2 : 1.We agree that KB completion often requires modeling hierarchical relations , and moreover we evaluate KB completion models as our baselines for this task . Our intent was not to say they are entirely unrelated , but rather to simply point out the differences , which , as you point out , are mostly in the amount of emphasis on hierarchical relations and modeling goals . In short , we believe we are essentially in agreement on this point , and have attempted to clarify the wording of this in the paper . 2.Thank you for suggesting the hyperbolic embeddings for multi relational knowledge bases . We have added them to the related work section , and also evaluated them as baselines . ( Also discussed again below . ) Sec 3 : As you point out , the meet is not actually the union , it is the smallest containing box , however ( 1 ) the meet operation serves primarily to justify the theoretical properties of the box as a lattice , ( 2 ) we do not directly train or evaluate using the meet operation , as it is not needed for our queries . That being said , for a well-trained model of hierarchies , the meet is still meaningful , as the meet of a node and one of it \u2019 s descendents would simply be the node itself , and the meet of any two arbitrary nodes will provide the smallest containing box which , itself , is contained in the closest common ancestor node . Sec 4 : We have updated the image and explanation . The lack of a transformation on f_1 ( b ) means that the transitive relations present in the IsA hierarchy interact exactly as desired with the HasPart hierarchy to encourage the composition edges . For example , since Dove is contained in Bird , if Bird is contained in HasPart-Wing , then Dove will also be contained in HasPart-Wing . A transformation on f_1 ( b ) would add flexibility to the model but would no longer guarantee these compositional edges . Furthermore , if we think of the Bird box as representative of \u201c all things which are birds \u201d and the HasPart-Wing box as \u201c all things which have wings \u201d , then we don \u2019 t want or need an additional transformation on the Bird box in this scenario , as \u201c all things which are birds \u201d is a subset of \u201c all things which have wings \u201d . Sec 5 : 1.We have run additional experiments using MuRP [ 1 ] , RotH , and AttH [ 2 ] , and updated Table 2 and 3 with the results . We observe that the RotH and AttH models were able to learn the joint hierarchy to some extent , however , their generalisation performance is poor . We are also running RotE ( the euclidean embedding version of the RotH ) to investigate how much the inductive bias of the hyperbolic embeddings is helping in this task . 2.The hierarchical relationships in WN18RR are member_meronym , has_part , instance_hypernym , and hypernym , which are already present in our dataset ( member_meronym and has_part are both HasPart , instance_hypernym and hypernym are IsA ) . The other dominant relationships are _derivationally_related_form , _verb_group , and _similar_to , which are symmetric in nature . Furthermore , more than 90 % of the evaluation data coming from these relations have a reverse edge present in the training data , which makes modeling these relations trivial [ 1 ] . Most of the models achieve 0.93 MRR performance on this subset , including our method that has no inducative bias towards modelling symmetry . Removing this trivial symmetric subset and focusing exclusively on hierarchical data in the training split WN18RR yields a large number of connected components , as opposed to a deep hierarchy , and thus is not suitable to our goals of assessing the ability of a model to handle hierarchical relations . [ 1 ] Pezeshkpour et.at . Revisiting Evaluation of Knowledge Base Completion Models , AKBC 2020 . 3.In the overfitting task , we train on the whole transitive reduction and predict the performance of the composite edges . However , in the generalisation task we provide a subset of the hierarchies as training data and try to predict on the composition edges and missing edges as well . Thus these numbers are not a direct indication of the generalization gap since the training data is different for these two settings . For this reason , we study the generalization performance for different parts of the dataset in detail in section 5.5 . 4.We are generating a visualization of the learned embeddings and will include it in the paper shortly ."}, {"review_id": "CLYe1Yke1r-1", "review_text": "The paper focuses on modeling multiple hierarchical relations on a heterogenous graph . The task \u201c modeling joint hierarchies \u201d is essentially trying to infer whether a given pair of entities has a hierarchical connection especially when there exists multiple hierarchical relations ( 2 in the paper ) , and missing links . The paper proposes to embed entities using boxes whose endpoints follow the Gumbel distribution . Given there exists two hierarchical relations , the paper transforms the box of one entity under relation 1 to the box of the entity under relation 2 with a parameterized linear function . This is in contrast to previous work that parameterized the box of two relations using separate independent parameters . The model seems sound , however I have two major concerns . ( 1 ) I do not think the model is motivated well , especially on why the model uses Gumbel distribution to parameterize the box . ( 2 ) The paper has no introduction how they train the model and use it for inference , what is the loss ? This makes it hard to evaluate the correctness of the model . I am very satisfied with the extensive experiments the paper has conducted . They include many strong baselines including the order embeddings , hyperbolic embeddings and even some KG embeddings . The results on the KG embeddings clearly show that their methods work much better in this ( a little specific ) hierarchical relation modeling setting . The paper also introduces a new missing-edge setting , where they show that joint modeling achieves better generalization than independent parameters . Some detailed questions are listed below . 1.The related work states the difference between modeling hierarchies and knowledge base completion , however , it lacks discussion how their Gumbel box is different from previous box embedding methods ( this should be added in the second paragraph ) . I understand the difference between the Gumbel box and the Two-box model , namely the Two-box model learns independent parameters . However , I did not find the discussion on the connection between the Gumbel box and hard/smooth box . Why can not we apply the same transformation idea to previous hard and smoothed box embeddings so that they can also model joint hierarchies without optimization issues ? Why is Gumbel distribution special and useful in parameterizing the boxes and modeling hierarchies ? 2.The paper has some vague sentences like \u201c the authors demonstrate that this method of training boxes leads to better representation of trees thus we will use this Gumbel box approach in our setting. \u201d and \u201c since gumbel boxes effectively model hierarchies , we would like to benefit from the inductive bias of this model for intra-relation edges and thus we seek to learn a function ... \u201d , but what is the inductive bias of Gumbel ? It \u2019 s better to clearly state it . 3.The paper lacks a short discussion and introduction to the Gumbel distribution in the background section , especially on the parameters \\mu and \\beta . 4.As defined in Eq.3 , the meet of two boxes may include some blank space that does not belong to the input boxes , do you think this will have any issues , especially when the two input boxes are far away from each other ? 5.Sec 4.1 , first paragraph , \u201c $ ( a \\leq_1 b ) \\wedge ( b \\leq_2 c ) \\to ( a \\leq_2 b ) $ \u201d is wrong . Bird has part Wing , and Wing is an Appendage , but Bird is not a Wing . 6.Sec 4.1 , end of page 4 , \u201c To simultaneously model a second relation , we ... \u201d , so the model can only model two hierarchical relations ? If so , I think it is a little limited and can the model provide a way to generalize beyond two hierarchical relations ? 7.Sec 4.1 , \u201c the free parameters are $ \\mu_i $ and $ \\Delta_i $ \u201d , why does the model not learn $ \\beta $ ? 8.As in Eq.11 and 12 , the transformation is a rather simple linear transformation , have you tried something that is more complex , e.g.a MLP ? 9.I am also confused by Remark 1 and Eq.8.For Bird , there should be two boxes where one represents the IsA relation and the other represents the HasPart relation , right ? Then in Figure 1 , why is the IsA-Bird box inside the HasPart-Wing box , I think it should be the HasPart-Bird box inside the HasPart-Wing box . 10.The paper does not introduce how to train the model or even how to make predictions during inference in Sec 4 . I understand the page limit but these two aspects are essential to a machine learning model . 11.What is the difference between the two-box model and the order embeddings in the experiments ? I assume if you apply the order embeddings to this multi-hierarchical relation setup , then it is the same as the two-box model ? 12.I am curious about the performance of the proposed model in an imbalanced dataset ( as introduced in Li et al.ICLR 2019 ) , where the ratio of positive and negative is 1:10 ? minors : The paper does not have grammar mistakes and here are some minor points . 1.Make it explicit in the introduction that the \u201c Two-Box Model \u201d is referred to Patel et al . ( 2020 ) 2.The definition of box lattice model is not self-contained in Eq.1 , what is $ x_i $ and $ x^i $ ? I guess it is the two end points of the box in one dimension . Better to state it clearly . 3.Sec 3.3 , \u201c For example , as shown in 1 , based on\u2026 \u201d - > \u201c For example , as shown in Figure 1 , .. \u201d", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you very much for your detailed comments , we have addressed them individually below . 1.GumbelBox was introduced by Dasgupta et al. , 2020 , where the authors demonstrate that it solves problems related to local non-identifiability and smooths the loss landscape of prior methods ( hard and smooth boxes ) . In that work , the authors choose a Gumbel distribution because it is min/max stable , and therefore boxes whose min/max endpoints are parametrized via Gumbel distributions are closed under intersection ( i.e.the intersection of two Gumbel boxes is another Gumbel box ) . We have clarified these points in the background section . All of our experiments are carried out using GumbelBox , as Dasgupta et al.2020 shows it outperforms HardBox and SmoothBox in all tasks . As you rightly point out , the same transformation can be applied to SmoothBox and HardBox , in fact Dasgupta et al.2020 point out that SmoothBox and HardBox can be viewed as special cases of GumbelBox for specific settings of hyperparameters ( i.e.zero variance / temperature ) . We perform a sweep over these hyperparameters , and thus our results implicitly include these models as potential special cases . 2.We have reworked these sentences to make them a bit clearer . Our aim was not to suggest that the Gumbel distribution over endpoints , itself , has a strong inductive bias toward modeling hierarchies , but rather point out that Vilnis et al.2018 demonstrate box embeddings effectively model hierarchies and Dasgupta et al.2020 demonstrate that using the Gumbel distribution over endpoints makes this even more effective . 3.We agree , and although GumbelBox was not the main focus of this paper ( having been introduced in Dasgupta et al.2020 ) we have updated the paper to include a short discussion of the Gumbel distribution . 4.This is true , however : ( 1 ) the meet operation serves primarily to justify the theoretical properties of the box as a lattice , ( 2 ) we do not directly train or evaluate using the meet operation , as it is not needed for our queries . That being said , for a well-trained model of hierarchies , the meet is still meaningful , as the meet of a node and one of it \u2019 s descendents would simply be the node itself , and the meet of any two arbitrary nodes will provide the smallest containing box which , itself , is contained in the closest common ancestor node . 5.Thank you for pointing this out , there is a typo here which we have corrected to \u201c ( a\u22641b ) \u2227 ( b\u22642c ) \u2192 ( a\u22642c ) \u201d . We \u2019 ve also added \u201c ( a\u22642b ) \u2227 ( b\u22641c ) \u2192 ( a\u22642c ) \u201d , which corresponds to your example ( Bird HasPart Wing , Wing IsA Appendage = > Bird HasPart Appendage ) . 6.This approach can easily be extended to more than two hierarchical relations by learning additional transformations , however we are not aware of any dataset which contains three or more hierarchical relations in sufficient quantity/density such that modeling all three jointly would lead to improved inference . IsA and HavePart are both prevalent and fundamental relations , however , and it is our belief that modeling them correctly will lead to benefits on additional non-hierarchical relations , which is a major aim of our future work . 7.Note that the gumbel beta is a global parameter which is the same for all embeddings . ( Dagupta et al.2020 mention this is a requirement for GumbelBox to be closed under intersection . ) In our experiments , we follow Dasgupta et al.2020 and tune \u03b2 on a validation set using Bayesian hyperparameter optimization . While it is possible to learn \u03b2 via gradient-descent on the training set , it is likely that this would also quickly lead to local minima with very small \u03b2 ( due to the influence of negative samples ) , and thus it seems more appropriate for this to be treated as a global hyperparameter selected based on validation set performance , or even annealed throughout training . 8.We have tried more complicated transformations , including shallow MLPs , but a simple linear transformation actually outperforms them . This is likely due to a fundamental difference in the way that MLPs interpret their input ( encoding information using the vector-space structure ) and the way these vectors are used in the GumbelBox model , where they are eventually used to calculate ratios of expected intersection volumes . 9.One way to think about this is that the \u201c IsA-Bird \u201d box represents all things which are birds , and the \u201c HasPart-Wing \u201d box represents all things which have wings . A bird is something which has a wing , so it belongs in the \u201c HasPart-Wing \u201d box . A box for \u201c HasPart-Bird \u201d , on the other hand , would represent all things which have birds as a part of them , so perhaps the \u201c IsA-Flock \u201d would be inside this box ( if such a Flock node existed ) . We have clarified this point in the updated version of the paper ."}, {"review_id": "CLYe1Yke1r-2", "review_text": "This paper builds upon the work of Patel et al . ( 2020 ) in modeling two hierarchies jointly within the box embedding framework . It also incorporates the GumbelBox formulation of Dasgupta et al . ( 2020 ) to resolve local identifiability issues during training . The contribution of the paper seems to only lie in the learning of a function \\phi that maps entity boxes to HasPart- * boxes . This function constrains the HasPart- * boxes in two ways : ( a ) their `` minimum '' corners remain at the same relative positions as their corresponding entity boxes , and ( b ) their lengths are scaled proportionately in each dimension . In contrast , Patel et al . ( 2020 ) does not have these constraints in their model . I find the novelty of these constraints to be incremental , especially in view that the joint hierarchy problem and evaluation methodology have already been formulated by Patel et al ( 2020 ) in the context of box embeddings . Though seemingly straightforward , the constraints do help the paper to improve upon the state of the art by significant margins in the experiments . The paper is well organized and clearly written for the most part , but the exposition can be improved in some areas . * Section 4.1 , ( a < _1 b ) ^ ( b < _2 c ) = > ( a < _2 b ) : Could the authors provide examples of what < _1 , < _2 , a , b , and c represent ? I interpret `` a < _1 b '' to be b IsA a , `` b < _2 c '' to be c HasPart b , which then leads to `` c HasPart a '' . This means that the consequent should ( a < _2 c ) rather than ( a < _2 b ) , no ? * Section 1 , 3rd para : hiearchy- > hierarchy , * Section 1 , 4th para : dialate- > dilate * Section 5.3 , 1st para , `` for those edges in table 5 '' - > should be `` table 2 '' ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for recognizing our contribution and promising experimental results as shown in the paper , and for providing the specific corrections , we have updated the paper accordingly . Although the proposed method is simple , prior to this work it was unclear how to effectively enable sharing of parameters between boxes for the purpose of transforming one graph to another . Based on other reviewer \u2019 s requests , we have also run additional baselines , including recent hyperbolic embedding methods , and find that our relatively simple model significantly outperforms them . A further contribution of our paper is the additional analysis of the model \u2019 s ability to generalize . Patel et al.2020 was purely a representation task , which was appropriate for the model structure proposed , however sharing parameters allow us to evaluate our model for generalization capability , and we include a thorough breakdown and analysis of various types of generalization this model is capable of performing ."}, {"review_id": "CLYe1Yke1r-3", "review_text": "This paper deals with tree-like structure embedding with box embedding on the lattice ( poset ) . This paper is well-motivated and well-presented . Though there is a limitation on data structure , this paper still presents a novel idea in this area . This method also achieved promising results in experiments . Thus , I would like to recommend to accept this paper .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks R1 for recognizing our contribution in proposing this novel method and promising experimental results in representing tree-like structures !"}], "0": {"review_id": "CLYe1Yke1r-0", "review_text": "This work proposes to model multiple hierarchical relations using box embeddings , motivated by the natural transitivity property of the containment between regions in region-based representations . The proposed model is evaluated on a dataset containing two relations ( is-a and has-part ) . Although the proposed model shows promise by outperforming several baselines on the above mentioned dataset , I believe that the paper is not ready for publication in its current form , mainly due to ( i ) missing comparison to the highly relevant line of work on hyperbolic embeddings of hierarchical multi-relational data ; and ( ii ) lacking additional experiments on a dataset with more than 2 relations . Detailed comments and questions for the authors : Sec.2 1.I find the claim that `` Modeling joint hierarchies is not quite the same as knowledge base completion . '' to be unsubstantiated . This is true to an extent , since the ultimate goal of KB completion is inferring which other facts are true based on existing ones . However , to achieve this goal , KG completion models need to learn entity and relation representations which capture various properties of entities ( e.g.semantics ) and relations ( e.g.transitivity , symmetry , etc . ) , which is very similar to the main idea of this work . 2.A whole line of very relevant work on hyperbolic embeddings of hierarchical relations in knowledge bases is missing [ 1 , 2 ] . Sec.3\\ If I understood Definition 2 correctly , the meet ( i.e.union ) of two boxes will be another box which in most cases contains an area that is not part of either boxes ( since a union of two boxes is not necessarily a box ) . Does n't this introduce errors into box embeddings which increase with increasing the dimensionality of the embeddings ? Sec.4\\ It is not clear to me why the lack of a transformation on f_1 ( b ) encourages the containment in figure 1 . Could you please explain this point further ? Sec.5 1.While the achieved results seem impressive , as mentioned above , a highly relevant comparison to [ 1 ] and [ 2 ] is missing . Both missing works are embedding models that represent multiple simultaneous hierarchies in hyperbolic space and where entity embeddings are shared across relations , which should lead to better generalisation on missing edges ( as claimed by the authors ) . 2.The authors evaluate the proposed model on a single dataset with only 2 relations . The proposed model should be evaluated on at least one more dataset , e.g.WN18RR [ 3 ] , since [ 1 ] show several relations in that dataset to be hierarchical . 3.I 'm surprised that the improvement over the TWO-BOX model is lower when testing for generalisation capability ( 5 % ) than in the original setup ( 8.5 % ) , given the original premise that the proposed model should benefit from sharing information across hierarchies . 4.It would be nice to see a visualisation of the learned embeddings . Minor comments : \\ Background section should be made shorter , especially the part regarding the probabilistic box model training , which is not that relevant to the overall goal of this work . This space could be used for additional experiments proposed above . [ 1 ] Balazevic et al.Multi-relational Poincar\u00e9 Graph Embeddings , NeurIPS 2019\\ [ 2 ] Chami et al.Low-Dimensional Hyperbolic Knowledge Graph Embeddings , ACL 2020\\ [ 3 ] Dettmers et al.Convolutional 2D Knowledge Graph Embeddings , AAAI 2018", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your detailed comments , we will address them invidividually below . Sec 2 : 1.We agree that KB completion often requires modeling hierarchical relations , and moreover we evaluate KB completion models as our baselines for this task . Our intent was not to say they are entirely unrelated , but rather to simply point out the differences , which , as you point out , are mostly in the amount of emphasis on hierarchical relations and modeling goals . In short , we believe we are essentially in agreement on this point , and have attempted to clarify the wording of this in the paper . 2.Thank you for suggesting the hyperbolic embeddings for multi relational knowledge bases . We have added them to the related work section , and also evaluated them as baselines . ( Also discussed again below . ) Sec 3 : As you point out , the meet is not actually the union , it is the smallest containing box , however ( 1 ) the meet operation serves primarily to justify the theoretical properties of the box as a lattice , ( 2 ) we do not directly train or evaluate using the meet operation , as it is not needed for our queries . That being said , for a well-trained model of hierarchies , the meet is still meaningful , as the meet of a node and one of it \u2019 s descendents would simply be the node itself , and the meet of any two arbitrary nodes will provide the smallest containing box which , itself , is contained in the closest common ancestor node . Sec 4 : We have updated the image and explanation . The lack of a transformation on f_1 ( b ) means that the transitive relations present in the IsA hierarchy interact exactly as desired with the HasPart hierarchy to encourage the composition edges . For example , since Dove is contained in Bird , if Bird is contained in HasPart-Wing , then Dove will also be contained in HasPart-Wing . A transformation on f_1 ( b ) would add flexibility to the model but would no longer guarantee these compositional edges . Furthermore , if we think of the Bird box as representative of \u201c all things which are birds \u201d and the HasPart-Wing box as \u201c all things which have wings \u201d , then we don \u2019 t want or need an additional transformation on the Bird box in this scenario , as \u201c all things which are birds \u201d is a subset of \u201c all things which have wings \u201d . Sec 5 : 1.We have run additional experiments using MuRP [ 1 ] , RotH , and AttH [ 2 ] , and updated Table 2 and 3 with the results . We observe that the RotH and AttH models were able to learn the joint hierarchy to some extent , however , their generalisation performance is poor . We are also running RotE ( the euclidean embedding version of the RotH ) to investigate how much the inductive bias of the hyperbolic embeddings is helping in this task . 2.The hierarchical relationships in WN18RR are member_meronym , has_part , instance_hypernym , and hypernym , which are already present in our dataset ( member_meronym and has_part are both HasPart , instance_hypernym and hypernym are IsA ) . The other dominant relationships are _derivationally_related_form , _verb_group , and _similar_to , which are symmetric in nature . Furthermore , more than 90 % of the evaluation data coming from these relations have a reverse edge present in the training data , which makes modeling these relations trivial [ 1 ] . Most of the models achieve 0.93 MRR performance on this subset , including our method that has no inducative bias towards modelling symmetry . Removing this trivial symmetric subset and focusing exclusively on hierarchical data in the training split WN18RR yields a large number of connected components , as opposed to a deep hierarchy , and thus is not suitable to our goals of assessing the ability of a model to handle hierarchical relations . [ 1 ] Pezeshkpour et.at . Revisiting Evaluation of Knowledge Base Completion Models , AKBC 2020 . 3.In the overfitting task , we train on the whole transitive reduction and predict the performance of the composite edges . However , in the generalisation task we provide a subset of the hierarchies as training data and try to predict on the composition edges and missing edges as well . Thus these numbers are not a direct indication of the generalization gap since the training data is different for these two settings . For this reason , we study the generalization performance for different parts of the dataset in detail in section 5.5 . 4.We are generating a visualization of the learned embeddings and will include it in the paper shortly ."}, "1": {"review_id": "CLYe1Yke1r-1", "review_text": "The paper focuses on modeling multiple hierarchical relations on a heterogenous graph . The task \u201c modeling joint hierarchies \u201d is essentially trying to infer whether a given pair of entities has a hierarchical connection especially when there exists multiple hierarchical relations ( 2 in the paper ) , and missing links . The paper proposes to embed entities using boxes whose endpoints follow the Gumbel distribution . Given there exists two hierarchical relations , the paper transforms the box of one entity under relation 1 to the box of the entity under relation 2 with a parameterized linear function . This is in contrast to previous work that parameterized the box of two relations using separate independent parameters . The model seems sound , however I have two major concerns . ( 1 ) I do not think the model is motivated well , especially on why the model uses Gumbel distribution to parameterize the box . ( 2 ) The paper has no introduction how they train the model and use it for inference , what is the loss ? This makes it hard to evaluate the correctness of the model . I am very satisfied with the extensive experiments the paper has conducted . They include many strong baselines including the order embeddings , hyperbolic embeddings and even some KG embeddings . The results on the KG embeddings clearly show that their methods work much better in this ( a little specific ) hierarchical relation modeling setting . The paper also introduces a new missing-edge setting , where they show that joint modeling achieves better generalization than independent parameters . Some detailed questions are listed below . 1.The related work states the difference between modeling hierarchies and knowledge base completion , however , it lacks discussion how their Gumbel box is different from previous box embedding methods ( this should be added in the second paragraph ) . I understand the difference between the Gumbel box and the Two-box model , namely the Two-box model learns independent parameters . However , I did not find the discussion on the connection between the Gumbel box and hard/smooth box . Why can not we apply the same transformation idea to previous hard and smoothed box embeddings so that they can also model joint hierarchies without optimization issues ? Why is Gumbel distribution special and useful in parameterizing the boxes and modeling hierarchies ? 2.The paper has some vague sentences like \u201c the authors demonstrate that this method of training boxes leads to better representation of trees thus we will use this Gumbel box approach in our setting. \u201d and \u201c since gumbel boxes effectively model hierarchies , we would like to benefit from the inductive bias of this model for intra-relation edges and thus we seek to learn a function ... \u201d , but what is the inductive bias of Gumbel ? It \u2019 s better to clearly state it . 3.The paper lacks a short discussion and introduction to the Gumbel distribution in the background section , especially on the parameters \\mu and \\beta . 4.As defined in Eq.3 , the meet of two boxes may include some blank space that does not belong to the input boxes , do you think this will have any issues , especially when the two input boxes are far away from each other ? 5.Sec 4.1 , first paragraph , \u201c $ ( a \\leq_1 b ) \\wedge ( b \\leq_2 c ) \\to ( a \\leq_2 b ) $ \u201d is wrong . Bird has part Wing , and Wing is an Appendage , but Bird is not a Wing . 6.Sec 4.1 , end of page 4 , \u201c To simultaneously model a second relation , we ... \u201d , so the model can only model two hierarchical relations ? If so , I think it is a little limited and can the model provide a way to generalize beyond two hierarchical relations ? 7.Sec 4.1 , \u201c the free parameters are $ \\mu_i $ and $ \\Delta_i $ \u201d , why does the model not learn $ \\beta $ ? 8.As in Eq.11 and 12 , the transformation is a rather simple linear transformation , have you tried something that is more complex , e.g.a MLP ? 9.I am also confused by Remark 1 and Eq.8.For Bird , there should be two boxes where one represents the IsA relation and the other represents the HasPart relation , right ? Then in Figure 1 , why is the IsA-Bird box inside the HasPart-Wing box , I think it should be the HasPart-Bird box inside the HasPart-Wing box . 10.The paper does not introduce how to train the model or even how to make predictions during inference in Sec 4 . I understand the page limit but these two aspects are essential to a machine learning model . 11.What is the difference between the two-box model and the order embeddings in the experiments ? I assume if you apply the order embeddings to this multi-hierarchical relation setup , then it is the same as the two-box model ? 12.I am curious about the performance of the proposed model in an imbalanced dataset ( as introduced in Li et al.ICLR 2019 ) , where the ratio of positive and negative is 1:10 ? minors : The paper does not have grammar mistakes and here are some minor points . 1.Make it explicit in the introduction that the \u201c Two-Box Model \u201d is referred to Patel et al . ( 2020 ) 2.The definition of box lattice model is not self-contained in Eq.1 , what is $ x_i $ and $ x^i $ ? I guess it is the two end points of the box in one dimension . Better to state it clearly . 3.Sec 3.3 , \u201c For example , as shown in 1 , based on\u2026 \u201d - > \u201c For example , as shown in Figure 1 , .. \u201d", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you very much for your detailed comments , we have addressed them individually below . 1.GumbelBox was introduced by Dasgupta et al. , 2020 , where the authors demonstrate that it solves problems related to local non-identifiability and smooths the loss landscape of prior methods ( hard and smooth boxes ) . In that work , the authors choose a Gumbel distribution because it is min/max stable , and therefore boxes whose min/max endpoints are parametrized via Gumbel distributions are closed under intersection ( i.e.the intersection of two Gumbel boxes is another Gumbel box ) . We have clarified these points in the background section . All of our experiments are carried out using GumbelBox , as Dasgupta et al.2020 shows it outperforms HardBox and SmoothBox in all tasks . As you rightly point out , the same transformation can be applied to SmoothBox and HardBox , in fact Dasgupta et al.2020 point out that SmoothBox and HardBox can be viewed as special cases of GumbelBox for specific settings of hyperparameters ( i.e.zero variance / temperature ) . We perform a sweep over these hyperparameters , and thus our results implicitly include these models as potential special cases . 2.We have reworked these sentences to make them a bit clearer . Our aim was not to suggest that the Gumbel distribution over endpoints , itself , has a strong inductive bias toward modeling hierarchies , but rather point out that Vilnis et al.2018 demonstrate box embeddings effectively model hierarchies and Dasgupta et al.2020 demonstrate that using the Gumbel distribution over endpoints makes this even more effective . 3.We agree , and although GumbelBox was not the main focus of this paper ( having been introduced in Dasgupta et al.2020 ) we have updated the paper to include a short discussion of the Gumbel distribution . 4.This is true , however : ( 1 ) the meet operation serves primarily to justify the theoretical properties of the box as a lattice , ( 2 ) we do not directly train or evaluate using the meet operation , as it is not needed for our queries . That being said , for a well-trained model of hierarchies , the meet is still meaningful , as the meet of a node and one of it \u2019 s descendents would simply be the node itself , and the meet of any two arbitrary nodes will provide the smallest containing box which , itself , is contained in the closest common ancestor node . 5.Thank you for pointing this out , there is a typo here which we have corrected to \u201c ( a\u22641b ) \u2227 ( b\u22642c ) \u2192 ( a\u22642c ) \u201d . We \u2019 ve also added \u201c ( a\u22642b ) \u2227 ( b\u22641c ) \u2192 ( a\u22642c ) \u201d , which corresponds to your example ( Bird HasPart Wing , Wing IsA Appendage = > Bird HasPart Appendage ) . 6.This approach can easily be extended to more than two hierarchical relations by learning additional transformations , however we are not aware of any dataset which contains three or more hierarchical relations in sufficient quantity/density such that modeling all three jointly would lead to improved inference . IsA and HavePart are both prevalent and fundamental relations , however , and it is our belief that modeling them correctly will lead to benefits on additional non-hierarchical relations , which is a major aim of our future work . 7.Note that the gumbel beta is a global parameter which is the same for all embeddings . ( Dagupta et al.2020 mention this is a requirement for GumbelBox to be closed under intersection . ) In our experiments , we follow Dasgupta et al.2020 and tune \u03b2 on a validation set using Bayesian hyperparameter optimization . While it is possible to learn \u03b2 via gradient-descent on the training set , it is likely that this would also quickly lead to local minima with very small \u03b2 ( due to the influence of negative samples ) , and thus it seems more appropriate for this to be treated as a global hyperparameter selected based on validation set performance , or even annealed throughout training . 8.We have tried more complicated transformations , including shallow MLPs , but a simple linear transformation actually outperforms them . This is likely due to a fundamental difference in the way that MLPs interpret their input ( encoding information using the vector-space structure ) and the way these vectors are used in the GumbelBox model , where they are eventually used to calculate ratios of expected intersection volumes . 9.One way to think about this is that the \u201c IsA-Bird \u201d box represents all things which are birds , and the \u201c HasPart-Wing \u201d box represents all things which have wings . A bird is something which has a wing , so it belongs in the \u201c HasPart-Wing \u201d box . A box for \u201c HasPart-Bird \u201d , on the other hand , would represent all things which have birds as a part of them , so perhaps the \u201c IsA-Flock \u201d would be inside this box ( if such a Flock node existed ) . We have clarified this point in the updated version of the paper ."}, "2": {"review_id": "CLYe1Yke1r-2", "review_text": "This paper builds upon the work of Patel et al . ( 2020 ) in modeling two hierarchies jointly within the box embedding framework . It also incorporates the GumbelBox formulation of Dasgupta et al . ( 2020 ) to resolve local identifiability issues during training . The contribution of the paper seems to only lie in the learning of a function \\phi that maps entity boxes to HasPart- * boxes . This function constrains the HasPart- * boxes in two ways : ( a ) their `` minimum '' corners remain at the same relative positions as their corresponding entity boxes , and ( b ) their lengths are scaled proportionately in each dimension . In contrast , Patel et al . ( 2020 ) does not have these constraints in their model . I find the novelty of these constraints to be incremental , especially in view that the joint hierarchy problem and evaluation methodology have already been formulated by Patel et al ( 2020 ) in the context of box embeddings . Though seemingly straightforward , the constraints do help the paper to improve upon the state of the art by significant margins in the experiments . The paper is well organized and clearly written for the most part , but the exposition can be improved in some areas . * Section 4.1 , ( a < _1 b ) ^ ( b < _2 c ) = > ( a < _2 b ) : Could the authors provide examples of what < _1 , < _2 , a , b , and c represent ? I interpret `` a < _1 b '' to be b IsA a , `` b < _2 c '' to be c HasPart b , which then leads to `` c HasPart a '' . This means that the consequent should ( a < _2 c ) rather than ( a < _2 b ) , no ? * Section 1 , 3rd para : hiearchy- > hierarchy , * Section 1 , 4th para : dialate- > dilate * Section 5.3 , 1st para , `` for those edges in table 5 '' - > should be `` table 2 '' ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for recognizing our contribution and promising experimental results as shown in the paper , and for providing the specific corrections , we have updated the paper accordingly . Although the proposed method is simple , prior to this work it was unclear how to effectively enable sharing of parameters between boxes for the purpose of transforming one graph to another . Based on other reviewer \u2019 s requests , we have also run additional baselines , including recent hyperbolic embedding methods , and find that our relatively simple model significantly outperforms them . A further contribution of our paper is the additional analysis of the model \u2019 s ability to generalize . Patel et al.2020 was purely a representation task , which was appropriate for the model structure proposed , however sharing parameters allow us to evaluate our model for generalization capability , and we include a thorough breakdown and analysis of various types of generalization this model is capable of performing ."}, "3": {"review_id": "CLYe1Yke1r-3", "review_text": "This paper deals with tree-like structure embedding with box embedding on the lattice ( poset ) . This paper is well-motivated and well-presented . Though there is a limitation on data structure , this paper still presents a novel idea in this area . This method also achieved promising results in experiments . Thus , I would like to recommend to accept this paper .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks R1 for recognizing our contribution in proposing this novel method and promising experimental results in representing tree-like structures !"}}