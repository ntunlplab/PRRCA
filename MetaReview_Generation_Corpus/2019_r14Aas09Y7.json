{"year": "2019", "forum": "r14Aas09Y7", "title": "COCO-GAN: Conditional Coordinate Generative Adversarial Network", "decision": "Reject", "meta_review": "The paper introduces a GAN architecture for generating small patches of an image and subsequently combining them. Following the rebuttal and discussion, reviewers still rate the paper as marginally above or below the acceptance threshold.\n\nIn response to updates, AnonReviewer3 comments that \"ablation experiments do make the paper stronger\" but it \"still lacks convincing experiments for its main motivating use case: generating outputs at a resolution that won't fit in memory within a single forward pass\".\n\nAnonReviewer2 points to the major shortcoming that \"throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works. I was missing a concrete use case where COCO-GAN performs much better.\"\n\nThough authors provide additional experiments and reference high-resolution output during the discussion phase, they caution that these results are preliminary and could likely benefit from more time/work devoted to training.\n\nOn balance, the AC agrees with the reviewers that the paper contains some interesting ideas, but also believes that experimental validation simply needs more work, and as a result the paper does not meet the bar for acceptance.\n", "reviews": [{"review_id": "r14Aas09Y7-0", "review_text": "The paper describes a GAN architecture and training methodology where a generator is trained to generate \"micro-\" patches, being passed as input a latent vector and patch co-ordinates. Micro-patches generated for different adjacent locations with the same latent vector are combined to generate a \"macro\" patch. This \"macro\" output is trained against a discriminator that tries to label this output as real and fake, as well as predict the location of the macro patch and the value of the latent vector. The generator is trained to fool the discriminator's label, and minimize the error in the prediction of location and latent vector information. - The paper proposes a combination of different interesting strategies. However, a major drawback of the method is that it's not clear which of these are critical to the quality of the generated output. - Firstly, it isn't clear to me why the further breakdown of the macro patch into micro patches is useful. There appears to be no separate loss on these intermediate outputs. Surely, a DC-GAN like architecture with sufficient capacity would be as well able to generate \"macro\" patches. The paper needs to justify this split into micro patches with a comparison to a direct architecture that generates the macro patches (everything else being the same). Note that applications like \"interpolation\" of micro patches could be achieved simply by interpolating crops of the macro patch. - As a means of simply producing high-resolution images, it appears that \"PGGAN\" performs better than the proposed method. Therefore, the paper doesn't clearly explain the setting when the division into patches produces a better result. It is worth noting that the idea of applying \"local\" critics (i.e., discriminators acting on sub-regions) isn't new (e.g., Generative Image Inpainting with Contextual Attention in CVPR 2018). What's new is the proposed method's way of achieving consistency between different regions by providing the 'co-ordinate' of the patch as input (and seeking consistency in the latent vector through a loss)---rather than applying a discriminator at a coarser level on the downsampled image. But given the poorer performance compared to PGGAN, it isn't clear that there is a an advantage to this approach. Overall, the paper brings up some interesting ideas, but it doesn't motivate all its design choices, and doesn't make a clear argument about the settings in which the proposed method would provide an actual advantage. ===Post-rebuttal I'm upgrading my score from 5 to 6, because some of the ablation experiments do make the paper stronger. Having said that, I still think this is a borderline paper. \"Co-ordinate conditioning\" is an interesting approach, but I think the paper still lacks convincing experiments for its main motivating use case: generating outputs at a resolution that won't fit in memory within a single forward pass. (This motivation wasn't clear in the initial version, but is clearer now). The authors' displayed some high-resolution results during the rebuttal phase, but note that they haven't tuned the hyper-parameter for these (and so the results might not be the best they can be). Moreover, they scale up the sizes of their micro and macro patches so that they're still the same factor below the full image. I think a version of this paper whose main experimental focus is on high-resolution data generation, and especially, from much smaller micro-macro patches, would make a more convincing case. So while the paper is about at the borderline for acceptance, I do think it could be much stronger with a focus on high-resolution image experiments (which is after all, forms its motivation). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We sincerely appreciate the reviewer raises many important questions we are more than willing to discuss . All reviewers agree our work is novel , which is our target to introduce the new \u201c conditional coordinate \u201d idea to the community . Note that since some questions are correlated , our response is not in the reviewer \u2019 s original question order . 1. \u201c As a means of simply producing high-resolution images , it appears that `` PGGAN '' performs better than the proposed method . Therefore , the paper does n't clearly explain the setting when the division into patches produces a better result . It is worth noting that the idea of applying `` local '' critics ( i.e. , discriminators acting on sub-regions ) is n't new ( e.g. , Generative Image Inpainting with Contextual Attention in CVPR 2018 ) . What 's new is the proposed method 's way of achieving consistency between different regions by providing the 'co-ordinate ' of the patch as input ( and seeking consistency in the latent vector through a loss ) -- -rather than applying a discriminator at a coarser level on the downsampled image . But given the poorer performance compared to PGGAN , it is n't clear that there is a an advantage to this approach. \u201d > The main target of COCO-GAN is exploring other applications instead of increasing generation quality . The low FID score is a by-product . > In many real-world applications ( e.g. , VR , medical images ) , the data are normally too large to even fit into memory . Modern GAN architectures require the generator to generate the full image at once . This requirement makes generating these super-large images hard to achieve . As the result , we propose COCO-GAN , which can break full-image generation into patches generation . Furthermore , the discriminator also takes macro patches as input , since taking the full image as the input of the discriminator is infeasible in super-large image generation problem . > COCO-GAN is orthogonal to PGGAN , one can still add the \u201c progressive growing \u201d strategy to micro/macro patches generation/discrimination . However , this will introduce more hyperparameters , thus making it more challenging to balance everything . 2. \u201c Firstly , it is n't clear to me why the further breakdown of the macro patch into micro patches is useful . There appears to be no separate loss on these intermediate outputs . Surely , a DC-GAN like architecture with sufficient capacity would be as well able to generate `` macro '' patches . The paper needs to justify this split into micro patches with a comparison to a direct architecture that generates the macro patches ( everything else being the same ) . Note that applications like `` interpolation '' of micro patches could be achieved simply by interpolating crops of the macro patch. \u201d > The output of generator * must * be smaller than the input of the discriminator for COCO-GAN . This is for smoothening the seam between patches after concatenating multiple patches . The discriminator oversees whether the concatenated patches have discontinuities between the concatenated edges . > In the CelebA 128x128 setting , our micro patches are of size 32x32 , macro patches are of size 64x64 . Even if the generator generates macro patches , it still needs to take care of seams while producing the full image . If one decides to make the discriminator taking the full image as input while the output of generator is a 64x64 patch , which can be done via concatenating four patches produced by the generator , then it becomes another special case of COCO-GAN . > We provide an anonymous link below . The seam between patches is smoothed out through time . This suggests the adversarial loss takes cares of the seam between patches . > As described in response to 3. , we will update the methodology section to justify this design . > > The anonymous link to the per-epoch generated samples ( CelebA 128x128 and LSUN 256x256 ) : > https : //www.dropbox.com/sh/ucpthw2mnu3yw3g/AAC0AU5f7f1RfOvB3C5RM1YUa ? dl=0 3 . \u201c Overall , the paper brings up some interesting ideas , but it does n't motivate all its design choices , and does n't make a clear argument about the settings in which the proposed method would provide an actual advantage. \u201d > We will update the methodology section to discuss the design motivations of each component and the introduction section to make arguments of actual advantages more clear ."}, {"review_id": "r14Aas09Y7-1", "review_text": "This paper proposes to constrain the Generator of a WGAN-GP on patches locations to generate small images (\u201cmicro-patches\u201d), with an additional smoothness condition so these can be combined into full images. This is done by concatenating micro-patches into macro patches, that are fed to the Discriminator. The discriminator aims at classifying the macro-patches as fake or real, while additionally recovering the latent noise used for generation as well as the spatial prior. There are many grammar and syntax issues (e.g. the very first sentence of the introduction is not correct (\u201cHuman perception has only partial access to the surrounding environment due to the limited acuity area of fovea, and therefore human learns to recognize or reconstruct the world by moving their eyesight.\u201d). The paper goes to 10 pages but does so by adding redundant information (e.g. the intro is highly redundant) while some important details are missing The paper does not cite, discuss or compare with the related work \u201cSynthesizing Images of Humans in Unseen Poses\u201d, by G. Lalakrishan et al. in CVPR 2018. Page. 3, in the overview the authors mention annotated components: in what sense, and how are these annotated? How are the patches generated? By random cropping? Still in the overview, page 3, the first sentence states that D has an auxiliary head Q, but later it is stated that D has two auxiliary prediction heads. Why is the content prediction head trained separately while the spatial one is trained jointly with the discriminator? Is this based on intuition or the result of experimentations? What is the advantage in practice of using macro-patches for the Discriminator rather than full images obtained by concatenating the micro-patches? Has this comparison been done? While this is done by concatenation for micro-patches, how is the smoothness between macro-patches imposed? How would this method generalise to objects with less/no structure? In section 3.4, the various statements are not accompanied by justification or citations. In particular, how do existing image pinpointing frameworks all assume the spatial position of remaining parts of the image is known? How does figure 5 show that model can be misled to learn reasonable but incorrect spatial patterns? Is there any intuition/justification as to why discrete uniform sampling would work so much better than continuous uniform sampling? Could these results be included? How were the samples in Figure.2 chosen? Given that the appendix. C shows mostly the same image, the reader is led to believe these are carefully curated samples rather than random ones.", "rating": "4: Ok but not good enough - rejection", "reply_text": "11. \u201c How were the samples in Figure.2 chosen ? Given that the appendix . C shows mostly the same image , the reader is led to believe these are carefully curated samples rather than random ones. \u201d > First , we only save 64 ( 8x8 ) randomly generated images for each epoch . Then we pick the epoch which has the lowest validation FID score . Since we believe showing fewer samples ( which makes each generated sample larger ) can make the generated samples clearer to see on the paper , so we just reuse and show the upper-left 25 samples . > We thank for the reviewer pointing out that our process may lead the reader to doubt that these samples are cherry-picked . We believe by : > 1 . Release generated samples across epochs ( each epoch with 64 images ) . > 2.Release the source code after acceptance . > 3.Replace the images in Figure . 2. > 4.The FID score also matches the image quality . > can support our samples are truly random-selected . > > The anonymous link to the per-epoch generated samples ( CelebA 128x128 and LSUN 256x256 ) : > https : //www.dropbox.com/sh/ucpthw2mnu3yw3g/AAC0AU5f7f1RfOvB3C5RM1YUa ? dl=0"}, {"review_id": "r14Aas09Y7-2", "review_text": "+ Interesting and novel idea + It works - Insufficient ablation and comparison - Unclear what the advantages of the presented framework are The presented idea is clearly new and a deviation from standard GAN architectures. I was surprised to see that this actually produces visually coherent results. I was certain that it would create ugly seams at the boundary. For this reason I like the submission overall. However, the submission has two major short-comings. First, throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works. I was missing a concrete use case where COCO-GAN performs much better. Second, I was missing any sort of ablation experiments. The authors only evaluate the complete system, and never show which components are actually needed. Specifically, I'd have liked to see experiments: * with/without a context model Q * with a standard discriminator (single output or convolutional), but a micro-coordinate generator * with a macro-block discriminator, but a standard generator * without coordinate conditioning, but different Generator parameters for each coordinate These experiments would help better understand the strength of COCO-GAN and how it fits in with other GAN models. Minor: The name of the method is not ideal. First, it collides with the COCO dataset. Second, it does not become clear why the proposed GAN uses a \"Conditional Coordinate until late in the exposition. Third, the main idea could easily stand without the coordinate conditioning (see above).", "rating": "6: Marginally above acceptance threshold", "reply_text": "Sincerely thanks for the valuable suggestions from the reviewer . All reviewers agree our work is novel , which is our target to introduce the new \u201c conditional coordinate \u201d idea to the community . Here are some responses to the reviewer \u2019 s question : 1 . \u201c The presented idea is clearly new and a deviation from standard GAN architectures . I was surprised to see that this actually produces visually coherent results . I was certain that it would create ugly seams at the boundary . For this reason I like the submission overall. \u201d > Thanks for being interested in one of our most important observations . We believe this characteristic provides many merits to different tasks , which is our main thread across all analysis , discussion and experiments . 2. \u201c However , the submission has two major short-comings . First , throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works . I was missing a concrete use case where COCO-GAN performs much better. \u201d > We will update the introduction section in the following days to ensure the reader can have a fast and clear view of the main contributions and use cases of COCO-GAN . > In general , we first observe COCO-GAN has fewer seams than we expected . This property enables both G and D to learn with partial views ( i.e. , micro patches and macro patches , respectively ) . We believe this non-before-seen property has three interesting merits : > 1 . Patch-Inspired Image Generation > 2 . Partial-Scene Generation > 3 . Computation-Friendly Generation . > We further discuss and perform experiments to support these applications and benefits . 3. \u201c Second , I was missing any sort of ablation experiments . The authors only evaluate the complete system , and never show which components are actually needed . Specifically , I 'd have liked to see experiments : * with/without a context model Q * with a standard discriminator ( single output or convolutional ) , but a micro-coordinate generator * with a macro-block discriminator , but a standard generator * without coordinate conditioning , but different Generator parameters for each coordinate \u201d \u201c These experiments would help better understand the strength of COCO-GAN and how it fits in with other GAN models. \u201d > Thanks for pointing this out . We agree although each component of COCO-GAN is necessary for specific applications in our work , some users may not necessarily need all applications or benefits at the same time . > We will perform the former three ablation studies in the following days in CelebA 64x64 setting , which is relatively fast , and also other datasets afterward . > However , the last one is slightly out-of-topic . This will result in a dramatic increase in the total number of parameters . In our basic setting , we split the full image into 4x4 micro patches , and 12x4 micro patches for panorama dataset . The suggested setting of the last ablation study might not a feasible solution to real-world applications . Furthermore , it is hard to perform a fair comparison between models with different numbers of total parameters and FLOPs . 4. \u201c The name of the method is not ideal . First , it collides with the COCO dataset . Second , it does not become clear why the proposed GAN uses a `` Conditional Coordinate until late in the exposition . Third , the main idea could easily stand without the coordinate conditioning ( see above ) . \u201d > We are aware of this problem . Conditional coordinate is our core idea and component . We believe it is important and should appear in the name of model . We will update the introduction to make the idea clearer . > Lastly , we believe conditional coordinate is essential for our framework . The generator learns to generate micro patches based on their coordinate and take cares of edge smoothness with respect to their potential siblings , which are also defined by the coordinate system . Furthermore , generating panorama in the cylindrical coordinate system is also a nature and straightforward choice , and investigating other coordinate systems for different image types is also an interesting and unexplored research direction ."}], "0": {"review_id": "r14Aas09Y7-0", "review_text": "The paper describes a GAN architecture and training methodology where a generator is trained to generate \"micro-\" patches, being passed as input a latent vector and patch co-ordinates. Micro-patches generated for different adjacent locations with the same latent vector are combined to generate a \"macro\" patch. This \"macro\" output is trained against a discriminator that tries to label this output as real and fake, as well as predict the location of the macro patch and the value of the latent vector. The generator is trained to fool the discriminator's label, and minimize the error in the prediction of location and latent vector information. - The paper proposes a combination of different interesting strategies. However, a major drawback of the method is that it's not clear which of these are critical to the quality of the generated output. - Firstly, it isn't clear to me why the further breakdown of the macro patch into micro patches is useful. There appears to be no separate loss on these intermediate outputs. Surely, a DC-GAN like architecture with sufficient capacity would be as well able to generate \"macro\" patches. The paper needs to justify this split into micro patches with a comparison to a direct architecture that generates the macro patches (everything else being the same). Note that applications like \"interpolation\" of micro patches could be achieved simply by interpolating crops of the macro patch. - As a means of simply producing high-resolution images, it appears that \"PGGAN\" performs better than the proposed method. Therefore, the paper doesn't clearly explain the setting when the division into patches produces a better result. It is worth noting that the idea of applying \"local\" critics (i.e., discriminators acting on sub-regions) isn't new (e.g., Generative Image Inpainting with Contextual Attention in CVPR 2018). What's new is the proposed method's way of achieving consistency between different regions by providing the 'co-ordinate' of the patch as input (and seeking consistency in the latent vector through a loss)---rather than applying a discriminator at a coarser level on the downsampled image. But given the poorer performance compared to PGGAN, it isn't clear that there is a an advantage to this approach. Overall, the paper brings up some interesting ideas, but it doesn't motivate all its design choices, and doesn't make a clear argument about the settings in which the proposed method would provide an actual advantage. ===Post-rebuttal I'm upgrading my score from 5 to 6, because some of the ablation experiments do make the paper stronger. Having said that, I still think this is a borderline paper. \"Co-ordinate conditioning\" is an interesting approach, but I think the paper still lacks convincing experiments for its main motivating use case: generating outputs at a resolution that won't fit in memory within a single forward pass. (This motivation wasn't clear in the initial version, but is clearer now). The authors' displayed some high-resolution results during the rebuttal phase, but note that they haven't tuned the hyper-parameter for these (and so the results might not be the best they can be). Moreover, they scale up the sizes of their micro and macro patches so that they're still the same factor below the full image. I think a version of this paper whose main experimental focus is on high-resolution data generation, and especially, from much smaller micro-macro patches, would make a more convincing case. So while the paper is about at the borderline for acceptance, I do think it could be much stronger with a focus on high-resolution image experiments (which is after all, forms its motivation). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We sincerely appreciate the reviewer raises many important questions we are more than willing to discuss . All reviewers agree our work is novel , which is our target to introduce the new \u201c conditional coordinate \u201d idea to the community . Note that since some questions are correlated , our response is not in the reviewer \u2019 s original question order . 1. \u201c As a means of simply producing high-resolution images , it appears that `` PGGAN '' performs better than the proposed method . Therefore , the paper does n't clearly explain the setting when the division into patches produces a better result . It is worth noting that the idea of applying `` local '' critics ( i.e. , discriminators acting on sub-regions ) is n't new ( e.g. , Generative Image Inpainting with Contextual Attention in CVPR 2018 ) . What 's new is the proposed method 's way of achieving consistency between different regions by providing the 'co-ordinate ' of the patch as input ( and seeking consistency in the latent vector through a loss ) -- -rather than applying a discriminator at a coarser level on the downsampled image . But given the poorer performance compared to PGGAN , it is n't clear that there is a an advantage to this approach. \u201d > The main target of COCO-GAN is exploring other applications instead of increasing generation quality . The low FID score is a by-product . > In many real-world applications ( e.g. , VR , medical images ) , the data are normally too large to even fit into memory . Modern GAN architectures require the generator to generate the full image at once . This requirement makes generating these super-large images hard to achieve . As the result , we propose COCO-GAN , which can break full-image generation into patches generation . Furthermore , the discriminator also takes macro patches as input , since taking the full image as the input of the discriminator is infeasible in super-large image generation problem . > COCO-GAN is orthogonal to PGGAN , one can still add the \u201c progressive growing \u201d strategy to micro/macro patches generation/discrimination . However , this will introduce more hyperparameters , thus making it more challenging to balance everything . 2. \u201c Firstly , it is n't clear to me why the further breakdown of the macro patch into micro patches is useful . There appears to be no separate loss on these intermediate outputs . Surely , a DC-GAN like architecture with sufficient capacity would be as well able to generate `` macro '' patches . The paper needs to justify this split into micro patches with a comparison to a direct architecture that generates the macro patches ( everything else being the same ) . Note that applications like `` interpolation '' of micro patches could be achieved simply by interpolating crops of the macro patch. \u201d > The output of generator * must * be smaller than the input of the discriminator for COCO-GAN . This is for smoothening the seam between patches after concatenating multiple patches . The discriminator oversees whether the concatenated patches have discontinuities between the concatenated edges . > In the CelebA 128x128 setting , our micro patches are of size 32x32 , macro patches are of size 64x64 . Even if the generator generates macro patches , it still needs to take care of seams while producing the full image . If one decides to make the discriminator taking the full image as input while the output of generator is a 64x64 patch , which can be done via concatenating four patches produced by the generator , then it becomes another special case of COCO-GAN . > We provide an anonymous link below . The seam between patches is smoothed out through time . This suggests the adversarial loss takes cares of the seam between patches . > As described in response to 3. , we will update the methodology section to justify this design . > > The anonymous link to the per-epoch generated samples ( CelebA 128x128 and LSUN 256x256 ) : > https : //www.dropbox.com/sh/ucpthw2mnu3yw3g/AAC0AU5f7f1RfOvB3C5RM1YUa ? dl=0 3 . \u201c Overall , the paper brings up some interesting ideas , but it does n't motivate all its design choices , and does n't make a clear argument about the settings in which the proposed method would provide an actual advantage. \u201d > We will update the methodology section to discuss the design motivations of each component and the introduction section to make arguments of actual advantages more clear ."}, "1": {"review_id": "r14Aas09Y7-1", "review_text": "This paper proposes to constrain the Generator of a WGAN-GP on patches locations to generate small images (\u201cmicro-patches\u201d), with an additional smoothness condition so these can be combined into full images. This is done by concatenating micro-patches into macro patches, that are fed to the Discriminator. The discriminator aims at classifying the macro-patches as fake or real, while additionally recovering the latent noise used for generation as well as the spatial prior. There are many grammar and syntax issues (e.g. the very first sentence of the introduction is not correct (\u201cHuman perception has only partial access to the surrounding environment due to the limited acuity area of fovea, and therefore human learns to recognize or reconstruct the world by moving their eyesight.\u201d). The paper goes to 10 pages but does so by adding redundant information (e.g. the intro is highly redundant) while some important details are missing The paper does not cite, discuss or compare with the related work \u201cSynthesizing Images of Humans in Unseen Poses\u201d, by G. Lalakrishan et al. in CVPR 2018. Page. 3, in the overview the authors mention annotated components: in what sense, and how are these annotated? How are the patches generated? By random cropping? Still in the overview, page 3, the first sentence states that D has an auxiliary head Q, but later it is stated that D has two auxiliary prediction heads. Why is the content prediction head trained separately while the spatial one is trained jointly with the discriminator? Is this based on intuition or the result of experimentations? What is the advantage in practice of using macro-patches for the Discriminator rather than full images obtained by concatenating the micro-patches? Has this comparison been done? While this is done by concatenation for micro-patches, how is the smoothness between macro-patches imposed? How would this method generalise to objects with less/no structure? In section 3.4, the various statements are not accompanied by justification or citations. In particular, how do existing image pinpointing frameworks all assume the spatial position of remaining parts of the image is known? How does figure 5 show that model can be misled to learn reasonable but incorrect spatial patterns? Is there any intuition/justification as to why discrete uniform sampling would work so much better than continuous uniform sampling? Could these results be included? How were the samples in Figure.2 chosen? Given that the appendix. C shows mostly the same image, the reader is led to believe these are carefully curated samples rather than random ones.", "rating": "4: Ok but not good enough - rejection", "reply_text": "11. \u201c How were the samples in Figure.2 chosen ? Given that the appendix . C shows mostly the same image , the reader is led to believe these are carefully curated samples rather than random ones. \u201d > First , we only save 64 ( 8x8 ) randomly generated images for each epoch . Then we pick the epoch which has the lowest validation FID score . Since we believe showing fewer samples ( which makes each generated sample larger ) can make the generated samples clearer to see on the paper , so we just reuse and show the upper-left 25 samples . > We thank for the reviewer pointing out that our process may lead the reader to doubt that these samples are cherry-picked . We believe by : > 1 . Release generated samples across epochs ( each epoch with 64 images ) . > 2.Release the source code after acceptance . > 3.Replace the images in Figure . 2. > 4.The FID score also matches the image quality . > can support our samples are truly random-selected . > > The anonymous link to the per-epoch generated samples ( CelebA 128x128 and LSUN 256x256 ) : > https : //www.dropbox.com/sh/ucpthw2mnu3yw3g/AAC0AU5f7f1RfOvB3C5RM1YUa ? dl=0"}, "2": {"review_id": "r14Aas09Y7-2", "review_text": "+ Interesting and novel idea + It works - Insufficient ablation and comparison - Unclear what the advantages of the presented framework are The presented idea is clearly new and a deviation from standard GAN architectures. I was surprised to see that this actually produces visually coherent results. I was certain that it would create ugly seams at the boundary. For this reason I like the submission overall. However, the submission has two major short-comings. First, throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works. I was missing a concrete use case where COCO-GAN performs much better. Second, I was missing any sort of ablation experiments. The authors only evaluate the complete system, and never show which components are actually needed. Specifically, I'd have liked to see experiments: * with/without a context model Q * with a standard discriminator (single output or convolutional), but a micro-coordinate generator * with a macro-block discriminator, but a standard generator * without coordinate conditioning, but different Generator parameters for each coordinate These experiments would help better understand the strength of COCO-GAN and how it fits in with other GAN models. Minor: The name of the method is not ideal. First, it collides with the COCO dataset. Second, it does not become clear why the proposed GAN uses a \"Conditional Coordinate until late in the exposition. Third, the main idea could easily stand without the coordinate conditioning (see above).", "rating": "6: Marginally above acceptance threshold", "reply_text": "Sincerely thanks for the valuable suggestions from the reviewer . All reviewers agree our work is novel , which is our target to introduce the new \u201c conditional coordinate \u201d idea to the community . Here are some responses to the reviewer \u2019 s question : 1 . \u201c The presented idea is clearly new and a deviation from standard GAN architectures . I was surprised to see that this actually produces visually coherent results . I was certain that it would create ugly seams at the boundary . For this reason I like the submission overall. \u201d > Thanks for being interested in one of our most important observations . We believe this characteristic provides many merits to different tasks , which is our main thread across all analysis , discussion and experiments . 2. \u201c However , the submission has two major short-comings . First , throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works . I was missing a concrete use case where COCO-GAN performs much better. \u201d > We will update the introduction section in the following days to ensure the reader can have a fast and clear view of the main contributions and use cases of COCO-GAN . > In general , we first observe COCO-GAN has fewer seams than we expected . This property enables both G and D to learn with partial views ( i.e. , micro patches and macro patches , respectively ) . We believe this non-before-seen property has three interesting merits : > 1 . Patch-Inspired Image Generation > 2 . Partial-Scene Generation > 3 . Computation-Friendly Generation . > We further discuss and perform experiments to support these applications and benefits . 3. \u201c Second , I was missing any sort of ablation experiments . The authors only evaluate the complete system , and never show which components are actually needed . Specifically , I 'd have liked to see experiments : * with/without a context model Q * with a standard discriminator ( single output or convolutional ) , but a micro-coordinate generator * with a macro-block discriminator , but a standard generator * without coordinate conditioning , but different Generator parameters for each coordinate \u201d \u201c These experiments would help better understand the strength of COCO-GAN and how it fits in with other GAN models. \u201d > Thanks for pointing this out . We agree although each component of COCO-GAN is necessary for specific applications in our work , some users may not necessarily need all applications or benefits at the same time . > We will perform the former three ablation studies in the following days in CelebA 64x64 setting , which is relatively fast , and also other datasets afterward . > However , the last one is slightly out-of-topic . This will result in a dramatic increase in the total number of parameters . In our basic setting , we split the full image into 4x4 micro patches , and 12x4 micro patches for panorama dataset . The suggested setting of the last ablation study might not a feasible solution to real-world applications . Furthermore , it is hard to perform a fair comparison between models with different numbers of total parameters and FLOPs . 4. \u201c The name of the method is not ideal . First , it collides with the COCO dataset . Second , it does not become clear why the proposed GAN uses a `` Conditional Coordinate until late in the exposition . Third , the main idea could easily stand without the coordinate conditioning ( see above ) . \u201d > We are aware of this problem . Conditional coordinate is our core idea and component . We believe it is important and should appear in the name of model . We will update the introduction to make the idea clearer . > Lastly , we believe conditional coordinate is essential for our framework . The generator learns to generate micro patches based on their coordinate and take cares of edge smoothness with respect to their potential siblings , which are also defined by the coordinate system . Furthermore , generating panorama in the cylindrical coordinate system is also a nature and straightforward choice , and investigating other coordinate systems for different image types is also an interesting and unexplored research direction ."}}