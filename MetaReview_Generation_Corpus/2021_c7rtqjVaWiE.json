{"year": "2021", "forum": "c7rtqjVaWiE", "title": "Efficient Sampling for Generative Adversarial Networks with Reparameterized Markov Chains", "decision": "Reject", "meta_review": "The consensus among the reviewers is that this is a borderline paper: its main idea is sensible and natural. Unfortunately, while the reviewers appreciated the authors' responses to their comments, they felt that the paper failed to demonstrate the usefulness of the idea beyond toy-datasets. The latter would considerably strengthen this paper.", "reviews": [{"review_id": "c7rtqjVaWiE-0", "review_text": "# # # Summary In this work , the authors propose coupling markov chain GAN ( CMC-GAN ) , a technique that allows to draw GAN samples by running an MCMC chain that uses the generator to produce proposals , and the discriminator to compute acceptance probabilities . Whereas prior work by Turner et al . ( 2019 ) uses an independent proposal , for each sample , the present work uses a small random perturbation of the last sample * in the latent space * to create the proposal . Goodfellow et al.2014 showed that in the large data limit and large model capacity limit for absolutely continuous distributions , the output of the optimal discriminator represents encodes the density ratio of target and generated data . Using this result , the authors of the present work derive a tractable expression for the acceptance probabilities that leads to an unbiased estimate of the target distribution in settings where the results of Goodfellow et al.2014 hold . They also show that an analogue acceptance criterion can be derived for the popular WGAN . The authors show experimental results on the synthetic swiss roll dataset as well as CIFAR10 and CELEBA with DCGAN and WGAN architecture , showing improved sample quality ( measured by IS on the image datasets ) compared to standard GAN and competing MCMC approaches , and improved acceptance rate compared to GAN . # # # Decision I believe that proposes the most natural way for performing MCMC sampling on GANs . Both the dependent sampling based on the latent space and the acceptance mechanism based on the discriminator are natural and clean and , I 'm sure will end up useful one way or another . Where the paper is lacking , in my opinion , is in making a case * why * and * when * one should be using MCMC based methods in the first place when using GANs . While I do find the results on the swiss roll experiments are convincing , I am not convinced by the results on image datasets . The improvements seem to be minor , inconsistent , and on baselines performing worse than commonly reported in the literature . Given how clean the proposed method itself is authors should improve the motivation by trying to find a more convincing application . I think it would be a wasted opportunity for what could be a very nice paper to accept it without such improvements . # # # Questions/Suggestions - The only motivation for the use of MCMC techniques is to not `` waste the discriminator '' . Why should I expect the discriminator to be any better than the generator that it was trained with ? Are there situations where one would naturally end up with a `` better '' discriminator than generator ? Given that ordinary GAN sampling has 100 percent sample efficiency , I feel that a stronger argument in favor of using any MCMC based-technique in the first place is necessary . - While I do find the experiments on swiss roll convincing , I am confused by the experiments on image GANs . * * First * * , the inception scores given in Table 2 seem significantly below those usually reported in the literature . * * Second * * , the experiments in Figure 3 show a minimal improvement of CMC-GAN compared to ordinary GAN sampling , in particular compared to the wide oscillation of IS over the different epochs . In particular , Figure 3 and Table 2 do not seem to be consistent . * * Third * * , it is my understanding that it does not make much sense to evaluate the IS on CELEBA . Usually , FID is used instead . - Recent work such as [ Berard et al . ] ( https : //arxiv.org/abs/1906.04848 ) , [ Schafer et al . ] ( https : //arxiv.org/abs/1910.05852 ) , [ Arjovsky and Bottou 2017 ] ( https : //arxiv.org/abs/1701.04862 ) suggests that the behavior of discriminator training on image GANs might be radically different than in the idealized case analyzed by Goodfellow et al.in 2017.Could this be the reason why the results on image data sets fall short of those obtained in the absolutely continuous swiss roll dataset . Maybe techniques such as in [ Dieng et al.2019 ] ( https : //arxiv.org/abs/1910.04302 ) could be useful ? - Although it has a somewhat different goal , it might still be useful to cite [ Song et al . ] ( https : //arxiv.org/abs/1706.07561 ) . After discussion with the authors and reading the other reviews I still believe that the paper should not be accepted and therefore stay with my original review . While the authors have shown improvement over previous work ( MH-GAN ) using a very natural idea , this previous work in turn has not provided sufficient evidence that MCMC-GANs are useful . I believe that we should not accept further MCMC-GAN papers , before this methodology has shown any improvement on a plausible use-case .", "rating": "5: Marginally below acceptance threshold", "reply_text": "* * Q4 * * : Figure 3 and Table 2 seem to be inconsistent . * * A4 * * : Sorry for the confusion . First , Figure 3 only demonstrates the first 25 epochs of training , while in total , we train the model for 60 epochs . Second , as mentioned in the caption of Table 2 , the results of GAN , DRS , MH-GAN are directly taken from the MH-GAN paper ( Turner et al. , 2019 ) , while the results in Figure 3 are based on our re-implementation to compare results epoch by epoch . So they are different because of the instability of GANs . To see the comparison of these methods with the same implementation , we recommend Table 3 , where scores are all reported based on our implementation , and you can find the corresponding versions of MH-GAN ( IND proposal w/ MH ) and DDLS ( REP proposal w/o MH ) there . Our method still outperforms them in most cases . * * Q5 * * : It does not make much sense to evaluate IS on CELEBA . Should use FID instead . * * A5 * * : We use Inception scores for evaluation because previous works usually report Inception scores on these two benchmark datasets , CIFAR-10 and CELEBA . For a fair comparison , we also report Inception scores following the same setup . Nevertheless , we think your concern is reasonable as CELEBA is quite different from ImageNet and it is better to utilize the real data statistics here to measure sample quality . Thus , we additionally report the comparison of FID scores in Table 4 ( Appendix A.3 ) based on our re-implementation ( because there is not any FID reported on these benchmarks in previous sampling methods ) on all benchmarks . It can be seen that our method also outperforms previous ones in terms of FID scores . * * Q6 * * : The behavior of discriminator training can be radically different than in the idealized case , and this may explain the limited improvement on image data . What mechanism might help ? * * A6 * * : We agree with you that this could be the reason why the sample quality of sampling methods is still lower than that of real data distribution , and even longer chains can not fully mitigate the gap . In the sampling methods of GANs , we always assume the discriminator gives a perfect estimation of the density ratio for the theory to hold . However , it is usually not the case in practice because the generator is also changing all the time , and the one-step update of the discriminator can not fully capture this information , but it can capture a certain extent information of density ratio which explains why the sampling methods can consistently improve over the baseline at each epoch . From our view , the estimated density ratio is enough to push the generator better but not able to bring it up to the data distribution . Hence , how to develop mechanisms that bring more accurate density ratio estimation remains an interesting research direction . We are willing to put more effort into investigating this problem in the future . We have added this discussion in the second assumption in Appendix A.1 . * * Q7 * * : Helpful to cite the paper \u201c A-NICE-MC \u201d . * * A7 * * : Thanks for your advice . A-NICE-MC is an excellent pioneer work on bridging MCMC and NNs by learning NN transition kernels . Ours instead directly utilizes properties of existing NN modules for the transition kernel . The two share the same spirit that NN helps design MCMC transition kernels . We have added the citation in the related work . In all , thanks for your valuable review , and we hope you find our explanations helpful !"}, {"review_id": "c7rtqjVaWiE-1", "review_text": "* * Summary * * The paper proposes an MCMC based sampling mechanism for GANs . In contrast to earlier work , the proposal distribution is conditioning conditioned on the previous state ( here in latent space ) , which is supposed to help sampling efficiency . This is achieved by a clever re-parametrization of intermediate steps of the MCMC chain . As an example , the authors provide a Langevin version ( which uses gradient information ) of their method . I enjoyed reading this well-written paper and think the re-parameterized MCMC chain is a very neat idea that fits very naturally in the GAN framework . The paper is of quite incremental nature though : little to no theory contribution , only some incremental empirical benefits . I also have some doubts whether the comparisons are fair in terms of compute and effective sample size ( more below ) . Below are a few points to consider : * * Effective sample size * * What puzzles me here is the fact that while the independent proposal of Turner et al gets stuck in certain parts of the space , the Langevin updates of the proposed method ( Figure 4 ) do have less variability . I assume the incremental improvement happen due to relatively small step sizes in the Langevin sampler ? This would have a bad effect on the effective sample size . Does the MCMC chain eventually visits other parts of the space , or does it need to be restarted for every sample created ? This does not seem to be true for the MH sampler , which despite its low acceptance rate produces samples from the entire space . Could the authors clarify this , and if possible provide measure of effective sample size for a fixed number of iterations ? * * Compute * * The authors do neither discuss nor evaluate the computational load compared to other methods , especially performance metrics as a function of compute would be interesting . Or maybe the computational load is comparable for all methods ? * * Title * * The term `` coupled '' is currently heavily used within the MCMC community , e.g . [ 2 ] , and it denotes a different technique . I would suggest replacing it by `` re-parameterized '' which would be more accurate in that respect . * * '' Proof '' for convergence * * The abstract claims that convergence to the true data distribution is proved , but that is really stretching the term . All the paper contains is a valid MH ratio . But that alone does not prove convergence , for which the authors would need to go into the weeds of MCMC convergence , with conditions on the target distribution . This is especially true for the Langevin proposal , e.g. [ 1 ] . * * Experiments * * I would suggest to move the Swiss roll dataset to the Appendix and replace it with something more interesting , preferably higher dimensional . This would make the paper stronger . In fact some analysis how all the different sampling methods compare as a function of dimensional ( or `` difficulty '' ) would make it even more so . [ 1 ] Roberts , G. O. , & Tweedie , R. L. ( 1996 ) . Exponential convergence of Langevin distributions and their discrete approximations . Bernoulli . [ 2 ] Jacob , P. E. , O'Leary , J. , & Atchad\u00e9 , Y. F. ( 2017 ) . Unbiased markov chain monte carlo with couplings . JRSS-B .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your valuable comments . We address them in detail as follows . * * Q1 * * : Improvements are due to relatively small step sizes in the Langevin sampler ? The effect on the effective sample size ? Does the MCMC chain eventually visits other parts of the space\uff1f * * A1 * * : First of all , the improvement is brought by the relatively small step size that we choose for better sample quality . As is mentioned in Section 5.2 , we evaluate our methods following the conventional setting of the sampling methods of GANs ( as in MH-GAN , DDLS ) by running a chain for 640 steps , and taking only the sample of the last step for evaluation . In this test scenario , because we only need the last example , we do not need the chain to have diversity among its different steps , thus effective sample size is not a matter of concern here . Instead , we mainly use the chain to finetune the initial sample with a relatively small step size ( e.g. , tau=0.01 for CIFAR-10 ) for better sample quality . As shown in the newly added Figure 5 , our gradient-based proposal can also propose very diverse examples with large step size ( tau=1 for CIFAR-10 ) , just like the independent proposal of MH-GAN ( which is an extreme case of our REP proposal ) . Therefore , the resulting chains are likely able to visit other parts of the space . We have added this discussion to the last paragraph of Section 5.2 . We have also added multi-modal experiments in Appendix A.4 , and show that our method well preserves the sample diversity while promoting the sample quality . * * Q2 * * : Comparison of computation cost . * * A2 * * : We have added a comparison of computation cost in Table 5 in the Appendix A.3 . Comparing DDLS and ours , they take 88.94s and 88.85s to run 500 chains for 640 steps on a single 1080 Ti GPU , respectively , hence the difference is negligible . Without the MH-step , our method takes 87.62s , meaning the additional MH-step only costs 1.4 % computation overhead , which is almost negligible , but it brings a significant improvement in sample quality . * * Q3 * * : The title needs to be changed to avoid confusion with existing literature . * * A3 * * : Thank you for your kind advice . We are happy to take your excellent advice and rename the title with `` Reparameterized Markov Chains '' together with the short name `` REP-GAN '' . * * Q4 * * : The abstract claims that convergence to the true data distribution is proved , but that is really stretching the term . All the paper contains is a valid M2H ratio . But that alone does not prove convergence . * * A4 * * : Thanks for pointing it out . Indeed , as our reparameterized proposal is designed to be a general framework compatible with many MCMC proposals , we can not give convergence results without knowing the properties of the specific proposal distribution . Hence , in our Theorem 1 , we assume the chain having certain regularity conditions ( irreducible , aperiodic , and not transient [ 1 ] ) to obtain convergence in general . As you suggested , we have revised our statements in the paper to make it more clear and rigorous . [ 1 ] Gelman et al . ( 2013 ) .Bayesian data analysis . CRC press . * * Q5 * * : Compare different methods as a function of input dimension , or task difficulty . * * A5 * * : Following your suggestions , we compare the sampling methods with increasing task difficulties . Specifically , in the multi-modal experiments in Appendix A.4 , we experiment with the mixture of Gaussian distributions that have 5x5 , 9x9 , and 13x13 modes . Intuitively , the tasks get harder with more modes to cover , as it becomes more challenging for the sampling methods to improve sample quality while preserving sample diversity . As shown in Figure 7 and 8 , our method has done a good job by outperforming both independent samplers ( MH-GAN ) and pure Langevin steps ( DDLS ) . It shows our method is less unlikely to degrade sample diversity while promoting the overall sample quality . Please refer to the discussion there for more details . Overall , thank you a lot for your insightful comments , which encourage us to collect more interesting results . Hope our feedback could help answer your concerns !"}, {"review_id": "c7rtqjVaWiE-2", "review_text": "Summary : The paper proposes an MCMC sampling strategy for GANs . The idea is clear : for high-dimensional x , making a good proposal is difficult , so they propose to do that in the latent space . Then they use a similar strategy as MH-GAN to compute a rejection strategy . The difference between the two methods is that proposal in MH-GAN does not depend on x while the proposed method does , and the argument is that it results in a higher acceptance rate . The idea is interesting , and the paper is relatively well-written , but the execution and experiment left a lot to be desired . * One of the arguments of the paper ( in the related work ) the method overcomes sample low sample diversity . No metric is reported for that . The authors need to report LPIPS [ 1 ] and compare different methods . * Fig 4 shows very poor diversity ; all samples seem identical to each other , and honestly , it seems that the GAN collapsed . * The results in Fig 3 is also very strange . First of all , what is the point of Fig 3 ( left ) ? All IS scores are roughly going up , but this figure is no comparison and does not show any if one method is doing better . Fig 3 ( right ) is more concerning . One expects that as the epoch increases , the generator becomes better at generating samples . The acceptance rate improves ( b/c G generates more realistic results and discriminator can not tell them apart ) ; why the acceptance rates are going down ? * Fig 2 is also presented in a confusing way . All methods except the second column from left almost perform the same and propose methods is in both columns ( ! ! ) What does each column , row mean ? Given what I read in the related work , I expected to see the model 's performance in the sample a multi-modal distribution . In fact , I want to see that : 100 Gaussian distributions centered at the 10x10 grids and small enough variance . I want to see how this method performs in recovering centers of the clusters ( you can see examples in the literature ) . * Given that finally , the sampling strategy becomes very similar to the recent energy-based method . It is fair to say comparison is required . Yes , GAN is and the energy-based methods are different but the sampling strategy ( the Langevian dynamic ) are very similar and I would like to see how those two methods perform in term of quality of the samples . * Finally , if one views this method as a general strategy for generating samples using GAN , perhaps you can think of this approach as an approximate inference approach for inference in a complicated Baysian model . This paper does not focus on that and I do n't expect authors to do any experiment for that but it can useful there . [ 1 ] Richard Zhang , Phillip Isola , Alexei A Efros , Eli Shechtman , and Oliver Wang . The Unreasonable Effectiveness of Deep Features as a Perceptual Metric . In CVPR , 2018 .", "rating": "5: Marginally below acceptance threshold", "reply_text": "* * Q4 * * : Figure 2 is presented in a confusing way . Expect a multi-modal experiment . * * A4 * * : Sorry for the confusion . Each sub-figure shows the samples obtained by the corresponding sampling method on its top . The sub-figures are arranged left to right , and we show pairs of results of DDLS and our method under different step sizes ( tau ) to illustrate their different behaviors , now marked with dashed boxes . To address your concern , we have added the multi-modal experiments , including a 25-Gaussians experiment as well as more difficult tasks with more modes , in Appendix A.4 . In the newly added Figure 7 and 8 , our method shows clear benefits in terms of sampling quality , sample diversity , and numerical stability . Please refer to the discussion there for more details . * * Q5 * * : Similarity and comparison with energy-based models ( EBM ) . * * A5 * * : Yes our sampling scheme of GANs is similar to that of EBM because essentially they both utilize HMC-like methods . However , there is an essential difference that EBM uses HMC sampling for training , while our method only uses it to post-process trained GANs . Thus , the difference between their performance could be largely due to the difference of training mechanisms between EBM and GAN themselves , instead of the difference in sampling methods . As far as we can see , EBM and GAN have become two strong competitors in the field of generative models , each with a lot of modern variants with state-of-the-art results . A fair comparison of the two diagrams may need a more thorough , large-scale study of various components that affect their relative performance , which is left for our further work . * * Q6 * * : Our method can serve as a general approximate inference method for complex Bayesian models . * * A6 * * : Yes , it is ! Thanks for pointing out that . Indeed , our method can serve as a general approximate inference technique for Bayesian models by bridging MCMC and GANs . Previous works [ 2,3,4 ] also propose to avoid the bad geometry of a complex probability measure by reparameterizing the Markov transitions into a simpler measure . However , these methods are limited to explicit invertible mappings without dimensionality reduction . In our work , we first show that it is also tractable to conduct such model-based reparameterization with implicit models like GANs . Also notice that our method is designed for GANs , but not limited to existing ( unstable ) GAN training mechanisms because our method does not depend on how GANs are trained . In fact , our method can be applied to general implicit generative models with density ratio estimation . We have now added this discussion to the last paragraph in Section 4.2 . [ 2 ] Marzouk et al . ( 2016 ) .An introduction to sampling via measure transport . [ 3 ] Hoffman et al . ( 2019 ) .Neutra-lizing bad geometry in Hamiltonian Monte Carlo using neural transport . [ 4 ] Titsias . ( 2017 ) .Learning model reparametrizations : Implicit variational inference by fitting MCMC distributions . Thank you again for all your insightful comments and hope our feedback is helpful !"}, {"review_id": "c7rtqjVaWiE-3", "review_text": "The paper is a good idea . It is based on the notion of following the same line of reasoning as the prior work of MH-GAN . However , it makes the crucial advance of allowing the use of gradient information for the far more efficient HMC-type samplers . The paper is able to do much of the sampling in the latent space , which enables the use of gradient-based sampling . One nitpick would be that I suspect there is a latent assumption that the mapping of z - > x is injective ( but need not be bijective like in normalizing flows ) . However , this is not explicitly stated at all in the paper .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your positive comments ! Here is our answer to your concern . Q1 : Is there a latent assumption that the mapping of z - > x is injective ? A1 : Yes , it is true . When introducing Eq . ( 8 ) , the change-of-variable formula , we omit technical details to focus on the main story , and instead refer readers to the reference for further details and proof . We have now made these points clear in the newly added Appendix A.1 . First , the mapping should be injective , otherwise there would not be a \u201c one-to-one \u201d change of variables . Second , according to Ben-Israel [ 1 ] , to ensure Eq . ( 8 ) hold , we also need the Jacobian matrix of the mapping to have full column rank for every input . A mild sufficient condition for injectivity is that the generator only contains ( non-degenerate ) affine layers and injective non-linearities , like LeakyReLU . It is not hard to show that such a condition also implies the full rankness of the Jacobian . In fact , this architecture has already been found to benefit GANs and achieved state-of-the-art results [ 2 ] . The affine layers here are also likely to be non-degenerate because their weights are randomly initialized and typically will not degenerate in practice during the training of GANs . Thank you again and hope you find our explanations helpful ! [ 1 ] Ben-Israel , A . ( 1999 ) .The change-of-variables formula using matrix volume . SIAM Journal on Matrix Analysis and Applications , 21 ( 1 ) , 300-312 . [ 2 ] Tang , S. ( 2020 ) . Lessons Learned From the Training of GANs on Artificial Datasets . IEEE Access , 8 , 165044-165055 ."}], "0": {"review_id": "c7rtqjVaWiE-0", "review_text": "# # # Summary In this work , the authors propose coupling markov chain GAN ( CMC-GAN ) , a technique that allows to draw GAN samples by running an MCMC chain that uses the generator to produce proposals , and the discriminator to compute acceptance probabilities . Whereas prior work by Turner et al . ( 2019 ) uses an independent proposal , for each sample , the present work uses a small random perturbation of the last sample * in the latent space * to create the proposal . Goodfellow et al.2014 showed that in the large data limit and large model capacity limit for absolutely continuous distributions , the output of the optimal discriminator represents encodes the density ratio of target and generated data . Using this result , the authors of the present work derive a tractable expression for the acceptance probabilities that leads to an unbiased estimate of the target distribution in settings where the results of Goodfellow et al.2014 hold . They also show that an analogue acceptance criterion can be derived for the popular WGAN . The authors show experimental results on the synthetic swiss roll dataset as well as CIFAR10 and CELEBA with DCGAN and WGAN architecture , showing improved sample quality ( measured by IS on the image datasets ) compared to standard GAN and competing MCMC approaches , and improved acceptance rate compared to GAN . # # # Decision I believe that proposes the most natural way for performing MCMC sampling on GANs . Both the dependent sampling based on the latent space and the acceptance mechanism based on the discriminator are natural and clean and , I 'm sure will end up useful one way or another . Where the paper is lacking , in my opinion , is in making a case * why * and * when * one should be using MCMC based methods in the first place when using GANs . While I do find the results on the swiss roll experiments are convincing , I am not convinced by the results on image datasets . The improvements seem to be minor , inconsistent , and on baselines performing worse than commonly reported in the literature . Given how clean the proposed method itself is authors should improve the motivation by trying to find a more convincing application . I think it would be a wasted opportunity for what could be a very nice paper to accept it without such improvements . # # # Questions/Suggestions - The only motivation for the use of MCMC techniques is to not `` waste the discriminator '' . Why should I expect the discriminator to be any better than the generator that it was trained with ? Are there situations where one would naturally end up with a `` better '' discriminator than generator ? Given that ordinary GAN sampling has 100 percent sample efficiency , I feel that a stronger argument in favor of using any MCMC based-technique in the first place is necessary . - While I do find the experiments on swiss roll convincing , I am confused by the experiments on image GANs . * * First * * , the inception scores given in Table 2 seem significantly below those usually reported in the literature . * * Second * * , the experiments in Figure 3 show a minimal improvement of CMC-GAN compared to ordinary GAN sampling , in particular compared to the wide oscillation of IS over the different epochs . In particular , Figure 3 and Table 2 do not seem to be consistent . * * Third * * , it is my understanding that it does not make much sense to evaluate the IS on CELEBA . Usually , FID is used instead . - Recent work such as [ Berard et al . ] ( https : //arxiv.org/abs/1906.04848 ) , [ Schafer et al . ] ( https : //arxiv.org/abs/1910.05852 ) , [ Arjovsky and Bottou 2017 ] ( https : //arxiv.org/abs/1701.04862 ) suggests that the behavior of discriminator training on image GANs might be radically different than in the idealized case analyzed by Goodfellow et al.in 2017.Could this be the reason why the results on image data sets fall short of those obtained in the absolutely continuous swiss roll dataset . Maybe techniques such as in [ Dieng et al.2019 ] ( https : //arxiv.org/abs/1910.04302 ) could be useful ? - Although it has a somewhat different goal , it might still be useful to cite [ Song et al . ] ( https : //arxiv.org/abs/1706.07561 ) . After discussion with the authors and reading the other reviews I still believe that the paper should not be accepted and therefore stay with my original review . While the authors have shown improvement over previous work ( MH-GAN ) using a very natural idea , this previous work in turn has not provided sufficient evidence that MCMC-GANs are useful . I believe that we should not accept further MCMC-GAN papers , before this methodology has shown any improvement on a plausible use-case .", "rating": "5: Marginally below acceptance threshold", "reply_text": "* * Q4 * * : Figure 3 and Table 2 seem to be inconsistent . * * A4 * * : Sorry for the confusion . First , Figure 3 only demonstrates the first 25 epochs of training , while in total , we train the model for 60 epochs . Second , as mentioned in the caption of Table 2 , the results of GAN , DRS , MH-GAN are directly taken from the MH-GAN paper ( Turner et al. , 2019 ) , while the results in Figure 3 are based on our re-implementation to compare results epoch by epoch . So they are different because of the instability of GANs . To see the comparison of these methods with the same implementation , we recommend Table 3 , where scores are all reported based on our implementation , and you can find the corresponding versions of MH-GAN ( IND proposal w/ MH ) and DDLS ( REP proposal w/o MH ) there . Our method still outperforms them in most cases . * * Q5 * * : It does not make much sense to evaluate IS on CELEBA . Should use FID instead . * * A5 * * : We use Inception scores for evaluation because previous works usually report Inception scores on these two benchmark datasets , CIFAR-10 and CELEBA . For a fair comparison , we also report Inception scores following the same setup . Nevertheless , we think your concern is reasonable as CELEBA is quite different from ImageNet and it is better to utilize the real data statistics here to measure sample quality . Thus , we additionally report the comparison of FID scores in Table 4 ( Appendix A.3 ) based on our re-implementation ( because there is not any FID reported on these benchmarks in previous sampling methods ) on all benchmarks . It can be seen that our method also outperforms previous ones in terms of FID scores . * * Q6 * * : The behavior of discriminator training can be radically different than in the idealized case , and this may explain the limited improvement on image data . What mechanism might help ? * * A6 * * : We agree with you that this could be the reason why the sample quality of sampling methods is still lower than that of real data distribution , and even longer chains can not fully mitigate the gap . In the sampling methods of GANs , we always assume the discriminator gives a perfect estimation of the density ratio for the theory to hold . However , it is usually not the case in practice because the generator is also changing all the time , and the one-step update of the discriminator can not fully capture this information , but it can capture a certain extent information of density ratio which explains why the sampling methods can consistently improve over the baseline at each epoch . From our view , the estimated density ratio is enough to push the generator better but not able to bring it up to the data distribution . Hence , how to develop mechanisms that bring more accurate density ratio estimation remains an interesting research direction . We are willing to put more effort into investigating this problem in the future . We have added this discussion in the second assumption in Appendix A.1 . * * Q7 * * : Helpful to cite the paper \u201c A-NICE-MC \u201d . * * A7 * * : Thanks for your advice . A-NICE-MC is an excellent pioneer work on bridging MCMC and NNs by learning NN transition kernels . Ours instead directly utilizes properties of existing NN modules for the transition kernel . The two share the same spirit that NN helps design MCMC transition kernels . We have added the citation in the related work . In all , thanks for your valuable review , and we hope you find our explanations helpful !"}, "1": {"review_id": "c7rtqjVaWiE-1", "review_text": "* * Summary * * The paper proposes an MCMC based sampling mechanism for GANs . In contrast to earlier work , the proposal distribution is conditioning conditioned on the previous state ( here in latent space ) , which is supposed to help sampling efficiency . This is achieved by a clever re-parametrization of intermediate steps of the MCMC chain . As an example , the authors provide a Langevin version ( which uses gradient information ) of their method . I enjoyed reading this well-written paper and think the re-parameterized MCMC chain is a very neat idea that fits very naturally in the GAN framework . The paper is of quite incremental nature though : little to no theory contribution , only some incremental empirical benefits . I also have some doubts whether the comparisons are fair in terms of compute and effective sample size ( more below ) . Below are a few points to consider : * * Effective sample size * * What puzzles me here is the fact that while the independent proposal of Turner et al gets stuck in certain parts of the space , the Langevin updates of the proposed method ( Figure 4 ) do have less variability . I assume the incremental improvement happen due to relatively small step sizes in the Langevin sampler ? This would have a bad effect on the effective sample size . Does the MCMC chain eventually visits other parts of the space , or does it need to be restarted for every sample created ? This does not seem to be true for the MH sampler , which despite its low acceptance rate produces samples from the entire space . Could the authors clarify this , and if possible provide measure of effective sample size for a fixed number of iterations ? * * Compute * * The authors do neither discuss nor evaluate the computational load compared to other methods , especially performance metrics as a function of compute would be interesting . Or maybe the computational load is comparable for all methods ? * * Title * * The term `` coupled '' is currently heavily used within the MCMC community , e.g . [ 2 ] , and it denotes a different technique . I would suggest replacing it by `` re-parameterized '' which would be more accurate in that respect . * * '' Proof '' for convergence * * The abstract claims that convergence to the true data distribution is proved , but that is really stretching the term . All the paper contains is a valid MH ratio . But that alone does not prove convergence , for which the authors would need to go into the weeds of MCMC convergence , with conditions on the target distribution . This is especially true for the Langevin proposal , e.g. [ 1 ] . * * Experiments * * I would suggest to move the Swiss roll dataset to the Appendix and replace it with something more interesting , preferably higher dimensional . This would make the paper stronger . In fact some analysis how all the different sampling methods compare as a function of dimensional ( or `` difficulty '' ) would make it even more so . [ 1 ] Roberts , G. O. , & Tweedie , R. L. ( 1996 ) . Exponential convergence of Langevin distributions and their discrete approximations . Bernoulli . [ 2 ] Jacob , P. E. , O'Leary , J. , & Atchad\u00e9 , Y. F. ( 2017 ) . Unbiased markov chain monte carlo with couplings . JRSS-B .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your valuable comments . We address them in detail as follows . * * Q1 * * : Improvements are due to relatively small step sizes in the Langevin sampler ? The effect on the effective sample size ? Does the MCMC chain eventually visits other parts of the space\uff1f * * A1 * * : First of all , the improvement is brought by the relatively small step size that we choose for better sample quality . As is mentioned in Section 5.2 , we evaluate our methods following the conventional setting of the sampling methods of GANs ( as in MH-GAN , DDLS ) by running a chain for 640 steps , and taking only the sample of the last step for evaluation . In this test scenario , because we only need the last example , we do not need the chain to have diversity among its different steps , thus effective sample size is not a matter of concern here . Instead , we mainly use the chain to finetune the initial sample with a relatively small step size ( e.g. , tau=0.01 for CIFAR-10 ) for better sample quality . As shown in the newly added Figure 5 , our gradient-based proposal can also propose very diverse examples with large step size ( tau=1 for CIFAR-10 ) , just like the independent proposal of MH-GAN ( which is an extreme case of our REP proposal ) . Therefore , the resulting chains are likely able to visit other parts of the space . We have added this discussion to the last paragraph of Section 5.2 . We have also added multi-modal experiments in Appendix A.4 , and show that our method well preserves the sample diversity while promoting the sample quality . * * Q2 * * : Comparison of computation cost . * * A2 * * : We have added a comparison of computation cost in Table 5 in the Appendix A.3 . Comparing DDLS and ours , they take 88.94s and 88.85s to run 500 chains for 640 steps on a single 1080 Ti GPU , respectively , hence the difference is negligible . Without the MH-step , our method takes 87.62s , meaning the additional MH-step only costs 1.4 % computation overhead , which is almost negligible , but it brings a significant improvement in sample quality . * * Q3 * * : The title needs to be changed to avoid confusion with existing literature . * * A3 * * : Thank you for your kind advice . We are happy to take your excellent advice and rename the title with `` Reparameterized Markov Chains '' together with the short name `` REP-GAN '' . * * Q4 * * : The abstract claims that convergence to the true data distribution is proved , but that is really stretching the term . All the paper contains is a valid M2H ratio . But that alone does not prove convergence . * * A4 * * : Thanks for pointing it out . Indeed , as our reparameterized proposal is designed to be a general framework compatible with many MCMC proposals , we can not give convergence results without knowing the properties of the specific proposal distribution . Hence , in our Theorem 1 , we assume the chain having certain regularity conditions ( irreducible , aperiodic , and not transient [ 1 ] ) to obtain convergence in general . As you suggested , we have revised our statements in the paper to make it more clear and rigorous . [ 1 ] Gelman et al . ( 2013 ) .Bayesian data analysis . CRC press . * * Q5 * * : Compare different methods as a function of input dimension , or task difficulty . * * A5 * * : Following your suggestions , we compare the sampling methods with increasing task difficulties . Specifically , in the multi-modal experiments in Appendix A.4 , we experiment with the mixture of Gaussian distributions that have 5x5 , 9x9 , and 13x13 modes . Intuitively , the tasks get harder with more modes to cover , as it becomes more challenging for the sampling methods to improve sample quality while preserving sample diversity . As shown in Figure 7 and 8 , our method has done a good job by outperforming both independent samplers ( MH-GAN ) and pure Langevin steps ( DDLS ) . It shows our method is less unlikely to degrade sample diversity while promoting the overall sample quality . Please refer to the discussion there for more details . Overall , thank you a lot for your insightful comments , which encourage us to collect more interesting results . Hope our feedback could help answer your concerns !"}, "2": {"review_id": "c7rtqjVaWiE-2", "review_text": "Summary : The paper proposes an MCMC sampling strategy for GANs . The idea is clear : for high-dimensional x , making a good proposal is difficult , so they propose to do that in the latent space . Then they use a similar strategy as MH-GAN to compute a rejection strategy . The difference between the two methods is that proposal in MH-GAN does not depend on x while the proposed method does , and the argument is that it results in a higher acceptance rate . The idea is interesting , and the paper is relatively well-written , but the execution and experiment left a lot to be desired . * One of the arguments of the paper ( in the related work ) the method overcomes sample low sample diversity . No metric is reported for that . The authors need to report LPIPS [ 1 ] and compare different methods . * Fig 4 shows very poor diversity ; all samples seem identical to each other , and honestly , it seems that the GAN collapsed . * The results in Fig 3 is also very strange . First of all , what is the point of Fig 3 ( left ) ? All IS scores are roughly going up , but this figure is no comparison and does not show any if one method is doing better . Fig 3 ( right ) is more concerning . One expects that as the epoch increases , the generator becomes better at generating samples . The acceptance rate improves ( b/c G generates more realistic results and discriminator can not tell them apart ) ; why the acceptance rates are going down ? * Fig 2 is also presented in a confusing way . All methods except the second column from left almost perform the same and propose methods is in both columns ( ! ! ) What does each column , row mean ? Given what I read in the related work , I expected to see the model 's performance in the sample a multi-modal distribution . In fact , I want to see that : 100 Gaussian distributions centered at the 10x10 grids and small enough variance . I want to see how this method performs in recovering centers of the clusters ( you can see examples in the literature ) . * Given that finally , the sampling strategy becomes very similar to the recent energy-based method . It is fair to say comparison is required . Yes , GAN is and the energy-based methods are different but the sampling strategy ( the Langevian dynamic ) are very similar and I would like to see how those two methods perform in term of quality of the samples . * Finally , if one views this method as a general strategy for generating samples using GAN , perhaps you can think of this approach as an approximate inference approach for inference in a complicated Baysian model . This paper does not focus on that and I do n't expect authors to do any experiment for that but it can useful there . [ 1 ] Richard Zhang , Phillip Isola , Alexei A Efros , Eli Shechtman , and Oliver Wang . The Unreasonable Effectiveness of Deep Features as a Perceptual Metric . In CVPR , 2018 .", "rating": "5: Marginally below acceptance threshold", "reply_text": "* * Q4 * * : Figure 2 is presented in a confusing way . Expect a multi-modal experiment . * * A4 * * : Sorry for the confusion . Each sub-figure shows the samples obtained by the corresponding sampling method on its top . The sub-figures are arranged left to right , and we show pairs of results of DDLS and our method under different step sizes ( tau ) to illustrate their different behaviors , now marked with dashed boxes . To address your concern , we have added the multi-modal experiments , including a 25-Gaussians experiment as well as more difficult tasks with more modes , in Appendix A.4 . In the newly added Figure 7 and 8 , our method shows clear benefits in terms of sampling quality , sample diversity , and numerical stability . Please refer to the discussion there for more details . * * Q5 * * : Similarity and comparison with energy-based models ( EBM ) . * * A5 * * : Yes our sampling scheme of GANs is similar to that of EBM because essentially they both utilize HMC-like methods . However , there is an essential difference that EBM uses HMC sampling for training , while our method only uses it to post-process trained GANs . Thus , the difference between their performance could be largely due to the difference of training mechanisms between EBM and GAN themselves , instead of the difference in sampling methods . As far as we can see , EBM and GAN have become two strong competitors in the field of generative models , each with a lot of modern variants with state-of-the-art results . A fair comparison of the two diagrams may need a more thorough , large-scale study of various components that affect their relative performance , which is left for our further work . * * Q6 * * : Our method can serve as a general approximate inference method for complex Bayesian models . * * A6 * * : Yes , it is ! Thanks for pointing out that . Indeed , our method can serve as a general approximate inference technique for Bayesian models by bridging MCMC and GANs . Previous works [ 2,3,4 ] also propose to avoid the bad geometry of a complex probability measure by reparameterizing the Markov transitions into a simpler measure . However , these methods are limited to explicit invertible mappings without dimensionality reduction . In our work , we first show that it is also tractable to conduct such model-based reparameterization with implicit models like GANs . Also notice that our method is designed for GANs , but not limited to existing ( unstable ) GAN training mechanisms because our method does not depend on how GANs are trained . In fact , our method can be applied to general implicit generative models with density ratio estimation . We have now added this discussion to the last paragraph in Section 4.2 . [ 2 ] Marzouk et al . ( 2016 ) .An introduction to sampling via measure transport . [ 3 ] Hoffman et al . ( 2019 ) .Neutra-lizing bad geometry in Hamiltonian Monte Carlo using neural transport . [ 4 ] Titsias . ( 2017 ) .Learning model reparametrizations : Implicit variational inference by fitting MCMC distributions . Thank you again for all your insightful comments and hope our feedback is helpful !"}, "3": {"review_id": "c7rtqjVaWiE-3", "review_text": "The paper is a good idea . It is based on the notion of following the same line of reasoning as the prior work of MH-GAN . However , it makes the crucial advance of allowing the use of gradient information for the far more efficient HMC-type samplers . The paper is able to do much of the sampling in the latent space , which enables the use of gradient-based sampling . One nitpick would be that I suspect there is a latent assumption that the mapping of z - > x is injective ( but need not be bijective like in normalizing flows ) . However , this is not explicitly stated at all in the paper .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your positive comments ! Here is our answer to your concern . Q1 : Is there a latent assumption that the mapping of z - > x is injective ? A1 : Yes , it is true . When introducing Eq . ( 8 ) , the change-of-variable formula , we omit technical details to focus on the main story , and instead refer readers to the reference for further details and proof . We have now made these points clear in the newly added Appendix A.1 . First , the mapping should be injective , otherwise there would not be a \u201c one-to-one \u201d change of variables . Second , according to Ben-Israel [ 1 ] , to ensure Eq . ( 8 ) hold , we also need the Jacobian matrix of the mapping to have full column rank for every input . A mild sufficient condition for injectivity is that the generator only contains ( non-degenerate ) affine layers and injective non-linearities , like LeakyReLU . It is not hard to show that such a condition also implies the full rankness of the Jacobian . In fact , this architecture has already been found to benefit GANs and achieved state-of-the-art results [ 2 ] . The affine layers here are also likely to be non-degenerate because their weights are randomly initialized and typically will not degenerate in practice during the training of GANs . Thank you again and hope you find our explanations helpful ! [ 1 ] Ben-Israel , A . ( 1999 ) .The change-of-variables formula using matrix volume . SIAM Journal on Matrix Analysis and Applications , 21 ( 1 ) , 300-312 . [ 2 ] Tang , S. ( 2020 ) . Lessons Learned From the Training of GANs on Artificial Datasets . IEEE Access , 8 , 165044-165055 ."}}