{"year": "2018", "forum": "rJlMAAeC-", "title": "Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction", "decision": "Accept (Poster)", "meta_review": "This paper present a functional extension to NPI, allowing the learning of simpler, more expressive programs.\n\nAlthough the conference does not put explicit bounds on the length of papers, the authors pushed their luck with their initial submission (a body of 14 pages). It is clear, from the discussion and the reviews, however, that the authors have sought to substantially reduce the length of their paper while improving its clarity.\n\nReviewers found the method and experiments interesting, and two out of three heartily recommend it for acceptance to ICLR. I am forced to discount the score of the third reviewer, which does not align with the content of their review. I had discussed the issue of length with them, and am disappointed that they chose not to adjust their score to reflect their assessment of the paper, but rather their displeasure at the length of the paper (which, as stated above, does push the boundary a little).\n\nOverall, I recommend accepting this paper, but warn the authors that this is a generous decision, heavily motivated by my appreciation for the work, and that they should be careful not to try such stunts in future conference in order to preserve the fairness of the submission process.", "reviews": [{"review_id": "rJlMAAeC--0", "review_text": "The paper is interesting to read and gives valuable insights. However, the paper clearly breaks the submission guidelines. The paper is far too long, 14 pages (+refs and appendix, in total 19 pages), while the page limit is 8 pages (+refs and appendix). Therefore, the paper should be rejected. I can not foresee how the authors should be able to squeeze to content into 8 pages. The paper is more suitable for a journal, where page limit is less of an issue.", "rating": "3: Clear rejection", "reply_text": "Thanks very much for your comments . The original version is indeed too long . We have uploaded a revision . We have shortened the paper from 14 to 12 pages ( +refs and appendix , from 19 to 17 pages ) while preserving most of the important contents by : 1 ) abbreviating the description of NPI and removing NPI 's inference algorithm ( Algorithm 1 in the original version ) in Section 2.1 ; 2 ) rewriting some paragraphs ( especially those in Section 5 ) to make them more succinct ; 3 ) substantial re-typesetting ( e.g.placing some figures and tables side by side , which is also common practice in other submissions ) . In order to present the somewhat intricate idea as clear as possible , we use in this paper quite a few figures and tables . The bad typesetting of them in the original version made the manuscript unnecessarily long . Considering the dense contents of the paper this is the best that we can do . We 'd like to mention that the 12-page revision is in fact shorter than a number of other submissions , e.g . : 1.Modular Continual Learning in a Unified Visual Environment ( https : //openreview.net/forum ? id=rkPLzgZAZ ) , 14 pages 2 . Towards Synthesizing Complex Programs From Input-Output Examples ( https : //openreview.net/forum ? id=Skp1ESxRZ ) , 16 pages 3 . Sobolev GAN ( https : //openreview.net/forum ? id=SJA7xfb0b ) , 15 pages 4 . N2N learning : Network to Network Compression via Policy Gradient Reinforcement Learning ( https : //openreview.net/forum ? id=B1hcZZ-AW ) , 13 pages"}, {"review_id": "rJlMAAeC--1", "review_text": "Quality The paper is very interesting and clearly motivated. The idea of importing concepts from functional programming into neural programming looks very promising, helping to address a bit the somewhat naive approach taken so far in the deep learning community towards program induction. However, I found the model description difficult to fully understand and have significant unresolved questions - especially *why* exactly the model should be expected to have better universality compared to NPI and RNPI, given than applier memory is unbounded just like NPI/RNPI program memories are unbounded. Clarity The paper does a good job of summarizing NPI and motivating the universality property of the core module. I had a lot of questions while reading: What is the purpose of detectors? It is not clear what is being detected. From the context it seems to be encoding observations from the environment, which can vary according to the task and change during program execution. The detector memory is also confusing. In the original NPI, it is assumed that the caller knows which encoder is needed for each program. In CNPI, is this part learned or more general in some way? Appliers - is it the case that *every* program apart from the four combinators must be written as an applier? For example ADD1, BSTEP, BUBBLESORT, etc all must be implemented as an applier, and programs that cannot be implemented as appliers are not expressible by CNPI? Memory - combinator memory looks like a 4-way softmax over the four combinators, right? The previous NPI program memory is analogous then to the applier memory. Eqn 3 - binarizing the detector output introduces a non-differentiable operation. How is the detector then trained e.g. from execution traces? Later I see that there is a notion of a \u201ccorrect condition\u201d for the detector to regress on, which makes me confused again about what exactly the output of a detector means. Computing the next subprogram - since the size of applier memory is unbounded, the core still needs to be aware of an unlimited number of subprograms. I must be missing something here - how does the proposed model therefore achieve better universality than the original NPI and RNPI models? Analysis - for the claim of perfect generalization, I think this will not generally hold true for perceptual inputs. Will the proposed model only be useful in discrete domains for algorithmic tasks, or could it be more broadly applicable, e.g. to robotics tasks? Originality This methods proposed in this paper are quite novel and start to bridge an important gap between neural program induction and functional programming, by importing the concept of combinator abstraction into NPI. Significance The paper will be significant to people interested in NPI-related models and neural program induction generally, but on the other hand, there is currently not yet a \u201ckiller application\u201d to this line of work. The experiments appear to show significant new capabilities of CNPI compared to NPI and RNPI in terms of better generalization and universality, as well as being trainable by reinforcement learning. Pros - Learns new programs without catastrophic forgetting in the NPI core, in particular where previous NPI models fail. - Detector training is decoupled from core and memory training, so that perfect generalization does not have to be re-verified after learning new behaviors. Cons - So far lacking useful applications in the real world. Could the techniques in this paper help in robotics extensions to NPI? (see e.g. https://arxiv.org/abs/1710.01813) - Adds a significant amount of further structure into the NPI framework, which could potentially make broader applications more complex to implement. Do the proposed modifications reduce generality in any way? ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your very constructive feedback . We have uploaded a revision to incorporate your suggestions . We will try to answer your questions and concerns one by one below . > especially * why * exactly the model should be expected to have better universality compared to NPI and RNPI , given than applier memory is unbounded just like NPI/RNPI program memories are unbounded . Also related to : > Computing the next subprogram - since the size of applier memory is unbounded , the core still needs to be aware of an unlimited number of subprograms . I must be missing something here - how does the proposed model therefore achieve better universality than the original NPI and RNPI models ? Re : Applier memory is indeed unbounded . However , the core is in fact * not * aware of any actual applier programs . Let 's take the BSTEP program in Figure 4 as an example ( also see Figure 3 ( c ) and line 5-7 and 15-16 of Algorithm 1 in the revision ) . At the first execution step , the core does not directly call 'COMPSWAP ' as the next subprogram . It calls 'a1 ' . Then the actual subprogram COMPSWAP 's ID is looked up in the frame , which is constructed on the fly by the BSTEP applier when calling linrec . The _Parse function in Algorithm 1 and Lemma 1 in Appendix C guarantee that the frame will be filled with correct values . In CNPI , the core is only responsible for interpreting combinators and is only aware of formal callable arguments . We offload the responsibility of interpreting appliers from the core to a parser . The two key facts are : 1 ) the execution of all appliers follows exactly the same pattern : call a combinator with a detector arguments and a fixed number of callable arguments and then return , and 2 ) the parser itself is a * fixed * program ( see function _Parse in Algorithm 1 ) with no learning taking place at all . As a result , the parser can correctly interpret * any * applier with appropriately set program embeddings ( according to equation ( 1 ) ) regardless of how many applier programs are already stored in the program memory . We propose and prove a lemma ( Lemma 1 in Appendix C ) on the interpretation of appliers in the revision . The distinguishing feature of CNPI that enables this separation of responsibility and that eventually provides the universality of CNPI is the dynamic binding of formal detectors and callable arguments to actual programs . We have rewritten the first half of Section 4 to explicitly propose a theorem and a proposition on the universality of CNPI and added Appendix C in the revision to prove the theorem . Please see the last part of our reply to Review 3 's comments for more details . > Appliers - is it the case that * every * program apart from the four combinators must be written as an applier ? For example ADD1 , BSTEP , BUBBLESORT , etc all must be implemented as an applier , and programs that can not be implemented as appliers are not expressible by CNPI ? Re : Yes.Actually we have proposed a `` combinatory programing language '' for CNPI where programs are composed by iteratively defining appliers from the bottom up . We give a formal definition of combinatory programs in Appendix C in the revision . We propose a proposition in Section 4 stating that any recursive program is combinatorizable , i.e. , can be converted to a combinatory equivalent . This proposition shows that the set of all combinatory programs is adequate for solving most algorithmic tasks , considering that most , if not all , algorithmic tasks have a recursive solution . Instead of giving a formal proof of it , we propose a concrete algorithm for combinatorizing any program set expressing an recursive algorithm in Appendix B . Although we believe that the proposition is true ( effectively , it says that the combinatory programming language is Turing-complete ) , we think that a formal proof of it would be too tedious to be included in this paper . The intuition behind is that during the execution of a combinatory programs , combinators and appliers call each other to form an alternating call sequence until reaching a ACT . Arbitrarily complex program structures can be expressed in this way ( see the last paragraph of Section 3.1 and Figure 3 ( c ) and ( d ) ) . We 'd like to point out that the circle formed by the mutual invocation of combinators and appliers is a very fundamental construct in the interpretation of functional program languages . It can be seen as a `` neural equivalent '' of the eval-apply circle that lies at the heart of a LISP evaluator . The book `` Structure and Interpretation of Computer Programs ( 2nd edition ) '' has a good discussion on this ( Section 4.1.1 , Figure 4.1 : The eval-apply cycle exposes the essence of a computer language.https : //mitpress.mit.edu/sicp/full-text/book/book-Z-H-26.html # % _sec_4.1.1 ) . The expressive power ( Turing-completeness ) of functional programming languages like LISP has been well recognized . Anyway , we admit that this is a weakness regarding the theoretical rigor of this paper , which could be improved by future work ."}, {"review_id": "rJlMAAeC--2", "review_text": "The authors propose a variant of the neural programmer-interpreter that can support so called combinators for composing an d structuring computations. In a sense, programs in this variant are at a higher level than those in the original neural programmer-interpreter. The distinguishing aspect of the neural programmer-interpreter is that it learns a generic core (which in the variant of the paper corresponds to an interpreter of the programming language) and programs for concrete tasks simultaneously. Increasing the expressivity of the language with combinators has a danger of making the training of core very difficult. The authors avoids this pitfall by carefully re-designing the deterministic part of the core. For instance, they separate out the evaluation of the detector from the LSTM used for the core. Also, they use a fixed routine for parsing the applier instruction. The authors describe two ways of training their variant of the neural programmer-interpreter. The first is similar to the existing methods, and trains the variant using traces. The second is different and trains the variant using just input-output pairs but under carefully designed curriculum. The authors experimentally show that their approach leads to a more stable core of the neural programmer-interpreter that is close to being universal, in the sense that the core knows how to interpret commands. I found the new architecture of the neural programmer-interpreter very interesting. It is carefully crafted so as to support expressive combinators without making the learning more difficult. I can't quite judge how strong their experimental evaluations are, but I think that learning a neural programmer-interpreter from just input-output pairs using RL techniques is new and worth being pursued further. I am generally positive about accepting this paper to ICLR'18. I have three complaints, though. First, the paper uses 14 pages well over 8 pages, the recommended limit. Second, it has many typos. Third, the authors claim universality of the approach. When I read this claim, I expected a theorem initially but later I realized that the claim was mostly about informal understanding and got disappointed slightly. I hope that the authors consider these complaints when they revise the paper. * abstract, p1: is is universal -> is universal * p2: may still intractable to provable -> may still be intractable to prove * p2: import abstraction -> important abstraction * p2: a_(t+1)are -> a_(t+1) are * p2: Algorithm 1 The -> Algorithm 1. The * Algorithm1, p3: f_lstm(c,p,h) -> f_lstm(s,p,h) * p3: learn to interpreting -> learn to interpret * p3: it it common -> it is common * p3: The two program share -> The two programs share * p3: that server as -> that serve as * p3: be interpret by -> be interpreted by * p3: (le 9 in our -> (<= 9 in our * Figure 1, p4: the type of linrec is wrong. * p6: f_d et -> f_det * p8: it+1 -> i_(t+1) * p8: detector. the -> detector. The * p9: As I mentioned, I suggest you to make clear that the claim about universality is mostly based on intuition, not on theorem. * p9: to to -> to * p10: the the set -> the set * p11: What are DETs?", "rating": "7: Good paper, accept", "reply_text": "Thanks for your very constructive feedback . We have uploaded a revision to incorporate your suggestions . We will try to answer your questions and concerns one by one below . > First , the paper uses 14 pages well over 8 pages , the recommended limit . Re : We have shortened the paper from 14 to 12 pages ( +refs and appendix , from 19 to 17 pages ) while preserving most of the important contents by : 1 ) abbreviating the description of NPI and removing NPI 's inference algorithm ( Algorithm 1 in the original version ) in Section 2.1 ; 2 ) rewriting some paragraphs ( especially those in Section 5 ) to make them more succinct ; 3 ) substantial re-typesetting ( e.g.placing some figures and tables side by side , which is also common practice in other submissions ) . In order to present the somewhat intricate idea as clear as possible , we use in this paper quite a few figures and tables . The bad typesetting of them in the original version made the manuscript unnecessarily long . We 'd like to mention that the 12-page revision is in fact shorter than a number of other submissions , e.g . : 1.Modular Continual Learning in a Unified Visual Environment ( https : //openreview.net/forum ? id=rkPLzgZAZ ) , 14 pages 2 . Towards Synthesizing Complex Programs From Input-Output Examples ( https : //openreview.net/forum ? id=Skp1ESxRZ ) , 16 pages 3 . Sobolev GAN ( https : //openreview.net/forum ? id=SJA7xfb0b ) , 15 pages 4 . N2N learning : Network to Network Compression via Policy Gradient Reinforcement Learning ( https : //openreview.net/forum ? id=B1hcZZ-AW ) , 13 pages > Second , it has many typos . Re : We have corrected these and some other typos in the revision . We apologize for the carelessness leading to so many typos and thank you very much for the effort of pointing them out . * Figure 1 , p4 : the type of linrec is wrong . Do you mean that linrec has fewer arguments than shown in Figure 2 ? The pseudo-code in Figure 1 is only for illustration purpose . We deliberately use a simpler version of linrec to make its connection with ADD and BSTEP more apparent . * p11 : What are DETs ? DETs stand for detectors . The abbreviation is defined in paragraph 1 of Section 3.1 ."}], "0": {"review_id": "rJlMAAeC--0", "review_text": "The paper is interesting to read and gives valuable insights. However, the paper clearly breaks the submission guidelines. The paper is far too long, 14 pages (+refs and appendix, in total 19 pages), while the page limit is 8 pages (+refs and appendix). Therefore, the paper should be rejected. I can not foresee how the authors should be able to squeeze to content into 8 pages. The paper is more suitable for a journal, where page limit is less of an issue.", "rating": "3: Clear rejection", "reply_text": "Thanks very much for your comments . The original version is indeed too long . We have uploaded a revision . We have shortened the paper from 14 to 12 pages ( +refs and appendix , from 19 to 17 pages ) while preserving most of the important contents by : 1 ) abbreviating the description of NPI and removing NPI 's inference algorithm ( Algorithm 1 in the original version ) in Section 2.1 ; 2 ) rewriting some paragraphs ( especially those in Section 5 ) to make them more succinct ; 3 ) substantial re-typesetting ( e.g.placing some figures and tables side by side , which is also common practice in other submissions ) . In order to present the somewhat intricate idea as clear as possible , we use in this paper quite a few figures and tables . The bad typesetting of them in the original version made the manuscript unnecessarily long . Considering the dense contents of the paper this is the best that we can do . We 'd like to mention that the 12-page revision is in fact shorter than a number of other submissions , e.g . : 1.Modular Continual Learning in a Unified Visual Environment ( https : //openreview.net/forum ? id=rkPLzgZAZ ) , 14 pages 2 . Towards Synthesizing Complex Programs From Input-Output Examples ( https : //openreview.net/forum ? id=Skp1ESxRZ ) , 16 pages 3 . Sobolev GAN ( https : //openreview.net/forum ? id=SJA7xfb0b ) , 15 pages 4 . N2N learning : Network to Network Compression via Policy Gradient Reinforcement Learning ( https : //openreview.net/forum ? id=B1hcZZ-AW ) , 13 pages"}, "1": {"review_id": "rJlMAAeC--1", "review_text": "Quality The paper is very interesting and clearly motivated. The idea of importing concepts from functional programming into neural programming looks very promising, helping to address a bit the somewhat naive approach taken so far in the deep learning community towards program induction. However, I found the model description difficult to fully understand and have significant unresolved questions - especially *why* exactly the model should be expected to have better universality compared to NPI and RNPI, given than applier memory is unbounded just like NPI/RNPI program memories are unbounded. Clarity The paper does a good job of summarizing NPI and motivating the universality property of the core module. I had a lot of questions while reading: What is the purpose of detectors? It is not clear what is being detected. From the context it seems to be encoding observations from the environment, which can vary according to the task and change during program execution. The detector memory is also confusing. In the original NPI, it is assumed that the caller knows which encoder is needed for each program. In CNPI, is this part learned or more general in some way? Appliers - is it the case that *every* program apart from the four combinators must be written as an applier? For example ADD1, BSTEP, BUBBLESORT, etc all must be implemented as an applier, and programs that cannot be implemented as appliers are not expressible by CNPI? Memory - combinator memory looks like a 4-way softmax over the four combinators, right? The previous NPI program memory is analogous then to the applier memory. Eqn 3 - binarizing the detector output introduces a non-differentiable operation. How is the detector then trained e.g. from execution traces? Later I see that there is a notion of a \u201ccorrect condition\u201d for the detector to regress on, which makes me confused again about what exactly the output of a detector means. Computing the next subprogram - since the size of applier memory is unbounded, the core still needs to be aware of an unlimited number of subprograms. I must be missing something here - how does the proposed model therefore achieve better universality than the original NPI and RNPI models? Analysis - for the claim of perfect generalization, I think this will not generally hold true for perceptual inputs. Will the proposed model only be useful in discrete domains for algorithmic tasks, or could it be more broadly applicable, e.g. to robotics tasks? Originality This methods proposed in this paper are quite novel and start to bridge an important gap between neural program induction and functional programming, by importing the concept of combinator abstraction into NPI. Significance The paper will be significant to people interested in NPI-related models and neural program induction generally, but on the other hand, there is currently not yet a \u201ckiller application\u201d to this line of work. The experiments appear to show significant new capabilities of CNPI compared to NPI and RNPI in terms of better generalization and universality, as well as being trainable by reinforcement learning. Pros - Learns new programs without catastrophic forgetting in the NPI core, in particular where previous NPI models fail. - Detector training is decoupled from core and memory training, so that perfect generalization does not have to be re-verified after learning new behaviors. Cons - So far lacking useful applications in the real world. Could the techniques in this paper help in robotics extensions to NPI? (see e.g. https://arxiv.org/abs/1710.01813) - Adds a significant amount of further structure into the NPI framework, which could potentially make broader applications more complex to implement. Do the proposed modifications reduce generality in any way? ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your very constructive feedback . We have uploaded a revision to incorporate your suggestions . We will try to answer your questions and concerns one by one below . > especially * why * exactly the model should be expected to have better universality compared to NPI and RNPI , given than applier memory is unbounded just like NPI/RNPI program memories are unbounded . Also related to : > Computing the next subprogram - since the size of applier memory is unbounded , the core still needs to be aware of an unlimited number of subprograms . I must be missing something here - how does the proposed model therefore achieve better universality than the original NPI and RNPI models ? Re : Applier memory is indeed unbounded . However , the core is in fact * not * aware of any actual applier programs . Let 's take the BSTEP program in Figure 4 as an example ( also see Figure 3 ( c ) and line 5-7 and 15-16 of Algorithm 1 in the revision ) . At the first execution step , the core does not directly call 'COMPSWAP ' as the next subprogram . It calls 'a1 ' . Then the actual subprogram COMPSWAP 's ID is looked up in the frame , which is constructed on the fly by the BSTEP applier when calling linrec . The _Parse function in Algorithm 1 and Lemma 1 in Appendix C guarantee that the frame will be filled with correct values . In CNPI , the core is only responsible for interpreting combinators and is only aware of formal callable arguments . We offload the responsibility of interpreting appliers from the core to a parser . The two key facts are : 1 ) the execution of all appliers follows exactly the same pattern : call a combinator with a detector arguments and a fixed number of callable arguments and then return , and 2 ) the parser itself is a * fixed * program ( see function _Parse in Algorithm 1 ) with no learning taking place at all . As a result , the parser can correctly interpret * any * applier with appropriately set program embeddings ( according to equation ( 1 ) ) regardless of how many applier programs are already stored in the program memory . We propose and prove a lemma ( Lemma 1 in Appendix C ) on the interpretation of appliers in the revision . The distinguishing feature of CNPI that enables this separation of responsibility and that eventually provides the universality of CNPI is the dynamic binding of formal detectors and callable arguments to actual programs . We have rewritten the first half of Section 4 to explicitly propose a theorem and a proposition on the universality of CNPI and added Appendix C in the revision to prove the theorem . Please see the last part of our reply to Review 3 's comments for more details . > Appliers - is it the case that * every * program apart from the four combinators must be written as an applier ? For example ADD1 , BSTEP , BUBBLESORT , etc all must be implemented as an applier , and programs that can not be implemented as appliers are not expressible by CNPI ? Re : Yes.Actually we have proposed a `` combinatory programing language '' for CNPI where programs are composed by iteratively defining appliers from the bottom up . We give a formal definition of combinatory programs in Appendix C in the revision . We propose a proposition in Section 4 stating that any recursive program is combinatorizable , i.e. , can be converted to a combinatory equivalent . This proposition shows that the set of all combinatory programs is adequate for solving most algorithmic tasks , considering that most , if not all , algorithmic tasks have a recursive solution . Instead of giving a formal proof of it , we propose a concrete algorithm for combinatorizing any program set expressing an recursive algorithm in Appendix B . Although we believe that the proposition is true ( effectively , it says that the combinatory programming language is Turing-complete ) , we think that a formal proof of it would be too tedious to be included in this paper . The intuition behind is that during the execution of a combinatory programs , combinators and appliers call each other to form an alternating call sequence until reaching a ACT . Arbitrarily complex program structures can be expressed in this way ( see the last paragraph of Section 3.1 and Figure 3 ( c ) and ( d ) ) . We 'd like to point out that the circle formed by the mutual invocation of combinators and appliers is a very fundamental construct in the interpretation of functional program languages . It can be seen as a `` neural equivalent '' of the eval-apply circle that lies at the heart of a LISP evaluator . The book `` Structure and Interpretation of Computer Programs ( 2nd edition ) '' has a good discussion on this ( Section 4.1.1 , Figure 4.1 : The eval-apply cycle exposes the essence of a computer language.https : //mitpress.mit.edu/sicp/full-text/book/book-Z-H-26.html # % _sec_4.1.1 ) . The expressive power ( Turing-completeness ) of functional programming languages like LISP has been well recognized . Anyway , we admit that this is a weakness regarding the theoretical rigor of this paper , which could be improved by future work ."}, "2": {"review_id": "rJlMAAeC--2", "review_text": "The authors propose a variant of the neural programmer-interpreter that can support so called combinators for composing an d structuring computations. In a sense, programs in this variant are at a higher level than those in the original neural programmer-interpreter. The distinguishing aspect of the neural programmer-interpreter is that it learns a generic core (which in the variant of the paper corresponds to an interpreter of the programming language) and programs for concrete tasks simultaneously. Increasing the expressivity of the language with combinators has a danger of making the training of core very difficult. The authors avoids this pitfall by carefully re-designing the deterministic part of the core. For instance, they separate out the evaluation of the detector from the LSTM used for the core. Also, they use a fixed routine for parsing the applier instruction. The authors describe two ways of training their variant of the neural programmer-interpreter. The first is similar to the existing methods, and trains the variant using traces. The second is different and trains the variant using just input-output pairs but under carefully designed curriculum. The authors experimentally show that their approach leads to a more stable core of the neural programmer-interpreter that is close to being universal, in the sense that the core knows how to interpret commands. I found the new architecture of the neural programmer-interpreter very interesting. It is carefully crafted so as to support expressive combinators without making the learning more difficult. I can't quite judge how strong their experimental evaluations are, but I think that learning a neural programmer-interpreter from just input-output pairs using RL techniques is new and worth being pursued further. I am generally positive about accepting this paper to ICLR'18. I have three complaints, though. First, the paper uses 14 pages well over 8 pages, the recommended limit. Second, it has many typos. Third, the authors claim universality of the approach. When I read this claim, I expected a theorem initially but later I realized that the claim was mostly about informal understanding and got disappointed slightly. I hope that the authors consider these complaints when they revise the paper. * abstract, p1: is is universal -> is universal * p2: may still intractable to provable -> may still be intractable to prove * p2: import abstraction -> important abstraction * p2: a_(t+1)are -> a_(t+1) are * p2: Algorithm 1 The -> Algorithm 1. The * Algorithm1, p3: f_lstm(c,p,h) -> f_lstm(s,p,h) * p3: learn to interpreting -> learn to interpret * p3: it it common -> it is common * p3: The two program share -> The two programs share * p3: that server as -> that serve as * p3: be interpret by -> be interpreted by * p3: (le 9 in our -> (<= 9 in our * Figure 1, p4: the type of linrec is wrong. * p6: f_d et -> f_det * p8: it+1 -> i_(t+1) * p8: detector. the -> detector. The * p9: As I mentioned, I suggest you to make clear that the claim about universality is mostly based on intuition, not on theorem. * p9: to to -> to * p10: the the set -> the set * p11: What are DETs?", "rating": "7: Good paper, accept", "reply_text": "Thanks for your very constructive feedback . We have uploaded a revision to incorporate your suggestions . We will try to answer your questions and concerns one by one below . > First , the paper uses 14 pages well over 8 pages , the recommended limit . Re : We have shortened the paper from 14 to 12 pages ( +refs and appendix , from 19 to 17 pages ) while preserving most of the important contents by : 1 ) abbreviating the description of NPI and removing NPI 's inference algorithm ( Algorithm 1 in the original version ) in Section 2.1 ; 2 ) rewriting some paragraphs ( especially those in Section 5 ) to make them more succinct ; 3 ) substantial re-typesetting ( e.g.placing some figures and tables side by side , which is also common practice in other submissions ) . In order to present the somewhat intricate idea as clear as possible , we use in this paper quite a few figures and tables . The bad typesetting of them in the original version made the manuscript unnecessarily long . We 'd like to mention that the 12-page revision is in fact shorter than a number of other submissions , e.g . : 1.Modular Continual Learning in a Unified Visual Environment ( https : //openreview.net/forum ? id=rkPLzgZAZ ) , 14 pages 2 . Towards Synthesizing Complex Programs From Input-Output Examples ( https : //openreview.net/forum ? id=Skp1ESxRZ ) , 16 pages 3 . Sobolev GAN ( https : //openreview.net/forum ? id=SJA7xfb0b ) , 15 pages 4 . N2N learning : Network to Network Compression via Policy Gradient Reinforcement Learning ( https : //openreview.net/forum ? id=B1hcZZ-AW ) , 13 pages > Second , it has many typos . Re : We have corrected these and some other typos in the revision . We apologize for the carelessness leading to so many typos and thank you very much for the effort of pointing them out . * Figure 1 , p4 : the type of linrec is wrong . Do you mean that linrec has fewer arguments than shown in Figure 2 ? The pseudo-code in Figure 1 is only for illustration purpose . We deliberately use a simpler version of linrec to make its connection with ADD and BSTEP more apparent . * p11 : What are DETs ? DETs stand for detectors . The abbreviation is defined in paragraph 1 of Section 3.1 ."}}