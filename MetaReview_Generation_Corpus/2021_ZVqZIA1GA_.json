{"year": "2021", "forum": "ZVqZIA1GA_", "title": "Deformable Capsules for Object Detection", "decision": "Reject", "meta_review": "This work proposes capsule networks with deformable capsules for tackling object detection. All reviewers agreed that object detection is an important problem that is interesting to the ICLR community. Reviewers also agree that the proposed approach is novel and interesting, and in particular they mention that proposing an efficient capsule network for detection is non-trivial. On the less positive side, during the discussion phase all reviewers had concerns about the weak experimental validation, particularly missing ablation studies to analyse the effectiveness of their contributions. At the end, all reviewers felt that, while this is a promising direction of research for object detection, the experimentation should be improved.", "reviews": [{"review_id": "ZVqZIA1GA_-0", "review_text": "The paper proposes to use the capsules to perform object detection on COCO . Capsules , while showing promises , are usually too expensive for tasks beyond MNIST and Cifar . The authors propose three key improvements in DeformCaps , SplitCaps and SE-Routing to improve the efficiency and therefore allow capsules to be applied on larger tasks such as object detection . The authors claim novelties in : -- First ever capsule-based object detection on COCO . -- Deformable capsules that let parent to samples child capsules instead of having fixed connections to improve efficiency . -- SplitCaps : a reparametrization trick to reduce the number of capsules needed . -- Squeeze-and-excitation routing that finds agreement without iterative loop . I agree with the authors ' novelty claims . Strengths : -- Impressive results : Capsule Networks are well known to be computationally expensive . Getting it to work on large images is certainly no easy task . There has been other works operating on larger images , as noted by this paper , but they usually can not achieve quality on par with CNNs . Having said that , I need to note that the SOTA for COCO has consistently improved , and is at ~51 % AP [ a ] , quite better than the numbers listed in Table 1 . -- Good novelty : DeformCapsule and SplitCaps both follow a straightforward pattern to dissect prohibitively large tensor predictions into smaller ones . And together with the SE-routing methods , the novelty should be sufficient for this venue . -- Clear writing . Figure 1 and 2 helped a lot with the understanding of the key components as well . [ a ] : SpineNet : Learning Scale-Permuted Backbone for Recognition and Localization Weaknesses : -- Insufficient experimentation : There is only a single experimental table that contains both comparisons to the SOTA and ablations to DeformCaps and SE-Routing . It would be nice to see additional results , be it on another dataset / task ( e.g.sem seg ) , or even additional ablations . For example , one premise of capsules was the requirement of less training data . Is it true here as well ? Conclusion : I 'd recommend acceptance because of the strong results and good novelty . The only major weakness is the lack of additional ablations to highlight the advantages ( if not on AP ) over CNNs . Nonetheless , I believe this work is a good step towards more interests and advances in capsules , and will be of interests to the audience of this venue . Post-rebuttal : I concur with R1 in that the results look poor when taking into the account how close the proposed method is compared to CenterNet and that it was finetuned from a CenterNet . Therefore , I 'll lower my rating to 6 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We appreciate the reviewer \u2019 s thoughtful consideration of our work and agree with the reviewer \u2019 s conclusions . We are hopeful the novelties proposed , which culminate in enabling capsules to scale up to large-scale tasks , will encourage interest and future advancements in capsule networks for a wide range of applications . For completeness , we would like to address two of the points made by the reviewer . 1. \u201c SOTA for COCO has consistently improved , and is at ~51 % AP [ a ] \u201d . The field is moving extremely quickly and results are consistently being improved . A main advantage of our proposed capsule innovations is that they act solely within a new detection head on the network . Hence , any improvements in network backbones can be easily swapped in . For example , the reviewer referenced SpineNet [ a ] uses a RetinaNet detection head which could easily be replaced by our proposed SplitCaps detection head . This is a strength of our work , indeed . 2. \u201c It would be nice to see additional results , be it on another dataset / task ( e.g.sem seg ) , or even additional ablations . For example , one premise of capsules was the requirement of less training data . Is it true here as well ? \u201d We again completely agree with the reviewer \u2019 s opinion . Additional experimentation is nearly always desirable and we can think of a large number of new datasets and tasks we are excited to pursue , as well as hopefully see others in the community investigate . For example , the task of ReID/Search from different viewpoints would be an excellent candidate for testing the generalization of capsules to new viewpoints . However , we would like to emphasize that the large number of interesting further studies that could be performed is a benefit of our proposed work and will hopefully lead to a flourishing of new capsule network research , rather than a negative for us not performing all of them ourselves in this single-scoped paper which introduces these concepts . Other works , such as [ b ] demonstrate capsule networks require less training data , and we felt such ablations about capsule networks in general would take away from the specific innovations being proposed in this study . Refs : [ a ] Du , Xianzhi , et al . `` SpineNet : Learning scale-permuted backbone for recognition and localization . '' Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2020 . [ b ] Jim\u00e9nez-S\u00e1nchez , Amelia , Shadi Albarqouni , and Diana Mateus . `` Capsule networks against medical imaging data challenges . '' Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis . Springer , Cham , 2018 . 150-160 ."}, {"review_id": "ZVqZIA1GA_-1", "review_text": "Pros : It is indeed that capsules have many promising attributes but they are not quite easy to be exploited in object detectors . This paper has addressed many problems existed when applying capsule architectures for the object detection task . In particular , deformable capsules , SplitCaps , and SE-Routing are respectively introduced to help tackle the object detection with capsules . I believe the techniques of this paper will attract interests from researchers in the corresponding areas . The writing is also good . Cons : There are several points that prevent me from giving a higher rating : 1 ) I feel that the descriptions or presentations of introduced techniques are not quite sufficient . In particular , I am confused about the details of deformable capsules . What are the exact operations performed by the deformable capsules ? Is it to make parent capsules only aggregate information from a smaller set of their children and the sampling of such a smaller set is implemented by deformable operations ? I believe it will be much better to present some detailed formulations or equations to illustrate this operation . Similarly , I also recommend adding detailed equations to describe SE-Routing . 2 ) Without sufficient information about operations , I found that the descriptions of motivations are also quite weak , especially in the introductory part . It seems that the authors only mention the problems they will address and the techniques they proposed to address problems . There is not sufficient content briefly explaining why the proposed techniques can tackle the mentioned problems , or at least what are the advantages of the proposed techniques for tackling the problems . 3 ) The figures also have many confusing points . For example , in Figure 1 , the authors marked that solid red arrows represent 'up ' but I can only find dotted red arrows in the figure . Moreover , in what place the modules inside the big blue box is implemented in the detector ? After reading , I think it should represent what 's inside the SplitCaps , but I do recommend the authors to add some indicative symbols to corresponding related modules . 4 ) In addition to the reviewed literature , I found that there are some missing articles that also study how to borrow the capsule concepts for various computer vision tasks . For example : [ 1 ] Vijayakumar T. Comparative study of capsule neural network in various applications [ J ] . Journal of Artificial Intelligence , 2019 , 1 ( 01 ) : 19-27 . [ 2 ] Zhao Y , Birdal T , Deng H , et al.3D point capsule networks [ C ] //Proceedings of the IEEE conference on computer vision and pattern recognition . 2019 : 1009-1018 . [ 3 ] Chen Z , Zhang J , Tao D. Recursive Context Routing for Object Detection [ J ] . International Journal of Computer Vision , 2020 : 1-19 . Overall , I would like to have some feedback from the authors regarding the above issues before making my final decision .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We appreciate the reviewer \u2019 s comments . We will do our best to address each of these comments below in a succinct manner . 1. \u201c I feel that the descriptions or presentations of introduced techniques are not quite sufficient . In particular , I am confused about the details of deformable capsules . What are the exact operations performed by the deformable capsules ? Is it to make parent capsules only aggregate information from a smaller set of their children and the sampling of such a smaller set is implemented by deformable operations ? I believe it will be much better to present some detailed formulations or equations to illustrate this operation . Similarly , I also recommend adding detailed equations to describe SE-Routing. \u201d We understand the reviewer \u2019 s request for clarification on some of the points related to deformable capsules specifically and the work in general . As mentioned in our response to Reviewer 1 , capsule networks by nature can be somewhat involved in their explanation . We did our best now to sample the relevant capsule literature in the field at major venues ( e.g.NeurIPS , ICLR , etc . ) and ensure that our basic definitions and formulations are consistent with those already accepted and published in the field . To directly address the raised questions , the purpose of deformable capsules in short is this . The original method of fully-connected capsules in CapsNet [ a ] was to sample all children from a previous layer when forming parents in the current layer . This method does not scale up to larger image sizes ( described in Section 2 Paragraphs 1 and 4 ) , so several works introduced convolutional style capsules which only sample children from a smaller local kernel centered on the parent capsules spatial location ( described in Section 2 Paragraph 1 ) . Our approach is an extension of these convolutional methods which subsample children . However , instead of sampling in a geometrically-rigid manner , which does not easily allow for spatial deformations of objects and is antithetical to one of the main benefits of capsules ( described in Section 2 Paragraph 1 ) , we do so in a learned dynamic manner ( described in Section 2 Paragraph 2 ) . The formulation of that is identical to the formulation in deformable convolutions , where a first set of weights is learned to dynamically predict a set of offsets for the second set of weights to be applied to ( cited and described in Section 2 Paragraph 3 ) . We choose not to repeat the entire formulation of deformable kernels in the paper , as such is fairly well-known already . In regards to equations for SE-Routing , we have included a large number of in-line equations throughout Section 3.2 to precisely provide the formulation of our proposed methods ."}, {"review_id": "ZVqZIA1GA_-2", "review_text": "# # # summary This paper introduces capsule network for object detection . To solve the issue of capsule network when applied to large-scale detection problems , this paper develops deformable capsules , a new prediction head SplitCaps , and a dynamic routing algorithm , SE-Routing . Experiments are conducted on COCO where it performs slightly worse than the baselines but arguably predicts less false positives . # # # pros I appreciate the spirit of developing new architectures for a highly-competitive task like object detection . It 's totally acceptable that the performance can not fully match the SOTA results in this kind of scenario . This paper is insightly as it studies several important issues of capsule network when being applied to large-scale visual tasks . The proposed solutions have at least make the framework run-able on standard hardware . # # # cons 1 . My current rating is not purely based on the performance , but it is one of the major concerns here . The proposed framework ( 1 ) performs worse than baseline -- CenterNet , and ( 2 ) performs much worse then the SOTA solutions ( Tab.1 ) in terms of both performance and speed . Note that the network weights are initialized from CenterNet . 2.The whole analysis in Appendix A.2 reads very confusing for several reasons : * CenterNet achieves higher AP ( TP/ ( TP+FP ) ) and also high FP , which is a quite common thing to me . Ignoring the ratio and simply compare the absolute value of FP does n't seems to be the correct thing to do . * Some visualizations are weird like Fig.4 human and dog . Why NMS can not remove such highly-redundant predictions ? It seems more like a bug to me . * On page 12 top row it writes `` CenterNet consistently producing fairly confident false predictions ( e.g. > 0.4 ) '' , how does this threshold 0.4 is chosen ? It 's not a standard thing and in fact if we improve it to 0.5 or higher , most of the FPs about CenterNet will disappear . Moreover , is this how FP gets counted ? If yes , I think this is problematic as the total number ( TP+FP ) is changing across methods . A more fair way is to choose top-k ( k=100 in coco ) predictions and compute the metrics . 3.Lots of reference are missing . For example , Tab.1 compares multiple different methods but most of them are not cited . The related work only cites few very classical papers , but most recent works are missing . 4.The writing , especially the approach section , is n't very clear . I had a relatively hard time to understand how do each modules work , and what are the motivations behind these design choices . 5.Moreover , there are couple of new things proposed , and each one of them have specific design choices and parameters . However , there are no ablation studies properly studying them . As a results I do n't understand which module is working , and how does it work . # # # questions 1 . How do the FPS numbers in Tab.1 get computed ? Are they simply borrowed from original paper or some published work ? Some of them look strange to me . 2.Why KL in Sec.3.2 ? Does the asymmetric natural of KL influence the results ?", "rating": "4: Ok but not good enough - rejection", "reply_text": "We appreciate the reviewer \u2019 s thorough and critical review of our work . After careful inspection of each critique , we have identified that the major concern is related to a claim which is not made ( performance ) in our paper . Furthermore , several areas of potential misunderstanding for readers were highlighted by this review and we appreciate the chance to make these more clear . We will address each of these points individually ; but first , we would like to re-emphasize the contribution of this study is the development of novel techniques and architectures which allow capsule networks to scale up to large scale tasks and object detection for the first time in the literature . Our goal was not to push state-of-the-art performances and we are not claiming any such thing in the paper . Similar to the CapsNet [ a ] paper ( cited more than 2800 times since 2017 ) , which formalized the concept of capsules and introduced dynamic routing , but produced less than state-of-the-art results on CIFAR-10 . In analogy to CapsNet [ a ] paper , we feel that our study is an important study opening many potential avenues for further investigation of capsules on a now much wider range of accessible tasks . 1. \u201c The proposed framework ( 1 ) performs worse than baseline -- CenterNet , and ( 2 ) performs much worse then the SOTA solutions ( Tab.1 ) in terms of both performance and speed. \u201d We kindly direct the reviewer to our above paragraph about the primary focus of our study and also suggest that the reviewer \u2019 s point ( 2 ) is perhaps a bit of an overstatement . While we perform inferior to very slow networks such as TridentNet which runs at 0.7 FPS. , we still outperform networks which run at comparable speeds such as Mask R-CNN which runs at a slower 11 FPS ( compared to our 15 FPS ) and achieves a lower mAP score of 39.8 compared with our 40.6 . We also perform 7.6 mAP points better than YOLOv3 while only being 5 FPS slower ( 15 compared to 20 FPS ) . While we are obtaining all these encouraging results , we would like to re-emphasize that our focus was not accuracy improvement or architectural engineering to boost the accuracy . 2.Several comments related to False Positives appendix , \u201c Appendix A.2 reads very confusing for several reasons \u201d 2.a . \u201c CenterNet achieves higher AP ( TP/ ( TP+FP ) ) and also high FP , which is a quite common thing to me . Ignoring the ratio and simply comparing the absolute value of FP does n't seem to be the correct thing to do. \u201d We acknowledge that CenterNet produces slightly higher AP scores on average than our proposed Deformable Capsules , and we do not ignore this ratio , and in fact we stated it in the main Table 1 . Many applications exist where reducing false positives is of extreme and primary importance ( e.g.military or security applications ) . In these applications , users are willing to sacrifice some missed detections and even a slightly lower AP if it means significantly reduced FPs . This is why we add the additional reporting of not only the ratio TP/ ( TP+FP ) but also the raw FP values as well . 2.b. \u201c Some visualizations are weird like Fig.4 human and dog . Why NMS can not remove such highly-redundant predictions ? It seems more like a bug to me. \u201d CenterNet and other anchorless detection frameworks are not that easy to interpret compared to other detection frameworks ; hence , we appreciate this comment from the reviewer that we now have a chance to resolve this understandable confusion . We have updated the language in the paper to better explain where these false positives are coming from , and how our proposed method helps to solve this issue . In short , CenterNet performs a sort of pseudo-NMS by passing a 3x3 Max Pool over the final detection grid to extract objects \u2019 centers , and only performs a true NMS when running multi-scale testing ( note : we are using multi-scale testing in Fig.4 ) . However , in CenterNet ( and we emphasize we are using the official CenterNet code repo ) , NMS acts by choosing which scale is the most relevant for each detected objects \u2019 centers and does not remove separately detected objects which might overlap significantly . This is a design choice since overlapping boxes can occur naturally , and CenterNet relies on the detection centers to determine the existence of objects . Thus , if multiple center points are incorrectly predicted for the same object , this will not be suppressed by the NMS operation . While it is true that further post-processing could likely be performed to help mitigate this issue , our proposed method removes the issue completely . Our SplitCaps prediction head produces a detection grid which is a set of capsule vectors rather than scalars , with the final predictions having passed through the proposed SE-Routing dynamic routing algorithm . This combination of techniques produces a final detection grid which , after passing through the 3x3 Max Pool , does not contain the same high degree of redundant detection centers for objects ."}], "0": {"review_id": "ZVqZIA1GA_-0", "review_text": "The paper proposes to use the capsules to perform object detection on COCO . Capsules , while showing promises , are usually too expensive for tasks beyond MNIST and Cifar . The authors propose three key improvements in DeformCaps , SplitCaps and SE-Routing to improve the efficiency and therefore allow capsules to be applied on larger tasks such as object detection . The authors claim novelties in : -- First ever capsule-based object detection on COCO . -- Deformable capsules that let parent to samples child capsules instead of having fixed connections to improve efficiency . -- SplitCaps : a reparametrization trick to reduce the number of capsules needed . -- Squeeze-and-excitation routing that finds agreement without iterative loop . I agree with the authors ' novelty claims . Strengths : -- Impressive results : Capsule Networks are well known to be computationally expensive . Getting it to work on large images is certainly no easy task . There has been other works operating on larger images , as noted by this paper , but they usually can not achieve quality on par with CNNs . Having said that , I need to note that the SOTA for COCO has consistently improved , and is at ~51 % AP [ a ] , quite better than the numbers listed in Table 1 . -- Good novelty : DeformCapsule and SplitCaps both follow a straightforward pattern to dissect prohibitively large tensor predictions into smaller ones . And together with the SE-routing methods , the novelty should be sufficient for this venue . -- Clear writing . Figure 1 and 2 helped a lot with the understanding of the key components as well . [ a ] : SpineNet : Learning Scale-Permuted Backbone for Recognition and Localization Weaknesses : -- Insufficient experimentation : There is only a single experimental table that contains both comparisons to the SOTA and ablations to DeformCaps and SE-Routing . It would be nice to see additional results , be it on another dataset / task ( e.g.sem seg ) , or even additional ablations . For example , one premise of capsules was the requirement of less training data . Is it true here as well ? Conclusion : I 'd recommend acceptance because of the strong results and good novelty . The only major weakness is the lack of additional ablations to highlight the advantages ( if not on AP ) over CNNs . Nonetheless , I believe this work is a good step towards more interests and advances in capsules , and will be of interests to the audience of this venue . Post-rebuttal : I concur with R1 in that the results look poor when taking into the account how close the proposed method is compared to CenterNet and that it was finetuned from a CenterNet . Therefore , I 'll lower my rating to 6 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We appreciate the reviewer \u2019 s thoughtful consideration of our work and agree with the reviewer \u2019 s conclusions . We are hopeful the novelties proposed , which culminate in enabling capsules to scale up to large-scale tasks , will encourage interest and future advancements in capsule networks for a wide range of applications . For completeness , we would like to address two of the points made by the reviewer . 1. \u201c SOTA for COCO has consistently improved , and is at ~51 % AP [ a ] \u201d . The field is moving extremely quickly and results are consistently being improved . A main advantage of our proposed capsule innovations is that they act solely within a new detection head on the network . Hence , any improvements in network backbones can be easily swapped in . For example , the reviewer referenced SpineNet [ a ] uses a RetinaNet detection head which could easily be replaced by our proposed SplitCaps detection head . This is a strength of our work , indeed . 2. \u201c It would be nice to see additional results , be it on another dataset / task ( e.g.sem seg ) , or even additional ablations . For example , one premise of capsules was the requirement of less training data . Is it true here as well ? \u201d We again completely agree with the reviewer \u2019 s opinion . Additional experimentation is nearly always desirable and we can think of a large number of new datasets and tasks we are excited to pursue , as well as hopefully see others in the community investigate . For example , the task of ReID/Search from different viewpoints would be an excellent candidate for testing the generalization of capsules to new viewpoints . However , we would like to emphasize that the large number of interesting further studies that could be performed is a benefit of our proposed work and will hopefully lead to a flourishing of new capsule network research , rather than a negative for us not performing all of them ourselves in this single-scoped paper which introduces these concepts . Other works , such as [ b ] demonstrate capsule networks require less training data , and we felt such ablations about capsule networks in general would take away from the specific innovations being proposed in this study . Refs : [ a ] Du , Xianzhi , et al . `` SpineNet : Learning scale-permuted backbone for recognition and localization . '' Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2020 . [ b ] Jim\u00e9nez-S\u00e1nchez , Amelia , Shadi Albarqouni , and Diana Mateus . `` Capsule networks against medical imaging data challenges . '' Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis . Springer , Cham , 2018 . 150-160 ."}, "1": {"review_id": "ZVqZIA1GA_-1", "review_text": "Pros : It is indeed that capsules have many promising attributes but they are not quite easy to be exploited in object detectors . This paper has addressed many problems existed when applying capsule architectures for the object detection task . In particular , deformable capsules , SplitCaps , and SE-Routing are respectively introduced to help tackle the object detection with capsules . I believe the techniques of this paper will attract interests from researchers in the corresponding areas . The writing is also good . Cons : There are several points that prevent me from giving a higher rating : 1 ) I feel that the descriptions or presentations of introduced techniques are not quite sufficient . In particular , I am confused about the details of deformable capsules . What are the exact operations performed by the deformable capsules ? Is it to make parent capsules only aggregate information from a smaller set of their children and the sampling of such a smaller set is implemented by deformable operations ? I believe it will be much better to present some detailed formulations or equations to illustrate this operation . Similarly , I also recommend adding detailed equations to describe SE-Routing . 2 ) Without sufficient information about operations , I found that the descriptions of motivations are also quite weak , especially in the introductory part . It seems that the authors only mention the problems they will address and the techniques they proposed to address problems . There is not sufficient content briefly explaining why the proposed techniques can tackle the mentioned problems , or at least what are the advantages of the proposed techniques for tackling the problems . 3 ) The figures also have many confusing points . For example , in Figure 1 , the authors marked that solid red arrows represent 'up ' but I can only find dotted red arrows in the figure . Moreover , in what place the modules inside the big blue box is implemented in the detector ? After reading , I think it should represent what 's inside the SplitCaps , but I do recommend the authors to add some indicative symbols to corresponding related modules . 4 ) In addition to the reviewed literature , I found that there are some missing articles that also study how to borrow the capsule concepts for various computer vision tasks . For example : [ 1 ] Vijayakumar T. Comparative study of capsule neural network in various applications [ J ] . Journal of Artificial Intelligence , 2019 , 1 ( 01 ) : 19-27 . [ 2 ] Zhao Y , Birdal T , Deng H , et al.3D point capsule networks [ C ] //Proceedings of the IEEE conference on computer vision and pattern recognition . 2019 : 1009-1018 . [ 3 ] Chen Z , Zhang J , Tao D. Recursive Context Routing for Object Detection [ J ] . International Journal of Computer Vision , 2020 : 1-19 . Overall , I would like to have some feedback from the authors regarding the above issues before making my final decision .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We appreciate the reviewer \u2019 s comments . We will do our best to address each of these comments below in a succinct manner . 1. \u201c I feel that the descriptions or presentations of introduced techniques are not quite sufficient . In particular , I am confused about the details of deformable capsules . What are the exact operations performed by the deformable capsules ? Is it to make parent capsules only aggregate information from a smaller set of their children and the sampling of such a smaller set is implemented by deformable operations ? I believe it will be much better to present some detailed formulations or equations to illustrate this operation . Similarly , I also recommend adding detailed equations to describe SE-Routing. \u201d We understand the reviewer \u2019 s request for clarification on some of the points related to deformable capsules specifically and the work in general . As mentioned in our response to Reviewer 1 , capsule networks by nature can be somewhat involved in their explanation . We did our best now to sample the relevant capsule literature in the field at major venues ( e.g.NeurIPS , ICLR , etc . ) and ensure that our basic definitions and formulations are consistent with those already accepted and published in the field . To directly address the raised questions , the purpose of deformable capsules in short is this . The original method of fully-connected capsules in CapsNet [ a ] was to sample all children from a previous layer when forming parents in the current layer . This method does not scale up to larger image sizes ( described in Section 2 Paragraphs 1 and 4 ) , so several works introduced convolutional style capsules which only sample children from a smaller local kernel centered on the parent capsules spatial location ( described in Section 2 Paragraph 1 ) . Our approach is an extension of these convolutional methods which subsample children . However , instead of sampling in a geometrically-rigid manner , which does not easily allow for spatial deformations of objects and is antithetical to one of the main benefits of capsules ( described in Section 2 Paragraph 1 ) , we do so in a learned dynamic manner ( described in Section 2 Paragraph 2 ) . The formulation of that is identical to the formulation in deformable convolutions , where a first set of weights is learned to dynamically predict a set of offsets for the second set of weights to be applied to ( cited and described in Section 2 Paragraph 3 ) . We choose not to repeat the entire formulation of deformable kernels in the paper , as such is fairly well-known already . In regards to equations for SE-Routing , we have included a large number of in-line equations throughout Section 3.2 to precisely provide the formulation of our proposed methods ."}, "2": {"review_id": "ZVqZIA1GA_-2", "review_text": "# # # summary This paper introduces capsule network for object detection . To solve the issue of capsule network when applied to large-scale detection problems , this paper develops deformable capsules , a new prediction head SplitCaps , and a dynamic routing algorithm , SE-Routing . Experiments are conducted on COCO where it performs slightly worse than the baselines but arguably predicts less false positives . # # # pros I appreciate the spirit of developing new architectures for a highly-competitive task like object detection . It 's totally acceptable that the performance can not fully match the SOTA results in this kind of scenario . This paper is insightly as it studies several important issues of capsule network when being applied to large-scale visual tasks . The proposed solutions have at least make the framework run-able on standard hardware . # # # cons 1 . My current rating is not purely based on the performance , but it is one of the major concerns here . The proposed framework ( 1 ) performs worse than baseline -- CenterNet , and ( 2 ) performs much worse then the SOTA solutions ( Tab.1 ) in terms of both performance and speed . Note that the network weights are initialized from CenterNet . 2.The whole analysis in Appendix A.2 reads very confusing for several reasons : * CenterNet achieves higher AP ( TP/ ( TP+FP ) ) and also high FP , which is a quite common thing to me . Ignoring the ratio and simply compare the absolute value of FP does n't seems to be the correct thing to do . * Some visualizations are weird like Fig.4 human and dog . Why NMS can not remove such highly-redundant predictions ? It seems more like a bug to me . * On page 12 top row it writes `` CenterNet consistently producing fairly confident false predictions ( e.g. > 0.4 ) '' , how does this threshold 0.4 is chosen ? It 's not a standard thing and in fact if we improve it to 0.5 or higher , most of the FPs about CenterNet will disappear . Moreover , is this how FP gets counted ? If yes , I think this is problematic as the total number ( TP+FP ) is changing across methods . A more fair way is to choose top-k ( k=100 in coco ) predictions and compute the metrics . 3.Lots of reference are missing . For example , Tab.1 compares multiple different methods but most of them are not cited . The related work only cites few very classical papers , but most recent works are missing . 4.The writing , especially the approach section , is n't very clear . I had a relatively hard time to understand how do each modules work , and what are the motivations behind these design choices . 5.Moreover , there are couple of new things proposed , and each one of them have specific design choices and parameters . However , there are no ablation studies properly studying them . As a results I do n't understand which module is working , and how does it work . # # # questions 1 . How do the FPS numbers in Tab.1 get computed ? Are they simply borrowed from original paper or some published work ? Some of them look strange to me . 2.Why KL in Sec.3.2 ? Does the asymmetric natural of KL influence the results ?", "rating": "4: Ok but not good enough - rejection", "reply_text": "We appreciate the reviewer \u2019 s thorough and critical review of our work . After careful inspection of each critique , we have identified that the major concern is related to a claim which is not made ( performance ) in our paper . Furthermore , several areas of potential misunderstanding for readers were highlighted by this review and we appreciate the chance to make these more clear . We will address each of these points individually ; but first , we would like to re-emphasize the contribution of this study is the development of novel techniques and architectures which allow capsule networks to scale up to large scale tasks and object detection for the first time in the literature . Our goal was not to push state-of-the-art performances and we are not claiming any such thing in the paper . Similar to the CapsNet [ a ] paper ( cited more than 2800 times since 2017 ) , which formalized the concept of capsules and introduced dynamic routing , but produced less than state-of-the-art results on CIFAR-10 . In analogy to CapsNet [ a ] paper , we feel that our study is an important study opening many potential avenues for further investigation of capsules on a now much wider range of accessible tasks . 1. \u201c The proposed framework ( 1 ) performs worse than baseline -- CenterNet , and ( 2 ) performs much worse then the SOTA solutions ( Tab.1 ) in terms of both performance and speed. \u201d We kindly direct the reviewer to our above paragraph about the primary focus of our study and also suggest that the reviewer \u2019 s point ( 2 ) is perhaps a bit of an overstatement . While we perform inferior to very slow networks such as TridentNet which runs at 0.7 FPS. , we still outperform networks which run at comparable speeds such as Mask R-CNN which runs at a slower 11 FPS ( compared to our 15 FPS ) and achieves a lower mAP score of 39.8 compared with our 40.6 . We also perform 7.6 mAP points better than YOLOv3 while only being 5 FPS slower ( 15 compared to 20 FPS ) . While we are obtaining all these encouraging results , we would like to re-emphasize that our focus was not accuracy improvement or architectural engineering to boost the accuracy . 2.Several comments related to False Positives appendix , \u201c Appendix A.2 reads very confusing for several reasons \u201d 2.a . \u201c CenterNet achieves higher AP ( TP/ ( TP+FP ) ) and also high FP , which is a quite common thing to me . Ignoring the ratio and simply comparing the absolute value of FP does n't seem to be the correct thing to do. \u201d We acknowledge that CenterNet produces slightly higher AP scores on average than our proposed Deformable Capsules , and we do not ignore this ratio , and in fact we stated it in the main Table 1 . Many applications exist where reducing false positives is of extreme and primary importance ( e.g.military or security applications ) . In these applications , users are willing to sacrifice some missed detections and even a slightly lower AP if it means significantly reduced FPs . This is why we add the additional reporting of not only the ratio TP/ ( TP+FP ) but also the raw FP values as well . 2.b. \u201c Some visualizations are weird like Fig.4 human and dog . Why NMS can not remove such highly-redundant predictions ? It seems more like a bug to me. \u201d CenterNet and other anchorless detection frameworks are not that easy to interpret compared to other detection frameworks ; hence , we appreciate this comment from the reviewer that we now have a chance to resolve this understandable confusion . We have updated the language in the paper to better explain where these false positives are coming from , and how our proposed method helps to solve this issue . In short , CenterNet performs a sort of pseudo-NMS by passing a 3x3 Max Pool over the final detection grid to extract objects \u2019 centers , and only performs a true NMS when running multi-scale testing ( note : we are using multi-scale testing in Fig.4 ) . However , in CenterNet ( and we emphasize we are using the official CenterNet code repo ) , NMS acts by choosing which scale is the most relevant for each detected objects \u2019 centers and does not remove separately detected objects which might overlap significantly . This is a design choice since overlapping boxes can occur naturally , and CenterNet relies on the detection centers to determine the existence of objects . Thus , if multiple center points are incorrectly predicted for the same object , this will not be suppressed by the NMS operation . While it is true that further post-processing could likely be performed to help mitigate this issue , our proposed method removes the issue completely . Our SplitCaps prediction head produces a detection grid which is a set of capsule vectors rather than scalars , with the final predictions having passed through the proposed SE-Routing dynamic routing algorithm . This combination of techniques produces a final detection grid which , after passing through the 3x3 Max Pool , does not contain the same high degree of redundant detection centers for objects ."}}