{"year": "2017", "forum": "Sk36NgFeg", "title": "Filling in the details: Perceiving from low fidelity visual input", "decision": "Reject", "meta_review": "The program committee appreciates the authors' response to concerns raised in the reviews. Unfortunately, reviews are not leaning sufficiently towards acceptance. Reviewers find this direction of exploration to be interesting, but a bit preliminary at the moment. Authors are strongly encouraged to incorporate reviewer comments to make future iterations of the work stronger.", "reviews": [{"review_id": "Sk36NgFeg-0", "review_text": "This paper aims to characterize the perceptual ability of a neural network under different input conditions. This is done by manipulating the input image x in various ways (e.g. downsamplig, foveating), and training an auto-encoder to reconstruct the original full-resolution image. MSE and qualitative results are shown and compared for the different input conditions. Unfortunately, this paper seems to lack focus, presenting a set of preliminary inspections with few concrete conclusions. For example, at the end of sec 4.4, \"This result is not surprising, given that FOV-R contains additional information .... These results suggests that a small number of foveations containing rich details might be all these neural networks need....\". But this hypothesis is left dangling: What detailed regions are needed, and from where? For what sort of tasks? Secondly, it isn't clear to me what reconstruction behaviors are caused by a fundamental perception of the input, and what are artifacts of the autoencoder and pixelwise l2 loss? A prime example is texture, which the autoencoder fails to recover. But with a pixelwise loss, the network must predict high-frequency textures nearly pixel-for-pixel at training time; if this is impossible, then it will generate a pixelwise average of the training samples --- a flat region. So then the network's inability to reconstruct textures is due to a problem generating them, specifically averaging from the training loss, not necessarily an issue in perceiving textures. A network trained a different way (perhaps an adversarial network) may infer a texture is there, even if it wouldn't be able to generate it in a pixelwise l2 sense. Similarly, the ability to perform color reconstruction given a color glimpse I think has much to do with disambiguating the color of an object/scene: If there is an ambiguity, the network won't know which to \"choose\" (white flower or yellow flower?) and output an average, which is why there are so many sepia tones. However, in its section on this, the paper only measures the reconstruction error for different amounts of color given, and does not drill very far into any hypotheses for why this behavior occurs. There are some interesting measurements here, such as the amount of color needed in the foveation to reconstruct a color image, and the discussion on global features, which may start to get at a mechanism by which glimpses may propagate to an entire reconstruction. But overall it's hard to know what to take away from this paper. What are larger concrete conclusions that can be garnered from the details, and what mechanisms bring them about? Can these be more thoroughly explored with more focus? ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks for your comments . We agree that there are some burning questions left unanswered , but at the same time hope that our initial data provides some interesting insights about a relatively unexplored area of research . As a first pass , we presented a breadth of problems to understand what a relatively simple network is capable of . It \u2019 s true that we did not explore each problem in depth but we wanted to gain an understanding on what happens under these three conditions : ( 1 ) foveations ( 2 ) missing information ( scotomas ) ( 3 ) presence or absence of color information in the fovea . RE : MSE evaluation . Good point about texture . Indeed MSE is not a perfect quantitative evaluation metric , but it would seem that nearly all other metrics have the same problems with texture . To help overcome MSE 's deficiencies we also supply the actual output reconstructions so that they may also be qualitatively judged . Our conclusions regarding texture were not from an artifact of MSE , but from our own visual inspections of the images in which we determined much of the high frequency information in the periphery was clearly missing or inaccurate . RE : ability to perform color reconstruction . We share your intuition about the sepia tones . There are some rare instances of the network learning to correlate shape and color for completely black and white foveation functions , but this was the exception not the norm . One case that is interesting is that the network colors a black & white sky as blue ( actually this is incorrect because the sky happened to be a red sunset ) by employing a learned global blue color feature . Again , this is a rare case and in general the network requires some color information , but we can only speculate on why ."}, {"review_id": "Sk36NgFeg-1", "review_text": "I like the idea the paper is exploring. Nevertheless I see some issues with the analysis: - To get a better understanding of the quality of the results, I think at least some state-of-the-art comparisons should be included (e.g. by setting d times d pixel patches too their average and applying a denoising autoencoder). If they perform significantly better, then this indicates that the presented model is not yet taking all the information from the input image that could be used. - SCT-R and FOV-R are supposed to test how much information can be restored from the Fovea alone as opposed to the Fovea together with low resolution periphery. However, there is an additional difference between the two conditions: According to the paper, in SCT-R, part of the image was set to zero, while in FOV-R it was removed alltogether. With only one or two hidden layers, I could easily imagine this making a difference. - On page 4, you compare the performance of FOV-R (1% error) with that of DS-D (1.5%) and attribute this to information about the periphery that the autoencoder extracts from the fovea. While this might be the case, at least part of the reduced error will be due to the fact that the fovea is (hopefully) perfectly reconstructed. To answer the actual question \"how much additional information about the periphery can be extracted from the fovea\", you should consider calculating the error only in the periphery, i.e. the part of the image where DS-D and FOV-R got exactly the same input for. Then any decreased error is only due to the additional fovea information. Other issues: - The images in Figure 2 (a) and (b) in the rows \"factor 2\", \"factor 4\", \"factor 8\" look very blurry. There seems some interpolation to be going on (although slighly different than the bilinear interpolation). This makes it hard to asses how much information is in these images. I think it would be much more insightfull to print them with \"nearest\" interpolation. - Figure 3 caption too vague. Maybe add something like footnote 2? - Often figures appear too early in paper which leads to lots of distance between text and figures. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Great suggestion about evaluating both the periphery and the fovea separately . As you suggest , this would provide more direct evidence that the high resolution areas are helping the low resolutions areas . And indeed , for some of our foveation functions it may be possible to tease apart the two regions and evaluate them separately . Comparing structured noise to random noise ( denoising AE ) would be interesting as well . RE : Other issues . We will integrate your suggestions , thanks ."}, {"review_id": "Sk36NgFeg-2", "review_text": "This paper is motivated by the ability that human's visual system can recognize contents of environment by from critical features, and tried to investigate whether neural networks can also have this kind of ability. Specifically, the paper proposed to use Auto-Encoder (AE) as the network to reconstruct the low fidelity of visual input. Moreover, similar to Mnih et al. (2014), the paper also proposed to use a recurrent fashion to mimic the sequential behavior the human visual system. I think the paper is well motivated. However, there are several concerns: 1. The baselines of the paper are too weak. Nearest neighbor, bilinear, bicubic and cubic interpolations without any learning procedure are of course performed worse than AE based models. The author should compare with the STOA methods such as https://arxiv.org/abs/1609.04802 2. Can the experiments based on AE support the idea that artificial neural networks can perceive an image from low fidelity? AE is only a kind of neural network, can the conclusion extend to other kind of networks? I think it would be much better if the authors can provide a more general conclusion. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for the comments . 1.It may be interesting to compare to a SOA super-resolution system on that particular task , but we would not expect our simple networks to compete with such systems ( neural-network based or otherwise ) . We kept the network simple to more easily study their behavior ( on various types of input degradations , not just low resolution ) and the nature of the learnt solution . 2.Good question . We find AE to be a natural model for this problem because the output is easy to visually interpret . The idea could be easily extend to other kinds of autoencoders ( with other types of layers or architectures ) , but it is less clear whether they could be directly extended to a classification architectures . The two problems here are ( 1 ) a lot of data would be required to provide enough constraints on the weights ( 2 ) how to know whether detail is being perceived or whether another signal is learned that happens to correlate with the classification problem ."}], "0": {"review_id": "Sk36NgFeg-0", "review_text": "This paper aims to characterize the perceptual ability of a neural network under different input conditions. This is done by manipulating the input image x in various ways (e.g. downsamplig, foveating), and training an auto-encoder to reconstruct the original full-resolution image. MSE and qualitative results are shown and compared for the different input conditions. Unfortunately, this paper seems to lack focus, presenting a set of preliminary inspections with few concrete conclusions. For example, at the end of sec 4.4, \"This result is not surprising, given that FOV-R contains additional information .... These results suggests that a small number of foveations containing rich details might be all these neural networks need....\". But this hypothesis is left dangling: What detailed regions are needed, and from where? For what sort of tasks? Secondly, it isn't clear to me what reconstruction behaviors are caused by a fundamental perception of the input, and what are artifacts of the autoencoder and pixelwise l2 loss? A prime example is texture, which the autoencoder fails to recover. But with a pixelwise loss, the network must predict high-frequency textures nearly pixel-for-pixel at training time; if this is impossible, then it will generate a pixelwise average of the training samples --- a flat region. So then the network's inability to reconstruct textures is due to a problem generating them, specifically averaging from the training loss, not necessarily an issue in perceiving textures. A network trained a different way (perhaps an adversarial network) may infer a texture is there, even if it wouldn't be able to generate it in a pixelwise l2 sense. Similarly, the ability to perform color reconstruction given a color glimpse I think has much to do with disambiguating the color of an object/scene: If there is an ambiguity, the network won't know which to \"choose\" (white flower or yellow flower?) and output an average, which is why there are so many sepia tones. However, in its section on this, the paper only measures the reconstruction error for different amounts of color given, and does not drill very far into any hypotheses for why this behavior occurs. There are some interesting measurements here, such as the amount of color needed in the foveation to reconstruct a color image, and the discussion on global features, which may start to get at a mechanism by which glimpses may propagate to an entire reconstruction. But overall it's hard to know what to take away from this paper. What are larger concrete conclusions that can be garnered from the details, and what mechanisms bring them about? Can these be more thoroughly explored with more focus? ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks for your comments . We agree that there are some burning questions left unanswered , but at the same time hope that our initial data provides some interesting insights about a relatively unexplored area of research . As a first pass , we presented a breadth of problems to understand what a relatively simple network is capable of . It \u2019 s true that we did not explore each problem in depth but we wanted to gain an understanding on what happens under these three conditions : ( 1 ) foveations ( 2 ) missing information ( scotomas ) ( 3 ) presence or absence of color information in the fovea . RE : MSE evaluation . Good point about texture . Indeed MSE is not a perfect quantitative evaluation metric , but it would seem that nearly all other metrics have the same problems with texture . To help overcome MSE 's deficiencies we also supply the actual output reconstructions so that they may also be qualitatively judged . Our conclusions regarding texture were not from an artifact of MSE , but from our own visual inspections of the images in which we determined much of the high frequency information in the periphery was clearly missing or inaccurate . RE : ability to perform color reconstruction . We share your intuition about the sepia tones . There are some rare instances of the network learning to correlate shape and color for completely black and white foveation functions , but this was the exception not the norm . One case that is interesting is that the network colors a black & white sky as blue ( actually this is incorrect because the sky happened to be a red sunset ) by employing a learned global blue color feature . Again , this is a rare case and in general the network requires some color information , but we can only speculate on why ."}, "1": {"review_id": "Sk36NgFeg-1", "review_text": "I like the idea the paper is exploring. Nevertheless I see some issues with the analysis: - To get a better understanding of the quality of the results, I think at least some state-of-the-art comparisons should be included (e.g. by setting d times d pixel patches too their average and applying a denoising autoencoder). If they perform significantly better, then this indicates that the presented model is not yet taking all the information from the input image that could be used. - SCT-R and FOV-R are supposed to test how much information can be restored from the Fovea alone as opposed to the Fovea together with low resolution periphery. However, there is an additional difference between the two conditions: According to the paper, in SCT-R, part of the image was set to zero, while in FOV-R it was removed alltogether. With only one or two hidden layers, I could easily imagine this making a difference. - On page 4, you compare the performance of FOV-R (1% error) with that of DS-D (1.5%) and attribute this to information about the periphery that the autoencoder extracts from the fovea. While this might be the case, at least part of the reduced error will be due to the fact that the fovea is (hopefully) perfectly reconstructed. To answer the actual question \"how much additional information about the periphery can be extracted from the fovea\", you should consider calculating the error only in the periphery, i.e. the part of the image where DS-D and FOV-R got exactly the same input for. Then any decreased error is only due to the additional fovea information. Other issues: - The images in Figure 2 (a) and (b) in the rows \"factor 2\", \"factor 4\", \"factor 8\" look very blurry. There seems some interpolation to be going on (although slighly different than the bilinear interpolation). This makes it hard to asses how much information is in these images. I think it would be much more insightfull to print them with \"nearest\" interpolation. - Figure 3 caption too vague. Maybe add something like footnote 2? - Often figures appear too early in paper which leads to lots of distance between text and figures. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Great suggestion about evaluating both the periphery and the fovea separately . As you suggest , this would provide more direct evidence that the high resolution areas are helping the low resolutions areas . And indeed , for some of our foveation functions it may be possible to tease apart the two regions and evaluate them separately . Comparing structured noise to random noise ( denoising AE ) would be interesting as well . RE : Other issues . We will integrate your suggestions , thanks ."}, "2": {"review_id": "Sk36NgFeg-2", "review_text": "This paper is motivated by the ability that human's visual system can recognize contents of environment by from critical features, and tried to investigate whether neural networks can also have this kind of ability. Specifically, the paper proposed to use Auto-Encoder (AE) as the network to reconstruct the low fidelity of visual input. Moreover, similar to Mnih et al. (2014), the paper also proposed to use a recurrent fashion to mimic the sequential behavior the human visual system. I think the paper is well motivated. However, there are several concerns: 1. The baselines of the paper are too weak. Nearest neighbor, bilinear, bicubic and cubic interpolations without any learning procedure are of course performed worse than AE based models. The author should compare with the STOA methods such as https://arxiv.org/abs/1609.04802 2. Can the experiments based on AE support the idea that artificial neural networks can perceive an image from low fidelity? AE is only a kind of neural network, can the conclusion extend to other kind of networks? I think it would be much better if the authors can provide a more general conclusion. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for the comments . 1.It may be interesting to compare to a SOA super-resolution system on that particular task , but we would not expect our simple networks to compete with such systems ( neural-network based or otherwise ) . We kept the network simple to more easily study their behavior ( on various types of input degradations , not just low resolution ) and the nature of the learnt solution . 2.Good question . We find AE to be a natural model for this problem because the output is easy to visually interpret . The idea could be easily extend to other kinds of autoencoders ( with other types of layers or architectures ) , but it is less clear whether they could be directly extended to a classification architectures . The two problems here are ( 1 ) a lot of data would be required to provide enough constraints on the weights ( 2 ) how to know whether detail is being perceived or whether another signal is learned that happens to correlate with the classification problem ."}}