{"year": "2019", "forum": "SJldZ2RqFX", "title": "D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation", "decision": "Reject", "meta_review": "With positive unlabeled learning the paper targets an interesting problem and proposes a new GAN based method to tackle it. All reviewers however agree that the write-up and the motivation behind the method could be made more clear and that novelty compared to other GAN based methods is limited. Also the experimental analysis does not show a strong clear performance advantage over existing models. ", "reviews": [{"review_id": "SJldZ2RqFX-0", "review_text": "[Summary] PU learning is the problem of learning a binary classifier given labelled data from the positive class and unlabelled data from both the classes. The authors propose a new GAN architecture in this paper called the Divergent Gan (DGAN) which they claim has the benefits of two previous GAN architectures proposed for PU learning: The GenPU method and the Positive-Gan architecture. The key-equation of the paper is (5) which essentially adds an additional loss term to the GAN objective to encourage the generator to generate samples from the negative class and not from the positive class. The proposed method is validated through experiments on CIFAR and MNIST. [Pros] 1. The problem of PU learning is interesting. 2. The experimental results on CIFAR/MNIST suggest that some method that the authors coded worked at par with existing methods. [Cons] 1. The quality of the writeup is quite bad and a large number of critical sentences are unclear. E.g. a. [From Abstract] It keeps the light adversarial architecture of the PGAN method, with **a better robustness counter the varying images complexity**, while simultaneously allowing the same functionalities as the GenPU method, like the generation of relevant counter-examples. b. Equation (3) and (4) which are unclear in defining R_{PN}(D, \u03b4) c. Equation (6) which says log[1 - D(Xp)] = Yp log[D(Xp)] + (1-Yp) log[1-D(Xp)] which does not make any sense. d. The distinction between the true data distribution and the distribution hallucinated by the the generator is not maintained in the paper. In key places the authors mix one with the other such as the statement that supp(Pp (Xp )) \u2229 supp(Pn (Xn )) \u2192 \u2205 In short even after a careful reading it is not clear exactly what is the method that the authors are proposing. 2. Section 2.2 on noisy-label learning is only tangentially related to the paper and seems more like a space filler. 3. The experimental results in Table 4 and Table 3 do not compare to GenPU. Although the authors claim several times that the GenPU method is *onerous*, it is not clear why GenPU is so much more onerous in comparison to other GAN based methods which all require careful hyper-parameter tuning and expensive training. Furthermore the reference PN method performs worse than other PU learning methods which does not make sense. Because of this I am not quite convinced by the experiments.", "rating": "3: Clear rejection", "reply_text": "Thanks for your constructive review , 1. a . \u201c a better robustness counter the varying images complexity \u201d will be replaced by \u201c a better adaptability to the images complexity \u201d According to the PGAN article , PGAN should not be used for simple tasks . D-GAN works on both simple and complex tasks : D-GAN is more adaptable to the images complexity . b. l ( D ( X ) , \u03b4 ) will be replaced by l ( D ( X ) , y=\u03b4 ) and \u201c \u21d4 \u201d by \u201c = \u201d . \u03b4 is the label of positive samples : \u03b4 substitutes both contradictory labels \u201c 0 \u201d and \u201c 1 \u201d associated to Pp in the risk Rpu ( equation 1 ) . Unlabeled positive samples are separated from unlabeled negative ones with D trained with the risk Rpu . c. Equation ( 6 ) will be replaced as follow . The loss function Ld of D is defined as : Ld = Rpu + Eg [ l ( D ( Xg ) , Yg=0 ) ] , with Rpu the PU risk ( equation ( 1 ) ) , Yg=0 the label associated to the samples Xg generated by G ; Xg = G ( z ) , and Eg the expectation for samples Xg . We recall Rpu = Eu [ l ( D ( Xu ) , Yu=1 ) ] + Ep [ l ( D ( Xp ) , Yp=0 ) ] , with Yu=1 the label of unlabeled samples Xu with the expectation Eu , and Yp=0 the label of labeled positive samples Xp with the expectation Ep . The loss function \u201c l \u201d used in the proposed D-GAN framework can be the binary cross-entropy \u201c H \u201d such that \u201c l=-H \u201d . So : Ld = Eu [ -H ( D ( Xu ) , Yu=1 ) ] + Ep [ -H ( D ( Xp ) , Yp=0 ) ] + Eg [ -H ( D ( Xg ) , Yg=0 ) ] . The binary cross-entropy H is defined as below : H ( D ( X ) , Y ) = - Y log ( D ( X ) ) \u2013 ( 1-Y ) log ( 1-D ( X ) ) , with Y represents the label associated to the D input samples X . Thus H ( D ( X ) , Y=1 ) = - log ( D ( X ) ) and H ( D ( X ) , Y=0 ) = - log ( 1-D ( X ) ) . Finally , Ld can be developed as follow : Ld = Eu [ log [ D ( Xu ) ] ] + Ep [ log [ 1-D ( Xp ) ] ] + Eg [ log [ 1-D ( Xg ) ] ] . This shows the incorporation of Rpu ( equation ( 1 ) ) inside the D-GAN loss function ( equation ( 5 ) ) . The role of G during the adversarial training is to generate samples considered by D as \u201c 1 \u201d . Only negative samples are considered as \u201c 1 \u201d by D thanks to the Rpu risk . This justifies intuitively the G convergence towards the negative samples distribution . d. The sentence part `` such that we have supp ( Pp ( Xp ) ) \u2229 supp ( Pn ( Xn ) ) \u2192 \u2205 , with supp the support function of probability distributions . '' will be removed . We talked about D ability to distinguish positive samples distribution Pp from negative one Pn . If D does this distinction , then G converges towards Pn . If D fails to do this task , then G converges to the unlabeled samples distribution Pu as the PGAN . 2.We take into consideration your comment . This is not the main message of the article . Section 2.2 will be removed from the method part . 3. \u201c results in Table 4 and Table 3 do not compare to GenPU. \u201d We do not compare our results to GenPU method for the challenging One vs. Rest task because : a. GenPU method is not reproducible . - Code not provided . - Implementation details are missing in their article : Three hyper-parameters ( lambda_P , lambda_N and lambda_U ) are introduced in the GenPU article , but the values are not specified . They are important for the GenPU training with respect to their role inside the GenPU cost function ( GenPU equation ( 3 ) ) : Instructions 8 , 9 and 10 of the GenPU pseudo-code ( GenPU Algorithm 1 ) apply them directly to the prior knowledge parameters \u03c0p and \u03c0n ( =1-\u03c0p ) . That makes impossible the GenPU reproducibility . b. GenPU mode collapse issue does not enable to perform complex tasks as the One vs. Rest challenge . c. GenPU is not valorized in their article as an interesting alternative for the standard PU context where we own relatively enough positive labeled samples : GenPU article does not present results with more than 100 positive labeled samples . d. The goal of tables 3 and 4 is to compare methods which do not need prior knowledge . \u201c the authors claim several times that the GenPU method is * onerous * \u201d GenPU training computational cost can not be quantified : GenPU is not reproducible and training epoch iterations needed to converge are not specified . If we consider that both standard GAN and GenPU architectures need the same number of training epochs to converge to the expected distribution , then training five models ( GenPU ) instead of two ( D-GAN ) is more computational demanding . D-GAN does not add or modify hyper-parameters of GAN variants tested ( GAN , DCGAN , WGAN-GP , LS-GAN ) . \u201c the reference PN method performs worse than other PU learning methods which does not make sense. \u201d D-GAN performs better than PN on CIFAR-10 because : - It learns relevant counter-examples distribution . RP article discusses the same behavior on CIFAR-10 . - Generated images enable data augmentation . GANs latent linear interpolations result in semantic images interpolations outputs . Thus GANs learn generic representation . It is not observed on MNIST because data augmentation is difficult to produce on low-dimensional data . PGAN score when \u03c0p=0 ( as for PN ) will be added in tables 3 and 4 to highlight this effect . This phenomenon is not straightforward , but these reasons clarify it . We sincerely thank you for your review ."}, {"review_id": "SJldZ2RqFX-1", "review_text": "The motivation of the work is not clear but the novelty seems to be present. The paper is very hard to follow as the problem description and intuition of the D-GAN is not clearly written. Based on the experiments, the proposed method achieves marginal improvement in terms of F1 score but sometimes also slightly lower performance than other GAN based such as PGAN, so the impact of this work to solve positive unlabelled data problem is not evident. I am personally not as familiar with the PU problem and existing frameworks so my confidence in the assessment is low; my main experience is in the computer vision for autonomous driving and sparse coding. But my feeling is this paper is marginally below the threshold of acceptance.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for your review , Firstly we apologize for not making the text clear enough . We hope the following answers to your respective points will clarify the proposed contributions . * * * \u201c The motivation of the work is not clear \u201d Motivations can be expressed as follow . 1 : Overcome the previous state of the art approaches disadvantages . - GenPU architecture is more computational demanding ( three discriminators and two generators ) than standard GAN architectures ( one discriminator and one generator ) . Furthermore , GenPU requires prior knowledge and additional loss function hyper-parameters . - The PGAN method has overfitting issues on simple datasets ( see figure 6 . ( b ) ) because its approach is based on GANs imperfections . 2 : A framework easily adaptable to GANs variants . - A GAN PU framework similar to standard GAN could enable a better adaptability to last and potentially future GANs variants . It is an important point because the state of the art is updated continuously but the architectures remain similar ( one generator and one discriminator ) . 3 : Adversarial training of GAN-based approaches enables to learn automatically relevant high level feature metrics . - GANs generate semantically realistic images . The most interesting aspect is probably that the error computed to evaluate the generated images quality is estimated from a high level feature point of view : the discriminator output . In this way , GANs enable relevant data augmentation . * * * \u201c the novelty seems to be present \u201d The two article contributions can be highlighted as follow . Contribution 1 : We propose to incorporate a PU risk inside the discriminator loss function . We show that a GAN can solve by itself a Positive Unlabeled learning task if the problem is well formulated : We combine a PU risk with the GAN discriminator loss function . That enables the G convergence to the distribution of counter-examples included in the unlabeled dataset . Previous GAN-based PU approaches do not include the PU risk in the discriminator cost function . GenPU and PGAN logics are as follow : - GenPU convergence is inspired by the original GAN convergence exposed by GoodFellow in 2014 . The main idea is in this sentence : \u201c Du is aimed at separating the unlabelled training samples from the fake samples of both Gp and Gn \u201d . Thus the global system GenPU enables the convergence \u201c pi Pgp + ( 1-pi ) Pgn - > Pu \u201d , with Pgp the distribution of positive samples generated by Gp , Pgn the distribution of the negative samples generated by Gn , and Pu the distribution of unlabeled samples . However , the same reasoning can be expressed using one single generator Gn if we replace the generated positive samples by the positive labeled samples that we have in a PU dataset . Thus training five different models is not necessary to address standard PU learning challenge where we have enough positive samples . This reasoning is different to the propose one . - PGAN is trained to converge towards the unlabeled dataset distribution during the first step . The PGAN exploits GANs imperfections such that the generated distribution at the adversarial equilibrium is still separable from the unlabeled samples distribution by a classifier . The PGAN does not use a PU learning risk to train its GAN part . Contribution 2 : Highlight of a critical normalization issue discussed in the context of the proposed framework Batch-normalization ( BN ) technique can not be used when several minibatches distributions ( unlabeled , positive , and generated ones ) are used to train a learning model . With BN , a classifier prediction for a given sample is critically influenced by the other samples of the same minibatch . As presented in the article , the consequence with a PU learning risk is that BN does not allow a classifier to distinguish positive from negative samples ( see figure 5 ( a ) and subsections 2.3 and 3.1 ) . These sections include the analysis of this BN effect and alternative normalization solutions , such that this effect disappears . In practice , a D-GAN using BN converges towards the unlabeled samples distribution . Without , it converges exclusively towards the negative samples distribution . The normalization training impact is clearly highlighted in the figure 5 . To the best of our knowledge , we are the first to highlight this critical phenomenon for the PU learning task . * * * \u201c intuition of the D-GAN is not clearly written. \u201d The D-GAN intuition can be expressed as follow . The discriminator D addresses to the generator G the riddle : \u201c Show me what IS unlabeled AND NOT positive. \u201d It turns out that negative samples included in the unlabeled dataset are both unlabeled and not positive . Consequently G addresses this riddle by learning to show the negative samples distribution to D ."}, {"review_id": "SJldZ2RqFX-2", "review_text": "This paper proposed another GAN-based PU learning method. The mathematics in this paper is not easy to follow, and there are many other critical issues. ***** The clarity is really an issue. First of all, I cannot easily follow the meanings behind the equations. I guess the authors first came up with some concrete implementation and then formalize it into an algorithm. Given the current version of the paper, I am not sure whether this clarity of equations can be fixed without an additional round of review or not. Moreover, the logic in the story line is unclear to me, especially the 3rd paragraph that seems to be mostly important in the introduction. There are two different binary classification problems, of separating the positive and negative classes, and of separating the given and generated data. I cannot see why the generated data can serve as negative data. This paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me. ***** The paper classified PU learning methods into two categories, one-stage methods and two-stage methods. This is interesting. However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning. The former problem setting was proposed very early and formalized in \"learning classifiers from only positive and unlabeled data\", KDD 2008; the latter problem setting was proposed in \"presence-only data and the EM algorithm\", Biometrics 2009 and formalized in \"analysis of learning from positive and unlabeled data\", NIPS 2014. Surprisingly, none of these 3 papers was cited. By definition, GAN-based PU learning belongs to the latter problem setting while Rank Prune can only be applied to the former but was included as a baseline method. The huge difference between these two settings and their connections to learning with noisy labels are known for long time. To be short, class-conditional noise model corrupts P(Y|X) and covers censoring PU, mutual contamination distribution framework corrupts P(X|Y) and covers case-control PU, and mathematically mutual contamination distribution framework is more general than class-conditional noise model and so is case-control PU than censoring PU. See \"learning from corrupted binary labels via class-probability estimation\", ICML 2015 for more information where the above theoretical result has been proven. An arXiv paper entitled \"on the minimal supervision for training any binary classifier from only unlabeled data\" has some experimental results showing that methods for class-conditional noise model cannot handle mutual contamination distributions. The situation is similar when applying censoring PU methods to case-control PU problem setting. Furthermore, the class-prior probability pi is well-defined and easy to estimate in censoring PU, see \"learning classifiers from only positive and unlabeled data\" mentioned above. However, it is not well-defined in case-control PU due to an identifiability issue described in \"presence-only data and the EM algorithm\" mentioned above. Thus, the target to be estimated is defined as the maximal theta such that theta*P(X|Y)<=P(X) following \"estimating the class prior and posterior from noisy positives and unlabeled data\", NIPS 2016. BTW, \"mixture proportion estimation via kernel embedding of distributions\" is SOTA in class-prior estimation; the previous NIPS paper was written earlier and accepted later. In summary, as claimed in the paper and shown in Table 1 in the introduction, all discriminative PU methods and GenPU require to know pi for learning. This is true, but this is because they are designed for a more difficult problem setting---learning classifiers and estimating pi are both more difficult. Lacking some basic knowledge of PU learning is another big issue. ***** The novelty is to be honest incremental and thus below the bar of ICLR. The significance is similarly poor, due to that the experiments mixed up methods for censoring PU and those for case-control PU. What is more, F1-score is a performance measure for information retrieval rather than binary classification. We all know GANs are pretty good at MNIST but not CIFAR-10. In fact, GenPU has a critical issue of mode collapse, and this is why GenPU reports 1-vs-1 rather than 5-vs-5 on MNIST. Even though, I still think GenPU makes much more sense than PGAN and D-GAN.", "rating": "3: Clear rejection", "reply_text": "Thanks for your constructive review , Your comments indicate that the text and equations are not clear enough and that some previous state of the art methods were omitted . We understand that the lack of clarity can be an issue . We made during this rebuttal period a clarification effort . Moreover , please find as follow the answers to your comments . * * * * * \u201c I can not easily follow the meanings behind the equations. \u201d We have clarified the equations . \u201c I can not see why the generated data can serve as negative data. \u201d \u201c This paragraph is discussing GenPU , PGAN and the proposed method , and consequently the motivation of the current paper does not make sense at least to me. \u201d GANs are known to be relevant because of their ability of finding a boundary between real and generated samples : A GAN discriminator is trained to find autonomously the best metric to evaluate the generated samples quality . This metric is considered as more relevant than previous ones such as the auto-encoders per-pixel reconstruction loss function . The GAN-based PU approaches main idea is to exploit this GAN benefit to address a PU learning problem : The initial goal of GANs is to imitate the unlabeled distribution . In the context of the PU task , this goal is adapted to identify and imitate autonomously the distribution of relevant counter-examples hidden in the unlabeled dataset . The motivation in this paragraph is to discuss the previous GAN-based approaches following issues : - GenPU issues : GenPU is not easily adaptable to the current GAN state of the art ( fast ) evolutions because of its untraditional adversarial framework . Moreover , GenPU uses prior knowledge . This is unpractical for example on some real application incremental datasets in which the fraction pi value can change continuously at each new training minibatch . - PGAN issue : It has a first stage overfitting problem when it is applied on relatively simple datasets as MNIST . In fact , it is mentioned in their article : \u201c It is also known that a GAN is not perfect in its operation when it is applied to high dimensional data , \u2026 Thus it is possible to estimate the non-zero distance d computed into the cost function of Db \u201d . In other words , the PGAN exploits the GANs convergence defaults to address the PU learning problem . The proposed approach overcomes the above enumerated issues while keeping their respective advantages . This is done by using a different technique : The D-GAN directly incorporates a PU learning risk into the discriminator loss function . This guides naturally the generator to converge towards the distribution of the negative samples included in the unlabeled dataset . * * * * * \u201c The paper classified PU learning methods into two categories , one-stage methods and two-stage methods . This is interesting . However , before that , they should be classified into two categories , for censoring PU learning and for case-control PU learning. \u201d Previous relevant state of the art articles , like nnPU , classify PU learning methods in two-stage and one-stage categories . The article nnPU ( \u201c Positive-Unlabeled Learning with Non-Negative Risk Estimator \u201d , NIPS 2017 ) says : \u201c Existing PU methods can be divided into two categories based on how U data is handled . The first category ( e.g. , [ 11 , 12 ] ) identifies possible negative ( N ) data in U data , and then performs ordinary supervised ( PN ) learning ; the second ( e.g. , [ 13 , 14 ] ) regards U data as N data with smaller weights. \u201d . GAN-based approaches generate samples in the first step , and they perform ordinary PN learning during the second step by considering the generated samples as relevant counter-examples . RP prepares a PN dataset from a PU dataset . Thus it is relevant to classify into the same category ( two-stage ) RP , and GAN-based approaches ( D-GAN , PGAN , GenPU ) . We introduce these categories ( one-stage/two-stage ) because our goal is to focus the attention on methods which aim at producing a relevant PN dataset from a PU dataset ."}], "0": {"review_id": "SJldZ2RqFX-0", "review_text": "[Summary] PU learning is the problem of learning a binary classifier given labelled data from the positive class and unlabelled data from both the classes. The authors propose a new GAN architecture in this paper called the Divergent Gan (DGAN) which they claim has the benefits of two previous GAN architectures proposed for PU learning: The GenPU method and the Positive-Gan architecture. The key-equation of the paper is (5) which essentially adds an additional loss term to the GAN objective to encourage the generator to generate samples from the negative class and not from the positive class. The proposed method is validated through experiments on CIFAR and MNIST. [Pros] 1. The problem of PU learning is interesting. 2. The experimental results on CIFAR/MNIST suggest that some method that the authors coded worked at par with existing methods. [Cons] 1. The quality of the writeup is quite bad and a large number of critical sentences are unclear. E.g. a. [From Abstract] It keeps the light adversarial architecture of the PGAN method, with **a better robustness counter the varying images complexity**, while simultaneously allowing the same functionalities as the GenPU method, like the generation of relevant counter-examples. b. Equation (3) and (4) which are unclear in defining R_{PN}(D, \u03b4) c. Equation (6) which says log[1 - D(Xp)] = Yp log[D(Xp)] + (1-Yp) log[1-D(Xp)] which does not make any sense. d. The distinction between the true data distribution and the distribution hallucinated by the the generator is not maintained in the paper. In key places the authors mix one with the other such as the statement that supp(Pp (Xp )) \u2229 supp(Pn (Xn )) \u2192 \u2205 In short even after a careful reading it is not clear exactly what is the method that the authors are proposing. 2. Section 2.2 on noisy-label learning is only tangentially related to the paper and seems more like a space filler. 3. The experimental results in Table 4 and Table 3 do not compare to GenPU. Although the authors claim several times that the GenPU method is *onerous*, it is not clear why GenPU is so much more onerous in comparison to other GAN based methods which all require careful hyper-parameter tuning and expensive training. Furthermore the reference PN method performs worse than other PU learning methods which does not make sense. Because of this I am not quite convinced by the experiments.", "rating": "3: Clear rejection", "reply_text": "Thanks for your constructive review , 1. a . \u201c a better robustness counter the varying images complexity \u201d will be replaced by \u201c a better adaptability to the images complexity \u201d According to the PGAN article , PGAN should not be used for simple tasks . D-GAN works on both simple and complex tasks : D-GAN is more adaptable to the images complexity . b. l ( D ( X ) , \u03b4 ) will be replaced by l ( D ( X ) , y=\u03b4 ) and \u201c \u21d4 \u201d by \u201c = \u201d . \u03b4 is the label of positive samples : \u03b4 substitutes both contradictory labels \u201c 0 \u201d and \u201c 1 \u201d associated to Pp in the risk Rpu ( equation 1 ) . Unlabeled positive samples are separated from unlabeled negative ones with D trained with the risk Rpu . c. Equation ( 6 ) will be replaced as follow . The loss function Ld of D is defined as : Ld = Rpu + Eg [ l ( D ( Xg ) , Yg=0 ) ] , with Rpu the PU risk ( equation ( 1 ) ) , Yg=0 the label associated to the samples Xg generated by G ; Xg = G ( z ) , and Eg the expectation for samples Xg . We recall Rpu = Eu [ l ( D ( Xu ) , Yu=1 ) ] + Ep [ l ( D ( Xp ) , Yp=0 ) ] , with Yu=1 the label of unlabeled samples Xu with the expectation Eu , and Yp=0 the label of labeled positive samples Xp with the expectation Ep . The loss function \u201c l \u201d used in the proposed D-GAN framework can be the binary cross-entropy \u201c H \u201d such that \u201c l=-H \u201d . So : Ld = Eu [ -H ( D ( Xu ) , Yu=1 ) ] + Ep [ -H ( D ( Xp ) , Yp=0 ) ] + Eg [ -H ( D ( Xg ) , Yg=0 ) ] . The binary cross-entropy H is defined as below : H ( D ( X ) , Y ) = - Y log ( D ( X ) ) \u2013 ( 1-Y ) log ( 1-D ( X ) ) , with Y represents the label associated to the D input samples X . Thus H ( D ( X ) , Y=1 ) = - log ( D ( X ) ) and H ( D ( X ) , Y=0 ) = - log ( 1-D ( X ) ) . Finally , Ld can be developed as follow : Ld = Eu [ log [ D ( Xu ) ] ] + Ep [ log [ 1-D ( Xp ) ] ] + Eg [ log [ 1-D ( Xg ) ] ] . This shows the incorporation of Rpu ( equation ( 1 ) ) inside the D-GAN loss function ( equation ( 5 ) ) . The role of G during the adversarial training is to generate samples considered by D as \u201c 1 \u201d . Only negative samples are considered as \u201c 1 \u201d by D thanks to the Rpu risk . This justifies intuitively the G convergence towards the negative samples distribution . d. The sentence part `` such that we have supp ( Pp ( Xp ) ) \u2229 supp ( Pn ( Xn ) ) \u2192 \u2205 , with supp the support function of probability distributions . '' will be removed . We talked about D ability to distinguish positive samples distribution Pp from negative one Pn . If D does this distinction , then G converges towards Pn . If D fails to do this task , then G converges to the unlabeled samples distribution Pu as the PGAN . 2.We take into consideration your comment . This is not the main message of the article . Section 2.2 will be removed from the method part . 3. \u201c results in Table 4 and Table 3 do not compare to GenPU. \u201d We do not compare our results to GenPU method for the challenging One vs. Rest task because : a. GenPU method is not reproducible . - Code not provided . - Implementation details are missing in their article : Three hyper-parameters ( lambda_P , lambda_N and lambda_U ) are introduced in the GenPU article , but the values are not specified . They are important for the GenPU training with respect to their role inside the GenPU cost function ( GenPU equation ( 3 ) ) : Instructions 8 , 9 and 10 of the GenPU pseudo-code ( GenPU Algorithm 1 ) apply them directly to the prior knowledge parameters \u03c0p and \u03c0n ( =1-\u03c0p ) . That makes impossible the GenPU reproducibility . b. GenPU mode collapse issue does not enable to perform complex tasks as the One vs. Rest challenge . c. GenPU is not valorized in their article as an interesting alternative for the standard PU context where we own relatively enough positive labeled samples : GenPU article does not present results with more than 100 positive labeled samples . d. The goal of tables 3 and 4 is to compare methods which do not need prior knowledge . \u201c the authors claim several times that the GenPU method is * onerous * \u201d GenPU training computational cost can not be quantified : GenPU is not reproducible and training epoch iterations needed to converge are not specified . If we consider that both standard GAN and GenPU architectures need the same number of training epochs to converge to the expected distribution , then training five models ( GenPU ) instead of two ( D-GAN ) is more computational demanding . D-GAN does not add or modify hyper-parameters of GAN variants tested ( GAN , DCGAN , WGAN-GP , LS-GAN ) . \u201c the reference PN method performs worse than other PU learning methods which does not make sense. \u201d D-GAN performs better than PN on CIFAR-10 because : - It learns relevant counter-examples distribution . RP article discusses the same behavior on CIFAR-10 . - Generated images enable data augmentation . GANs latent linear interpolations result in semantic images interpolations outputs . Thus GANs learn generic representation . It is not observed on MNIST because data augmentation is difficult to produce on low-dimensional data . PGAN score when \u03c0p=0 ( as for PN ) will be added in tables 3 and 4 to highlight this effect . This phenomenon is not straightforward , but these reasons clarify it . We sincerely thank you for your review ."}, "1": {"review_id": "SJldZ2RqFX-1", "review_text": "The motivation of the work is not clear but the novelty seems to be present. The paper is very hard to follow as the problem description and intuition of the D-GAN is not clearly written. Based on the experiments, the proposed method achieves marginal improvement in terms of F1 score but sometimes also slightly lower performance than other GAN based such as PGAN, so the impact of this work to solve positive unlabelled data problem is not evident. I am personally not as familiar with the PU problem and existing frameworks so my confidence in the assessment is low; my main experience is in the computer vision for autonomous driving and sparse coding. But my feeling is this paper is marginally below the threshold of acceptance.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for your review , Firstly we apologize for not making the text clear enough . We hope the following answers to your respective points will clarify the proposed contributions . * * * \u201c The motivation of the work is not clear \u201d Motivations can be expressed as follow . 1 : Overcome the previous state of the art approaches disadvantages . - GenPU architecture is more computational demanding ( three discriminators and two generators ) than standard GAN architectures ( one discriminator and one generator ) . Furthermore , GenPU requires prior knowledge and additional loss function hyper-parameters . - The PGAN method has overfitting issues on simple datasets ( see figure 6 . ( b ) ) because its approach is based on GANs imperfections . 2 : A framework easily adaptable to GANs variants . - A GAN PU framework similar to standard GAN could enable a better adaptability to last and potentially future GANs variants . It is an important point because the state of the art is updated continuously but the architectures remain similar ( one generator and one discriminator ) . 3 : Adversarial training of GAN-based approaches enables to learn automatically relevant high level feature metrics . - GANs generate semantically realistic images . The most interesting aspect is probably that the error computed to evaluate the generated images quality is estimated from a high level feature point of view : the discriminator output . In this way , GANs enable relevant data augmentation . * * * \u201c the novelty seems to be present \u201d The two article contributions can be highlighted as follow . Contribution 1 : We propose to incorporate a PU risk inside the discriminator loss function . We show that a GAN can solve by itself a Positive Unlabeled learning task if the problem is well formulated : We combine a PU risk with the GAN discriminator loss function . That enables the G convergence to the distribution of counter-examples included in the unlabeled dataset . Previous GAN-based PU approaches do not include the PU risk in the discriminator cost function . GenPU and PGAN logics are as follow : - GenPU convergence is inspired by the original GAN convergence exposed by GoodFellow in 2014 . The main idea is in this sentence : \u201c Du is aimed at separating the unlabelled training samples from the fake samples of both Gp and Gn \u201d . Thus the global system GenPU enables the convergence \u201c pi Pgp + ( 1-pi ) Pgn - > Pu \u201d , with Pgp the distribution of positive samples generated by Gp , Pgn the distribution of the negative samples generated by Gn , and Pu the distribution of unlabeled samples . However , the same reasoning can be expressed using one single generator Gn if we replace the generated positive samples by the positive labeled samples that we have in a PU dataset . Thus training five different models is not necessary to address standard PU learning challenge where we have enough positive samples . This reasoning is different to the propose one . - PGAN is trained to converge towards the unlabeled dataset distribution during the first step . The PGAN exploits GANs imperfections such that the generated distribution at the adversarial equilibrium is still separable from the unlabeled samples distribution by a classifier . The PGAN does not use a PU learning risk to train its GAN part . Contribution 2 : Highlight of a critical normalization issue discussed in the context of the proposed framework Batch-normalization ( BN ) technique can not be used when several minibatches distributions ( unlabeled , positive , and generated ones ) are used to train a learning model . With BN , a classifier prediction for a given sample is critically influenced by the other samples of the same minibatch . As presented in the article , the consequence with a PU learning risk is that BN does not allow a classifier to distinguish positive from negative samples ( see figure 5 ( a ) and subsections 2.3 and 3.1 ) . These sections include the analysis of this BN effect and alternative normalization solutions , such that this effect disappears . In practice , a D-GAN using BN converges towards the unlabeled samples distribution . Without , it converges exclusively towards the negative samples distribution . The normalization training impact is clearly highlighted in the figure 5 . To the best of our knowledge , we are the first to highlight this critical phenomenon for the PU learning task . * * * \u201c intuition of the D-GAN is not clearly written. \u201d The D-GAN intuition can be expressed as follow . The discriminator D addresses to the generator G the riddle : \u201c Show me what IS unlabeled AND NOT positive. \u201d It turns out that negative samples included in the unlabeled dataset are both unlabeled and not positive . Consequently G addresses this riddle by learning to show the negative samples distribution to D ."}, "2": {"review_id": "SJldZ2RqFX-2", "review_text": "This paper proposed another GAN-based PU learning method. The mathematics in this paper is not easy to follow, and there are many other critical issues. ***** The clarity is really an issue. First of all, I cannot easily follow the meanings behind the equations. I guess the authors first came up with some concrete implementation and then formalize it into an algorithm. Given the current version of the paper, I am not sure whether this clarity of equations can be fixed without an additional round of review or not. Moreover, the logic in the story line is unclear to me, especially the 3rd paragraph that seems to be mostly important in the introduction. There are two different binary classification problems, of separating the positive and negative classes, and of separating the given and generated data. I cannot see why the generated data can serve as negative data. This paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me. ***** The paper classified PU learning methods into two categories, one-stage methods and two-stage methods. This is interesting. However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning. The former problem setting was proposed very early and formalized in \"learning classifiers from only positive and unlabeled data\", KDD 2008; the latter problem setting was proposed in \"presence-only data and the EM algorithm\", Biometrics 2009 and formalized in \"analysis of learning from positive and unlabeled data\", NIPS 2014. Surprisingly, none of these 3 papers was cited. By definition, GAN-based PU learning belongs to the latter problem setting while Rank Prune can only be applied to the former but was included as a baseline method. The huge difference between these two settings and their connections to learning with noisy labels are known for long time. To be short, class-conditional noise model corrupts P(Y|X) and covers censoring PU, mutual contamination distribution framework corrupts P(X|Y) and covers case-control PU, and mathematically mutual contamination distribution framework is more general than class-conditional noise model and so is case-control PU than censoring PU. See \"learning from corrupted binary labels via class-probability estimation\", ICML 2015 for more information where the above theoretical result has been proven. An arXiv paper entitled \"on the minimal supervision for training any binary classifier from only unlabeled data\" has some experimental results showing that methods for class-conditional noise model cannot handle mutual contamination distributions. The situation is similar when applying censoring PU methods to case-control PU problem setting. Furthermore, the class-prior probability pi is well-defined and easy to estimate in censoring PU, see \"learning classifiers from only positive and unlabeled data\" mentioned above. However, it is not well-defined in case-control PU due to an identifiability issue described in \"presence-only data and the EM algorithm\" mentioned above. Thus, the target to be estimated is defined as the maximal theta such that theta*P(X|Y)<=P(X) following \"estimating the class prior and posterior from noisy positives and unlabeled data\", NIPS 2016. BTW, \"mixture proportion estimation via kernel embedding of distributions\" is SOTA in class-prior estimation; the previous NIPS paper was written earlier and accepted later. In summary, as claimed in the paper and shown in Table 1 in the introduction, all discriminative PU methods and GenPU require to know pi for learning. This is true, but this is because they are designed for a more difficult problem setting---learning classifiers and estimating pi are both more difficult. Lacking some basic knowledge of PU learning is another big issue. ***** The novelty is to be honest incremental and thus below the bar of ICLR. The significance is similarly poor, due to that the experiments mixed up methods for censoring PU and those for case-control PU. What is more, F1-score is a performance measure for information retrieval rather than binary classification. We all know GANs are pretty good at MNIST but not CIFAR-10. In fact, GenPU has a critical issue of mode collapse, and this is why GenPU reports 1-vs-1 rather than 5-vs-5 on MNIST. Even though, I still think GenPU makes much more sense than PGAN and D-GAN.", "rating": "3: Clear rejection", "reply_text": "Thanks for your constructive review , Your comments indicate that the text and equations are not clear enough and that some previous state of the art methods were omitted . We understand that the lack of clarity can be an issue . We made during this rebuttal period a clarification effort . Moreover , please find as follow the answers to your comments . * * * * * \u201c I can not easily follow the meanings behind the equations. \u201d We have clarified the equations . \u201c I can not see why the generated data can serve as negative data. \u201d \u201c This paragraph is discussing GenPU , PGAN and the proposed method , and consequently the motivation of the current paper does not make sense at least to me. \u201d GANs are known to be relevant because of their ability of finding a boundary between real and generated samples : A GAN discriminator is trained to find autonomously the best metric to evaluate the generated samples quality . This metric is considered as more relevant than previous ones such as the auto-encoders per-pixel reconstruction loss function . The GAN-based PU approaches main idea is to exploit this GAN benefit to address a PU learning problem : The initial goal of GANs is to imitate the unlabeled distribution . In the context of the PU task , this goal is adapted to identify and imitate autonomously the distribution of relevant counter-examples hidden in the unlabeled dataset . The motivation in this paragraph is to discuss the previous GAN-based approaches following issues : - GenPU issues : GenPU is not easily adaptable to the current GAN state of the art ( fast ) evolutions because of its untraditional adversarial framework . Moreover , GenPU uses prior knowledge . This is unpractical for example on some real application incremental datasets in which the fraction pi value can change continuously at each new training minibatch . - PGAN issue : It has a first stage overfitting problem when it is applied on relatively simple datasets as MNIST . In fact , it is mentioned in their article : \u201c It is also known that a GAN is not perfect in its operation when it is applied to high dimensional data , \u2026 Thus it is possible to estimate the non-zero distance d computed into the cost function of Db \u201d . In other words , the PGAN exploits the GANs convergence defaults to address the PU learning problem . The proposed approach overcomes the above enumerated issues while keeping their respective advantages . This is done by using a different technique : The D-GAN directly incorporates a PU learning risk into the discriminator loss function . This guides naturally the generator to converge towards the distribution of the negative samples included in the unlabeled dataset . * * * * * \u201c The paper classified PU learning methods into two categories , one-stage methods and two-stage methods . This is interesting . However , before that , they should be classified into two categories , for censoring PU learning and for case-control PU learning. \u201d Previous relevant state of the art articles , like nnPU , classify PU learning methods in two-stage and one-stage categories . The article nnPU ( \u201c Positive-Unlabeled Learning with Non-Negative Risk Estimator \u201d , NIPS 2017 ) says : \u201c Existing PU methods can be divided into two categories based on how U data is handled . The first category ( e.g. , [ 11 , 12 ] ) identifies possible negative ( N ) data in U data , and then performs ordinary supervised ( PN ) learning ; the second ( e.g. , [ 13 , 14 ] ) regards U data as N data with smaller weights. \u201d . GAN-based approaches generate samples in the first step , and they perform ordinary PN learning during the second step by considering the generated samples as relevant counter-examples . RP prepares a PN dataset from a PU dataset . Thus it is relevant to classify into the same category ( two-stage ) RP , and GAN-based approaches ( D-GAN , PGAN , GenPU ) . We introduce these categories ( one-stage/two-stage ) because our goal is to focus the attention on methods which aim at producing a relevant PN dataset from a PU dataset ."}}