{"year": "2019", "forum": "Byg3y3C9Km", "title": "Learning Protein Structure with a Differentiable Simulator", "decision": "Accept (Oral)", "meta_review": "This paper presents a differentiable simulator for protein structure prediction that can be trained end-to-end. It makes several contributions to this research area. Particularly training a differentiable sampling simulator could be of interest to a wider community.\n\nThe main criticism comes from the clarity for the machine learning community and empirical comparison with the state-of-the-art methods. The authors' feedback addressed a few  confusions in the description, and I recommend the authors to further polish the text for better readability. R4 argues that a good comparison with the state-of-the-art method in this field would be difficult and the comparison with an RNN baseline is rigorously carried out.\n\nAfter discussion, all reviewers agree that this paper deserves a publication at ICLR.", "reviews": [{"review_id": "Byg3y3C9Km-0", "review_text": "Post-rebuttal revision: The authors have adressed my concerns sufficiently. The paper still has issues with presentation, and weak comparisons to earlier methods. However, the field is currently rapidly developing, and comparing to earlier works is often difficult. I believe the Langevin-based prediction is a significant and clever contribution. I'm raising my score to 6. ------ The paper proposes an end-to-end neural architecture for learning protein structures from sequences. The problem is highly important. The method proposes to use a Langevin simulator to fold the protein \u2018in silico\u2019 from some initial state, proposes numerous tricks for the optimisation, and proposes neural networks to extract information from both the sequence and the fold state (energy function). The system works on internal coordinates, which are conditioned and integrated on the fly. The method seems to perform very well, improving upon their baseline model considerably. In spite of the paper being an outstanding work, I have two criticisms about the accessibility and impact of the paper on the broader ICLR audience. In its current form and complexity, the paper feels accessible mostly to a narrow audience. First, the framework proposed in the paper is massive, containing a large amount of components, neural networks, simulators, integrators, optimisation tricks, alignments, profiles, stabilizations, etc. The amount of work done in the manuscript is staggering, but the method is also difficult to understand from reading the main manuscript alone. The 10+ page appendix is critical for understanding (for instance, the appendix reveals that MSA is used to generate more data), and even with it the method is difficult to grasp as a whole. This paper should be presented in a journal form with a presentation not hindered by page limits, while currently one needs to jump between the main text and appendix to get the whole picture. I also wonder if some parts of the system have already been published, and perhaps the presentation could be condensed that way. Second, the introduction lists numerous competing methods both on the protein modelling side and on the MCMC vs optimisation side. The paper does not compare to any of these, which is strange, and makes it difficult to assess how much this paper improves upon state-of-the-art. Right now its unclear what is state-of-the-art in general. No bigger context of protein folding is given either, for instance, how well the method fares against purely alignment based approaches, or against purely physics-based simulators. Finally, the experimental section poorly describes how all the pieces of the system affect the final predictions. The discussion on the exploding gradients and dampening is excellent however. The only baseline is one with the simulator replaced by an RNN. There does not seem to be any running time analyses. As such, it is hard to interpret the current system, and it feels like a black box.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your constructive review of this work . We hope that with improved presentation and contextualization , it can be relevant to a broad audience at ICLR . > In its current form and complexity , the paper feels accessible mostly to a narrow audience . > The amount of work done in the manuscript is staggering , but the method is also difficult to understand from reading the main manuscript alone . The 10+ page appendix is critical for understanding \u2026 This paper should be presented in a journal form with a presentation not hindered by page limits\u2026 I also wonder if some parts of the system have already been published , and perhaps the presentation could be condensed that way . While a journal might better accommodate the appendix , we believe that the complete system can be of interest to a general audience at ICLR because it connects recent interesting ideas in machine learning ( e.g.differentiable simulators & meta-learning ) to a challenging and well-known application domain with novel methodology ( transform integrator , stabilization strategies , etc ) . To make these contributions more accessible , we have simplified the presentation of the model in the main text and added previously missing legends and overview paragraphs . ( Lastly , in case its relevant , no parts of the model have previously been published . ) > The paper does not compare to any of these , which is strange , and makes it difficult to assess how much this paper improves upon state-of-the-art . Right now its unclear what is state-of-the-art in general . \u2026 The only baseline is one with the simulator replaced by an RNN We focus on comparing to end-to-end approaches with a controlled dataset , largely due to the computational challenges of training the differentiable simulator model . We have added a discussion of Advantages and Disadvantages that more explicitly makes the connection to recent end-to-end methods for predicting protein structure in terms of angles ( AlQuraishi et al ) and our baseline RNN . We focus on comparing to the RNN baseline because it shares the same loss and data augmentation strategies as our simulator , thus making clearer where differences in performance come from . While we do see that our differentiable simulator model can generalize more effectively to distant folds on our controlled dataset of ~35k proteins < 200AAs , the dataset splitting and significant cost of training ( 2 months on 2 GPUs ) mean that it is difficult to evaluate the approach performance on large proteins . Nevertheless , new models in machine learning with better inductive biases but greater computational demands often get their start via medium-sized controlled datasets . > There does not seem to be any running time analyses Thanks for pointing this out . We have added a table of qualitative running times in the results section . > the experimental section poorly describes how all the pieces of the system affect the final predictions > it feels like a black box . While we could not afford to perform ablation studies of individual components given the long training time , we believe that structured nature of a differentiable simulator can make it easier to interpret and engineer than purely neural architectures . For example , the Markov Random Field formulation of the energy function means the sequence and structure features can be interpreted separately , and both the efficacy of Langevin dynamics and benefits of alternative coordinate parameterizations to sampling are well-understood phenomena ."}, {"review_id": "Byg3y3C9Km-1", "review_text": "Overall this is an important piece of work that deserves publication at ICLR. I recommend to the authors revise their manuscript to make it more accessible to the machine learning community and that they provide better context to allow them to assess the relative quality of the work compared to state of the art results. # Quality The hypothesis that the authors set out to resolve is whether there is an advantage in using an energy function sampled by Langevin dynamics versus simply using a neural network to regress shape from sequence. They construct a flexible deep energy model where the sequence and structure dependent parts are separated in such a way that fast rollouts are possible. They also adapt the learning algorithm to ensure that long rollouts can be carried out and present a clever trick for integrating internal coordinates efficiently on a GPU. The only criticism in terms of quality of work is that it somewhat lacks putting in context with results from the larger community, for example how well does the model compare in terms of speed and accuracy with co-evolutionary approaches? I realise it will not be possible to give a completely fair like to like comparison, but it will help readers put the results in context if they understood, for example, what the average TM score for CASP12 results was, as summarized in this paper for example: https://onlinelibrary.wiley.com/doi/full/10.1002/prot.25423. Similarly, it would be useful to compare the baseline - at least qualitatively - with the results from AlQuraishi et. al. whose model seems very similar in spirit. # Clarity I think in terms of clarity, the paper could be improved a little to take into account the audience of ICLR. In particular: * It may be useful to add a sentence of how profiles have been found to improve secondary structure prediction greatly. Currently the text makes it sound as though they constitute a sort of 'data augmentation', whereas in my opinion they add information compared to the sequence alone. In fact a brief explanation of the importance of homology might help the reader understand the relevance of the hierarchical approach taken to splitting the training set. * Fig. 2 caption. Could add some information to explain what panel B is showing. I think this would go a long way to explain why both cartesian and internal coordinates are important. * Fig. 4 second panel. The x axis should be labeled fraction or be numbered 0-100. * Fig 4. caption. The figure does not have a caption explaining what the graphs are showing. This would be a good place to explain that the colors refer to test sets that overlap with the training set in the full CATH code (black), overlap only in the CAT code (orange) etc. I admit I had found the explanation of the test/train/validation split rather confusing. It is not clear what the validation set is used for, i.e. which hyper-parameters have been tuned on it etc. * The nature of the loss. The appendix does a good job in describing each term in the loss function, but does not explain how the empirical loss function and the log-likelihood terms are mixed together. # Originality The work is original and is references the relevant literature. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the positive comments about the approach and suggestions for how to improve the presentation . > It may be useful to add a sentence of how profiles have been found to improve secondary structure prediction greatly . Currently the text makes it sound as though they constitute a sort of 'data augmentation ' , whereas in my opinion they add information compared to the sequence alone . We agree that evolutionary profiles add far more information than data augmentation , and have added an explicit point of comparison in the results section to draw the connection to SS prediction . We have also clarified the distinction between data augmentation and profiles in Appendix B . > lacks putting in context with results from the larger community , for example how well does the model compare in terms of speed and accuracy with co-evolutionary approaches ? \u2026 Similarly , it would be useful to compare the baseline - at least qualitatively - with the results from AlQuraishi et . al.whose model seems very similar in spirit . We agree that the paper needs to provide better context in the landscape of methods for protein structure prediction and have tried to address this by adding an \u2018 Advantages and Disadvantages \u2019 paragraph to the Results . Since scaling our method to larger datasets of proteins remains difficult with current computational resources , we focus primarily on comparing to other end-to-end approaches , of which an RNN-based angle prediction ( of AlQuraishi et al ) is the other major approach . Hopefully our updated text and figure legends can clarify this . > [ Fig 2. , Fig 4 second panel and caption ] Thank you for these suggestions . We have fixed these figure legends to be clearer . > does not explain how the empirical loss function and the log-likelihood terms are mixed together . Thanks for pointing this out . Our loss involves a simple sum of all terms without weights , and we have added a sentence to clarify this . > I admit I had found the explanation of the test/train/validation split rather confusing.It is not clear what the validation set is used for , i.e.which hyper-parameters have been tuned on it etc . We have improved the explanation of how we split the dataset hierarchically and temporally to capture different generalization difficulties . We did not explicitly tune hyperparameters on the validation set ( in part due to the long training time , for which 200k iterations was what we could afford ) , but we did allow ourselves to look at the validation set during model development and thus refer to it as such ."}, {"review_id": "Byg3y3C9Km-2", "review_text": "The paper proposes a new end-to-end training framework for computational prediction of protein structure from sequence. This is a very important problem and any progress due to new data and/or methods for utilizing may have high impact. The paper presents several technical contributions in the modelling and training procedure - for example, automatic transformation between Cartesian and angular coordinates, using Langevin dynamics, and imputation method to get fine atomic coordinates. The overall breadth and depth of the methods presented in the paper are impressive. The paper describes a quite complicated systems with multiple modules interacting between them. The paper doesn't describe the system built in enough details, although many of the details are given in the appendix. Figure. 6 presents a scheme of the entire system, but it lacks details about the different modules, and it is not clear how they interact and how their training together is performed. The pseudo-code boxes describing Algorithms 1-4, and Table 2 describing the representation are informative and helpful, and more descriptions of this type would help. For example: - In Algorithm 3, what do 'CartesianStep' and 'ClippedInternalStep' mean? where are they described? (should have their own boxes/description). - I didn't see an Algorithm describing the atomic imputation part. - It would be good to add a high-level pseudo-code for the entire end-to-end training algorithm. In it there could be calls to Algorithms 1-4 when needed. There is also no single place where all the parameters used by the authors to achieve their empirical results are presented (e.g. learning rates, Gaussian kernel widths, how are random time steps for enforcing Lipschitz condition chosen etc.). In addition, the empirical loss defined in eq. (8) is a sum of 6 different losses. It is not clear how are these very different losses scaled to the same 'units', which ones are more important, if and how are constants multiplying them chosen to give lower/higher weights to some of the losses etc. - I guess these choices will have a large effect on the training. The authors present generalization results of their trained model in predicting 3D structures from CATH at different generalization level (i.e. different similarity levels to the training set proteins). It is not clear to me how good are these results, except that they are shown to be better than a baseline simple model. How well does the author's model compare to other recently suggested end-to-end models? (the authors mention AlQuraishi, Anand&Huang, papers). How do they compare to state-of-the art structure prediction programs? (e.g. CASP winners)? I realize giving an automatic end-to-end solution is interesting even if performance is below that of best programs, but still it would be good to know gaps. If such comparisons are less meaningful/not practical to perform this should be argued convincingly. It would also be useful to add some metrics of running time - it is not clear how computationally heavy and scalable is the author's model and training, compared to other methods. There are many typos and inconsistent notations which makes it harder for the reader to understand the paper. For example, 'Figure ??' in multiple locations, wrong Figure referenced, using s vs. S for sequence - S is defined as an L*20 matrix but in the appendix there are 3 indices: s_{i,l,j} and it looks like different sequences in alignment should be denoted s_i. Equation for M_{l,j} isn't clear: j is used both as fixed index and index in summation. The indexing in 'orientation vectors' v-hat_ij definition seems off (the formula of base vectors gives 0/0) ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the extensive comments as well as suggestions for improving the presentation and evaluation . > Figure.6 presents a scheme of the entire system , but it lacks details about the different modules , and it is not clear how they interact and how their training together is performed . We apologize for the lack of clarity and have added a legend to this figure that walks through the complete sampling process ( which is , in turn , backpropagated through ) . > The pseudo-code boxes describing Algorithms 1-4 , and Table 2 describing the representation are informative and helpful , and more descriptions of this type would help . > what do 'CartesianStep ' and 'ClippedInternalStep ' mean ? where are they described ? We are glad that these algorithm boxes are helpful , and while we have not made them for 'CartesianStep ' and 'ClippedInternalStep ' , these computations refer to the Langevin Dynamics and Speed Clipping paragraphs in Appendix A . > I did n't see an Algorithm describing the atomic imputation part . The atomic imputation was small and potentially easy to miss , but is defined in Section 2.4 \u2018 atomic imputation \u2019 . We have modified the formatting and added an overview paragraph to highlight its importance . > There is also no single place where all the parameters used by the authors While the complexity of the model makes presenting the hyperparameters in table form cumbersome , we intend to release the code which includes hyperparameters as structured objects . > if and how are constants multiplying them chosen to give lower/higher weights to some of the losses etc Regarding the loss , we simply sum the individual loss terms and have not explored weighting ( owing to the the costly training time ) . We have clarified this in the text . > It is not clear to me how good are these results , except that they are shown to be better than a baseline simple model . How well does the author 's model compare to other recently suggested end-to-end models ? ( the authors mention AlQuraishi , Anand & Huang , papers ) . How do they compare to state-of-the art structure prediction programs ? ( e.g.CASP winners ) ? I realize giving an automatic end-to-end solution is interesting even if performance is below that of best programs , but still it would be good to know gaps . If such comparisons are less meaningful/not practical to perform this should be argued convincingly . To better contextualize our model , we have added an Advantages and Disadvantages discussion as well as an improved explanation of the baseline . The RNN baseline method is similar to the approach of AlQuraishi ( though differing in the use of coarse-to-fine reconstruction as well as our loss terms ) . We focus on comparing to the baseline model because it uses the same loss and imputation network , thus isolating the differences to the simulator itself . Regarding CASP : Although our method was able to scale to training on a database of ~35k protein domains up to length 200 ( on 2 GPUs & 2 months ) , this particular dataset excludes the longer proteins and more diverse templates that would be necessary to be relevant to CASP . > It would also be useful to add some metrics of running time We have added a qualitative table of approximate running times for our methods as well as conventional protein folding approaches . > typos and inconsistent notations Thank you for pointing these typos out , we believe they are now fixed ."}, {"review_id": "Byg3y3C9Km-3", "review_text": "This paper presents an end-to-end differentiable model (NEMO) for protein structure prediction. I found this paper very interesting and the idea of training the network through the sampling procedure promising. The authors present the challenges and techniques (damping, Lyapunov regularization etc) in detail. The paper is clearly written, however the description of the method can be confusing. This stems in part from the many components of the network as well as the fact that the protein is represented using various coordinate systems and features, so that it is not easy to follow which applies at each stage. Fig. 6 in the appendix helps, however it would be better to have a (perhaps more concise) overview in the main text. In the evaluation, the NEMO method is compared to a baseline approach using RNNs. While NEMO trained on profile features performs best, the baseline is trained on sequences only. However, it outperforms the NEMO model trained on sequence-only in every category. Therefore, it would be interesting to see whether NEMO outperforms a baseline trained on profile features. Otherwise, I am not certain whether I can follow the conclusion that \"NEMO generalizes more effectively\". Beyond that, it would be interesting to see some generated atomic substructures from the imputation network, in particular an analysis of how diverse the generated atom positions are and whether they depend on the local environment. Overall, I appreciate the general idea and find the proposed approach very interesting. The contribution could have been stronger with a more detailed evaluation and better presentation.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review and positive words about the idea and approach . While we will respond in full later , we wanted to briefly clarify that all RNN models and NEMO results of Fig 4,5 were trained on profiles . The sentence `` We report the results of a sequence-only model in Table 1 and Figure 4 '' is a figure-link typo and should instead read `` We also report the results of a sequence-only NEMO model in Table 1 and Figure 9 . '' We apologize for the confusion and will make these points clearer upon revision . In the meantime , we hope that this can clarify that our main claim about generalization is based on comparing profile-based NEMO to profile-based baselines ."}], "0": {"review_id": "Byg3y3C9Km-0", "review_text": "Post-rebuttal revision: The authors have adressed my concerns sufficiently. The paper still has issues with presentation, and weak comparisons to earlier methods. However, the field is currently rapidly developing, and comparing to earlier works is often difficult. I believe the Langevin-based prediction is a significant and clever contribution. I'm raising my score to 6. ------ The paper proposes an end-to-end neural architecture for learning protein structures from sequences. The problem is highly important. The method proposes to use a Langevin simulator to fold the protein \u2018in silico\u2019 from some initial state, proposes numerous tricks for the optimisation, and proposes neural networks to extract information from both the sequence and the fold state (energy function). The system works on internal coordinates, which are conditioned and integrated on the fly. The method seems to perform very well, improving upon their baseline model considerably. In spite of the paper being an outstanding work, I have two criticisms about the accessibility and impact of the paper on the broader ICLR audience. In its current form and complexity, the paper feels accessible mostly to a narrow audience. First, the framework proposed in the paper is massive, containing a large amount of components, neural networks, simulators, integrators, optimisation tricks, alignments, profiles, stabilizations, etc. The amount of work done in the manuscript is staggering, but the method is also difficult to understand from reading the main manuscript alone. The 10+ page appendix is critical for understanding (for instance, the appendix reveals that MSA is used to generate more data), and even with it the method is difficult to grasp as a whole. This paper should be presented in a journal form with a presentation not hindered by page limits, while currently one needs to jump between the main text and appendix to get the whole picture. I also wonder if some parts of the system have already been published, and perhaps the presentation could be condensed that way. Second, the introduction lists numerous competing methods both on the protein modelling side and on the MCMC vs optimisation side. The paper does not compare to any of these, which is strange, and makes it difficult to assess how much this paper improves upon state-of-the-art. Right now its unclear what is state-of-the-art in general. No bigger context of protein folding is given either, for instance, how well the method fares against purely alignment based approaches, or against purely physics-based simulators. Finally, the experimental section poorly describes how all the pieces of the system affect the final predictions. The discussion on the exploding gradients and dampening is excellent however. The only baseline is one with the simulator replaced by an RNN. There does not seem to be any running time analyses. As such, it is hard to interpret the current system, and it feels like a black box.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your constructive review of this work . We hope that with improved presentation and contextualization , it can be relevant to a broad audience at ICLR . > In its current form and complexity , the paper feels accessible mostly to a narrow audience . > The amount of work done in the manuscript is staggering , but the method is also difficult to understand from reading the main manuscript alone . The 10+ page appendix is critical for understanding \u2026 This paper should be presented in a journal form with a presentation not hindered by page limits\u2026 I also wonder if some parts of the system have already been published , and perhaps the presentation could be condensed that way . While a journal might better accommodate the appendix , we believe that the complete system can be of interest to a general audience at ICLR because it connects recent interesting ideas in machine learning ( e.g.differentiable simulators & meta-learning ) to a challenging and well-known application domain with novel methodology ( transform integrator , stabilization strategies , etc ) . To make these contributions more accessible , we have simplified the presentation of the model in the main text and added previously missing legends and overview paragraphs . ( Lastly , in case its relevant , no parts of the model have previously been published . ) > The paper does not compare to any of these , which is strange , and makes it difficult to assess how much this paper improves upon state-of-the-art . Right now its unclear what is state-of-the-art in general . \u2026 The only baseline is one with the simulator replaced by an RNN We focus on comparing to end-to-end approaches with a controlled dataset , largely due to the computational challenges of training the differentiable simulator model . We have added a discussion of Advantages and Disadvantages that more explicitly makes the connection to recent end-to-end methods for predicting protein structure in terms of angles ( AlQuraishi et al ) and our baseline RNN . We focus on comparing to the RNN baseline because it shares the same loss and data augmentation strategies as our simulator , thus making clearer where differences in performance come from . While we do see that our differentiable simulator model can generalize more effectively to distant folds on our controlled dataset of ~35k proteins < 200AAs , the dataset splitting and significant cost of training ( 2 months on 2 GPUs ) mean that it is difficult to evaluate the approach performance on large proteins . Nevertheless , new models in machine learning with better inductive biases but greater computational demands often get their start via medium-sized controlled datasets . > There does not seem to be any running time analyses Thanks for pointing this out . We have added a table of qualitative running times in the results section . > the experimental section poorly describes how all the pieces of the system affect the final predictions > it feels like a black box . While we could not afford to perform ablation studies of individual components given the long training time , we believe that structured nature of a differentiable simulator can make it easier to interpret and engineer than purely neural architectures . For example , the Markov Random Field formulation of the energy function means the sequence and structure features can be interpreted separately , and both the efficacy of Langevin dynamics and benefits of alternative coordinate parameterizations to sampling are well-understood phenomena ."}, "1": {"review_id": "Byg3y3C9Km-1", "review_text": "Overall this is an important piece of work that deserves publication at ICLR. I recommend to the authors revise their manuscript to make it more accessible to the machine learning community and that they provide better context to allow them to assess the relative quality of the work compared to state of the art results. # Quality The hypothesis that the authors set out to resolve is whether there is an advantage in using an energy function sampled by Langevin dynamics versus simply using a neural network to regress shape from sequence. They construct a flexible deep energy model where the sequence and structure dependent parts are separated in such a way that fast rollouts are possible. They also adapt the learning algorithm to ensure that long rollouts can be carried out and present a clever trick for integrating internal coordinates efficiently on a GPU. The only criticism in terms of quality of work is that it somewhat lacks putting in context with results from the larger community, for example how well does the model compare in terms of speed and accuracy with co-evolutionary approaches? I realise it will not be possible to give a completely fair like to like comparison, but it will help readers put the results in context if they understood, for example, what the average TM score for CASP12 results was, as summarized in this paper for example: https://onlinelibrary.wiley.com/doi/full/10.1002/prot.25423. Similarly, it would be useful to compare the baseline - at least qualitatively - with the results from AlQuraishi et. al. whose model seems very similar in spirit. # Clarity I think in terms of clarity, the paper could be improved a little to take into account the audience of ICLR. In particular: * It may be useful to add a sentence of how profiles have been found to improve secondary structure prediction greatly. Currently the text makes it sound as though they constitute a sort of 'data augmentation', whereas in my opinion they add information compared to the sequence alone. In fact a brief explanation of the importance of homology might help the reader understand the relevance of the hierarchical approach taken to splitting the training set. * Fig. 2 caption. Could add some information to explain what panel B is showing. I think this would go a long way to explain why both cartesian and internal coordinates are important. * Fig. 4 second panel. The x axis should be labeled fraction or be numbered 0-100. * Fig 4. caption. The figure does not have a caption explaining what the graphs are showing. This would be a good place to explain that the colors refer to test sets that overlap with the training set in the full CATH code (black), overlap only in the CAT code (orange) etc. I admit I had found the explanation of the test/train/validation split rather confusing. It is not clear what the validation set is used for, i.e. which hyper-parameters have been tuned on it etc. * The nature of the loss. The appendix does a good job in describing each term in the loss function, but does not explain how the empirical loss function and the log-likelihood terms are mixed together. # Originality The work is original and is references the relevant literature. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the positive comments about the approach and suggestions for how to improve the presentation . > It may be useful to add a sentence of how profiles have been found to improve secondary structure prediction greatly . Currently the text makes it sound as though they constitute a sort of 'data augmentation ' , whereas in my opinion they add information compared to the sequence alone . We agree that evolutionary profiles add far more information than data augmentation , and have added an explicit point of comparison in the results section to draw the connection to SS prediction . We have also clarified the distinction between data augmentation and profiles in Appendix B . > lacks putting in context with results from the larger community , for example how well does the model compare in terms of speed and accuracy with co-evolutionary approaches ? \u2026 Similarly , it would be useful to compare the baseline - at least qualitatively - with the results from AlQuraishi et . al.whose model seems very similar in spirit . We agree that the paper needs to provide better context in the landscape of methods for protein structure prediction and have tried to address this by adding an \u2018 Advantages and Disadvantages \u2019 paragraph to the Results . Since scaling our method to larger datasets of proteins remains difficult with current computational resources , we focus primarily on comparing to other end-to-end approaches , of which an RNN-based angle prediction ( of AlQuraishi et al ) is the other major approach . Hopefully our updated text and figure legends can clarify this . > [ Fig 2. , Fig 4 second panel and caption ] Thank you for these suggestions . We have fixed these figure legends to be clearer . > does not explain how the empirical loss function and the log-likelihood terms are mixed together . Thanks for pointing this out . Our loss involves a simple sum of all terms without weights , and we have added a sentence to clarify this . > I admit I had found the explanation of the test/train/validation split rather confusing.It is not clear what the validation set is used for , i.e.which hyper-parameters have been tuned on it etc . We have improved the explanation of how we split the dataset hierarchically and temporally to capture different generalization difficulties . We did not explicitly tune hyperparameters on the validation set ( in part due to the long training time , for which 200k iterations was what we could afford ) , but we did allow ourselves to look at the validation set during model development and thus refer to it as such ."}, "2": {"review_id": "Byg3y3C9Km-2", "review_text": "The paper proposes a new end-to-end training framework for computational prediction of protein structure from sequence. This is a very important problem and any progress due to new data and/or methods for utilizing may have high impact. The paper presents several technical contributions in the modelling and training procedure - for example, automatic transformation between Cartesian and angular coordinates, using Langevin dynamics, and imputation method to get fine atomic coordinates. The overall breadth and depth of the methods presented in the paper are impressive. The paper describes a quite complicated systems with multiple modules interacting between them. The paper doesn't describe the system built in enough details, although many of the details are given in the appendix. Figure. 6 presents a scheme of the entire system, but it lacks details about the different modules, and it is not clear how they interact and how their training together is performed. The pseudo-code boxes describing Algorithms 1-4, and Table 2 describing the representation are informative and helpful, and more descriptions of this type would help. For example: - In Algorithm 3, what do 'CartesianStep' and 'ClippedInternalStep' mean? where are they described? (should have their own boxes/description). - I didn't see an Algorithm describing the atomic imputation part. - It would be good to add a high-level pseudo-code for the entire end-to-end training algorithm. In it there could be calls to Algorithms 1-4 when needed. There is also no single place where all the parameters used by the authors to achieve their empirical results are presented (e.g. learning rates, Gaussian kernel widths, how are random time steps for enforcing Lipschitz condition chosen etc.). In addition, the empirical loss defined in eq. (8) is a sum of 6 different losses. It is not clear how are these very different losses scaled to the same 'units', which ones are more important, if and how are constants multiplying them chosen to give lower/higher weights to some of the losses etc. - I guess these choices will have a large effect on the training. The authors present generalization results of their trained model in predicting 3D structures from CATH at different generalization level (i.e. different similarity levels to the training set proteins). It is not clear to me how good are these results, except that they are shown to be better than a baseline simple model. How well does the author's model compare to other recently suggested end-to-end models? (the authors mention AlQuraishi, Anand&Huang, papers). How do they compare to state-of-the art structure prediction programs? (e.g. CASP winners)? I realize giving an automatic end-to-end solution is interesting even if performance is below that of best programs, but still it would be good to know gaps. If such comparisons are less meaningful/not practical to perform this should be argued convincingly. It would also be useful to add some metrics of running time - it is not clear how computationally heavy and scalable is the author's model and training, compared to other methods. There are many typos and inconsistent notations which makes it harder for the reader to understand the paper. For example, 'Figure ??' in multiple locations, wrong Figure referenced, using s vs. S for sequence - S is defined as an L*20 matrix but in the appendix there are 3 indices: s_{i,l,j} and it looks like different sequences in alignment should be denoted s_i. Equation for M_{l,j} isn't clear: j is used both as fixed index and index in summation. The indexing in 'orientation vectors' v-hat_ij definition seems off (the formula of base vectors gives 0/0) ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the extensive comments as well as suggestions for improving the presentation and evaluation . > Figure.6 presents a scheme of the entire system , but it lacks details about the different modules , and it is not clear how they interact and how their training together is performed . We apologize for the lack of clarity and have added a legend to this figure that walks through the complete sampling process ( which is , in turn , backpropagated through ) . > The pseudo-code boxes describing Algorithms 1-4 , and Table 2 describing the representation are informative and helpful , and more descriptions of this type would help . > what do 'CartesianStep ' and 'ClippedInternalStep ' mean ? where are they described ? We are glad that these algorithm boxes are helpful , and while we have not made them for 'CartesianStep ' and 'ClippedInternalStep ' , these computations refer to the Langevin Dynamics and Speed Clipping paragraphs in Appendix A . > I did n't see an Algorithm describing the atomic imputation part . The atomic imputation was small and potentially easy to miss , but is defined in Section 2.4 \u2018 atomic imputation \u2019 . We have modified the formatting and added an overview paragraph to highlight its importance . > There is also no single place where all the parameters used by the authors While the complexity of the model makes presenting the hyperparameters in table form cumbersome , we intend to release the code which includes hyperparameters as structured objects . > if and how are constants multiplying them chosen to give lower/higher weights to some of the losses etc Regarding the loss , we simply sum the individual loss terms and have not explored weighting ( owing to the the costly training time ) . We have clarified this in the text . > It is not clear to me how good are these results , except that they are shown to be better than a baseline simple model . How well does the author 's model compare to other recently suggested end-to-end models ? ( the authors mention AlQuraishi , Anand & Huang , papers ) . How do they compare to state-of-the art structure prediction programs ? ( e.g.CASP winners ) ? I realize giving an automatic end-to-end solution is interesting even if performance is below that of best programs , but still it would be good to know gaps . If such comparisons are less meaningful/not practical to perform this should be argued convincingly . To better contextualize our model , we have added an Advantages and Disadvantages discussion as well as an improved explanation of the baseline . The RNN baseline method is similar to the approach of AlQuraishi ( though differing in the use of coarse-to-fine reconstruction as well as our loss terms ) . We focus on comparing to the baseline model because it uses the same loss and imputation network , thus isolating the differences to the simulator itself . Regarding CASP : Although our method was able to scale to training on a database of ~35k protein domains up to length 200 ( on 2 GPUs & 2 months ) , this particular dataset excludes the longer proteins and more diverse templates that would be necessary to be relevant to CASP . > It would also be useful to add some metrics of running time We have added a qualitative table of approximate running times for our methods as well as conventional protein folding approaches . > typos and inconsistent notations Thank you for pointing these typos out , we believe they are now fixed ."}, "3": {"review_id": "Byg3y3C9Km-3", "review_text": "This paper presents an end-to-end differentiable model (NEMO) for protein structure prediction. I found this paper very interesting and the idea of training the network through the sampling procedure promising. The authors present the challenges and techniques (damping, Lyapunov regularization etc) in detail. The paper is clearly written, however the description of the method can be confusing. This stems in part from the many components of the network as well as the fact that the protein is represented using various coordinate systems and features, so that it is not easy to follow which applies at each stage. Fig. 6 in the appendix helps, however it would be better to have a (perhaps more concise) overview in the main text. In the evaluation, the NEMO method is compared to a baseline approach using RNNs. While NEMO trained on profile features performs best, the baseline is trained on sequences only. However, it outperforms the NEMO model trained on sequence-only in every category. Therefore, it would be interesting to see whether NEMO outperforms a baseline trained on profile features. Otherwise, I am not certain whether I can follow the conclusion that \"NEMO generalizes more effectively\". Beyond that, it would be interesting to see some generated atomic substructures from the imputation network, in particular an analysis of how diverse the generated atom positions are and whether they depend on the local environment. Overall, I appreciate the general idea and find the proposed approach very interesting. The contribution could have been stronger with a more detailed evaluation and better presentation.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review and positive words about the idea and approach . While we will respond in full later , we wanted to briefly clarify that all RNN models and NEMO results of Fig 4,5 were trained on profiles . The sentence `` We report the results of a sequence-only model in Table 1 and Figure 4 '' is a figure-link typo and should instead read `` We also report the results of a sequence-only NEMO model in Table 1 and Figure 9 . '' We apologize for the confusion and will make these points clearer upon revision . In the meantime , we hope that this can clarify that our main claim about generalization is based on comparing profile-based NEMO to profile-based baselines ."}}