{"year": "2020", "forum": "H1gax6VtDB", "title": "Contrastive Learning of Structured World Models", "decision": "Accept (Talk)", "meta_review": "This paper presents an approach to learn state representations of the scene as well as their action-conditioned transition model, applying contrastive learning on top of a graph neural network. The reviewers unanimously agree that this paper contains a solid research contribution and the authors' response to the reviews further clarified their concerns.", "reviews": [{"review_id": "H1gax6VtDB-0", "review_text": "This paper aims to learn a structured latent space for images, which is made up of objects and their relations. The method works by (1) extracting object masks via a CNN, (2) turning those masks into feature vectors via an MLP, (3) estimating an action-conditioned delta for each feature via a GNN. Learning happens with contrastive losses, which ask that each feature+delta is close to the true next feature, and far away from other random possibilities. Experiments in simple synthetic environments (e.g., 2D geometric shapes moving on a black background) show encouraging results. This paper has a simple, well-motivated method. It is clearly written, and easy to understand. The evaluation is straightforward also: the paper merely shows that this model's nearest neighbors in featurespace are better than the nearest neighbors of World Model (2018) and PAIG (2019). Also, some visualizations indicate that for these simple directional manipulations (up/down/left/right motion), PCA compressions of the model's states have a clean lattice-like structure. It is impressive that the model discovers and segments objects so accurately. Perhaps this could actually be evaluated. However, I do not understand why results are so sensitive to the number of object slots (K). This seems like a severe limitation of the model, since in general we have no idea what value to set for this. Although I like the paper, I am not sure that there is sufficient evidence for the method being something useful. Yes, H@1 and MRR are high, but as the paper itself implies, the real goal is to improve performance (or, e.g., sample efficiency) in some downstream task. Given how simple these domains are, and the fact that data is collected with purely random exploration, it is difficult to imagine that there is any significant difference between the training set and the test set. For example, if you make 1000 episodes of 10 steps each in Space Invaders, you practically get 1000 copies of the same 10 frames. I worry that all the evaluation has shown so far is that this model can efficiently represent the state transitions that it has observed. The authors note that it was beneficial to only use the hinge on the negative energy term. This seems unusual, since a hinge on the positive term allows some slack, which intuitively makes the objective better-formulated. Can the authors please clarify this result, at least empirically? ", "rating": "8: Accept", "reply_text": "Thank you for your valuable feedback . Please find our responses to your questions and comments below . [ Number of object slots ( K ) ] : This is a very good question . Our results indicate that it is best to choose K based on validation set performance if there is no clear a-priori choice . Generalization to unseen environment instances likely not only depends on how well objects are discovered and represented , but also to what degree the learned transition model ( GNN ) on this structured latent space generalizes . Hence , it is difficult to a-priori predict which number of object slots would work well on a particular problem , unless the model has some built-in mechanism to assign `` empty '' slots , such as the iterative mechanism in MONet ( Burgess et al. , 2019 ) , which however relies on pixel-based losses . Despite the dependency on K , we still observe stronger generalization performance across a range of settings compared to unstructured baselines using pixel-based losses . [ Difference between training and test sets ] : This is a very good point and we indeed try to control for this issue . For the Atari benchmarks , we populate the experience buffer only after a certain number of frames ( which represent fully deterministic opponent transitions ) during which we take random actions . We have verified that no episode ( i.e. , the full 10-step sequence of states/actions ) in the test set exactly coincides with an episode from the training set for both Pong and Space Invaders , and hence performing well on this task requires some form of generalization . In the grid world / block pushing environments , there are around 6.4M possible environment configurations , and hence the train/test overlap can be expected to be small ( both train and test set contain 100k experience triples ) . For the physics simulation the state space is continuous and starting positions are sampled at random . We have made this clearer in the paper . [ Hinge loss ] : We performed a direct comparison between our loss and the triplet loss from TransE ( Bordes et al. , 2013 ) , i.e.with the hinge covering both the positive and the negative energy term . The table below summarizes mean MRR ( in % ) results ( from 4 runs with random init . ) on the 2D Shapes environment for hinge parameters $ \\gamma $ in { 1,5,10 } . + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Model | 1 Step | 5 Steps | 10 Steps | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | C-SWM ( default loss , $ \\gamma=1 $ ) | 100 | 100 | 100 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Full hinge , $ \\gamma=1 $ | 97.8 | 54.4 | 21.8 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Full hinge , $ \\gamma=5 $ | 98.8 | 65.7 | 26.8 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Full hinge , $ \\gamma=10 $ | 98.5 | 63.3 | 30.3 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + This setting performs significantly worse in In ( Bordes et al. , 2013 ) , the authors include this constraint to avoid pathologies in their loss function ( trivial minimization by growing the norms of the embeddings ) , which might be the cause for suboptimal performance in our case . We do not wish to constrain embeddings to a hypersphere in general , however , as this could affect how accurately we can learn certain structures ( e.g. , a hyperspherical latent space is likely less suitable for learning grid-structured representations and might make it more difficult for the transition model to generalize ) . Hyperspherical latent spaces could be useful , however , for learning rotational transformations . We have posted an updated version of our manuscript . You can find a short summary of our changes in our top-level comment ."}, {"review_id": "H1gax6VtDB-1", "review_text": "This paper tackles the problem of learning an encoder and transition model of an environment, such that the representation learnt uses an object-centric representation which could favor compositionality and generalisation. This is trained using a contrastive max-margin loss, instead of a generative loss as previously explored. They do not consider RL or follow-up tasks leveraging these representations and transition models yet. They perform an extensive assessment of their model, with many ablations, on 2 gridworld environments, one physical domain, and on Atari. The paper is very well motivated, easy to follow, and most of its assumptions and decisions are sensible and well supported. They also provide interesting assessments and insights into the evaluation scheme of such transition models, which would be of interest to many practitioners of this field. Apart from some issues presented below, I feel that this work is of good quality and would recommend it for acceptance. 1. The model is introduced in a very clear way, and most decisions seem particularly fair. I found the presentation of the contrastive loss with margin to be clear, and the GraphNet is also well supported (although see question below). However, two choices are surprising to me and would deserve some clarification and more space in the main text, instead of the Appendix: a. Why does the object extractor only output a scalar mask? This was not extremely clear from reading the main text (and confused me when I first saw Figure 1 and 3a), but as explained in the Appendix, the CNN is forced to output a sigmoid logit between [0, 1] per object channel. This seems overly constraining to me, as this restricts the network to only output \u201c1 bit\u201d of information per \u201cobject\u201d. However, maybe being able to represent other factors of these objects might be necessary to make better predictions? This also requires the user to select the number of output channels precisely, or the model might fail. This is visible in the Atari results, where the \u201cobjectness\u201d is much less clear. Did you try allowing the encoder to output more features per objects? Obviously this would be more complicated and would place you closer to a setting similar to MONet (Burgess et al. 2019) or IODINE (Greff et al. 2019), but this might help a lot. b. It was hard to find the dimensionality D of the abstract representation $z_t$. It is only reported in the Appendix, and is set to $D=2$ for the 2D gridworld tasks and $D=4$ for Atari and the physics environments. These are quite small, and the fact that they exactly coincide with your assumed sufficient statistics is a bit unfortunate. What happens if D is larger? Could you find the optimal D by some means? 2. The GraphNet makes sense to me, but I wondered why you did not provide $a_t^j$ to $e_t^{(i, j)}$ as well? I could imagine situations where one would need the action to know if an interaction between two slots is required. 3. Similarly, the fact that the action was directly partitioned per object (except in Atari where it was replicated), seemed slightly odd. Would it still work if it was not directly pre-aligned for the network? I.e. provide $a_t$ as conditioning for the global() module of the GraphNet, and let the network learn which nodes/edges it actually affects. 4. In your multi-object contrastive loss, how is the mapping between slot k in $z_t$ and $\\tilde{z}_t$ performed? Do you assume that a given object (say the red cube) is placed in the same $k$ slot across different scenes/timesteps? This may actually be harder to enforce by the network than expected (e.g. with MONet, there is no such \u201cslot stability\u201d, see [1] for a discussion). 5. It was unclear to me if the \u201cgrid\u201d shown in Figure 3 (b) and 5 is \u201creal\u201d? I.e. are you exactly plotting your $z_t$ embeddings, and they happen to lie precisely along this grid? If yes, I feel this is a slightly stronger result as you currently present, given this means that the latent space has mirrored the transition dynamics in a rather impressive fashion. 6. Related to that point, I found Figure 3 b) to be slightly too hard to understand and parse. The mapping of the colours of the arrows is not provided, and the correspondence between \u201cwhat 3D object is actually moving where\u201d and \u201cwhich of the coloured circles correspond to which other cubes in the image\u201d is hard to do (especially given the arbitrary rotation). Could you add arrows/annotations to make this clearer? Alternatively, presenting this as a sequence might help: e.g. show the sequence of real 3D images, along with the trajectory it traces on the 2D grid. 7. Figure 4 a) was also hard to interpret. Seeing these learnt filters did not tell much, and I felt that you were trying too hard to impose meaning on these, or at least it wasn\u2019t clear to me what to take of them directly. I would have left this in the Appendix. Figure 4 b) on the other hand was great, and I would put more emphasis on it. 8. There are no details on how the actual test data used to generate Table 1 was created, and what \u201cunseen environment instances\u201d would correspond to. It would be good to add this to the Appendix, and point forward to it at the end of the first paragraph of Section 4.6, as if you are claiming that combinatorial generalization is being tested this should be made explicit. I found Table 1 to be great, complete, and easy to parse. 9. It would be quite interesting to discuss how your work relates to [1], as the principles and goals are quite similar. On a similar note, if you wanted to extend your 2D shape environment from a gridworld to a continuous one with more factors of variations, their Spriteworld environment [2] might be a good candidate. References: [1] Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher P. Burgess, Alexander Lerchner, \u201cCOBRA: Data-Efficient Model-Based RL through Unsupervised Object Discovery and Curiosity-Driven Exploration\u201d, 2019, https://arxiv.org/abs/1905.09275 [2] Nicholas Watters, Loic Matthey, Sebastian Borgeaud, Rishabh Kabra, Alexander Lerchner, \u201cSpriteworld: A Flexible, Configurable Reinforcement Learning Environment\u201d, https://github.com/deepmind/spriteworld/ ", "rating": "8: Accept", "reply_text": "Thank you for your extensive review and for your detailed feedback , this is greatly appreciated . Please find our responses to your questions and comments below . Q1a [ Scalar mask ] : This is indeed a very good point , which we initially did not try experimentally to avoid additional complexity . Our synthetic block pushing environment does not require more than a simple scalar mask , as the model only needs to encode object location . For more complex environments , it could indeed be beneficial to assign more than one output channel per object . Note that the object encoder ( which maps from scalar mask to object latent variable ) is an MLP with high-dimensional hidden representations , which allows the model to extract , e.g. , object position from its mask . We carried out additional experiments on the Space Invaders task with { 2 , 5 , 10 } output channels per object slot and we found no significant difference in MRR results compared to using just one output channel . We added these results to the appendix , and we also further clarified this architecture detail in the paper . Q1b [ Dimensionality of latent space ] : We ran additional experiments with D > 2 on the block pushing experiments ( 2D shapes ) and we found that we get the same results for D in { 4 , 8 , 16 } , i.e. , MRR=100 % ( on { 1,5,10 } prediction steps into the future ) and the latent representations lie on a close to perfect 2D grid that is randomly oriented in the higher-dimensional latent space . So it seems like the choice of D does not have a significant influence on results as long as it is not too small . We have improved clarity on this detail in the paper . Q2 [ Actions on edge messages ] : Thanks for this suggestion . We initially designed the model with the example of the synthetic block pushing environments in mind , where it is not necessary to condition the messages on the action , but this could indeed in principle be useful for the Atari game setting . Alternatively , one could perform multiple rounds of message passing as suggested in the paper . We ran an additional experiment on Space Invaders with K=5 object slots , where we also conditioned the edge update on the action , but the results were very similar to our original setting , where we only condition the node update on the action : 26.0\u00b14.1 MRR ( in % ) 10-step prediction for the original setting vs. 27.5\u00b12.3 MRR ( in % ) for the setting with actions included in the edge update . Q3 [ Learning action-to-node assignment ] : This is a very good point and something we have n't had the chance to try experimentally yet . Extending the GNN model with a global state in the line of GraphNets ( Battaglia et al. , 2018 ) would certainly be a good starting point for learning the action-to-node/-edge assignment automatically , but it would likely require some more changes to the model ( or to the way actions are encoded ) as object slots are fully exchangeable in the current architecture and one would need a way to break this symmetry . Q4 [ Slot stability ] : Our model is `` slot stable '' as objects are identified with a particular feature map of the CNN . In other words , we can assume that the same object always ends up in the same slot ( for a fixed set of model parameters ) . While this is convenient , this is of course a limitation as it does not allow for instance disambiguation ( e.g.two objects with the same appearance ) , which needs to be overcome in future work ( see `` Instance Disambiguation '' in Section 4.7 on Limitations ) . For encoders that are not `` slot stable '' , one could potentially use something like the Sinkhorn distance to compute the energy terms , but this could come with other challenges . Q5 [ Grid-structure of embedding space ] : Yes , the grid is `` real '' ! There is no post-processing done to get these plots -- we directly visualize the learned 2D embedding space and plot learned transitions as lines/edges . We found it indeed remarkable that the model learns to uncover this latent structure so precisely . We made this point clearer in the paper . Q6/7 [ Figure clarity ] : Thank you , this is very helpful feedback regarding Figures 3 and 4 . We have updated both figures in the paper to improve clarity . ( continued in the next comment due to character limitations )"}, {"review_id": "H1gax6VtDB-2", "review_text": "The construction and learning of structured world models is an interesting area of research that could in principle enable better generalisation and interpretability for predictive models. The authors overcome the problem of using pixel-based losses (a common issue being reconstruction of small but potentially important objects) by using a contrastive latent space. The model otherwise makes use of a fixed number of object slots and a GNN transition model, similarly to prior approaches. The authors back up their method with nice results on 3D cubes and 3-body physics domains, and reasonable initial results on two Atari games, with ablations on the different components showing their contributions, so I would give this paper an accept. The comparisons to existing literature and related areas is very extensive, with interesting pointers to potential future work - particularly on the transition model and graph embeddings. As expected, the object-factorized action space appears to work well for generalisation, and could be extended/adapted, but setting a fixed number of objects K is a clearly fundamentally limiting hyperparameter, and so showing how the model performs under misspecification of this hyperparameter is useful to know for settings where this is known (2D shapes, 3D blocks, 3-body physics). The fact that K=1 is the best for Pong but K=5 is the best for Space Invaders raises at least two questions: can scaling K > 5 further improve performance on Space Invaders, and is it possible to make the model more robust to a greater-than-needed number of object slots? On a similar note, the data collection procedure for the Atari games seems to indicate that the model is quite sensitive to domains where actions rarely have an impact on the transition dynamics, or the interaction is more complex (e.g. other agents exist in the world) - coming up with a synthetic dataset where the importance of this can be quantified would again aid understanding of the authors' proposed method.", "rating": "8: Accept", "reply_text": "Thank you for your valuable feedback . Please find our responses to your questions and comments below . [ Number of object slots ] : We have carried out an analysis for the 3-body physics environment with misspecification of the number of object slots ( all other parameters are left the same ) , see results table for mean MRR ( in % ) results over 4 model runs below . The results show that K=1 is not sufficient for good generalization on the 3-body system , whereas K=5 performs comparable or slightly better than K=3 ( note that there is some variance in between runs ) . Looking only at the best 10-step prediction result out of 4 runs , we have 95.4 ( for K=3 ) vs. 93.3 ( for K=5 ) . + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Model | 1 Step | 5 Steps | 10 Steps | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | K=1 | 97.5 | 71.5 | 40.9 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | K=3 ( default ) | 100 | 98.5 | 85.2 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | K=5 | 100 | 98.7 | 91.0 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + In terms of increasing K beyond 5 on the Space Invaders benchmark : We have carried out an additional experiment with K=7 with the following mean MRR ( in % ) results : 71.5 ( 1 step ) , 28.3 ( 5 steps ) , 22.7 ( 10 steps ) -- i.e. , worse in long-term prediction than for K=5 ( best setting ) but comparable to K=5 in the 1 step prediction setting . Note that for the block pushing environments , we can not change the number of object slots without changing the way actions are factorized and presented to our model . To make the model more robust to the number of object slots , an iterative object detection mechanism such as in MONet ( Burgess et al. , 2019 ) might be useful which can assign 'empty ' slots if all objects are explained by the model already , which would be interesting to explore in future work . [ Synthetic dataset to test the effect of no-op actions & other agents ] : This is a great suggestion . We have performed additional experiments on a variant of the block pushing ( 2D Shapes ) environment where a ) some actions have no effect ( no-op action ) , and b ) one block moves randomly and independent of agent actions . We find that adding a no-op action has little to no effect on the ability of the model to discover objects , learn the underlying grid structure and to generalize to new environment instances . In the other setting ( one out of the five objects moves randomly ) , the model correctly discovers representations for the other 4 objects , but learns a `` blank '' feature map for the randomly moving object -- prediction performance on the test set is negatively affected by the randomly moving object : 93.7 mean MRR ( in % ) instead of 100 for 10-step prediction . It would be interesting to extend the C-SWM model to explicitly handle uncertainty in environments in future work to address this gap in performance . We have posted an updated version of our manuscript . You can find a short summary of our changes in our top-level comment ."}], "0": {"review_id": "H1gax6VtDB-0", "review_text": "This paper aims to learn a structured latent space for images, which is made up of objects and their relations. The method works by (1) extracting object masks via a CNN, (2) turning those masks into feature vectors via an MLP, (3) estimating an action-conditioned delta for each feature via a GNN. Learning happens with contrastive losses, which ask that each feature+delta is close to the true next feature, and far away from other random possibilities. Experiments in simple synthetic environments (e.g., 2D geometric shapes moving on a black background) show encouraging results. This paper has a simple, well-motivated method. It is clearly written, and easy to understand. The evaluation is straightforward also: the paper merely shows that this model's nearest neighbors in featurespace are better than the nearest neighbors of World Model (2018) and PAIG (2019). Also, some visualizations indicate that for these simple directional manipulations (up/down/left/right motion), PCA compressions of the model's states have a clean lattice-like structure. It is impressive that the model discovers and segments objects so accurately. Perhaps this could actually be evaluated. However, I do not understand why results are so sensitive to the number of object slots (K). This seems like a severe limitation of the model, since in general we have no idea what value to set for this. Although I like the paper, I am not sure that there is sufficient evidence for the method being something useful. Yes, H@1 and MRR are high, but as the paper itself implies, the real goal is to improve performance (or, e.g., sample efficiency) in some downstream task. Given how simple these domains are, and the fact that data is collected with purely random exploration, it is difficult to imagine that there is any significant difference between the training set and the test set. For example, if you make 1000 episodes of 10 steps each in Space Invaders, you practically get 1000 copies of the same 10 frames. I worry that all the evaluation has shown so far is that this model can efficiently represent the state transitions that it has observed. The authors note that it was beneficial to only use the hinge on the negative energy term. This seems unusual, since a hinge on the positive term allows some slack, which intuitively makes the objective better-formulated. Can the authors please clarify this result, at least empirically? ", "rating": "8: Accept", "reply_text": "Thank you for your valuable feedback . Please find our responses to your questions and comments below . [ Number of object slots ( K ) ] : This is a very good question . Our results indicate that it is best to choose K based on validation set performance if there is no clear a-priori choice . Generalization to unseen environment instances likely not only depends on how well objects are discovered and represented , but also to what degree the learned transition model ( GNN ) on this structured latent space generalizes . Hence , it is difficult to a-priori predict which number of object slots would work well on a particular problem , unless the model has some built-in mechanism to assign `` empty '' slots , such as the iterative mechanism in MONet ( Burgess et al. , 2019 ) , which however relies on pixel-based losses . Despite the dependency on K , we still observe stronger generalization performance across a range of settings compared to unstructured baselines using pixel-based losses . [ Difference between training and test sets ] : This is a very good point and we indeed try to control for this issue . For the Atari benchmarks , we populate the experience buffer only after a certain number of frames ( which represent fully deterministic opponent transitions ) during which we take random actions . We have verified that no episode ( i.e. , the full 10-step sequence of states/actions ) in the test set exactly coincides with an episode from the training set for both Pong and Space Invaders , and hence performing well on this task requires some form of generalization . In the grid world / block pushing environments , there are around 6.4M possible environment configurations , and hence the train/test overlap can be expected to be small ( both train and test set contain 100k experience triples ) . For the physics simulation the state space is continuous and starting positions are sampled at random . We have made this clearer in the paper . [ Hinge loss ] : We performed a direct comparison between our loss and the triplet loss from TransE ( Bordes et al. , 2013 ) , i.e.with the hinge covering both the positive and the negative energy term . The table below summarizes mean MRR ( in % ) results ( from 4 runs with random init . ) on the 2D Shapes environment for hinge parameters $ \\gamma $ in { 1,5,10 } . + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Model | 1 Step | 5 Steps | 10 Steps | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | C-SWM ( default loss , $ \\gamma=1 $ ) | 100 | 100 | 100 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Full hinge , $ \\gamma=1 $ | 97.8 | 54.4 | 21.8 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Full hinge , $ \\gamma=5 $ | 98.8 | 65.7 | 26.8 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Full hinge , $ \\gamma=10 $ | 98.5 | 63.3 | 30.3 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + This setting performs significantly worse in In ( Bordes et al. , 2013 ) , the authors include this constraint to avoid pathologies in their loss function ( trivial minimization by growing the norms of the embeddings ) , which might be the cause for suboptimal performance in our case . We do not wish to constrain embeddings to a hypersphere in general , however , as this could affect how accurately we can learn certain structures ( e.g. , a hyperspherical latent space is likely less suitable for learning grid-structured representations and might make it more difficult for the transition model to generalize ) . Hyperspherical latent spaces could be useful , however , for learning rotational transformations . We have posted an updated version of our manuscript . You can find a short summary of our changes in our top-level comment ."}, "1": {"review_id": "H1gax6VtDB-1", "review_text": "This paper tackles the problem of learning an encoder and transition model of an environment, such that the representation learnt uses an object-centric representation which could favor compositionality and generalisation. This is trained using a contrastive max-margin loss, instead of a generative loss as previously explored. They do not consider RL or follow-up tasks leveraging these representations and transition models yet. They perform an extensive assessment of their model, with many ablations, on 2 gridworld environments, one physical domain, and on Atari. The paper is very well motivated, easy to follow, and most of its assumptions and decisions are sensible and well supported. They also provide interesting assessments and insights into the evaluation scheme of such transition models, which would be of interest to many practitioners of this field. Apart from some issues presented below, I feel that this work is of good quality and would recommend it for acceptance. 1. The model is introduced in a very clear way, and most decisions seem particularly fair. I found the presentation of the contrastive loss with margin to be clear, and the GraphNet is also well supported (although see question below). However, two choices are surprising to me and would deserve some clarification and more space in the main text, instead of the Appendix: a. Why does the object extractor only output a scalar mask? This was not extremely clear from reading the main text (and confused me when I first saw Figure 1 and 3a), but as explained in the Appendix, the CNN is forced to output a sigmoid logit between [0, 1] per object channel. This seems overly constraining to me, as this restricts the network to only output \u201c1 bit\u201d of information per \u201cobject\u201d. However, maybe being able to represent other factors of these objects might be necessary to make better predictions? This also requires the user to select the number of output channels precisely, or the model might fail. This is visible in the Atari results, where the \u201cobjectness\u201d is much less clear. Did you try allowing the encoder to output more features per objects? Obviously this would be more complicated and would place you closer to a setting similar to MONet (Burgess et al. 2019) or IODINE (Greff et al. 2019), but this might help a lot. b. It was hard to find the dimensionality D of the abstract representation $z_t$. It is only reported in the Appendix, and is set to $D=2$ for the 2D gridworld tasks and $D=4$ for Atari and the physics environments. These are quite small, and the fact that they exactly coincide with your assumed sufficient statistics is a bit unfortunate. What happens if D is larger? Could you find the optimal D by some means? 2. The GraphNet makes sense to me, but I wondered why you did not provide $a_t^j$ to $e_t^{(i, j)}$ as well? I could imagine situations where one would need the action to know if an interaction between two slots is required. 3. Similarly, the fact that the action was directly partitioned per object (except in Atari where it was replicated), seemed slightly odd. Would it still work if it was not directly pre-aligned for the network? I.e. provide $a_t$ as conditioning for the global() module of the GraphNet, and let the network learn which nodes/edges it actually affects. 4. In your multi-object contrastive loss, how is the mapping between slot k in $z_t$ and $\\tilde{z}_t$ performed? Do you assume that a given object (say the red cube) is placed in the same $k$ slot across different scenes/timesteps? This may actually be harder to enforce by the network than expected (e.g. with MONet, there is no such \u201cslot stability\u201d, see [1] for a discussion). 5. It was unclear to me if the \u201cgrid\u201d shown in Figure 3 (b) and 5 is \u201creal\u201d? I.e. are you exactly plotting your $z_t$ embeddings, and they happen to lie precisely along this grid? If yes, I feel this is a slightly stronger result as you currently present, given this means that the latent space has mirrored the transition dynamics in a rather impressive fashion. 6. Related to that point, I found Figure 3 b) to be slightly too hard to understand and parse. The mapping of the colours of the arrows is not provided, and the correspondence between \u201cwhat 3D object is actually moving where\u201d and \u201cwhich of the coloured circles correspond to which other cubes in the image\u201d is hard to do (especially given the arbitrary rotation). Could you add arrows/annotations to make this clearer? Alternatively, presenting this as a sequence might help: e.g. show the sequence of real 3D images, along with the trajectory it traces on the 2D grid. 7. Figure 4 a) was also hard to interpret. Seeing these learnt filters did not tell much, and I felt that you were trying too hard to impose meaning on these, or at least it wasn\u2019t clear to me what to take of them directly. I would have left this in the Appendix. Figure 4 b) on the other hand was great, and I would put more emphasis on it. 8. There are no details on how the actual test data used to generate Table 1 was created, and what \u201cunseen environment instances\u201d would correspond to. It would be good to add this to the Appendix, and point forward to it at the end of the first paragraph of Section 4.6, as if you are claiming that combinatorial generalization is being tested this should be made explicit. I found Table 1 to be great, complete, and easy to parse. 9. It would be quite interesting to discuss how your work relates to [1], as the principles and goals are quite similar. On a similar note, if you wanted to extend your 2D shape environment from a gridworld to a continuous one with more factors of variations, their Spriteworld environment [2] might be a good candidate. References: [1] Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher P. Burgess, Alexander Lerchner, \u201cCOBRA: Data-Efficient Model-Based RL through Unsupervised Object Discovery and Curiosity-Driven Exploration\u201d, 2019, https://arxiv.org/abs/1905.09275 [2] Nicholas Watters, Loic Matthey, Sebastian Borgeaud, Rishabh Kabra, Alexander Lerchner, \u201cSpriteworld: A Flexible, Configurable Reinforcement Learning Environment\u201d, https://github.com/deepmind/spriteworld/ ", "rating": "8: Accept", "reply_text": "Thank you for your extensive review and for your detailed feedback , this is greatly appreciated . Please find our responses to your questions and comments below . Q1a [ Scalar mask ] : This is indeed a very good point , which we initially did not try experimentally to avoid additional complexity . Our synthetic block pushing environment does not require more than a simple scalar mask , as the model only needs to encode object location . For more complex environments , it could indeed be beneficial to assign more than one output channel per object . Note that the object encoder ( which maps from scalar mask to object latent variable ) is an MLP with high-dimensional hidden representations , which allows the model to extract , e.g. , object position from its mask . We carried out additional experiments on the Space Invaders task with { 2 , 5 , 10 } output channels per object slot and we found no significant difference in MRR results compared to using just one output channel . We added these results to the appendix , and we also further clarified this architecture detail in the paper . Q1b [ Dimensionality of latent space ] : We ran additional experiments with D > 2 on the block pushing experiments ( 2D shapes ) and we found that we get the same results for D in { 4 , 8 , 16 } , i.e. , MRR=100 % ( on { 1,5,10 } prediction steps into the future ) and the latent representations lie on a close to perfect 2D grid that is randomly oriented in the higher-dimensional latent space . So it seems like the choice of D does not have a significant influence on results as long as it is not too small . We have improved clarity on this detail in the paper . Q2 [ Actions on edge messages ] : Thanks for this suggestion . We initially designed the model with the example of the synthetic block pushing environments in mind , where it is not necessary to condition the messages on the action , but this could indeed in principle be useful for the Atari game setting . Alternatively , one could perform multiple rounds of message passing as suggested in the paper . We ran an additional experiment on Space Invaders with K=5 object slots , where we also conditioned the edge update on the action , but the results were very similar to our original setting , where we only condition the node update on the action : 26.0\u00b14.1 MRR ( in % ) 10-step prediction for the original setting vs. 27.5\u00b12.3 MRR ( in % ) for the setting with actions included in the edge update . Q3 [ Learning action-to-node assignment ] : This is a very good point and something we have n't had the chance to try experimentally yet . Extending the GNN model with a global state in the line of GraphNets ( Battaglia et al. , 2018 ) would certainly be a good starting point for learning the action-to-node/-edge assignment automatically , but it would likely require some more changes to the model ( or to the way actions are encoded ) as object slots are fully exchangeable in the current architecture and one would need a way to break this symmetry . Q4 [ Slot stability ] : Our model is `` slot stable '' as objects are identified with a particular feature map of the CNN . In other words , we can assume that the same object always ends up in the same slot ( for a fixed set of model parameters ) . While this is convenient , this is of course a limitation as it does not allow for instance disambiguation ( e.g.two objects with the same appearance ) , which needs to be overcome in future work ( see `` Instance Disambiguation '' in Section 4.7 on Limitations ) . For encoders that are not `` slot stable '' , one could potentially use something like the Sinkhorn distance to compute the energy terms , but this could come with other challenges . Q5 [ Grid-structure of embedding space ] : Yes , the grid is `` real '' ! There is no post-processing done to get these plots -- we directly visualize the learned 2D embedding space and plot learned transitions as lines/edges . We found it indeed remarkable that the model learns to uncover this latent structure so precisely . We made this point clearer in the paper . Q6/7 [ Figure clarity ] : Thank you , this is very helpful feedback regarding Figures 3 and 4 . We have updated both figures in the paper to improve clarity . ( continued in the next comment due to character limitations )"}, "2": {"review_id": "H1gax6VtDB-2", "review_text": "The construction and learning of structured world models is an interesting area of research that could in principle enable better generalisation and interpretability for predictive models. The authors overcome the problem of using pixel-based losses (a common issue being reconstruction of small but potentially important objects) by using a contrastive latent space. The model otherwise makes use of a fixed number of object slots and a GNN transition model, similarly to prior approaches. The authors back up their method with nice results on 3D cubes and 3-body physics domains, and reasonable initial results on two Atari games, with ablations on the different components showing their contributions, so I would give this paper an accept. The comparisons to existing literature and related areas is very extensive, with interesting pointers to potential future work - particularly on the transition model and graph embeddings. As expected, the object-factorized action space appears to work well for generalisation, and could be extended/adapted, but setting a fixed number of objects K is a clearly fundamentally limiting hyperparameter, and so showing how the model performs under misspecification of this hyperparameter is useful to know for settings where this is known (2D shapes, 3D blocks, 3-body physics). The fact that K=1 is the best for Pong but K=5 is the best for Space Invaders raises at least two questions: can scaling K > 5 further improve performance on Space Invaders, and is it possible to make the model more robust to a greater-than-needed number of object slots? On a similar note, the data collection procedure for the Atari games seems to indicate that the model is quite sensitive to domains where actions rarely have an impact on the transition dynamics, or the interaction is more complex (e.g. other agents exist in the world) - coming up with a synthetic dataset where the importance of this can be quantified would again aid understanding of the authors' proposed method.", "rating": "8: Accept", "reply_text": "Thank you for your valuable feedback . Please find our responses to your questions and comments below . [ Number of object slots ] : We have carried out an analysis for the 3-body physics environment with misspecification of the number of object slots ( all other parameters are left the same ) , see results table for mean MRR ( in % ) results over 4 model runs below . The results show that K=1 is not sufficient for good generalization on the 3-body system , whereas K=5 performs comparable or slightly better than K=3 ( note that there is some variance in between runs ) . Looking only at the best 10-step prediction result out of 4 runs , we have 95.4 ( for K=3 ) vs. 93.3 ( for K=5 ) . + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | Model | 1 Step | 5 Steps | 10 Steps | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | K=1 | 97.5 | 71.5 | 40.9 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | K=3 ( default ) | 100 | 98.5 | 85.2 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + | K=5 | 100 | 98.7 | 91.0 | + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + In terms of increasing K beyond 5 on the Space Invaders benchmark : We have carried out an additional experiment with K=7 with the following mean MRR ( in % ) results : 71.5 ( 1 step ) , 28.3 ( 5 steps ) , 22.7 ( 10 steps ) -- i.e. , worse in long-term prediction than for K=5 ( best setting ) but comparable to K=5 in the 1 step prediction setting . Note that for the block pushing environments , we can not change the number of object slots without changing the way actions are factorized and presented to our model . To make the model more robust to the number of object slots , an iterative object detection mechanism such as in MONet ( Burgess et al. , 2019 ) might be useful which can assign 'empty ' slots if all objects are explained by the model already , which would be interesting to explore in future work . [ Synthetic dataset to test the effect of no-op actions & other agents ] : This is a great suggestion . We have performed additional experiments on a variant of the block pushing ( 2D Shapes ) environment where a ) some actions have no effect ( no-op action ) , and b ) one block moves randomly and independent of agent actions . We find that adding a no-op action has little to no effect on the ability of the model to discover objects , learn the underlying grid structure and to generalize to new environment instances . In the other setting ( one out of the five objects moves randomly ) , the model correctly discovers representations for the other 4 objects , but learns a `` blank '' feature map for the randomly moving object -- prediction performance on the test set is negatively affected by the randomly moving object : 93.7 mean MRR ( in % ) instead of 100 for 10-step prediction . It would be interesting to extend the C-SWM model to explicitly handle uncertainty in environments in future work to address this gap in performance . We have posted an updated version of our manuscript . You can find a short summary of our changes in our top-level comment ."}}