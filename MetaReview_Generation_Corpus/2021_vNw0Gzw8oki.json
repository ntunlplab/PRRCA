{"year": "2021", "forum": "vNw0Gzw8oki", "title": "Physics Informed Deep Kernel Learning", "decision": "Reject", "meta_review": "The paper presents a framework for incorporating physics knowledge (through, potentially incomplete, differential equations) into the deep kernel learning approach of Wilson et al. The reviewers found the paper addresses an important problem and presents good results.  However, one of the main issues raised by R1 is that, although the proposed method can be applied to broader settings such as that of incomplete differential equations, there are still regimes where the comparison is not only possible but perhaps insightful. An example baseline is the work of Lorenzi and Filippone, \u201cConstraining the Dynamics of Deep Probabilistic Models\u201d (ICML, 2018). Another critical issue, raised by R4, is the insufficient clarity in the presentation. Many of the concerns raised by this reviewer were clarified in the discussion and I thank the authors for their engagement. However, the AC believes some of the points raised by R4 in this regard were left unaddressed in the paper and the manuscript does indeed require at least one more iteration.\n\nThe format violation concerns raised during the reviewing process did not affect the decision on this paper, as the PCs confirmed that they did not meet the bar for desk rejection and recommended to assess the paper on its technical merits.", "reviews": [{"review_id": "vNw0Gzw8oki-0", "review_text": "Post-discussion update : The authors have clarified their work considerably , and I believe the work is probably correct . However , the paper still suffers from poor presentation and poorly-motivated or justified modelling choices . The current version of the paper has not been updated , and all below issues thus stand . The paper overall presents a good idea , but I believe the authors made poor modelling choices , which led the kludgy math . - The paper proposes to combine deep kernel learning ( DKL ) with PDE/ODE prior knowledge for learning spatiotemporal systems . The idea is sound and sensible , although it represents an incremental combination of two existing techniques . The differential assumption clearly improves in spatiotemporal experiments , which also motivates the idea . The paper has unfortunately three major mathematical errors . First , the very first equation of the method ( eq 4 ) is already incorrect : g ( x ) is not a function of input \u201c x \u201d but instead it \u2019 s a function of solution \u201c f \u201d . The paper itself acknowledges this by giving series of examples which all are functions of \u201c f \u201d . The following GP prior for g ( x ) is then placed on incorrect inputs and seems misguided or at least insufficient to model the differential . Intuitively this is also easy to see : the differential of the solution is obviously not just a function of space and time ( but of solution as well ) . Second , the eq 6 states that a non-linear differential of a GP is some other Gaussian process . This is incorrect : non-linear transforms of a Gaussian process does not retain Gaussianity . Since this is a central definition of the paper , the whole method is likely incorrect . Third , the paper introduces a bizarre concept of constant zero vectors as random variables , ie . p ( 0|g ) .This is clearly wrong , and the probabilistic model is then wrong as well . While this could be easily fixed , the model is an example of GP-matching ( which has known pathologies ) , and this has been extensively studied by many authors ( eg.Wenk \u2019 19 , Wenk \u2019 18 , Gorbach \u2019 17 , MacDonalds \u2019 15 ) . Given these obvious errors , the paper needs a major revision . Technical comments : o Eq 4 should be g ( f , x ) , since later the \\varphi is a function of f and its x-derivatives . Currently none of the examples ( eg.burger ) follow eq 4 . Also eq6 is also wrong with same argument o Please define ( mathematically ) the tackled problem and the problem domain . The paper starts by discussing classification , but at sec 3 the context suddenly changes into PDEs without the reader being informed about this . o The paragraph \u201c to incorporate .. \u201d is difficult to follow since its technical but does not open up the math yet . It would help to write this in more conceptual way o It would greatly help the reader understand the method to include the sup-fig1 in the main paper o It seems that both f and g are assumed to be separate GPs . This is unclear from text , please clarify o eq7 is strange , since it defines a dirac between a random variable g and a sample of h. This is nonsensical . o The 0-sampling is obviously wrong and unnecessary . Double priors are perfectly fine in Bayesian modelling , and eq9 could be defined without the 0-stuff . The double priors are called product of expert priors , see eg . MacDonalds'15 or Wenk \u2019 19 . They do have their own pathologies , but these papers discuss them extensively .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We are astonished that the reviewer totally misunderstood our paper , and left baseless and wrong comments . C : comments ; R : response . C1 : the very first equation of the method ( eq 4 ) is already incorrect : g ( x ) is not a function of input \u201c x \u201d but instead it \u2019 s a function of solution `` f '' ; R1 : First , g ( x ) is a source term ( see the 2nd line under eq 4 ) . In the literature of differential equations , the source term usually represents external influence on the physical system ( described by \\psi [ f ] ) . Therefore , in general , g should be considered as a function of x , rather than assume a nested structure including f. Note that this is NOT a definition of ODE . Our work is NOT restricted to ODE either . Second , even we put an extra assumption that g is also a function of f , i.e. , g ( f , x ) , because f is a function of x , g is in essence still a function of x . There is NOT any conceptual and mathematical error . Third , the prior works , including Graepel03 , Raissi17 , and latent force models by Lawrence07 ( see Sec.5 related work ) , all assume the same general form as in ( 4 ) . The only difference is that they further assume \\psi is linear , while ours do not have such restrictions . Do you imply all these pioneer works are wrong ? C2 : The paper itself acknowledges this by giving series of examples which all are functions of \u201c f \u201d R2 : This is a misunderstanding . The definition of \\psi only gives how we model the physical system . It has nothing to do with the definition of the extra source term . In general , all the equations , should have the from \\psi [ f ] -g = 0 . We just move g to the right . In the ideal case , g can be constant 0 this is how most textbooks introduce various equations . But in practice , this is rarely true , because no system is completely closed . C3 : the eq 6 states that a non-linear differential of a GP is some other Gaussian process . This is incorrect : non-linear transforms of a Gaussian process does not retain Gaussianity . Since this is a central definition of the paper , the whole method is likely incorrect . R3 : First , we NEVER claim a non-linear differential of a GP is some other GP \u2019 \u2019 , neither does Eq6 reflect it . Eq6 only states given the posterior form of f , how we obtain g based on which we construct the conditional prior of \\textbf { g } in Eq7 , which obviously is NOT a GP . Second , in our modeling , we NEVER place a GP prior over g that will cause the double prior problem , and result in an INVALID probabilistic model . We use the symmetric property of Gaussian , to instead sample a set of virtual observations 0 given \\textbf { g } , see Eq8 and the surrounding text . This is equivalent to a GP prior only in COMPUTATION , rather than from modeling ! This is also our contribution we want to regularize the learning of g ( and then f ) with a simpler prior , i.e. , GP , but still obey the Bayes \u2019 rule to ensure proper , well-calibrated uncertainty quantification . Our model fulfills this effect in computation but in a correct probabilistic framework . C4 : the paper introduces a bizarre concept of constant zero vectors as random variables , ie . p ( 0|g ) .This is clearly wrong , and the probabilistic model is then wrong as well \u201d \u201c Double priors are perfectly fine in Bayesian modelling , and eq9 could be defined without the 0-stuff R4 : First , double priors will lead to an improper Bayesian model with an incorrect joint probability distribution . It might be fine if we just want point estimations and predictions . However , we aim to also improve uncertainty quantification in the posteriors . If the joint distribution is conceptually incorrect , how to justify the posterior computed based on the joint distribution ? Second , we have clearly mentioned that we introduce a set of virtual observation to build a valid probabilistic model ( see Sec1 & Sec3.1 ) . This strategy is originally introduced in the Bayesian hybrid framework to principally combine a conditional and generative model ( see Lasserre06 cited in our paper ) . The idea of virtual observations has also been used in Bayesian joint individual and group variable selection [ 1,2 ] and learning monotonic functions with GPs [ 3 ] . We do NOT see anything that is `` `` Bizarre and clearly wrong '' . Third , regarding the product of experts ( PoE ) , please see MacDonald \u2019 s15 at Sec3 end ( cited in Sec5 of our paper ) , they make a clear comment about the advantage of an alternative model GPODE over the PoE based model AGM : `` Conceptually , the GPODE is a proper probabilistic generative model , which can be consistently represented by a directed acyclic graph ( DAG ) \u201d . This is consistent with the advantage claimed in our paper . [ 1 ] Feng , Y , and Qi , Y . `` EigenNet : A Bayesian hybrid of generative and conditional models for sparse learning . '' NIPS , 2011 . [ 2 ] Zhe , S , and et . al.Joint network and node selection for pathway-based genomic data analysis . Bioinformatics ( 2013 ) , 29 ( 16 ) , 1987-1996 . [ 3 ] Riihim\u00e4ki , J , and Vehtari , A . `` Gaussian processes with monotonicity information . '' AISTATS , 2010 ."}, {"review_id": "vNw0Gzw8oki-1", "review_text": "# # # Summary of my understanding The authors address the problem of function estimation given noisy observations of the function 's values . The estimation is done in a non-parametric manner as posterior inference of Gaussian processes . The authors ' proposal is to incorporate physics knowledge into this process . The knowledge here refers to a differential equation on the function to be estimated ( $ f $ ) , and it may include unknown parameters and an unknown external force term $ g $ . They derive a joint distribution of 1 ) observation of $ f $ , i.e. , $ y $ , 2 ) `` virtual '' observations $ 0 $ of $ g $ , 3 ) latent variable $ Z $ for latent force $ g $ , 4 ) randomness between $ f $ and $ g $ , and 5 ) values of $ g $ . Afterward , they propose to perform a collapsed inference based on a lower bound of the log marginal likelihood ( of observations $ y $ and virtual observations $ 0 $ ) . # # # Evaluation The problem setting is clear . The proposed method is technically sound , and the experiments are enough convincing to show its superiority to baselines . Regardless of the common points with the latent force models [ Alvarez+ 09 ] in terms of the problem setting , this paper proposes a somewhat new technique to perform inference under the presence of differential equation-based constraints on a target function . I think this paper is a sound work . # # # Note I think a concern lies in the paper 's clear violation of the formatting instruction of ICLR 2021 . Especially , the too narrow margins before and after headings seem to compress the main text , which might seem quite unfair . I delegate judgment on this regard to the chairs and for now , I decided the rating ignoring this matter .", "rating": "7: Good paper, accept", "reply_text": "C : comments ; R : response C1 : two narrow margins before and headings . R1 : Thanks for pointing out this issue . We will definitely compress the text and make the margins better fit for the original template ."}, {"review_id": "vNw0Gzw8oki-2", "review_text": "This work proposes a deep Gaussian Process ( GP ) framework for data modeling informed by dynamical systems . The analogous to the one of gradient matching , where a GP regression problem is penalised by constraints taking the form of differential equations acting on the GP itself . This study merges this framework to the scalable deep-GP framework of Wilson et al , and proposes an approximated inference setting in which the problem can be optimised through stochastic variational inference . The proposed method is tested in several experimental scenarios and compared to standard kernel-based methods , and to the Latent Force Model of Alvarez and colleagues . The results show promising performances in terms of prediction and stability of extrapolation . The proposed methodology contributes to the domain of gradient-matching and extends the classical approaches to allow for scalability in deep models . In this sense , the comparison with respect to the state of the art appears weak . The comparisons proposed in the study are with respect to either shallow models , or deep-models not allowing the integration of physics-informed contraints . Recent works ( e.g . [ 1,2,3,4 ] ) could provide a fairer benchmark for the proposed approach . In this sense , the feeling is that proposed methodology largely overlaps with these more recent studies , for example for what concerns the use of deep models and variational inference schemes . In particular , the idea of soft-regularisation of deep-GP models has been already explored in [ 2 ] , and the authors may want to compare the method with respect to this approach . It is not clear whether the parameters of the dynamical systems in the term h ( Z , \\epsilon ) of ( 12 ) are inferred . If this is the case , the ability of the framework in estimating the systems \u2019 should be assessed and compared to other moment matching approaches . This aspect is overlooked in the paper , although it is quite relevant for interpretability purposes .", "rating": "5: Marginally below acceptance threshold", "reply_text": "C : comment ; R : response C1 : \u201c This work proposes a deep Gaussian Process ( GP ) framework for data modeling informed by dynamical systems . \u2026 In this sense , the comparison with respect to the state of the art appears weak\u2026 Recent works ( e.g . [ 1,2,3,4 ] ) could provide a fairer benchmark for the proposed approach \u201d R1 : Actually , our model is not a deep GP as originally proposed in Damianou13 . We did not stack many GPs in several layers . We only have one GP , but the kernel is constructed from a ( deep ) neural network . We aim to use physics to regularize the estimation of the deep kernels so as to enhance the GP learning . That \u2019 s why in the experiments , we only compare with state-of-the-art single GP approaches . Incorporating physics into deep GPs is definitely promising and we will consider it as our future research plan . Second , while our evaluation includes ODEs , our model is not restricted by being informed by dynamic systems . Eq . ( 4 ) is general and NOT necessarily an ODE ; it can be any PDE with or without time variables . See Sec.6.2 metal pollution prediction where we actually did not use any time information . Third , from the review , we can not find the references numbered as [ 1,2,3 , 4 ] . We will appreciate if the reviewer could list the corresponding papers . We will definitely double check . C2 : \u201c It is not clear whether the parameters of the dynamical systems in the term h ( Z , \\epsilon ) of ( 12 ) are inferred . If this is the case , the ability of the framework in estimating the systems \u2019 should be assessed and compared to other moment matching approaches \u201d R2 : Great question . First , as mentioned in Sec.3.1 , the 3rd line under Eq . ( 4 ) , we allow \\psi [ ] to include unknown parameters . Therefore , h couples the deep kernels , the differential operators , and unknown parameters in the differential equation . The parameters will be jointly estimated in the training . We will emphasize this point in our paper . Second , it is a great idea to assess these learned parameters . We will supplement the assessment . However , the goal of our paper is NOT system identification ( via GPs ) . Rather , we aim to use incomplete differential equations to improve deep-kernel GP when learning with scarce data , in both prediction accuracy ( esp.extrapolation ) and uncertainty quantification . On two synthetic datasets and four real-world applications , our method has clearly shown improvement in both aspects . Therefore , we believe the advantage of our method has been well demonstrated . While many excellent works ( e.g. , gradient matching , see the references in Sec.5 ) were proposed to ( accurately ) recover the equation parameters , they demand we have sufficient samples in the domain and restrict to special type of equations ( typically ODEs ) . Most of them also require the equation form is completely specified . The problem setting is hence very different from ours , where the data is scarce , the equation is arbitrary , and include unknown source terms ( functions ) ."}, {"review_id": "vNw0Gzw8oki-3", "review_text": "The paper is clearly written , technically sound and innovative . # # # Impact : The paper is bringing an important contribution in the domain of Physics-Informed Machine Learning . It proposes an interesting and technically sounds ( and not obvious ) way to combine multiple successful components of recent literature in the field . # # # Clarity and technical soundness : The paper is clear , technically sound and manipulates tools in an advanced way . It would be useful to provide more intuition and high-level interpretation on the most technical aspects of Deep Kernel inference and on the usage of ELBO methods . That would go at the benefit of understanding for the non-specialists of Kernel-based learning who are interested in Physics Informed ML . # # # Results : The results are extensive , are exploiting both simulation-type data and real-world data . The benchmark used for comparison are relevant . # # # Applicability : It would be interesting to have a more high-level interpretation and analysis of the applicability of the method to 3D simulation data . In 4.2 , it was not clear to me what N and M stand for . Could you clarify it and provide a more high-level analysis with it too ?", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "C : comment ; R : response C1 : \u201c In 4.2 , it was not clear to me what N and M stand for \u201d R1 : N is the number of training examples and M is the number of latent inputs Z . We will polish our paper to be clearer . C2 : \u201c provide more intuition and high-level interpretation on the most technical aspects of Deep Kernel inference and on the usage of ELBO methods \u201d R2 : Great suggestion . We will definitely polish our paper and provide more intuition and interpretation ."}], "0": {"review_id": "vNw0Gzw8oki-0", "review_text": "Post-discussion update : The authors have clarified their work considerably , and I believe the work is probably correct . However , the paper still suffers from poor presentation and poorly-motivated or justified modelling choices . The current version of the paper has not been updated , and all below issues thus stand . The paper overall presents a good idea , but I believe the authors made poor modelling choices , which led the kludgy math . - The paper proposes to combine deep kernel learning ( DKL ) with PDE/ODE prior knowledge for learning spatiotemporal systems . The idea is sound and sensible , although it represents an incremental combination of two existing techniques . The differential assumption clearly improves in spatiotemporal experiments , which also motivates the idea . The paper has unfortunately three major mathematical errors . First , the very first equation of the method ( eq 4 ) is already incorrect : g ( x ) is not a function of input \u201c x \u201d but instead it \u2019 s a function of solution \u201c f \u201d . The paper itself acknowledges this by giving series of examples which all are functions of \u201c f \u201d . The following GP prior for g ( x ) is then placed on incorrect inputs and seems misguided or at least insufficient to model the differential . Intuitively this is also easy to see : the differential of the solution is obviously not just a function of space and time ( but of solution as well ) . Second , the eq 6 states that a non-linear differential of a GP is some other Gaussian process . This is incorrect : non-linear transforms of a Gaussian process does not retain Gaussianity . Since this is a central definition of the paper , the whole method is likely incorrect . Third , the paper introduces a bizarre concept of constant zero vectors as random variables , ie . p ( 0|g ) .This is clearly wrong , and the probabilistic model is then wrong as well . While this could be easily fixed , the model is an example of GP-matching ( which has known pathologies ) , and this has been extensively studied by many authors ( eg.Wenk \u2019 19 , Wenk \u2019 18 , Gorbach \u2019 17 , MacDonalds \u2019 15 ) . Given these obvious errors , the paper needs a major revision . Technical comments : o Eq 4 should be g ( f , x ) , since later the \\varphi is a function of f and its x-derivatives . Currently none of the examples ( eg.burger ) follow eq 4 . Also eq6 is also wrong with same argument o Please define ( mathematically ) the tackled problem and the problem domain . The paper starts by discussing classification , but at sec 3 the context suddenly changes into PDEs without the reader being informed about this . o The paragraph \u201c to incorporate .. \u201d is difficult to follow since its technical but does not open up the math yet . It would help to write this in more conceptual way o It would greatly help the reader understand the method to include the sup-fig1 in the main paper o It seems that both f and g are assumed to be separate GPs . This is unclear from text , please clarify o eq7 is strange , since it defines a dirac between a random variable g and a sample of h. This is nonsensical . o The 0-sampling is obviously wrong and unnecessary . Double priors are perfectly fine in Bayesian modelling , and eq9 could be defined without the 0-stuff . The double priors are called product of expert priors , see eg . MacDonalds'15 or Wenk \u2019 19 . They do have their own pathologies , but these papers discuss them extensively .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We are astonished that the reviewer totally misunderstood our paper , and left baseless and wrong comments . C : comments ; R : response . C1 : the very first equation of the method ( eq 4 ) is already incorrect : g ( x ) is not a function of input \u201c x \u201d but instead it \u2019 s a function of solution `` f '' ; R1 : First , g ( x ) is a source term ( see the 2nd line under eq 4 ) . In the literature of differential equations , the source term usually represents external influence on the physical system ( described by \\psi [ f ] ) . Therefore , in general , g should be considered as a function of x , rather than assume a nested structure including f. Note that this is NOT a definition of ODE . Our work is NOT restricted to ODE either . Second , even we put an extra assumption that g is also a function of f , i.e. , g ( f , x ) , because f is a function of x , g is in essence still a function of x . There is NOT any conceptual and mathematical error . Third , the prior works , including Graepel03 , Raissi17 , and latent force models by Lawrence07 ( see Sec.5 related work ) , all assume the same general form as in ( 4 ) . The only difference is that they further assume \\psi is linear , while ours do not have such restrictions . Do you imply all these pioneer works are wrong ? C2 : The paper itself acknowledges this by giving series of examples which all are functions of \u201c f \u201d R2 : This is a misunderstanding . The definition of \\psi only gives how we model the physical system . It has nothing to do with the definition of the extra source term . In general , all the equations , should have the from \\psi [ f ] -g = 0 . We just move g to the right . In the ideal case , g can be constant 0 this is how most textbooks introduce various equations . But in practice , this is rarely true , because no system is completely closed . C3 : the eq 6 states that a non-linear differential of a GP is some other Gaussian process . This is incorrect : non-linear transforms of a Gaussian process does not retain Gaussianity . Since this is a central definition of the paper , the whole method is likely incorrect . R3 : First , we NEVER claim a non-linear differential of a GP is some other GP \u2019 \u2019 , neither does Eq6 reflect it . Eq6 only states given the posterior form of f , how we obtain g based on which we construct the conditional prior of \\textbf { g } in Eq7 , which obviously is NOT a GP . Second , in our modeling , we NEVER place a GP prior over g that will cause the double prior problem , and result in an INVALID probabilistic model . We use the symmetric property of Gaussian , to instead sample a set of virtual observations 0 given \\textbf { g } , see Eq8 and the surrounding text . This is equivalent to a GP prior only in COMPUTATION , rather than from modeling ! This is also our contribution we want to regularize the learning of g ( and then f ) with a simpler prior , i.e. , GP , but still obey the Bayes \u2019 rule to ensure proper , well-calibrated uncertainty quantification . Our model fulfills this effect in computation but in a correct probabilistic framework . C4 : the paper introduces a bizarre concept of constant zero vectors as random variables , ie . p ( 0|g ) .This is clearly wrong , and the probabilistic model is then wrong as well \u201d \u201c Double priors are perfectly fine in Bayesian modelling , and eq9 could be defined without the 0-stuff R4 : First , double priors will lead to an improper Bayesian model with an incorrect joint probability distribution . It might be fine if we just want point estimations and predictions . However , we aim to also improve uncertainty quantification in the posteriors . If the joint distribution is conceptually incorrect , how to justify the posterior computed based on the joint distribution ? Second , we have clearly mentioned that we introduce a set of virtual observation to build a valid probabilistic model ( see Sec1 & Sec3.1 ) . This strategy is originally introduced in the Bayesian hybrid framework to principally combine a conditional and generative model ( see Lasserre06 cited in our paper ) . The idea of virtual observations has also been used in Bayesian joint individual and group variable selection [ 1,2 ] and learning monotonic functions with GPs [ 3 ] . We do NOT see anything that is `` `` Bizarre and clearly wrong '' . Third , regarding the product of experts ( PoE ) , please see MacDonald \u2019 s15 at Sec3 end ( cited in Sec5 of our paper ) , they make a clear comment about the advantage of an alternative model GPODE over the PoE based model AGM : `` Conceptually , the GPODE is a proper probabilistic generative model , which can be consistently represented by a directed acyclic graph ( DAG ) \u201d . This is consistent with the advantage claimed in our paper . [ 1 ] Feng , Y , and Qi , Y . `` EigenNet : A Bayesian hybrid of generative and conditional models for sparse learning . '' NIPS , 2011 . [ 2 ] Zhe , S , and et . al.Joint network and node selection for pathway-based genomic data analysis . Bioinformatics ( 2013 ) , 29 ( 16 ) , 1987-1996 . [ 3 ] Riihim\u00e4ki , J , and Vehtari , A . `` Gaussian processes with monotonicity information . '' AISTATS , 2010 ."}, "1": {"review_id": "vNw0Gzw8oki-1", "review_text": "# # # Summary of my understanding The authors address the problem of function estimation given noisy observations of the function 's values . The estimation is done in a non-parametric manner as posterior inference of Gaussian processes . The authors ' proposal is to incorporate physics knowledge into this process . The knowledge here refers to a differential equation on the function to be estimated ( $ f $ ) , and it may include unknown parameters and an unknown external force term $ g $ . They derive a joint distribution of 1 ) observation of $ f $ , i.e. , $ y $ , 2 ) `` virtual '' observations $ 0 $ of $ g $ , 3 ) latent variable $ Z $ for latent force $ g $ , 4 ) randomness between $ f $ and $ g $ , and 5 ) values of $ g $ . Afterward , they propose to perform a collapsed inference based on a lower bound of the log marginal likelihood ( of observations $ y $ and virtual observations $ 0 $ ) . # # # Evaluation The problem setting is clear . The proposed method is technically sound , and the experiments are enough convincing to show its superiority to baselines . Regardless of the common points with the latent force models [ Alvarez+ 09 ] in terms of the problem setting , this paper proposes a somewhat new technique to perform inference under the presence of differential equation-based constraints on a target function . I think this paper is a sound work . # # # Note I think a concern lies in the paper 's clear violation of the formatting instruction of ICLR 2021 . Especially , the too narrow margins before and after headings seem to compress the main text , which might seem quite unfair . I delegate judgment on this regard to the chairs and for now , I decided the rating ignoring this matter .", "rating": "7: Good paper, accept", "reply_text": "C : comments ; R : response C1 : two narrow margins before and headings . R1 : Thanks for pointing out this issue . We will definitely compress the text and make the margins better fit for the original template ."}, "2": {"review_id": "vNw0Gzw8oki-2", "review_text": "This work proposes a deep Gaussian Process ( GP ) framework for data modeling informed by dynamical systems . The analogous to the one of gradient matching , where a GP regression problem is penalised by constraints taking the form of differential equations acting on the GP itself . This study merges this framework to the scalable deep-GP framework of Wilson et al , and proposes an approximated inference setting in which the problem can be optimised through stochastic variational inference . The proposed method is tested in several experimental scenarios and compared to standard kernel-based methods , and to the Latent Force Model of Alvarez and colleagues . The results show promising performances in terms of prediction and stability of extrapolation . The proposed methodology contributes to the domain of gradient-matching and extends the classical approaches to allow for scalability in deep models . In this sense , the comparison with respect to the state of the art appears weak . The comparisons proposed in the study are with respect to either shallow models , or deep-models not allowing the integration of physics-informed contraints . Recent works ( e.g . [ 1,2,3,4 ] ) could provide a fairer benchmark for the proposed approach . In this sense , the feeling is that proposed methodology largely overlaps with these more recent studies , for example for what concerns the use of deep models and variational inference schemes . In particular , the idea of soft-regularisation of deep-GP models has been already explored in [ 2 ] , and the authors may want to compare the method with respect to this approach . It is not clear whether the parameters of the dynamical systems in the term h ( Z , \\epsilon ) of ( 12 ) are inferred . If this is the case , the ability of the framework in estimating the systems \u2019 should be assessed and compared to other moment matching approaches . This aspect is overlooked in the paper , although it is quite relevant for interpretability purposes .", "rating": "5: Marginally below acceptance threshold", "reply_text": "C : comment ; R : response C1 : \u201c This work proposes a deep Gaussian Process ( GP ) framework for data modeling informed by dynamical systems . \u2026 In this sense , the comparison with respect to the state of the art appears weak\u2026 Recent works ( e.g . [ 1,2,3,4 ] ) could provide a fairer benchmark for the proposed approach \u201d R1 : Actually , our model is not a deep GP as originally proposed in Damianou13 . We did not stack many GPs in several layers . We only have one GP , but the kernel is constructed from a ( deep ) neural network . We aim to use physics to regularize the estimation of the deep kernels so as to enhance the GP learning . That \u2019 s why in the experiments , we only compare with state-of-the-art single GP approaches . Incorporating physics into deep GPs is definitely promising and we will consider it as our future research plan . Second , while our evaluation includes ODEs , our model is not restricted by being informed by dynamic systems . Eq . ( 4 ) is general and NOT necessarily an ODE ; it can be any PDE with or without time variables . See Sec.6.2 metal pollution prediction where we actually did not use any time information . Third , from the review , we can not find the references numbered as [ 1,2,3 , 4 ] . We will appreciate if the reviewer could list the corresponding papers . We will definitely double check . C2 : \u201c It is not clear whether the parameters of the dynamical systems in the term h ( Z , \\epsilon ) of ( 12 ) are inferred . If this is the case , the ability of the framework in estimating the systems \u2019 should be assessed and compared to other moment matching approaches \u201d R2 : Great question . First , as mentioned in Sec.3.1 , the 3rd line under Eq . ( 4 ) , we allow \\psi [ ] to include unknown parameters . Therefore , h couples the deep kernels , the differential operators , and unknown parameters in the differential equation . The parameters will be jointly estimated in the training . We will emphasize this point in our paper . Second , it is a great idea to assess these learned parameters . We will supplement the assessment . However , the goal of our paper is NOT system identification ( via GPs ) . Rather , we aim to use incomplete differential equations to improve deep-kernel GP when learning with scarce data , in both prediction accuracy ( esp.extrapolation ) and uncertainty quantification . On two synthetic datasets and four real-world applications , our method has clearly shown improvement in both aspects . Therefore , we believe the advantage of our method has been well demonstrated . While many excellent works ( e.g. , gradient matching , see the references in Sec.5 ) were proposed to ( accurately ) recover the equation parameters , they demand we have sufficient samples in the domain and restrict to special type of equations ( typically ODEs ) . Most of them also require the equation form is completely specified . The problem setting is hence very different from ours , where the data is scarce , the equation is arbitrary , and include unknown source terms ( functions ) ."}, "3": {"review_id": "vNw0Gzw8oki-3", "review_text": "The paper is clearly written , technically sound and innovative . # # # Impact : The paper is bringing an important contribution in the domain of Physics-Informed Machine Learning . It proposes an interesting and technically sounds ( and not obvious ) way to combine multiple successful components of recent literature in the field . # # # Clarity and technical soundness : The paper is clear , technically sound and manipulates tools in an advanced way . It would be useful to provide more intuition and high-level interpretation on the most technical aspects of Deep Kernel inference and on the usage of ELBO methods . That would go at the benefit of understanding for the non-specialists of Kernel-based learning who are interested in Physics Informed ML . # # # Results : The results are extensive , are exploiting both simulation-type data and real-world data . The benchmark used for comparison are relevant . # # # Applicability : It would be interesting to have a more high-level interpretation and analysis of the applicability of the method to 3D simulation data . In 4.2 , it was not clear to me what N and M stand for . Could you clarify it and provide a more high-level analysis with it too ?", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "C : comment ; R : response C1 : \u201c In 4.2 , it was not clear to me what N and M stand for \u201d R1 : N is the number of training examples and M is the number of latent inputs Z . We will polish our paper to be clearer . C2 : \u201c provide more intuition and high-level interpretation on the most technical aspects of Deep Kernel inference and on the usage of ELBO methods \u201d R2 : Great suggestion . We will definitely polish our paper and provide more intuition and interpretation ."}}