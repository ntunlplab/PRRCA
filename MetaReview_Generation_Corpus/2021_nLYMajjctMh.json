{"year": "2021", "forum": "nLYMajjctMh", "title": "Federated Learning of a Mixture of Global and Local Models", "decision": "Reject", "meta_review": "The paper studies an elegant formulation of personalized federated learning, which balances between a global model and locally trained models. It then analyzes algorithm variants inspired by local update SGD in this setting. The problem formulation using the explicit trade-off between model differences and global objective was received positively, as mentioned by R1 and R2. After a productive discussion including the authors and reviewers, unfortunately consensus remained that the paper remains below the bar in the current form. The contributions are not presented clearly enough in context, the set of competing algorithms (including e.g. EA-SGD, ADMM, SVRG/Scaffold for the heterogeneous setting, and others) needs to be clarified in particular for the modified formulation compared to traditional FL, since objectives are different. Some smaller concerns also remained on the applicability to more general non-convex settings in practice. We hope the feedback helps to strengthen the paper for a future occasion.", "reviews": [{"review_id": "nLYMajjctMh-0", "review_text": "# # Summary This paper proposed a new formulation of federated learning , which balances between traditional global model and purely local models . The authors discuss the advantages of the new formulation and propose a new algorithm L2GD to solve the problem . They theoretically analyzed the communication complexity of L2GD under stronly-convex settings and propose several algorithmic variants . # # Pros 1 . The authors developed a set of algorithms based on L2GD and provided theoretical analysis . The efforts are appreciated . # # Cons Unfortunately , most contributions of this paper does n't make sense to me . I have concerns regarding novelty and correctness of the statements made by this paper . Detailed comments are listed as follows . * * New formulation * * 1 . In section 2 , the authors claim that `` we prove that the optimal local models converge to the traditional global model characterized by ( 1 ) at the rate $ O ( 1/\\lambda ) $ '' . However , I did n't find any discussions or proof around this statement in following sections . From my understanding , there should be some equations showing how $ x ( \\lambda ) -x ( \\infty ) $ or $ f ( x ( \\lambda ) ) -f ( x ( \\infty ) ) $ changes over $ \\lambda $ . But I did n't find any . 2.In experiments , the authors did n't compare the proposed formulation with the original formulation . How much benefits one can obtain from the new formulation is unclear , making this paper to be incomplete . 3.The formulation is not new . A nearly same formulation can be found in [ 1 ] . The authors did n't notice this paper . Since [ 1 ] also proposed an algorithm EASGD to solve the new formulation , the authors are supposed to compare L2GD with the algorithm in [ 1 ] . * * New algorithm : Loopless LGD * * 1 . The algorithm is also not new . An extremely similar algorithm has appeared in [ 2 ] . By some re-parameterization , I believe they are equivalent to each other . The authors missed this reference . They should justify the differences and compare the results . 2.It is unclear why L2GD uses random local steps instead of a fixed one . Or what are the benefits of the randomized one ? * * Convergence theory * * 1 . The conclusions of convergence analysis are questionable . In particular , when obtaining the convergence rate , it seems that the authors completely ignore the second term in ( 9 ) . In general , people use $ f ( x ) -f ( x_ * ) < \\epsilon $ or $ \\|x-x_ * \\| < \\epsilon $ to define the $ \\epsilon $ -neighborhood of the optimum . However , in this paper , the authors use $ \\|x-x_ * \\| < \\epsilon \\|x_0 - x_ * \\| + c $ to define the neighborhood and just ignore the second term when deriving the rate . Under this definition , they draw the conclusion that L2GD can improve the communication complexity of GD . This can be misleading and questionable . In GD , we do n't have the second term in ( 9 ) at all . 2.Similarly , when obtaining the best value of $ p $ , the authors only optimize the first term . However , the second term in ( 9 ) also depend on $ p $ . The authors seem to ignore it again . * * New insights about the role of local steps * * 1 . The authors state that `` the role of local steps in gradient type methods is not to reduce communication complexity , as is generally believed . Indeed , there is no theoretical result supporting this claim in the key heterogeneous data regime . '' This statement is not true . It has been shown in literature ( eg , [ 3 ] ) that local SGD can achieve the same rate $ 1/\\sqrt { n K } $ as synchronous SGD but only uses $ O ( n^ { 3/4 } T^ { 3/4 } ) $ communication rounds , while synchronous SGD uses $ T $ rounds . 2 . `` The more local steps are taken , the more we bias the method towards the purely local models . '' I feel we can not draw this conclusion from this paper 's analysis . In particular , in this paper , the choice of local steps is controlled by the parameter $ \\lambda $ ( expected local steps = $ 1+L/\\lambda $ ) . When we set a small $ \\lambda $ , we get two consequences : ( 1 ) the formulation will emphasize more on $ f ( x ) $ , and hence , the solution is biased towards purely local models . ( 2 ) the `` optimal '' local steps derived in this paper becomes larger . Obviously , these two consequences are parallel to each other . We can not say the second point is the reason of the first point . Instead of setting the expected local steps to be $ 1+L/\\lambda $ , one can also use other values which wo n't influence the final solution . * * Experiments * * The experimental results can only show the importance of variance reduction , which seems to be a minor contribution of the paper . Most theoretical claims are not validated empirically . # # Post-rebuttal Thanks the authors for the clarifications ! I appreciate it . However , some of my concerns are not addressed . - The main concern I have is about the new insight on local update methods . Basically , the author obtain the insights based on a newly proposed algorithm ( L2GD , let 's call this algorithm B ) and a new problem formulation ( let 's call this formulation B ) . However , they want to apply the insight from algorithm B and formulation B to algorithm A ( original local update methods ) and formulation A ( original FL formulation ) . It is obvious that one can not draw this conclusion because both the algorithm and the formulation are different . - Second , as I stated in the original review , I do n't think one can obtain the insights from the analyses in this paper . The author did n't directly answer my question and just said `` they did n't expect people to interpret it in this way '' . But it is still unclear how to correctly understand their insights . Based on the above two points , I strongly feel that their main insights about the effects of local updates should be further and carefully examined . The current version could be misleading . Besides , I also have the following minor concerns : - The authors claim that [ Yu et al.ICML 2019 ] did n't consider the heterogeneous setting . This is not true . Although [ Yu et al.ICML2019 ] assumes that the gradient dissimilarity is uniformly bounded ( which is widely used in literature ) , their setting is still non-iid setting . It 's unfair to say that they only study the IID data setting . So the second motivation of this paper does not make sense to me . The authors oversell their contribution . More precisely , their contribution is not the first proof under data heterogeneous setting but should be the new proof without data similarity assumption . - `` non-local cousins '' is unclear and has n't been properly defined in the paper . For local SGD with mini-batch size , local steps and clients , there are two non-local cousins : ( a ) SGD with mini-batch size ; and ( b ) SGD with mini-batch size . It seems that the authors misused these two algorithms . In the response , they agree that [ Yu et al.ICML 2019 ] proves `` with data dissimilarity assumption , local SGD can improve the communication complexity of classical SGD '' . Here , classical SGD refers to algorithm ( a ) . In the updated paper , they cite two papers from Woodworth et al.to support their claim . However , the non-local methods in Woodworth et al.is algorithm ( b ) . The authors should formally define which non-local algorithm they want to compare with . - In the paper , the authors claim that they prove for the first time local methods can improve the communication complexity of the non-local cousins . However , this statement is overselling . The more precise version is that they prove that the variance-reduced version of local methods can improve the communication complexity of the vanilla non-local version algorithms . - It seems that the authors want to claim a lot of contributions in this single paper and they did n't organize these contributions well . Hence , it causes difficulties for readers to understand their true novelty . I recommend the authors to rewrite the paper and carefully consider the paper structure . For example , if I understand correctly , the main contribution of this paper should be the insights on local updates . However , the authors did n't show any experiments on this insight in the main paper ( they put them in the appendix ) . Instead , they just validate the effect of variance reduction in the main paper , which is just a minor point . Also , in the introduction , there is a long paragraph to introduce L2GD as one of the main contributions . However , as discussed in the responses , L2GD is not a new algorithm . The authors do n't need to give it so much emphasize or should not claim it as one contribution . - Also , in [ 1 ] EASGD does use multiple local steps . The authors should compare L2GD with EASGD , as they both are designed to minimize the new formulation . # # References [ 1 ] Zhang et al.Deep learning with elastic averaging SGD . NeurIPS 2015 . [ 2 ] Wang et al.Overlap Local-SGD : An algorithmic approach to hide communication delay in distributed SGD . ICASSP 2020 . [ 3 ] Yu et al.On the linear speedup analysis of communication efficient momentum sgd for distributed non-convex optimization . ICML 2019 .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for the many questions and issues raised . Appreciated . Some are easily addressable and very minor , as we explain below . All remaining issues come from a fundamental misunderstanding by the reviewer of what our paper 's key contributions are . We are happy to explain . We kindly ask the reviewer to read our response and reconsider their score , which we believe is unjustified . * * New insights about the role of local steps : Issue 1 * * We start with this point because we believe that it the most crucial , and it would be a major issue if the mentioned criticism was valid . It is not . We insist that the claim `` the role of local steps in gradient type methods is not to reduce communication complexity , as is generally believed . Indeed , there is no theoretical result supporting this claim in the key heterogeneous data regime '' is correct . Note that the provided reference [ 3 ] { \\bf does not consider the data heterogeneous setup . } ; [ 3 ] considers either identical data or a bounded dissimilarity between local gradients ( equation ( 3 ) therein ) over the whole domain . Under such data similarity assumption , local SGD can outperform classical SGD ( similar results have been provided in a convex case as well ) . However , and we do make this very clear in the paper , we are concerned with the much more difficult and important to FL setting : the data heterogeneous setting . That is , we do not use any kind of data similarity assumption whatsoever ! Our paper is the first to show that ( variants of ) local SGD can outperform synchronous SGD in communication complexity * if no data similarity is assumed * . We show that this is the case when one aims to solve our new FL formulation ( 1 ) , which happens to have a natural interpretation as a personalized FL formulation , with personalization level controlled by a single global parameter $ \\lambda $ . In other words , we interpret the purpose of local steps : we claim they indeed do help in reducing communication complexity even in the heterogeneous data regime ( and are the first to prove so ) , but in order for this to happen , we need to see them as methods for solving the personalized FL formulation ( 1 ) we propose . Moreover , as we show , ( some variants of known and new ) local methods can indeed be seen as methods for solving ( 1 ) . We spend considerable real estate in the main paper to explain this on what we believe is the simplest of all local methods : local gradient descent ( LGD ) . Indeed , LGD can be seen as SGD with importance sampling applied to ( 1 ) seen as a 2-sum problem . This alone , we believe , offers new conceptual insights to the FL community . We stress that in the practical FL applications , the often invoked bounded data dissimilarity assumption ( between local gradients over the whole domain ) does not hold : in such a case , local GD methods do not provide any benefit over their non-local cousins , yet they are still the most prominent FL optimizers . * * New insights about the role of local steps : Issue 2 * * We did not intend this sentence to be interpreted the way you interpreted it . It was intended as an informal `` intuitive '' statement capturing some of the essence of our findings . It is not precise and was not intended to be . We will find a way to reformulate this sentence to avoid the kinds of confusion you are pointing out . However , notice this is a very minor point about a single sentence which is easily fixable ."}, {"review_id": "nLYMajjctMh-1", "review_text": "Interesting insights into federated learning , possibly limited by the focus on strong convexity This paper considers distributed training problems arising in the context of federated learning . It proposes a novel framing of the problem as a compromise between fitting a model locally to the data available at a device , and fitting a model globally to the data from all devices . This leads to the so-called loopless local gradient descent ( L2GD ) method , which is loosely related to the popular FedAvg/LocalSGD method , and also loosely related to a randomized version of the well-studied ADMM for consensus optimization problems . The paper provides theoretical convergence guarantees for L2GD and related variance-reduced versions L2GD+ and L2GD++ . As is pointed out in footnote 1 , the ideas underlying the L2GD and its analysis have been previously explored in the literature . It would be worth clarifying in the paper ( in footnote 1 or elsewhere ) what aspects of L2GD and its analysis which are novel and not completely subsumed by the previous works Liu et al . ( 2017 ) or Wang et al . ( 2018 ) .The last sentence of footnote 1 is somewhat in this direction , but is not very precise . I generally think the perspective proposed in this paper , along with the L2GD method , are novel and interesting , and I expect they will be useful to researchers working on federated learning . The main limitation of the work , in my view , is the limited fit and interest to the broader ICLR audience . For example , the CFP emphasizes the importance of non-convex optimization , and deep learning methods and architectures for representation learning . On the other hand , this paper focuses on convex models , both for the analysis ( smooth and strongly convex ) and in the experiments ( l2-regularized logistic regression ) . The analysis techniques do not appear to make use of strong global structure ( beyond the definition of strong convexity ) . Is there reason to believe it will not be possible to provide local convergence guarantees for L2GD under more relaxed assumptions ( in particular , without assuming convexity ) ? A few other minor points : * Regarding the second motivating point , see also the recent work of Woodworth et al . ( arxiv:2006.04735 and arxiv:2002.07839 ) . * Is there any intuition why , in Fig 1 , when $ \\lambda $ approaches $ 10^ { 1 } $ , the blue curve begins to decrease and orange curve begins to increase ? ( I.e. , why the non-monotonic behaviour ? ) * Minor nit . : Alg 1 seems to violate the important notion in FL that devices never reveal their private information ( e.g. , their local decision variables or gradients ) directly to the centralized master . Rather than saying that ( 8 ) is implemented at the master , would it make more sense for each device to receive $ \\bar { x } ^k $ from the Master and implement ( 8 ) locally ? ( The averaged model can be computed in a secure way using DP and secure aggregation , much the same as it is in current FL implementations . )", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * Footnote 1 * * While the optimization problem that we study is not new on its own ( we arrived at it independently and naturally by thinking about the role of local steps in FL methods ) , the link of such an objective with the FL is new . Specifically , the personalized FL objective ( 1 ) allows explaining the role of local steps as the local methods appear as natural applications of various SGD methods to ( 1 ) . We get meaningful convergence rates , and in communication complexity , our approach shows ( for the first time ! ) better performance than their non-local counterparts . So , we provide new links between local methods , personalization and communication complexity . This is the main novelty of our work explained as a high-level idea . * * Limited fit * * We decided to focus on ( strongly ) convex optimization in this work since the results , in that case , are easier to interpret . Until now , local methods have never been proven to outperform their non-local cousins on problems with heterogeneous data even in the convex or strongly convex case . We believe that it is important to explain properly the convex case first before moving to the non-convex one . Note that we could consider a relaxation of a strong convexity such as quasi-strong convexity or the PL condition , and we can easily derive similar rates and claim that our results apply to such a ( arguably limited ) non-convex case . There is nothing preventing us from deriving rates for nonconvex functions . We did not do so as there is already a lot of material covered in the paper and it does not make sense to make the coverage even more dense . We plan to do this in a follow up work , and already have some results in this direction . There is too much to be said here , and much of it is different from the strongly convex case , so indeed , mixing the convex and nonconvex cases would not be a good idea . * * Minor * * Re the motivation point : Thanks a lot for the reference ! Indeed , we are aware of that paper , however , we decided to not include it since our work was done sooner , and hence was not influenced by this paper . * * Re Fig 1 * * Very good question . Intuitively , the blue curve should keep increasing and the orange curve should indeed keep decreasing as we increase lambda . However , we do not have a proof of that statement . So , this does not contradict our theory nut instead provided additional computational insights complementing our theory . * * Re privacy * * We agree with the reviewer that our current algorithm designs did not take the privacy into the consideration . While privacy is a very important aspect of FL ; in this paper , we tackle different FL challenges and thus we ignore privacy issues . However , similar to the classical local SGD methods , our algorithms can be implemented in a private fashion as well using similar ideas as you have pointed out . We will add a remark about this in the paper ; thanks ! Typically , papers that do theory will necessarily ignore some systems level considerations , and papers that do not ignore such things typically ca n't contain any meaningful theory ."}, {"review_id": "nLYMajjctMh-2", "review_text": "Summary of the paper : The paper proposes a new formulation for the federated learning problem , in which each agent has its local model , and a penalty term is added to the objective function to control the deviation of these local models from their average . Next , the authors develop a randomized algorithm to tackle this problem and characterize its convergence under several assumptions , such as smoothness and strong convexity . They also discuss variants of their algorithm , which uses variance reduction techniques or considers users ' partial participation . The paper is well-written , and the goals , problem formulation , and contributions are all explained in detail . However , the reviewer has a number of concerns , which are listed below : The first concern is regarding the novelty of the formulation or analysis . The idea of this paper 's formulation , giving a copy to each agent and adding a regularizer to keep the copies close , has been discussed in the distributed literature , for instance , in ADMM . Moreover , it is not clear which part of the analysis is novel or challenging . It seems that the authors use an unbiased estimator to solve an optimization problem with a smooth and strongly convex objective function . This setting has been studied extensively in the literature , including applying variance reduction techniques . Second , the regularizer parameter $ \\lambda $ seems to be at the heart of this framework . With $ \\lambda=\\infty $ , the problem reduces to the classic federated learning setting , and when $ \\lambda=0 $ , the formulation boils down to the case that each agent solves its own problem . In particular , for the latter , the authors claim that `` such purely local models are rarely useful . '' However , this claim 's reasoning is not clear ; for instance , from a theoretical point of view , results such as Theorem 3.1 suggest that having $ \\lambda=0 $ will lead to the minimum loss $ f $ . In other words , it is not clear how we should compare the different trained models from setting different values for $ \\lambda $ , and which range of $ \\lambda $ leads to a good model with respect to that measure . Third , as stated in the introduction , several methods have been recently proposed to address the heterogeneous case or achieve personalization in the federated learning problem . I wonder why the authors have only compared their methods against each other in experiments and have not included those methods for comparison .", "rating": "4: Ok but not good enough - rejection", "reply_text": "First concern . Penalization is an old and well studied technique in optimization , and of course , we are not claiming novelty of this type . Similar penalties were considered earlier in the literature in very different contexts ; see footnote 1 . Our main insight is that the formulation we propose is * new and particularly meaningful in the context federated learning ( FL ) , resolving or at least giving important insights to several key issues in FL * . We spend a considerable space in the paper to explain this . Let us reiterate some of these points here : Despite a significant effort by the FL community , and despite the fact that this was the original and ( still is ! ) motivation for their development , local methods ( e.g. , LGD ) were never proven to reduce communication complexity when compared to their non-local counterparts in the heterogeneous data regime ( see Woodworth et al.2020 https : //arxiv.org/pdf/2006.04735.pdf ) . There are also counterexamples which show this ca n't be done in general , even if one considers just convex quadratic functions . The belief that local steps are performed to reduced communication complexity is , we argue , one of the key confusions the FL community seems to suffer from , and our work is trying to remedy this situation . One can make several possible conclusions from this : i ) local methods have better communication complexity , but we still do not know why as our analysis tools ca n't fully explain how well they work , ii ) local methods are not actually beating non-local methods in terms of communication complexity , as it is universally asserted , and hence should be replaced by better performing methods , iii ) local methods are good at solving a different problem of crucial importance to FL , but we do not know what problem it is . Our work is motivated by mounting evidence that ii ) is true ( in the heterogeneous data setting ) , which motivated us to think about iii ) as a possible solution . Indeed , we manage to show that if one thinks of local methods as methods for solving our FL formulation ( 1 ) instead , then they become superior to non-local methods in communication complexity ! This is the first time such superiority of local methods is shown to nonlocal methods in the heterogeneous data regime , which is the most important regime for FL ! Hence , we believe our work is a major conceptual breakthrough in the field . See lines 108-116 : communication complexity of LGD decreases to 0 as $ \\lambda \\to 0 $ . So , if one aims for more personalization ( corresponding to small $ \\lambda $ ) , then local methods will have better and better complexity . In the extreme case when one requires absolute personalization ( $ \\lambda=0 $ ) , each device is simply training a model from their own data only , and no communication is needed . So , this makes very good intuitive sense . Note that , for example , LGD ( one of the most basic variants of FedAvg ) can be interpreted as a SGD with importance sampling applied to ( 1 ) seen as a 2-sum problem . Yes , we did not have to come up with a new analysis for SGD in this case ; we clearly explain this in the paper . So , our novelty here is not in the analysis , which , as you say and as we say in the paper , simply follows from Gower et al ( 2019 ) . The novelty is the insights that SGD applied to ( 1 ) in the way we do it generates LGD ! So , the mystery of the utility of local steps evaporates : they are there to put more emphasis on $ f $ instead of the penalty . However , more emphasis of this type is desired precisely when $ \\lambda $ is small , i.e. , when we require more personalization . So , the key novelty of our paper is that we connect personalization , communication complexity and local methods together , in an insightful manner . Our several new local methods are a secondary contribution . Second concern . We study the effect of how $ \\lambda $ influences the convergence rate and the optimal # of local steps . We do not study which choice of $ \\lambda $ is better from a generalization perspective and hence we ca n't give a theoretical prescription to practitioners of this type . What we mean by saying that `` such purely models are rarely useful '' is this : in practice , devices do not have enough data to be able to train models using their own data only , which is why we need to resort to distributed methods such as FedAvg or LGD . If they had enough data , $ \\lambda=0 $ would be a perfectly fine choice , and there would be no need to do any communication . So , $ \\lambda=0 $ would be optimal and FL in such a data-rich regime would simply reduce to $ n $ independent training problems performed by the devices independently . Yes , $ \\lambda =0 $ leads to the smallest training loss . However , this does not mean we would get the smallest testing loss . Third concern . The reason is simple : the other methods solve a different optimization problem and hence are not comparable . Note that none of these methods outperform their non-local cousins in terms of the comm . complexity in the heterog . data setting ."}, {"review_id": "nLYMajjctMh-3", "review_text": "* * * Strong Personalization is a hardcore problem in FL . The authors target an important problem . The theory analysis seems correct , but the bound seems not tight enough . * * * Weakness Recently , there are many personalized methods proposed for FL . In the I.I.D . setting , local SGD training ( FedAvg ) can obtain similar accuracy as centralized training with a theory guarantee . But in the non-I.I.D . setting , I am curious to know what \u2019 s the ultimate goal of optimization . Can the proposed personalized methods obtain accuracy comparable to centralized training ? If we do not compare with the centralized accuracy , how can we know the optimized personalized model can obtain sufficient accuracy for practical applications . The experimental results are weak . The authors only provide results on the LR model for toy datasets ( LibSVM ) . Without non-convex experiments , it is hard to believe the proposed method works in practice given that DNN-based models dominate nearly all ML tasks . The code style and readability are poor , which discourages the popularity of the proposed method . Although the authors mentioned some contributions of the proposed method , I still can not get what \u2019 s the advantages of the new formulation over conventional Federated optimization ? What is its limitation ? What \u2019 s the cost to use this method ? When should we choose this algorithm in practice ? In which degree of non-IIDness ? Playing with optimization analysis tricks won \u2019 t solve the personalized challenge of federated learning in practice .", "rating": "4: Ok but not good enough - rejection", "reply_text": "This review does not seem to address any substance actually contained in our paper . Instead , it offers general philosophical thoughts related to the general theme of our paper . It is not possible to meaningfully respond to a review of this type . These kids of reviews are not helpful , and actually inflict quite a bit of harm on the community . - `` The bound seems not tight . '' What bound ? We have many . We believe we offer several efficient algorithms , starting with simple ones which are easier to understand ( for pedagogical/clarity reasons ) , and gradually adding features and enhancements ( e.g. , adding control variates , partial participation and so on ) . Your comment is generic and does not address our work . It could have been made without actually reading our paper at all . This comment should be ignored by the AC . - First paragraph in weaknesses : you ask some questions but our paper is not about this . Our contributions are clearly stated and you do not refer to them . You do not seem to have a genuine interest in what we actually accomplished . - Experiments : The results are not weak . Our theory is for convex problems , and the methods are fine-tuned for convex problems . We test the theoretical predictions with carefully designed experiments and observe that our theory predicts what happens in experiments very well . This is the ideal scenario of any scientific work containing theory . The experiments are strong . Testing our methods in the nonconvex regime does not make much sense ; we would need to first develop the associated theory , and this is beyond the scope of the current paper . Not all FL tasks are deep learning tasks . - Code : You criticize the readability of our code , but offer no concrete evidence of what is wrong . Again , this is a generic comment that could have been made about any paper containing a method . This kind of a comment is not helpful . If you found concrete issues , list them . We are happy to correct and improve our paper , but we ca n't do this if issues are not pointed out to us . - Last paragraph : These are again comments divorced from the actual contents and contributions of our paper . It is very clear to us that this reviewer simply failed to understand our work and contributions . Or perhaps the reviewer even did not read the work properly . In any case , it is not possible to respond meaningfully to a review that fails to address the evaluated paper to such a degree as this review manages to do so ."}], "0": {"review_id": "nLYMajjctMh-0", "review_text": "# # Summary This paper proposed a new formulation of federated learning , which balances between traditional global model and purely local models . The authors discuss the advantages of the new formulation and propose a new algorithm L2GD to solve the problem . They theoretically analyzed the communication complexity of L2GD under stronly-convex settings and propose several algorithmic variants . # # Pros 1 . The authors developed a set of algorithms based on L2GD and provided theoretical analysis . The efforts are appreciated . # # Cons Unfortunately , most contributions of this paper does n't make sense to me . I have concerns regarding novelty and correctness of the statements made by this paper . Detailed comments are listed as follows . * * New formulation * * 1 . In section 2 , the authors claim that `` we prove that the optimal local models converge to the traditional global model characterized by ( 1 ) at the rate $ O ( 1/\\lambda ) $ '' . However , I did n't find any discussions or proof around this statement in following sections . From my understanding , there should be some equations showing how $ x ( \\lambda ) -x ( \\infty ) $ or $ f ( x ( \\lambda ) ) -f ( x ( \\infty ) ) $ changes over $ \\lambda $ . But I did n't find any . 2.In experiments , the authors did n't compare the proposed formulation with the original formulation . How much benefits one can obtain from the new formulation is unclear , making this paper to be incomplete . 3.The formulation is not new . A nearly same formulation can be found in [ 1 ] . The authors did n't notice this paper . Since [ 1 ] also proposed an algorithm EASGD to solve the new formulation , the authors are supposed to compare L2GD with the algorithm in [ 1 ] . * * New algorithm : Loopless LGD * * 1 . The algorithm is also not new . An extremely similar algorithm has appeared in [ 2 ] . By some re-parameterization , I believe they are equivalent to each other . The authors missed this reference . They should justify the differences and compare the results . 2.It is unclear why L2GD uses random local steps instead of a fixed one . Or what are the benefits of the randomized one ? * * Convergence theory * * 1 . The conclusions of convergence analysis are questionable . In particular , when obtaining the convergence rate , it seems that the authors completely ignore the second term in ( 9 ) . In general , people use $ f ( x ) -f ( x_ * ) < \\epsilon $ or $ \\|x-x_ * \\| < \\epsilon $ to define the $ \\epsilon $ -neighborhood of the optimum . However , in this paper , the authors use $ \\|x-x_ * \\| < \\epsilon \\|x_0 - x_ * \\| + c $ to define the neighborhood and just ignore the second term when deriving the rate . Under this definition , they draw the conclusion that L2GD can improve the communication complexity of GD . This can be misleading and questionable . In GD , we do n't have the second term in ( 9 ) at all . 2.Similarly , when obtaining the best value of $ p $ , the authors only optimize the first term . However , the second term in ( 9 ) also depend on $ p $ . The authors seem to ignore it again . * * New insights about the role of local steps * * 1 . The authors state that `` the role of local steps in gradient type methods is not to reduce communication complexity , as is generally believed . Indeed , there is no theoretical result supporting this claim in the key heterogeneous data regime . '' This statement is not true . It has been shown in literature ( eg , [ 3 ] ) that local SGD can achieve the same rate $ 1/\\sqrt { n K } $ as synchronous SGD but only uses $ O ( n^ { 3/4 } T^ { 3/4 } ) $ communication rounds , while synchronous SGD uses $ T $ rounds . 2 . `` The more local steps are taken , the more we bias the method towards the purely local models . '' I feel we can not draw this conclusion from this paper 's analysis . In particular , in this paper , the choice of local steps is controlled by the parameter $ \\lambda $ ( expected local steps = $ 1+L/\\lambda $ ) . When we set a small $ \\lambda $ , we get two consequences : ( 1 ) the formulation will emphasize more on $ f ( x ) $ , and hence , the solution is biased towards purely local models . ( 2 ) the `` optimal '' local steps derived in this paper becomes larger . Obviously , these two consequences are parallel to each other . We can not say the second point is the reason of the first point . Instead of setting the expected local steps to be $ 1+L/\\lambda $ , one can also use other values which wo n't influence the final solution . * * Experiments * * The experimental results can only show the importance of variance reduction , which seems to be a minor contribution of the paper . Most theoretical claims are not validated empirically . # # Post-rebuttal Thanks the authors for the clarifications ! I appreciate it . However , some of my concerns are not addressed . - The main concern I have is about the new insight on local update methods . Basically , the author obtain the insights based on a newly proposed algorithm ( L2GD , let 's call this algorithm B ) and a new problem formulation ( let 's call this formulation B ) . However , they want to apply the insight from algorithm B and formulation B to algorithm A ( original local update methods ) and formulation A ( original FL formulation ) . It is obvious that one can not draw this conclusion because both the algorithm and the formulation are different . - Second , as I stated in the original review , I do n't think one can obtain the insights from the analyses in this paper . The author did n't directly answer my question and just said `` they did n't expect people to interpret it in this way '' . But it is still unclear how to correctly understand their insights . Based on the above two points , I strongly feel that their main insights about the effects of local updates should be further and carefully examined . The current version could be misleading . Besides , I also have the following minor concerns : - The authors claim that [ Yu et al.ICML 2019 ] did n't consider the heterogeneous setting . This is not true . Although [ Yu et al.ICML2019 ] assumes that the gradient dissimilarity is uniformly bounded ( which is widely used in literature ) , their setting is still non-iid setting . It 's unfair to say that they only study the IID data setting . So the second motivation of this paper does not make sense to me . The authors oversell their contribution . More precisely , their contribution is not the first proof under data heterogeneous setting but should be the new proof without data similarity assumption . - `` non-local cousins '' is unclear and has n't been properly defined in the paper . For local SGD with mini-batch size , local steps and clients , there are two non-local cousins : ( a ) SGD with mini-batch size ; and ( b ) SGD with mini-batch size . It seems that the authors misused these two algorithms . In the response , they agree that [ Yu et al.ICML 2019 ] proves `` with data dissimilarity assumption , local SGD can improve the communication complexity of classical SGD '' . Here , classical SGD refers to algorithm ( a ) . In the updated paper , they cite two papers from Woodworth et al.to support their claim . However , the non-local methods in Woodworth et al.is algorithm ( b ) . The authors should formally define which non-local algorithm they want to compare with . - In the paper , the authors claim that they prove for the first time local methods can improve the communication complexity of the non-local cousins . However , this statement is overselling . The more precise version is that they prove that the variance-reduced version of local methods can improve the communication complexity of the vanilla non-local version algorithms . - It seems that the authors want to claim a lot of contributions in this single paper and they did n't organize these contributions well . Hence , it causes difficulties for readers to understand their true novelty . I recommend the authors to rewrite the paper and carefully consider the paper structure . For example , if I understand correctly , the main contribution of this paper should be the insights on local updates . However , the authors did n't show any experiments on this insight in the main paper ( they put them in the appendix ) . Instead , they just validate the effect of variance reduction in the main paper , which is just a minor point . Also , in the introduction , there is a long paragraph to introduce L2GD as one of the main contributions . However , as discussed in the responses , L2GD is not a new algorithm . The authors do n't need to give it so much emphasize or should not claim it as one contribution . - Also , in [ 1 ] EASGD does use multiple local steps . The authors should compare L2GD with EASGD , as they both are designed to minimize the new formulation . # # References [ 1 ] Zhang et al.Deep learning with elastic averaging SGD . NeurIPS 2015 . [ 2 ] Wang et al.Overlap Local-SGD : An algorithmic approach to hide communication delay in distributed SGD . ICASSP 2020 . [ 3 ] Yu et al.On the linear speedup analysis of communication efficient momentum sgd for distributed non-convex optimization . ICML 2019 .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for the many questions and issues raised . Appreciated . Some are easily addressable and very minor , as we explain below . All remaining issues come from a fundamental misunderstanding by the reviewer of what our paper 's key contributions are . We are happy to explain . We kindly ask the reviewer to read our response and reconsider their score , which we believe is unjustified . * * New insights about the role of local steps : Issue 1 * * We start with this point because we believe that it the most crucial , and it would be a major issue if the mentioned criticism was valid . It is not . We insist that the claim `` the role of local steps in gradient type methods is not to reduce communication complexity , as is generally believed . Indeed , there is no theoretical result supporting this claim in the key heterogeneous data regime '' is correct . Note that the provided reference [ 3 ] { \\bf does not consider the data heterogeneous setup . } ; [ 3 ] considers either identical data or a bounded dissimilarity between local gradients ( equation ( 3 ) therein ) over the whole domain . Under such data similarity assumption , local SGD can outperform classical SGD ( similar results have been provided in a convex case as well ) . However , and we do make this very clear in the paper , we are concerned with the much more difficult and important to FL setting : the data heterogeneous setting . That is , we do not use any kind of data similarity assumption whatsoever ! Our paper is the first to show that ( variants of ) local SGD can outperform synchronous SGD in communication complexity * if no data similarity is assumed * . We show that this is the case when one aims to solve our new FL formulation ( 1 ) , which happens to have a natural interpretation as a personalized FL formulation , with personalization level controlled by a single global parameter $ \\lambda $ . In other words , we interpret the purpose of local steps : we claim they indeed do help in reducing communication complexity even in the heterogeneous data regime ( and are the first to prove so ) , but in order for this to happen , we need to see them as methods for solving the personalized FL formulation ( 1 ) we propose . Moreover , as we show , ( some variants of known and new ) local methods can indeed be seen as methods for solving ( 1 ) . We spend considerable real estate in the main paper to explain this on what we believe is the simplest of all local methods : local gradient descent ( LGD ) . Indeed , LGD can be seen as SGD with importance sampling applied to ( 1 ) seen as a 2-sum problem . This alone , we believe , offers new conceptual insights to the FL community . We stress that in the practical FL applications , the often invoked bounded data dissimilarity assumption ( between local gradients over the whole domain ) does not hold : in such a case , local GD methods do not provide any benefit over their non-local cousins , yet they are still the most prominent FL optimizers . * * New insights about the role of local steps : Issue 2 * * We did not intend this sentence to be interpreted the way you interpreted it . It was intended as an informal `` intuitive '' statement capturing some of the essence of our findings . It is not precise and was not intended to be . We will find a way to reformulate this sentence to avoid the kinds of confusion you are pointing out . However , notice this is a very minor point about a single sentence which is easily fixable ."}, "1": {"review_id": "nLYMajjctMh-1", "review_text": "Interesting insights into federated learning , possibly limited by the focus on strong convexity This paper considers distributed training problems arising in the context of federated learning . It proposes a novel framing of the problem as a compromise between fitting a model locally to the data available at a device , and fitting a model globally to the data from all devices . This leads to the so-called loopless local gradient descent ( L2GD ) method , which is loosely related to the popular FedAvg/LocalSGD method , and also loosely related to a randomized version of the well-studied ADMM for consensus optimization problems . The paper provides theoretical convergence guarantees for L2GD and related variance-reduced versions L2GD+ and L2GD++ . As is pointed out in footnote 1 , the ideas underlying the L2GD and its analysis have been previously explored in the literature . It would be worth clarifying in the paper ( in footnote 1 or elsewhere ) what aspects of L2GD and its analysis which are novel and not completely subsumed by the previous works Liu et al . ( 2017 ) or Wang et al . ( 2018 ) .The last sentence of footnote 1 is somewhat in this direction , but is not very precise . I generally think the perspective proposed in this paper , along with the L2GD method , are novel and interesting , and I expect they will be useful to researchers working on federated learning . The main limitation of the work , in my view , is the limited fit and interest to the broader ICLR audience . For example , the CFP emphasizes the importance of non-convex optimization , and deep learning methods and architectures for representation learning . On the other hand , this paper focuses on convex models , both for the analysis ( smooth and strongly convex ) and in the experiments ( l2-regularized logistic regression ) . The analysis techniques do not appear to make use of strong global structure ( beyond the definition of strong convexity ) . Is there reason to believe it will not be possible to provide local convergence guarantees for L2GD under more relaxed assumptions ( in particular , without assuming convexity ) ? A few other minor points : * Regarding the second motivating point , see also the recent work of Woodworth et al . ( arxiv:2006.04735 and arxiv:2002.07839 ) . * Is there any intuition why , in Fig 1 , when $ \\lambda $ approaches $ 10^ { 1 } $ , the blue curve begins to decrease and orange curve begins to increase ? ( I.e. , why the non-monotonic behaviour ? ) * Minor nit . : Alg 1 seems to violate the important notion in FL that devices never reveal their private information ( e.g. , their local decision variables or gradients ) directly to the centralized master . Rather than saying that ( 8 ) is implemented at the master , would it make more sense for each device to receive $ \\bar { x } ^k $ from the Master and implement ( 8 ) locally ? ( The averaged model can be computed in a secure way using DP and secure aggregation , much the same as it is in current FL implementations . )", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * Footnote 1 * * While the optimization problem that we study is not new on its own ( we arrived at it independently and naturally by thinking about the role of local steps in FL methods ) , the link of such an objective with the FL is new . Specifically , the personalized FL objective ( 1 ) allows explaining the role of local steps as the local methods appear as natural applications of various SGD methods to ( 1 ) . We get meaningful convergence rates , and in communication complexity , our approach shows ( for the first time ! ) better performance than their non-local counterparts . So , we provide new links between local methods , personalization and communication complexity . This is the main novelty of our work explained as a high-level idea . * * Limited fit * * We decided to focus on ( strongly ) convex optimization in this work since the results , in that case , are easier to interpret . Until now , local methods have never been proven to outperform their non-local cousins on problems with heterogeneous data even in the convex or strongly convex case . We believe that it is important to explain properly the convex case first before moving to the non-convex one . Note that we could consider a relaxation of a strong convexity such as quasi-strong convexity or the PL condition , and we can easily derive similar rates and claim that our results apply to such a ( arguably limited ) non-convex case . There is nothing preventing us from deriving rates for nonconvex functions . We did not do so as there is already a lot of material covered in the paper and it does not make sense to make the coverage even more dense . We plan to do this in a follow up work , and already have some results in this direction . There is too much to be said here , and much of it is different from the strongly convex case , so indeed , mixing the convex and nonconvex cases would not be a good idea . * * Minor * * Re the motivation point : Thanks a lot for the reference ! Indeed , we are aware of that paper , however , we decided to not include it since our work was done sooner , and hence was not influenced by this paper . * * Re Fig 1 * * Very good question . Intuitively , the blue curve should keep increasing and the orange curve should indeed keep decreasing as we increase lambda . However , we do not have a proof of that statement . So , this does not contradict our theory nut instead provided additional computational insights complementing our theory . * * Re privacy * * We agree with the reviewer that our current algorithm designs did not take the privacy into the consideration . While privacy is a very important aspect of FL ; in this paper , we tackle different FL challenges and thus we ignore privacy issues . However , similar to the classical local SGD methods , our algorithms can be implemented in a private fashion as well using similar ideas as you have pointed out . We will add a remark about this in the paper ; thanks ! Typically , papers that do theory will necessarily ignore some systems level considerations , and papers that do not ignore such things typically ca n't contain any meaningful theory ."}, "2": {"review_id": "nLYMajjctMh-2", "review_text": "Summary of the paper : The paper proposes a new formulation for the federated learning problem , in which each agent has its local model , and a penalty term is added to the objective function to control the deviation of these local models from their average . Next , the authors develop a randomized algorithm to tackle this problem and characterize its convergence under several assumptions , such as smoothness and strong convexity . They also discuss variants of their algorithm , which uses variance reduction techniques or considers users ' partial participation . The paper is well-written , and the goals , problem formulation , and contributions are all explained in detail . However , the reviewer has a number of concerns , which are listed below : The first concern is regarding the novelty of the formulation or analysis . The idea of this paper 's formulation , giving a copy to each agent and adding a regularizer to keep the copies close , has been discussed in the distributed literature , for instance , in ADMM . Moreover , it is not clear which part of the analysis is novel or challenging . It seems that the authors use an unbiased estimator to solve an optimization problem with a smooth and strongly convex objective function . This setting has been studied extensively in the literature , including applying variance reduction techniques . Second , the regularizer parameter $ \\lambda $ seems to be at the heart of this framework . With $ \\lambda=\\infty $ , the problem reduces to the classic federated learning setting , and when $ \\lambda=0 $ , the formulation boils down to the case that each agent solves its own problem . In particular , for the latter , the authors claim that `` such purely local models are rarely useful . '' However , this claim 's reasoning is not clear ; for instance , from a theoretical point of view , results such as Theorem 3.1 suggest that having $ \\lambda=0 $ will lead to the minimum loss $ f $ . In other words , it is not clear how we should compare the different trained models from setting different values for $ \\lambda $ , and which range of $ \\lambda $ leads to a good model with respect to that measure . Third , as stated in the introduction , several methods have been recently proposed to address the heterogeneous case or achieve personalization in the federated learning problem . I wonder why the authors have only compared their methods against each other in experiments and have not included those methods for comparison .", "rating": "4: Ok but not good enough - rejection", "reply_text": "First concern . Penalization is an old and well studied technique in optimization , and of course , we are not claiming novelty of this type . Similar penalties were considered earlier in the literature in very different contexts ; see footnote 1 . Our main insight is that the formulation we propose is * new and particularly meaningful in the context federated learning ( FL ) , resolving or at least giving important insights to several key issues in FL * . We spend a considerable space in the paper to explain this . Let us reiterate some of these points here : Despite a significant effort by the FL community , and despite the fact that this was the original and ( still is ! ) motivation for their development , local methods ( e.g. , LGD ) were never proven to reduce communication complexity when compared to their non-local counterparts in the heterogeneous data regime ( see Woodworth et al.2020 https : //arxiv.org/pdf/2006.04735.pdf ) . There are also counterexamples which show this ca n't be done in general , even if one considers just convex quadratic functions . The belief that local steps are performed to reduced communication complexity is , we argue , one of the key confusions the FL community seems to suffer from , and our work is trying to remedy this situation . One can make several possible conclusions from this : i ) local methods have better communication complexity , but we still do not know why as our analysis tools ca n't fully explain how well they work , ii ) local methods are not actually beating non-local methods in terms of communication complexity , as it is universally asserted , and hence should be replaced by better performing methods , iii ) local methods are good at solving a different problem of crucial importance to FL , but we do not know what problem it is . Our work is motivated by mounting evidence that ii ) is true ( in the heterogeneous data setting ) , which motivated us to think about iii ) as a possible solution . Indeed , we manage to show that if one thinks of local methods as methods for solving our FL formulation ( 1 ) instead , then they become superior to non-local methods in communication complexity ! This is the first time such superiority of local methods is shown to nonlocal methods in the heterogeneous data regime , which is the most important regime for FL ! Hence , we believe our work is a major conceptual breakthrough in the field . See lines 108-116 : communication complexity of LGD decreases to 0 as $ \\lambda \\to 0 $ . So , if one aims for more personalization ( corresponding to small $ \\lambda $ ) , then local methods will have better and better complexity . In the extreme case when one requires absolute personalization ( $ \\lambda=0 $ ) , each device is simply training a model from their own data only , and no communication is needed . So , this makes very good intuitive sense . Note that , for example , LGD ( one of the most basic variants of FedAvg ) can be interpreted as a SGD with importance sampling applied to ( 1 ) seen as a 2-sum problem . Yes , we did not have to come up with a new analysis for SGD in this case ; we clearly explain this in the paper . So , our novelty here is not in the analysis , which , as you say and as we say in the paper , simply follows from Gower et al ( 2019 ) . The novelty is the insights that SGD applied to ( 1 ) in the way we do it generates LGD ! So , the mystery of the utility of local steps evaporates : they are there to put more emphasis on $ f $ instead of the penalty . However , more emphasis of this type is desired precisely when $ \\lambda $ is small , i.e. , when we require more personalization . So , the key novelty of our paper is that we connect personalization , communication complexity and local methods together , in an insightful manner . Our several new local methods are a secondary contribution . Second concern . We study the effect of how $ \\lambda $ influences the convergence rate and the optimal # of local steps . We do not study which choice of $ \\lambda $ is better from a generalization perspective and hence we ca n't give a theoretical prescription to practitioners of this type . What we mean by saying that `` such purely models are rarely useful '' is this : in practice , devices do not have enough data to be able to train models using their own data only , which is why we need to resort to distributed methods such as FedAvg or LGD . If they had enough data , $ \\lambda=0 $ would be a perfectly fine choice , and there would be no need to do any communication . So , $ \\lambda=0 $ would be optimal and FL in such a data-rich regime would simply reduce to $ n $ independent training problems performed by the devices independently . Yes , $ \\lambda =0 $ leads to the smallest training loss . However , this does not mean we would get the smallest testing loss . Third concern . The reason is simple : the other methods solve a different optimization problem and hence are not comparable . Note that none of these methods outperform their non-local cousins in terms of the comm . complexity in the heterog . data setting ."}, "3": {"review_id": "nLYMajjctMh-3", "review_text": "* * * Strong Personalization is a hardcore problem in FL . The authors target an important problem . The theory analysis seems correct , but the bound seems not tight enough . * * * Weakness Recently , there are many personalized methods proposed for FL . In the I.I.D . setting , local SGD training ( FedAvg ) can obtain similar accuracy as centralized training with a theory guarantee . But in the non-I.I.D . setting , I am curious to know what \u2019 s the ultimate goal of optimization . Can the proposed personalized methods obtain accuracy comparable to centralized training ? If we do not compare with the centralized accuracy , how can we know the optimized personalized model can obtain sufficient accuracy for practical applications . The experimental results are weak . The authors only provide results on the LR model for toy datasets ( LibSVM ) . Without non-convex experiments , it is hard to believe the proposed method works in practice given that DNN-based models dominate nearly all ML tasks . The code style and readability are poor , which discourages the popularity of the proposed method . Although the authors mentioned some contributions of the proposed method , I still can not get what \u2019 s the advantages of the new formulation over conventional Federated optimization ? What is its limitation ? What \u2019 s the cost to use this method ? When should we choose this algorithm in practice ? In which degree of non-IIDness ? Playing with optimization analysis tricks won \u2019 t solve the personalized challenge of federated learning in practice .", "rating": "4: Ok but not good enough - rejection", "reply_text": "This review does not seem to address any substance actually contained in our paper . Instead , it offers general philosophical thoughts related to the general theme of our paper . It is not possible to meaningfully respond to a review of this type . These kids of reviews are not helpful , and actually inflict quite a bit of harm on the community . - `` The bound seems not tight . '' What bound ? We have many . We believe we offer several efficient algorithms , starting with simple ones which are easier to understand ( for pedagogical/clarity reasons ) , and gradually adding features and enhancements ( e.g. , adding control variates , partial participation and so on ) . Your comment is generic and does not address our work . It could have been made without actually reading our paper at all . This comment should be ignored by the AC . - First paragraph in weaknesses : you ask some questions but our paper is not about this . Our contributions are clearly stated and you do not refer to them . You do not seem to have a genuine interest in what we actually accomplished . - Experiments : The results are not weak . Our theory is for convex problems , and the methods are fine-tuned for convex problems . We test the theoretical predictions with carefully designed experiments and observe that our theory predicts what happens in experiments very well . This is the ideal scenario of any scientific work containing theory . The experiments are strong . Testing our methods in the nonconvex regime does not make much sense ; we would need to first develop the associated theory , and this is beyond the scope of the current paper . Not all FL tasks are deep learning tasks . - Code : You criticize the readability of our code , but offer no concrete evidence of what is wrong . Again , this is a generic comment that could have been made about any paper containing a method . This kind of a comment is not helpful . If you found concrete issues , list them . We are happy to correct and improve our paper , but we ca n't do this if issues are not pointed out to us . - Last paragraph : These are again comments divorced from the actual contents and contributions of our paper . It is very clear to us that this reviewer simply failed to understand our work and contributions . Or perhaps the reviewer even did not read the work properly . In any case , it is not possible to respond meaningfully to a review that fails to address the evaluated paper to such a degree as this review manages to do so ."}}