{"year": "2021", "forum": "wQRlSUZ5V7B", "title": "Capturing Label Characteristics in VAEs", "decision": "Accept (Poster)", "meta_review": "This paper proposes a novel technique to learn a disentangled latent space using VAEs and semi-supervision. The technique is based on a careful specification of the joint distribution where the labels inform a factorisation of the distribution over continuous latent factors. The technique allows for inference, generation, and intervention in a tractable way.\n\nThe paper is well-written, the formulation is original, and the experiments convincing. There were some confusions that were mostly resolved during the discussion.  \n\nIn addition to the expert reviews attached, I would like to remark that I too find the formulation interesting and elegant. And if I may add to the discussion, oiVAE (output-interpretable VAEs) by Ainsworth et al presented at ICML18 is a related piece of work that did not occur to me earlier, but which the authors could still relate to (I'd certainly enjoy reading about the authors' views on that line of work). ", "reviews": [{"review_id": "wQRlSUZ5V7B-0", "review_text": "This paper focuses on latent representations learning when some labels are provided . The authors propose a method called the characteristic capturing VAE ( CCVAE ) . This method learns real-valued auxiliary variables that capture the label information . The proposed method is tested on a medical image and a face image dataset . One of the major motivations of the proposed method is that it can be used to conditionally generate images based on desired characteristics . However , this paper proposes a VAE model , which usually generates lower-quality images compared to Generative Adversarial Networks ( GAN ) . It is not clear to me why this paper focuses on a VAE model rather than a GAN model . There have been GAN-based methods [ 1 , 2 ] also based on an auto-encoding framework . Note that if we remove the adversarial loss from the objective functions of these methods , and add the KL divergence penalty , these methods become VAE . Since these methods also introduce real-value variables , I believe the authors should compare to the VAE-version of these methods . In addition , in the VAE literature , [ 3 ] proposes a semi-supervised method . Since [ 3 ] also involves a real-value latent variable , it looks like the difference between the proposed method and [ 3 ] is that the author extends [ 3 ] to multiple labels . Is this true ? I suggest the authors better clarify the novelty of the proposed method compared to [ 3 ] . I do not suggest accepting this paper because the relationships to some existing methods are not sufficiently discussed . Minor : In the experiments , the paper reports the quantitative measures for classification and disentanglement . However , no quantitative measures for image quality are reported . I suggest the authors report some measures such as reconstruction error and FID score . References [ 1 ] Xiao , Taihong , Jiapeng Hong , and Jinwen Ma . `` DNA-GAN : Learning disentangled representations from multi-attribute images . '' International Conference on Learning Representation Workshop . 2018 . [ 2 ] Xiao , Taihong , Jiapeng Hong , and Jinwen Ma . `` Elegant : Exchanging latent encodings with gan for transferring multiple face attributes . '' Proceedings of the European conference on computer vision ( ECCV ) . 2018 . [ 3 ] Li , Yang , et al . `` Disentangled variational auto-encoder for semi-supervised learning . '' Information Sciences 482 ( 2019 ) : 73-85 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank you for your review and effort to help us improve our submission . We hope our response below ( and associated paper update ) alleviates some of your concerns and hope you will consider increasing your score if it does . In particular , we would ask you to consider the fact that large numbers of papers on VAEs are published at ICLR each year , such that the fact the paper is based around VAEs should not itself be a reason for rejection . * _ \u201c It is not clear to me why this paper focuses on a VAE model rather than a GAN model \u201d _ : The primary contribution of this submission is demonstrating how labels should be used to obtain interpretable/manipulatable representations , for which VAEs are a suitable and popular model . Though GANs tend to have better generative capabilities , they are not generally considered superior from a representation learning perspective ( and arguably are actually less effective here ) . Moreover , many aspects of both our conceptual contributions and our algorithmic approach would not be directly applicable to a GAN setting ; our contributions to the literature would not be possible without taking a VAE approach . Indeed , the flexibility of the VAE framework to allow innovations like ours are one of its greatest strengths . * _ \u201c I do not suggest accepting this paper because the relationships to some existing methods are not sufficiently discussed. \u201d _ : Though we have gladly added references and a short discussion to the paper on these works , we point out that they are of less relevance to the work than many more closely related papers already discussed . For example , [ 1 ] and [ 2 ] are based on a completely different model class and do not allow the same range of tasks to be performed . [ 3 ] is an extension to M2 , which is already discussed extensively , and its extensions relative to M2 do not themselves seem to relate to our contributions . Taking this into account , we do not feel that this is a justified reason for rejecting the paper , particularly now the citations and discussion have been added , and ask the reviewer to reconsider their score accordingly . * _ \u201c I believe the authors should compare to the VAE-version of [ [ 1 ] and [ 2 ] ] \u201d _ : This is unfortunately not feasible . Such methods do not currently exist in the literature and would be novel contributions in their own right . Moreover , they are less relevant baselines than those already compared to . * _ \u201c I suggest the authors report some measures such as reconstruction error and FID score. \u201d _ : We would like to point out that there are the more relevant generative classification accuracies presented in the Appendix along with MI scores for MNIST and FashionMNIST : unconditional generation is not the aim of this work and FID is far from an absolute measure of visual fidelity , meaning it is of little relevance to our aims . Nonetheless , we have added FID scores as per your request to Appendix E.3 , where we see that these are almost identical for CCVAE and M2 as one would expect . We opted not to report reconstruction error as this metric provides little intuition regarding the disentangled nature of the latent space and adds little beyond the FID scores themselves . We can still add this if you think it is necessary though ."}, {"review_id": "wQRlSUZ5V7B-1", "review_text": "Update after rebuttal : the authors have clarified some of my concerns , and I have therefore increased my score . This paper introduces the characteristic-capturing VAE , an architecture that extends VAEs by modelling label-dependent characteristics in generative and classification tasks . In a multi-label setting , the CCVAE learns representations of individual characteristics , which are disentangled by design to the one of other labels . The paper is well written in general , and is a good contribution to the important research direction on deep generative models focusing on using some labelled data to learn a disentangled latent space . The experiments in the paper are well thought and show convincing performances in terms of label-dependent generations and interventions . My biggest doubts are in terms of the positioning/novelty of the paper , which I found a bit confusing/misleading in the current form . When `` rethinking supervision '' the authors argue for the need of treating labels as auxiliary variables - and not as latent variables - in the model . This leads to the formulation called ALVAE , that introduces label-dependent information in latent space learning jointly a classifier from z to y . This formulation is novel as far as I know , but leads to some challenges mentioned by the authors in terms of conditional generation/intervention with this model . The authors then offer as a solution the CCVAE , which uses a conditional generative model p ( z_c|y ) p ( y ) . * Is y in a CCVAE still an auxiliary variable ? To me it seems that the benefits of the CCVAE are not due to the auxiliary nature of y , but more from the fact that y is now a partially observed latent variable that is however only connected to x through continuous latent variables . If this is the case , why is it relevant to leave in the paper the whole ALVAE discussion which is purely theoretical and not even presented in the experiments ? Perhaps the authors should focus more instead on clarifying even further on the benefits of the hierarchical generative architectures y- > z- > x . * The discussions in section 3 are valid for 1-layer models such as M2 or MVAE models in which z_y=y . This discussion is not however considering hierarchical VAE architectures for semi-supervised learning , such as the one presented in `` Semi-Supervised Generation with Cluster-aware Generative Models '' by Maal\u00f8e et al , 2017 . These architectures also learn a latent space that captures the information associated with a class , not just the class itself , and do so without the need for `` auxiliary '' variables . Is there any advantage of the CCVAE has with respect to this model ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "* \u201d _The discussions in section 3 are valid for 1-layer models such as M2 or MVAE models in which_ z_y=y . _This discussion is not however considering hierarchical VAE architectures for semi-supervised learning , such as the one presented in `` Semi-Supervised Generation with Cluster-aware Generative Models '' by Maal\u00f8e et al , 2017 . These architectures also learn a latent space that captures the information associated with a class , not just the class itself , and do so without the need for `` auxiliary '' variables_ '' . The connection to hierarchical semi-supervised VAEs is indeed an interesting one , and something we are keen to explore going forward in the context of our model . Thank you for your pointer to Maal\u00f8e et al. , 2017 [ 1 ] . It is important to note however that where such models employ semi-supervised learning [ 1,2 ] , the intention appears to be to incorporate labels in much the same fashion as M2 by treating labels as a latent in addition to the hierarchy of $ \\textbf { z } _i $ variables , see Figure 2 in [ 1 ] and Appendix F in [ 2 ] , for an example . While the latent variables do capture some notion of hierarchy information from the data ( eg.Figure 5 of [ 1 ] ) , there is no constraint to disentangle the characteristic information of the label ( what we refer to as $ \\textbf { z } _c $ ) from information in the data that is independent of all labels ( what we refer to as $ \\textbf { z } _\\c $ ) . It would indeed be an interesting question to explore how using $ \\textbf { y } $ as an auxiliary variable applies in the hierarchical latent case , but that is beyond the scope of this work . We have included references to hierarchical models in our updated manuscript . [ 1 ] Semi-Supervised Generation with Cluster-aware Generative Models , Maal\u00f8e et al. , 2017 [ 2 ] BIVA : A Very Deep Hierarchy of Latent Variables for Generative Modeling , Maal\u00f8e et al. , 2019 * _ \u201c Is there any advantage of the CCVAE has with respect to this model ? \u201d _ : Yes indeed : a. CCVAE is simpler ; it does n't require extra latent variables b. CCVAE has a sound objective that targets the actual variational free energy whereas CaGeM employs additional regularisers with associated hyperparameters . c. CCVAE can perform explicit manipulations of characteristics such as characteristic swaps ( Figure 7 ) ; something that CaGeM can not do because it does not have latent variables independent of labels d. CCVAE demonstrates its utility and performance on more complex data such as CelebA and Chexpert"}, {"review_id": "wQRlSUZ5V7B-2", "review_text": "In this paper the authors have propsed a method to incorporate label information in variational autoencoders ( VAEs ) to captures the characteristics associated with those labels . Experiments show that using the label information helps them to better intervation and conditional generation of images . The paper is well written . However I have few concern regarding the model . Firstly the paper has not cited a very important related work by Adel , Tameem , Zoubin Ghahramani , and Adrian Weller . `` Discovering interpretable representations for both deep generative and discriminative models . '' International Conference on Machine Learning . 2018. where a similar hiererchical approach was proposed . The authors should provide a discussion related to this method or if possible should compare their performance by extending the previous model for multiple features . The main concerns regarding the model perspective are as follows : 1 . How the authors ensuring that there is no mutual information between the parts z_c and z_\\c ? There is no analysis regarding the same . They should report some quanitative measures as proposed by betaVae to support the same . 2.How they are controlling the KLD between encoding and decoing distribution i.e KL ( q ( z|x ) || p ( z| z_c ) ) and KL ( q ( z_c|z ) || p ( z_c|y ) ) ? If the first kl is not significantly low , there will be information loss which might affect the quality of the overall generation ? They should report the KL achieved in each layer . 3.As they are learning the reverse mapping from a given label to corresponding representation i.e.p_\\theta ( z_c | y ) -- is it necessary to make z_c unidimensional for interpolation ? How are they learning the correspondance between fin grained values of y and z_c ? do they have such label information available ?", "rating": "5: Marginally below acceptance threshold", "reply_text": "_ \u201c Adel et al 2018 \u201d _ Thank you for bringing the work of Adel et al.to our notice ; the JLVM model in particular is indeed relevant . We however note that while their graphical model bears some close resemblance to ours , there are quite distinct differences between their and our approaches . Model : The JLVM model can be viewed as a VAE with a normalising flow-based posterior that additionally includes side-channel information to influence the latent $ z^ * $ . From that perspective , the JLVM model is closer to the MVAE model ( Wu & Goodman , 2018 ) than to ours , as the conditional distribution $ p ( z^ * | s ) $ is viewed as a posterior rather than a prior ( and vice versa with $ p ( s | z^ * ) $ ) . Moreover , given the difference in information content between $ x $ and $ s $ , having both project to exactly the same latent space $ z^ * $ results in an imbalancesomething we explicitly account for by only jointly projecting to $ z_c $ , and leaving $ z_\\c $ to capture the residual information from $ x $ \\ $ s $ ( or y as we denote it ) , as shown in Figure 2 . It is this explicit factorisation that allows us to perform 'characteristics swaps ' ( Figure 7 ) , which would otherwise be infeasible as with the comparison models , and with the JLVM ( or indeed the ILVM ) model.\\rObjective : For the JLVM model , the objective considered is also quite different in that it involves the ( unweighted ) concatenation of the total marginal likelihood over data and the ( bounded ) information bottleneck ( IB ) estimator . Note that for continuous latents $ z^ * $ , this means that the objective is not guaranteed to target the variational free energy anymoresomething our objective preserves . Moreover , the proposed objective has two potential hyperparameters to tweak : \\beta corresponding to the IB margin , and the relative weight between the total marginal likelihood and the bounded IB estimator which is implicitly taken to be 1.0 . Our objective on the other hand needs no extra hyperparameters ."}, {"review_id": "wQRlSUZ5V7B-3", "review_text": "* * GENERAL * * The paper proposes to re-think the fashion of using label information in the VAE framework . The authors propose to disentangle information about the label ( or , more generally , the context ) in a `` hard-coded '' manner , namely , by using a separate set of variables for the label ( context ) . The paper is written in a lucid manner , and the presented results are sound . * * Strengths : * * S1 : The presented VAE framework ( CCVAE ) is interesting . S2 : The final objective in Eq . ( 6 ) that follows from applying Jensen 's inequality two times , allows to efficiently train the model . Moreover , it allows the use of interventions to modify information about images . S3 : The demo is a nice fashion of presenting the idea . S4 : I highly appreciate that the authors used a dataset outside of standard benchmarks , and they focused on a medical application ( the Chexpert dataset ) . S5 : The authors explained all implementation details that increases reproducibility of the paper . S6 : I appreciate the close relation of the propose framework to other models , e.g. , DIVA . Moreover , the idea of improving upon DIVA is very interesting . * * Deficiencies : * * D1 : My only concern is rather average generative capabilities of the model . Nevertheless , it does not affect my overall good assessment of the paper . * * Remarks : * * R1 : In Eq.2 , there is a fudge factor , \\alpha . However , in the CCVAE objective ( Eq.4 ) it is no longer necessary . I would like to ask the authors whether they thought about adding this fudge factor , or it is simply unnecessary . ( I am aware that q ( y|x ) follows naturally from the objective , nevertheless , it might further improve the classification accuracy ) .", "rating": "7: Good paper, accept", "reply_text": "We would like to thank you for your hard work and positive feedback . In particular , we appreciate the effort you have undertaken to understand and convey the nuances and underlying concepts of our paper that set it apart from other work . * _ \u201c [ Fudge factor ] \u201d _ : The idea of a fudge factor is an interesting one and something we did actually consider , but generally found provided little improvement . Our setup effectively allows for a natural scaling of the classification pressure and the fact that we achieve such good results without such heuristics or hyperparameters is , in our opinion , a real strength of the paper . We did find that improving the flexibility of the classifier helped improve the accuracy for the MNIST/FashionMNIST experiments , see Appendix E.5 . We believe that this is because in contrast to other approaches our objective corresponds to the variational free energy of the model ."}], "0": {"review_id": "wQRlSUZ5V7B-0", "review_text": "This paper focuses on latent representations learning when some labels are provided . The authors propose a method called the characteristic capturing VAE ( CCVAE ) . This method learns real-valued auxiliary variables that capture the label information . The proposed method is tested on a medical image and a face image dataset . One of the major motivations of the proposed method is that it can be used to conditionally generate images based on desired characteristics . However , this paper proposes a VAE model , which usually generates lower-quality images compared to Generative Adversarial Networks ( GAN ) . It is not clear to me why this paper focuses on a VAE model rather than a GAN model . There have been GAN-based methods [ 1 , 2 ] also based on an auto-encoding framework . Note that if we remove the adversarial loss from the objective functions of these methods , and add the KL divergence penalty , these methods become VAE . Since these methods also introduce real-value variables , I believe the authors should compare to the VAE-version of these methods . In addition , in the VAE literature , [ 3 ] proposes a semi-supervised method . Since [ 3 ] also involves a real-value latent variable , it looks like the difference between the proposed method and [ 3 ] is that the author extends [ 3 ] to multiple labels . Is this true ? I suggest the authors better clarify the novelty of the proposed method compared to [ 3 ] . I do not suggest accepting this paper because the relationships to some existing methods are not sufficiently discussed . Minor : In the experiments , the paper reports the quantitative measures for classification and disentanglement . However , no quantitative measures for image quality are reported . I suggest the authors report some measures such as reconstruction error and FID score . References [ 1 ] Xiao , Taihong , Jiapeng Hong , and Jinwen Ma . `` DNA-GAN : Learning disentangled representations from multi-attribute images . '' International Conference on Learning Representation Workshop . 2018 . [ 2 ] Xiao , Taihong , Jiapeng Hong , and Jinwen Ma . `` Elegant : Exchanging latent encodings with gan for transferring multiple face attributes . '' Proceedings of the European conference on computer vision ( ECCV ) . 2018 . [ 3 ] Li , Yang , et al . `` Disentangled variational auto-encoder for semi-supervised learning . '' Information Sciences 482 ( 2019 ) : 73-85 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank you for your review and effort to help us improve our submission . We hope our response below ( and associated paper update ) alleviates some of your concerns and hope you will consider increasing your score if it does . In particular , we would ask you to consider the fact that large numbers of papers on VAEs are published at ICLR each year , such that the fact the paper is based around VAEs should not itself be a reason for rejection . * _ \u201c It is not clear to me why this paper focuses on a VAE model rather than a GAN model \u201d _ : The primary contribution of this submission is demonstrating how labels should be used to obtain interpretable/manipulatable representations , for which VAEs are a suitable and popular model . Though GANs tend to have better generative capabilities , they are not generally considered superior from a representation learning perspective ( and arguably are actually less effective here ) . Moreover , many aspects of both our conceptual contributions and our algorithmic approach would not be directly applicable to a GAN setting ; our contributions to the literature would not be possible without taking a VAE approach . Indeed , the flexibility of the VAE framework to allow innovations like ours are one of its greatest strengths . * _ \u201c I do not suggest accepting this paper because the relationships to some existing methods are not sufficiently discussed. \u201d _ : Though we have gladly added references and a short discussion to the paper on these works , we point out that they are of less relevance to the work than many more closely related papers already discussed . For example , [ 1 ] and [ 2 ] are based on a completely different model class and do not allow the same range of tasks to be performed . [ 3 ] is an extension to M2 , which is already discussed extensively , and its extensions relative to M2 do not themselves seem to relate to our contributions . Taking this into account , we do not feel that this is a justified reason for rejecting the paper , particularly now the citations and discussion have been added , and ask the reviewer to reconsider their score accordingly . * _ \u201c I believe the authors should compare to the VAE-version of [ [ 1 ] and [ 2 ] ] \u201d _ : This is unfortunately not feasible . Such methods do not currently exist in the literature and would be novel contributions in their own right . Moreover , they are less relevant baselines than those already compared to . * _ \u201c I suggest the authors report some measures such as reconstruction error and FID score. \u201d _ : We would like to point out that there are the more relevant generative classification accuracies presented in the Appendix along with MI scores for MNIST and FashionMNIST : unconditional generation is not the aim of this work and FID is far from an absolute measure of visual fidelity , meaning it is of little relevance to our aims . Nonetheless , we have added FID scores as per your request to Appendix E.3 , where we see that these are almost identical for CCVAE and M2 as one would expect . We opted not to report reconstruction error as this metric provides little intuition regarding the disentangled nature of the latent space and adds little beyond the FID scores themselves . We can still add this if you think it is necessary though ."}, "1": {"review_id": "wQRlSUZ5V7B-1", "review_text": "Update after rebuttal : the authors have clarified some of my concerns , and I have therefore increased my score . This paper introduces the characteristic-capturing VAE , an architecture that extends VAEs by modelling label-dependent characteristics in generative and classification tasks . In a multi-label setting , the CCVAE learns representations of individual characteristics , which are disentangled by design to the one of other labels . The paper is well written in general , and is a good contribution to the important research direction on deep generative models focusing on using some labelled data to learn a disentangled latent space . The experiments in the paper are well thought and show convincing performances in terms of label-dependent generations and interventions . My biggest doubts are in terms of the positioning/novelty of the paper , which I found a bit confusing/misleading in the current form . When `` rethinking supervision '' the authors argue for the need of treating labels as auxiliary variables - and not as latent variables - in the model . This leads to the formulation called ALVAE , that introduces label-dependent information in latent space learning jointly a classifier from z to y . This formulation is novel as far as I know , but leads to some challenges mentioned by the authors in terms of conditional generation/intervention with this model . The authors then offer as a solution the CCVAE , which uses a conditional generative model p ( z_c|y ) p ( y ) . * Is y in a CCVAE still an auxiliary variable ? To me it seems that the benefits of the CCVAE are not due to the auxiliary nature of y , but more from the fact that y is now a partially observed latent variable that is however only connected to x through continuous latent variables . If this is the case , why is it relevant to leave in the paper the whole ALVAE discussion which is purely theoretical and not even presented in the experiments ? Perhaps the authors should focus more instead on clarifying even further on the benefits of the hierarchical generative architectures y- > z- > x . * The discussions in section 3 are valid for 1-layer models such as M2 or MVAE models in which z_y=y . This discussion is not however considering hierarchical VAE architectures for semi-supervised learning , such as the one presented in `` Semi-Supervised Generation with Cluster-aware Generative Models '' by Maal\u00f8e et al , 2017 . These architectures also learn a latent space that captures the information associated with a class , not just the class itself , and do so without the need for `` auxiliary '' variables . Is there any advantage of the CCVAE has with respect to this model ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "* \u201d _The discussions in section 3 are valid for 1-layer models such as M2 or MVAE models in which_ z_y=y . _This discussion is not however considering hierarchical VAE architectures for semi-supervised learning , such as the one presented in `` Semi-Supervised Generation with Cluster-aware Generative Models '' by Maal\u00f8e et al , 2017 . These architectures also learn a latent space that captures the information associated with a class , not just the class itself , and do so without the need for `` auxiliary '' variables_ '' . The connection to hierarchical semi-supervised VAEs is indeed an interesting one , and something we are keen to explore going forward in the context of our model . Thank you for your pointer to Maal\u00f8e et al. , 2017 [ 1 ] . It is important to note however that where such models employ semi-supervised learning [ 1,2 ] , the intention appears to be to incorporate labels in much the same fashion as M2 by treating labels as a latent in addition to the hierarchy of $ \\textbf { z } _i $ variables , see Figure 2 in [ 1 ] and Appendix F in [ 2 ] , for an example . While the latent variables do capture some notion of hierarchy information from the data ( eg.Figure 5 of [ 1 ] ) , there is no constraint to disentangle the characteristic information of the label ( what we refer to as $ \\textbf { z } _c $ ) from information in the data that is independent of all labels ( what we refer to as $ \\textbf { z } _\\c $ ) . It would indeed be an interesting question to explore how using $ \\textbf { y } $ as an auxiliary variable applies in the hierarchical latent case , but that is beyond the scope of this work . We have included references to hierarchical models in our updated manuscript . [ 1 ] Semi-Supervised Generation with Cluster-aware Generative Models , Maal\u00f8e et al. , 2017 [ 2 ] BIVA : A Very Deep Hierarchy of Latent Variables for Generative Modeling , Maal\u00f8e et al. , 2019 * _ \u201c Is there any advantage of the CCVAE has with respect to this model ? \u201d _ : Yes indeed : a. CCVAE is simpler ; it does n't require extra latent variables b. CCVAE has a sound objective that targets the actual variational free energy whereas CaGeM employs additional regularisers with associated hyperparameters . c. CCVAE can perform explicit manipulations of characteristics such as characteristic swaps ( Figure 7 ) ; something that CaGeM can not do because it does not have latent variables independent of labels d. CCVAE demonstrates its utility and performance on more complex data such as CelebA and Chexpert"}, "2": {"review_id": "wQRlSUZ5V7B-2", "review_text": "In this paper the authors have propsed a method to incorporate label information in variational autoencoders ( VAEs ) to captures the characteristics associated with those labels . Experiments show that using the label information helps them to better intervation and conditional generation of images . The paper is well written . However I have few concern regarding the model . Firstly the paper has not cited a very important related work by Adel , Tameem , Zoubin Ghahramani , and Adrian Weller . `` Discovering interpretable representations for both deep generative and discriminative models . '' International Conference on Machine Learning . 2018. where a similar hiererchical approach was proposed . The authors should provide a discussion related to this method or if possible should compare their performance by extending the previous model for multiple features . The main concerns regarding the model perspective are as follows : 1 . How the authors ensuring that there is no mutual information between the parts z_c and z_\\c ? There is no analysis regarding the same . They should report some quanitative measures as proposed by betaVae to support the same . 2.How they are controlling the KLD between encoding and decoing distribution i.e KL ( q ( z|x ) || p ( z| z_c ) ) and KL ( q ( z_c|z ) || p ( z_c|y ) ) ? If the first kl is not significantly low , there will be information loss which might affect the quality of the overall generation ? They should report the KL achieved in each layer . 3.As they are learning the reverse mapping from a given label to corresponding representation i.e.p_\\theta ( z_c | y ) -- is it necessary to make z_c unidimensional for interpolation ? How are they learning the correspondance between fin grained values of y and z_c ? do they have such label information available ?", "rating": "5: Marginally below acceptance threshold", "reply_text": "_ \u201c Adel et al 2018 \u201d _ Thank you for bringing the work of Adel et al.to our notice ; the JLVM model in particular is indeed relevant . We however note that while their graphical model bears some close resemblance to ours , there are quite distinct differences between their and our approaches . Model : The JLVM model can be viewed as a VAE with a normalising flow-based posterior that additionally includes side-channel information to influence the latent $ z^ * $ . From that perspective , the JLVM model is closer to the MVAE model ( Wu & Goodman , 2018 ) than to ours , as the conditional distribution $ p ( z^ * | s ) $ is viewed as a posterior rather than a prior ( and vice versa with $ p ( s | z^ * ) $ ) . Moreover , given the difference in information content between $ x $ and $ s $ , having both project to exactly the same latent space $ z^ * $ results in an imbalancesomething we explicitly account for by only jointly projecting to $ z_c $ , and leaving $ z_\\c $ to capture the residual information from $ x $ \\ $ s $ ( or y as we denote it ) , as shown in Figure 2 . It is this explicit factorisation that allows us to perform 'characteristics swaps ' ( Figure 7 ) , which would otherwise be infeasible as with the comparison models , and with the JLVM ( or indeed the ILVM ) model.\\rObjective : For the JLVM model , the objective considered is also quite different in that it involves the ( unweighted ) concatenation of the total marginal likelihood over data and the ( bounded ) information bottleneck ( IB ) estimator . Note that for continuous latents $ z^ * $ , this means that the objective is not guaranteed to target the variational free energy anymoresomething our objective preserves . Moreover , the proposed objective has two potential hyperparameters to tweak : \\beta corresponding to the IB margin , and the relative weight between the total marginal likelihood and the bounded IB estimator which is implicitly taken to be 1.0 . Our objective on the other hand needs no extra hyperparameters ."}, "3": {"review_id": "wQRlSUZ5V7B-3", "review_text": "* * GENERAL * * The paper proposes to re-think the fashion of using label information in the VAE framework . The authors propose to disentangle information about the label ( or , more generally , the context ) in a `` hard-coded '' manner , namely , by using a separate set of variables for the label ( context ) . The paper is written in a lucid manner , and the presented results are sound . * * Strengths : * * S1 : The presented VAE framework ( CCVAE ) is interesting . S2 : The final objective in Eq . ( 6 ) that follows from applying Jensen 's inequality two times , allows to efficiently train the model . Moreover , it allows the use of interventions to modify information about images . S3 : The demo is a nice fashion of presenting the idea . S4 : I highly appreciate that the authors used a dataset outside of standard benchmarks , and they focused on a medical application ( the Chexpert dataset ) . S5 : The authors explained all implementation details that increases reproducibility of the paper . S6 : I appreciate the close relation of the propose framework to other models , e.g. , DIVA . Moreover , the idea of improving upon DIVA is very interesting . * * Deficiencies : * * D1 : My only concern is rather average generative capabilities of the model . Nevertheless , it does not affect my overall good assessment of the paper . * * Remarks : * * R1 : In Eq.2 , there is a fudge factor , \\alpha . However , in the CCVAE objective ( Eq.4 ) it is no longer necessary . I would like to ask the authors whether they thought about adding this fudge factor , or it is simply unnecessary . ( I am aware that q ( y|x ) follows naturally from the objective , nevertheless , it might further improve the classification accuracy ) .", "rating": "7: Good paper, accept", "reply_text": "We would like to thank you for your hard work and positive feedback . In particular , we appreciate the effort you have undertaken to understand and convey the nuances and underlying concepts of our paper that set it apart from other work . * _ \u201c [ Fudge factor ] \u201d _ : The idea of a fudge factor is an interesting one and something we did actually consider , but generally found provided little improvement . Our setup effectively allows for a natural scaling of the classification pressure and the fact that we achieve such good results without such heuristics or hyperparameters is , in our opinion , a real strength of the paper . We did find that improving the flexibility of the classifier helped improve the accuracy for the MNIST/FashionMNIST experiments , see Appendix E.5 . We believe that this is because in contrast to other approaches our objective corresponds to the variational free energy of the model ."}}