{"year": "2019", "forum": "H1xQSjCqFQ", "title": "Excitation Dropout: Encouraging Plasticity in Deep Neural Networks", "decision": "Reject", "meta_review": "The reviewers overall agree that excitation dropout is a novel idea that seems to produce good empirical performance. However, they remain optimistic, but unconvinced by the experiments in their current form. The authors have done an admiral job of addressing this through more experiments, including providing error bars, however it seems as though the reviewers still require more. I would recommend creating tables of architecture x dropout technique, where dropout technique includes information dropout, adaptive dropout, curriculum dropout, and standard dropout, across several standard datasets. Alternatively, the authors could try to be more ambitious and classify Imagenet. Essentially, it seems as though the current small-scale datasets have become somewhat saturated, and therefore the bar for gauging a new method on them is higher in terms of experimental rigor. This means the best strategy is to either try more difficult benchmarks, or be extremely thorough and complete in your experiments.\n\nRegarding the wide resnet result, while I can appreciate that the original version published with higher errors, the later draft should still be taken into account as it has a) been out for a while now and b) can been reproduced in open source implementations (e.g., https://github.com/szagoruyko/wide-residual-networks).", "reviews": [{"review_id": "H1xQSjCqFQ-0", "review_text": "This paper presents a variation of dropout, where the proposed method drops with higher probability those neurons which contribute more to decision making at training time. This idea is evaluated on several standard datasets for image classification and action recognition. Pros: 1. This paper has interesting idea related to dropout, and shows some benefit. 2. Paper is well-written and easy to understand. Cons: 1. There are many variations in dropouts and they all claim superiority to others. Unfortunately, most of them are not justified properly. Excitation dropout looks interesting and has potential, but its validation is not strong enough. Use of Cifar10/100, Caltech256, and UCF 101 may be okay for concept proofing, but not be sufficient for thorough validation. Also, the reported results are far from the state-of-the-art performance of each dataset. I would recommended to add the idea to the network to achieve the state-of-the-art performance because it will show real extra benefit of \"excitation\" dropout. 2. There are many variations of dropouts including variational dropout, L0-regularization, and adaptive dropout, and the paper needs to report their accuracy in addition to curriculum dropout. 3. Dropout does not exist in many modern deep neural networks and its usability is a bit weak. It would be better to generalize this idea and make it applicable to ResNet-style networks. 4. There is no clear (theoretical) justification and intuition why excitation dropout improves performance. More ablation study with internal analysis would be helpful. Overall, this paper has interesting idea but needs more efforts to make the idea convincing.", "rating": "5: Marginally below acceptance threshold", "reply_text": "1.Adaptive Dropout ( NIPS \u2019 13 ) reported results on MNIST and NORB , Information Dropout ( TPAMI \u2019 18 ) and Variational Dropout ( NIPS \u2019 15 ) reported results on MNIST and Cifar10 , Curriculum Dropout ( ICCV \u2019 17 ) reported results on MNIST , Cifar10/100 , and Caltech101/256 . In this work , we present results on the small scale dataset Caltech256 having ~18K images ( but 256 classes ) , the medium scale datasets Cifar10/100 having ~60K images ( 10/100 classes ) , and on the larger scale UCF101 dataset which has ~13K videos ( 101 classes ) , from which we sample 2M frames . Dropout is adopted in WideResNet which is used to obtain state-of-the-art results on Cifar10 . We gladly provide Excitation Dropout performance results for WideResNet ( WRN-28-10 ) on Cifar10 : 3.88 % test error ( vs. 4.17 % Zagoruyko et al. \u2019 s published result , BMVC \u2019 16 ) . Therefore , Excitation Dropout gives state-of-the-art result on Cifar10 . 2.Comparison against Adaptive Dropout was included in the Appendix ( section titled : Least vs. most relevant neurons ) of our original submission , and we referred to it in the middle of page 4 of our original manuscript . In that section we discuss how Adaptive Dropout and Excitation Dropout use opposite strategies of neuron selection : Adaptive Dropout drops with a higher probability the least active neurons , while Excitation Dropout drops with higher probability the most relevant neurons . We note that Adaptive Dropout was originally introduced for an autoencoder architecture . Variational Dropout ( NIPS \u2019 15 ) reports results on MNIST and Cifar10 only . The best result reported by Variational Dropout on Cifar10 has error ~23 % , while Excitation Dropout with a CNN-2 architecture has error ~18 % and with a WideResNet architecture has ~4 % error . 3.Dropout is one of the most important regularization techniques for deep learning and it is also adopted in WideResNet . ResNet and DenseNet architectures do not have dropout layers , and rely on batch normalization for regularization . Effectiveness of regularization methods for training neural networks is dependent on the architecture and training process , and is still an open problem ( e.g. , batch normalization can not handle small batches ) . Moreover , please note how the following dropout papers deal with computationally heavy experiments . Curriculum Dropout ( ICCV \u2019 17 ) uses two variants of somewhat shallow networks , LeNet and the deeper version CNN-2 we also use . Variational Dropout ( NIPS \u2019 15 ) and Dropout ( JMLR \u2019 14 ) use an architecture with 3 hidden layers . Adaptive Dropout ( NIPS \u2019 13 ) uses a one-hidden-layer autoencoder . We present experiments on the medium-scale network CNN-2 for datasets trained from scratch , and on the deeper AlexNet , VGG16 , and VGG19 for the larger dataset UCF101 where fine-tuning is sufficient . We also gladly provide results for Cifar10 on WideResNet and for Caltech256 on the deeper AlexNet , VGG16 , and VGG19 in the Appendix ( section titled : Validation on Multiple Architectures ) . 4.Dropout is a model averaging technique . Averaging models having less specialized neurons results in higher robustness to information loss . In Table 2 we demonstrate that Excitation Dropout has less specialized neurons ( lower saliency peaks and higher entropy ) , as compared to Standard and Curriculum Dropout for all datasets considered ( Cifar10/100 , Caltech256 and UCF101 ) . In addition , Table 2 presents an internal analysis of the network filters demonstrating that a lower number of stale/conservative filters for Excitation Dropout ( as compared to Standard and Curriculum Dropout ) is achieved . These considerations are now better highlighted in the last paragraph of Section 4.3 ."}, {"review_id": "H1xQSjCqFQ-1", "review_text": "This is an interesting idea that seems to do better than regular dropout. However, the experiment seem a bit artificial, starting with less modern network designs (VGG) that can benefit from adding dropout. State of the art computer vision networks don't seem to need dropout so much, so the impact of the paper is unclear. Section 4.4: How does this compare to state-of-the-art network compression techniques? (Deep compression, etc) ", "rating": "5: Marginally below acceptance threshold", "reply_text": "1.Dropout is one of the most important regularization techniques for deep learning -adopted in WideResNet which is used to obtain state-of-the-art results on Cifar10 . We gladly provide Excitation Dropout performance results for WideResNet ( WRN-28-10 ) on Cifar10 : 3.88 % test error ( vs. 4.17 % Zagoruyko et al. \u2019 s published result , BMVC \u2019 16 ) . Therefore , Excitation Dropout gives state-of-the-art result on Cifar10 . This is now reported in the Appendix ( section titled : Validation on Multiple Architectures ) . Some modern network architectures like ResNet and DenseNet do not have dropout layers , and rely on batch normalization for regularization . However , this does not preclude research on dropout : Ghiasi et al . ( NIPS \u2019 18 ) , Achille et al . ( TPAMI \u2019 18 ) , Cavazza et al . ( AISTATS \u2019 18 ) , Morerio et al . ( ICCV \u2019 17 ) , Kang et al . ( TPAMI \u2019 17 ) , Molchanov et al . ( PMLR \u2019 17 ) . Effectiveness of regularization methods for training neural networks is dependent on the architecture and training process , and is still an open problem ( e.g.batch normalization can not handle small batches ) . 2.In this work , we are not proposing a network compression technique . We propose a technique that improves network generalization on unseen data by increasing the utilization of network neurons and learning alternative paths . We then demonstrate that learning alternative paths also results in added resilience to network compression ."}, {"review_id": "H1xQSjCqFQ-2", "review_text": "The authors propose a data-dependent dropout variant that produces dropout candidates based on their predictive saliency / relevance. Results are reported for 4 datasets (Cifar10, Cifar100, Caltech256 and UCF101) and 4 different models (CNN-2, AlexNet, VGG16 and VGG19), and suggest an increase in generalization performance over other dropout approaches (curriculum dropout, standard dropout, no dropout), as well as increase in the network's plasticity as measured by some existing metrics from the literature. The authors conclude that Excitation Dropout results in better network utilization and offers advantages for network compression (in the sense of neuron pruning). Overall I find the idea to be interesting and fairly novel, and commend the authors for the fluid writing style. However, I find key issues with the testing and experiments. Specifically, the lack of confidence bounds for individual results makes it impossible to determine whether the reported incremental improvements are actually significant over those of existing approaches. Likewise, I criticize the choice of methods the authors have chosen to compare against, as several other data-dependent dropout approaches (e.g. Information Dropout) exist that may be conceptually closer (and therefore more comparable) to the proposed approach. I also question the choice of tested network architectures and the placement of the dropout layer. The paper could be of high significance if all claims in the paper could be backed up by experiments that show the advantage of Excitation Dropout to be not a random effect. I will therefore give a lower score for the paper in its current form, but am willing to revise my rating the major points below are properly addressed. Pros: + novel mechanism to improve dropout, results seemingly superior over other methods + achieves better utilization of network resources and achieves robustness to dropping out neurons at test time Cons: - results without error bars, unclear if advantage is significant - did not compare against most relevant competing methods MAJOR POINTS Section 2 - The comparison to Moreiro et al. is not entirely clear. A fairer comparison would be with some of the other methods listed which also focus on answering the question of which neurons to dropout, or approaches which determine the dropout policy based on information gained from the data, such as Information Dropout (Achille & Soatto). The authors state that Morerio et al are the state-of-the-art in dropout techniques, however based on the results presented here (Figure 3) it seems to perform just as well as standard dropout. Perhaps there are architecture-specific or data-specific issues? In any case this example undermines the confidence of the claims. Section 3.2, equation 3 - is there some theoretical underpinning as to how this equation was modelled, or was it chosen simply because it covers the expected corner cases described in paragraph 4 of this section? Also, given the intuition in this paragraph (e.g. p_EB = 1 / N), it is correct to assume this equation models the dropout probability but only for fully connected layers? What about dropout in convolutional layers? Though some previous statements do point to the usage of dropout predominantly for fully connected layers, I feel that this context is missing here and should be explicitly addressed. The caption to e.g. Table 1 seems to imply the authors add a single dropout layer in one of the fully connected layers, however this begs the question as to why this positioning was chosen - why only one dropout layer, and why precisely at that location? The scope of the claims should be adapted accordingly. Section 4.2 - \"After convergence, ED demonstrates a significant improvement in performance compared to other methods\". If five trained models were used, then some sense of measure of uncertainty should be given throughout. For example, in the Cifar10 results for Figure 3, it is difficult to say whether the marginal improvement from about 80% (standard dropout and curriculum dropout) to about 82% (excitation dropout) is significant or not. Perhaps this would be less of an issue if the authors had worked with e.g. ImageNet, but for these smaller datasets it would definitely be worth to be on the safe side. I highly suspect that statistically speaking (perhaps with the exception of the results on Caltech256), the effects of all of these dropout variants are indistinguishable from each other. I urge the authors to include a measure of the standard deviation / 95% confidence interval across the models that were tested. The results presented sub-section 4.3 do not justify the claim that the models trained with Excitation Dropout tend to be more informative. Perhaps the definition of \"informative\" should be expanded upon in length. Can the authors show that the alternative paths learned by the models augmented with Excitation Dropout indeed carry complimentary information and not just redundant information? Figure 5 shows interesting results, but once again begs the question of whether there is any significant difference between standard dropout and curriculum dropout. I encourage the authors to include confidence bounds for each trace. Likewise, there is an inherent bias in the results, in that the leftmost figure compares EB and CD in the context in which EB was trained, i.e. dropping of \"most salient\" neurons. The comparison is one-sided, however, as no results are reported from the context in which CD was trained, i.e. dropping neurons more frequently as training progresses. Comparing these results would bring to light whether the performance boost see in Figure 5 is a function of \"overfitting\" to the training manner or not. Also, I believe the results for the second column (dropping out least relevant neurons) are misleading. To the best of my understanding, as p_c increases, at some point neurons start to be dropped that actually have high relevance. This could explain why all curves start out similarly and EB slowly begins to stick out - at this point the EB models once again start to be used in the context within which they were trained, in contrast to the other approaches. The authors should perhaps also explicity clarify why this second column gives any more information than the first. MINOR POINTS The authors propose Excitation Dropout as a guided regularization technique. Batch normalization is another standard regularization technique which is often compared with dropout. In particular, for deep CNNs, batch normalization is known to work very well, often better than the standard dropout. In the experiments here, to what extent was batch normalization and / or any other widely utilized network regularizers used? Is it possible that the regularizing effect found here actually comes from one of these? I.e. were the models that were not trained from scratch trained with batch normalization? It would be good if more data could be provided for EB vs. other regularizing techniques, if the claim is that EB is a novel regularizer. Section 3.1 - \"We choose to use EB since it produces a valid probability distribution for each network layer\". Though this is a nice property, were there any other considerations for choosing the saliency method? Recent work (Adebayo et al, \"Sanity Checks for Saliency Maps\") has shown that even some well established saliency techniques are actually independent from both the model and data. As this approach relies heavily on the correctness of EB, I feel that a further justification should be given to validate its use for this scenario other than just based on the type of output it produces. Section 3.1, equation 2 - more detail and reasoning should be given as to why connections with negative weights are excluded from the computation of the conditional probability, if possible without referring the reader to the EB paper. Why is this justified? Is this probability modelled for a specific activation function? The authors do not provide the details of the CNN-2 architecture (even in the appendix) and simply refer to another article. If the majority of the results presented in the paper are based on this network (including a reference made to a specific layer of the network in subsection 4.2) \u2013 which is not commonly known \u2013 why not to detail the network architecture and save additional effort for the reader? How are the class-wise training and test images chosen for Caltech256 dataset? The authors test the CNN-2 architecture on Cifar10 and Cifar100, and AlexNet, VGG16, and VGG19 on UCF101. I feel that at least a couple architectures should be validated with more than a single dataset, or the authors should justify the current matching between architectures and datasets. Table 2 is unclear regarding what models were used for what datasets (caption could be interpreted to mean that VGG16 was also used for Cifar and Caltech, however other statements seem to say otherwise). \"To prove that the actual boost in accuracy with ED is not provided by the choice of specific masks,...\" I suggest that the authors rephrase or explain this sentence in more detail. To the best of my understanding, it is precisely the fact that different masks are used, each reflective of the particular input used to generate the forward activations, that gives boost in performance over \"standard\" dropout methods by identifying salient paths in the network. Although it is a very important experimental detail, only in the end of sub-section 4.2, it becomes clear in which layers Excitation Dropout was applied. Y-axis labels are missing for the left panels in Figure 3. The authors randomly choose to abbreviate Excitation Dropout as ED in some paragraphs, while write the full form in others. Table 2 - It is not clear that the \"Neurons ON\" metric refers to the \"average percentage of zero activations\" explained below. Table 2 - How is peak p_EB measured? Is this an average over a set of test images after convergence? If so, I similarly suggest for confidence bounds to be introduced. It would be interesting to compare this to intermediate values (e.g. after every epoch) during training. Same question for entropy of activations and entropy of pEB. This information would be useful for reproducibility. Table 2 - Where do the delta values in Table 2 come from? If empirically determined, it should be stated explicitly. Table 2 - In general, because the metrics provided in Table 2 are averages (second paragraph of this Section 4.3), both (to the best of my understanding) across input subsets (e.g. averging results over many test inputs) and models (caption to Table 1), I feel Table 2 in its current form raises confusion given the lack of confidence bounds. I recommend the authors to clarify what type of averaging was done and to introduce e.g. standard deviations across all reported scores. The authors should refrain from using the term \"significantly\" while describing results if no statistical testing was done, or explicitly clarify their usage of this term. Table 2 - In general, Table 2 reports results on selected metrics which, if the authors' hypothesis is correct, should have a clear trend as training progresses. An interesting idea to explore would be to include an analysis (in the appendix) of how these factors change over the course of the training procedure. Intuitively, it seems plasticity is something that should be learned slowly over time, so if these plots were to reveal something different, it would be indicative that something else is going on. Figure 4 - Judging heatmaps is difficult as it depends on the visual perception of the reader. Thus, it is difficult to judge whether, as the authors claim, ED is indeed less \"peaky\" than the other alternatives. I suggest that the authors use a perceptually uniform heatmap, and to acompany these figures with e.g. the histogram of the heatmap values. Likewise, it is unclear how the multi-model aspect of the testing plays a role in generating these results. From the 5 originally trained models, how was the model selected that generated these results? Was there averaging of any kind? Figure 5: the text is too small to be readble Is \"re-wiring\" the most appropriate term to use to describe what is happening at inference time? Although different paths may be used, the network connections themselves are fixed and thus this is a potential source for confusion. What do numbers in Table-4 in the appendix represent? Test accuracy? ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Major Points 1 . Curriculum Dropout ( ICCV \u2019 17 ) reports results on a large subset of the datasets on which we report results and have publicly available code . Curriculum Dropout ( ICCV \u2019 17 ) , on average , performs better than Standard Dropout in all our experiments reported in Figure 3 and Table 1 . Information Dropout only reports results on MNIST and Cifar10 . The best error rate obtained for Cifar10 by Information Dropout is ~8 % . We gladly provide Excitation Dropout performance results for WideResNet ( WRN-28-10 ) on Cifar10 : 3.88 % test error ( vs. 4.17 % Zagoruyko et al. \u2019 s published result , BMVC \u2019 16 ) . Therefore , Excitation Dropout gives state-of-the-art result on Cifar10 . This is now reported in the Appendix ( section titled : Validation on Multiple Architectures ) . Closest methods that focus on answering the question of which neurons to drop out are Adaptive Dropout ( NIPS \u2019 13 ) and Information Dropout ( TPAMI \u2019 18 ) , both having no publicly available implementation . We chose to implement Adaptive Dropout because it has a directly comparable neuron selection strategy . Comparison against Adaptive Dropout was included in the Appendix ( section titled : Least vs. most relevant neurons ) of our original submission , and we refer to it in the middle of page 4 of our original manuscript . In that section we discuss how Adaptive Dropout and Excitation Dropout use opposite strategies of neuron selection : Adaptive Dropout drops with a higher probability the least active neurons , whereas Excitation Dropout drops with higher probability the most relevant neurons . We also note that Adaptive Dropout was originally introduced for an autoencoder architecture . 2.Equation 3 was designed to fit the three constraints ( corner cases ) described in the paper , starting from a general hyperbolic function p= ( a-a * x ) / ( a+x ) . Other simpler variations such as p=1-p_EB were studied , but did not perform as well as Equation 3 . The latter linear scheme shows its limitations when p_EB=1/N ; the probability of retaining a neuron p becomes almost 1 ( i.e.no dropout ) , for typical values of N ( e.g.2048,4096 ) . Excitation Dropout can be applied to any neural network layer . We add the following clarification to Section 3.2 \u201c N is the number of neurons in a fully-connected layer l or the number of filters in a convolutional layer l. \u201d In response to the reviewer request , we implement Excitation Dropout ( ED ) in convolutional layers of the CNN-2 architecture . We apply ED to a generic convolutional activation map [ w , h , N ] by first calculating p_EB for each of the N feature maps as the sum of p_EB across the spatial locations ( w and h ) . We then drop a 2D feature map as per Equation 3 and obtain the following accuracy results for Cifar10 : no-dropout 76.91 % , ED @ conv3 78.01 % , ED @ fc1 81.94 % . Again , we observe an improvement respect to no-dropout but , consistent with the literature [ Hinton et al . ( 2012 ) , Srivastava et al . ( 2014 ) ] , the improvement is not as large as using dropout in fully connected layers . This result is now added in the Appendix ( section titled : Excitation Dropout in Convolutional Layers ) . 3.We now update Fig.3 of the main manuscript to include the standard deviations for accuracies over all iterations of the five models for every dataset to statistically validate our results . 4.Entropy is a measure of average information content . In Table 2 , we show that ED results in a higher entropy for neuron activations , justifying the sentence in Section 4.3 , which read \u201c These results show that the models trained with ED were trained to be more informative , i.e.the contribution for the final classification task is provided by a higher number of neurons in the network , reflecting the alternative learnt paths. \u201d If the additional active neurons carried redundant information , we would not observe an increased accuracy . 5.We now update Fig.5 of the main manuscript and Fig 9. of the Appendix to include the standard deviations for ground-truth probabilities of the five models for every dataset to statistically validate our results . The context in which ED is trained is : dropping the most salient neurons . The context in which CD is trained is : increasing the dropout rate over time . The context in which CD was trained can not be replicated in testing since there are no sequential iterations at test time . We agree that the leftmost figure is obtained in the same context ED was trained , but it is added for completeness . The middle figure demonstrates the case of dropping the least salient neurons first . We note that ED in the middle figure does not exactly converge to the context in which ED was trained because by the time the most relevant neurons are dropped , the less relevant ones have been already dropped too . The rightmost figure demonstrates the case of dropping neurons selected uniformly at random ( unlike the context in which ED was trained ) , and ED again demonstrates a more robust behavior ."}], "0": {"review_id": "H1xQSjCqFQ-0", "review_text": "This paper presents a variation of dropout, where the proposed method drops with higher probability those neurons which contribute more to decision making at training time. This idea is evaluated on several standard datasets for image classification and action recognition. Pros: 1. This paper has interesting idea related to dropout, and shows some benefit. 2. Paper is well-written and easy to understand. Cons: 1. There are many variations in dropouts and they all claim superiority to others. Unfortunately, most of them are not justified properly. Excitation dropout looks interesting and has potential, but its validation is not strong enough. Use of Cifar10/100, Caltech256, and UCF 101 may be okay for concept proofing, but not be sufficient for thorough validation. Also, the reported results are far from the state-of-the-art performance of each dataset. I would recommended to add the idea to the network to achieve the state-of-the-art performance because it will show real extra benefit of \"excitation\" dropout. 2. There are many variations of dropouts including variational dropout, L0-regularization, and adaptive dropout, and the paper needs to report their accuracy in addition to curriculum dropout. 3. Dropout does not exist in many modern deep neural networks and its usability is a bit weak. It would be better to generalize this idea and make it applicable to ResNet-style networks. 4. There is no clear (theoretical) justification and intuition why excitation dropout improves performance. More ablation study with internal analysis would be helpful. Overall, this paper has interesting idea but needs more efforts to make the idea convincing.", "rating": "5: Marginally below acceptance threshold", "reply_text": "1.Adaptive Dropout ( NIPS \u2019 13 ) reported results on MNIST and NORB , Information Dropout ( TPAMI \u2019 18 ) and Variational Dropout ( NIPS \u2019 15 ) reported results on MNIST and Cifar10 , Curriculum Dropout ( ICCV \u2019 17 ) reported results on MNIST , Cifar10/100 , and Caltech101/256 . In this work , we present results on the small scale dataset Caltech256 having ~18K images ( but 256 classes ) , the medium scale datasets Cifar10/100 having ~60K images ( 10/100 classes ) , and on the larger scale UCF101 dataset which has ~13K videos ( 101 classes ) , from which we sample 2M frames . Dropout is adopted in WideResNet which is used to obtain state-of-the-art results on Cifar10 . We gladly provide Excitation Dropout performance results for WideResNet ( WRN-28-10 ) on Cifar10 : 3.88 % test error ( vs. 4.17 % Zagoruyko et al. \u2019 s published result , BMVC \u2019 16 ) . Therefore , Excitation Dropout gives state-of-the-art result on Cifar10 . 2.Comparison against Adaptive Dropout was included in the Appendix ( section titled : Least vs. most relevant neurons ) of our original submission , and we referred to it in the middle of page 4 of our original manuscript . In that section we discuss how Adaptive Dropout and Excitation Dropout use opposite strategies of neuron selection : Adaptive Dropout drops with a higher probability the least active neurons , while Excitation Dropout drops with higher probability the most relevant neurons . We note that Adaptive Dropout was originally introduced for an autoencoder architecture . Variational Dropout ( NIPS \u2019 15 ) reports results on MNIST and Cifar10 only . The best result reported by Variational Dropout on Cifar10 has error ~23 % , while Excitation Dropout with a CNN-2 architecture has error ~18 % and with a WideResNet architecture has ~4 % error . 3.Dropout is one of the most important regularization techniques for deep learning and it is also adopted in WideResNet . ResNet and DenseNet architectures do not have dropout layers , and rely on batch normalization for regularization . Effectiveness of regularization methods for training neural networks is dependent on the architecture and training process , and is still an open problem ( e.g. , batch normalization can not handle small batches ) . Moreover , please note how the following dropout papers deal with computationally heavy experiments . Curriculum Dropout ( ICCV \u2019 17 ) uses two variants of somewhat shallow networks , LeNet and the deeper version CNN-2 we also use . Variational Dropout ( NIPS \u2019 15 ) and Dropout ( JMLR \u2019 14 ) use an architecture with 3 hidden layers . Adaptive Dropout ( NIPS \u2019 13 ) uses a one-hidden-layer autoencoder . We present experiments on the medium-scale network CNN-2 for datasets trained from scratch , and on the deeper AlexNet , VGG16 , and VGG19 for the larger dataset UCF101 where fine-tuning is sufficient . We also gladly provide results for Cifar10 on WideResNet and for Caltech256 on the deeper AlexNet , VGG16 , and VGG19 in the Appendix ( section titled : Validation on Multiple Architectures ) . 4.Dropout is a model averaging technique . Averaging models having less specialized neurons results in higher robustness to information loss . In Table 2 we demonstrate that Excitation Dropout has less specialized neurons ( lower saliency peaks and higher entropy ) , as compared to Standard and Curriculum Dropout for all datasets considered ( Cifar10/100 , Caltech256 and UCF101 ) . In addition , Table 2 presents an internal analysis of the network filters demonstrating that a lower number of stale/conservative filters for Excitation Dropout ( as compared to Standard and Curriculum Dropout ) is achieved . These considerations are now better highlighted in the last paragraph of Section 4.3 ."}, "1": {"review_id": "H1xQSjCqFQ-1", "review_text": "This is an interesting idea that seems to do better than regular dropout. However, the experiment seem a bit artificial, starting with less modern network designs (VGG) that can benefit from adding dropout. State of the art computer vision networks don't seem to need dropout so much, so the impact of the paper is unclear. Section 4.4: How does this compare to state-of-the-art network compression techniques? (Deep compression, etc) ", "rating": "5: Marginally below acceptance threshold", "reply_text": "1.Dropout is one of the most important regularization techniques for deep learning -adopted in WideResNet which is used to obtain state-of-the-art results on Cifar10 . We gladly provide Excitation Dropout performance results for WideResNet ( WRN-28-10 ) on Cifar10 : 3.88 % test error ( vs. 4.17 % Zagoruyko et al. \u2019 s published result , BMVC \u2019 16 ) . Therefore , Excitation Dropout gives state-of-the-art result on Cifar10 . This is now reported in the Appendix ( section titled : Validation on Multiple Architectures ) . Some modern network architectures like ResNet and DenseNet do not have dropout layers , and rely on batch normalization for regularization . However , this does not preclude research on dropout : Ghiasi et al . ( NIPS \u2019 18 ) , Achille et al . ( TPAMI \u2019 18 ) , Cavazza et al . ( AISTATS \u2019 18 ) , Morerio et al . ( ICCV \u2019 17 ) , Kang et al . ( TPAMI \u2019 17 ) , Molchanov et al . ( PMLR \u2019 17 ) . Effectiveness of regularization methods for training neural networks is dependent on the architecture and training process , and is still an open problem ( e.g.batch normalization can not handle small batches ) . 2.In this work , we are not proposing a network compression technique . We propose a technique that improves network generalization on unseen data by increasing the utilization of network neurons and learning alternative paths . We then demonstrate that learning alternative paths also results in added resilience to network compression ."}, "2": {"review_id": "H1xQSjCqFQ-2", "review_text": "The authors propose a data-dependent dropout variant that produces dropout candidates based on their predictive saliency / relevance. Results are reported for 4 datasets (Cifar10, Cifar100, Caltech256 and UCF101) and 4 different models (CNN-2, AlexNet, VGG16 and VGG19), and suggest an increase in generalization performance over other dropout approaches (curriculum dropout, standard dropout, no dropout), as well as increase in the network's plasticity as measured by some existing metrics from the literature. The authors conclude that Excitation Dropout results in better network utilization and offers advantages for network compression (in the sense of neuron pruning). Overall I find the idea to be interesting and fairly novel, and commend the authors for the fluid writing style. However, I find key issues with the testing and experiments. Specifically, the lack of confidence bounds for individual results makes it impossible to determine whether the reported incremental improvements are actually significant over those of existing approaches. Likewise, I criticize the choice of methods the authors have chosen to compare against, as several other data-dependent dropout approaches (e.g. Information Dropout) exist that may be conceptually closer (and therefore more comparable) to the proposed approach. I also question the choice of tested network architectures and the placement of the dropout layer. The paper could be of high significance if all claims in the paper could be backed up by experiments that show the advantage of Excitation Dropout to be not a random effect. I will therefore give a lower score for the paper in its current form, but am willing to revise my rating the major points below are properly addressed. Pros: + novel mechanism to improve dropout, results seemingly superior over other methods + achieves better utilization of network resources and achieves robustness to dropping out neurons at test time Cons: - results without error bars, unclear if advantage is significant - did not compare against most relevant competing methods MAJOR POINTS Section 2 - The comparison to Moreiro et al. is not entirely clear. A fairer comparison would be with some of the other methods listed which also focus on answering the question of which neurons to dropout, or approaches which determine the dropout policy based on information gained from the data, such as Information Dropout (Achille & Soatto). The authors state that Morerio et al are the state-of-the-art in dropout techniques, however based on the results presented here (Figure 3) it seems to perform just as well as standard dropout. Perhaps there are architecture-specific or data-specific issues? In any case this example undermines the confidence of the claims. Section 3.2, equation 3 - is there some theoretical underpinning as to how this equation was modelled, or was it chosen simply because it covers the expected corner cases described in paragraph 4 of this section? Also, given the intuition in this paragraph (e.g. p_EB = 1 / N), it is correct to assume this equation models the dropout probability but only for fully connected layers? What about dropout in convolutional layers? Though some previous statements do point to the usage of dropout predominantly for fully connected layers, I feel that this context is missing here and should be explicitly addressed. The caption to e.g. Table 1 seems to imply the authors add a single dropout layer in one of the fully connected layers, however this begs the question as to why this positioning was chosen - why only one dropout layer, and why precisely at that location? The scope of the claims should be adapted accordingly. Section 4.2 - \"After convergence, ED demonstrates a significant improvement in performance compared to other methods\". If five trained models were used, then some sense of measure of uncertainty should be given throughout. For example, in the Cifar10 results for Figure 3, it is difficult to say whether the marginal improvement from about 80% (standard dropout and curriculum dropout) to about 82% (excitation dropout) is significant or not. Perhaps this would be less of an issue if the authors had worked with e.g. ImageNet, but for these smaller datasets it would definitely be worth to be on the safe side. I highly suspect that statistically speaking (perhaps with the exception of the results on Caltech256), the effects of all of these dropout variants are indistinguishable from each other. I urge the authors to include a measure of the standard deviation / 95% confidence interval across the models that were tested. The results presented sub-section 4.3 do not justify the claim that the models trained with Excitation Dropout tend to be more informative. Perhaps the definition of \"informative\" should be expanded upon in length. Can the authors show that the alternative paths learned by the models augmented with Excitation Dropout indeed carry complimentary information and not just redundant information? Figure 5 shows interesting results, but once again begs the question of whether there is any significant difference between standard dropout and curriculum dropout. I encourage the authors to include confidence bounds for each trace. Likewise, there is an inherent bias in the results, in that the leftmost figure compares EB and CD in the context in which EB was trained, i.e. dropping of \"most salient\" neurons. The comparison is one-sided, however, as no results are reported from the context in which CD was trained, i.e. dropping neurons more frequently as training progresses. Comparing these results would bring to light whether the performance boost see in Figure 5 is a function of \"overfitting\" to the training manner or not. Also, I believe the results for the second column (dropping out least relevant neurons) are misleading. To the best of my understanding, as p_c increases, at some point neurons start to be dropped that actually have high relevance. This could explain why all curves start out similarly and EB slowly begins to stick out - at this point the EB models once again start to be used in the context within which they were trained, in contrast to the other approaches. The authors should perhaps also explicity clarify why this second column gives any more information than the first. MINOR POINTS The authors propose Excitation Dropout as a guided regularization technique. Batch normalization is another standard regularization technique which is often compared with dropout. In particular, for deep CNNs, batch normalization is known to work very well, often better than the standard dropout. In the experiments here, to what extent was batch normalization and / or any other widely utilized network regularizers used? Is it possible that the regularizing effect found here actually comes from one of these? I.e. were the models that were not trained from scratch trained with batch normalization? It would be good if more data could be provided for EB vs. other regularizing techniques, if the claim is that EB is a novel regularizer. Section 3.1 - \"We choose to use EB since it produces a valid probability distribution for each network layer\". Though this is a nice property, were there any other considerations for choosing the saliency method? Recent work (Adebayo et al, \"Sanity Checks for Saliency Maps\") has shown that even some well established saliency techniques are actually independent from both the model and data. As this approach relies heavily on the correctness of EB, I feel that a further justification should be given to validate its use for this scenario other than just based on the type of output it produces. Section 3.1, equation 2 - more detail and reasoning should be given as to why connections with negative weights are excluded from the computation of the conditional probability, if possible without referring the reader to the EB paper. Why is this justified? Is this probability modelled for a specific activation function? The authors do not provide the details of the CNN-2 architecture (even in the appendix) and simply refer to another article. If the majority of the results presented in the paper are based on this network (including a reference made to a specific layer of the network in subsection 4.2) \u2013 which is not commonly known \u2013 why not to detail the network architecture and save additional effort for the reader? How are the class-wise training and test images chosen for Caltech256 dataset? The authors test the CNN-2 architecture on Cifar10 and Cifar100, and AlexNet, VGG16, and VGG19 on UCF101. I feel that at least a couple architectures should be validated with more than a single dataset, or the authors should justify the current matching between architectures and datasets. Table 2 is unclear regarding what models were used for what datasets (caption could be interpreted to mean that VGG16 was also used for Cifar and Caltech, however other statements seem to say otherwise). \"To prove that the actual boost in accuracy with ED is not provided by the choice of specific masks,...\" I suggest that the authors rephrase or explain this sentence in more detail. To the best of my understanding, it is precisely the fact that different masks are used, each reflective of the particular input used to generate the forward activations, that gives boost in performance over \"standard\" dropout methods by identifying salient paths in the network. Although it is a very important experimental detail, only in the end of sub-section 4.2, it becomes clear in which layers Excitation Dropout was applied. Y-axis labels are missing for the left panels in Figure 3. The authors randomly choose to abbreviate Excitation Dropout as ED in some paragraphs, while write the full form in others. Table 2 - It is not clear that the \"Neurons ON\" metric refers to the \"average percentage of zero activations\" explained below. Table 2 - How is peak p_EB measured? Is this an average over a set of test images after convergence? If so, I similarly suggest for confidence bounds to be introduced. It would be interesting to compare this to intermediate values (e.g. after every epoch) during training. Same question for entropy of activations and entropy of pEB. This information would be useful for reproducibility. Table 2 - Where do the delta values in Table 2 come from? If empirically determined, it should be stated explicitly. Table 2 - In general, because the metrics provided in Table 2 are averages (second paragraph of this Section 4.3), both (to the best of my understanding) across input subsets (e.g. averging results over many test inputs) and models (caption to Table 1), I feel Table 2 in its current form raises confusion given the lack of confidence bounds. I recommend the authors to clarify what type of averaging was done and to introduce e.g. standard deviations across all reported scores. The authors should refrain from using the term \"significantly\" while describing results if no statistical testing was done, or explicitly clarify their usage of this term. Table 2 - In general, Table 2 reports results on selected metrics which, if the authors' hypothesis is correct, should have a clear trend as training progresses. An interesting idea to explore would be to include an analysis (in the appendix) of how these factors change over the course of the training procedure. Intuitively, it seems plasticity is something that should be learned slowly over time, so if these plots were to reveal something different, it would be indicative that something else is going on. Figure 4 - Judging heatmaps is difficult as it depends on the visual perception of the reader. Thus, it is difficult to judge whether, as the authors claim, ED is indeed less \"peaky\" than the other alternatives. I suggest that the authors use a perceptually uniform heatmap, and to acompany these figures with e.g. the histogram of the heatmap values. Likewise, it is unclear how the multi-model aspect of the testing plays a role in generating these results. From the 5 originally trained models, how was the model selected that generated these results? Was there averaging of any kind? Figure 5: the text is too small to be readble Is \"re-wiring\" the most appropriate term to use to describe what is happening at inference time? Although different paths may be used, the network connections themselves are fixed and thus this is a potential source for confusion. What do numbers in Table-4 in the appendix represent? Test accuracy? ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Major Points 1 . Curriculum Dropout ( ICCV \u2019 17 ) reports results on a large subset of the datasets on which we report results and have publicly available code . Curriculum Dropout ( ICCV \u2019 17 ) , on average , performs better than Standard Dropout in all our experiments reported in Figure 3 and Table 1 . Information Dropout only reports results on MNIST and Cifar10 . The best error rate obtained for Cifar10 by Information Dropout is ~8 % . We gladly provide Excitation Dropout performance results for WideResNet ( WRN-28-10 ) on Cifar10 : 3.88 % test error ( vs. 4.17 % Zagoruyko et al. \u2019 s published result , BMVC \u2019 16 ) . Therefore , Excitation Dropout gives state-of-the-art result on Cifar10 . This is now reported in the Appendix ( section titled : Validation on Multiple Architectures ) . Closest methods that focus on answering the question of which neurons to drop out are Adaptive Dropout ( NIPS \u2019 13 ) and Information Dropout ( TPAMI \u2019 18 ) , both having no publicly available implementation . We chose to implement Adaptive Dropout because it has a directly comparable neuron selection strategy . Comparison against Adaptive Dropout was included in the Appendix ( section titled : Least vs. most relevant neurons ) of our original submission , and we refer to it in the middle of page 4 of our original manuscript . In that section we discuss how Adaptive Dropout and Excitation Dropout use opposite strategies of neuron selection : Adaptive Dropout drops with a higher probability the least active neurons , whereas Excitation Dropout drops with higher probability the most relevant neurons . We also note that Adaptive Dropout was originally introduced for an autoencoder architecture . 2.Equation 3 was designed to fit the three constraints ( corner cases ) described in the paper , starting from a general hyperbolic function p= ( a-a * x ) / ( a+x ) . Other simpler variations such as p=1-p_EB were studied , but did not perform as well as Equation 3 . The latter linear scheme shows its limitations when p_EB=1/N ; the probability of retaining a neuron p becomes almost 1 ( i.e.no dropout ) , for typical values of N ( e.g.2048,4096 ) . Excitation Dropout can be applied to any neural network layer . We add the following clarification to Section 3.2 \u201c N is the number of neurons in a fully-connected layer l or the number of filters in a convolutional layer l. \u201d In response to the reviewer request , we implement Excitation Dropout ( ED ) in convolutional layers of the CNN-2 architecture . We apply ED to a generic convolutional activation map [ w , h , N ] by first calculating p_EB for each of the N feature maps as the sum of p_EB across the spatial locations ( w and h ) . We then drop a 2D feature map as per Equation 3 and obtain the following accuracy results for Cifar10 : no-dropout 76.91 % , ED @ conv3 78.01 % , ED @ fc1 81.94 % . Again , we observe an improvement respect to no-dropout but , consistent with the literature [ Hinton et al . ( 2012 ) , Srivastava et al . ( 2014 ) ] , the improvement is not as large as using dropout in fully connected layers . This result is now added in the Appendix ( section titled : Excitation Dropout in Convolutional Layers ) . 3.We now update Fig.3 of the main manuscript to include the standard deviations for accuracies over all iterations of the five models for every dataset to statistically validate our results . 4.Entropy is a measure of average information content . In Table 2 , we show that ED results in a higher entropy for neuron activations , justifying the sentence in Section 4.3 , which read \u201c These results show that the models trained with ED were trained to be more informative , i.e.the contribution for the final classification task is provided by a higher number of neurons in the network , reflecting the alternative learnt paths. \u201d If the additional active neurons carried redundant information , we would not observe an increased accuracy . 5.We now update Fig.5 of the main manuscript and Fig 9. of the Appendix to include the standard deviations for ground-truth probabilities of the five models for every dataset to statistically validate our results . The context in which ED is trained is : dropping the most salient neurons . The context in which CD is trained is : increasing the dropout rate over time . The context in which CD was trained can not be replicated in testing since there are no sequential iterations at test time . We agree that the leftmost figure is obtained in the same context ED was trained , but it is added for completeness . The middle figure demonstrates the case of dropping the least salient neurons first . We note that ED in the middle figure does not exactly converge to the context in which ED was trained because by the time the most relevant neurons are dropped , the less relevant ones have been already dropped too . The rightmost figure demonstrates the case of dropping neurons selected uniformly at random ( unlike the context in which ED was trained ) , and ED again demonstrates a more robust behavior ."}}