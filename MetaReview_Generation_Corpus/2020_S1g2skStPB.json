{"year": "2020", "forum": "S1g2skStPB", "title": "Causal Discovery with Reinforcement Learning", "decision": "Accept (Talk)", "meta_review": "This paper proposes an RL-based structure search method for causal discovery. The reviewers and AC think that the idea of applying reinforcement learning to causal structure discovery is novel and intriguing. While there were initially some concerns regarding presentation of the results, these have been taken care of during the discussion period. The reviewers agree that this is a very good submission, which merits acceptance to ICLR-2020.", "reviews": [{"review_id": "S1g2skStPB-0", "review_text": "Update: after the revision, I have decided to increase my score to 8. Original comments: In this paper, the authors proposed a new reinforcement learning based algorithm to learn causal graphical models. Simulations on real and synthetic data also shows promise. Pros 1. It's great to see the authors has done a comprehensive comparison with the other methods, especially under different simulation scenarios. 2. The novel idea of applying reinforcement learning to DAG search sounds intriguing. Reinforcement learning offers a powerful tool for policy evaluation and decision making. It\u2019s good to see that the author can successfully extend such toolbox to the field of causal structure learning. To the best of the author\u2019s knowledge, such idea has never been considered by previous work in causal graphical models. Cons. 1. In the introduction section, the authors claimed that \u201cGES is not guaranteed in the finite sample regime\u201d. This seems to be incorrect. For example, the Nandy et al. paper tackles exactly the finite sample problem. In conclusion, overall this is a sensible idea, although some of the preliminaries still remain to be polished.", "rating": "8: Accept", "reply_text": "We thank the reviewer for the positive feedback on our work . Regarding 'GES is not guaranteed in the finite sample regime ' and Nandy et al.paper 'High-dimensional consistency in score-based and hybrid structure learning ' : Here we aimed to state the consistency result of GES established by Chickering , and we find that Nandy et al.paper is also about consistency of GES but w.r.t.high dimension settings . In our understanding , consistency means that the probability of correct estimation of the ground truth goes to one as the number of samples approaches infinity , and we believe that this is also the case with Nandy et al.paper ( please find below some quoted sentences where $ n $ denotes the number of samples ) . We however do not find a result or claim regarding guaranteed performance in the finite sample regime . In case we may misunderstand or miss certain results , can the reviewer please give more details on 'the Nandy et al.paper tackles exactly the finite sample problem ' , and if possible , the corresponding theorems or claims in Nandy et al.paper and other papers as well ? Again we greatly appreciate the reviewer 's effort . We would definitely revise our statement if we misunderstand/omit the result of GES in the finite sample regime . -- -- -- -- -- -- - Quoted sentences from the arxiv version of Nandy et al.paper , available at https : //arxiv.org/pdf/1507.02608.pdf : Page 3 : 'In this paper , we prove high-dimensional consistency of GES , and we propose new hybrid algorithms based on GES that are consistent in several sparse high-dimensional settings and scale well to large sparse graphs . To the best of our knowledge , these are the first results on high-dimensional consistency of score-based and hybrid methods . ' Page 7 : 'Consistency of $ \\mathcal S $ assures that $ \\mathcal G_0 $ has a lower score than any DAG that is not in the Markov equivalence class of $ \\mathcal G_0 $ , with probability approaching one as $ n\\to\\infty $ ( Proposition 8 of Chickering [ 2002b ] ) . ' Page 19 , Theorem 5.2 : 'Assume ( A1 ) - ( A6 ) . Let $ \\hat { \\mathcal C } _n $ , $ \\breve { \\mathcal C } _n $ and $ \\tilde { \\mathcal C } _n $ be the outputs of ARGES-CIG based on $ \\hat { \\mathcal I } _n $ , ARGES-skeleton based on $ \\hat { \\mathcal U } _n $ and GES respectively , with the scoring criterion $ \\mathcal S_ { \\lambda_n } $ . Then there exists a sequence $ \\lambda_n\\to 0 $ such that $ \\lim_ { n\\to\\infty } \\mathbb P ( \\hat { \\mathcal C } _n=\\mathcal C_ { n0 } ) =\\lim_ { n\\to\\infty } \\mathbb P ( \\breve { \\mathcal C } _n=\\mathcal C_ { n0 } ) =\\lim_ { n\\to\\infty } \\mathbb P ( \\tilde { \\mathcal C } _n=\\mathcal C_ { n0 } ) =1. $ '"}, {"review_id": "S1g2skStPB-1", "review_text": "In this paper, the authors propose an RL-based structure searching method for causal discovery. The authors reformulate the score-based causal discovery problem into an RL-format, which includes the reward function re-design, hyper-parameter choose, and graph generation. To my knowledge, it\u2019s the first time that the RL algorithm is applied to causal discovery area for structure searching. The authors\u2019 contributions are: (1) re-design the reword function which concludes the traditional score function and the acyclic constraint (2) Theoretically prove that the maximizing the reward function is equivalent to maximizing the original score function under some choices of the hyper-parameters. (3) Apply the reinforce gradient estimator to search the parameters related to adjacency matrix generation. (4) In the experiment, the authors conduct experiment on datasets which includes both linear/non-linear model with Gaussian/Non-gaussian noise. (5) The authors public their code for reproducibility. Overall, the idea of this paper is novel, and the experiment is comprehensive. I have the following concerns. (1) In page 4 Encoder paragraph, the authors mention that the self-attention scheme is capable of finding the causal relationships. Why? In my opinion, the attention scheme only reflects the correlation relationship. The authors should give more clarifications to convince me about their beliefs. (2) The authors first introduce the h(A) constraint in eqn. (4), and mentioned that only have that constraint would result in a large penalty weight. To solve this, the authors introduce the indicator function constraint. What if we only use the indicator function constraint? In this case, the equivalence is still satisfied, so I am confused about the motivation of imposing the h(A) constraint. (3) In the last paragraph of page 5, why the authors adjust the predefined scores to a certain range? (4) Whether the acyclic can be guaranteed after minimizing the negative reward function (the eqn.(6))? I.e., After the training process, whether the graph with the best reward can be theoretically guaranteed to be acyclic? (5) In section 5.3, the authors mention that the generated graph may contain spurious edges? Whether the edges that in the cyclic are spurious? Whether the last pruning step contains pruning the cyclic path? (6) In the experiment, the authors adopt three metrics. For better comparison, the author should clarify that: the smaller the FDR/SHD is, the better the performance, and the larger the TPR is, the better the performance. (7) From the experimental results, the proposed method seems more superiors under the non-linear model case. Why? Could the authors give a few sentences about the guidance of the model selection in the real-world? i.e., when to select the proposed RL-based method? And under which case to choose RL-BIC, and which case to selection RL-BIC2? (8) What\u2019s training time, and how many samples are needed in the training process? Minor: 1. In the page 4 decoder section, the notation of enc_i and enc_j is not clarified. 2. On page 5, the \\Delta_1 and \\Delta_2 are not explained. 3. For better reading experience, in table 1,2,3,4, the authors should bold value that has the best performance. ", "rating": "8: Accept", "reply_text": "( 8 ) 'What \u2019 s training time , and how many samples are needed in the training process ? ' We did not include the training time because we used different machines for our experiments . The implementation of benchmark methods can also be optimized to reduce time ( e.g. , DAG-GNN 's codes did not work with GPU ) and the results may be somehow inaccurate . Here we just provide a rough description with 12-node linear data models : - Traditional methods PC and GES were run on a laptop with Intel 4-core i7 CPU , and produced the estimated result within 10 seconds ; - NOTEARS and ICA-LiNGAM were also run on the laptop and can be finished in 1~3 minutes ( we set the maximum number of iterations of the ICA algorithm to be 20,000 , ten times of the default number used by the ICA-LiNGAM authors ) ; - CAM was run on the same laptop and typically required 7~8 minutes ; - Our algorithms RL-BIC and RL-BIC2 were run with Intel Xeon 3.20GHz CPU and Nvidia Quadro RTX 5000 GPU . Both methods took about 30~40 minutes with 12-nodes graphs and 20,000 iterations . For 30-node graphs and 30,000 iterations , they needed around 3 hours ; - DAG-GNN took about 1 hour with the same Intel Xeon 3.20GHz CPU ( their codes with GPU option did not work ; the algorithm in fact did not require such a long time to reach convergence , yet no early stopping choice was provided in the codes ) ; - GraN-DAG with the same CPU and GPU took about 20~30 minutes . Regarding the sample number , we have given the number of samples in each experiment description . ( 9 ) Minor : 1 . 'In the page 4 decoder section , the notation of enc_i and enc_j is not clarified . ' Actually $ enc_i $ is given in the last sentence of the encoder part . 2 . 'On page 5 , the \\Delta_1 and \\Delta_2 are not explained . ' Thanks for pointing this out . We will add a definition for the two notations . 3 . 'For better reading experience , in table 1,2,3,4 , the authors should bold value that has the best performance . ' Thanks for this suggestion . We have considered doing so , but it is usually the case that a method that has the best TPR does not achieve the lowest FDR , and only making one in bold seems insufficient to evaluate the overall performance of a method . If possible , can the reviewer give further suggestion on this part ? Thanks ."}, {"review_id": "S1g2skStPB-2", "review_text": "This work addresses the task of causal discovery. The proposed contribution is to apply prior work which uses reinforcement learning for combinatorial optimization to structure learning. Specifically, the proposed optimization problem seeks to maximize a penalized score criterion subject to the acyclicity constraint proposed by Zheng, et al. Empirical results show the proposed method performing favorably in contrast to prior art. Overall I think this is a sensible idea, and the authors do a nice job of exposition, and empirical evaluation. My concerns are as follows: * The novelty is somewhat limited, since the paper is combining two previously proposed ideas (combinatorial search and the acyclicity constraint) for structure learning. * The paper is loose with technical points. Specifically, the authors claim to use the additive noise model, but then make no restrictions on f(). In this setting, it is fairly well known that we can only hope to learn up to the Markov equivalence class (not the fully directed graph), but there is no mention of this in the paper. With all of this said, I think overall the paper is an interesting addition to the causal discovery literature. ", "rating": "8: Accept", "reply_text": "We are grateful to the reviewer 's effort and the positive comment on our paper . We are revising the paper by taking into accounts all the reviewers ' comments/suggestions , and the revised version will be uploaded at a later time within this week . * Regarding 'The novelty is somewhat limited , since the paper is combining two previously proposed ideas ( combinatorial search and the acyclicity constraint ) for structure learning ' : These two ideas are indeed important to our RL based approach to causal discovery . Here we would like to briefly discuss the necessity of the acyclicity constraint from Zheng et al.With the proposed penalty weights in our work , Zheng et al. \u2019 s acyclicity constraint $ h ( A ) $ is used to guide the RL agent to generate directed graphs \u2018 closer \u2019 to be acyclic and the indicator function w.r.t.acyclicity aims to induce exact DAGs . The major benefit of $ h ( A ) $ , or more precisely , $ h ( W\\circ W ) $ ( $ W $ denotes the weighted adjacent matrix if it exists , e.g. , for linear models , and $ \\circ $ denotes Hadamard product ) , is its smoothness that enables continuous optimization for structure learning . This property is not utilized in our approach , and we believe other acyclicity functions , which measure certain \u2018 distance \u2019 of a directed graph to be acyclic and do not need to be differentiable , can also be used here . We will add more discussions on this point in the revision . * Regarding 'The paper is loose with technical points . Specifically , the authors claim to use the additive noise model , but then make no restrictions on f ( ) . In this setting , it is fairly well known that we can only hope to learn up to the Markov equivalence class ( not the fully directed graph ) , but there is no mention of this in the paper ' : Thanks for this helpful comment . We will add a sentence in Section 2 to state this result , along with the fact that we use fully identifiable models to generate observations in our experiments . We once again appreciate the reviewer \u2019 s effort on reviewing our paper ."}], "0": {"review_id": "S1g2skStPB-0", "review_text": "Update: after the revision, I have decided to increase my score to 8. Original comments: In this paper, the authors proposed a new reinforcement learning based algorithm to learn causal graphical models. Simulations on real and synthetic data also shows promise. Pros 1. It's great to see the authors has done a comprehensive comparison with the other methods, especially under different simulation scenarios. 2. The novel idea of applying reinforcement learning to DAG search sounds intriguing. Reinforcement learning offers a powerful tool for policy evaluation and decision making. It\u2019s good to see that the author can successfully extend such toolbox to the field of causal structure learning. To the best of the author\u2019s knowledge, such idea has never been considered by previous work in causal graphical models. Cons. 1. In the introduction section, the authors claimed that \u201cGES is not guaranteed in the finite sample regime\u201d. This seems to be incorrect. For example, the Nandy et al. paper tackles exactly the finite sample problem. In conclusion, overall this is a sensible idea, although some of the preliminaries still remain to be polished.", "rating": "8: Accept", "reply_text": "We thank the reviewer for the positive feedback on our work . Regarding 'GES is not guaranteed in the finite sample regime ' and Nandy et al.paper 'High-dimensional consistency in score-based and hybrid structure learning ' : Here we aimed to state the consistency result of GES established by Chickering , and we find that Nandy et al.paper is also about consistency of GES but w.r.t.high dimension settings . In our understanding , consistency means that the probability of correct estimation of the ground truth goes to one as the number of samples approaches infinity , and we believe that this is also the case with Nandy et al.paper ( please find below some quoted sentences where $ n $ denotes the number of samples ) . We however do not find a result or claim regarding guaranteed performance in the finite sample regime . In case we may misunderstand or miss certain results , can the reviewer please give more details on 'the Nandy et al.paper tackles exactly the finite sample problem ' , and if possible , the corresponding theorems or claims in Nandy et al.paper and other papers as well ? Again we greatly appreciate the reviewer 's effort . We would definitely revise our statement if we misunderstand/omit the result of GES in the finite sample regime . -- -- -- -- -- -- - Quoted sentences from the arxiv version of Nandy et al.paper , available at https : //arxiv.org/pdf/1507.02608.pdf : Page 3 : 'In this paper , we prove high-dimensional consistency of GES , and we propose new hybrid algorithms based on GES that are consistent in several sparse high-dimensional settings and scale well to large sparse graphs . To the best of our knowledge , these are the first results on high-dimensional consistency of score-based and hybrid methods . ' Page 7 : 'Consistency of $ \\mathcal S $ assures that $ \\mathcal G_0 $ has a lower score than any DAG that is not in the Markov equivalence class of $ \\mathcal G_0 $ , with probability approaching one as $ n\\to\\infty $ ( Proposition 8 of Chickering [ 2002b ] ) . ' Page 19 , Theorem 5.2 : 'Assume ( A1 ) - ( A6 ) . Let $ \\hat { \\mathcal C } _n $ , $ \\breve { \\mathcal C } _n $ and $ \\tilde { \\mathcal C } _n $ be the outputs of ARGES-CIG based on $ \\hat { \\mathcal I } _n $ , ARGES-skeleton based on $ \\hat { \\mathcal U } _n $ and GES respectively , with the scoring criterion $ \\mathcal S_ { \\lambda_n } $ . Then there exists a sequence $ \\lambda_n\\to 0 $ such that $ \\lim_ { n\\to\\infty } \\mathbb P ( \\hat { \\mathcal C } _n=\\mathcal C_ { n0 } ) =\\lim_ { n\\to\\infty } \\mathbb P ( \\breve { \\mathcal C } _n=\\mathcal C_ { n0 } ) =\\lim_ { n\\to\\infty } \\mathbb P ( \\tilde { \\mathcal C } _n=\\mathcal C_ { n0 } ) =1. $ '"}, "1": {"review_id": "S1g2skStPB-1", "review_text": "In this paper, the authors propose an RL-based structure searching method for causal discovery. The authors reformulate the score-based causal discovery problem into an RL-format, which includes the reward function re-design, hyper-parameter choose, and graph generation. To my knowledge, it\u2019s the first time that the RL algorithm is applied to causal discovery area for structure searching. The authors\u2019 contributions are: (1) re-design the reword function which concludes the traditional score function and the acyclic constraint (2) Theoretically prove that the maximizing the reward function is equivalent to maximizing the original score function under some choices of the hyper-parameters. (3) Apply the reinforce gradient estimator to search the parameters related to adjacency matrix generation. (4) In the experiment, the authors conduct experiment on datasets which includes both linear/non-linear model with Gaussian/Non-gaussian noise. (5) The authors public their code for reproducibility. Overall, the idea of this paper is novel, and the experiment is comprehensive. I have the following concerns. (1) In page 4 Encoder paragraph, the authors mention that the self-attention scheme is capable of finding the causal relationships. Why? In my opinion, the attention scheme only reflects the correlation relationship. The authors should give more clarifications to convince me about their beliefs. (2) The authors first introduce the h(A) constraint in eqn. (4), and mentioned that only have that constraint would result in a large penalty weight. To solve this, the authors introduce the indicator function constraint. What if we only use the indicator function constraint? In this case, the equivalence is still satisfied, so I am confused about the motivation of imposing the h(A) constraint. (3) In the last paragraph of page 5, why the authors adjust the predefined scores to a certain range? (4) Whether the acyclic can be guaranteed after minimizing the negative reward function (the eqn.(6))? I.e., After the training process, whether the graph with the best reward can be theoretically guaranteed to be acyclic? (5) In section 5.3, the authors mention that the generated graph may contain spurious edges? Whether the edges that in the cyclic are spurious? Whether the last pruning step contains pruning the cyclic path? (6) In the experiment, the authors adopt three metrics. For better comparison, the author should clarify that: the smaller the FDR/SHD is, the better the performance, and the larger the TPR is, the better the performance. (7) From the experimental results, the proposed method seems more superiors under the non-linear model case. Why? Could the authors give a few sentences about the guidance of the model selection in the real-world? i.e., when to select the proposed RL-based method? And under which case to choose RL-BIC, and which case to selection RL-BIC2? (8) What\u2019s training time, and how many samples are needed in the training process? Minor: 1. In the page 4 decoder section, the notation of enc_i and enc_j is not clarified. 2. On page 5, the \\Delta_1 and \\Delta_2 are not explained. 3. For better reading experience, in table 1,2,3,4, the authors should bold value that has the best performance. ", "rating": "8: Accept", "reply_text": "( 8 ) 'What \u2019 s training time , and how many samples are needed in the training process ? ' We did not include the training time because we used different machines for our experiments . The implementation of benchmark methods can also be optimized to reduce time ( e.g. , DAG-GNN 's codes did not work with GPU ) and the results may be somehow inaccurate . Here we just provide a rough description with 12-node linear data models : - Traditional methods PC and GES were run on a laptop with Intel 4-core i7 CPU , and produced the estimated result within 10 seconds ; - NOTEARS and ICA-LiNGAM were also run on the laptop and can be finished in 1~3 minutes ( we set the maximum number of iterations of the ICA algorithm to be 20,000 , ten times of the default number used by the ICA-LiNGAM authors ) ; - CAM was run on the same laptop and typically required 7~8 minutes ; - Our algorithms RL-BIC and RL-BIC2 were run with Intel Xeon 3.20GHz CPU and Nvidia Quadro RTX 5000 GPU . Both methods took about 30~40 minutes with 12-nodes graphs and 20,000 iterations . For 30-node graphs and 30,000 iterations , they needed around 3 hours ; - DAG-GNN took about 1 hour with the same Intel Xeon 3.20GHz CPU ( their codes with GPU option did not work ; the algorithm in fact did not require such a long time to reach convergence , yet no early stopping choice was provided in the codes ) ; - GraN-DAG with the same CPU and GPU took about 20~30 minutes . Regarding the sample number , we have given the number of samples in each experiment description . ( 9 ) Minor : 1 . 'In the page 4 decoder section , the notation of enc_i and enc_j is not clarified . ' Actually $ enc_i $ is given in the last sentence of the encoder part . 2 . 'On page 5 , the \\Delta_1 and \\Delta_2 are not explained . ' Thanks for pointing this out . We will add a definition for the two notations . 3 . 'For better reading experience , in table 1,2,3,4 , the authors should bold value that has the best performance . ' Thanks for this suggestion . We have considered doing so , but it is usually the case that a method that has the best TPR does not achieve the lowest FDR , and only making one in bold seems insufficient to evaluate the overall performance of a method . If possible , can the reviewer give further suggestion on this part ? Thanks ."}, "2": {"review_id": "S1g2skStPB-2", "review_text": "This work addresses the task of causal discovery. The proposed contribution is to apply prior work which uses reinforcement learning for combinatorial optimization to structure learning. Specifically, the proposed optimization problem seeks to maximize a penalized score criterion subject to the acyclicity constraint proposed by Zheng, et al. Empirical results show the proposed method performing favorably in contrast to prior art. Overall I think this is a sensible idea, and the authors do a nice job of exposition, and empirical evaluation. My concerns are as follows: * The novelty is somewhat limited, since the paper is combining two previously proposed ideas (combinatorial search and the acyclicity constraint) for structure learning. * The paper is loose with technical points. Specifically, the authors claim to use the additive noise model, but then make no restrictions on f(). In this setting, it is fairly well known that we can only hope to learn up to the Markov equivalence class (not the fully directed graph), but there is no mention of this in the paper. With all of this said, I think overall the paper is an interesting addition to the causal discovery literature. ", "rating": "8: Accept", "reply_text": "We are grateful to the reviewer 's effort and the positive comment on our paper . We are revising the paper by taking into accounts all the reviewers ' comments/suggestions , and the revised version will be uploaded at a later time within this week . * Regarding 'The novelty is somewhat limited , since the paper is combining two previously proposed ideas ( combinatorial search and the acyclicity constraint ) for structure learning ' : These two ideas are indeed important to our RL based approach to causal discovery . Here we would like to briefly discuss the necessity of the acyclicity constraint from Zheng et al.With the proposed penalty weights in our work , Zheng et al. \u2019 s acyclicity constraint $ h ( A ) $ is used to guide the RL agent to generate directed graphs \u2018 closer \u2019 to be acyclic and the indicator function w.r.t.acyclicity aims to induce exact DAGs . The major benefit of $ h ( A ) $ , or more precisely , $ h ( W\\circ W ) $ ( $ W $ denotes the weighted adjacent matrix if it exists , e.g. , for linear models , and $ \\circ $ denotes Hadamard product ) , is its smoothness that enables continuous optimization for structure learning . This property is not utilized in our approach , and we believe other acyclicity functions , which measure certain \u2018 distance \u2019 of a directed graph to be acyclic and do not need to be differentiable , can also be used here . We will add more discussions on this point in the revision . * Regarding 'The paper is loose with technical points . Specifically , the authors claim to use the additive noise model , but then make no restrictions on f ( ) . In this setting , it is fairly well known that we can only hope to learn up to the Markov equivalence class ( not the fully directed graph ) , but there is no mention of this in the paper ' : Thanks for this helpful comment . We will add a sentence in Section 2 to state this result , along with the fact that we use fully identifiable models to generate observations in our experiments . We once again appreciate the reviewer \u2019 s effort on reviewing our paper ."}}