{"year": "2020", "forum": "S1lSapVtwS", "title": "Stochastic Conditional Generative Networks with Basis Decomposition", "decision": "Accept (Poster)", "meta_review": "Main content: BasiGAN, a novel method for  introducing stochasticity in conditional GANs\nSummary of discussion:\nreviewer1: interesting work and results on GANs. Reviewer had a question on pre-defned basis but i think it was answered by the authors. \nreviewer3: interesting and novel work on GANS, wel-written paper and improves on SOTA. The main uestion is around bases again like reviewer 1, but it seems the authors have addressed this.\nreviewer4: Novel interesting work. Main comments are around making Theorem 1 more theoretically correct, which it sounds like the authors addressed.\nRecommendation: Poster. Well written and novel paper and authors addressed a lot of concerns. ", "reviews": [{"review_id": "S1lSapVtwS-0", "review_text": "In this paper, the authors introduce BasisGAN, a novel method for introducing stochasticity in conditional GANs, i.e., a way of conducting one-to-many mappings. This is a good addition in the literature as: (a) most of the widely-used conditional GANs such as pix2pix (Isola et al., 2016) or pix2pixHD (Wang et al., 2018) are deterministic (i.e., for a specific input a single output is always generated), (b) it improves upon the current SOTA in one-to-many mappings, (c) it is very useful application-wise. As also stated in the paper, there is a number of applications where this method is handy (e.g., converting a sketch to images varying in colors, etc.). I am leaning towards accepting this paper as this work is well-motivated and found the idea of using the basis generator to learn the bases for the generation of the parameters quite interesting. This is the main contribution and difference of this paper in comparison to DCFNet (Qiu et al., ICML 2018), where the bases are not learned. Nevertheless, I have the following questions/requests: - How can we tell that the generated bases are indeed bases (e.g., are they orthogonal?) - Please report the number of parameters used in your implementation in comparison to the rest of the methods. - Please provide qualitative results against the compared methods and especially against DSGAN (Qin et al., 2018).", "rating": "6: Weak Accept", "reply_text": "Thanks for the support and the valuable suggestions . * Basis generation In our training , we do not explicitly regularize the orthogonality of the generated basis elements . We provide additional discussion on linear independence in the response to R4 , and have incorporated such additional details in Section 4 and Theorem 1 . * Number of parameters The number of trainable parameters is updated in supplemental material Table A.3 . Adopting basis generator achieves fewer trainable parameters , thanks to the small number of basis elements and tiny structure of basis generators . This is critical to make the proposed framework and system trainable and manageable . Regularization based method like MSGAN and DSGAN do not reduce parameter numbers of the underlying network models . We have further discussed this in Section 5.2 . * Qualitative results Thanks for your valuable suggestions and we have included qualitative comparisons in supplemental material Figure A.3 ."}, {"review_id": "S1lSapVtwS-1", "review_text": "The paper proposes a new conditional GAN architecture. In particular, in order to allow for further diversity in conditional signal generation, the BasiGAN proposes to model the convolutional layers as a combination of basis which is stochastically sampled. The idea of the paper is interesting and some interesting experiments are presented. Nevertheless, I do not quite get why a set of predefined random basis would enforce more variability than the non-parametric way of training which is currently applied for conditional-GANs. If I get a convincing answer from the authors, I would definitely accept the paper (which otherwise is well-written and quite interesting to read). ", "rating": "6: Weak Accept", "reply_text": "Thanks for the support . Instead of sampling predefined random basis , we learn in our network basis generators , in the form of tiny neural networks , that generate stochastic basis elements from random latent codes ( details in Figure 1 ) , which thus introduces great variability to the features and the output images without increasing dimensions to an unmanageable level . We have revised the last paragraph of Section 4 to further clarify this ."}, {"review_id": "S1lSapVtwS-2", "review_text": "The paper proposes a model for stochasticity for conditional image generation, building upon the previously available (DCFNet) results on composition of convolutional filters out of the elements of the filter basis. The idea of introducing stochasticity by convolutional filters into the conditional generative models seems to be novel and the reviewer thinks it could be of interest for the community. The following remarks could be given to improve the presentation: 1) Theorem 1 is an existence theorem, so it does not give the procedure for construction of the basis. Does the construction procedure for the basis, described under the theorem formulation, meet the conditions of Theorem 1? 2) The Theorem 1 formulation states that \u201c If there exists a set of deterministic linear transforms\u201d. Should the linear independence be stated as well as one of the theorem conditions ( so that the space dimensionality would indeed be K)? 3) The reviewer finds the structure of Section 4 confusing: it starts from the problem statement (first paragraph 'Using the method above, filters of each stochastic layer\u2026\u2019), then provides the description of the approach and only then outlines Theorem 1. It might be that stating Theorem 1 and then defining the method for generation of the basis (how exactly could we get to the basis? ) could improve readability of the paper. Essentially, the question is: is there any way to emphasise the procedure for filter generation and inform the reader in which circumstances these filters would be the basis (e.g. why it wouldn't be prone to the analogue of mode collapse when the filters do not effectively have enough diversity for linear independence)? *** In addition to this list, it might be useful to provide some evidence on whether there is any inherent mechanism to regulate the diversity of filters and therefore of samples (so that to change the variability of the conditional samples from the model with the impact analogous to the one of temperature in Glow (Kingma et al, 2018)). If there is one, further experimental evidence, which shows the impact on diversity of filters, would contribute to improvement of the paper. ", "rating": "6: Weak Accept", "reply_text": "Thanks for your support and all the insightful suggestions . * Construction procedure for the basis The network construction procedure meets the condition of Theorem 1 , that is , we constrain the number of basis to a small number of K ( e.g.K=7 ) , which imposes low-rankness of the generated filters as stated in Theorem 1 . As discussed in Section 4 , when we directly generate random convolution filters , we consistently observe that the obtained filters are always of low effective rank . This observation of low-rankness motivates our construction of non-random ( trainable ) 1x1 convolutional layers ( $ a_k $ 's ) and randomly generated basis layers . In the revised version , we additionally present an ablation study in supplemental material Section E and Table A.2 to show that increasing K , i.e.using more basis elements , does not provide any performance improvement . We thus think K may serve as a parameter to regularize the model , also see below in `` Model collapse '' . * Linear Independence Theoretically , linear independence is not needed for Theorem 1 to hold . In case that $ a_k $ 's are linearly dependent , it does not affect the existence result of the theorem , and the dimensionality of the subspace ( the true rank ) will be K ' < K. We have revised the proof in supplemental material Section B to clarify this point . In practice , the trained $ a_k $ 's are of rank-K , due to that the choice of relatively small K is a tight restriction of the model . * Mode collapse In all experiments on real-world datasets , our model does not develop mode collapse as shown by the good diversity score . We are working to understand the precise relation between the fidelity-diversity trade-off . Based on the experiments ( see supplemental material Table A.2 ) so far , we think the constraint rank K serves as a parameter to regularize the generative model . We will keep this as a direction of future efforts . The content of Section 4 is organized as following : we start with filter generation , which introduces stochasticity with considerable cost . Based on the low rank observation of generated filters , we further propose to decompose filters into bases with stochasticity and deterministic coefficients . And the decomposition is further supported by Theorem 1 , which shows that it suffices to generate bases in order to generate the desired distribution of filters . We then provide detail on the process of basis generation , and how we construct the proposed BasisGAN with basis generators ."}], "0": {"review_id": "S1lSapVtwS-0", "review_text": "In this paper, the authors introduce BasisGAN, a novel method for introducing stochasticity in conditional GANs, i.e., a way of conducting one-to-many mappings. This is a good addition in the literature as: (a) most of the widely-used conditional GANs such as pix2pix (Isola et al., 2016) or pix2pixHD (Wang et al., 2018) are deterministic (i.e., for a specific input a single output is always generated), (b) it improves upon the current SOTA in one-to-many mappings, (c) it is very useful application-wise. As also stated in the paper, there is a number of applications where this method is handy (e.g., converting a sketch to images varying in colors, etc.). I am leaning towards accepting this paper as this work is well-motivated and found the idea of using the basis generator to learn the bases for the generation of the parameters quite interesting. This is the main contribution and difference of this paper in comparison to DCFNet (Qiu et al., ICML 2018), where the bases are not learned. Nevertheless, I have the following questions/requests: - How can we tell that the generated bases are indeed bases (e.g., are they orthogonal?) - Please report the number of parameters used in your implementation in comparison to the rest of the methods. - Please provide qualitative results against the compared methods and especially against DSGAN (Qin et al., 2018).", "rating": "6: Weak Accept", "reply_text": "Thanks for the support and the valuable suggestions . * Basis generation In our training , we do not explicitly regularize the orthogonality of the generated basis elements . We provide additional discussion on linear independence in the response to R4 , and have incorporated such additional details in Section 4 and Theorem 1 . * Number of parameters The number of trainable parameters is updated in supplemental material Table A.3 . Adopting basis generator achieves fewer trainable parameters , thanks to the small number of basis elements and tiny structure of basis generators . This is critical to make the proposed framework and system trainable and manageable . Regularization based method like MSGAN and DSGAN do not reduce parameter numbers of the underlying network models . We have further discussed this in Section 5.2 . * Qualitative results Thanks for your valuable suggestions and we have included qualitative comparisons in supplemental material Figure A.3 ."}, "1": {"review_id": "S1lSapVtwS-1", "review_text": "The paper proposes a new conditional GAN architecture. In particular, in order to allow for further diversity in conditional signal generation, the BasiGAN proposes to model the convolutional layers as a combination of basis which is stochastically sampled. The idea of the paper is interesting and some interesting experiments are presented. Nevertheless, I do not quite get why a set of predefined random basis would enforce more variability than the non-parametric way of training which is currently applied for conditional-GANs. If I get a convincing answer from the authors, I would definitely accept the paper (which otherwise is well-written and quite interesting to read). ", "rating": "6: Weak Accept", "reply_text": "Thanks for the support . Instead of sampling predefined random basis , we learn in our network basis generators , in the form of tiny neural networks , that generate stochastic basis elements from random latent codes ( details in Figure 1 ) , which thus introduces great variability to the features and the output images without increasing dimensions to an unmanageable level . We have revised the last paragraph of Section 4 to further clarify this ."}, "2": {"review_id": "S1lSapVtwS-2", "review_text": "The paper proposes a model for stochasticity for conditional image generation, building upon the previously available (DCFNet) results on composition of convolutional filters out of the elements of the filter basis. The idea of introducing stochasticity by convolutional filters into the conditional generative models seems to be novel and the reviewer thinks it could be of interest for the community. The following remarks could be given to improve the presentation: 1) Theorem 1 is an existence theorem, so it does not give the procedure for construction of the basis. Does the construction procedure for the basis, described under the theorem formulation, meet the conditions of Theorem 1? 2) The Theorem 1 formulation states that \u201c If there exists a set of deterministic linear transforms\u201d. Should the linear independence be stated as well as one of the theorem conditions ( so that the space dimensionality would indeed be K)? 3) The reviewer finds the structure of Section 4 confusing: it starts from the problem statement (first paragraph 'Using the method above, filters of each stochastic layer\u2026\u2019), then provides the description of the approach and only then outlines Theorem 1. It might be that stating Theorem 1 and then defining the method for generation of the basis (how exactly could we get to the basis? ) could improve readability of the paper. Essentially, the question is: is there any way to emphasise the procedure for filter generation and inform the reader in which circumstances these filters would be the basis (e.g. why it wouldn't be prone to the analogue of mode collapse when the filters do not effectively have enough diversity for linear independence)? *** In addition to this list, it might be useful to provide some evidence on whether there is any inherent mechanism to regulate the diversity of filters and therefore of samples (so that to change the variability of the conditional samples from the model with the impact analogous to the one of temperature in Glow (Kingma et al, 2018)). If there is one, further experimental evidence, which shows the impact on diversity of filters, would contribute to improvement of the paper. ", "rating": "6: Weak Accept", "reply_text": "Thanks for your support and all the insightful suggestions . * Construction procedure for the basis The network construction procedure meets the condition of Theorem 1 , that is , we constrain the number of basis to a small number of K ( e.g.K=7 ) , which imposes low-rankness of the generated filters as stated in Theorem 1 . As discussed in Section 4 , when we directly generate random convolution filters , we consistently observe that the obtained filters are always of low effective rank . This observation of low-rankness motivates our construction of non-random ( trainable ) 1x1 convolutional layers ( $ a_k $ 's ) and randomly generated basis layers . In the revised version , we additionally present an ablation study in supplemental material Section E and Table A.2 to show that increasing K , i.e.using more basis elements , does not provide any performance improvement . We thus think K may serve as a parameter to regularize the model , also see below in `` Model collapse '' . * Linear Independence Theoretically , linear independence is not needed for Theorem 1 to hold . In case that $ a_k $ 's are linearly dependent , it does not affect the existence result of the theorem , and the dimensionality of the subspace ( the true rank ) will be K ' < K. We have revised the proof in supplemental material Section B to clarify this point . In practice , the trained $ a_k $ 's are of rank-K , due to that the choice of relatively small K is a tight restriction of the model . * Mode collapse In all experiments on real-world datasets , our model does not develop mode collapse as shown by the good diversity score . We are working to understand the precise relation between the fidelity-diversity trade-off . Based on the experiments ( see supplemental material Table A.2 ) so far , we think the constraint rank K serves as a parameter to regularize the generative model . We will keep this as a direction of future efforts . The content of Section 4 is organized as following : we start with filter generation , which introduces stochasticity with considerable cost . Based on the low rank observation of generated filters , we further propose to decompose filters into bases with stochasticity and deterministic coefficients . And the decomposition is further supported by Theorem 1 , which shows that it suffices to generate bases in order to generate the desired distribution of filters . We then provide detail on the process of basis generation , and how we construct the proposed BasisGAN with basis generators ."}}