{"year": "2021", "forum": "foNTMJHXHXC", "title": "Out-of-Distribution Generalization via Risk Extrapolation (REx)", "decision": "Reject", "meta_review": "The paper is proposing Risk Extrapolation (REX) as a domain generalization algorithm. Authors extends the distributionally robust learning to affine mixture of distributions from convex mixture. Authors later uses variances instead of this extension and demonstrate various empirical and theoretical properties. The paper is reviewed by four expert reviewers and the reviewers did not reach to a consensus. Hence, I also read the paper in detailed and reviewed it. In summary, reviewers argue the following:\n\n- R#2: Main argument is the lack of justification of the claim \"Rex could deal with both covariate and concept shift together\". Authors try to address this in their response. Moreover, reviewer also argues in the private discussion that manuscript is not updated and authors did not address any of the issues during the discussion period.\n- R#3: Argues that (similar to R#2), dealing with covariate shift is not explained properly. Reviewer is not persuaded that REX results in invariant prediction.\n- R#1 and R#4: Largely positive about the paper. In the mean time, argue that organization of the paper is lacking and some of the material in the supplement is relevant and should be moved to the main text. R#1 decreases their score due to the lack of re-organization during the discussion.\n\nThe value of the paper is clear to me, the joint treatment of minimax perspective, domain generalization and invariances is definitely interesting and valuable. Hence, the paper has merit to be published. However, the presentation is lacking significantly.  The main contribution of the paper lies in Table 1 but the invariant prediction property is not justified at all in the main text. Hence, Table 1 is not justified properly. Authors discuss Thm 1&2 in their response but they both are in the supplement. From reading only the main text, confusion of the reviewers are well justified. ICLR guidelines clearly states that \"...Note that reviewers are encouraged, but not required to review supplementary material during the review process...\" It is authors' responsibility to make the main paper self contained. Even more worrisome is the fact that authors dismiss this concern in their response to R#1 which eventually leads to R#1 decreasing their score. Hence, I decided to reject the paper since the presentation is subpar and authors did not persuaded reviewers that they can fix this presentation issue by the camera-ready deadline. On the other hand, I think the paper can be really influential if it was written clearly. I suggest authors to revise the claims more precisely, extended the discussion on the claims and move the theorems to the main paper.", "reviews": [{"review_id": "foNTMJHXHXC-0", "review_text": "Summary : This paper addresses the problem of distributional shift in transfer learning from multiple training domains . The authors propose Risk Extrapolation ( REx ) , which is a novel approach for out-of-distribution generalization when the new test domain for which we do not even have the covariate matrix . Thorough empirical experiments show that REx significantly outperforms state-of-the-art . Pros : - This is a highly quality paper with strong theoretical and empirical results . - The paper is clearly written and easy to understand . - Based on the thorough literature review , this idea of this work is original . - The results of this work are highly significant and of interest to the domain adaptation and transfer learning community . Cons : - Although I understand the page limit , most of the major parts of the paper ( especially the theoretical aspects ) can be found in the appendix . As a person who is not very familiar with the literature on distributional shift from multiple domains , I did appreciate having this thorough overview ; however , the detailed discussions of the contributions of the paper might be overlooked if ( when ) located in the appendix . Specifically , there is only half a page on introducing the proposed methods for REx in Sec.3.1.Minor comment ( s ) : - Reference \u201c Peter B\u00fchlmann . Invariance , causality and robustness , 2018a. \u201d is duplicated . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Post-Rebuttal : After reviewing the concerns raised by the other reviewers , and the responses provided by the authors , I have decided to adjust my scores . Moreover , I was disappointed that the authors did not use the extra one page to move some material from the appendix to the main text in order to elaborate on the proposed method .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your review . We found it hard to decide which material to leave out of the main text . Ultimately , we decided to focus on communicating the key ideas and intuitions of the paper with maximal clarity in the main text . We 'd love any more specific suggestions for which content you 'd like to see cut from or added to the main text . In particular , other reviewers suggested cutting Algorithm 1 and Figure 3 , and including theoretical results from Appendix E. What do you think of those suggestions ?"}, {"review_id": "foNTMJHXHXC-1", "review_text": "Overview : The authors propose Risk Extrapolation ( Rex ) which is an invariance-based approach to domain generalization . The main idea is to go from worst-casing over a convex combination of domains to an affine set of domains ( MM-Rex ) or to penalize the variance ( V-Rex ) . Evaluations compare to IRM and ERM and show uniform improvements . Positives : The paper has a well written and motivated introduction , and there 's substantial added expository material in the supplement . I would maybe tone down on the amount of bolded text . The arguments are pretty well-thought-out , including some discussion of the differences between causal recovery , invariant prediction , and domain generalization . The method itself seems simple ( in a good way ) , though I have some questions below . I also wonder if the variance version of the objective can be tied to DRO based approaches via the fact that DRO on a chi-squared perturbation ball is equivalent to variance regularization of the risk . The method seems to work well overall compared to IRM , and although it only matches ERM in the domain generalization benchmark , I think this is still a decent result given that most methods underperformed ERM . Negatives : This is possibly a comment that refers to a paper that 's too recent , so not addressing this comment wo n't affect my rating of the paper , but it seems worthwhile from a scientific perspective to address how recent negative theory results ( Rosenfeld , Ravikumar , Risteski 2020 ) about IRM ( and REx ) affect the intro framing . In particular , I 'd like to see the claim in the intro about how REx can extrapolate can be reconciled with the claims in the other paper that IRM and REx succeed under the same conditions as ERM . As a note : I also do n't think Williamson and Menon suggest the use of variance of risks . They explicitly state that the R_ { sd } risk aggregator is not a fairness risk measure . The risks fulfilling the axioms in that paper are coherent risk measures , and I believe they will all fall under the category of RI methods through duality arguments . I can believe that minimizing the max risk is a reasonable thing to do , but it seems like an added leap of faith to want to actively increase the risk of the other domains since minimax risk would naturally equalize the different domains ( if it 's possible to achieve equal risk ) . It would be nice to see a clearer justification for this behavior . Having looked at the supplement , there 's substantial and good material there , and I would maybe suggest that the authors cut something like figure 3 and algorithm 1 to bring back some more intuition and motivation about REx , maybe some result from section E. Having looked at the Thm 1 result , would n't 3 interventions on every variable also recover the true beta with ERM ? This result also depends very heavily on fixed noise across environments . I do think this is a neat result though , and it might be useful to use this to give additional intuition about REx in the main text . Does E.1.2 require pointwise homoskedasticity ? that seems wildly strong for a general result ... In classification , I think this means that the map from x \u2192 y has to be deterministic and in general , for any log-probably loss , this says that the entropies have to be identical everywhere . Minor : Might be worth re-stating what the methods are in the experiment section ( RI , for example , is defined pretty early on ) . DRO is usually expanded to distributionally robust optimization , not domain robust optimization . Figure 3 seems unnecessary . Is Epsilon_j in the statement of Theorem 1 a typo ? is there a typo in the subscript of beta_j = beta_ { 0 , j } for all j ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the review , and the questions and pointers . Some responses , ordered as in your review : * We agree that the variance-based penalty can be related to the DRO version , and plan to include this in our revision . * Thanks for mentioning the Rosenfeld , Ravikumar , Risteski paper . We have n't had time to look at it yet , but are interested in discussing it further . Could you perhaps elaborate a bit , e.g.characterize these negative results and/or point to specific parts of the paper ? * We 'll take a closer look at Williamson and Menon and get back to you on this point . * In fact , minimax does * not * equalize risk across different domains . Figure 3 ( right ) provides a demonstration : beta=0 gives better minimax ( training ) risk , but * worse * test risk . This is because paying more attention to color reduces risk on * both * training domains , but also * increases * the difference between training risks , and the risk on the * test * domain . This example should help explain out intuition for enforcing * exact * equality , as well as why DRO fails to do so , and thus can not serve as a method for invariant prediction . Please let us know if any of this is still unclear . * We 'll move some of the results such as statements of theorems to the main text , and would love more suggestions as to which material from the appendix would be most valuable to include in the main text . * No , ERM is sensitive to the number of examples from different domains ; see the Remark on page 18 . In particular , we can consider the case where $ 1-\\epsilon $ of the data comes from the observational distribution ( with no interventions ) , and $ \\epsilon $ of the data comes from other domains . Then the ERM objective is easily dominated by the loss on the observational distribution . * Yes , the assumptions for E.1.2 are indeed strong , although I 'm not sure exactly what you mean by `` pointwise '' homoskedasticity . The homoskedasticity assumption could be replaced with a `` no covariate shift '' assumption . Note that IRM does n't require either assumption , but also ( unlike REx ) fails to provide robustness to covariate shift in the limited data regime . It is possible in principle to control for the effects of covariate shift in the infinite data/capacity ( `` realizable '' ) case using variant of REx , but we were advised in a previous review cycle to remove this content , which is still somewhat a work-in-progress . Ultimately , we seek a method of invariant prediction that provides robustness to covariate shift in the limited data/capacity case , which does not require such strong assumptions ; it seems like such a method would need to distinguish between inputs x that have high loss due to 1 ) inherent noise vs. 2 ) underfitting . * Thanks for the minor comments ; we 'll implement the suggestions in our revision ( except we might keep Figure 3 , space permitting ) ."}, {"review_id": "foNTMJHXHXC-2", "review_text": "This paper studies the out-of-distribution ( OOD ) generalisation problem via risk extrapolation ( REx ) . The authors propose two methods , MM-REx and V-REx , and empirically show that REx can recover the causal mechanisms on Colored MNIST , while also providing some robustness to covariate shift . The authors deal with the relationship between robustness , invariance and causality carefully , and provide experimental evidence beyond Colored MNIST . I vote for weakly rejecting . This paper reviews various previous work but does not provide a clear comparison from them . I have some comments and questions as follows : 1 . Contribution 1 and Table 1 state that REx is suitable for invariant prediction . In the experiments , the authors also take IRM as the competitor . So I think the main objective of REx is the invariant prediction , rather than covariate shift . However , the authors emphasize that REx can deal with covariate shift . Please explain more on how REx discovers the invariant prediction . 2.When considering the invariant prediction , we aim to discover a stable conditional distribution $ P ( Y|X ) $ or an invariant conditional mean $ E [ Y|X ] . $ However , the covariate shift refers to the changes in the distribution of X . What is the novelty of assuming covariate shift here ? Please also figure out the importance of considering covariate shift under the invariant prediction . 3.What is the expression ( 1 ) in Page 1 ? If ( 1 ) is the risk function of the OOD generalization problem , $ \\mathcal { F } $ is unseen and should be the same throughout this paper . At the end of Page 1 , you say : `` Our method minimax Risk Extrapolation ( MM-REx ) is an extension of DRO where $ \\mathcal { F } $ instead contains affine combinations of training risks , see Figure 1 . '' Does MM-REx solve a different OOD problem ? Please figure out the definitions of $ \\mathcal { F } $ of DRO , MM-REx and IRM respectively . 4.Please explain Contribution 3 . In general , the equality of risks is not a sufficient condition of the causality . 5.In the VLCS and PACS experiments , the evaluation is incorrect . In Section 4.3 , the task is to train on three domains and generalize to the fourth one at test time . However , this test accuracy is not worst-case performance . According to ( 1 ) , the problem is to generalize to all four domains at test time and to find out the worst domain . Then Table 3 should report the average of the worst-domain accuracy .", "rating": "5: Marginally below acceptance threshold", "reply_text": "It looks to us like this is the main reason given for rejecting our submission : `` This paper reviews various previous work but does not provide a clear comparison from them . '' Can you please elaborate on this critique ? And/or explain what , if not this , are the main reasons for recommending rejection ? To clarify our position : - We consider the methods listed in Table 1 to be our primary points of comparison . - This table is meant to provide a summary of the qualitative advantages of REx over these alternatives , i.e.a clear comparison . - Arjovsky et al.2019 already demonstrated IRM 's advantages over the other methods listed . - Our work focuses on comparing REx with IRM , and especially the advantage REx has in handling covariate shift . We believe our experiments ( 4.1,4.2,4.4 ) , and mathematical analyses ( C.2 ) provide a clear comparison ."}, {"review_id": "foNTMJHXHXC-3", "review_text": "This manuscript studies the problem of domain generalization and proposes a method , dubbed Rex , for this purpose . The main movitation of this work over the invariant risk minimization ( IRM ) [ 1 ] paradigm is that IRM is not robust to covariate shift , while the authors claim that Rex can deal with both covariate shift and concept shift together . Although the argument that IRM is not robust to covariate shift in the feature space is true , out-of-domain generalization is not the original goal of IRM either . My main concern is that it is not clear to me why Rex could deal with both covariate and concept shift together , as from the optimization formulation in Eq . ( 6 ) , neither invariant predictor nor invariant representation is enforced . In particular , no theoretical analysis is given to justify this claim . Perhaps what adds more confusion to me is that , what 's the meaning of negative probability since the authors allow the combination weight \\lambda of different domains to be negative ? As the authors have already pointed out on page 5 ( Probabilities vs Risks ) , the risk is a linear functional of the joint distribution over X and Y , hence using affine combination in the risk functions from different domains directly translate to allowing the use of negative coefficient for probabilities . This is quite strange , since the mixture distribution is only a convex combination , not affine combination . Furthermore , I also found some of the discussions in the related work section misleading : - `` The first method for invariant prediction ... is IRM '' . This is not correct . As the authors have already realized , ICP [ 2 ] has been proposed in 2015 , and the definition of IRM is essentially the same as ICP . - The discussions about invariant representations on page 4 are not accurate . Only P_e ( \\phi ) ( but not P_e ( \\phi | Y ) ) is called invariant representations , and only this one can fail domain adaption if the marginal label distributions differ . The C-ADA does not try to find invariant P_e ( \\phi | Y ) . Instead , it tries to find invariant P_e ( \\phi x \\hat { Y } ) , where \\hat { Y } is the classifier output , and this is precisely the reason why C-ADA also fails under different label distributions . See more discussions in [ 4 ] . In fact , it has recently been shown in [ 4 ] that matching P_e ( \\phi | Y ) provably works for domain adaptation , see Theorem 3.1 of [ 4 ] . - `` Also , unlike Rex , IRM seeks to match E [ Y | \\phi ] , not the full P ( Y | \\phi ) '' . Again , this discussion is misleading . For the purpose of out of domain generalization , the learner does not need to match the full distributions P ( Y | \\phi ) . Only the conditional mean matters . See Theorem 4.1 of [ 5 ] as well as Theorem 3.3 of [ 6 ] in the context of fairness . - About the discussion on fairness of equalizing risk across groups . In fact a sufficient condition for this goal has been proved in Theorem 3.3 of [ 6 ] . Given the close relationship between these two problems , I feel it 's necessary to cite and have a discussion of this result here as well . More detailed comments : - The reference of David et al. , 2010 should be Ben-David et al.2010 on page 2 - I think the naming of invariant prediction on page 2 is not very accurate . To be precise , as long as the same hypothesis ( classifier ) is used over different domains , this amounts to be an invariant prediction rule . Instead , what IRM enforces is the invariant OPTIMAL predictor , i.e. , invariant conditional means . - Eq . ( 3 ) is not correct : the second term is a weighted combination of samples from different domains , where the larger the sample size from a domain the more weight it has in the combination . However , the right most term has a wrong weight for a domain . The correct one should be |D_e| / \\sum_e |D_e| . - On page 4 , the citation of Pan et al.2010 is not accurate . Invariant representations for domain adaptation is first proposed by [ 3 ] . [ 1 ] Invariant Risk Minimization [ 2 ] Causal inference using invariant prediction : identification and confidence intervals [ 3 ] Unsupervised Domain Adaptation by Backpropagation [ 4 ] Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift [ 5 ] On Learning Invariant Representation for Domain Adaptation [ 6 ] Inherent Tradeoffs in Learning Fair Representations", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . As I understand it , you were not convinced that REx can provide robustness by encouraging both : 1 ) robustness to covariate shift and 2 ) invariant prediction . This is indeed a central claim of our paper , which we believe is well supported experimentally and conceptually . Responding to your statements in more detail : > Although the argument that IRM is not robust to covariate shift in the feature space is true , out-of-domain generalization is not the original goal of IRM either . We 're not sure we 've understood this argument . Can you clarify what you mean by this ? Our understanding is that out-of- * distribution * ( OOD ) generalization is the goal of IRM . Would you agree ? Did you mean something different by out-of- * domain * generalization ? As support the claim that IRM * is * focused on OOD generalization , we offer this quote from the abstract of Arjovsky et al.2019 : `` we leverage tools from causation to develop the mathematics of spurious and invariant correlations , in order to alleviate the excessive reliance of machine learning systems on data biases , allowing them to generalize to new test distributions . '' We also refer to Arjovsky 's thesis ( see : https : //cs.nyu.edu/dynamic/reports/ ? type=PhD ) , titled `` Out of Distribution Generalization in Machine Learning '' , which is simply a somewhat expanded version of Arjovsky et al. , 2019 . In this thesis they also note that IRM may not help in the `` realizable '' case , where X is already an invariant predictor . In this case , P ( Y|X ) is fixed by assumption , and so only covariate shift occurs . Their discussion of this setting indicates their recognition of covariate shift as an important problem in OOD generalization . Arjovsky 's thesis recognizes this as an apparent limitation of IRM , while providing some arguments for optimism that invariant prediction could help even in this realizable case . > My main concern is that it is not clear to me why Rex could deal with both covariate and concept shift together , as from the optimization formulation in Eq . ( 6 ) , neither invariant predictor nor invariant representation is enforced . In particular , no theoretical analysis is given to justify this claim . * First , we want to note that our experiments provide a demonstration of REx dealing with both covariate and concept shift . * Our work also describes and illustrates conceptually why equalizing risks ( i.e . `` flattening the risk plane '' ) could be expected to provide robustness to the kinds of shifts encountered at training time . In the case of MM-REx this also follows directly from the definition and the linearity of the risk in the P ( X , Y ) . * Appendix C.1/2 also provides simple examples illustrating how REx can encourage robustness to both kinds of shift . * In terms of theory , Appendix E.1 proves that REx can perform causal discovery . This has a close correspondance with invariant prediction , as discussed in Arjovsky et al . ( 2019 ) , although as far as we know , the details of the relationship between these two has not been fully elaborated . We recognize that many of these important results we refer to are in the Appendix , and plan to emphasize these results more clearly in the main text in our revision . We also welcome suggestions regarding which content would be most helpful to move to the main text ."}], "0": {"review_id": "foNTMJHXHXC-0", "review_text": "Summary : This paper addresses the problem of distributional shift in transfer learning from multiple training domains . The authors propose Risk Extrapolation ( REx ) , which is a novel approach for out-of-distribution generalization when the new test domain for which we do not even have the covariate matrix . Thorough empirical experiments show that REx significantly outperforms state-of-the-art . Pros : - This is a highly quality paper with strong theoretical and empirical results . - The paper is clearly written and easy to understand . - Based on the thorough literature review , this idea of this work is original . - The results of this work are highly significant and of interest to the domain adaptation and transfer learning community . Cons : - Although I understand the page limit , most of the major parts of the paper ( especially the theoretical aspects ) can be found in the appendix . As a person who is not very familiar with the literature on distributional shift from multiple domains , I did appreciate having this thorough overview ; however , the detailed discussions of the contributions of the paper might be overlooked if ( when ) located in the appendix . Specifically , there is only half a page on introducing the proposed methods for REx in Sec.3.1.Minor comment ( s ) : - Reference \u201c Peter B\u00fchlmann . Invariance , causality and robustness , 2018a. \u201d is duplicated . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Post-Rebuttal : After reviewing the concerns raised by the other reviewers , and the responses provided by the authors , I have decided to adjust my scores . Moreover , I was disappointed that the authors did not use the extra one page to move some material from the appendix to the main text in order to elaborate on the proposed method .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your review . We found it hard to decide which material to leave out of the main text . Ultimately , we decided to focus on communicating the key ideas and intuitions of the paper with maximal clarity in the main text . We 'd love any more specific suggestions for which content you 'd like to see cut from or added to the main text . In particular , other reviewers suggested cutting Algorithm 1 and Figure 3 , and including theoretical results from Appendix E. What do you think of those suggestions ?"}, "1": {"review_id": "foNTMJHXHXC-1", "review_text": "Overview : The authors propose Risk Extrapolation ( Rex ) which is an invariance-based approach to domain generalization . The main idea is to go from worst-casing over a convex combination of domains to an affine set of domains ( MM-Rex ) or to penalize the variance ( V-Rex ) . Evaluations compare to IRM and ERM and show uniform improvements . Positives : The paper has a well written and motivated introduction , and there 's substantial added expository material in the supplement . I would maybe tone down on the amount of bolded text . The arguments are pretty well-thought-out , including some discussion of the differences between causal recovery , invariant prediction , and domain generalization . The method itself seems simple ( in a good way ) , though I have some questions below . I also wonder if the variance version of the objective can be tied to DRO based approaches via the fact that DRO on a chi-squared perturbation ball is equivalent to variance regularization of the risk . The method seems to work well overall compared to IRM , and although it only matches ERM in the domain generalization benchmark , I think this is still a decent result given that most methods underperformed ERM . Negatives : This is possibly a comment that refers to a paper that 's too recent , so not addressing this comment wo n't affect my rating of the paper , but it seems worthwhile from a scientific perspective to address how recent negative theory results ( Rosenfeld , Ravikumar , Risteski 2020 ) about IRM ( and REx ) affect the intro framing . In particular , I 'd like to see the claim in the intro about how REx can extrapolate can be reconciled with the claims in the other paper that IRM and REx succeed under the same conditions as ERM . As a note : I also do n't think Williamson and Menon suggest the use of variance of risks . They explicitly state that the R_ { sd } risk aggregator is not a fairness risk measure . The risks fulfilling the axioms in that paper are coherent risk measures , and I believe they will all fall under the category of RI methods through duality arguments . I can believe that minimizing the max risk is a reasonable thing to do , but it seems like an added leap of faith to want to actively increase the risk of the other domains since minimax risk would naturally equalize the different domains ( if it 's possible to achieve equal risk ) . It would be nice to see a clearer justification for this behavior . Having looked at the supplement , there 's substantial and good material there , and I would maybe suggest that the authors cut something like figure 3 and algorithm 1 to bring back some more intuition and motivation about REx , maybe some result from section E. Having looked at the Thm 1 result , would n't 3 interventions on every variable also recover the true beta with ERM ? This result also depends very heavily on fixed noise across environments . I do think this is a neat result though , and it might be useful to use this to give additional intuition about REx in the main text . Does E.1.2 require pointwise homoskedasticity ? that seems wildly strong for a general result ... In classification , I think this means that the map from x \u2192 y has to be deterministic and in general , for any log-probably loss , this says that the entropies have to be identical everywhere . Minor : Might be worth re-stating what the methods are in the experiment section ( RI , for example , is defined pretty early on ) . DRO is usually expanded to distributionally robust optimization , not domain robust optimization . Figure 3 seems unnecessary . Is Epsilon_j in the statement of Theorem 1 a typo ? is there a typo in the subscript of beta_j = beta_ { 0 , j } for all j ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the review , and the questions and pointers . Some responses , ordered as in your review : * We agree that the variance-based penalty can be related to the DRO version , and plan to include this in our revision . * Thanks for mentioning the Rosenfeld , Ravikumar , Risteski paper . We have n't had time to look at it yet , but are interested in discussing it further . Could you perhaps elaborate a bit , e.g.characterize these negative results and/or point to specific parts of the paper ? * We 'll take a closer look at Williamson and Menon and get back to you on this point . * In fact , minimax does * not * equalize risk across different domains . Figure 3 ( right ) provides a demonstration : beta=0 gives better minimax ( training ) risk , but * worse * test risk . This is because paying more attention to color reduces risk on * both * training domains , but also * increases * the difference between training risks , and the risk on the * test * domain . This example should help explain out intuition for enforcing * exact * equality , as well as why DRO fails to do so , and thus can not serve as a method for invariant prediction . Please let us know if any of this is still unclear . * We 'll move some of the results such as statements of theorems to the main text , and would love more suggestions as to which material from the appendix would be most valuable to include in the main text . * No , ERM is sensitive to the number of examples from different domains ; see the Remark on page 18 . In particular , we can consider the case where $ 1-\\epsilon $ of the data comes from the observational distribution ( with no interventions ) , and $ \\epsilon $ of the data comes from other domains . Then the ERM objective is easily dominated by the loss on the observational distribution . * Yes , the assumptions for E.1.2 are indeed strong , although I 'm not sure exactly what you mean by `` pointwise '' homoskedasticity . The homoskedasticity assumption could be replaced with a `` no covariate shift '' assumption . Note that IRM does n't require either assumption , but also ( unlike REx ) fails to provide robustness to covariate shift in the limited data regime . It is possible in principle to control for the effects of covariate shift in the infinite data/capacity ( `` realizable '' ) case using variant of REx , but we were advised in a previous review cycle to remove this content , which is still somewhat a work-in-progress . Ultimately , we seek a method of invariant prediction that provides robustness to covariate shift in the limited data/capacity case , which does not require such strong assumptions ; it seems like such a method would need to distinguish between inputs x that have high loss due to 1 ) inherent noise vs. 2 ) underfitting . * Thanks for the minor comments ; we 'll implement the suggestions in our revision ( except we might keep Figure 3 , space permitting ) ."}, "2": {"review_id": "foNTMJHXHXC-2", "review_text": "This paper studies the out-of-distribution ( OOD ) generalisation problem via risk extrapolation ( REx ) . The authors propose two methods , MM-REx and V-REx , and empirically show that REx can recover the causal mechanisms on Colored MNIST , while also providing some robustness to covariate shift . The authors deal with the relationship between robustness , invariance and causality carefully , and provide experimental evidence beyond Colored MNIST . I vote for weakly rejecting . This paper reviews various previous work but does not provide a clear comparison from them . I have some comments and questions as follows : 1 . Contribution 1 and Table 1 state that REx is suitable for invariant prediction . In the experiments , the authors also take IRM as the competitor . So I think the main objective of REx is the invariant prediction , rather than covariate shift . However , the authors emphasize that REx can deal with covariate shift . Please explain more on how REx discovers the invariant prediction . 2.When considering the invariant prediction , we aim to discover a stable conditional distribution $ P ( Y|X ) $ or an invariant conditional mean $ E [ Y|X ] . $ However , the covariate shift refers to the changes in the distribution of X . What is the novelty of assuming covariate shift here ? Please also figure out the importance of considering covariate shift under the invariant prediction . 3.What is the expression ( 1 ) in Page 1 ? If ( 1 ) is the risk function of the OOD generalization problem , $ \\mathcal { F } $ is unseen and should be the same throughout this paper . At the end of Page 1 , you say : `` Our method minimax Risk Extrapolation ( MM-REx ) is an extension of DRO where $ \\mathcal { F } $ instead contains affine combinations of training risks , see Figure 1 . '' Does MM-REx solve a different OOD problem ? Please figure out the definitions of $ \\mathcal { F } $ of DRO , MM-REx and IRM respectively . 4.Please explain Contribution 3 . In general , the equality of risks is not a sufficient condition of the causality . 5.In the VLCS and PACS experiments , the evaluation is incorrect . In Section 4.3 , the task is to train on three domains and generalize to the fourth one at test time . However , this test accuracy is not worst-case performance . According to ( 1 ) , the problem is to generalize to all four domains at test time and to find out the worst domain . Then Table 3 should report the average of the worst-domain accuracy .", "rating": "5: Marginally below acceptance threshold", "reply_text": "It looks to us like this is the main reason given for rejecting our submission : `` This paper reviews various previous work but does not provide a clear comparison from them . '' Can you please elaborate on this critique ? And/or explain what , if not this , are the main reasons for recommending rejection ? To clarify our position : - We consider the methods listed in Table 1 to be our primary points of comparison . - This table is meant to provide a summary of the qualitative advantages of REx over these alternatives , i.e.a clear comparison . - Arjovsky et al.2019 already demonstrated IRM 's advantages over the other methods listed . - Our work focuses on comparing REx with IRM , and especially the advantage REx has in handling covariate shift . We believe our experiments ( 4.1,4.2,4.4 ) , and mathematical analyses ( C.2 ) provide a clear comparison ."}, "3": {"review_id": "foNTMJHXHXC-3", "review_text": "This manuscript studies the problem of domain generalization and proposes a method , dubbed Rex , for this purpose . The main movitation of this work over the invariant risk minimization ( IRM ) [ 1 ] paradigm is that IRM is not robust to covariate shift , while the authors claim that Rex can deal with both covariate shift and concept shift together . Although the argument that IRM is not robust to covariate shift in the feature space is true , out-of-domain generalization is not the original goal of IRM either . My main concern is that it is not clear to me why Rex could deal with both covariate and concept shift together , as from the optimization formulation in Eq . ( 6 ) , neither invariant predictor nor invariant representation is enforced . In particular , no theoretical analysis is given to justify this claim . Perhaps what adds more confusion to me is that , what 's the meaning of negative probability since the authors allow the combination weight \\lambda of different domains to be negative ? As the authors have already pointed out on page 5 ( Probabilities vs Risks ) , the risk is a linear functional of the joint distribution over X and Y , hence using affine combination in the risk functions from different domains directly translate to allowing the use of negative coefficient for probabilities . This is quite strange , since the mixture distribution is only a convex combination , not affine combination . Furthermore , I also found some of the discussions in the related work section misleading : - `` The first method for invariant prediction ... is IRM '' . This is not correct . As the authors have already realized , ICP [ 2 ] has been proposed in 2015 , and the definition of IRM is essentially the same as ICP . - The discussions about invariant representations on page 4 are not accurate . Only P_e ( \\phi ) ( but not P_e ( \\phi | Y ) ) is called invariant representations , and only this one can fail domain adaption if the marginal label distributions differ . The C-ADA does not try to find invariant P_e ( \\phi | Y ) . Instead , it tries to find invariant P_e ( \\phi x \\hat { Y } ) , where \\hat { Y } is the classifier output , and this is precisely the reason why C-ADA also fails under different label distributions . See more discussions in [ 4 ] . In fact , it has recently been shown in [ 4 ] that matching P_e ( \\phi | Y ) provably works for domain adaptation , see Theorem 3.1 of [ 4 ] . - `` Also , unlike Rex , IRM seeks to match E [ Y | \\phi ] , not the full P ( Y | \\phi ) '' . Again , this discussion is misleading . For the purpose of out of domain generalization , the learner does not need to match the full distributions P ( Y | \\phi ) . Only the conditional mean matters . See Theorem 4.1 of [ 5 ] as well as Theorem 3.3 of [ 6 ] in the context of fairness . - About the discussion on fairness of equalizing risk across groups . In fact a sufficient condition for this goal has been proved in Theorem 3.3 of [ 6 ] . Given the close relationship between these two problems , I feel it 's necessary to cite and have a discussion of this result here as well . More detailed comments : - The reference of David et al. , 2010 should be Ben-David et al.2010 on page 2 - I think the naming of invariant prediction on page 2 is not very accurate . To be precise , as long as the same hypothesis ( classifier ) is used over different domains , this amounts to be an invariant prediction rule . Instead , what IRM enforces is the invariant OPTIMAL predictor , i.e. , invariant conditional means . - Eq . ( 3 ) is not correct : the second term is a weighted combination of samples from different domains , where the larger the sample size from a domain the more weight it has in the combination . However , the right most term has a wrong weight for a domain . The correct one should be |D_e| / \\sum_e |D_e| . - On page 4 , the citation of Pan et al.2010 is not accurate . Invariant representations for domain adaptation is first proposed by [ 3 ] . [ 1 ] Invariant Risk Minimization [ 2 ] Causal inference using invariant prediction : identification and confidence intervals [ 3 ] Unsupervised Domain Adaptation by Backpropagation [ 4 ] Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift [ 5 ] On Learning Invariant Representation for Domain Adaptation [ 6 ] Inherent Tradeoffs in Learning Fair Representations", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . As I understand it , you were not convinced that REx can provide robustness by encouraging both : 1 ) robustness to covariate shift and 2 ) invariant prediction . This is indeed a central claim of our paper , which we believe is well supported experimentally and conceptually . Responding to your statements in more detail : > Although the argument that IRM is not robust to covariate shift in the feature space is true , out-of-domain generalization is not the original goal of IRM either . We 're not sure we 've understood this argument . Can you clarify what you mean by this ? Our understanding is that out-of- * distribution * ( OOD ) generalization is the goal of IRM . Would you agree ? Did you mean something different by out-of- * domain * generalization ? As support the claim that IRM * is * focused on OOD generalization , we offer this quote from the abstract of Arjovsky et al.2019 : `` we leverage tools from causation to develop the mathematics of spurious and invariant correlations , in order to alleviate the excessive reliance of machine learning systems on data biases , allowing them to generalize to new test distributions . '' We also refer to Arjovsky 's thesis ( see : https : //cs.nyu.edu/dynamic/reports/ ? type=PhD ) , titled `` Out of Distribution Generalization in Machine Learning '' , which is simply a somewhat expanded version of Arjovsky et al. , 2019 . In this thesis they also note that IRM may not help in the `` realizable '' case , where X is already an invariant predictor . In this case , P ( Y|X ) is fixed by assumption , and so only covariate shift occurs . Their discussion of this setting indicates their recognition of covariate shift as an important problem in OOD generalization . Arjovsky 's thesis recognizes this as an apparent limitation of IRM , while providing some arguments for optimism that invariant prediction could help even in this realizable case . > My main concern is that it is not clear to me why Rex could deal with both covariate and concept shift together , as from the optimization formulation in Eq . ( 6 ) , neither invariant predictor nor invariant representation is enforced . In particular , no theoretical analysis is given to justify this claim . * First , we want to note that our experiments provide a demonstration of REx dealing with both covariate and concept shift . * Our work also describes and illustrates conceptually why equalizing risks ( i.e . `` flattening the risk plane '' ) could be expected to provide robustness to the kinds of shifts encountered at training time . In the case of MM-REx this also follows directly from the definition and the linearity of the risk in the P ( X , Y ) . * Appendix C.1/2 also provides simple examples illustrating how REx can encourage robustness to both kinds of shift . * In terms of theory , Appendix E.1 proves that REx can perform causal discovery . This has a close correspondance with invariant prediction , as discussed in Arjovsky et al . ( 2019 ) , although as far as we know , the details of the relationship between these two has not been fully elaborated . We recognize that many of these important results we refer to are in the Appendix , and plan to emphasize these results more clearly in the main text in our revision . We also welcome suggestions regarding which content would be most helpful to move to the main text ."}}