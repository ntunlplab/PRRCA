{"year": "2020", "forum": "BkxDxJHFDr", "title": "Power up! Robust Graph Convolutional Network based on Graph Powering", "decision": "Reject", "meta_review": "The paper identifies the limitation of graph neural networks and proposed new variants of graph neural works. However, the reviewers feel that the theory of the paper have some problems: \n1. A major concern is that the theoretical analyses in this paper are limited to graphs sampled from the SBM model. It is unclear how these analyses can be generalized to real graphs. \n2. The robustness definition is inconsistent. \nFurthermore, more extensive experiments on more datasets will also be helpful. ", "reviews": [{"review_id": "BkxDxJHFDr-0", "review_text": "This paper proposes a new architecture for graph convolutional network based on graph powering operation which generates a new graph based on the shortest distance between pair of nodes. Its main motivation is to overcome the dominance of the first eigenvector in the existing GCN architectures based on the graph Laplacian operator. The theoretical evidence for the robustness is provided based on the signal-to-noise (SNR) ratio of the simplified stochastic block model (SBM). Two versions of the algorithms are proposed, namely the robust graph convolutional network (r-GCN) and variable power network (VPN). First, r-GCN is based on augmenting the graphs with graph powering operation. Next, VPN replaces the adjacency matrix of the graph convolutional operator by the newly proposed variable power operator. An additional sparsification scheme is proposed since the graph powering operation densifies the original graph. Overall, I like how the paper addresses the weakness of the existing graph Laplacian operators (dominance of the first eigenvector) and proposed a new method with theoretical justifications. Experiments were conducted thoroughly and results look great in the presented datasets. However, I also have concerns about the paper that I feel necessary to be resolved. Most importantly, the concept of \"robustness\" in GCN seems to be inconsistent throughout the paper. Namely, the meaning of robustness in the neural network (adversarial robustness) and the SBM literature (spectral robustness) are different. This point is crucial since the paper use the spectral robustness for justification of the method, yet experiments are done on the adversarial attacks. More specifically, adversarial training methods for neural networks, e.g., adversarial attack methods [1] considered in the paper, typically make the loss function (or output of network) more persistent against the small perturbation of inputs. On the other side, the robustness for SBM models, e.g., Theorem 3 in the paper, cares more about the preservation of the original input characteristics. For illustration, an invertible neural network [2] is not necessarily robust to adversarial attacks (the first meaning of robustness) but preserves all the input characteristics (the second meaning of robustness). I also hope the paper could have done the experiments on more datasets since there exists some evidence on the unreliability of evaluations on citation networks [3]. However, I do not think this point is critical since the paper did a great job of evaluating the robustness in various aspects and they all show consistent improvement. Minor questions and suggestions: - The acronyms are slightly confusing to understand at first sight, since they first appear at the equations without any information on what the letters stand for. Something like a \"variable power network (VPN)\" would make the paper more pleasant to read. - In the r-GCN framework, there might be an edge case where the powered graph is almost identical to another graph. Would there be any justification for avoiding this? - In the r-GCN framework, the terminology distillation is slightly confusing. Was this choice of word used for making a connection to the knowledge distillation [4]? How is the knowledge distilled between graphs? References [1] Bojchevski and G\u00fcnnemann. Adversarial attacks on node embeddings via graph poisoning. ICML 2019 [2] Jacobsen et al., i-RevNet: Deep Invertible Networks. ICLR 2018 [3] Shchur et al., Pitfalls of Graph Neural Network Evaluation, Arxiv 2018 [4] Hinton et al., Distilling the Knowledge in a Neural Network, Arxiv 2015", "rating": "3: Weak Reject", "reply_text": "Q : The acronyms are slightly confusing to understand at first sight , since they first appear at the equations without any information on what the letters stand for . Something like a `` variable power network ( VPN ) '' would make the paper more pleasant to read . A : Thank you for the suggestion ! We have addressed it in the revised paper . Q : In the r-GCN framework , there might be an edge case where the powered graph is almost identical to another graph . Would there be any justification for avoiding this ? A : Thank you for introducing this interesting scenario ! We do not think this poses a serious problem to our framework . In fact , every powered graph is a different graph than the original graph . But since they are derived from the original graph , they inherit some important information from the original graph , both in the spatial and in the spectral domain . For example , under SBM , the leading eigenvectors of the adjacency matrix are relatively stable for powered graphs , as proven in Theorem 3 . In addition , these powered graphs are also introduced in the training as a regularization term , whose influence is controlled by the regularization parameter . Therefore , even if the powered graph is almost identical to another graph , it does not do harm to our learning performance . Q : In the r-GCN framework , the terminology distillation is slightly confusing . Was this choice of word used for making a connection to the knowledge distillation [ 4 ] ? How is the knowledge distilled between graphs ? A : Thank you for this comment ! In the original paper [ 4 ] , the knowledge is distilled between models , where knowledge is transferred from one to another . We attempted to draw an analogy to graphs , where the knowledge learned on the powered graph is transferred to the model that is applied to the original graph . We agree with the reviewer that using this term can be confusing to some readers . To improve clarity , we replaced this term with `` transfer '' in the revised manuscript . Thank you once again for the useful feedback ! Please do not hesitate to let us know if there are further issues that we could address ."}, {"review_id": "BkxDxJHFDr-1", "review_text": "In this paper, the authors study the classic GCN and proposed the new convolution operator with wider spatial scope and robust properties. The proposed models could improve the accuracy in both benign and evasion setting on synthetic, ie., SBM dataset and real world benchmark graphs. However, I have the following questions for the authors: 1. In the paper, compared to the classic GCN, the authors replace the adjacent matrix $A$ with the proposed \u201cvariable power operator\u201d. However, the proposed \u201cvariable power operator\u201d is very similar to \u201ck-th order polynomials of the Laplacian\u201d, which has been fully discussed in [1]. Could you distinguish the differences between the proposed \u201cvariable power operator\u201d and \u201ck-th order polynomials of the Laplacian\u201d? And as the authors proposed to use high-order matrix some recent models which also explores high-order matrix such as [2, 3] may also need to be selected as baseline methods. 2. As it is clearly defined in [4,5], all the five attack methods adopted in the paper are poisoning (training time) attacks methods. However, the proposed models are claimed to defense against evasion (testing) attacks. Why choose the poisoning attacks methods here? The experiment with the evasion attack method [6] is suggested to be added. 3. When the proposed models are applied to other kind of graph data, ie., social network, according to the small world theory, the \"variable power adjacency matrix\" would be very dense when $r>2$ with 2-layer GCN. The efficiency of the proposed might be an issue. Is it possible to add one experiment with demonstrating the running time on the real world social network? [1] Defferrard, Micha\u00ebl, Xavier Bresson, and Pierre Vandergheynst. \"Convolutional neural networks on graphs with fast localized spectral filtering.\" Advances in neural information processing systems. 2016. [2]Wu, Felix, et al. \"Simplifying graph convolutional networks.\" International Conference on Machine Learning. 2019. [3] Abu-El-Haija, Sami, et al. \"Mixhop: Higher-order graph convolution architectures via sparsified neighborhood mixing.\" International Conference on Machine Learning. 2019. [4]Z\u00fcgner, Daniel, and Stephan G\u00fcnnemann. \"Adversarial attacks on graph neural networks via meta learning.\" In ICLR 2019. [5]Bojchevski, Aleksandar, and Stephan G\u00fcnnemann. \"Adversarial Attacks on Node Embeddings via Graph Poisoning.\" International Conference on Machine Learning. 2019. [6] Dai, Hanjun, et al. \"Adversarial attack on graph structured data.\" International Conference on Machine Learning. 2018. ", "rating": "3: Weak Reject", "reply_text": "Q : As it is clearly defined in [ 4 , 5 ] , all the five attack methods adopted in the paper are poisoning ( training time ) attacks methods . However , the proposed models are claimed to defend against evasion ( testing ) attacks . Why choose the poisoning attacks methods here ? The experiment with the evasion attack method [ 6 ] is suggested to be added . A : Thank you for this comment ! The main difference between the poisoning attack and the evasion attack is whether the target model is retrained to update the parameters of the model after the attack . Since we assume the model parameters remain unchanged in our theory , we choose the evasion attack in our experimental settings . Furthermore , we aim to defend the global attack methods to be consistent with our theory , where the percentage of attacked edges indicates how the severity of the attack . All the five attack methods are very strong and state-of-the-art global attack methods that can be found in the literature and they also perform effectively under the evasion setting though they were proposed under the poisoning attack setting . Thus we choose them as attack methods for experiments . We thank the reviewer for pointing out the interesting work [ 6 ] . The method in [ 6 ] is developed for the targeted attack as opposed to the global attack . Moreover , we find that it could not finish within the given time limit even for the case where 30 % nodes are selected as target nodes on smaller datasets such as Citeseer and Cora . Therefore , we only discuss its relevance in the paper . Q : When the proposed models are applied to other kind of graph data , ie. , social network , according to the small world theory , the `` variable power adjacency matrix '' would be very dense when with 2-layer GCN . The efficiency of the proposed might be an issue . Is it possible to add one experiment with demonstrating the running time on the real world social network ? A : Thank you for raising this important issue ! We agree with the reviewer that the adjacent matrix could be very dense after powered several times , which is a general challenge for all high-order matrix based approaches . To alleviate this issue , we employ a simple sparsification strategy in our proposed method . Thank you for your suggestion for the additional experiment ! We introduced a running time comparison experiment on the real world social network ( Social circles : Facebook ) [ A1 ] . This dataset consists of 'circles ' ( or 'friends lists ' ) from Facebook and becomes very dense from power 1 ( 4.71 % ) to power 2 ( 92.12 % ) , thus is suitable for this scenario . The results are as follows : METHOD | Vanilla GCN | PowerLaplacian | IGCN ( RNM ) | IGCN ( AR ) | LNet | RGCN | SGC | MixHop | r-GCN | VPN | Run Time ( s ) | 6.02 | 6.36 | 3.33 | 7.21 | 5.56 | 18.14 | 0.231 | 11.38 | 6.73 | 7.18 We can find that the running efficiency of our proposed method is compatible with baselines and the density does n't affect the efficiency significantly when the dataset is not too large . Moreover , in this paper , our primary goal is to improve the robustness . We leave the solution to resolve the scalability issue as a future direction . [ A1 ] J. McAuley and J. Leskovec . Learning to Discover Social Circles in Ego Networks . NIPS , 2012. https : //snap.stanford.edu/data/ego-Facebook.html We thank the reviewer once again for the constructive feedback to improve the paper further . Please do not hesitate to let us know if there are further issues that we could address ."}, {"review_id": "BkxDxJHFDr-2", "review_text": "This paper proposes a graph convolutional operator based on graph powering and applies it to GCN architecture to improve the performance and robustness. This work is mainly motivated by the paper (Graph powering and spectral robustness, Abbe et al., 2018). The authors introduce the graph powering to graph convolution neural network domain to replace the original Laplacian operator. They further propose a graph sparsification/pruning strategy on the powered adjacency matrices in order to reduce the complexity and increase the robustness against adversarial attacks. They also provide theoretical analysis to prove that the proposed powering operator and subsequent methods have some spectral properties and theoretical feasibility. However, some conclusions are limited to the ideal situations or seem subjective. Extensive experiments are conducted to show better or comparable performance in both benign and adversarial situations. There are some concerns that need to be addressed or clarified: A major concern is that the theoretical analyses in this paper are limited to graphs sampled from the SBM model. It is unclear how these analyses can be generalized to real graphs. Furthermore, the theorem 3 and proposition 5 are even limited to SBM model with 2 communities, which makes the analyses less convincing. Some of the arguments in the paper might be imprecise. For example, in Section 1.1, when discuss \u201cwhy not graph Laplacian?\u201d, a small spatial scope is claimed to be problematic. Although, it is correct for the GCN (Kipf & Welling, 2017), the powered Laplacian (mentioned earlier in the same section) does have a broad spatial scope. It would be better if the authors could provide more details about the sparsification. Specifically, how to choose the threshold (adaptively). In the performance part of Section 4.2, the improvement of the performance by replacing Laplacian with VPN is marginal (compared with the original GCN). Furthermore, the performance of VPN is close to or sometimes worse than the baseline RGCN. Suggestions: In the Informative and robust low-frequency spectral signal part of Section 4.3, it would be better if the authors can clarify the experiments setting. Is it using the low-frequency part (first few eigenvectors) to recover the signal and then using the recovered signal to perform the classification task? The titles of Figure 7 and Figure 8 are a little bit confusing. Some minor problems: There are many typos such as: \u201cwith the presence of absence of edges\u201d, \u201cnormalizating\u201d, \u201casymptotoic\u201d, \u201cbenigh\u201d, \u201cajdacency\u201d, \u201csensitve\u201d, \u201cadajacent\u201d, \u201cone of the network\u201d, etc.", "rating": "3: Weak Reject", "reply_text": "Q : In the Informative and robust low-frequency spectral signal part of Section 4.3 , it would be better if the authors can clarify the experiments setting . Is it using the low-frequency part ( first few eigenvectors ) to recover the signal and then using the recovered signal to perform the classification task ? The titles of Figure 7 and Figure 8 are a little bit confusing . A : Thank you for this valuable suggestion ! We have added more details about the experimental setting in Section 4.3 . For the experiments in Section 4.3 , we first perform eigen-decomposition of the graph convolutional operator ( i.e. , graph Laplacian or VPN ) to obtain the Fourier modes $ \\Phi $ . We then reconstruct the nodal features $ X $ using only the k-th and k+1-th eigenvectors , i.e. , $ \\Phi_ { : ,k : ( k+1 ) } \\Phi_ { : ,k : ( k+1 ) } ^\\top X $ . We then use the reconstructed features in MLP to perform the classification task in a supervised learning setting . We performed this experiments for all three datasets . We have also changed the titles of Fig.7 and 8 to avoid the confusion . Q : There are many typos such as : \u201c with the presence of absence of edges \u201d , \u201c normalizating \u201d , \u201c asymptotoic \u201d , \u201c benigh \u201d , \u201c ajdacency \u201d , \u201c sensitve \u201d , \u201c adajacent \u201d , \u201c one of the network \u201d , etc . A : Thank you for catching these typos ! We have corrected them in the revised version . We thank the reviewer once again for the very interesting and important remarks ! Please do not hesitate to let us know if there are further issues that we could help clarify ."}], "0": {"review_id": "BkxDxJHFDr-0", "review_text": "This paper proposes a new architecture for graph convolutional network based on graph powering operation which generates a new graph based on the shortest distance between pair of nodes. Its main motivation is to overcome the dominance of the first eigenvector in the existing GCN architectures based on the graph Laplacian operator. The theoretical evidence for the robustness is provided based on the signal-to-noise (SNR) ratio of the simplified stochastic block model (SBM). Two versions of the algorithms are proposed, namely the robust graph convolutional network (r-GCN) and variable power network (VPN). First, r-GCN is based on augmenting the graphs with graph powering operation. Next, VPN replaces the adjacency matrix of the graph convolutional operator by the newly proposed variable power operator. An additional sparsification scheme is proposed since the graph powering operation densifies the original graph. Overall, I like how the paper addresses the weakness of the existing graph Laplacian operators (dominance of the first eigenvector) and proposed a new method with theoretical justifications. Experiments were conducted thoroughly and results look great in the presented datasets. However, I also have concerns about the paper that I feel necessary to be resolved. Most importantly, the concept of \"robustness\" in GCN seems to be inconsistent throughout the paper. Namely, the meaning of robustness in the neural network (adversarial robustness) and the SBM literature (spectral robustness) are different. This point is crucial since the paper use the spectral robustness for justification of the method, yet experiments are done on the adversarial attacks. More specifically, adversarial training methods for neural networks, e.g., adversarial attack methods [1] considered in the paper, typically make the loss function (or output of network) more persistent against the small perturbation of inputs. On the other side, the robustness for SBM models, e.g., Theorem 3 in the paper, cares more about the preservation of the original input characteristics. For illustration, an invertible neural network [2] is not necessarily robust to adversarial attacks (the first meaning of robustness) but preserves all the input characteristics (the second meaning of robustness). I also hope the paper could have done the experiments on more datasets since there exists some evidence on the unreliability of evaluations on citation networks [3]. However, I do not think this point is critical since the paper did a great job of evaluating the robustness in various aspects and they all show consistent improvement. Minor questions and suggestions: - The acronyms are slightly confusing to understand at first sight, since they first appear at the equations without any information on what the letters stand for. Something like a \"variable power network (VPN)\" would make the paper more pleasant to read. - In the r-GCN framework, there might be an edge case where the powered graph is almost identical to another graph. Would there be any justification for avoiding this? - In the r-GCN framework, the terminology distillation is slightly confusing. Was this choice of word used for making a connection to the knowledge distillation [4]? How is the knowledge distilled between graphs? References [1] Bojchevski and G\u00fcnnemann. Adversarial attacks on node embeddings via graph poisoning. ICML 2019 [2] Jacobsen et al., i-RevNet: Deep Invertible Networks. ICLR 2018 [3] Shchur et al., Pitfalls of Graph Neural Network Evaluation, Arxiv 2018 [4] Hinton et al., Distilling the Knowledge in a Neural Network, Arxiv 2015", "rating": "3: Weak Reject", "reply_text": "Q : The acronyms are slightly confusing to understand at first sight , since they first appear at the equations without any information on what the letters stand for . Something like a `` variable power network ( VPN ) '' would make the paper more pleasant to read . A : Thank you for the suggestion ! We have addressed it in the revised paper . Q : In the r-GCN framework , there might be an edge case where the powered graph is almost identical to another graph . Would there be any justification for avoiding this ? A : Thank you for introducing this interesting scenario ! We do not think this poses a serious problem to our framework . In fact , every powered graph is a different graph than the original graph . But since they are derived from the original graph , they inherit some important information from the original graph , both in the spatial and in the spectral domain . For example , under SBM , the leading eigenvectors of the adjacency matrix are relatively stable for powered graphs , as proven in Theorem 3 . In addition , these powered graphs are also introduced in the training as a regularization term , whose influence is controlled by the regularization parameter . Therefore , even if the powered graph is almost identical to another graph , it does not do harm to our learning performance . Q : In the r-GCN framework , the terminology distillation is slightly confusing . Was this choice of word used for making a connection to the knowledge distillation [ 4 ] ? How is the knowledge distilled between graphs ? A : Thank you for this comment ! In the original paper [ 4 ] , the knowledge is distilled between models , where knowledge is transferred from one to another . We attempted to draw an analogy to graphs , where the knowledge learned on the powered graph is transferred to the model that is applied to the original graph . We agree with the reviewer that using this term can be confusing to some readers . To improve clarity , we replaced this term with `` transfer '' in the revised manuscript . Thank you once again for the useful feedback ! Please do not hesitate to let us know if there are further issues that we could address ."}, "1": {"review_id": "BkxDxJHFDr-1", "review_text": "In this paper, the authors study the classic GCN and proposed the new convolution operator with wider spatial scope and robust properties. The proposed models could improve the accuracy in both benign and evasion setting on synthetic, ie., SBM dataset and real world benchmark graphs. However, I have the following questions for the authors: 1. In the paper, compared to the classic GCN, the authors replace the adjacent matrix $A$ with the proposed \u201cvariable power operator\u201d. However, the proposed \u201cvariable power operator\u201d is very similar to \u201ck-th order polynomials of the Laplacian\u201d, which has been fully discussed in [1]. Could you distinguish the differences between the proposed \u201cvariable power operator\u201d and \u201ck-th order polynomials of the Laplacian\u201d? And as the authors proposed to use high-order matrix some recent models which also explores high-order matrix such as [2, 3] may also need to be selected as baseline methods. 2. As it is clearly defined in [4,5], all the five attack methods adopted in the paper are poisoning (training time) attacks methods. However, the proposed models are claimed to defense against evasion (testing) attacks. Why choose the poisoning attacks methods here? The experiment with the evasion attack method [6] is suggested to be added. 3. When the proposed models are applied to other kind of graph data, ie., social network, according to the small world theory, the \"variable power adjacency matrix\" would be very dense when $r>2$ with 2-layer GCN. The efficiency of the proposed might be an issue. Is it possible to add one experiment with demonstrating the running time on the real world social network? [1] Defferrard, Micha\u00ebl, Xavier Bresson, and Pierre Vandergheynst. \"Convolutional neural networks on graphs with fast localized spectral filtering.\" Advances in neural information processing systems. 2016. [2]Wu, Felix, et al. \"Simplifying graph convolutional networks.\" International Conference on Machine Learning. 2019. [3] Abu-El-Haija, Sami, et al. \"Mixhop: Higher-order graph convolution architectures via sparsified neighborhood mixing.\" International Conference on Machine Learning. 2019. [4]Z\u00fcgner, Daniel, and Stephan G\u00fcnnemann. \"Adversarial attacks on graph neural networks via meta learning.\" In ICLR 2019. [5]Bojchevski, Aleksandar, and Stephan G\u00fcnnemann. \"Adversarial Attacks on Node Embeddings via Graph Poisoning.\" International Conference on Machine Learning. 2019. [6] Dai, Hanjun, et al. \"Adversarial attack on graph structured data.\" International Conference on Machine Learning. 2018. ", "rating": "3: Weak Reject", "reply_text": "Q : As it is clearly defined in [ 4 , 5 ] , all the five attack methods adopted in the paper are poisoning ( training time ) attacks methods . However , the proposed models are claimed to defend against evasion ( testing ) attacks . Why choose the poisoning attacks methods here ? The experiment with the evasion attack method [ 6 ] is suggested to be added . A : Thank you for this comment ! The main difference between the poisoning attack and the evasion attack is whether the target model is retrained to update the parameters of the model after the attack . Since we assume the model parameters remain unchanged in our theory , we choose the evasion attack in our experimental settings . Furthermore , we aim to defend the global attack methods to be consistent with our theory , where the percentage of attacked edges indicates how the severity of the attack . All the five attack methods are very strong and state-of-the-art global attack methods that can be found in the literature and they also perform effectively under the evasion setting though they were proposed under the poisoning attack setting . Thus we choose them as attack methods for experiments . We thank the reviewer for pointing out the interesting work [ 6 ] . The method in [ 6 ] is developed for the targeted attack as opposed to the global attack . Moreover , we find that it could not finish within the given time limit even for the case where 30 % nodes are selected as target nodes on smaller datasets such as Citeseer and Cora . Therefore , we only discuss its relevance in the paper . Q : When the proposed models are applied to other kind of graph data , ie. , social network , according to the small world theory , the `` variable power adjacency matrix '' would be very dense when with 2-layer GCN . The efficiency of the proposed might be an issue . Is it possible to add one experiment with demonstrating the running time on the real world social network ? A : Thank you for raising this important issue ! We agree with the reviewer that the adjacent matrix could be very dense after powered several times , which is a general challenge for all high-order matrix based approaches . To alleviate this issue , we employ a simple sparsification strategy in our proposed method . Thank you for your suggestion for the additional experiment ! We introduced a running time comparison experiment on the real world social network ( Social circles : Facebook ) [ A1 ] . This dataset consists of 'circles ' ( or 'friends lists ' ) from Facebook and becomes very dense from power 1 ( 4.71 % ) to power 2 ( 92.12 % ) , thus is suitable for this scenario . The results are as follows : METHOD | Vanilla GCN | PowerLaplacian | IGCN ( RNM ) | IGCN ( AR ) | LNet | RGCN | SGC | MixHop | r-GCN | VPN | Run Time ( s ) | 6.02 | 6.36 | 3.33 | 7.21 | 5.56 | 18.14 | 0.231 | 11.38 | 6.73 | 7.18 We can find that the running efficiency of our proposed method is compatible with baselines and the density does n't affect the efficiency significantly when the dataset is not too large . Moreover , in this paper , our primary goal is to improve the robustness . We leave the solution to resolve the scalability issue as a future direction . [ A1 ] J. McAuley and J. Leskovec . Learning to Discover Social Circles in Ego Networks . NIPS , 2012. https : //snap.stanford.edu/data/ego-Facebook.html We thank the reviewer once again for the constructive feedback to improve the paper further . Please do not hesitate to let us know if there are further issues that we could address ."}, "2": {"review_id": "BkxDxJHFDr-2", "review_text": "This paper proposes a graph convolutional operator based on graph powering and applies it to GCN architecture to improve the performance and robustness. This work is mainly motivated by the paper (Graph powering and spectral robustness, Abbe et al., 2018). The authors introduce the graph powering to graph convolution neural network domain to replace the original Laplacian operator. They further propose a graph sparsification/pruning strategy on the powered adjacency matrices in order to reduce the complexity and increase the robustness against adversarial attacks. They also provide theoretical analysis to prove that the proposed powering operator and subsequent methods have some spectral properties and theoretical feasibility. However, some conclusions are limited to the ideal situations or seem subjective. Extensive experiments are conducted to show better or comparable performance in both benign and adversarial situations. There are some concerns that need to be addressed or clarified: A major concern is that the theoretical analyses in this paper are limited to graphs sampled from the SBM model. It is unclear how these analyses can be generalized to real graphs. Furthermore, the theorem 3 and proposition 5 are even limited to SBM model with 2 communities, which makes the analyses less convincing. Some of the arguments in the paper might be imprecise. For example, in Section 1.1, when discuss \u201cwhy not graph Laplacian?\u201d, a small spatial scope is claimed to be problematic. Although, it is correct for the GCN (Kipf & Welling, 2017), the powered Laplacian (mentioned earlier in the same section) does have a broad spatial scope. It would be better if the authors could provide more details about the sparsification. Specifically, how to choose the threshold (adaptively). In the performance part of Section 4.2, the improvement of the performance by replacing Laplacian with VPN is marginal (compared with the original GCN). Furthermore, the performance of VPN is close to or sometimes worse than the baseline RGCN. Suggestions: In the Informative and robust low-frequency spectral signal part of Section 4.3, it would be better if the authors can clarify the experiments setting. Is it using the low-frequency part (first few eigenvectors) to recover the signal and then using the recovered signal to perform the classification task? The titles of Figure 7 and Figure 8 are a little bit confusing. Some minor problems: There are many typos such as: \u201cwith the presence of absence of edges\u201d, \u201cnormalizating\u201d, \u201casymptotoic\u201d, \u201cbenigh\u201d, \u201cajdacency\u201d, \u201csensitve\u201d, \u201cadajacent\u201d, \u201cone of the network\u201d, etc.", "rating": "3: Weak Reject", "reply_text": "Q : In the Informative and robust low-frequency spectral signal part of Section 4.3 , it would be better if the authors can clarify the experiments setting . Is it using the low-frequency part ( first few eigenvectors ) to recover the signal and then using the recovered signal to perform the classification task ? The titles of Figure 7 and Figure 8 are a little bit confusing . A : Thank you for this valuable suggestion ! We have added more details about the experimental setting in Section 4.3 . For the experiments in Section 4.3 , we first perform eigen-decomposition of the graph convolutional operator ( i.e. , graph Laplacian or VPN ) to obtain the Fourier modes $ \\Phi $ . We then reconstruct the nodal features $ X $ using only the k-th and k+1-th eigenvectors , i.e. , $ \\Phi_ { : ,k : ( k+1 ) } \\Phi_ { : ,k : ( k+1 ) } ^\\top X $ . We then use the reconstructed features in MLP to perform the classification task in a supervised learning setting . We performed this experiments for all three datasets . We have also changed the titles of Fig.7 and 8 to avoid the confusion . Q : There are many typos such as : \u201c with the presence of absence of edges \u201d , \u201c normalizating \u201d , \u201c asymptotoic \u201d , \u201c benigh \u201d , \u201c ajdacency \u201d , \u201c sensitve \u201d , \u201c adajacent \u201d , \u201c one of the network \u201d , etc . A : Thank you for catching these typos ! We have corrected them in the revised version . We thank the reviewer once again for the very interesting and important remarks ! Please do not hesitate to let us know if there are further issues that we could help clarify ."}}