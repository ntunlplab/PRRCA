{"year": "2017", "forum": "BkLhzHtlg", "title": "Learning Recurrent Representations for Hierarchical Behavior Modeling", "decision": "Accept (Poster)", "meta_review": "Originality and Significance:\n  The paper develops a recurrently coupled discriminative / generative hierarchical model, as applied to fruit-fly behavior and online handwriting. Qualitative evaluation is provided by generating motions, in addition to quantitative results. Writer identity and fly gender are learned in an unsupervised fashion. While the individual components of the solution are not particularly novel, their combination together with the detailed experimental validation makes the method potentially interesting to a broad audience. Some reviewers have concerns about the broad claims that are implied by the title and abstract, and thus it is recommended that these be refined to be more specific about the method and the applications.\n \n Quality and Clarity:\n  The paper is well written.\n \n Pros:\n - interesting problem and application domains; will be of broad interest\n - useful ideas and architecture: shows that forcing the network to predictions about motion leads to improved classification\n - well written paper backed up by good experiments\n \n Cons:\n - the individual architectural features have for the most part been proposed before", "reviews": [{"review_id": "BkLhzHtlg-0", "review_text": "While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between). The overall approach is interesting: all three of the key techniques (aux. tasks, skip/diagonal connections, and the use of internal labels for the kind of data available) make a lot of sense. I found some of the results hard to understand/interpret. Some of the explanation in the discussion below has been helpful (e.g. see my earlier questions about Fig 4 and 5); the paper would benefit from including more such explanations. It may be worthwhile very briefly mentioning the relationship of \"diagonal\" connections to other emerging terms for similar ideas (e.g. skip connections, etc). \"Skip\" seems to me to be accurate regardless of how you draw the network, whereas \"diagonal\" only makes sense for certain visual layouts. In response to comment in the discussion below: \"leading to less over-segmentation of action bouts\" (and corresponding discussion in section 5.1 of the paper): I would be like to have a bit more about this in the paper. I have assumed that \"per-bout\" refers to \"per-action event\", but now I am not certain that I have understood this correctly (i.e. can a \"bout\" last for a few minutes?): given the readership, I think it would not be inappropriate to define some of these things explicitly. In response to comment about fly behaviours that last minutes vs milliseconds: This is interesting, and I would be curious to know how classification accuracy relates to the time-scale of the behaviour (e.g. are most of the mistakes on long-term behaviours? i realize that this would only tell part of the story, e.g. if you have a behaviour that has both a long-term duration, but that also has very different short-term characteristics than many other behaviours, it should be easy to classify accuractely despite being \"long-term\"). If easy to investigate this, I would add a comment about it; if this is hard to investigate, it's probably not worth it at this point, although it's something you might want to look at in future. In response to comment about scaling to human behavior: I agree that in principle, adding conv layers directly above the sensory input would be the right thing to try, but seriously: there is usually a pretty big gap between what \"should\" work and what actually works, as I am sure the authors are aware. (Indeed, I am sure the authors have a much more experiential and detailed understanding of the limitations of their work than I do). What I see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories. The claims made should correspond to this. I would consider adjusting my rating to a 7 depending on future revisions. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review . Majority of your comments are addressed in the global response . Regarding how classification accuracy relates to the time-scale of the behavior , I agree that it would be interesting to further analyze the types of errors we get with respect to timescale and we plan to explore this for future development ."}, {"review_id": "BkLhzHtlg-1", "review_text": "The paper presents a method for joint motion prediction and activity classification from sequences with two different applications: motion of fruit flies and online handwriting recognition. The method uses a classical encoder-decoder pipeline, with skip connections allowing direct communication between the encoder and the decoder on respective levels of abstraction. Motion is discretized and predicted using classification. The model is trained on classification loss combined with a loss on motion prediction. The goal is to leverage latter loss in a semi-supervised setting from parts of the data which do not contain action labels. The idea of leveraging predictions to train feature representations for discrimination is not new. However, the paper presents a couple of interesting ideas, partially inspired from other work in other areas. My biggest concern is with the experimental evaluation. The experimental section contains a large amount of figures, which visualize what the model has learned in a qualitative way. However, quantitative evaluation is rarer. - On the fly application, the authors compare the classification performance with another method previously published by the first author. - Again on the fly application, the performance gain on motion prediction in figure 5c looks small compared to the baseline. I am not sure it is significant. - I did not see any recognition results on the handwriting application. Has this part not been evaluated? Figure 5a is difficult to understand and to interpret. The term \"BesNet\" is used here without any introduction. Figure 4 seems to tell multiple and different stories. I'd suggest splitting it into at least two different figures. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review . To answer your questions : * * I did not see any recognition results on the handwriting application . Has this part not been evaluated ? - Figure 4 has quantitative results for all 3 labeled datasets , including handwriting , for varying number of training labels . * * Figure 4 seems to tell multiple and different stories . I 'd suggest splitting it into at least two different figures . - The 3 plots in Figure 4 are grouped because they all refer to classification performance , in order to make best use of space . - We have added more details to the caption of figure 4 to connect the stories . * * Figure 5a is difficult to understand and to interpret . The term `` BesNet '' is used here without any introduction . - BESNet and BENet are described on page 7 paragraph 2 , before figure 5 on page 8 . - We have added more details to the caption of figure 5 . * * The experimental section contains a large amount of figures , which visualize what the model has learned in a qualitative way . However , quantitative evaluation is rarer . - Figure 5 shows quantitative 1-step motion prediction performance , and figure 4 quantitatively evaluates classification performance . - For multi-step prediction ( i.e.simulation ) , qualitative results can be more informative than quantitative , as the objective function may not capture what looks realistic to humans . This is comparable to image generation where qualitative results and human scoring are standard methods of evaluation , e.g.https : //arxiv.org/pdf/1506.05751v1.pdf . - The paper does indeed have a lot of qualitative results , which are better demonstrated on our project website as videos : http : //www.vision.caltech.edu/~eeyjolfs/behavior_modeling/"}, {"review_id": "BkLhzHtlg-2", "review_text": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents. The paper is well written, clear in its presentation and backed up by good experiments. They demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states, allowing more accurate classification with less training data. They also show how the information learned by the network is interpretable and organised in a hierarchy. Weaknesses: - a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper. - moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing; The criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios, making the original claim a little bit far fetched unless its backed up by additional evidence. Using \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\".", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review . We have added a discussion at the end of the paper about scaling to more complex data . Regarding a critical discussion on the interplay between motion and behavior , in the introduction we explain that motion trajectories and actions represent behavior at different levels of timescales , and that actions can be detected from motion trajectories . If your point refers to a more biological explanation , such as the one we discuss in our global response , I am also happy to add that to the introduction of the paper ."}], "0": {"review_id": "BkLhzHtlg-0", "review_text": "While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between). The overall approach is interesting: all three of the key techniques (aux. tasks, skip/diagonal connections, and the use of internal labels for the kind of data available) make a lot of sense. I found some of the results hard to understand/interpret. Some of the explanation in the discussion below has been helpful (e.g. see my earlier questions about Fig 4 and 5); the paper would benefit from including more such explanations. It may be worthwhile very briefly mentioning the relationship of \"diagonal\" connections to other emerging terms for similar ideas (e.g. skip connections, etc). \"Skip\" seems to me to be accurate regardless of how you draw the network, whereas \"diagonal\" only makes sense for certain visual layouts. In response to comment in the discussion below: \"leading to less over-segmentation of action bouts\" (and corresponding discussion in section 5.1 of the paper): I would be like to have a bit more about this in the paper. I have assumed that \"per-bout\" refers to \"per-action event\", but now I am not certain that I have understood this correctly (i.e. can a \"bout\" last for a few minutes?): given the readership, I think it would not be inappropriate to define some of these things explicitly. In response to comment about fly behaviours that last minutes vs milliseconds: This is interesting, and I would be curious to know how classification accuracy relates to the time-scale of the behaviour (e.g. are most of the mistakes on long-term behaviours? i realize that this would only tell part of the story, e.g. if you have a behaviour that has both a long-term duration, but that also has very different short-term characteristics than many other behaviours, it should be easy to classify accuractely despite being \"long-term\"). If easy to investigate this, I would add a comment about it; if this is hard to investigate, it's probably not worth it at this point, although it's something you might want to look at in future. In response to comment about scaling to human behavior: I agree that in principle, adding conv layers directly above the sensory input would be the right thing to try, but seriously: there is usually a pretty big gap between what \"should\" work and what actually works, as I am sure the authors are aware. (Indeed, I am sure the authors have a much more experiential and detailed understanding of the limitations of their work than I do). What I see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories. The claims made should correspond to this. I would consider adjusting my rating to a 7 depending on future revisions. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review . Majority of your comments are addressed in the global response . Regarding how classification accuracy relates to the time-scale of the behavior , I agree that it would be interesting to further analyze the types of errors we get with respect to timescale and we plan to explore this for future development ."}, "1": {"review_id": "BkLhzHtlg-1", "review_text": "The paper presents a method for joint motion prediction and activity classification from sequences with two different applications: motion of fruit flies and online handwriting recognition. The method uses a classical encoder-decoder pipeline, with skip connections allowing direct communication between the encoder and the decoder on respective levels of abstraction. Motion is discretized and predicted using classification. The model is trained on classification loss combined with a loss on motion prediction. The goal is to leverage latter loss in a semi-supervised setting from parts of the data which do not contain action labels. The idea of leveraging predictions to train feature representations for discrimination is not new. However, the paper presents a couple of interesting ideas, partially inspired from other work in other areas. My biggest concern is with the experimental evaluation. The experimental section contains a large amount of figures, which visualize what the model has learned in a qualitative way. However, quantitative evaluation is rarer. - On the fly application, the authors compare the classification performance with another method previously published by the first author. - Again on the fly application, the performance gain on motion prediction in figure 5c looks small compared to the baseline. I am not sure it is significant. - I did not see any recognition results on the handwriting application. Has this part not been evaluated? Figure 5a is difficult to understand and to interpret. The term \"BesNet\" is used here without any introduction. Figure 4 seems to tell multiple and different stories. I'd suggest splitting it into at least two different figures. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review . To answer your questions : * * I did not see any recognition results on the handwriting application . Has this part not been evaluated ? - Figure 4 has quantitative results for all 3 labeled datasets , including handwriting , for varying number of training labels . * * Figure 4 seems to tell multiple and different stories . I 'd suggest splitting it into at least two different figures . - The 3 plots in Figure 4 are grouped because they all refer to classification performance , in order to make best use of space . - We have added more details to the caption of figure 4 to connect the stories . * * Figure 5a is difficult to understand and to interpret . The term `` BesNet '' is used here without any introduction . - BESNet and BENet are described on page 7 paragraph 2 , before figure 5 on page 8 . - We have added more details to the caption of figure 5 . * * The experimental section contains a large amount of figures , which visualize what the model has learned in a qualitative way . However , quantitative evaluation is rarer . - Figure 5 shows quantitative 1-step motion prediction performance , and figure 4 quantitatively evaluates classification performance . - For multi-step prediction ( i.e.simulation ) , qualitative results can be more informative than quantitative , as the objective function may not capture what looks realistic to humans . This is comparable to image generation where qualitative results and human scoring are standard methods of evaluation , e.g.https : //arxiv.org/pdf/1506.05751v1.pdf . - The paper does indeed have a lot of qualitative results , which are better demonstrated on our project website as videos : http : //www.vision.caltech.edu/~eeyjolfs/behavior_modeling/"}, "2": {"review_id": "BkLhzHtlg-2", "review_text": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents. The paper is well written, clear in its presentation and backed up by good experiments. They demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states, allowing more accurate classification with less training data. They also show how the information learned by the network is interpretable and organised in a hierarchy. Weaknesses: - a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper. - moreover, a discussion on how this approach could scale to more challenging scenarios \"involving animals\" and visual input for instance and more general \"behaviours\" is also missing; The criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios, making the original claim a little bit far fetched unless its backed up by additional evidence. Using \"Insects\", or \"fruit flies\" would be more appropriate than \"animals\".", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review . We have added a discussion at the end of the paper about scaling to more complex data . Regarding a critical discussion on the interplay between motion and behavior , in the introduction we explain that motion trajectories and actions represent behavior at different levels of timescales , and that actions can be detected from motion trajectories . If your point refers to a more biological explanation , such as the one we discuss in our global response , I am also happy to add that to the introduction of the paper ."}}