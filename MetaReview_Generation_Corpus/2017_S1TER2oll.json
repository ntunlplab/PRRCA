{"year": "2017", "forum": "S1TER2oll", "title": "FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS", "decision": "Accept (Poster)", "meta_review": "Using covariance analysis for designing convolution connection structure is a nice and novel idea. All three reviewers recommended acceptance. Since the reviewers were not confident about the theoretical derivations, the AC asked for an opinion from an additional reviewer. This reviewer also found the paper interesting and novel, and recommended acceptance.", "reviews": [{"review_id": "S1TER2oll-0", "review_text": "Authors propose a mechanism for selecting the design of filters in convolutional layers. The basic idea is that convolution should be applied to input feature dimensions that are highly correlated in order to detect rare events. For example, adjacent pixels in images are correlated and edges are rare events of interest to be detected. Authors argue that square filters are therefore appropriate in images. However, in data such as bird songs high correlations might exist between non-adjacent harmonics and a convolution filter should take a weighted summation over these input feature dimensions. Such an operation can thus be thought of computing data-dependent dilated convolutions. Paper theoretically motivates this choice using the idea of Gaussian complexity of the learner (i.e. a CNN in this case). The main idea being that choosing convolution filters that sum over correlated features results in lower Gaussian complexity and thus the learner has higher ability to generalize. While I am no expert in theoretical analysis of learning algorithms \u2013 there are parts of proof that look sound, but there are parts that are rather hand wavy (for eg, extension to networks using max-pooling from average pooling). Also, the theory is not directly applicable to choosing filters when number of layers are more than 1. I am willing to overlook the paucity in rigor in some parts of the theoretical arguments because the empirical evidence looks convincing. The method of choosing the filter shape can be briefly summarized as: (a) The covariance matrix of the input features is computed. (b) Using the covariance matrix, feature dimensions with highest correlations are determined by solving equation (7). A hard limit on maximum number of filter dimensions is imposed (typically ~ 10-15). This leads to choice of a single design for all filters in the layer. (c) Authors extend the framework to work with multiple layers in the following way: A subset of feature dimensions cannot account for all variance in the inputs and there is some residual variance. The filter design of the next layer attempts to minimize this residual variance. This process is repeated iteratively by solving eq (8) to obtain filter designs for all the layers. Ideally for determining filter designs of different layers \u2013 one should have computed the covariance statistics of outputs of the previous layer. However this assumes that filters of the previous layer are already known and this is not computationally feasible to implement. Authors instead use the method described in (c). A question which comes to my mind is \u2013 a single feature design is chosen for each layer. Have the authors considered using the process in (c) to chose different filter designs for different filters in the same layer as opposed to using the same filter design for all the filters? Regarding baselines: B1. It would be great to see a comparison with randomly chosen filter designs. Two comparisons could be made \u2013 (1a) A single random design is chosen for each layer. (1b) The design of each filter is chosen randomly (i.e. allowing for different designs of filter within each layer). B2. Since the theory is not really applicable to CNNs with more that one layer \u2013 I wonder how much of the benefit is obtained by choosing the filter design just in a single layer v/s all the layers. A good comparison would be when filter design of the first layer are chosen using the described method and filters in higher layers are chosen to be square. B3. Authors mention the use L1 regularization in the baselines. Was the L1 penalty cross-validated? If so, then upto what range? Somethings which are unclear: - \u201cexclude data that represent obvious noise\u201d - DFMax mentioned in the supplementary materials Overall I think this is very interesting idea for filter design. The authors have done a fair set of experiments but I would really like to see results of B1, B2 and the answer to question in B3. I have currently set my rating to a weak reject, but I am happy to raise my ratings to \u2013 \u201cGood paper, accept\u201d if the authors provide results of experiments and answers to questions in my comments above. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer , Thank you so much for your comments ! We would like to respond to your questions . For B1 , could we ask that what does random filter design mean ? Thank you so much ! Best ,"}, {"review_id": "S1TER2oll-1", "review_text": "This work proposes a way how to learn filter shapes for CNNs in an unsupervised manner for multiple tasks by solving a lasso problem. Even though this method does not seem to be applicable for image classification CNNs (as image data generally do not have bias towards anisotropic structures), it gives an empirical methodology to design filter shapes for tasks with different input data structure. Authors show that this method is applicable for spectrogram classification and gene sequence classification. The paper is well written and and is of interest to the community as it presents a unsupervised method applicable to problems with less training data. Authors compare the performance of the proposed method against reasonable baselines (i.e. handcrafted filter sizes) and based on the evaluation it seems to improve the results and help to avoid over-fitting (probably due to reduced filter size and thus number of parameters). In this way it is an interesting combination of unsupervised methods for a supervised training. Unfortunately, I am not able to validate correctness of the theoretical justification. As a side note: * It would be useful to give some reference showing that using spectrogram for sound classification is a reasonable choice", "rating": "7: Good paper, accept", "reply_text": "Spectrogram is a very common data form for sound classification , e.g . [ Abdel-Hamid et al.2014 ] which was cited in the paper . More references will be added on this . For example , [ Stowell , Dan , and Mark D. Plumbley . `` Birdsong and C4DM : A survey of UK birdsong and machine recognition for music researchers . '' Centre for Digital Music , Queen Mary University of London Technical report C4DM-TR-09 12 ( 2010 ) ] , [ Ranjard , Louis , and Howard A. Ross . `` Unsupervised bird song syllable classification using evolving neural networks . '' The Journal of the Acoustical Society of America 123.6 ( 2008 ) : 4358-4368 ] , [ Lasseck , Mario . `` Bird song classification in field recordings : winning solution for NIPS4B 2013 competition . '' Proc.of int.symp.Neural Information Scaled for Bioacoustics , sabiod . org/nips4b , joint to NIPS , Nevada . 2013 ] are very typical relevant papers ."}, {"review_id": "S1TER2oll-2", "review_text": "The paper proposes a method for optimising the shape of filters in convolutional neural network layers, i.e. the structure of their receptive fields. CNNs for images almost invariably feature small square filters (e.g. 3x3, 5x5, ...) and this paper provides an algorithm to optimise this aspect of the model architecture (which is often treated as fixed) based on data. It is argued that this is especially useful for data modalities where the assumption of locality breaks down, as in e.g. spectrograms, where correlations between harmonics are often relevant to the task at hand, but they are not local in frequency space. Improved performance is demonstrated on two tasks that are fairly non-standard, but I think that is fine given that the proposed approach probably isn't useful for the vast majority of popular benchmark datasets (e.g. MNIST, CIFAR-10), where the locality assumption holds and a square filter shape is probably close to optimal anyway. Fig. 1 is a nice demonstration of this. The paper spends quite a bit of space on a theoretical argument for the proposed method based on Gaussian complexity, which is interesting but maybe doesn't warrant quite so much detail. In contrast, section 3.3 (about how to deal with pooling) is quite handwavy in comparison. This is probably fine but the level of detail in the preceding sections makes it a bit suspicious. I'm also not 100% convinced that the theoretical argument is particularly relevant, because it seems to rely on some assumptions that are clearly untrue for practical CNNs, such as 1-norm weight constraints and the fact that it is probably okay to swap out the L1 norm for the L2 norm. I would also like to see a bit more discussion about Fig. 4, especially about the fact that some of the filter shapes end up having many fewer nonzeros than the algorithm enforces (e.g. 3 nonzeros for layers 6 and 7, whereas the maximum is 13). Of course this is a perfectly valid outcome as the algorithm doesn't force the solution to have an exact number of nonzeros, but surely the authors will agree that it is a bit surprising/unintuitive? The same figure also features an interesting phase transition between layers 1-4 and 5-8, with the former 4 layers having very similar, almost circular/square filter shapes, and the later having very different, spread out shapes. Some comments about why this happens would be welcome. Regarding my question about computational performance, I still think that this warrants some discussion in the paper as well. For many new techniques, whether they end up being adopted mainly depends on the ratio between the amount of work that goes into implementing them, and the benefit they provide. I'm not convinced that the proposed approach is very practical. My intuition is that creating efficient implementations of various non-square convolutions for each new problem might end up not being worth the effort, but I could be wrong here. Minor comments: - please have the manuscript proofread for spelling and grammar. - there is a bit of repetition in sections 2 and 3, e.g. the last paragraphs of sections 2.1 and 2.2 basically say the same thing, it would be good to consolidate this. - a few things mentioned in the paper that were unclear to me (\"syllables\", \"exclude data that represent obvious noise\", choice of \"max nonzero elements\" parameter) have already been adequately addressed by the authors in their response to my questions, but it would be good to include these answers in the manuscript as well. - the comparison in Fig. 5 with L1 regularisation on the filter weights does not seem entirely fair, since the resulting shape would have to be encompassed in a 5x5 window whereas Fig. 4 shows that the filter shapes found by the algorithm often extend beyond that. I appreciate that training nets with very large square filters is problematic in many ways, but the claim \"L1 regularization cannot achieve the same effect as filter shaping\" is not really convincingly backed up by this experiment.", "rating": "7: Good paper, accept", "reply_text": "We will add most of the relevant discussions ( e.g.computational performance , explanation of terms ) into the paper and proofread it . As for the practical usefulness of our method , we believe that for certain data that has special correlation patterns , our model may well be worth the effort because the performance improvement outweighs the relatively minor speed penalty . For the question about Figure 4 , we have discussed it briefly in the last sentence in Sec.6.1 , the phase transition happened because layers 5-8 captured the global harmonic patterns . We suspect that CNN managed to capture all the local patterns in the first 4 layers . As seen in Fig.2 ( a ) , the harmonic patterns are discontinuous hence very different from the local patterns . The discussion will be expanded in the final version . For the comparison in Figure 5 , we have tried larger square filters such as 7x7 but the performance was significantly worse , even with automatic step-size tuning approaches such as Adam ."}], "0": {"review_id": "S1TER2oll-0", "review_text": "Authors propose a mechanism for selecting the design of filters in convolutional layers. The basic idea is that convolution should be applied to input feature dimensions that are highly correlated in order to detect rare events. For example, adjacent pixels in images are correlated and edges are rare events of interest to be detected. Authors argue that square filters are therefore appropriate in images. However, in data such as bird songs high correlations might exist between non-adjacent harmonics and a convolution filter should take a weighted summation over these input feature dimensions. Such an operation can thus be thought of computing data-dependent dilated convolutions. Paper theoretically motivates this choice using the idea of Gaussian complexity of the learner (i.e. a CNN in this case). The main idea being that choosing convolution filters that sum over correlated features results in lower Gaussian complexity and thus the learner has higher ability to generalize. While I am no expert in theoretical analysis of learning algorithms \u2013 there are parts of proof that look sound, but there are parts that are rather hand wavy (for eg, extension to networks using max-pooling from average pooling). Also, the theory is not directly applicable to choosing filters when number of layers are more than 1. I am willing to overlook the paucity in rigor in some parts of the theoretical arguments because the empirical evidence looks convincing. The method of choosing the filter shape can be briefly summarized as: (a) The covariance matrix of the input features is computed. (b) Using the covariance matrix, feature dimensions with highest correlations are determined by solving equation (7). A hard limit on maximum number of filter dimensions is imposed (typically ~ 10-15). This leads to choice of a single design for all filters in the layer. (c) Authors extend the framework to work with multiple layers in the following way: A subset of feature dimensions cannot account for all variance in the inputs and there is some residual variance. The filter design of the next layer attempts to minimize this residual variance. This process is repeated iteratively by solving eq (8) to obtain filter designs for all the layers. Ideally for determining filter designs of different layers \u2013 one should have computed the covariance statistics of outputs of the previous layer. However this assumes that filters of the previous layer are already known and this is not computationally feasible to implement. Authors instead use the method described in (c). A question which comes to my mind is \u2013 a single feature design is chosen for each layer. Have the authors considered using the process in (c) to chose different filter designs for different filters in the same layer as opposed to using the same filter design for all the filters? Regarding baselines: B1. It would be great to see a comparison with randomly chosen filter designs. Two comparisons could be made \u2013 (1a) A single random design is chosen for each layer. (1b) The design of each filter is chosen randomly (i.e. allowing for different designs of filter within each layer). B2. Since the theory is not really applicable to CNNs with more that one layer \u2013 I wonder how much of the benefit is obtained by choosing the filter design just in a single layer v/s all the layers. A good comparison would be when filter design of the first layer are chosen using the described method and filters in higher layers are chosen to be square. B3. Authors mention the use L1 regularization in the baselines. Was the L1 penalty cross-validated? If so, then upto what range? Somethings which are unclear: - \u201cexclude data that represent obvious noise\u201d - DFMax mentioned in the supplementary materials Overall I think this is very interesting idea for filter design. The authors have done a fair set of experiments but I would really like to see results of B1, B2 and the answer to question in B3. I have currently set my rating to a weak reject, but I am happy to raise my ratings to \u2013 \u201cGood paper, accept\u201d if the authors provide results of experiments and answers to questions in my comments above. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer , Thank you so much for your comments ! We would like to respond to your questions . For B1 , could we ask that what does random filter design mean ? Thank you so much ! Best ,"}, "1": {"review_id": "S1TER2oll-1", "review_text": "This work proposes a way how to learn filter shapes for CNNs in an unsupervised manner for multiple tasks by solving a lasso problem. Even though this method does not seem to be applicable for image classification CNNs (as image data generally do not have bias towards anisotropic structures), it gives an empirical methodology to design filter shapes for tasks with different input data structure. Authors show that this method is applicable for spectrogram classification and gene sequence classification. The paper is well written and and is of interest to the community as it presents a unsupervised method applicable to problems with less training data. Authors compare the performance of the proposed method against reasonable baselines (i.e. handcrafted filter sizes) and based on the evaluation it seems to improve the results and help to avoid over-fitting (probably due to reduced filter size and thus number of parameters). In this way it is an interesting combination of unsupervised methods for a supervised training. Unfortunately, I am not able to validate correctness of the theoretical justification. As a side note: * It would be useful to give some reference showing that using spectrogram for sound classification is a reasonable choice", "rating": "7: Good paper, accept", "reply_text": "Spectrogram is a very common data form for sound classification , e.g . [ Abdel-Hamid et al.2014 ] which was cited in the paper . More references will be added on this . For example , [ Stowell , Dan , and Mark D. Plumbley . `` Birdsong and C4DM : A survey of UK birdsong and machine recognition for music researchers . '' Centre for Digital Music , Queen Mary University of London Technical report C4DM-TR-09 12 ( 2010 ) ] , [ Ranjard , Louis , and Howard A. Ross . `` Unsupervised bird song syllable classification using evolving neural networks . '' The Journal of the Acoustical Society of America 123.6 ( 2008 ) : 4358-4368 ] , [ Lasseck , Mario . `` Bird song classification in field recordings : winning solution for NIPS4B 2013 competition . '' Proc.of int.symp.Neural Information Scaled for Bioacoustics , sabiod . org/nips4b , joint to NIPS , Nevada . 2013 ] are very typical relevant papers ."}, "2": {"review_id": "S1TER2oll-2", "review_text": "The paper proposes a method for optimising the shape of filters in convolutional neural network layers, i.e. the structure of their receptive fields. CNNs for images almost invariably feature small square filters (e.g. 3x3, 5x5, ...) and this paper provides an algorithm to optimise this aspect of the model architecture (which is often treated as fixed) based on data. It is argued that this is especially useful for data modalities where the assumption of locality breaks down, as in e.g. spectrograms, where correlations between harmonics are often relevant to the task at hand, but they are not local in frequency space. Improved performance is demonstrated on two tasks that are fairly non-standard, but I think that is fine given that the proposed approach probably isn't useful for the vast majority of popular benchmark datasets (e.g. MNIST, CIFAR-10), where the locality assumption holds and a square filter shape is probably close to optimal anyway. Fig. 1 is a nice demonstration of this. The paper spends quite a bit of space on a theoretical argument for the proposed method based on Gaussian complexity, which is interesting but maybe doesn't warrant quite so much detail. In contrast, section 3.3 (about how to deal with pooling) is quite handwavy in comparison. This is probably fine but the level of detail in the preceding sections makes it a bit suspicious. I'm also not 100% convinced that the theoretical argument is particularly relevant, because it seems to rely on some assumptions that are clearly untrue for practical CNNs, such as 1-norm weight constraints and the fact that it is probably okay to swap out the L1 norm for the L2 norm. I would also like to see a bit more discussion about Fig. 4, especially about the fact that some of the filter shapes end up having many fewer nonzeros than the algorithm enforces (e.g. 3 nonzeros for layers 6 and 7, whereas the maximum is 13). Of course this is a perfectly valid outcome as the algorithm doesn't force the solution to have an exact number of nonzeros, but surely the authors will agree that it is a bit surprising/unintuitive? The same figure also features an interesting phase transition between layers 1-4 and 5-8, with the former 4 layers having very similar, almost circular/square filter shapes, and the later having very different, spread out shapes. Some comments about why this happens would be welcome. Regarding my question about computational performance, I still think that this warrants some discussion in the paper as well. For many new techniques, whether they end up being adopted mainly depends on the ratio between the amount of work that goes into implementing them, and the benefit they provide. I'm not convinced that the proposed approach is very practical. My intuition is that creating efficient implementations of various non-square convolutions for each new problem might end up not being worth the effort, but I could be wrong here. Minor comments: - please have the manuscript proofread for spelling and grammar. - there is a bit of repetition in sections 2 and 3, e.g. the last paragraphs of sections 2.1 and 2.2 basically say the same thing, it would be good to consolidate this. - a few things mentioned in the paper that were unclear to me (\"syllables\", \"exclude data that represent obvious noise\", choice of \"max nonzero elements\" parameter) have already been adequately addressed by the authors in their response to my questions, but it would be good to include these answers in the manuscript as well. - the comparison in Fig. 5 with L1 regularisation on the filter weights does not seem entirely fair, since the resulting shape would have to be encompassed in a 5x5 window whereas Fig. 4 shows that the filter shapes found by the algorithm often extend beyond that. I appreciate that training nets with very large square filters is problematic in many ways, but the claim \"L1 regularization cannot achieve the same effect as filter shaping\" is not really convincingly backed up by this experiment.", "rating": "7: Good paper, accept", "reply_text": "We will add most of the relevant discussions ( e.g.computational performance , explanation of terms ) into the paper and proofread it . As for the practical usefulness of our method , we believe that for certain data that has special correlation patterns , our model may well be worth the effort because the performance improvement outweighs the relatively minor speed penalty . For the question about Figure 4 , we have discussed it briefly in the last sentence in Sec.6.1 , the phase transition happened because layers 5-8 captured the global harmonic patterns . We suspect that CNN managed to capture all the local patterns in the first 4 layers . As seen in Fig.2 ( a ) , the harmonic patterns are discontinuous hence very different from the local patterns . The discussion will be expanded in the final version . For the comparison in Figure 5 , we have tried larger square filters such as 7x7 but the performance was significantly worse , even with automatic step-size tuning approaches such as Adam ."}}