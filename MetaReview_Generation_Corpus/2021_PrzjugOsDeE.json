{"year": "2021", "forum": "PrzjugOsDeE", "title": "CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation", "decision": "Accept (Poster)", "meta_review": "The submission proposes a novel conditional GAN formulation where continuous scalars (named regression labels) are fed into the GAN as a conditioning variable. Since cGANs with discrete labels are trained to minimize the empirical loss, they fail for continuous conditions, because there might be few or even zero samples for many labels values and also the label cannot be embedded by one-hot encoding like discrete labels. As a solution, the authors propose new methods of encoding the label. \n\nThe paper received a clear accept, two weak accepts and a weak reject. As agreed by all the reviewers, the paper proposes an interesting framework to eliminate some weaknesses of GANs. The rebuttal adequately addresses the reviewer comments and hence the meta reviewer recommends acceptance. ", "reviews": [{"review_id": "PrzjugOsDeE-0", "review_text": "* * * Summary : This paper proposes a novel continuous conditional GAN which takes continuous scalars ( named regression labels ) as conditions . There are two problems for continuous conditional GAN : ( P1 ) cGANs with discrete labels are trained to minimize the empirical loss , but this fails for continuous conditions , because there might be few or even zero samples for many labels values . ( P2 ) For continuous labels , the label can not be embedded by one-hot encoding like discrete labels . The authors propose two solutions for the problems respectively : ( S1 ) The authors give two types of estimate ( HVE and SVE ) of the joint probability used for calculating the loss , and further formulate new loss functions HVDL and SVDL , based on the estimated joint distribution . ( S2 ) The authors propose new methods of encoding the label input : element-wise addition for the generator , and linear embedding layer for the discriminator . The authors further derive and prove the error bounds for a discriminator trained with HVDL and SVDL . Experiments are conducted on continuous label datasets , and the authors propose a new dataset with continuous labels . Comparisons are made with traditional cGANs with discrete labels . * * * Pros : 1 . This paper is the first work on continuous conditional GAN . It solves the two key problems for generalizing traditional cGANs to continuous conditions , and empirically validates the effectiveness of the proposed approach . 2.The proposed approach is theoretically sound . The generalization from traditional cGANs with discrete labels to the novel continuous label conditional GANs is reasonable . The estimations ( HVE and SVE ) for deriving the new loss functions are clearly explained and mathematically elegant and solid . 3.Error bounds of the discriminator trained with HVDL and SVDL losses are derived and proved . This builds a strong and solid foundation of the proposed approach . 4.Experiments are conducted on various datasets . Reasonable results for generating synthetic data and real-world images are shown and compared with cGANs with discrete labels . * * * Cons : 1 . The experiments are conducted on low-resolution images with SNGAN structure . In order to test the generalization ability of the proposed approach , would it be possible to test on other state-of-the-art structures such as BigGAN ? And is it able to be trained to generate higher resolution images ? 2.Conditional GANs with continuous label conditions is an interesting direction that has been rarely explored before . Since most real-world datasets are with discrete labels , and even for some labels that can be discrete , it might be impossible to label it in a continuous way , and we will assign discrete labels . Can you elaborate more on the potential application scenarios and potential impacts of the continuous cGANs , besides the viewpoint and age examples used in this paper ? * * * Justification for rating I think this paper works on an interesting direction of continuous conditional GANs , which has rarely been explored before . The proposed approach to generalize cGANs to continuous label conditions and the proposed solutions to the key problems are elegant and novel . The authors not only give clear explanations but also provides mathematical error bounds and proves . So I would recommend acceptance . * * * Questions for the rebuttal Please address the questions in the Cons section . * * * After rebuttal Thank the authors for the detailed explanation . After reading other reviewers ' comments and the author feedback , I would like to keep my rating unchanged .", "rating": "7: Good paper, accept", "reply_text": "* * Q1 * * : `` The experiments are conducted on low-resolution images with SNGAN structure . In order to test the generalization ability of the proposed approach , would it be possible to test on other state-of-the-art structures such as BigGAN ? And is it able to be trained to generate higher resolution images ? '' * * A1 * * : We thank the reviewer for recognizing the novelty/contributions of our work , which we find very encouraging . Technically , the proposed algorithm can directly adopt more state-of-the-art network architectures to generate high-resolution images . This is because the method itself is a general framework , which is independent of image resolution or network architectures . In practice , generating high-resolution images ( 256x256 or 512x512 ) requires much more GPU memory than those for low-resolution images ( 64x64 ) . Also , SOTA architectures adopt larger batch-size which necessitates more GPU memory ( e.g. , BigGAN uses batch-size as 2048 ) . As our lab facility is limited , when we tried to experiment on BigGAN to generate high-resolution images , we found our lab GPU always prompted OOM error . We will open source all our codes/implementations , and we hope some researchers with adequate computational resources could help explore and experiment on generating high-resolution images . * * Q2 * * : `` Conditional GANs with continuous label conditions is an interesting direction that has been rarely explored before . Since most real-world datasets are with discrete labels , and even for some labels that can be discrete , it might be impossible to label it in a continuous way , and we will assign discrete labels . Can you elaborate more on the potential application scenarios and potential impacts of the continuous cGANs , besides the viewpoint and age examples used in this paper ? '' * * A2 * * : We agree with the reviewer that many real-world datasets are with discrete labels and it is sometimes impossible to make them mathematically continuous ( e.g. , ages are always labeled as integers despite their continuous nature ) . In general , there are three label scenarios that we can apply CcGANs . Scenario I : mathematically continuous labels ( e.g. , angles ) ; Scenarios II : discrete but ordinal labels ( e.g. , ages ) ; and Scenario III : discrete , categorical labels but they share close relationships among different label categories ( e.g. , fine-grained bird image generation ) . CcGANs can have potential applications in three above scenarios . For instance , in Scenario I , CcGANs could have potential impacts on autonomous driving which involves predicting the steering angle ( a continuous scalar ) to have better controllability over autonomous cars . In Scenario II , the proposed methods are potentially meaningful in some medical applications . E.g. , in medical experiments , an important task is cell counting , where the cell counting regressor needs to predict the number of cells ( i.e. , ordinal integers ) from a microscopic image . Even with limited microscopic cell images , the proposed CcGAN can generate visually synthetic and diverse microscopic images for the regressor training . In this way , CcGAN may help save many tedious efforts of medical doctors in gathering microscopic images . In Scenario III , as suggested by AnonReviewer 5 ( Q3 ) , CcGAN could be used on some fine-grained image classification datasets , e.g. , on the bird dataset where birds of different categories may share close similarities . The generated bird images can be used to enhance the fine-grained bird image classifiers , and potentially help us better recognize birds and protect the environment . More generally , CcGANs can be potentially used for image generation on regression datasets ( associated with scalar labels y ) , which can cover a wide range of tasks and applications . In the revision , we have elaborated and included more potential application scenarios and impacts of CcGANs in * * Supp . S.IX * * ( pp.30 ) ."}, {"review_id": "PrzjugOsDeE-1", "review_text": "# # # # # Summary This paper tries to make the generative adversarial network handle continuous , scalar conditions . Specifically , in order to make it work , the author set an empirical estimate that every small perturbation to the condition y results in negligible changes to the conditional distribution . The author shows comparative performance improvement over the basic cGAN on circular 2D Gaussians , RC-49 , and UTKFace dataset . # # # # # Strength First of all , this paper is well-written and easy to follow . This paper tackles one of the important topics in a generative network with appropriate assumptions and shows its relative effectiveness not only on a single dataset but also in various settings . It also provides rich details with the codes in supplementary . # # # # # Weakness First of all , although the math and logic are quite easy to follow , it is a bit hard to guess , especially to the person who does n't have a strong background in this domain , what exact behavior is enforced to the model . Also , along with the first issue , it is hard to predict this method 's stability for some non-well curated/designed setting . Please check the question section for the details . # # # # # Question 1 . As I mentioned in the weakness part , it is quite hard to imagine how this method will behave . Similar to Figure 1 of the original GAN paper ( Goodfellow et al. , in NeurIPS 2014 ) , or Figure 1 of VEEGAN ( Srivastava et al. , in NeurIPS 2017 ) , it would be great if the author can visualize how the distribution is matched and what kinds of behaviors are promoted/demoted by the loss . 2.As mentioned in ( P1 ) of this paper , there are many real-world cases that there are zero or only one label exists . To show the effectiveness in such an imbalanced setting , I recommend presenting the result that ( i ) train people of odd ages only and tested with even-numbered ages and ( ii ) tested with fewer data in some of the ages ( unlike the one in Figure S. VIII.5 or S.VIII.A ) . 3.Also , I also wonder what happened if the condition is not directly related ( to see whether the label power is essential or not ) . To alleviate such curiosity , I recommend testing it by modifying the label on one of the experiments . For instance , you can try this method on the RC-49 generation , not with the angle but with the chair 's volume . # # # # # Post-rebuttal I thank the authors for their thorough comments and detailed explanations for each question . I carefully read the whole , and it helps me understand the entire decision and the processes . However , I would like to suggest two things , regardless of its acceptance , but to make their claim more attractive to general readers : ( i ) re-sort out the indexes ( maybe after rebuttal but before submitting your camera-ready version ) , and ( ii ) update figures of the sample with a bit more realistic one ( with training the model on larger batch size , for instance ) . I hope this review phase would make your paper more powerful . ( disclaimer : I did not check the soundness of the mathematical equations thoroughly but did check all the rest )", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * Q1 * * : `` As I mentioned in the weakness part , it is quite hard to imagine how this method will behave . Similar to Figure 1 of the original GAN paper ( Goodfellow et al. , in NeurIPS 2014 ) , or Figure 1 of VEEGAN ( Srivastava et al. , in NeurIPS 2017 ) , it would be great if the author can visualize how the distribution is matched and what kinds of behaviors are promoted/demoted by the loss . '' * * A1 * * : We appreciate the reviewer \u2019 s constructive suggestion , and we have added * * Fig.1 * * ( pp.4 ) in the revised version . To make the proposed ideas easier to understand , similar to the practice in two suggested references , we visualize the behaviors of the key steps of the two proposed losses in diagrams . To derive the HVDL and SVDL in Eqs . ( 9 ) and ( 10 ) , we develop two estimates ( i.e. , HVE in Eq . ( 6 ) and SVE in Eq . ( 7 ) ) of the joint distributions of $ x $ and $ y $ . Firstly , we utilize KDEs to estimate the marginal distributions $ p ( y ) $ . We then estimate the key step , i.e. , the estimate of conditional distributions $ p ( x|y ) $ by utilizing samples in a hard/soft vicinity of y . We illustrate this step in * * Fig.1 * * ( pp.4 ) in the revised version . Specifically , as illustrated in * * Fig.1 * * , if we want to estimate $ p ( x|y ) $ ( the red curve ) but we only have samples ( red dots ) drawn from $ p ( x|y_1 ) $ and $ p ( x|y_2 ) $ ( the blue curves ) , then we do the estimation based on samples in a hard vicinity ( defined by $ y \\pm \\kappa $ ) or a soft vicinity ( defined by the weight decay curve ) of $ y $ . We hope the visualization/diagrams can better illustrate our ideas . * * Q2 * * : `` As mentioned in ( P1 ) of this paper , there are many real-world cases that there are zero or only one label exists . To show the effectiveness in such an imbalanced setting , I recommend presenting the result that ( i ) train people of odd ages only and tested with even-numbered ages and ( ii ) tested with fewer data in some of the ages ( unlike the one in Figure S. VIII.5 or S.VIII.A ) . '' * * A2 * * : We agree with the reviewer that there are zero or only one training image at some labels in real-world cases , and we appreciate the reviewer \u2019 s clever suggestions on additional experiments in ( i ) and ( ii ) . In the revised manuscript , we have performed experiments and presented complete comparisons on the UTKFace dataset in * * Supp . S.VIII.E.5 * * and * * Supp . S.VIII.E.6 * * ( from pp.28-pp.29 ) . We summarize our results and observations as follows . Experimental results on setting ( i ) : We train cGAN and CcGAN on images for odd ages only and test them on even-numbered ages following the suggested setup ( i ) . The quantitative results for cGAN and two CcGAN methods are summarized in * * Table S.VIII.3 * * ( pp.29 ) . From * * Table S.VIII.3 * * , we can see two CcGAN methods are still much better than cGAN in terms of all metrics except Label Score , since CcGAN is designed to sacrifice some ( not too much ) label consistency for much better visual quality and diversity . Experimental results on setting ( ii ) : To balance the training data and also test the performance of cGAN and CcGAN under smaller sample sizes , we vary the maximum sample size for each distinct age in the training from 200 to 50 . We visualize the line graphs of Intra-FID versus the maximum sample size for each age of cGAN and CcGAN in * * Fig.S.VIII.13 * * ( pp.29 ) . From the figure , we can clearly see that a smaller sample size degrades the performance of both cGAN and CcGAN . Moreover , the Intra-FID scores of cGAN always stay at a high level and are much larger than those of two CcGAN methods . In summary , with additional suggested experimental setups ( i.e. , ( i ) and ( ii ) ) , we demonstrate the effectiveness and superiority of the proposed CcGANs over cGANs under different settings . We have also included the full experimental comparison/discussions in * * Supp . S.VIII.E.5 * * and * * Supp . S.VIII.E.6 * * in the revised version ."}, {"review_id": "PrzjugOsDeE-2", "review_text": "This work proposes to perform Conditional GAN with regression labels , thus to benefit the model with data-sufficient continuations generation ( vs infinite distinct condition for generation ) . Inspired by VRM , a CcGAN model is proposed to tackle the challenges in existing methods . ( Eq . ( 6 ) > Eq . ( 10 ) ) An error bound is also derived for the proposed new discriminator loss . The idea to facilitate generation with continuous conditions is interesting and insightful . the experiments are also well-designed and analyzed to support the claim . My questions are mainly in the following aspects : 1 ) . Comparisons on more challenging data sets are suggested . Also , as you argue the deficiency of requiring large sample and condition size in baseline models , comparison regarding the different number of , or scare training data are better to be presented . 2 ) Can you please explain your superiority and connection with [ 1 ] . [ 1 ] .Zhao , Shengyu , et al . `` Differentiable augmentation for data-efficient gan training . '' arXiv preprint arXiv:2006.10738 ( 2020 ) .", "rating": "5: Marginally below acceptance threshold", "reply_text": "`` Interesting idea , but experiments needs to be strengthen and polished . '' With the experiments in the original submission and 6 extra experiments in the current version which are summarized in * * General Response to Reviewers \u2019 Comments * * , we believe current experiments are already strong enough to demonstrate the effectiveness of the proposed CcGAN . * * Q1 * * : `` Comparisons on more challenging data sets are suggested . Also , as you argue the deficiency of requiring large sample and condition size in baseline models , comparison regarding the different number of , or scare training data are better to be presented . '' * * A1 * * : We agree with the reviewer that challenging datasets are very important in evaluating CcGAN performances . As a new research direction , indeed we have tried our best to find challenging datasets for our experiments . We firstly design the 2D-circular Gaussian dataset with analytical conditional distribution to perform experimental comparisons . In addition , we also experiment on two real-world image datasets : the UTKFace and RC-49 datasets . The UTKFace dataset requires us to do careful manual preprocessing since some face images have bad visual quality and watermarks . We also generate the RC-49 dataset due to a lack of benchmark datasets in this research direction . As the first work in image generation conditional on continuous scalar labels , we focus on verifying the efficacy of the proposed methods and try to explain the story well . Indeed we plan to explore some other challenging real-world datasets/applications as our future work . As suggested by the reviewer , in the revision , we have additionally demonstrated the superiority of CcGANs by reducing the number of training samples at each scalar label . For instance , in the benchmark dataset RC-49 , we vary the number of sample sizes for each distinct training angle gradually from 45 to 5 . We include the experimental comparisons in * * Fig.S.VII.6 * * ( Intra-FID vs # sample sizes ) in the updated version ( in pp.25 ) . As shown in * * Fig.S.VII.6 * * , the proposed two CcGAN methods substantially outperform cGAN at different sample sizes for each distinct angle in the training set . Despite that both cGAN and CcGAN deteriorate with smaller sample sizes , we observe a sharper performance decrease trend on cGAN ; while CcGAN only degrades its performance slightly . Even with a very small sample size ( e.g. , 5 ) at each distinct angle , CcGANs can still maintain good performances . By contrast , cGAN fails even with much more training samples ( e.g. , 45 ) at each angle . Besides , as suggested by AnonReviewer1 ( Q2 ) , we also have conducted experiments on the UTKFace dataset with reduced number of training samples . Experimental results show that CcGANs consistently outperform cGANs by a large margin on UTKFace under different setups . In summary , even with limited training data , the proposed CcGANs work well while cGANs could completely fail . Indeed , these additional results show that the proposed CcGANs outperform cGANs substantially in the scarce training data scenario . This is because , CcGANs are proposed to tackle the limited ( or even 0 ) training sample problem encountered in the continuous conditional case . In the revision , we have included additional results in * * Fig.S.VII.6 * * ( pp.25 ) , * * Table S.VIII 3 * * ( pp.29 ) and * * Fig.S.VIII.13 * * ( pp.29 ) . Correspondingly , we have highlighted in red the detailed discussion regarding the experimental results/comparisons ."}, {"review_id": "PrzjugOsDeE-3", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper focuses on conditional image generation with continuous label . Current methods utilize categorical conditions , which easily suffers form two problems : ( 1 ) the inferior performance when given few images for special category ( 2 ) failure of using continue label . In this paper , authors reformulate the class-conditional GANs , and provide two new objectives ( hard vicinal discriminator loss and soft vicinal discriminator loss ) and one generator loss . Both the discriminator loss and the generator loss is extended based on the vicinal risk minimization . Authors design interesting experiments to evaluate the proposed method . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : +The paper explores new problem for conditional GANs . Specially the continues label never be studied , which is interesting for me . +Authors leverage vicinal risk minimization to replace current empirical generator loss , which is new viewpoint to investigate the conditional image generation . +The first experiment is interesting , which is suitable to support the proposed method . +The paper has good motivation , and is easy to follow . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # I have a few concerns which is as followiing : 1 . In page 2 , authors mention ' ( 1 ) our experiments in Section 4 show that this approach often makes cGANs collapse ; ' what is reason why current methods fail ? Is it due to the imbalance of data for each category ? or Is it normal issue of training GANs and cGANs ? 2.I really like 'circular 2-d gaussians ' experiment , which is smartly designed the proposed method . For the proposed method ( E.q.11 for generator ) , it has already seen the data which is corresponding to test label ( angle ) , since the real sample ( Figure 1 ( a ) ) is localized in any angle and the used label ( of the proposed method ) for training is noised , which means the noised label is the test label . Could authors try the real sample like one of Figure ( b ) which the real sample is not continues . 3.I am wondering the proposed method could be used for fine-grand image generation . For example , the bird dataset [ 1 ] has 555 category , and some categories are close . 4.In paragraph : How is ( P2 ) solved ? . The new method to map the label seems similar to the label embedding . For example , the label embedding of BigGAN is also be updated . But here authors map the label by FC layers , which is corresponding to the learned label embedding . And the combination of both the image embedding and the class embedding is similar to the one used in SNGAN and BigGAN . [ 1 ] Grant Van Horn , Steve Branson , Ryan Farrell , Scott Haber , Jessie Barry , Panos Ipeirotis , Pietro Perona , and Serge Belongie . Building a bird recognition app and large scale dataset with citizen scientists : The fine print in fine-grained dataset collection . In CVPR , pages 595\u2013604 , 2015 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * Q1 * * : `` In page 2 , authors mention ' ( 1 ) our experiments in Section 4 show that this approach often makes cGANs collapse ; ' what is reason why current methods fail ? Is it due to the imbalance of data for each category ? or Is it normal issue of training GANs and cGANs ? '' * * A1 * * : We appreciate the reviewer raising this interesting discussion on the failure of class-conditional GANs in the image generation conditional on continuous , scalar conditions ( i.e. , regression labels ) . Although more experiments on other datasets need to be done to confirm this observation , we feel it may be a normal issue in training class-conditional GANs in such continuous scenarios since we observe the same failure in both RC-49 and UTKFace experiments . We don \u2019 t think this issue is caused by the imbalance of data for each category since the RC-49 dataset is balanced but the class-conditional GAN still fails . Instead , we believe this failure occurs because there does not exist a good way to convert regression labels into class labels . In our experiments , to implement class-conditional GANs , regression labels are converted into class labels by binning regression labels into multiple disjoint intervals and each interval is taken as a class . Please note that , treating each distinct regression label as a class can be seen as a special case of the binning strategy when the width of the binned intervals equals zero . We intuitively explain as follows how this ill-defined label conversion may cause the failure of class-conditional GANs . After binning regression labels into disjoint intervals , two consecutive intervals are separated by a cutoff point . If the primary assumption holds in this paper that a small perturbation to $ y $ leads to a negligible change to $ p ( x|y ) $ , then samples at two sides of this cutoff point may come from similar conditional distributions ( conditional on regression labels ) but are grouped into two different classes . For example , if we bin the 60 distinct ages in UTKFace into three intervals , i.e. , [ 1,20 ] , [ 21 , 40 ] , [ 41 , 60 ] , the distribution of facial features at age 20 should be close to that at 21 , while now images for age 20 and images for age 21 are in two different classes . Consequently , the image distribution conditional on these two classes may have a high overlap and this high overlap reduces the inter-class variation . On the other hand , images in each binned interval may have a high variation ( i.e. , intra-class variation ) which may be comparable to or even larger than the inter-class variation . For example , in UTKFace , people of age 30 have different hair styles , different eye colors , different hair colors , different skin colors , different makeups , etc . It is very likely that such intra-class variation is much larger than the inter-class variation . Therefore , unlike the classes in common classification-oriented datasets ( e.g. , CIFAR-10 , ImageNet , etc . ) , the binned intervals in UTKFace and RC-49 may have a large intra-class variation but a small inter-class variation , which makes it difficult for the class-conditional GANs to learn how the image distribution varies in terms of class labels . Therefore , class-conditional GANs may fail in the continuous scenario ."}], "0": {"review_id": "PrzjugOsDeE-0", "review_text": "* * * Summary : This paper proposes a novel continuous conditional GAN which takes continuous scalars ( named regression labels ) as conditions . There are two problems for continuous conditional GAN : ( P1 ) cGANs with discrete labels are trained to minimize the empirical loss , but this fails for continuous conditions , because there might be few or even zero samples for many labels values . ( P2 ) For continuous labels , the label can not be embedded by one-hot encoding like discrete labels . The authors propose two solutions for the problems respectively : ( S1 ) The authors give two types of estimate ( HVE and SVE ) of the joint probability used for calculating the loss , and further formulate new loss functions HVDL and SVDL , based on the estimated joint distribution . ( S2 ) The authors propose new methods of encoding the label input : element-wise addition for the generator , and linear embedding layer for the discriminator . The authors further derive and prove the error bounds for a discriminator trained with HVDL and SVDL . Experiments are conducted on continuous label datasets , and the authors propose a new dataset with continuous labels . Comparisons are made with traditional cGANs with discrete labels . * * * Pros : 1 . This paper is the first work on continuous conditional GAN . It solves the two key problems for generalizing traditional cGANs to continuous conditions , and empirically validates the effectiveness of the proposed approach . 2.The proposed approach is theoretically sound . The generalization from traditional cGANs with discrete labels to the novel continuous label conditional GANs is reasonable . The estimations ( HVE and SVE ) for deriving the new loss functions are clearly explained and mathematically elegant and solid . 3.Error bounds of the discriminator trained with HVDL and SVDL losses are derived and proved . This builds a strong and solid foundation of the proposed approach . 4.Experiments are conducted on various datasets . Reasonable results for generating synthetic data and real-world images are shown and compared with cGANs with discrete labels . * * * Cons : 1 . The experiments are conducted on low-resolution images with SNGAN structure . In order to test the generalization ability of the proposed approach , would it be possible to test on other state-of-the-art structures such as BigGAN ? And is it able to be trained to generate higher resolution images ? 2.Conditional GANs with continuous label conditions is an interesting direction that has been rarely explored before . Since most real-world datasets are with discrete labels , and even for some labels that can be discrete , it might be impossible to label it in a continuous way , and we will assign discrete labels . Can you elaborate more on the potential application scenarios and potential impacts of the continuous cGANs , besides the viewpoint and age examples used in this paper ? * * * Justification for rating I think this paper works on an interesting direction of continuous conditional GANs , which has rarely been explored before . The proposed approach to generalize cGANs to continuous label conditions and the proposed solutions to the key problems are elegant and novel . The authors not only give clear explanations but also provides mathematical error bounds and proves . So I would recommend acceptance . * * * Questions for the rebuttal Please address the questions in the Cons section . * * * After rebuttal Thank the authors for the detailed explanation . After reading other reviewers ' comments and the author feedback , I would like to keep my rating unchanged .", "rating": "7: Good paper, accept", "reply_text": "* * Q1 * * : `` The experiments are conducted on low-resolution images with SNGAN structure . In order to test the generalization ability of the proposed approach , would it be possible to test on other state-of-the-art structures such as BigGAN ? And is it able to be trained to generate higher resolution images ? '' * * A1 * * : We thank the reviewer for recognizing the novelty/contributions of our work , which we find very encouraging . Technically , the proposed algorithm can directly adopt more state-of-the-art network architectures to generate high-resolution images . This is because the method itself is a general framework , which is independent of image resolution or network architectures . In practice , generating high-resolution images ( 256x256 or 512x512 ) requires much more GPU memory than those for low-resolution images ( 64x64 ) . Also , SOTA architectures adopt larger batch-size which necessitates more GPU memory ( e.g. , BigGAN uses batch-size as 2048 ) . As our lab facility is limited , when we tried to experiment on BigGAN to generate high-resolution images , we found our lab GPU always prompted OOM error . We will open source all our codes/implementations , and we hope some researchers with adequate computational resources could help explore and experiment on generating high-resolution images . * * Q2 * * : `` Conditional GANs with continuous label conditions is an interesting direction that has been rarely explored before . Since most real-world datasets are with discrete labels , and even for some labels that can be discrete , it might be impossible to label it in a continuous way , and we will assign discrete labels . Can you elaborate more on the potential application scenarios and potential impacts of the continuous cGANs , besides the viewpoint and age examples used in this paper ? '' * * A2 * * : We agree with the reviewer that many real-world datasets are with discrete labels and it is sometimes impossible to make them mathematically continuous ( e.g. , ages are always labeled as integers despite their continuous nature ) . In general , there are three label scenarios that we can apply CcGANs . Scenario I : mathematically continuous labels ( e.g. , angles ) ; Scenarios II : discrete but ordinal labels ( e.g. , ages ) ; and Scenario III : discrete , categorical labels but they share close relationships among different label categories ( e.g. , fine-grained bird image generation ) . CcGANs can have potential applications in three above scenarios . For instance , in Scenario I , CcGANs could have potential impacts on autonomous driving which involves predicting the steering angle ( a continuous scalar ) to have better controllability over autonomous cars . In Scenario II , the proposed methods are potentially meaningful in some medical applications . E.g. , in medical experiments , an important task is cell counting , where the cell counting regressor needs to predict the number of cells ( i.e. , ordinal integers ) from a microscopic image . Even with limited microscopic cell images , the proposed CcGAN can generate visually synthetic and diverse microscopic images for the regressor training . In this way , CcGAN may help save many tedious efforts of medical doctors in gathering microscopic images . In Scenario III , as suggested by AnonReviewer 5 ( Q3 ) , CcGAN could be used on some fine-grained image classification datasets , e.g. , on the bird dataset where birds of different categories may share close similarities . The generated bird images can be used to enhance the fine-grained bird image classifiers , and potentially help us better recognize birds and protect the environment . More generally , CcGANs can be potentially used for image generation on regression datasets ( associated with scalar labels y ) , which can cover a wide range of tasks and applications . In the revision , we have elaborated and included more potential application scenarios and impacts of CcGANs in * * Supp . S.IX * * ( pp.30 ) ."}, "1": {"review_id": "PrzjugOsDeE-1", "review_text": "# # # # # Summary This paper tries to make the generative adversarial network handle continuous , scalar conditions . Specifically , in order to make it work , the author set an empirical estimate that every small perturbation to the condition y results in negligible changes to the conditional distribution . The author shows comparative performance improvement over the basic cGAN on circular 2D Gaussians , RC-49 , and UTKFace dataset . # # # # # Strength First of all , this paper is well-written and easy to follow . This paper tackles one of the important topics in a generative network with appropriate assumptions and shows its relative effectiveness not only on a single dataset but also in various settings . It also provides rich details with the codes in supplementary . # # # # # Weakness First of all , although the math and logic are quite easy to follow , it is a bit hard to guess , especially to the person who does n't have a strong background in this domain , what exact behavior is enforced to the model . Also , along with the first issue , it is hard to predict this method 's stability for some non-well curated/designed setting . Please check the question section for the details . # # # # # Question 1 . As I mentioned in the weakness part , it is quite hard to imagine how this method will behave . Similar to Figure 1 of the original GAN paper ( Goodfellow et al. , in NeurIPS 2014 ) , or Figure 1 of VEEGAN ( Srivastava et al. , in NeurIPS 2017 ) , it would be great if the author can visualize how the distribution is matched and what kinds of behaviors are promoted/demoted by the loss . 2.As mentioned in ( P1 ) of this paper , there are many real-world cases that there are zero or only one label exists . To show the effectiveness in such an imbalanced setting , I recommend presenting the result that ( i ) train people of odd ages only and tested with even-numbered ages and ( ii ) tested with fewer data in some of the ages ( unlike the one in Figure S. VIII.5 or S.VIII.A ) . 3.Also , I also wonder what happened if the condition is not directly related ( to see whether the label power is essential or not ) . To alleviate such curiosity , I recommend testing it by modifying the label on one of the experiments . For instance , you can try this method on the RC-49 generation , not with the angle but with the chair 's volume . # # # # # Post-rebuttal I thank the authors for their thorough comments and detailed explanations for each question . I carefully read the whole , and it helps me understand the entire decision and the processes . However , I would like to suggest two things , regardless of its acceptance , but to make their claim more attractive to general readers : ( i ) re-sort out the indexes ( maybe after rebuttal but before submitting your camera-ready version ) , and ( ii ) update figures of the sample with a bit more realistic one ( with training the model on larger batch size , for instance ) . I hope this review phase would make your paper more powerful . ( disclaimer : I did not check the soundness of the mathematical equations thoroughly but did check all the rest )", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * Q1 * * : `` As I mentioned in the weakness part , it is quite hard to imagine how this method will behave . Similar to Figure 1 of the original GAN paper ( Goodfellow et al. , in NeurIPS 2014 ) , or Figure 1 of VEEGAN ( Srivastava et al. , in NeurIPS 2017 ) , it would be great if the author can visualize how the distribution is matched and what kinds of behaviors are promoted/demoted by the loss . '' * * A1 * * : We appreciate the reviewer \u2019 s constructive suggestion , and we have added * * Fig.1 * * ( pp.4 ) in the revised version . To make the proposed ideas easier to understand , similar to the practice in two suggested references , we visualize the behaviors of the key steps of the two proposed losses in diagrams . To derive the HVDL and SVDL in Eqs . ( 9 ) and ( 10 ) , we develop two estimates ( i.e. , HVE in Eq . ( 6 ) and SVE in Eq . ( 7 ) ) of the joint distributions of $ x $ and $ y $ . Firstly , we utilize KDEs to estimate the marginal distributions $ p ( y ) $ . We then estimate the key step , i.e. , the estimate of conditional distributions $ p ( x|y ) $ by utilizing samples in a hard/soft vicinity of y . We illustrate this step in * * Fig.1 * * ( pp.4 ) in the revised version . Specifically , as illustrated in * * Fig.1 * * , if we want to estimate $ p ( x|y ) $ ( the red curve ) but we only have samples ( red dots ) drawn from $ p ( x|y_1 ) $ and $ p ( x|y_2 ) $ ( the blue curves ) , then we do the estimation based on samples in a hard vicinity ( defined by $ y \\pm \\kappa $ ) or a soft vicinity ( defined by the weight decay curve ) of $ y $ . We hope the visualization/diagrams can better illustrate our ideas . * * Q2 * * : `` As mentioned in ( P1 ) of this paper , there are many real-world cases that there are zero or only one label exists . To show the effectiveness in such an imbalanced setting , I recommend presenting the result that ( i ) train people of odd ages only and tested with even-numbered ages and ( ii ) tested with fewer data in some of the ages ( unlike the one in Figure S. VIII.5 or S.VIII.A ) . '' * * A2 * * : We agree with the reviewer that there are zero or only one training image at some labels in real-world cases , and we appreciate the reviewer \u2019 s clever suggestions on additional experiments in ( i ) and ( ii ) . In the revised manuscript , we have performed experiments and presented complete comparisons on the UTKFace dataset in * * Supp . S.VIII.E.5 * * and * * Supp . S.VIII.E.6 * * ( from pp.28-pp.29 ) . We summarize our results and observations as follows . Experimental results on setting ( i ) : We train cGAN and CcGAN on images for odd ages only and test them on even-numbered ages following the suggested setup ( i ) . The quantitative results for cGAN and two CcGAN methods are summarized in * * Table S.VIII.3 * * ( pp.29 ) . From * * Table S.VIII.3 * * , we can see two CcGAN methods are still much better than cGAN in terms of all metrics except Label Score , since CcGAN is designed to sacrifice some ( not too much ) label consistency for much better visual quality and diversity . Experimental results on setting ( ii ) : To balance the training data and also test the performance of cGAN and CcGAN under smaller sample sizes , we vary the maximum sample size for each distinct age in the training from 200 to 50 . We visualize the line graphs of Intra-FID versus the maximum sample size for each age of cGAN and CcGAN in * * Fig.S.VIII.13 * * ( pp.29 ) . From the figure , we can clearly see that a smaller sample size degrades the performance of both cGAN and CcGAN . Moreover , the Intra-FID scores of cGAN always stay at a high level and are much larger than those of two CcGAN methods . In summary , with additional suggested experimental setups ( i.e. , ( i ) and ( ii ) ) , we demonstrate the effectiveness and superiority of the proposed CcGANs over cGANs under different settings . We have also included the full experimental comparison/discussions in * * Supp . S.VIII.E.5 * * and * * Supp . S.VIII.E.6 * * in the revised version ."}, "2": {"review_id": "PrzjugOsDeE-2", "review_text": "This work proposes to perform Conditional GAN with regression labels , thus to benefit the model with data-sufficient continuations generation ( vs infinite distinct condition for generation ) . Inspired by VRM , a CcGAN model is proposed to tackle the challenges in existing methods . ( Eq . ( 6 ) > Eq . ( 10 ) ) An error bound is also derived for the proposed new discriminator loss . The idea to facilitate generation with continuous conditions is interesting and insightful . the experiments are also well-designed and analyzed to support the claim . My questions are mainly in the following aspects : 1 ) . Comparisons on more challenging data sets are suggested . Also , as you argue the deficiency of requiring large sample and condition size in baseline models , comparison regarding the different number of , or scare training data are better to be presented . 2 ) Can you please explain your superiority and connection with [ 1 ] . [ 1 ] .Zhao , Shengyu , et al . `` Differentiable augmentation for data-efficient gan training . '' arXiv preprint arXiv:2006.10738 ( 2020 ) .", "rating": "5: Marginally below acceptance threshold", "reply_text": "`` Interesting idea , but experiments needs to be strengthen and polished . '' With the experiments in the original submission and 6 extra experiments in the current version which are summarized in * * General Response to Reviewers \u2019 Comments * * , we believe current experiments are already strong enough to demonstrate the effectiveness of the proposed CcGAN . * * Q1 * * : `` Comparisons on more challenging data sets are suggested . Also , as you argue the deficiency of requiring large sample and condition size in baseline models , comparison regarding the different number of , or scare training data are better to be presented . '' * * A1 * * : We agree with the reviewer that challenging datasets are very important in evaluating CcGAN performances . As a new research direction , indeed we have tried our best to find challenging datasets for our experiments . We firstly design the 2D-circular Gaussian dataset with analytical conditional distribution to perform experimental comparisons . In addition , we also experiment on two real-world image datasets : the UTKFace and RC-49 datasets . The UTKFace dataset requires us to do careful manual preprocessing since some face images have bad visual quality and watermarks . We also generate the RC-49 dataset due to a lack of benchmark datasets in this research direction . As the first work in image generation conditional on continuous scalar labels , we focus on verifying the efficacy of the proposed methods and try to explain the story well . Indeed we plan to explore some other challenging real-world datasets/applications as our future work . As suggested by the reviewer , in the revision , we have additionally demonstrated the superiority of CcGANs by reducing the number of training samples at each scalar label . For instance , in the benchmark dataset RC-49 , we vary the number of sample sizes for each distinct training angle gradually from 45 to 5 . We include the experimental comparisons in * * Fig.S.VII.6 * * ( Intra-FID vs # sample sizes ) in the updated version ( in pp.25 ) . As shown in * * Fig.S.VII.6 * * , the proposed two CcGAN methods substantially outperform cGAN at different sample sizes for each distinct angle in the training set . Despite that both cGAN and CcGAN deteriorate with smaller sample sizes , we observe a sharper performance decrease trend on cGAN ; while CcGAN only degrades its performance slightly . Even with a very small sample size ( e.g. , 5 ) at each distinct angle , CcGANs can still maintain good performances . By contrast , cGAN fails even with much more training samples ( e.g. , 45 ) at each angle . Besides , as suggested by AnonReviewer1 ( Q2 ) , we also have conducted experiments on the UTKFace dataset with reduced number of training samples . Experimental results show that CcGANs consistently outperform cGANs by a large margin on UTKFace under different setups . In summary , even with limited training data , the proposed CcGANs work well while cGANs could completely fail . Indeed , these additional results show that the proposed CcGANs outperform cGANs substantially in the scarce training data scenario . This is because , CcGANs are proposed to tackle the limited ( or even 0 ) training sample problem encountered in the continuous conditional case . In the revision , we have included additional results in * * Fig.S.VII.6 * * ( pp.25 ) , * * Table S.VIII 3 * * ( pp.29 ) and * * Fig.S.VIII.13 * * ( pp.29 ) . Correspondingly , we have highlighted in red the detailed discussion regarding the experimental results/comparisons ."}, "3": {"review_id": "PrzjugOsDeE-3", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper focuses on conditional image generation with continuous label . Current methods utilize categorical conditions , which easily suffers form two problems : ( 1 ) the inferior performance when given few images for special category ( 2 ) failure of using continue label . In this paper , authors reformulate the class-conditional GANs , and provide two new objectives ( hard vicinal discriminator loss and soft vicinal discriminator loss ) and one generator loss . Both the discriminator loss and the generator loss is extended based on the vicinal risk minimization . Authors design interesting experiments to evaluate the proposed method . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : +The paper explores new problem for conditional GANs . Specially the continues label never be studied , which is interesting for me . +Authors leverage vicinal risk minimization to replace current empirical generator loss , which is new viewpoint to investigate the conditional image generation . +The first experiment is interesting , which is suitable to support the proposed method . +The paper has good motivation , and is easy to follow . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # I have a few concerns which is as followiing : 1 . In page 2 , authors mention ' ( 1 ) our experiments in Section 4 show that this approach often makes cGANs collapse ; ' what is reason why current methods fail ? Is it due to the imbalance of data for each category ? or Is it normal issue of training GANs and cGANs ? 2.I really like 'circular 2-d gaussians ' experiment , which is smartly designed the proposed method . For the proposed method ( E.q.11 for generator ) , it has already seen the data which is corresponding to test label ( angle ) , since the real sample ( Figure 1 ( a ) ) is localized in any angle and the used label ( of the proposed method ) for training is noised , which means the noised label is the test label . Could authors try the real sample like one of Figure ( b ) which the real sample is not continues . 3.I am wondering the proposed method could be used for fine-grand image generation . For example , the bird dataset [ 1 ] has 555 category , and some categories are close . 4.In paragraph : How is ( P2 ) solved ? . The new method to map the label seems similar to the label embedding . For example , the label embedding of BigGAN is also be updated . But here authors map the label by FC layers , which is corresponding to the learned label embedding . And the combination of both the image embedding and the class embedding is similar to the one used in SNGAN and BigGAN . [ 1 ] Grant Van Horn , Steve Branson , Ryan Farrell , Scott Haber , Jessie Barry , Panos Ipeirotis , Pietro Perona , and Serge Belongie . Building a bird recognition app and large scale dataset with citizen scientists : The fine print in fine-grained dataset collection . In CVPR , pages 595\u2013604 , 2015 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * Q1 * * : `` In page 2 , authors mention ' ( 1 ) our experiments in Section 4 show that this approach often makes cGANs collapse ; ' what is reason why current methods fail ? Is it due to the imbalance of data for each category ? or Is it normal issue of training GANs and cGANs ? '' * * A1 * * : We appreciate the reviewer raising this interesting discussion on the failure of class-conditional GANs in the image generation conditional on continuous , scalar conditions ( i.e. , regression labels ) . Although more experiments on other datasets need to be done to confirm this observation , we feel it may be a normal issue in training class-conditional GANs in such continuous scenarios since we observe the same failure in both RC-49 and UTKFace experiments . We don \u2019 t think this issue is caused by the imbalance of data for each category since the RC-49 dataset is balanced but the class-conditional GAN still fails . Instead , we believe this failure occurs because there does not exist a good way to convert regression labels into class labels . In our experiments , to implement class-conditional GANs , regression labels are converted into class labels by binning regression labels into multiple disjoint intervals and each interval is taken as a class . Please note that , treating each distinct regression label as a class can be seen as a special case of the binning strategy when the width of the binned intervals equals zero . We intuitively explain as follows how this ill-defined label conversion may cause the failure of class-conditional GANs . After binning regression labels into disjoint intervals , two consecutive intervals are separated by a cutoff point . If the primary assumption holds in this paper that a small perturbation to $ y $ leads to a negligible change to $ p ( x|y ) $ , then samples at two sides of this cutoff point may come from similar conditional distributions ( conditional on regression labels ) but are grouped into two different classes . For example , if we bin the 60 distinct ages in UTKFace into three intervals , i.e. , [ 1,20 ] , [ 21 , 40 ] , [ 41 , 60 ] , the distribution of facial features at age 20 should be close to that at 21 , while now images for age 20 and images for age 21 are in two different classes . Consequently , the image distribution conditional on these two classes may have a high overlap and this high overlap reduces the inter-class variation . On the other hand , images in each binned interval may have a high variation ( i.e. , intra-class variation ) which may be comparable to or even larger than the inter-class variation . For example , in UTKFace , people of age 30 have different hair styles , different eye colors , different hair colors , different skin colors , different makeups , etc . It is very likely that such intra-class variation is much larger than the inter-class variation . Therefore , unlike the classes in common classification-oriented datasets ( e.g. , CIFAR-10 , ImageNet , etc . ) , the binned intervals in UTKFace and RC-49 may have a large intra-class variation but a small inter-class variation , which makes it difficult for the class-conditional GANs to learn how the image distribution varies in terms of class labels . Therefore , class-conditional GANs may fail in the continuous scenario ."}}