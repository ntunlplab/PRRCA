{"year": "2018", "forum": "BJNRFNlRW", "title": "TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN", "decision": "Accept (Poster)", "meta_review": "The paper makes a good theoretical contribution by formulating the GAN training as primal-dual subgradient method for convex optimization and providing convergence proof. The authors then propose a modified objective to standard GAN training, based on this formulation, that helps address the mode collapse issue.\nOne weak point of the paper as pointed out by reviewers is that that the experimental results are underwhelming and the approach may not scale well to high dimensional datasets / high-resolution images. Interestingly, the proposed approach is general enough to be applied to other GAN variants that may address this issue in future. I recommend acceptance.", "reviews": [{"review_id": "BJNRFNlRW-0", "review_text": "This paper formulates GAN as a Lagrangian of a primal convex constrained optimization problem. They then suggest to modify the updates used in the standard GAN training to be similar to the primal-dual updates typically used by primal-dual subgradient methods. Technically, the paper is sound. It mostly leverages the existing literature on primal-dual subgradient methods to modify the GAN training procedure. I think this is a nice contribution that does yield to some interesting insights. However I do have some concerns about the way the paper is currently written and I find some claims misleading. Prior convergence proofs: I think the way the paper is currently written is misleading. The authors quote the paper from Ian Goodfellow: \u201cFor GANs, there is no theoretical prediction as to whether simultaneous gradient descent should converge or not.\u201d. However, the f-GAN paper gave a proof of convergence, see Theorem 2 here: https://arxiv.org/pdf/1606.00709.pdf. A recent NIPS paper by (Nagarajan and Kolter, 2017) also study the convergence properties of simultaneous gradient descent. Another problem is of course the assumptions required for the proof that typically don\u2019t hold in practice (see comment below). Convex-concave assumption: In practice the GAN objective is optimized over the parameters of the neural network rather than the generative distribution. This typically yields a non-convex non-concave optimization problem. This should be mentioned in the paper and I would like to see a discussion concerning the gap between the theory and the practical algorithm. Relation to existing regularization techniques: Combining Equations 11 and 13, the second terms acts as a regularizer that minimizes [\\lapha f_1(D(x_i))]^2. This looks rather similar to some of the recent regularization techniques such as Improved Training of Wasserstein GANs, https://arxiv.org/pdf/1704.00028.pdf Stabilizing Training of Generative Adversarial Networks through Regularization, https://arxiv.org/pdf/1705.09367.pdf Can the authors comment on this? I think this would also shed some light as to why this approach alleviates the problem of mode collapse. Curse of dimensionality: Nonparametric density estimators such as the KDE technique used in this paper suffer from the well-known curse of dimensionality. For the synthetic data, the empirical evidence seem to indicate that the technique proposed by the authors does work but I\u2019m not sure the empirical evidence provided for the MNIST and CIFAR-10 datasets is sufficient to judge whether or not the method does help with mode collapse. The inception score fails to capture this property. Could the authors explore other quantitative measure? Have you considered trying your approach on the augmented version of the MNIST dataset used in Metz et al. (2016) and Che et al. (2016)? Experiments Typo: Should say \u201cThe data distribution is p_d(x) = 1{x=1}\u201d. ", "rating": "7: Good paper, accept", "reply_text": "The authors would like to thank the reviewer for his/her invaluable comments . We have taken the reviewers ' comments into consideration when revising our paper . Moreover , our responses to the comments raised by the reviewer are as follows : 1 . Comment : Prior convergence proofs : I think the way the paper is currently written is misleading . The authors quote the paper from Ian Goodfellow : \u201c For GANs , there is no theoretical prediction as to whether simultaneous gradient descent should converge or not. \u201d . However , the f-GAN paper gave a proof of convergence , see Theorem 2 here : https : //arxiv.org/pdf/1606.00709.pdf . A recent NIPS paper by ( Nagarajan and Kolter , 2017 ) also study the convergence properties of simultaneous gradient descent . Another problem is of course the assumptions required for the proof that typically don \u2019 t hold in practice ( see comment below ) . Our reply : We would like to thank the reviewer for pointing out the latest NIPS paper by Nagarajan and Kolter . We have included this in our literature review . We have also made revisions in the paper to avoid the misleading arguments ( see below ) . \\textit { However , the analysis of the convergence properties on the training approaches is challenging , as noted by Ian Goodfellow in ( Goodfellow , 2016 ) , `` For GANs , there is no theoretical prediction as to whether simultaneous gradient descent should converge or not . Settling this theoretical question , and developing algorithms guaranteed to converge , remain important open research problems . `` . There have been some recent studies on the convergence behaviours of GAN training ( Nowozin et al. , 2016 ; Li et al. , 2017 ; Heusel et al. , 2017 ; Nagarajan \\ & Kolter , 2017 ; Mescheder et al. , 2017 ) . The simultaneous gradient descent method was proved to converge assuming the objective function is convex-concave in the network parameters ( Nowozin et al. , 2016 ) . The local stability property is established in ( Heusel et al. , 2017 ; Nagarajan \\ & Kolter , 2017 ) . } Ian Goodfellow raised the convergence issue in the tutorial paper , because the study of convergence for the simultaneous gradient descent method was limited at that time . They also gave a counterexample in the tutorial paper , which shows that the simultaneous gradient descent can not converge for some objective functions with some step size . This is one of the motivations of the paper to study the simultaneous gradient descent method . We agree with the reviewer that this convergence issue has been studied at least in the following works : [ a ] `` f-GAN : Training Generative Neural Samplers using Variational Divergence Minimization '' by Nowozin and Cseke . [ b ] `` Gradient descent GAN optimization is locally stable '' by Nagarajan and Kolter . [ c ] `` GANs trained by a two time-scale update rule converge to a Nash equibrium '' by Heusel et al ( as noted in our introduction part ) . These papers together with our paper study the convergence issue from different perspectives . In particular , these three papers study the convergence behavior of updates over the network parameters . Reference [ a ] assumes the objective function is convex-concave in the network parameters , while reference [ b ] and [ c ] study the local stability property . Our paper studies the convergence behavior in the function space , which was the started point in the first GAN paper by Ian Goodfellow . We incorporate the two conventional training methods into one framework , namely simultaneous gradient descent update and discrminator-driven update ( discriminator is fully optimized before the gradient update of the generator ) . The theoretical convergence proof leverage some well-established results from the primal-dual subgradient methods for convex optimization . Although the actual optimization is over the network parameters , which is non-convex non-cave in general , our formulation provides important insights in improving the training methods , as detailed in the next point ."}, {"review_id": "BJNRFNlRW-1", "review_text": "This paper proposed a framework to connect the solving of GAN with finding the saddle point of a minimax problem. As a result, the primal-dual subgradient methods can be directly introduced to calculate the saddle point. Additionally, this idea not only fill the relatviely lacking of theoretical results for GAN or WGAN, but also provide a new perspective to modify the GAN-type models. But this saddle point model reformulation in section 2 is quite standard, with limited theoretical analysis in Theorem 1. As follows, the resulting algorithm 1 is also standard primal-dual method for a saddle point problem. Most important I think, the advantage of considering GAN-type model as a saddle point model is that first--order methods can be designed to solve it. But the numerical experiments part seems to be a bit weak, because the MINST or CIFAR-10 dataset is not large enough to test the extensibility for large-scale cases. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "The authors would like to thank the reviewer for his/her invaluable comments . We have taken the reviewers ' comments into consideration when revising our paper . Moreover , our responses to the comments raised by the reviewer are as follows : 1 . Comment : But this saddle point model reformulation in section 2 is quite standard , with limited theoretical analysis in Theorem 1 . As follows , the resulting algorithm 1 is also standard primal-dual method for a saddle point problem . Most important I think , the advantage of considering GAN-type model as a saddle point model is that first order methods can be designed to solve it . Our reply : We agree with the reviewer that the Lagrangian formulation in Section 2 is standard . The main contribution of the paper is to provide a new perspective of understanding GAN . In particular , we relate the minimax game to finding the saddle points of the Lagrangian function for a convex optimization problem , where the generated distribution plays the role of the dual variable . This inherent connection was not established in previous works and it shows that the standard training of GANs actually falls in the framework of primal-dual subgradient methods for convex optimization . As the the reviewer mentions , one important result is to show that the training actually converge to the optimal point if a proper step size is chosen , and both the discriminator output and the generated distribution are correctly updated according to the primal-dual rule . Besides this , it provides the following important insights : ( a ) . It inspires an improved training technique to avoid mode collapse . In practical training , the generated distribution is not updated according to the desired direction . As Claim 1 points out , when the generated probability at some data point $ \\bx $ is zero and the discriminator output $ D ( \\bx ) $ is locally constant , mode collapse occurs . Using the traditional training , we can hardly avoid such mode collapse , even under the recently proposed WGAN . The Lagrangian formulation tells that the optimal update direction of $ p_g ( \\cdot ) $ is given by Eq . ( 11 ) .When mode collapse occurs , Eq . ( 13 ) gives a large gradient to push the generator to produce some samples at $ \\bx $ . The synthetic example shows that it indeed increases the data sample diversity and effectively avoids mode collapse . ( b ) .It naturally incorporates different variants of GANs into the convex optimization framework including the family of f-GAN ( Nowozin et al. , 2016 ) and an approximate variant of WGAN . For all these GAN variants , an improved training objective can be easily derived . ( c ) .The simultaneous primal-dual update is known to have a very slow convergence rate . There have been proposed methods to accelerate the convergence rates in the following papers : Angelia Nedic and Asuman Ozdaglar , `` Subgradient methods for saddle-point problems '' . Yunmei Chen , Guanghui Lan and Yuyuan Ouyang , `` Optimal primal-dual methods for a class of saddle point problems '' . By building the relation of GAN training and the primal-dual approach for convex optimizations , these improved methods can be directly applied . In future research , we will evaluate the acceleration of the training process using these approaches . ( d ) .For some GAN variants , where the objective function is not strictly convex , the convergence may be slow or the converging point is not unique . By casting the minimax game in the Lagrangian framework , we could easily tweak the objective function such that the objective function is strictly convex and the optimal solution is not affected , then the convergence performance can be improved . Examples can be found in `` Nonlinear Programming '' by D. Bertsekas ."}, {"review_id": "BJNRFNlRW-2", "review_text": "In this paper, the authors study the relationship between training GANs and primal-dual subgradient methods for convex optimization. Their technique can be applied on top of existing GANs and can address issues such as mode collapse. The authors also derive a GAN variant similar to WGAN which is called the Approximate WGAN. Experiments on synthetic datasets demonstrate that the proposed formulation can avoid mode collapse. This is a strong contribution In Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore. The authors should explain more possibly. There is a typo in Page 2 \u2013 For all these varaints, -variants. ", "rating": "7: Good paper, accept", "reply_text": "The authors would like to thank the reviewer for his/her invaluable comments . We have taken the reviewers ' comments into consideration when revising our paper . Moreover , our responses to the comments raised by the reviewer are as follows : 1 . Comment : In Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore . The authors should explain more possibly . Our reply : The different performance is in part due to the different network architecture and different training objective from DCGAN . Specifically , - We do not use BatchNorm . \u000f- We do not use LeakyReLU activation in the discriminator . \u000f- We do not use SoftPlus for the last layer of discriminator . -\u000f We use the approximate-WGAN variant as proposed in the paper , while DCGAN uses the vanilla GAN objective function . In this regard , a more suitable baseline approach to compare is probably the WGAN result , which has similar architecture and optimization objective . In order to achieve better inception score performance , we probably need more extensive hyper-parameter tuning . We have to acknowledge that the aim of this paper is not to achieve superior performance , but to provide a new perspective on understanding GAN , and provide a new training technique that can be applied on top of different GAN variants to alleviate the mode collapse issue . 2.Comment : There is a typo in Page 2 \u2013 For all these varaints , -variants . Our reply : Corrected accordingly . We appreciate that the reviewer points out this mistake ."}], "0": {"review_id": "BJNRFNlRW-0", "review_text": "This paper formulates GAN as a Lagrangian of a primal convex constrained optimization problem. They then suggest to modify the updates used in the standard GAN training to be similar to the primal-dual updates typically used by primal-dual subgradient methods. Technically, the paper is sound. It mostly leverages the existing literature on primal-dual subgradient methods to modify the GAN training procedure. I think this is a nice contribution that does yield to some interesting insights. However I do have some concerns about the way the paper is currently written and I find some claims misleading. Prior convergence proofs: I think the way the paper is currently written is misleading. The authors quote the paper from Ian Goodfellow: \u201cFor GANs, there is no theoretical prediction as to whether simultaneous gradient descent should converge or not.\u201d. However, the f-GAN paper gave a proof of convergence, see Theorem 2 here: https://arxiv.org/pdf/1606.00709.pdf. A recent NIPS paper by (Nagarajan and Kolter, 2017) also study the convergence properties of simultaneous gradient descent. Another problem is of course the assumptions required for the proof that typically don\u2019t hold in practice (see comment below). Convex-concave assumption: In practice the GAN objective is optimized over the parameters of the neural network rather than the generative distribution. This typically yields a non-convex non-concave optimization problem. This should be mentioned in the paper and I would like to see a discussion concerning the gap between the theory and the practical algorithm. Relation to existing regularization techniques: Combining Equations 11 and 13, the second terms acts as a regularizer that minimizes [\\lapha f_1(D(x_i))]^2. This looks rather similar to some of the recent regularization techniques such as Improved Training of Wasserstein GANs, https://arxiv.org/pdf/1704.00028.pdf Stabilizing Training of Generative Adversarial Networks through Regularization, https://arxiv.org/pdf/1705.09367.pdf Can the authors comment on this? I think this would also shed some light as to why this approach alleviates the problem of mode collapse. Curse of dimensionality: Nonparametric density estimators such as the KDE technique used in this paper suffer from the well-known curse of dimensionality. For the synthetic data, the empirical evidence seem to indicate that the technique proposed by the authors does work but I\u2019m not sure the empirical evidence provided for the MNIST and CIFAR-10 datasets is sufficient to judge whether or not the method does help with mode collapse. The inception score fails to capture this property. Could the authors explore other quantitative measure? Have you considered trying your approach on the augmented version of the MNIST dataset used in Metz et al. (2016) and Che et al. (2016)? Experiments Typo: Should say \u201cThe data distribution is p_d(x) = 1{x=1}\u201d. ", "rating": "7: Good paper, accept", "reply_text": "The authors would like to thank the reviewer for his/her invaluable comments . We have taken the reviewers ' comments into consideration when revising our paper . Moreover , our responses to the comments raised by the reviewer are as follows : 1 . Comment : Prior convergence proofs : I think the way the paper is currently written is misleading . The authors quote the paper from Ian Goodfellow : \u201c For GANs , there is no theoretical prediction as to whether simultaneous gradient descent should converge or not. \u201d . However , the f-GAN paper gave a proof of convergence , see Theorem 2 here : https : //arxiv.org/pdf/1606.00709.pdf . A recent NIPS paper by ( Nagarajan and Kolter , 2017 ) also study the convergence properties of simultaneous gradient descent . Another problem is of course the assumptions required for the proof that typically don \u2019 t hold in practice ( see comment below ) . Our reply : We would like to thank the reviewer for pointing out the latest NIPS paper by Nagarajan and Kolter . We have included this in our literature review . We have also made revisions in the paper to avoid the misleading arguments ( see below ) . \\textit { However , the analysis of the convergence properties on the training approaches is challenging , as noted by Ian Goodfellow in ( Goodfellow , 2016 ) , `` For GANs , there is no theoretical prediction as to whether simultaneous gradient descent should converge or not . Settling this theoretical question , and developing algorithms guaranteed to converge , remain important open research problems . `` . There have been some recent studies on the convergence behaviours of GAN training ( Nowozin et al. , 2016 ; Li et al. , 2017 ; Heusel et al. , 2017 ; Nagarajan \\ & Kolter , 2017 ; Mescheder et al. , 2017 ) . The simultaneous gradient descent method was proved to converge assuming the objective function is convex-concave in the network parameters ( Nowozin et al. , 2016 ) . The local stability property is established in ( Heusel et al. , 2017 ; Nagarajan \\ & Kolter , 2017 ) . } Ian Goodfellow raised the convergence issue in the tutorial paper , because the study of convergence for the simultaneous gradient descent method was limited at that time . They also gave a counterexample in the tutorial paper , which shows that the simultaneous gradient descent can not converge for some objective functions with some step size . This is one of the motivations of the paper to study the simultaneous gradient descent method . We agree with the reviewer that this convergence issue has been studied at least in the following works : [ a ] `` f-GAN : Training Generative Neural Samplers using Variational Divergence Minimization '' by Nowozin and Cseke . [ b ] `` Gradient descent GAN optimization is locally stable '' by Nagarajan and Kolter . [ c ] `` GANs trained by a two time-scale update rule converge to a Nash equibrium '' by Heusel et al ( as noted in our introduction part ) . These papers together with our paper study the convergence issue from different perspectives . In particular , these three papers study the convergence behavior of updates over the network parameters . Reference [ a ] assumes the objective function is convex-concave in the network parameters , while reference [ b ] and [ c ] study the local stability property . Our paper studies the convergence behavior in the function space , which was the started point in the first GAN paper by Ian Goodfellow . We incorporate the two conventional training methods into one framework , namely simultaneous gradient descent update and discrminator-driven update ( discriminator is fully optimized before the gradient update of the generator ) . The theoretical convergence proof leverage some well-established results from the primal-dual subgradient methods for convex optimization . Although the actual optimization is over the network parameters , which is non-convex non-cave in general , our formulation provides important insights in improving the training methods , as detailed in the next point ."}, "1": {"review_id": "BJNRFNlRW-1", "review_text": "This paper proposed a framework to connect the solving of GAN with finding the saddle point of a minimax problem. As a result, the primal-dual subgradient methods can be directly introduced to calculate the saddle point. Additionally, this idea not only fill the relatviely lacking of theoretical results for GAN or WGAN, but also provide a new perspective to modify the GAN-type models. But this saddle point model reformulation in section 2 is quite standard, with limited theoretical analysis in Theorem 1. As follows, the resulting algorithm 1 is also standard primal-dual method for a saddle point problem. Most important I think, the advantage of considering GAN-type model as a saddle point model is that first--order methods can be designed to solve it. But the numerical experiments part seems to be a bit weak, because the MINST or CIFAR-10 dataset is not large enough to test the extensibility for large-scale cases. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "The authors would like to thank the reviewer for his/her invaluable comments . We have taken the reviewers ' comments into consideration when revising our paper . Moreover , our responses to the comments raised by the reviewer are as follows : 1 . Comment : But this saddle point model reformulation in section 2 is quite standard , with limited theoretical analysis in Theorem 1 . As follows , the resulting algorithm 1 is also standard primal-dual method for a saddle point problem . Most important I think , the advantage of considering GAN-type model as a saddle point model is that first order methods can be designed to solve it . Our reply : We agree with the reviewer that the Lagrangian formulation in Section 2 is standard . The main contribution of the paper is to provide a new perspective of understanding GAN . In particular , we relate the minimax game to finding the saddle points of the Lagrangian function for a convex optimization problem , where the generated distribution plays the role of the dual variable . This inherent connection was not established in previous works and it shows that the standard training of GANs actually falls in the framework of primal-dual subgradient methods for convex optimization . As the the reviewer mentions , one important result is to show that the training actually converge to the optimal point if a proper step size is chosen , and both the discriminator output and the generated distribution are correctly updated according to the primal-dual rule . Besides this , it provides the following important insights : ( a ) . It inspires an improved training technique to avoid mode collapse . In practical training , the generated distribution is not updated according to the desired direction . As Claim 1 points out , when the generated probability at some data point $ \\bx $ is zero and the discriminator output $ D ( \\bx ) $ is locally constant , mode collapse occurs . Using the traditional training , we can hardly avoid such mode collapse , even under the recently proposed WGAN . The Lagrangian formulation tells that the optimal update direction of $ p_g ( \\cdot ) $ is given by Eq . ( 11 ) .When mode collapse occurs , Eq . ( 13 ) gives a large gradient to push the generator to produce some samples at $ \\bx $ . The synthetic example shows that it indeed increases the data sample diversity and effectively avoids mode collapse . ( b ) .It naturally incorporates different variants of GANs into the convex optimization framework including the family of f-GAN ( Nowozin et al. , 2016 ) and an approximate variant of WGAN . For all these GAN variants , an improved training objective can be easily derived . ( c ) .The simultaneous primal-dual update is known to have a very slow convergence rate . There have been proposed methods to accelerate the convergence rates in the following papers : Angelia Nedic and Asuman Ozdaglar , `` Subgradient methods for saddle-point problems '' . Yunmei Chen , Guanghui Lan and Yuyuan Ouyang , `` Optimal primal-dual methods for a class of saddle point problems '' . By building the relation of GAN training and the primal-dual approach for convex optimizations , these improved methods can be directly applied . In future research , we will evaluate the acceleration of the training process using these approaches . ( d ) .For some GAN variants , where the objective function is not strictly convex , the convergence may be slow or the converging point is not unique . By casting the minimax game in the Lagrangian framework , we could easily tweak the objective function such that the objective function is strictly convex and the optimal solution is not affected , then the convergence performance can be improved . Examples can be found in `` Nonlinear Programming '' by D. Bertsekas ."}, "2": {"review_id": "BJNRFNlRW-2", "review_text": "In this paper, the authors study the relationship between training GANs and primal-dual subgradient methods for convex optimization. Their technique can be applied on top of existing GANs and can address issues such as mode collapse. The authors also derive a GAN variant similar to WGAN which is called the Approximate WGAN. Experiments on synthetic datasets demonstrate that the proposed formulation can avoid mode collapse. This is a strong contribution In Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore. The authors should explain more possibly. There is a typo in Page 2 \u2013 For all these varaints, -variants. ", "rating": "7: Good paper, accept", "reply_text": "The authors would like to thank the reviewer for his/her invaluable comments . We have taken the reviewers ' comments into consideration when revising our paper . Moreover , our responses to the comments raised by the reviewer are as follows : 1 . Comment : In Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore . The authors should explain more possibly . Our reply : The different performance is in part due to the different network architecture and different training objective from DCGAN . Specifically , - We do not use BatchNorm . \u000f- We do not use LeakyReLU activation in the discriminator . \u000f- We do not use SoftPlus for the last layer of discriminator . -\u000f We use the approximate-WGAN variant as proposed in the paper , while DCGAN uses the vanilla GAN objective function . In this regard , a more suitable baseline approach to compare is probably the WGAN result , which has similar architecture and optimization objective . In order to achieve better inception score performance , we probably need more extensive hyper-parameter tuning . We have to acknowledge that the aim of this paper is not to achieve superior performance , but to provide a new perspective on understanding GAN , and provide a new training technique that can be applied on top of different GAN variants to alleviate the mode collapse issue . 2.Comment : There is a typo in Page 2 \u2013 For all these varaints , -variants . Our reply : Corrected accordingly . We appreciate that the reviewer points out this mistake ."}}