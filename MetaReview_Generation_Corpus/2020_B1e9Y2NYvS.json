{"year": "2020", "forum": "B1e9Y2NYvS", "title": "On Robustness of Neural Ordinary Differential Equations", "decision": "Accept (Spotlight)", "meta_review": "This paper studies the robustness of NeuralODE, as well as propose a new variant. The results suggest that the neuralODE can be used as a building block to build robust deep networks. The reviewers agree that this is a good paper for ICLR, and based on their recommendation I suggest to accept this paper.", "reviews": [{"review_id": "B1e9Y2NYvS-0", "review_text": "This paper studied the robustness of neural ODE-based networks (ODENets) to various types of perturbations on the input images. The authors observed that ODENets are more robust to both Gaussian perturbation and adversarial attacks, which the authors explained as non-intersecting of the integral curves for different initial points. Moreover, the authors proposed the time-invariant steady neural ODE (TisODE) to enhance the robustness of ODENets. I list my concerns below: 1. To show the ODENet is more robust, the authors should bound the gap between the integral curves for different inputs. Non-intersecting of the integral curves does not guarantee the robustness. 2. The ODENet architecture showed in Figure~1 can be regarded as an augmented CNN. I think the identity map gives a good trade-off between robustness and generalization. To enhance robustness, one might design an expansion map, but this, in general, hurt the accuracy of the model. 3. Why do not perform experiments on the CIFAR10 benchmark dataset? I think it is very important to add these results. 4. To verify the robustness of ODENets and CNNs, the authors should also perform adversarial training besides training on the original and noisy images with Gaussian perturbation. 5. Theorem~1 is wrong. I suggest the authors check the conditions to make it valid. We can construct an ODE of the form (1) that blows up in finite-time, e.g., dx/dt = x^2. 6. Most importantly, the authors should match the number of function evaluations of neural ODE with the depth of the CNN, in addition to matching the number of parameters. Please perform such a comparison in rebuttal. (THIS IS THE MOST IMPORTANT RESULT I WANT TO SEE IN REBUTTAL) 7. The authors did not compare with existing work that tries to improve the robustness of neural nets from a differential equation viewpoint. The related works should be elaborated. ====================== I would like to point out a few related papers that lift the dimension of ODE to a transport equation and improve the neural nets' robustness from the lens of the transport equation's theory. Also, the author should compare their results with some reported results in 1, 3, 4. 1. Bao Wang, Binjie Yuan, Zuoqiang Shi, Stanley J. Osher. ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies, arXiv:1811.10745, NeurIPS, 2019 2. Bao Wang, Xiyang Luo, Zhen Li, Wei Zhu, Zuoqiang Shi, Stanley J. Osher. Deep Neural Nets with Interpolating Function as Output Activation, NeurIPS, 2018 3. Bao Wang, Alex T. Lin, Zuoqiang Shi, Wei Zhu, Penghang Yin, Andrea L. Bertozzi, Stanley J. Osher. Adversarial Defense via Data Dependent Activation Function and Total Variation Minimization, arXiv:1809.08516, 2018 4. B. Wang, S. Osher. Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning, arXiv:1907.06800 ======================= Please address the previously mentioned concerns in rebuttal.", "rating": "6: Weak Accept", "reply_text": "Thanks a lot for the review and the helpful advice . We have added experimental results into the revision ( Appendix section 7.4 ) . We group the questions into four topics and answer them as follows : [ # # # First # # # ] For Q.2 , on the architecture of ODENets , we follow the standard design in [ 5 ] , which originally proposes the neural ODE method ."}, {"review_id": "B1e9Y2NYvS-1", "review_text": "The paper is concerned with neural ODE-based networks, specifically their robustness. While ODEs are a classical subject in mathematics with many applications in the sciences and beyond, neural ODEs are a recently proposed family of models for nonlinear mappings in the context of machine learning systems. There they show promise and are an active field of research. The paper makes two primary contributions. (1) It studies the robustness of neural ODE, and (2) proposes a more robust variant of neural ODEs. For (1), robustness to both perturbed and adversarial inputs is considered, and theoretical interpretations for the robustness of neural ODEs are given. These theoretical insights form the basis of the contribution in (2). The paper is well and clearly written, supplies most of the necessary theoretical background and offers useful contributions. I recommend the paper for publication. In terms of improving the paper further, I\u2019d suggest a slightly less casual treatment of the conditions under which the mathematical statements quoted hold. E.g. Theorem 1 is part of the classical Picard-Lindelof theorem and requires similar conditions (or at least the conditions of the necessary and sufficient, but less well known, Okamura's theorem, see [1]). A differentiable counterexample if these conditions don\u2019t hold can be found e.g. in Wikipedia [2]. I see that the authors have responded to that point on the openreview website. I\u2019d suggest however that for a result going back to the early 19th century citing a paper from 2019 (which itself cites a textbook on computational anatomy) seems suboptimal from an educational point of view. Another possible improvement of the paper could be to expand the adversarial attacks considered to the gradient-free optimization techniques employed in e.g. [3] which have sharply reduced other defenses against adversarial attacks. [1] https://www.ams.org/journals/proc/1967-018-04/S0002-9939-1967-0212240-6/S0002-9939-1967-0212240-6.pdf [2] https://en.wikipedia.org/wiki/Picard\u2013Lindel\u00f6f_theorem#Example_of_non-uniqueness [3] https://arxiv.org/abs/1802.05666", "rating": "8: Accept", "reply_text": "Thanks a lot for the constructive review . 1.We agree that the mathematical statements ( Theorem 1 ) should be rigorous . We have modified the statement in the revised version . In particular , we add the conditions of global Lipschitz continuity in states and the continuity in time . In our original submission , we have cited a textbook [ 4 ] on ODEs to reference the theorem . In the revision , we also cite another well-known textbook [ 5 ] . Thanks.2.Following the suggestion , we experimented with the gradient-free attack method ( SPSA ) in [ 3 ] . We evaluated the performance of models trained with Gaussian perturbations on the MNIST , by choosing n=50 , T=10 , and epsilon = 0.4 for the SPSA attack . The results show that the neural ODE-based models are more robust than CNN models in front of such attack method . Besides , the proposed TisODE outperforms the vanilla neural ODE . ( CNN : avg 33.4 % ; ODENe : avg 43.1 % ; TisODE : avg 45.3 % ) We also evaluated these models with a black-box attack method ( ZOO [ 6 ] with epsilon=0.4 ) , which is also one type of gradient-free attacks . We still observed that neural ODE-based models are more robust than CNN models and the proposed TisODE enhances the robustness of the vanilla neural ODE . ( CNN : avg 15.6 % ; ODENet : avg 51.0 % ; TisODE : avg 52.5 % ) [ 4 ] Laurent Younes . Shapes and diffeomorphisms , volume 171 . Springer , 2010 . [ 5 ] Coddington , Earl A. , and Norman Levinson . Theory of ordinary differential equations . Tata McGraw-Hill Education , 1955 . [ 6 ] Pin-Yu Chen , Huan Zhang , Yash Sharma , Jinfeng Yi , and Cho-Jui Hsieh . Zoo : Zeroth order optimization based black-box attacks to deep neural networks without training substitute models . In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security , pp . 15\u201326.ACM,2017 ."}, {"review_id": "B1e9Y2NYvS-2", "review_text": "This paper investigates the robustness of Neural Ordinary differential equations (ODEs) against corrupted and adversarial examples. The crux of the analysis is based on the separation property of ODE integral curves. The insights from empirical robustness evaluation show that controlling the difference between neighboring integral curves is able to improve neural ODE's robustness. In general, neural ODE is a hot research topic in recent years, and a paper advancing knowledge in this area about understanding its various characteristics is certainly welcome. The paper is well motivated and clearly written. One aspect that confuses me a little originally is the different effects of getting ridding of the dependency on the time t and adding the steady state regularization. It would be nice to elucidate which part makes more contributions? Furthermore, to compare the robustness of the new approach with CNN, the input data consists of original images and their Gaussian-noise based perturbed samples. Since the paper already involves the evaluation using adversarial examples, it will make the paper much more stronger to show that when training both the new approach and the CNN with adversarial training, the proposed regularization can still lead to better robustness. ", "rating": "6: Weak Accept", "reply_text": "Thanks a lot for the review and the suggestions . 1.With regard to the time-invariant property and the steady-state constraint , the steady-state constraint enhances the robustness of vanilla neural ODEs based on the time-invariant property . To wit , consider a certain integral curve z1 and its neighboring curve \\tilde_z1 , and assume \\tilde_z1 ( 0 ) =z1 ( T \u2019 ) . Without the time-invariant property , Eqn . ( 3 ) does not hold . Consequently , the steady-state constraint can not control the difference between the two states at time t1 only with the information of curve z1 . Thus , these two parts can not be separated . As such , we feel that it is not necessary to perform an ablation study on these two aspects . 2.Thanks for the advice of evaluating models with adversarial training . We implemented the adversarial training of the models on the MNIST dataset , and the adversarial examples for training are generated in real-time via the FGSM method ( epsilon=0.3 ) during each epoch [ 1 ] . The results of the adversarially trained models are shown in the following table : \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 Acc ( % ) | \\sigma=100 | FGSM 0.3 | FGSM 0.5 | PGD 0.3 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 CNN | 58.0 | 98.4 | 21.1 | 5.3 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 ODENet | 84.2 | 99.1 | 36.0 | 12.3 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 TisODE | 87.9 | 99.1 | 66.5 | 78.9 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 -- - We can see that the neural ODE-based models are consistently more robust than CNN models . Besides , the proposed TisODE also outperforms the vanilla neural ODE . We have added these experiments to the revision ( Appendix setion 7.4 ) . [ 1 ] Aleksander Madry , Aleksandar Makelov , Ludwig Schmidt , Dimitris Tsipras , and Adrian Vladu . Towards deep learning models resistant to adversarial attacks . arXiv preprint arXiv:1706.06083 , 2017 ."}], "0": {"review_id": "B1e9Y2NYvS-0", "review_text": "This paper studied the robustness of neural ODE-based networks (ODENets) to various types of perturbations on the input images. The authors observed that ODENets are more robust to both Gaussian perturbation and adversarial attacks, which the authors explained as non-intersecting of the integral curves for different initial points. Moreover, the authors proposed the time-invariant steady neural ODE (TisODE) to enhance the robustness of ODENets. I list my concerns below: 1. To show the ODENet is more robust, the authors should bound the gap between the integral curves for different inputs. Non-intersecting of the integral curves does not guarantee the robustness. 2. The ODENet architecture showed in Figure~1 can be regarded as an augmented CNN. I think the identity map gives a good trade-off between robustness and generalization. To enhance robustness, one might design an expansion map, but this, in general, hurt the accuracy of the model. 3. Why do not perform experiments on the CIFAR10 benchmark dataset? I think it is very important to add these results. 4. To verify the robustness of ODENets and CNNs, the authors should also perform adversarial training besides training on the original and noisy images with Gaussian perturbation. 5. Theorem~1 is wrong. I suggest the authors check the conditions to make it valid. We can construct an ODE of the form (1) that blows up in finite-time, e.g., dx/dt = x^2. 6. Most importantly, the authors should match the number of function evaluations of neural ODE with the depth of the CNN, in addition to matching the number of parameters. Please perform such a comparison in rebuttal. (THIS IS THE MOST IMPORTANT RESULT I WANT TO SEE IN REBUTTAL) 7. The authors did not compare with existing work that tries to improve the robustness of neural nets from a differential equation viewpoint. The related works should be elaborated. ====================== I would like to point out a few related papers that lift the dimension of ODE to a transport equation and improve the neural nets' robustness from the lens of the transport equation's theory. Also, the author should compare their results with some reported results in 1, 3, 4. 1. Bao Wang, Binjie Yuan, Zuoqiang Shi, Stanley J. Osher. ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies, arXiv:1811.10745, NeurIPS, 2019 2. Bao Wang, Xiyang Luo, Zhen Li, Wei Zhu, Zuoqiang Shi, Stanley J. Osher. Deep Neural Nets with Interpolating Function as Output Activation, NeurIPS, 2018 3. Bao Wang, Alex T. Lin, Zuoqiang Shi, Wei Zhu, Penghang Yin, Andrea L. Bertozzi, Stanley J. Osher. Adversarial Defense via Data Dependent Activation Function and Total Variation Minimization, arXiv:1809.08516, 2018 4. B. Wang, S. Osher. Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning, arXiv:1907.06800 ======================= Please address the previously mentioned concerns in rebuttal.", "rating": "6: Weak Accept", "reply_text": "Thanks a lot for the review and the helpful advice . We have added experimental results into the revision ( Appendix section 7.4 ) . We group the questions into four topics and answer them as follows : [ # # # First # # # ] For Q.2 , on the architecture of ODENets , we follow the standard design in [ 5 ] , which originally proposes the neural ODE method ."}, "1": {"review_id": "B1e9Y2NYvS-1", "review_text": "The paper is concerned with neural ODE-based networks, specifically their robustness. While ODEs are a classical subject in mathematics with many applications in the sciences and beyond, neural ODEs are a recently proposed family of models for nonlinear mappings in the context of machine learning systems. There they show promise and are an active field of research. The paper makes two primary contributions. (1) It studies the robustness of neural ODE, and (2) proposes a more robust variant of neural ODEs. For (1), robustness to both perturbed and adversarial inputs is considered, and theoretical interpretations for the robustness of neural ODEs are given. These theoretical insights form the basis of the contribution in (2). The paper is well and clearly written, supplies most of the necessary theoretical background and offers useful contributions. I recommend the paper for publication. In terms of improving the paper further, I\u2019d suggest a slightly less casual treatment of the conditions under which the mathematical statements quoted hold. E.g. Theorem 1 is part of the classical Picard-Lindelof theorem and requires similar conditions (or at least the conditions of the necessary and sufficient, but less well known, Okamura's theorem, see [1]). A differentiable counterexample if these conditions don\u2019t hold can be found e.g. in Wikipedia [2]. I see that the authors have responded to that point on the openreview website. I\u2019d suggest however that for a result going back to the early 19th century citing a paper from 2019 (which itself cites a textbook on computational anatomy) seems suboptimal from an educational point of view. Another possible improvement of the paper could be to expand the adversarial attacks considered to the gradient-free optimization techniques employed in e.g. [3] which have sharply reduced other defenses against adversarial attacks. [1] https://www.ams.org/journals/proc/1967-018-04/S0002-9939-1967-0212240-6/S0002-9939-1967-0212240-6.pdf [2] https://en.wikipedia.org/wiki/Picard\u2013Lindel\u00f6f_theorem#Example_of_non-uniqueness [3] https://arxiv.org/abs/1802.05666", "rating": "8: Accept", "reply_text": "Thanks a lot for the constructive review . 1.We agree that the mathematical statements ( Theorem 1 ) should be rigorous . We have modified the statement in the revised version . In particular , we add the conditions of global Lipschitz continuity in states and the continuity in time . In our original submission , we have cited a textbook [ 4 ] on ODEs to reference the theorem . In the revision , we also cite another well-known textbook [ 5 ] . Thanks.2.Following the suggestion , we experimented with the gradient-free attack method ( SPSA ) in [ 3 ] . We evaluated the performance of models trained with Gaussian perturbations on the MNIST , by choosing n=50 , T=10 , and epsilon = 0.4 for the SPSA attack . The results show that the neural ODE-based models are more robust than CNN models in front of such attack method . Besides , the proposed TisODE outperforms the vanilla neural ODE . ( CNN : avg 33.4 % ; ODENe : avg 43.1 % ; TisODE : avg 45.3 % ) We also evaluated these models with a black-box attack method ( ZOO [ 6 ] with epsilon=0.4 ) , which is also one type of gradient-free attacks . We still observed that neural ODE-based models are more robust than CNN models and the proposed TisODE enhances the robustness of the vanilla neural ODE . ( CNN : avg 15.6 % ; ODENet : avg 51.0 % ; TisODE : avg 52.5 % ) [ 4 ] Laurent Younes . Shapes and diffeomorphisms , volume 171 . Springer , 2010 . [ 5 ] Coddington , Earl A. , and Norman Levinson . Theory of ordinary differential equations . Tata McGraw-Hill Education , 1955 . [ 6 ] Pin-Yu Chen , Huan Zhang , Yash Sharma , Jinfeng Yi , and Cho-Jui Hsieh . Zoo : Zeroth order optimization based black-box attacks to deep neural networks without training substitute models . In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security , pp . 15\u201326.ACM,2017 ."}, "2": {"review_id": "B1e9Y2NYvS-2", "review_text": "This paper investigates the robustness of Neural Ordinary differential equations (ODEs) against corrupted and adversarial examples. The crux of the analysis is based on the separation property of ODE integral curves. The insights from empirical robustness evaluation show that controlling the difference between neighboring integral curves is able to improve neural ODE's robustness. In general, neural ODE is a hot research topic in recent years, and a paper advancing knowledge in this area about understanding its various characteristics is certainly welcome. The paper is well motivated and clearly written. One aspect that confuses me a little originally is the different effects of getting ridding of the dependency on the time t and adding the steady state regularization. It would be nice to elucidate which part makes more contributions? Furthermore, to compare the robustness of the new approach with CNN, the input data consists of original images and their Gaussian-noise based perturbed samples. Since the paper already involves the evaluation using adversarial examples, it will make the paper much more stronger to show that when training both the new approach and the CNN with adversarial training, the proposed regularization can still lead to better robustness. ", "rating": "6: Weak Accept", "reply_text": "Thanks a lot for the review and the suggestions . 1.With regard to the time-invariant property and the steady-state constraint , the steady-state constraint enhances the robustness of vanilla neural ODEs based on the time-invariant property . To wit , consider a certain integral curve z1 and its neighboring curve \\tilde_z1 , and assume \\tilde_z1 ( 0 ) =z1 ( T \u2019 ) . Without the time-invariant property , Eqn . ( 3 ) does not hold . Consequently , the steady-state constraint can not control the difference between the two states at time t1 only with the information of curve z1 . Thus , these two parts can not be separated . As such , we feel that it is not necessary to perform an ablation study on these two aspects . 2.Thanks for the advice of evaluating models with adversarial training . We implemented the adversarial training of the models on the MNIST dataset , and the adversarial examples for training are generated in real-time via the FGSM method ( epsilon=0.3 ) during each epoch [ 1 ] . The results of the adversarially trained models are shown in the following table : \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 Acc ( % ) | \\sigma=100 | FGSM 0.3 | FGSM 0.5 | PGD 0.3 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 CNN | 58.0 | 98.4 | 21.1 | 5.3 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 ODENet | 84.2 | 99.1 | 36.0 | 12.3 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 TisODE | 87.9 | 99.1 | 66.5 | 78.9 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 -- - We can see that the neural ODE-based models are consistently more robust than CNN models . Besides , the proposed TisODE also outperforms the vanilla neural ODE . We have added these experiments to the revision ( Appendix setion 7.4 ) . [ 1 ] Aleksander Madry , Aleksandar Makelov , Ludwig Schmidt , Dimitris Tsipras , and Adrian Vladu . Towards deep learning models resistant to adversarial attacks . arXiv preprint arXiv:1706.06083 , 2017 ."}}