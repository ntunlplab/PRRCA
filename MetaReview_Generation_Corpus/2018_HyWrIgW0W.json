{"year": "2018", "forum": "HyWrIgW0W", "title": "Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks", "decision": "Accept (Poster)", "meta_review": "Dear authors,\n\nBased on the comments and your rebuttal, I am glad to accept your paper at ICLR.", "reviews": [{"review_id": "HyWrIgW0W-0", "review_text": "The paper takes a closer look at the analysis of SGD as variational inference, first proposed by Duvenaud et al. 2016 and Mandt et al. 2016. In particular, the authors point out that in general, SGD behaves quite differently from Langevin diffusion due to the multivariate nature of the Gaussian noise. As the authors show based on the Fokker-Planck equation of the underlying stochastic process, there exists a conservative current (a gradient of an underlying potential) and a non-conservative current (which might induce stationary persistent currents at long times). The non-conservative part leads to the fact that the dynamics of SGD may show oscillations, and these oscillations may even prevent the algorithm from converging to the 'right' local optima. The theoretical analysis is carried-out very nicely, and the theory is supported by experiments on two-dimensional toy examples, and Fourier-spectra of the iterates of SGD. This is a nice paper which I would like to see accepted. In particular I appreciate that the authors stress the importance of 'non-equilibrium physics' for understanding the SGD process. Also, the presentation is quite clear and the paper well written. There are a few minor points which I would like to ask the authors to address: 1. Why cite Kingma and Welling as a source for variational inference in section 3.1? VI is a much older field, and Kingma and Welling proposed a very special form of VI, namely amortized VI with inference networks. A better citation would be Jordan et al 1999. 2. I'm not sure how much to trust the Fourier-spectra. In particular, perhaps the deviations from Brownian motion could also be due to the discrete nature of SGD (i.e. that the continuous-time formalism is only an approximation of a discrete process). Could you elaborate on this? 3. Could you give the reader more details on how the uncertainty estimates on the Fourier transformations were obtained? Thanks.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your comments . Please read below for our clarifications . > > Why cite Kingma and Welling for variational inference , e.g. , cite Jordan \u2018 99 , VI is a much older field Good point : we will also include older citations . > > Not sure how much to trust Fourier spectra , deviations from Brownian motion can also be due to discretization Note that the plot in Fig.3a is the discrete Fourier transform of ( x_ { k+1 } - x_k ) _k . The trajectory is of length 10^5 epochs and sampled at each epoch ; we are thus sampling at a very high frequency , well above the Nyquist rate . Low frequency modes in the continuous-time dynamics will not be affected by such a discretization , high frequency modes might , see the right part of Fig.3a.The FFT , which is expected to be flat for Brownian motion , is distinctly non-flat in our experiments . This result is also predicted by other experiments in Sec.4.1 and Fig.3b , and our theoretical results . So the Fourier spectra are just one more confirmation of the claim . > > Give more details on how the uncertainty estimates on the Fourier transformations were obtained This is described in the caption of Fig.3.The FFT is computed , independently , for the one-dimensional trajectory of each weight . The standard deviation across all the weights is depicted as the \u201c error band \u201d . The eigenmodes of the weight vector are also the eigenmodes of the trajectory of each weight ; it is indeed surprising that different weights have very similar amplitude ."}, {"review_id": "HyWrIgW0W-1", "review_text": "The authors discuss the regularized objective function minimized by standard SGD in the context of neural nets, and provide a variational inference perspective using the Fokker-Planck equation. They note that the objective can be very different from the desired loss function if the SGD noise matrix is low rank, as evidenced in their experiments. Overall the paper is written quite well, and the authors do a good job of explaining their thesis. However I was unable to identify any real novelty in the theory: the Fokker-Planck equation has been widely used in analysis of stochastic noise in MCMC samplers in recent years, and this paper mostly rephrases those results. Also the fact that SGD theory only works for isotropic noise is well known, and that there is divergence from the true loss function in case of low rank noise is obvious. Thus I found most of section 3 to be a reformulation of known results, including Theorem 5 and its proof. Same goes for section 5; the symmetric- anti symmetric split is a common technique used in the stochastic MCMC literature over the last few years, and I did not find any new insight into those manipulations of the Fokker-Planck equation from this paper. Thus I think that although this paper is written well, the theory is mostly recycled and the empirical results in Section 4 are known; thus it is below acceptance threshold due to lack of novelty.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your comments . Please see our clarifications below . > > Unable to identify any novelty in the theory , reformulation of known results , empirical results are known We are glad to help : 1 . While it is widely * believed * that SGD acts as an \u201c implicit regularizer \u201d , to the best of our knowledge we are first to * prove * that it performs variational inference : SGD minimizes an average potential along with an entropic regularization term . 2.While someone may have noticed that mini-batch noise in deep networks is highly non-isotropic , nobody had connected this to convergence properties of SGD for deep nets . 3.The fact that anisotropy in deep networks causes the potential Phi to be different than the function upon which SGD evaluates its gradients was * not known * , nor proven , before . 4.The fact that the most likely trajectories of SGD for deep nets are limit cycles was * not known * , nor proven . We have scouted the literature diligently , but of course it is possible that we may have missed work where any of the above empirical and theoretical results may have been described . We will gladly examine specific references if provided . > > Fokker-Planck equation has been widely used before We surely do not claim to be the first to use the Fokker-Planck equation ; it is a standard tool in the analysis of stochastic processes . > > Fact that SGD theory only works for isotropic noise is well-known , that there is divergence from the true loss is obvious The issue is not that there is \u201c divergence from the true loss \u201d , but precisely of what * nature * it is . To the best of our knowledge , we are the first to point out -- and prove -- that SGD for deep nets has limit cycles as its most likely trajectories . This is surely not obvious : in fact , most of the literature focuses on which * critical points * SGD converges to . We show that , with anisotropic noise , it converges to none . Quite non-obvious , frankly . > > Common technique in stochastic MCMC , did not find any new insight into manipulations MCMC theory constructs grad f and D given a log-likelihood Phi that one would like to draw samples from . This paper is about the reverse direction : given a grad f and a D , what is the Phi ? This is a novel question and pertinent to understanding the efficacy of SGD for deep networks ; it is not under the purview of the MCMC literature . We * decompose * grad f into symmetric and anti-symmetric terms and develop assumptions and theory that enables us to do so . To emphasize , MCMC methods start with a given Phi , whereas we find the Phi . The two are completely opposite directions , even if some formulae might look familiar from the MCMC literature ."}, {"review_id": "HyWrIgW0W-2", "review_text": "This paper develop theory to study the impact of stochastic gradient noise for SGD, especially for deep neural network models. It is shown that when the gradient noise is isotropic normal, SGD converges to a distribution tilted by the original objective function. However, when the gradient noise is non isotropic normal, which is shown common in many models especially in deep neural network models, the behavior of SGD is intriguing, which will not converge to the tilted distribution by the original objective function, sometimes more interestingly, will converge to limit cycles around some critical points of the original objective function. The paper also provides some hints on why using SGD can get good generalization ability than gradient descend. I think the finding of this paper is interesting, and the technical details are correct. I still have the following comments. First, Assumption 4 seems a bit too abstract. It is not easy to see what the assumption means. It would be better if an example is given, which is verified to satisfy the assumption. Another comment is related to the overall content of this paper. Thought the paper point out that SGD will have the out-of-equilibrium behavior when the gradient noise is non isotropic normal, it remains to show how far away this stationary distribution is from the original distribution defined by the objective function.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your comments . Please see our clarifications below . > > Assumption 4 seems a bit too abstract , can you give an example Example 13 illustrates the effects of the assumption ; we will point the readers to it in Sec.3.Another example is in three dimensions , where the assumption is akin to Helmholtz decomposition of a vector field into divergence-free and curl-free components . We allow the force j ( x ) to be non-trivial , j ( x ) neq 0 corresponds to broken detailed balance while j ( x ) = 0 corresponds to detailed balance . This assumption is motivated by the second-law of thermodynamics as discussed in Appendix B . > > How far away is the stationary distribution from the original one The relation between the two is the offset described in Thm . 17.This difference scales linearly with learning rate/batch-size ; which can be large in practice because deep networks are trained with small batch-sizes and/or large learning rates . The divergence of the matrix Q is also explicitly computable , see ( A13 ) and Remarks 19-20 . Doing so is however computationally challenging for large networks , and a subject of our future investigation ."}], "0": {"review_id": "HyWrIgW0W-0", "review_text": "The paper takes a closer look at the analysis of SGD as variational inference, first proposed by Duvenaud et al. 2016 and Mandt et al. 2016. In particular, the authors point out that in general, SGD behaves quite differently from Langevin diffusion due to the multivariate nature of the Gaussian noise. As the authors show based on the Fokker-Planck equation of the underlying stochastic process, there exists a conservative current (a gradient of an underlying potential) and a non-conservative current (which might induce stationary persistent currents at long times). The non-conservative part leads to the fact that the dynamics of SGD may show oscillations, and these oscillations may even prevent the algorithm from converging to the 'right' local optima. The theoretical analysis is carried-out very nicely, and the theory is supported by experiments on two-dimensional toy examples, and Fourier-spectra of the iterates of SGD. This is a nice paper which I would like to see accepted. In particular I appreciate that the authors stress the importance of 'non-equilibrium physics' for understanding the SGD process. Also, the presentation is quite clear and the paper well written. There are a few minor points which I would like to ask the authors to address: 1. Why cite Kingma and Welling as a source for variational inference in section 3.1? VI is a much older field, and Kingma and Welling proposed a very special form of VI, namely amortized VI with inference networks. A better citation would be Jordan et al 1999. 2. I'm not sure how much to trust the Fourier-spectra. In particular, perhaps the deviations from Brownian motion could also be due to the discrete nature of SGD (i.e. that the continuous-time formalism is only an approximation of a discrete process). Could you elaborate on this? 3. Could you give the reader more details on how the uncertainty estimates on the Fourier transformations were obtained? Thanks.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your comments . Please read below for our clarifications . > > Why cite Kingma and Welling for variational inference , e.g. , cite Jordan \u2018 99 , VI is a much older field Good point : we will also include older citations . > > Not sure how much to trust Fourier spectra , deviations from Brownian motion can also be due to discretization Note that the plot in Fig.3a is the discrete Fourier transform of ( x_ { k+1 } - x_k ) _k . The trajectory is of length 10^5 epochs and sampled at each epoch ; we are thus sampling at a very high frequency , well above the Nyquist rate . Low frequency modes in the continuous-time dynamics will not be affected by such a discretization , high frequency modes might , see the right part of Fig.3a.The FFT , which is expected to be flat for Brownian motion , is distinctly non-flat in our experiments . This result is also predicted by other experiments in Sec.4.1 and Fig.3b , and our theoretical results . So the Fourier spectra are just one more confirmation of the claim . > > Give more details on how the uncertainty estimates on the Fourier transformations were obtained This is described in the caption of Fig.3.The FFT is computed , independently , for the one-dimensional trajectory of each weight . The standard deviation across all the weights is depicted as the \u201c error band \u201d . The eigenmodes of the weight vector are also the eigenmodes of the trajectory of each weight ; it is indeed surprising that different weights have very similar amplitude ."}, "1": {"review_id": "HyWrIgW0W-1", "review_text": "The authors discuss the regularized objective function minimized by standard SGD in the context of neural nets, and provide a variational inference perspective using the Fokker-Planck equation. They note that the objective can be very different from the desired loss function if the SGD noise matrix is low rank, as evidenced in their experiments. Overall the paper is written quite well, and the authors do a good job of explaining their thesis. However I was unable to identify any real novelty in the theory: the Fokker-Planck equation has been widely used in analysis of stochastic noise in MCMC samplers in recent years, and this paper mostly rephrases those results. Also the fact that SGD theory only works for isotropic noise is well known, and that there is divergence from the true loss function in case of low rank noise is obvious. Thus I found most of section 3 to be a reformulation of known results, including Theorem 5 and its proof. Same goes for section 5; the symmetric- anti symmetric split is a common technique used in the stochastic MCMC literature over the last few years, and I did not find any new insight into those manipulations of the Fokker-Planck equation from this paper. Thus I think that although this paper is written well, the theory is mostly recycled and the empirical results in Section 4 are known; thus it is below acceptance threshold due to lack of novelty.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your comments . Please see our clarifications below . > > Unable to identify any novelty in the theory , reformulation of known results , empirical results are known We are glad to help : 1 . While it is widely * believed * that SGD acts as an \u201c implicit regularizer \u201d , to the best of our knowledge we are first to * prove * that it performs variational inference : SGD minimizes an average potential along with an entropic regularization term . 2.While someone may have noticed that mini-batch noise in deep networks is highly non-isotropic , nobody had connected this to convergence properties of SGD for deep nets . 3.The fact that anisotropy in deep networks causes the potential Phi to be different than the function upon which SGD evaluates its gradients was * not known * , nor proven , before . 4.The fact that the most likely trajectories of SGD for deep nets are limit cycles was * not known * , nor proven . We have scouted the literature diligently , but of course it is possible that we may have missed work where any of the above empirical and theoretical results may have been described . We will gladly examine specific references if provided . > > Fokker-Planck equation has been widely used before We surely do not claim to be the first to use the Fokker-Planck equation ; it is a standard tool in the analysis of stochastic processes . > > Fact that SGD theory only works for isotropic noise is well-known , that there is divergence from the true loss is obvious The issue is not that there is \u201c divergence from the true loss \u201d , but precisely of what * nature * it is . To the best of our knowledge , we are the first to point out -- and prove -- that SGD for deep nets has limit cycles as its most likely trajectories . This is surely not obvious : in fact , most of the literature focuses on which * critical points * SGD converges to . We show that , with anisotropic noise , it converges to none . Quite non-obvious , frankly . > > Common technique in stochastic MCMC , did not find any new insight into manipulations MCMC theory constructs grad f and D given a log-likelihood Phi that one would like to draw samples from . This paper is about the reverse direction : given a grad f and a D , what is the Phi ? This is a novel question and pertinent to understanding the efficacy of SGD for deep networks ; it is not under the purview of the MCMC literature . We * decompose * grad f into symmetric and anti-symmetric terms and develop assumptions and theory that enables us to do so . To emphasize , MCMC methods start with a given Phi , whereas we find the Phi . The two are completely opposite directions , even if some formulae might look familiar from the MCMC literature ."}, "2": {"review_id": "HyWrIgW0W-2", "review_text": "This paper develop theory to study the impact of stochastic gradient noise for SGD, especially for deep neural network models. It is shown that when the gradient noise is isotropic normal, SGD converges to a distribution tilted by the original objective function. However, when the gradient noise is non isotropic normal, which is shown common in many models especially in deep neural network models, the behavior of SGD is intriguing, which will not converge to the tilted distribution by the original objective function, sometimes more interestingly, will converge to limit cycles around some critical points of the original objective function. The paper also provides some hints on why using SGD can get good generalization ability than gradient descend. I think the finding of this paper is interesting, and the technical details are correct. I still have the following comments. First, Assumption 4 seems a bit too abstract. It is not easy to see what the assumption means. It would be better if an example is given, which is verified to satisfy the assumption. Another comment is related to the overall content of this paper. Thought the paper point out that SGD will have the out-of-equilibrium behavior when the gradient noise is non isotropic normal, it remains to show how far away this stationary distribution is from the original distribution defined by the objective function.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your comments . Please see our clarifications below . > > Assumption 4 seems a bit too abstract , can you give an example Example 13 illustrates the effects of the assumption ; we will point the readers to it in Sec.3.Another example is in three dimensions , where the assumption is akin to Helmholtz decomposition of a vector field into divergence-free and curl-free components . We allow the force j ( x ) to be non-trivial , j ( x ) neq 0 corresponds to broken detailed balance while j ( x ) = 0 corresponds to detailed balance . This assumption is motivated by the second-law of thermodynamics as discussed in Appendix B . > > How far away is the stationary distribution from the original one The relation between the two is the offset described in Thm . 17.This difference scales linearly with learning rate/batch-size ; which can be large in practice because deep networks are trained with small batch-sizes and/or large learning rates . The divergence of the matrix Q is also explicitly computable , see ( A13 ) and Remarks 19-20 . Doing so is however computationally challenging for large networks , and a subject of our future investigation ."}}