{"year": "2017", "forum": "B16Jem9xe", "title": "Learning in Implicit Generative Models", "decision": "Invite to Workshop Track", "meta_review": "This paper provides a unifying review of various forms of generative model. The paper offers some neat perspectives that could encourage links between areas of machine learning and statistics. However, there aren't specific new proposals, and so there is no empirical evaluation either. The PCs thus believe this contribution is more appropriate for the Workshop Track.", "reviews": [{"review_id": "B16Jem9xe-0", "review_text": "I just noticed I submitted my review as a pre-review question - sorry about this. Here it is again, with a few more thoughts added... The authors present a great and - as far as I can tell - accurate and honest overview of the emerging theory about GANs from a likelihood ratio estimation/divergence minimisation perspective. It is well written and a good read, and one I would recommend to people who would like to get involved in GANs. My main problem with this submission is that it is hard as a reviewer to pin down what precisely the novelty is - beyond perhaps articulating these views better than other papers have done in the past. A sentence from the paper \"But it has left us unsatisfied since we have not gained the insight needed to choose between them.\u201d summarises my feeling about this paper: this is a nice 'unifying review\u2019 type paper that - for me - lacks a novel insight. In summary, my assessment is mixed: I think this is a great paper, I enjoyed reading it. I was left a bit disappointed by the lack of novel insight, or a singular key new idea which you often expect in conference presentations, and this is why I\u2019m not highly confident about this as a conference submission (and hence my low score) I am open to be convinced either way. Detailed comments: I think the authors should probably discuss the connection of Eq. (13) to KLIEP: Kullback-Leibler Importance Estimation by Shugiyama and colleagues. I don\u2019t quite see how the part with equation (13) and (14) fit into the flow of the paper. By this point the authors have established the view that GANs are about estimating likelihood ratios - and then using these likelihood ratios to improve the generator. These paragraphs read like: we also tried to derive another particular formulation for doing this but we failed to do it in a practical way. There is a typo in spelling Csiszar divergence Equation (15) is known (to me) as Least Squares Importance Estimation by Kanamori et al (2009). A variant of least-squares likelihood estimation uses the kernel trick, and finds a function from an RKHS that best represents the likelihood ratio between the two distributions in a least squares sense. I think it would be interesting to think about how this function is related to the witness function commonly used in MMD and what the properties of this function are compared to the witness function - perhaps showing the two things for simple distributions. I have stumbled upon the work of Sugiyama and collaborators on direct density ratio estimation before, and I found that work very insightful. Generally, while some of this work is cited in this paper, I felt that the authors could do more to highlight the great work of this group, who have made highly significant contributions to density ratio estimation, albeit with a different goal in mind. On likelihood ratio estimation: some methods approximate the likelihood ratio directly (such as least-squares importance estimation), some can be thought of more as approximating the log of this quantity (logistic regression, denoising autoencoders). An unbiased estimate of the ratio will provide a biased estimate of the logarithm and vice versa. To me it feels like estimating the log of the ratio directly is more useful, and in more generality estimating the convex function of the ratio which is used to define the f-divergence seems like a good approach. Could the authors comment on this? I think the hypothesis testing angle is oversold in the paper. I\u2019m not sure what additional insight is gained by mixing in some hypothesis testing terminology. Other than using quantities that appear in hypothesis testing as tests statistics, his work does not really talk about hypothesis testing, nor does it use any tools from the hypothesis testing literature. In this sense, this paper is in contrast with Sutherland et al (in review for ICLR) who do borrow concepts from two-sample testing to optimise hyperparameters of the divergence used.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your positive comments . Our aim is to provide clarity , share a different perspective , and to highlight all the related work addressing the same problem that is not otherwise cited and used . We believe there is both novelty in our presentation , and is a good fit and of relevance to ICLR . Please see the more detailed response we provide in general rebuttal to the paper , since this was highlighted by other reviewers as well . The work of Sugiyama et al. , is especially important and one that has been a great inspiration to us . We aim to cite it as much as possible , citing the book as our key source ( rather than individual papers and specific names such as KLIEP and LSIE ) . It is important to keep in mind that estimating the density ratio is only part of the problem when learning in GANs and implicit generative models , and why our discussion has taken the form it has . \u201c I think it would be interesting to think about how this function is related to the witness function commonly used in MMD and what the properties of this function are compared to the witness function - perhaps showing the two things for simple distributions. \u201d Sriperumbudur et al showed in the paper \u201c On the empirical estimation of integral probability metrics \u201d 2012 that f-divergences and integral probability metrics ( MMD , Wasserstein ) intersect only at the total variation distance . See also Arthur Gretton \u2019 s slides at the NIPS adversarial training workshop : http : //www.gatsby.ucl.ac.uk/~gretton/papers/testing_workshop.pdf For likelihood ratio estimation , we do not want to estimate the convex function of the ratio directly , since this will not allow us to exploit the duality properties of the divergence . The importance of hypothesis testing is perhaps a philosophical one . Recognising the role of hypothesis testing ( to test if two distributions are equal ) helps to ask the question of why we should compute the density ratio or density difference , which is otherwise vague and unclear . Once this is recognised , the path to using the myriad of methods for comparing two hypotheses such as two-sample tests , density ratios , density-differences , and classical tests such as Wald and likelihood ratio test , are all valid tools for learning implicit models . This view has been recognised by other authors as well , e.g. , Lopez-Paz and Oquab ( 2016 ) ."}, {"review_id": "B16Jem9xe-1", "review_text": "The paper provides an exposition of multiple ways of learning in implicit generative models, of which generative adversarial networks are an example. The paper is very clear, the exposition is insightful, and the presented material is clearly important. It is hard to assess \"novelty\" of this work, as the individual pieces are not novel, and yet the exposition of all of them in the same space with clear outline of the connections between them is novel. I believe this work is significant - it provides a bridge for language and methods used in multiple parts of statistics and machine learning. This has the potential to accelerate progress. I recommend publishing this paper at ICLR, even though it is not the \"typical\" paper that get published at this conference (in that it doesn't offer empirical validation, nor makes a particular claim about relative merits of different methods).", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your positive and encouraging feedback !"}, {"review_id": "B16Jem9xe-2", "review_text": "Thank you for an interesting read. Given the huge interest in generative modelling nowadays, this paper is very timely and does provide very clear connections between methods that don't use maximum likelihood for training. It made a very useful observation that the generative and the discriminative loss do **not** need to be coupled with each other. I think this paper in summary provides some very useful insights to the practitioners on how to select the objective function to train the implicit generative model. The only reason that I decided to hold back my strong acceptance recommendation is that I don't understand the acceptance criteria of ICLR. First this paper has the style very similar to the Sugiyama et al. papers that are cited (e.g. presenting in different perspectives that were all covered in those papers but in a different context), making me unsure about how to evaluate the novelty. Second this paper has no experiment nor mathematical theorem, and I'm not exactly sure what kinds of contributions the ICLR committee is looking for.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your positive comments . Our aim is to provide clarity , share a different perspective , and to highlight all the related work addressing the same problem that is not otherwise cited and used . We believe there is both novelty in our presentation , and is a good fit and of relevance to ICLR . Please see the more detailed response we provide in general rebuttal to the paper , since this was highlighted by other reviewers as well . The work of Sugiyama et al.is especially important and one that has been a great inspiration to us . It is important to keep in mind that estimating the density ratio is only part of the problem when learning in GANs and implicit generative models . Showing how this can be used to form both the ratio and generative losses is an important aspect of this paper ."}], "0": {"review_id": "B16Jem9xe-0", "review_text": "I just noticed I submitted my review as a pre-review question - sorry about this. Here it is again, with a few more thoughts added... The authors present a great and - as far as I can tell - accurate and honest overview of the emerging theory about GANs from a likelihood ratio estimation/divergence minimisation perspective. It is well written and a good read, and one I would recommend to people who would like to get involved in GANs. My main problem with this submission is that it is hard as a reviewer to pin down what precisely the novelty is - beyond perhaps articulating these views better than other papers have done in the past. A sentence from the paper \"But it has left us unsatisfied since we have not gained the insight needed to choose between them.\u201d summarises my feeling about this paper: this is a nice 'unifying review\u2019 type paper that - for me - lacks a novel insight. In summary, my assessment is mixed: I think this is a great paper, I enjoyed reading it. I was left a bit disappointed by the lack of novel insight, or a singular key new idea which you often expect in conference presentations, and this is why I\u2019m not highly confident about this as a conference submission (and hence my low score) I am open to be convinced either way. Detailed comments: I think the authors should probably discuss the connection of Eq. (13) to KLIEP: Kullback-Leibler Importance Estimation by Shugiyama and colleagues. I don\u2019t quite see how the part with equation (13) and (14) fit into the flow of the paper. By this point the authors have established the view that GANs are about estimating likelihood ratios - and then using these likelihood ratios to improve the generator. These paragraphs read like: we also tried to derive another particular formulation for doing this but we failed to do it in a practical way. There is a typo in spelling Csiszar divergence Equation (15) is known (to me) as Least Squares Importance Estimation by Kanamori et al (2009). A variant of least-squares likelihood estimation uses the kernel trick, and finds a function from an RKHS that best represents the likelihood ratio between the two distributions in a least squares sense. I think it would be interesting to think about how this function is related to the witness function commonly used in MMD and what the properties of this function are compared to the witness function - perhaps showing the two things for simple distributions. I have stumbled upon the work of Sugiyama and collaborators on direct density ratio estimation before, and I found that work very insightful. Generally, while some of this work is cited in this paper, I felt that the authors could do more to highlight the great work of this group, who have made highly significant contributions to density ratio estimation, albeit with a different goal in mind. On likelihood ratio estimation: some methods approximate the likelihood ratio directly (such as least-squares importance estimation), some can be thought of more as approximating the log of this quantity (logistic regression, denoising autoencoders). An unbiased estimate of the ratio will provide a biased estimate of the logarithm and vice versa. To me it feels like estimating the log of the ratio directly is more useful, and in more generality estimating the convex function of the ratio which is used to define the f-divergence seems like a good approach. Could the authors comment on this? I think the hypothesis testing angle is oversold in the paper. I\u2019m not sure what additional insight is gained by mixing in some hypothesis testing terminology. Other than using quantities that appear in hypothesis testing as tests statistics, his work does not really talk about hypothesis testing, nor does it use any tools from the hypothesis testing literature. In this sense, this paper is in contrast with Sutherland et al (in review for ICLR) who do borrow concepts from two-sample testing to optimise hyperparameters of the divergence used.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your positive comments . Our aim is to provide clarity , share a different perspective , and to highlight all the related work addressing the same problem that is not otherwise cited and used . We believe there is both novelty in our presentation , and is a good fit and of relevance to ICLR . Please see the more detailed response we provide in general rebuttal to the paper , since this was highlighted by other reviewers as well . The work of Sugiyama et al. , is especially important and one that has been a great inspiration to us . We aim to cite it as much as possible , citing the book as our key source ( rather than individual papers and specific names such as KLIEP and LSIE ) . It is important to keep in mind that estimating the density ratio is only part of the problem when learning in GANs and implicit generative models , and why our discussion has taken the form it has . \u201c I think it would be interesting to think about how this function is related to the witness function commonly used in MMD and what the properties of this function are compared to the witness function - perhaps showing the two things for simple distributions. \u201d Sriperumbudur et al showed in the paper \u201c On the empirical estimation of integral probability metrics \u201d 2012 that f-divergences and integral probability metrics ( MMD , Wasserstein ) intersect only at the total variation distance . See also Arthur Gretton \u2019 s slides at the NIPS adversarial training workshop : http : //www.gatsby.ucl.ac.uk/~gretton/papers/testing_workshop.pdf For likelihood ratio estimation , we do not want to estimate the convex function of the ratio directly , since this will not allow us to exploit the duality properties of the divergence . The importance of hypothesis testing is perhaps a philosophical one . Recognising the role of hypothesis testing ( to test if two distributions are equal ) helps to ask the question of why we should compute the density ratio or density difference , which is otherwise vague and unclear . Once this is recognised , the path to using the myriad of methods for comparing two hypotheses such as two-sample tests , density ratios , density-differences , and classical tests such as Wald and likelihood ratio test , are all valid tools for learning implicit models . This view has been recognised by other authors as well , e.g. , Lopez-Paz and Oquab ( 2016 ) ."}, "1": {"review_id": "B16Jem9xe-1", "review_text": "The paper provides an exposition of multiple ways of learning in implicit generative models, of which generative adversarial networks are an example. The paper is very clear, the exposition is insightful, and the presented material is clearly important. It is hard to assess \"novelty\" of this work, as the individual pieces are not novel, and yet the exposition of all of them in the same space with clear outline of the connections between them is novel. I believe this work is significant - it provides a bridge for language and methods used in multiple parts of statistics and machine learning. This has the potential to accelerate progress. I recommend publishing this paper at ICLR, even though it is not the \"typical\" paper that get published at this conference (in that it doesn't offer empirical validation, nor makes a particular claim about relative merits of different methods).", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your positive and encouraging feedback !"}, "2": {"review_id": "B16Jem9xe-2", "review_text": "Thank you for an interesting read. Given the huge interest in generative modelling nowadays, this paper is very timely and does provide very clear connections between methods that don't use maximum likelihood for training. It made a very useful observation that the generative and the discriminative loss do **not** need to be coupled with each other. I think this paper in summary provides some very useful insights to the practitioners on how to select the objective function to train the implicit generative model. The only reason that I decided to hold back my strong acceptance recommendation is that I don't understand the acceptance criteria of ICLR. First this paper has the style very similar to the Sugiyama et al. papers that are cited (e.g. presenting in different perspectives that were all covered in those papers but in a different context), making me unsure about how to evaluate the novelty. Second this paper has no experiment nor mathematical theorem, and I'm not exactly sure what kinds of contributions the ICLR committee is looking for.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your positive comments . Our aim is to provide clarity , share a different perspective , and to highlight all the related work addressing the same problem that is not otherwise cited and used . We believe there is both novelty in our presentation , and is a good fit and of relevance to ICLR . Please see the more detailed response we provide in general rebuttal to the paper , since this was highlighted by other reviewers as well . The work of Sugiyama et al.is especially important and one that has been a great inspiration to us . It is important to keep in mind that estimating the density ratio is only part of the problem when learning in GANs and implicit generative models . Showing how this can be used to form both the ratio and generative losses is an important aspect of this paper ."}}