{"year": "2019", "forum": "SkxXg2C5FX", "title": "Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors", "decision": "Accept (Poster)", "meta_review": "This paper presents new generalized methods for representing sentences and measuring their similarities based on word vectors. More specifically, the paper presents Fuzzy Bag-of-Words (FBoW), a generalized approach to composing sentence embeddings by combining word embeddings with different degrees of membership, which generalize more commonly used average or max-pooled vector representations. In addition, the paper presents DynaMax, an unsupervised and non-parametric similarity measure that can dynamically extract and max-pool features from a sentence pair. \n\nPros:\nThe proposed methods are natural generalization of exiting average and max-pooled vectors. The proposed methods are elegant, simple, easy to implement, and demonstrate strong performance on STS tasks.\n\nCons:\nThe paper is solid, no significant con other than that the proposed methods are not groundbreaking innovations per say. \n\nVerdict:\nThe simplicity is what makes the proposed methods elegant. The empirical results are strong. The paper is worthy of acceptance.", "reviews": [{"review_id": "SkxXg2C5FX-0", "review_text": "This is one of the best papers I reviewed so far this year (ICLR, NIPS, ICML, AISTATS), in terms of both the writing and technical novelty. Writing: the author provided sufficient context and did comprehensive literature survey, which made the paper easily accessible to a larger audience. And the flow of this paper was very smooth and I personally enjoyed reading it. Novelty: I wouldn't say this paper proposed a groundbreaking innovation, however, compared to many other submissions that are more obscure rather than inspiring to the readers, this paper presented a very natural extension to something practitioners were already very familiar with: taking an average of word vectors for a sentence and measure by cosine similarity. Both max pooling and Jaccard distance are not something new, but the author did a great job presenting the idea and proved it's effectiveness through extensive experiments. (disclaimer: I didn't follow the sentence embedding literature recently, and I would count on other reviewers to fact check the claimed novelty of this paper by the authors) Simplicity: besides the novelty mentioned above, what I enjoyed more about this paper is it's simplicity. Not just because it's easy to understand, but also it's easy to be reproduced by practitioners. Quibbles: the authors didn't provide error bar / confidence interval to the results presented in experiment session. I'd like to know whether the difference between baselines and proposed methods were significant or not. Miscellaneous: I have to say the authors provided a very eye-catching name to this paper as well, and the content of the paper didn't disappoint me neither. Well done :) ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer , We would like to thank you for such a positive assessment of our work . We were especially thrilled the Reviewer found our paper to be among the best they reviewed this year . Regarding the significance analysis , unfortunately , the SentEval toolkit [ 1 ] we 're using does not support this functionality . Moreover most works known to us , including some of the most prominent works published at ICLR , do not conduct significance analysis for STS benchmarks ( [ 2 ] , [ 3 ] , [ 4 ] , [ 5 ] ) . Admittedly , some other works apply the Fisher 's z test , which we believe is not appropriate in this setting . More appropriately , some apply the William 's t test [ 6 ] or Steiger 's z test [ 7 ] for correlated correlations . To the best of our knowledge , these tests require that data comes from a normal distribution , which is not case for STS . Although we have done a similar analysis using Steiger 's z , we have to refrain from reporting ( potentially ) statistically invalid results and are looking to obtain further evidence that these tests can in fact be applied here . We are also looking into alternative ( non-parametric ) methods and will let the Reviewer know when our analysis is complete . [ 1 ] Alexis Conneau and Douwe Kiela ( 2018 ) . SentEval : An Evaluation Toolkit for Universal Sentence Representations . http : //arxiv.org/abs/1803.05449 [ 2 ] John Wieting , Mohit Bansal , Kevin Gimpel and Karen Livescu . ICLR 2016 . [ 3 ] Sanjeev Arora , Yingyu Liang and Tengyu Ma . A Simple but Tough-to-Beat Baseline for Sentence Embeddings . ICLR 2017 . [ 4 ] Jiaqi Mu and Pramod Viswanath . All-but-the-Top : Simple and Effective Postprocessing for Word Representations . ICLR 2018 . [ 5 ] Sandeep Subramanian Adam Trischler , Yoshua Bengio and Christopher J Pal . Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning . ICLR 2018 . [ 6 ] Williams , E. J . ( 1959 ) .The comparison of regression variables . Journal of the Royal Statistical Society , Series B , 21 , 396-399 . [ 7 ] Steiger , J. H. ( 1980 ) . Tests for comparing elements of a correlation matrix . Psychological Bulletin , 87 ( 2 ) , 245-251 . Again , thank you very much and please do not hesitate to contact for with any further queries/clarifications . Best wishes , ICLR 2019 Conference Paper1058 Authors"}, {"review_id": "SkxXg2C5FX-1", "review_text": "This submission presents a simple model for sentence representation based on max-pooling of word vectors. The model is motivated by fuzzy-set theory, providing both a funded pooling scheme and a similarity score between documents. The proposed approach is evaluated on sentence similarity tasks (STS) and achieves very strong performance, comparable to state-of-the-art, computationally demanding methods. Pros: + The problem tackled by this paper is interesting and well motivated. Fast, efficient and non-parametric sentence similarity has tons of important applications (search, indexing, corpus mining). + The proposed solution is elegant and very simple to implement. + When compared to standard sentence representation models, the proposed approach has very good performance, while being very efficient. It only requires a matrix vector product and a dimension-wise max. + The paper is very well written and flows nicely. + Empirical results show significant differences between different word vectors. The simplicity of this approach makes it a good test bed for research on word vectors. Cons: - Nothing much, really. - Eq. (3) is awkward, as it is a sequence of equalities, which has to be avoided. Moreover, if U is the identity, I don't think that the reader really need this Eq... I have several questions and remarks that, if answered would make the quality of the presentation better: * In infersent, the authors reported the performance of a randomly-initialized and max-pooled bi-lstm with fasttext vectors as the input lookup. This can be seen as an extreme case of the presented formalism, where the linear operator U is replaced by a complicated non linear function that is implemented by the random LSTM. Drawing that link, and maybe including this baseline in the results would be good. * Related to this previous question, several choices for U are discussed in the paper. However, only two are compared in the experiments. It would be interesting to have an experimental comparison of: - taking U = W - taking U = I - taking U as the principal directions of W - taking U as a random matrix, and comparing performance for different output dimensions. Overall, this paper is a very strong baseline paper. The presented model is elegant and efficient. I rate it as an 8 and await other reviews and the author's response.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer , We would like to thank you for such a kind assessment of our work and so many positive comments . The Reviewer has asked some fascinating questions and we are jumping straight to them . * On InferSent Absolutely , in principle the linear operator U can be replaced by any non-linear function , such as a ( deep ) neural network . But because InferSent is a Bi-LSTM , the membership vector for a word w_t would depend on the membership vectors of words w_ ( t-1 ) and w_ ( t+1 ) . By contrast , in our fuzzy * bag * -of-words model all the memberships vectors are computed separately and independently of each other . We genuinely feel these `` fuzzy sequences '' have a great research potential but have to leave them to future work . Randomly initialised InferSent uses GloVe vectors for its embeddings layer , followed by a randomly initialised Bi-LSTM . However , we see from [ 1 ] ( Table 4 ) that its performance on STS14 is only 0.39 , when averaged GloVe vectors already attain 0.54 , while avg . fastText and word2vec both score above 0.63 . In other words , random InferSent is very unlikely to be a good baseline for unsupervised semantic textual similarity . Of course , the trained InferSent is a very strong model and we already compare against it in Table 1 . [ 1 ] Alexis Conneau , Douwe Kiela , Holger Schwenk , Loic Barrault , and Antoine Bordes . Supervised Learning of Universal Sentence Representations from Natural Language Inference Data . EMNLP 2017 , pp . 670\u2013680 * Different choices for U ( the universe matrix ) We were very excited the Reviewer suggested the random matrix . We did n't mention this in the paper but in fact we tried all of the following universes : -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - GloVe| STS12 STS13 STS14 STS15 STS16 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Avg . 52.1 49.6 54.6 56.1 51.4 W ( top 100K ) 58.6 48.2 62.8 69.3 69.4 DynaMax 58.2 53.9 65.1 70.9 71.1 Random 300x300 57.0 49.5 64.9 70.4 70.8 Identity 300 57.7 51.4 65.9 70.7 70.4 SVD basis 58.1 51.8 66.1 70.7 71.0 SVD ( top 200 vec ) 57.0 49.5 64.6 69.4 69.9 For GloVe vectors the methods are basically the same but DynaMax gets good improvement over the max-pooled word vectors ( identity matrix ) with most other word vectors ( Figures 1 & 2 ) . We chose to focus on DynaMax and max-pooled vectors exclusively because only these 2 universes are non-parametric and deterministic . We ourselves feel that DynaMax is probably the strongest and safest choice overall for any kind of word vectors . However , it is sensible to start with just max-pooled word vectors because they avoid matrix multiplication altogether . We will be linking our code repository after the anonymity period and hope the community discovers universes that we have n't so far . Also , we agree that sequence of equalities in Eq.3 is awkward , this is purely to emphasise the origins of max-pooled word vectors . We will consider how to alter this equation while keeping this message . Again , we would like to thank the Reviewer for such a positive assessment and great questions . Please do not hesitate to contact us for any further queries/clarifications . Best wishes , ICLR 2019 Conference Paper1058 Authors"}, {"review_id": "SkxXg2C5FX-2", "review_text": "Strengths: - Good coverage of related work - Clear presentation of the methods - Evaluation using established SemEval datasets Weaknesses: 1. It is not entirely clear what is the connection between fuzzy bag of words and DynaMax. In principle DynaMax can work with other methods too. This point should be elaborated a bit more. 2. It is claimed that the this paper shows that max-pooled word vectors are a special case of fuzzy bag of words. This is not correct. The paper shows how to \"convert\" one to the other. 3. It is also claimed that point 2 above implies that max-pooled vectors should be compared with the fuzzy Jaccard index instead of cosine similarity. There is no proof or substantial justification to support this. 4. Some relevant work that is missing: - De Boom, C., Van Canneyt, S., Demeester, T., Dhoedt, B.: Representation learning for very short texts using weighted word embedding aggregation. Pattern Recognition Letters 80, 150\u2013156 (2016) - Kenter, T., De Rijke, M.: Short text similarity with word embeddings. In: International on Conference on Information and Knowledge Management. pp. 1411\u20131420. ACM (2015)", "rating": "5: Marginally below acceptance threshold", "reply_text": "Dear Reviewer , We would like to thank you for your assessment of our paper and positive comments regarding presentation and coverage of related work . The Reviewer additionally had some concerns which we would like to address . 1.As we explain in Section 2.2.3 , the universe of DynaMax contains only the word embeddings from the 2 sentences being compared . If x1 , x2 , ... xk and y1 , y2 , ... , yl are word embeddings for sentences 1 and 2 respectively , then U = [ x1 ; x2 ; ... xk ; y1 ; y2 ; ... ; yl ] . This construction is also shown in Algorithm 1 ( Lines 5-7 ) . We are not quite sure what the Reviewer meant by `` In principle DynaMax can work with other methods too '' . The DynaMax-Jaccard ( DMJ ) similarity has 3 components . The `` dynamic '' universe U ( Section 2.2.3 ) , the max-pooling operation ( Eq.2 ) , and finally the fuzzy Jaccard index ( Section 2.2.1 ) . All 3 components are reflected and implemented in Algorithm 1 . Below we show the change in performance when max-pooling is replaced by average and when fuzzy Jaccard is replaced by cosine similarity . GloVe STS12 STS13 STS14 STS15 STS16 DynaMax Jaccard 58.2 53.9 65.1 70.9 71.1 DynaMax Cosine 58.2 53.6 63.2 67.2 67.4 DynaAvg . Jaccard 43.5 37.0 38.8 45.3 39.4 DynaAvg . Cosine 40.0 39.1 38.3 39.7 31.2 We see that all 3 components in DynaMax-Jaccard are very important . When we replaced Jaccard with cosine , the performance dropped . When we replaced max with average it fell even further . Unfortunately , there is only a limited number of combinations we could report in the paper . 2. > `` ... max-pooled word vectors are a special case of fuzzy bag of words . This is not correct . '' Please allow us to elaborate why max-pooled vectors are in fact a special case of fuzzy BoW : We deliberately left the matrix U unspecified in the definition of FBoW ( Section 2.2 , Eq.1 & 2 ) .When U=W , then U represents `` concrete '' words . We said this was the most intuitive ( but not the only ) choice . In some cases , we no longer have concrete words but instead the words are `` abstract '' . We acknowledge this in Section 2.2.2 . In case of max-pooled vectors , U is the identity matrix I . However , we can always assign text labels to the rows of I , for example 'dim1 ' , 'dim2 ' , ... , 'dim300 ' . These `` words '' represent abstract concepts learned by a neural network in its representations . In fact , there has been some work to figure out what these dimensions could contain ( e.g . [ 1 ] ) More generally , for any vector we can always generate a text label for that vector , and take that as a word . The fuzzy BoW is then fuzzy with respect to these abstract words ( concepts ) . We will clarify this in the updated manuscript . [ 1 ] Yulia Tsvetkov , Manaal Faruqui , and Chris Dyer . Correlation-based Intrinsic Evaluation of Word Vector Representations . Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP , pp . 111\u2013115 3 . `` ... max-pooled vectors should be compared with the fuzzy Jaccard index instead of cosine similarity . There is no proof or substantial justification to support this. `` We appreciate there is no proof but we respectfully disagree there is no substantial justification . As discussed above , max-pooled vectors are a special case of fuzzy BoW and so the fuzzy Jaccard index is fully justified for this representation . Empirically fuzzy Jaccard outperforms cosine similarity on most tasks ( Figure 1 ) . 4.Thanks for bringing these works to our attention . We 're happy to cite them where appropriate . Overall , we showed that word embeddings by themselves ( without any weights , tricks or supervision ) are still a formidable baseline for semantic textual similarity . We reported up to 20-point increase on standard benchmark datasets . We also tried to rekindle the interest in fuzzy set theory , which is quite underrepresented in the mainstream ML research . In addition to our replies , we hope the Reviewer can take these contributions into account and perhaps reconsider their score . Again , thank you very much for your assessment and please do not hesitate to contact us with any further queries . Best wishes , ICLR 2019 Conference Paper1058 Authors"}], "0": {"review_id": "SkxXg2C5FX-0", "review_text": "This is one of the best papers I reviewed so far this year (ICLR, NIPS, ICML, AISTATS), in terms of both the writing and technical novelty. Writing: the author provided sufficient context and did comprehensive literature survey, which made the paper easily accessible to a larger audience. And the flow of this paper was very smooth and I personally enjoyed reading it. Novelty: I wouldn't say this paper proposed a groundbreaking innovation, however, compared to many other submissions that are more obscure rather than inspiring to the readers, this paper presented a very natural extension to something practitioners were already very familiar with: taking an average of word vectors for a sentence and measure by cosine similarity. Both max pooling and Jaccard distance are not something new, but the author did a great job presenting the idea and proved it's effectiveness through extensive experiments. (disclaimer: I didn't follow the sentence embedding literature recently, and I would count on other reviewers to fact check the claimed novelty of this paper by the authors) Simplicity: besides the novelty mentioned above, what I enjoyed more about this paper is it's simplicity. Not just because it's easy to understand, but also it's easy to be reproduced by practitioners. Quibbles: the authors didn't provide error bar / confidence interval to the results presented in experiment session. I'd like to know whether the difference between baselines and proposed methods were significant or not. Miscellaneous: I have to say the authors provided a very eye-catching name to this paper as well, and the content of the paper didn't disappoint me neither. Well done :) ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer , We would like to thank you for such a positive assessment of our work . We were especially thrilled the Reviewer found our paper to be among the best they reviewed this year . Regarding the significance analysis , unfortunately , the SentEval toolkit [ 1 ] we 're using does not support this functionality . Moreover most works known to us , including some of the most prominent works published at ICLR , do not conduct significance analysis for STS benchmarks ( [ 2 ] , [ 3 ] , [ 4 ] , [ 5 ] ) . Admittedly , some other works apply the Fisher 's z test , which we believe is not appropriate in this setting . More appropriately , some apply the William 's t test [ 6 ] or Steiger 's z test [ 7 ] for correlated correlations . To the best of our knowledge , these tests require that data comes from a normal distribution , which is not case for STS . Although we have done a similar analysis using Steiger 's z , we have to refrain from reporting ( potentially ) statistically invalid results and are looking to obtain further evidence that these tests can in fact be applied here . We are also looking into alternative ( non-parametric ) methods and will let the Reviewer know when our analysis is complete . [ 1 ] Alexis Conneau and Douwe Kiela ( 2018 ) . SentEval : An Evaluation Toolkit for Universal Sentence Representations . http : //arxiv.org/abs/1803.05449 [ 2 ] John Wieting , Mohit Bansal , Kevin Gimpel and Karen Livescu . ICLR 2016 . [ 3 ] Sanjeev Arora , Yingyu Liang and Tengyu Ma . A Simple but Tough-to-Beat Baseline for Sentence Embeddings . ICLR 2017 . [ 4 ] Jiaqi Mu and Pramod Viswanath . All-but-the-Top : Simple and Effective Postprocessing for Word Representations . ICLR 2018 . [ 5 ] Sandeep Subramanian Adam Trischler , Yoshua Bengio and Christopher J Pal . Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning . ICLR 2018 . [ 6 ] Williams , E. J . ( 1959 ) .The comparison of regression variables . Journal of the Royal Statistical Society , Series B , 21 , 396-399 . [ 7 ] Steiger , J. H. ( 1980 ) . Tests for comparing elements of a correlation matrix . Psychological Bulletin , 87 ( 2 ) , 245-251 . Again , thank you very much and please do not hesitate to contact for with any further queries/clarifications . Best wishes , ICLR 2019 Conference Paper1058 Authors"}, "1": {"review_id": "SkxXg2C5FX-1", "review_text": "This submission presents a simple model for sentence representation based on max-pooling of word vectors. The model is motivated by fuzzy-set theory, providing both a funded pooling scheme and a similarity score between documents. The proposed approach is evaluated on sentence similarity tasks (STS) and achieves very strong performance, comparable to state-of-the-art, computationally demanding methods. Pros: + The problem tackled by this paper is interesting and well motivated. Fast, efficient and non-parametric sentence similarity has tons of important applications (search, indexing, corpus mining). + The proposed solution is elegant and very simple to implement. + When compared to standard sentence representation models, the proposed approach has very good performance, while being very efficient. It only requires a matrix vector product and a dimension-wise max. + The paper is very well written and flows nicely. + Empirical results show significant differences between different word vectors. The simplicity of this approach makes it a good test bed for research on word vectors. Cons: - Nothing much, really. - Eq. (3) is awkward, as it is a sequence of equalities, which has to be avoided. Moreover, if U is the identity, I don't think that the reader really need this Eq... I have several questions and remarks that, if answered would make the quality of the presentation better: * In infersent, the authors reported the performance of a randomly-initialized and max-pooled bi-lstm with fasttext vectors as the input lookup. This can be seen as an extreme case of the presented formalism, where the linear operator U is replaced by a complicated non linear function that is implemented by the random LSTM. Drawing that link, and maybe including this baseline in the results would be good. * Related to this previous question, several choices for U are discussed in the paper. However, only two are compared in the experiments. It would be interesting to have an experimental comparison of: - taking U = W - taking U = I - taking U as the principal directions of W - taking U as a random matrix, and comparing performance for different output dimensions. Overall, this paper is a very strong baseline paper. The presented model is elegant and efficient. I rate it as an 8 and await other reviews and the author's response.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer , We would like to thank you for such a kind assessment of our work and so many positive comments . The Reviewer has asked some fascinating questions and we are jumping straight to them . * On InferSent Absolutely , in principle the linear operator U can be replaced by any non-linear function , such as a ( deep ) neural network . But because InferSent is a Bi-LSTM , the membership vector for a word w_t would depend on the membership vectors of words w_ ( t-1 ) and w_ ( t+1 ) . By contrast , in our fuzzy * bag * -of-words model all the memberships vectors are computed separately and independently of each other . We genuinely feel these `` fuzzy sequences '' have a great research potential but have to leave them to future work . Randomly initialised InferSent uses GloVe vectors for its embeddings layer , followed by a randomly initialised Bi-LSTM . However , we see from [ 1 ] ( Table 4 ) that its performance on STS14 is only 0.39 , when averaged GloVe vectors already attain 0.54 , while avg . fastText and word2vec both score above 0.63 . In other words , random InferSent is very unlikely to be a good baseline for unsupervised semantic textual similarity . Of course , the trained InferSent is a very strong model and we already compare against it in Table 1 . [ 1 ] Alexis Conneau , Douwe Kiela , Holger Schwenk , Loic Barrault , and Antoine Bordes . Supervised Learning of Universal Sentence Representations from Natural Language Inference Data . EMNLP 2017 , pp . 670\u2013680 * Different choices for U ( the universe matrix ) We were very excited the Reviewer suggested the random matrix . We did n't mention this in the paper but in fact we tried all of the following universes : -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - GloVe| STS12 STS13 STS14 STS15 STS16 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Avg . 52.1 49.6 54.6 56.1 51.4 W ( top 100K ) 58.6 48.2 62.8 69.3 69.4 DynaMax 58.2 53.9 65.1 70.9 71.1 Random 300x300 57.0 49.5 64.9 70.4 70.8 Identity 300 57.7 51.4 65.9 70.7 70.4 SVD basis 58.1 51.8 66.1 70.7 71.0 SVD ( top 200 vec ) 57.0 49.5 64.6 69.4 69.9 For GloVe vectors the methods are basically the same but DynaMax gets good improvement over the max-pooled word vectors ( identity matrix ) with most other word vectors ( Figures 1 & 2 ) . We chose to focus on DynaMax and max-pooled vectors exclusively because only these 2 universes are non-parametric and deterministic . We ourselves feel that DynaMax is probably the strongest and safest choice overall for any kind of word vectors . However , it is sensible to start with just max-pooled word vectors because they avoid matrix multiplication altogether . We will be linking our code repository after the anonymity period and hope the community discovers universes that we have n't so far . Also , we agree that sequence of equalities in Eq.3 is awkward , this is purely to emphasise the origins of max-pooled word vectors . We will consider how to alter this equation while keeping this message . Again , we would like to thank the Reviewer for such a positive assessment and great questions . Please do not hesitate to contact us for any further queries/clarifications . Best wishes , ICLR 2019 Conference Paper1058 Authors"}, "2": {"review_id": "SkxXg2C5FX-2", "review_text": "Strengths: - Good coverage of related work - Clear presentation of the methods - Evaluation using established SemEval datasets Weaknesses: 1. It is not entirely clear what is the connection between fuzzy bag of words and DynaMax. In principle DynaMax can work with other methods too. This point should be elaborated a bit more. 2. It is claimed that the this paper shows that max-pooled word vectors are a special case of fuzzy bag of words. This is not correct. The paper shows how to \"convert\" one to the other. 3. It is also claimed that point 2 above implies that max-pooled vectors should be compared with the fuzzy Jaccard index instead of cosine similarity. There is no proof or substantial justification to support this. 4. Some relevant work that is missing: - De Boom, C., Van Canneyt, S., Demeester, T., Dhoedt, B.: Representation learning for very short texts using weighted word embedding aggregation. Pattern Recognition Letters 80, 150\u2013156 (2016) - Kenter, T., De Rijke, M.: Short text similarity with word embeddings. In: International on Conference on Information and Knowledge Management. pp. 1411\u20131420. ACM (2015)", "rating": "5: Marginally below acceptance threshold", "reply_text": "Dear Reviewer , We would like to thank you for your assessment of our paper and positive comments regarding presentation and coverage of related work . The Reviewer additionally had some concerns which we would like to address . 1.As we explain in Section 2.2.3 , the universe of DynaMax contains only the word embeddings from the 2 sentences being compared . If x1 , x2 , ... xk and y1 , y2 , ... , yl are word embeddings for sentences 1 and 2 respectively , then U = [ x1 ; x2 ; ... xk ; y1 ; y2 ; ... ; yl ] . This construction is also shown in Algorithm 1 ( Lines 5-7 ) . We are not quite sure what the Reviewer meant by `` In principle DynaMax can work with other methods too '' . The DynaMax-Jaccard ( DMJ ) similarity has 3 components . The `` dynamic '' universe U ( Section 2.2.3 ) , the max-pooling operation ( Eq.2 ) , and finally the fuzzy Jaccard index ( Section 2.2.1 ) . All 3 components are reflected and implemented in Algorithm 1 . Below we show the change in performance when max-pooling is replaced by average and when fuzzy Jaccard is replaced by cosine similarity . GloVe STS12 STS13 STS14 STS15 STS16 DynaMax Jaccard 58.2 53.9 65.1 70.9 71.1 DynaMax Cosine 58.2 53.6 63.2 67.2 67.4 DynaAvg . Jaccard 43.5 37.0 38.8 45.3 39.4 DynaAvg . Cosine 40.0 39.1 38.3 39.7 31.2 We see that all 3 components in DynaMax-Jaccard are very important . When we replaced Jaccard with cosine , the performance dropped . When we replaced max with average it fell even further . Unfortunately , there is only a limited number of combinations we could report in the paper . 2. > `` ... max-pooled word vectors are a special case of fuzzy bag of words . This is not correct . '' Please allow us to elaborate why max-pooled vectors are in fact a special case of fuzzy BoW : We deliberately left the matrix U unspecified in the definition of FBoW ( Section 2.2 , Eq.1 & 2 ) .When U=W , then U represents `` concrete '' words . We said this was the most intuitive ( but not the only ) choice . In some cases , we no longer have concrete words but instead the words are `` abstract '' . We acknowledge this in Section 2.2.2 . In case of max-pooled vectors , U is the identity matrix I . However , we can always assign text labels to the rows of I , for example 'dim1 ' , 'dim2 ' , ... , 'dim300 ' . These `` words '' represent abstract concepts learned by a neural network in its representations . In fact , there has been some work to figure out what these dimensions could contain ( e.g . [ 1 ] ) More generally , for any vector we can always generate a text label for that vector , and take that as a word . The fuzzy BoW is then fuzzy with respect to these abstract words ( concepts ) . We will clarify this in the updated manuscript . [ 1 ] Yulia Tsvetkov , Manaal Faruqui , and Chris Dyer . Correlation-based Intrinsic Evaluation of Word Vector Representations . Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP , pp . 111\u2013115 3 . `` ... max-pooled vectors should be compared with the fuzzy Jaccard index instead of cosine similarity . There is no proof or substantial justification to support this. `` We appreciate there is no proof but we respectfully disagree there is no substantial justification . As discussed above , max-pooled vectors are a special case of fuzzy BoW and so the fuzzy Jaccard index is fully justified for this representation . Empirically fuzzy Jaccard outperforms cosine similarity on most tasks ( Figure 1 ) . 4.Thanks for bringing these works to our attention . We 're happy to cite them where appropriate . Overall , we showed that word embeddings by themselves ( without any weights , tricks or supervision ) are still a formidable baseline for semantic textual similarity . We reported up to 20-point increase on standard benchmark datasets . We also tried to rekindle the interest in fuzzy set theory , which is quite underrepresented in the mainstream ML research . In addition to our replies , we hope the Reviewer can take these contributions into account and perhaps reconsider their score . Again , thank you very much for your assessment and please do not hesitate to contact us with any further queries . Best wishes , ICLR 2019 Conference Paper1058 Authors"}}