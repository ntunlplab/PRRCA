{"year": "2018", "forum": "SyqShMZRb", "title": "Syntax-Directed Variational Autoencoder for Structured Data", "decision": "Accept (Poster)", "meta_review": "This paper presents a more complex version of the grammar-VAE, which can be used to generate structured discrete objects for which a grammar is known, by adding a second 'attribute grammar', inspired by Knuth.\n\nOverall, the idea is a bit incremental, but the space is wide open and I think that structured encoder/decoders is an important direction.  The experiments seem to have been done carefully (with some help from the reviewers) and the results are convincing.", "reviews": [{"review_id": "SyqShMZRb-0", "review_text": "The paper presents an approach for improving variational autoencoders for structured data that provide an output that is both syntactically valid and semantically reasonable. The idea presented seems to have merit , however, I found the presentation lacking. Many sentences are poorly written making the paper hard to read, especially when not familiar with the presented methods. The experimental section could be organized better. I didn't like that two types of experiment are now presented in parallel. Finally, the paper stops abruptly without any final discussion and/or conclusion. ", "rating": "3: Clear rejection", "reply_text": "We thank you for providing reviews . We \u2019 ll refine the paper to include more introduction about background , and more detailed explanations about our method . We \u2019 ll include final discussion/conclusion section ."}, {"review_id": "SyqShMZRb-1", "review_text": "Let me first note that I am not very familiar with the literature on program generation, molecule design or compiler theory, which this paper draws heavily from, so my review is an educated guess. This paper proposes to include additional constraints into a VAE which generates discrete sequences, namely constraints enforcing both semantic and syntactic validity. This is an extension to the Grammar VAE of Kusner et. al, which includes syntactic constraints but not semantic ones. These semantic constraints are formalized in the form of an attribute grammar, which is provided in addition to the context-free grammar. The authors evaluate their methods on two tasks, program generation and molecule generation. Their method makes use of additional prior knowledge of semantics, which seems task-specific and limits the generality of their model. They report that their method outperforms the Character VAE (CVAE) and Grammar VAE (GVAE) of Kusner et. al. However, it isn't clear whether the comparison is appropriate: the authors report in the appendix that they use the kekulised version of the Zinc dataset of Kusner et. al, whereas Kusner et. al do not make any mention of this. The baselines they compare against for CVAE and GVAE in Table 1 are taken directly from Kusner et. al though. Can the authors clarify whether the different methods they compare in Table 1 are all run on the same dataset format? Typos: - Page 5: \"while in sampling procedure\" -> \"while in the sampling procedure\" - Page 6: \"a deep convolution neural networks\" -> \"a deep convolutional neural network\" - Page 6: \"KL-divergence that proposed in\" -> \"KL-divergence that was proposed in\" - Page 6: \"since in training time\" -> \"since at training time\" - Page 6: \"can effectively computed\" -> \"can effectively be computed\" - Page 7: \"reset for training\" -> \"rest for training\" ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for your effort in providing this detailed and useful review ! We present our clarification in the following : > > Use of data and comparison with baselines : We would first note that the anonymous accusation was set to \u201c 17 Nov 2017 ( modified : 28 Nov 2017 ) , readers : ICLR 2018 Conference Reviewers and Higher \u201d . That \u2019 s why it was not visible to us until Nov 28 , i.e. , the original review release date . This gives us no chance to clarify anything before the review deadline . We have replied to it actively since Nov 28 . * * Note the thread is invisible to us again since Dec 2 . * * 1 ) We have experimented both kekulization and non-kekulization for baselines , and have reported the best they can get in all experiments . For example , in Table 2 the GVAE baseline results are improved compared to what was reported in GVAE paper . 2 ) The anonymous commenter is using different kekulization ( RDKIT , rather than our used Marvin ) , different baseline implementation ( custom implementation , rather than the public one in GVAE \u2019 s paper ) and possibly different evaluation code ( since there is no corresponding evaluation online ) . For a reproducible comparision , we released our implementation , data , pretrained model and evaluation code at : https : //github.com/anonymous-author-80ee48b2f87/cvae-baseline 3 ) To make further clarification , we ran our method on the vanilla ( non-kekulised ) data . Our performance is actually boosted ( 76.2 % vs 72.8 % reported in the paper ) . The details of results from these experiments above can be seen in our public reply titled \u201c We released baseline CVAE code , data and evaluation code for clarification \u201d and \u201c Our reconstruction performance without kekulization on Zinc dataset \u201d . In either setting still , our method outperforms all baselines on reconstruction . We are sorry that this may have led to some confusions . To avoid further possible misunderstandings , we have extensively rerun all experiments involving ZINC dataset . Though differences are observed , the conclusion in each experiment remains the same . For example , our reconstruction performance is boosted ( 76.2 % vs 72.8 % ) . Since we didn \u2019 t address aromaticity semantics by the paper submission deadline , the valid prior fraction drops to 43.5 % , but it is still much higher than baselines ( 7.2 % GVAE , 0.7 % CVAE ) . Please find the updated paper for more details . > > prior knowledge and limitations We are targeting on domains where strict syntax and semantics are required . For example , the syntax and semantics are needed to compile a program , or to parse a molecule structure . So such prior knowledge comes naturally with the application . Our contribution is to incorporate such existing syntax and semantics in those compilers , into an on-the-fly generation process of structures . In general , when numerous amount of data is available , a general seq2seq model would be enough . However , obtaining the useful drug molecules is expensive , and thus data is quite limited . Using knowledges like syntax ( e.g. , in GVAE paper ) , or semantics ( like in our paper ) will greatly reduce the amount of data needed to obtain a good model . In our paper , we only addressed 2-3 semantic constraints , where the improvement is significant . Similarly , in \u201c Harnessing Deep Neural Networks with Logic Rules ( Hu et.al , ACL 16 ) \u201d , incorporating several intuitive rules can greatly improve the performance of sentiment analysis , NER , etc . So we believe that , incorporating the knowledge with powerful deep learning achieves a good trade-off between human efforts and model performance . > > Typos and other writing issue : We thank you very much for your careful reading and pointing out the typos and writing issues in our manuscript ! We have incorporated your suggested changes in the current revision , and are keeping conducting further detailed proofreading to fix as much as possible the writing issues in the future revisions ."}, {"review_id": "SyqShMZRb-2", "review_text": "NOTE: Would the authors kindly respond to the comment below regarding Kekulisation of the Zinc dataset? Fair comparison of the data is a serious concern. I have listed this review as a good for publication due to the novelty of ideas presented, but the accusation of misrepresentation below is a serious one and I would like to know the author's response. *Overview* This paper presents a method of generating both syntactically and semantically valid data from a variational autoencoder model using ideas inspired by compiler semantic checking. Instead of verifying the semantic correctness offline of a particular discrete structure, the authors propose \u201cstochastic lazy attributes\u201d, which amounts to loading semantic constraints into a CFG and using a tailored latent-space decoder algorithm that guarantees both syntactic semantic valid. Using Bayesian Optimization, search over this space can yield decodings with targeted properties. Many of the ideas presented are novel. The results presented are state-of-the art. As noted in the paper, the generation of syntactically and semantically valid data is still an open problem. This paper presents an interesting and valuable solution, and as such constitutes a large advance in this nascent area of machine learning. *Remarks on methodology* By initializing a decoding by \u201cguessing\u201d a value, the decoder will focus on high-probability starting regions of the space of possible structures. It is not clear to me immediately how this will affect the output distribution. Since this process on average begins at high-probability region and makes further decoding decisions from that starting point, the output distribution may be biased since it is the output of cuts through high-probability regions of the possible outputs space. Does this sacrifice exploration for exploitation in some quantifiable way? Some exploration of this issue or commentary would be valuable. *Nitpicks* I found the notion of stochastic predetermination somewhat opaque, and section 3 in general introduces much terminology, like lazy linking, that was new to me coming from a machine learning background. In my opinion, this section could benefit from a little more expansion and conceptual definition. The first 3 sections of the paper are very clearly written, but the remainder has many typos and grammatical errors (often word omission). The draft could use a few more passes before publication. ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your effort in providing this detailed and constructive review ! We present our clarification in the following : > > NOTE : We would first note that the anonymous accusation was set to \u201c 17 Nov 2017 ( modified : 28 Nov 2017 ) , readers : ICLR 2018 Conference Reviewers and Higher \u201d . That \u2019 s why it was not visible to us until Nov 28 , i.e. , the original review release date . This gives us no chance to clarify anything before the review deadline . We have replied to it actively since Nov 28 . * * Note the thread is invisible to us again since Dec 2 . * * To summarize our clarification : > > Use of data 1 ) We have experimented both kekulization and non-kekulization for baselines , and have reported the best they can get in all experiments . For example , in Table 2 the GVAE baseline results are improved compared to what was reported in GVAE paper . 2 ) The anonymous commenter is using different kekulization ( RDKIT , rather than our used Marvin ) , different baseline implementation ( custom implementation , rather than the public one in GVAE \u2019 s paper ) and possibly different evaluation code ( since there is no corresponding evaluation online ) . For a reproducible comparision , we released our implementation , data , pretrained model and evaluation code at : https : //github.com/anonymous-author-80ee48b2f87/cvae-baseline 3 ) To make further clarification , we ran our method on the vanilla ( non-kekulised ) data . Our performance is actually boosted ( 76.2 % vs 72.8 % reported in the paper ) . The details of results from these experiments above can be seen in our public reply titled \u201c We released baseline CVAE code , data and evaluation code for clarification \u201d and \u201c Our reconstruction performance without kekulization on Zinc dataset \u201d . In either setting still , our method outperforms all baselines on reconstruction . We are sorry that this may have led to some confusions . To avoid further possible misunderstandings , we have extensively rerun all experiments involving ZINC dataset . Though differences are observed , the conclusion in each experiment remains the same . For example , our reconstruction performance is boosted ( 76.2 % vs 72.8 % ) . Since we didn \u2019 t address aromaticity semantics by the paper submission deadline , the valid prior fraction drops to 43.5 % , but it is still much higher than baselines ( 7.2 % GVAE , 0.7 % CVAE ) . Please find the updated paper for more details . > > sacrifice of exploration CVAE , GVAE and our SD-VAE are all factorizing the joint probability of entire program / SMILES text in some way . CVAE factorizes in char level , GVAE in Context Free Grammar ( CFG ) tree , while ours factorizes both CFG and non-context free semantics . Since every method is factorizing the entire space , each structure in this space should have the possibility ( despite its magnitude ) of being sampled . Bias is not always a bad thing . Some bias will help the model quickly concentrate to the correct mode . Definitely , different methods will bias the distribution in a different way . For example , CVAE is biased towards the beginning of the sequence . GVAE is biased by several initial non-terminals . Our experiments on diversity of generated molecules ( table 3 ) demonstrate that , both GVAE and our method can generate quite diverse molecules . So we think both methods don \u2019 t have noticeable mode collapse problem on this dataset . > > writings : Thanks for the suggestions . We are adding more effort in explaining our algorithm and improve writing in revisions . We have revised our experiments sections for clarifying the most important issue , and will keep improving the writing . To briefly answer the \u201c lazy linking \u201d : We don \u2019 t sample the actual value of the attribute at the first encounter ; Instead , later when the actual content is generated , we use bottom-up calculation to fill the value . For example , when generating ringbond attribute , we only sample its existence . The ringbond information ( bond index and bond type ) are filled later . As a side note , this idea comes from \u201c lazy evaluation \u201d in compiler theory where a value is not calculated until it is needed ."}], "0": {"review_id": "SyqShMZRb-0", "review_text": "The paper presents an approach for improving variational autoencoders for structured data that provide an output that is both syntactically valid and semantically reasonable. The idea presented seems to have merit , however, I found the presentation lacking. Many sentences are poorly written making the paper hard to read, especially when not familiar with the presented methods. The experimental section could be organized better. I didn't like that two types of experiment are now presented in parallel. Finally, the paper stops abruptly without any final discussion and/or conclusion. ", "rating": "3: Clear rejection", "reply_text": "We thank you for providing reviews . We \u2019 ll refine the paper to include more introduction about background , and more detailed explanations about our method . We \u2019 ll include final discussion/conclusion section ."}, "1": {"review_id": "SyqShMZRb-1", "review_text": "Let me first note that I am not very familiar with the literature on program generation, molecule design or compiler theory, which this paper draws heavily from, so my review is an educated guess. This paper proposes to include additional constraints into a VAE which generates discrete sequences, namely constraints enforcing both semantic and syntactic validity. This is an extension to the Grammar VAE of Kusner et. al, which includes syntactic constraints but not semantic ones. These semantic constraints are formalized in the form of an attribute grammar, which is provided in addition to the context-free grammar. The authors evaluate their methods on two tasks, program generation and molecule generation. Their method makes use of additional prior knowledge of semantics, which seems task-specific and limits the generality of their model. They report that their method outperforms the Character VAE (CVAE) and Grammar VAE (GVAE) of Kusner et. al. However, it isn't clear whether the comparison is appropriate: the authors report in the appendix that they use the kekulised version of the Zinc dataset of Kusner et. al, whereas Kusner et. al do not make any mention of this. The baselines they compare against for CVAE and GVAE in Table 1 are taken directly from Kusner et. al though. Can the authors clarify whether the different methods they compare in Table 1 are all run on the same dataset format? Typos: - Page 5: \"while in sampling procedure\" -> \"while in the sampling procedure\" - Page 6: \"a deep convolution neural networks\" -> \"a deep convolutional neural network\" - Page 6: \"KL-divergence that proposed in\" -> \"KL-divergence that was proposed in\" - Page 6: \"since in training time\" -> \"since at training time\" - Page 6: \"can effectively computed\" -> \"can effectively be computed\" - Page 7: \"reset for training\" -> \"rest for training\" ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for your effort in providing this detailed and useful review ! We present our clarification in the following : > > Use of data and comparison with baselines : We would first note that the anonymous accusation was set to \u201c 17 Nov 2017 ( modified : 28 Nov 2017 ) , readers : ICLR 2018 Conference Reviewers and Higher \u201d . That \u2019 s why it was not visible to us until Nov 28 , i.e. , the original review release date . This gives us no chance to clarify anything before the review deadline . We have replied to it actively since Nov 28 . * * Note the thread is invisible to us again since Dec 2 . * * 1 ) We have experimented both kekulization and non-kekulization for baselines , and have reported the best they can get in all experiments . For example , in Table 2 the GVAE baseline results are improved compared to what was reported in GVAE paper . 2 ) The anonymous commenter is using different kekulization ( RDKIT , rather than our used Marvin ) , different baseline implementation ( custom implementation , rather than the public one in GVAE \u2019 s paper ) and possibly different evaluation code ( since there is no corresponding evaluation online ) . For a reproducible comparision , we released our implementation , data , pretrained model and evaluation code at : https : //github.com/anonymous-author-80ee48b2f87/cvae-baseline 3 ) To make further clarification , we ran our method on the vanilla ( non-kekulised ) data . Our performance is actually boosted ( 76.2 % vs 72.8 % reported in the paper ) . The details of results from these experiments above can be seen in our public reply titled \u201c We released baseline CVAE code , data and evaluation code for clarification \u201d and \u201c Our reconstruction performance without kekulization on Zinc dataset \u201d . In either setting still , our method outperforms all baselines on reconstruction . We are sorry that this may have led to some confusions . To avoid further possible misunderstandings , we have extensively rerun all experiments involving ZINC dataset . Though differences are observed , the conclusion in each experiment remains the same . For example , our reconstruction performance is boosted ( 76.2 % vs 72.8 % ) . Since we didn \u2019 t address aromaticity semantics by the paper submission deadline , the valid prior fraction drops to 43.5 % , but it is still much higher than baselines ( 7.2 % GVAE , 0.7 % CVAE ) . Please find the updated paper for more details . > > prior knowledge and limitations We are targeting on domains where strict syntax and semantics are required . For example , the syntax and semantics are needed to compile a program , or to parse a molecule structure . So such prior knowledge comes naturally with the application . Our contribution is to incorporate such existing syntax and semantics in those compilers , into an on-the-fly generation process of structures . In general , when numerous amount of data is available , a general seq2seq model would be enough . However , obtaining the useful drug molecules is expensive , and thus data is quite limited . Using knowledges like syntax ( e.g. , in GVAE paper ) , or semantics ( like in our paper ) will greatly reduce the amount of data needed to obtain a good model . In our paper , we only addressed 2-3 semantic constraints , where the improvement is significant . Similarly , in \u201c Harnessing Deep Neural Networks with Logic Rules ( Hu et.al , ACL 16 ) \u201d , incorporating several intuitive rules can greatly improve the performance of sentiment analysis , NER , etc . So we believe that , incorporating the knowledge with powerful deep learning achieves a good trade-off between human efforts and model performance . > > Typos and other writing issue : We thank you very much for your careful reading and pointing out the typos and writing issues in our manuscript ! We have incorporated your suggested changes in the current revision , and are keeping conducting further detailed proofreading to fix as much as possible the writing issues in the future revisions ."}, "2": {"review_id": "SyqShMZRb-2", "review_text": "NOTE: Would the authors kindly respond to the comment below regarding Kekulisation of the Zinc dataset? Fair comparison of the data is a serious concern. I have listed this review as a good for publication due to the novelty of ideas presented, but the accusation of misrepresentation below is a serious one and I would like to know the author's response. *Overview* This paper presents a method of generating both syntactically and semantically valid data from a variational autoencoder model using ideas inspired by compiler semantic checking. Instead of verifying the semantic correctness offline of a particular discrete structure, the authors propose \u201cstochastic lazy attributes\u201d, which amounts to loading semantic constraints into a CFG and using a tailored latent-space decoder algorithm that guarantees both syntactic semantic valid. Using Bayesian Optimization, search over this space can yield decodings with targeted properties. Many of the ideas presented are novel. The results presented are state-of-the art. As noted in the paper, the generation of syntactically and semantically valid data is still an open problem. This paper presents an interesting and valuable solution, and as such constitutes a large advance in this nascent area of machine learning. *Remarks on methodology* By initializing a decoding by \u201cguessing\u201d a value, the decoder will focus on high-probability starting regions of the space of possible structures. It is not clear to me immediately how this will affect the output distribution. Since this process on average begins at high-probability region and makes further decoding decisions from that starting point, the output distribution may be biased since it is the output of cuts through high-probability regions of the possible outputs space. Does this sacrifice exploration for exploitation in some quantifiable way? Some exploration of this issue or commentary would be valuable. *Nitpicks* I found the notion of stochastic predetermination somewhat opaque, and section 3 in general introduces much terminology, like lazy linking, that was new to me coming from a machine learning background. In my opinion, this section could benefit from a little more expansion and conceptual definition. The first 3 sections of the paper are very clearly written, but the remainder has many typos and grammatical errors (often word omission). The draft could use a few more passes before publication. ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your effort in providing this detailed and constructive review ! We present our clarification in the following : > > NOTE : We would first note that the anonymous accusation was set to \u201c 17 Nov 2017 ( modified : 28 Nov 2017 ) , readers : ICLR 2018 Conference Reviewers and Higher \u201d . That \u2019 s why it was not visible to us until Nov 28 , i.e. , the original review release date . This gives us no chance to clarify anything before the review deadline . We have replied to it actively since Nov 28 . * * Note the thread is invisible to us again since Dec 2 . * * To summarize our clarification : > > Use of data 1 ) We have experimented both kekulization and non-kekulization for baselines , and have reported the best they can get in all experiments . For example , in Table 2 the GVAE baseline results are improved compared to what was reported in GVAE paper . 2 ) The anonymous commenter is using different kekulization ( RDKIT , rather than our used Marvin ) , different baseline implementation ( custom implementation , rather than the public one in GVAE \u2019 s paper ) and possibly different evaluation code ( since there is no corresponding evaluation online ) . For a reproducible comparision , we released our implementation , data , pretrained model and evaluation code at : https : //github.com/anonymous-author-80ee48b2f87/cvae-baseline 3 ) To make further clarification , we ran our method on the vanilla ( non-kekulised ) data . Our performance is actually boosted ( 76.2 % vs 72.8 % reported in the paper ) . The details of results from these experiments above can be seen in our public reply titled \u201c We released baseline CVAE code , data and evaluation code for clarification \u201d and \u201c Our reconstruction performance without kekulization on Zinc dataset \u201d . In either setting still , our method outperforms all baselines on reconstruction . We are sorry that this may have led to some confusions . To avoid further possible misunderstandings , we have extensively rerun all experiments involving ZINC dataset . Though differences are observed , the conclusion in each experiment remains the same . For example , our reconstruction performance is boosted ( 76.2 % vs 72.8 % ) . Since we didn \u2019 t address aromaticity semantics by the paper submission deadline , the valid prior fraction drops to 43.5 % , but it is still much higher than baselines ( 7.2 % GVAE , 0.7 % CVAE ) . Please find the updated paper for more details . > > sacrifice of exploration CVAE , GVAE and our SD-VAE are all factorizing the joint probability of entire program / SMILES text in some way . CVAE factorizes in char level , GVAE in Context Free Grammar ( CFG ) tree , while ours factorizes both CFG and non-context free semantics . Since every method is factorizing the entire space , each structure in this space should have the possibility ( despite its magnitude ) of being sampled . Bias is not always a bad thing . Some bias will help the model quickly concentrate to the correct mode . Definitely , different methods will bias the distribution in a different way . For example , CVAE is biased towards the beginning of the sequence . GVAE is biased by several initial non-terminals . Our experiments on diversity of generated molecules ( table 3 ) demonstrate that , both GVAE and our method can generate quite diverse molecules . So we think both methods don \u2019 t have noticeable mode collapse problem on this dataset . > > writings : Thanks for the suggestions . We are adding more effort in explaining our algorithm and improve writing in revisions . We have revised our experiments sections for clarifying the most important issue , and will keep improving the writing . To briefly answer the \u201c lazy linking \u201d : We don \u2019 t sample the actual value of the attribute at the first encounter ; Instead , later when the actual content is generated , we use bottom-up calculation to fill the value . For example , when generating ringbond attribute , we only sample its existence . The ringbond information ( bond index and bond type ) are filled later . As a side note , this idea comes from \u201c lazy evaluation \u201d in compiler theory where a value is not calculated until it is needed ."}}