{"year": "2017", "forum": "HJDdiT9gl", "title": "Generating Long and Diverse Responses with Neural Conversation Models", "decision": "Reject", "meta_review": "The reviewers agree that the work presents interesting, but incremental, results. They are also unconvinced that this is the right direction for research on dialogue systems to go in or that the methods presented will appeal to a broader audience. It seems the authors have some work to do on the larger argument, before this work can be accepted.", "reviews": [{"review_id": "HJDdiT9gl-0", "review_text": "The paper proposes modification to seq2seq model to help it handle the problems when long responses are needed. Though the technical contributions may be of value, the work in my personal opinion is not in the right direction towards helping dialog systems. Essentially we try to generate long responses that sound \"nice\" yet are not grounded to any reality, they just need to be related to the question and not suffers from obvious mistakes. Yet, the architectural innovations proposed may be of merit.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the review ! As we mentioned below , the problem of `` grounding to reality '' , i.e. , modeling context , is orthogonal to the problem of generating long and informative responses . That says , when new advances are made to context modeling , we can apply the same technique we proposed , because our method is mainly on the decoder side . The two problems are both non-trivial and therefore worth separated efforts . Potential approaches towards context modeling spans from extensive feature engineering ( e.g. , [ 1 ] in my comments below ) to hierarchical memory modeling , commonsense modeling , etc. , and is likely an AI-complete problem . Therefore we believe that it is not supposed to be addressed as part of a paper which do not focus on context modeling ."}, {"review_id": "HJDdiT9gl-1", "review_text": "The paper is clearly interesting in that it does address important problems (length and diversity of responses) in sequence-to-sequence models. The two ideas put forward (glimpse model and segment-based stochastic decoding) both seem ideas in the right direction. I was however not so sold on the argument that these are particularly suitable for conversations. The results indicate that the ideas do indeed generate longer and also somewhat more sensible target sequences and as such the paper makes progress w.r.t these important problems. So overall I would suggest accepting the paper even though the flavor of the proposed ideas are somewhat \"small steps\". ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the reviews ! We appreciate the thoughts ! You are right , our work is more like taking the conversation as a problem setting to be grounded and addressing the sequence generation problem ."}, {"review_id": "HJDdiT9gl-2", "review_text": "This paper considers the problem of generating long and diverse responses in dialog systems. Two techniques are proposed to the seq-to-seq framework: (1) glimpse model that trains on fixed-length segments of the target side at a time, and (2) a segment-based stochastic decoding technique which injects diversity earlier in the generated responses. The large scale experiments on 2.3B conversation messages are quite impressive. Experiments on human evaluation should also be encouraged. With all these said, I am still not 100% convinced that machine generated long sequence is the right direction for dialog systems. As shown in Figure 3 (a), human evaluation shows that the proposed system is not significantly better than the baselines. I think more analysis and user preference mining should be done in the future to help us understand the nature of this problem. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the reviews ! I think you are right , we should have expressed our goal as the well-spoken-ness and consistency of long and informative responses , when generated from a sequence decoder network , and we take just this as a research problem without considering the actual end-user experience . The latter is mixed with too many other factors that we did n't touch . For example , short and accurate answers may be more effective when the conversation is answer-seeking . Also , a well-spoken response may exhibit negative sentiment in which case the evaluation tend to be negative . We 'll try to revise the paper accordingly . These affects the human eval results which causes the overall improve not be not great enough ."}], "0": {"review_id": "HJDdiT9gl-0", "review_text": "The paper proposes modification to seq2seq model to help it handle the problems when long responses are needed. Though the technical contributions may be of value, the work in my personal opinion is not in the right direction towards helping dialog systems. Essentially we try to generate long responses that sound \"nice\" yet are not grounded to any reality, they just need to be related to the question and not suffers from obvious mistakes. Yet, the architectural innovations proposed may be of merit.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for the review ! As we mentioned below , the problem of `` grounding to reality '' , i.e. , modeling context , is orthogonal to the problem of generating long and informative responses . That says , when new advances are made to context modeling , we can apply the same technique we proposed , because our method is mainly on the decoder side . The two problems are both non-trivial and therefore worth separated efforts . Potential approaches towards context modeling spans from extensive feature engineering ( e.g. , [ 1 ] in my comments below ) to hierarchical memory modeling , commonsense modeling , etc. , and is likely an AI-complete problem . Therefore we believe that it is not supposed to be addressed as part of a paper which do not focus on context modeling ."}, "1": {"review_id": "HJDdiT9gl-1", "review_text": "The paper is clearly interesting in that it does address important problems (length and diversity of responses) in sequence-to-sequence models. The two ideas put forward (glimpse model and segment-based stochastic decoding) both seem ideas in the right direction. I was however not so sold on the argument that these are particularly suitable for conversations. The results indicate that the ideas do indeed generate longer and also somewhat more sensible target sequences and as such the paper makes progress w.r.t these important problems. So overall I would suggest accepting the paper even though the flavor of the proposed ideas are somewhat \"small steps\". ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the reviews ! We appreciate the thoughts ! You are right , our work is more like taking the conversation as a problem setting to be grounded and addressing the sequence generation problem ."}, "2": {"review_id": "HJDdiT9gl-2", "review_text": "This paper considers the problem of generating long and diverse responses in dialog systems. Two techniques are proposed to the seq-to-seq framework: (1) glimpse model that trains on fixed-length segments of the target side at a time, and (2) a segment-based stochastic decoding technique which injects diversity earlier in the generated responses. The large scale experiments on 2.3B conversation messages are quite impressive. Experiments on human evaluation should also be encouraged. With all these said, I am still not 100% convinced that machine generated long sequence is the right direction for dialog systems. As shown in Figure 3 (a), human evaluation shows that the proposed system is not significantly better than the baselines. I think more analysis and user preference mining should be done in the future to help us understand the nature of this problem. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the reviews ! I think you are right , we should have expressed our goal as the well-spoken-ness and consistency of long and informative responses , when generated from a sequence decoder network , and we take just this as a research problem without considering the actual end-user experience . The latter is mixed with too many other factors that we did n't touch . For example , short and accurate answers may be more effective when the conversation is answer-seeking . Also , a well-spoken response may exhibit negative sentiment in which case the evaluation tend to be negative . We 'll try to revise the paper accordingly . These affects the human eval results which causes the overall improve not be not great enough ."}}