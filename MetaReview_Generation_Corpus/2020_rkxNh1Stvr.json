{"year": "2020", "forum": "rkxNh1Stvr", "title": "Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel", "decision": "Accept (Poster)", "meta_review": "This paper presents a method to model uncertainty in deep learning regressors by applying a post-hoc procedure.  Specifically, the authors model the residuals of neural networks using Gaussian processes, which provide a principled Bayesian estimate of uncertainty.  The reviewers were initially mixed and a fourth reviewer was brought in for an additional perspective.  The reviewers found that the paper was well written, well motivated and found the methodology sensible and experiments compelling.  AnonReviewer4 raised issues with the theoretical exposition of the paper (going so far as to suggest that moving the theory into the supplementary and using the reclaimed space for additional clarifications would make the paper stronger).  The reviewers found the author response compelling and as a result the reviewers have come to a consensus to accept.  Thus the recommendation is to accept the paper.  \n\nPlease do take the reviewer feedback into account in preparing the camera ready version.  In particular, please do address the remaining concerns from AnonReviewer4 regarding the theoretical portion of the paper.  It seems that the methodological and empirical portions of the paper are strong enough to stand on their own (and therefore the recommendation for an accept).  Adding theory just for the sake of having theory seems to detract from the message (particularly if it is irrelevant or incorrect as initially pointed out by the reviewer).", "reviews": [{"review_id": "rkxNh1Stvr-0", "review_text": "# Summary The authors propose a method for post-hoc correction and predictive variance estimation for neural network models. The method fits a GP to the model residuals, and learns a composite kernel that combines two kernels defined on the input space and the model\u2019s output space (called RIO, R for residual, and IO for the input-output kernel). The authors suggest that residual means and variances at test points can then be calculated explicitly using predictive distributions from the GP. The authors run a large panel of experiments across a number of datasets, and compare to a number of methods that draw connections between neural networks and GP\u2019s. In addition, the full method is compared to a number of methods that utilize only some components of the full RIO method. In these experiments, the RIO method generally shows strong performance in both RMSE and NLPD compared to these baselines. # Feedback Overall, this is a neat method. It has the flavor of a number of other composite ML methods that have worked well in the past---e.g., boosting and platt scaling---but is different enough to stand on its own. The experimental results are quite promising. However, I am torn about the paper, because the theoretical discussion of the method is quite convoluted and seems either irrelevant or incorrect. I wish that the authors had spent more time with small demonstrations of what the procedure does in some simple settings. This would give practitioners considering the method far more intuition about when they would expect it to work and fail than the current theoretical discussion. ## Uncertainty Discussion is Lacking The motivation and discussion sell this method as an uncertainty quantification method, but almost all of the theoretical development revolves around prediction correction. The methods properties as an uncertainty quantification tool are underdeveloped. The only theoretical point made about uncertainty estimation is Theorem 2.7, which states that the scalar variance of the GP \u201cnugget\u201d is positively correlated with the variance of the NN\u2019s residuals. Providing a scalar summary of noise is not particularly compelling for a method advertised as a point-prediction uncertainty quantification method. In addition, it is not clear what probability distribution the \u201ccorrelation\u201d is defined over. The argument made in the proof seems quite obvious: if a GP is used to model a noisier process (i.e., residuals with a larger variance), it will in some cases classify that variability as independent noise. If the authors wanted to focus on the properties of their method as an uncertainty quantification tool, they could discuss the assumptions underlying the GP error estimates, and when they would be likely to diverge from practical properties like predictive interval coverage. For example, because the base NN predictor is treated as fixed, it seems that this method ignore uncertainty that stems from the NN fit due to random initialization. Likewise, it seems that this method would not quantify uncertainty from resampling the data and obtaining a new NN predictor. )The coverage experiments in the appendix seem to confirm this -- generally, the predictive intervals generally under-cover the predicted values.) It\u2019s fine if the method doesn\u2019t quantify these types of uncertainty, but discussion of these types of issues would be far more welcome than the current convoluted theory in Section 2. This discussion might not yield theorems, but it would give practitioners useful guidelines for deciding whether the particular scheme would likely work for this application. ## Problems with the Error Correction Argument The theory section, especially 2.2, was very difficult to parse. First, as a matter of style, a sequence of Lemma and Theorem statements are given without defining most of the notation used therein, and with almost no prose providing context or intuition. In the buildup to the theorems, it is also unclear which assertions about the decompositions of y_i are assumptions about the true data generating process, and which assertions are specifications of a particular GP model. The substance also has some issues. I think the intention in this section is to get to a rather simple variance decomposition of the labels y. The question is how much variation in y or the residual is represented in the posterior predictive mean of a particular GP. It seems reasonable that in some cases, the structure in the residual may be more amenable to modeling with a stationary GP than the structure in the raw labels y. It is not clear that all of the theoretical complexity here is necessary to make this point. Instead, the authors make a convoluted argument that attempts to establish that the errors from the NN + GP approach will be smaller under very general circumstances. The argument is phrased somewhat ambiguously (it is not clear exactly what is being assumed, and what is corresponds to the specification of a working model), but depending on how one reads this section, the argument makes statements that are either too broad to be correct, or too narrow to be relevant. The argument decomposes for the raw labels and the residuals into pieces that a GP can \u201ccapture\u201d or \u201crepresent\u201d, and parts that it cannot. The two equations are: y_i = f(x_i) + g(x_i) + \\xi_i R_i = (y_i - h_NN(x_i)) = r_f(x_i) + r_g(x_i) + \\xi_i f(.) and r_f(.) represent the portions of the label and residual processes, respectively, that the GP \"captures\". It is assumed that the GP will model this portion correctly, and leave the \u201cepsilon-indistinguishable\u201d portion g(.) or r_g(.) untouched. The argument then assumes that f(.) and r_f(.) will have proportional kernels, and so it is possible to show that the predictions of residuals based on r_f(.) will have smaller predictive variance than predictions based on f(.) as long as the variation represented by r_g(.) is smaller than the variation represented by g(.). On its face, this argument raises some red flags. Because h_NN(.) is allowed to be an arbitrary function, the argument here should be symmetric. Why can\u2019t we also get a guaranteed variance reduction by adding h_NN(.) to y rather than subtracting it? Perhaps some of this is captured in the parameter \\delta, which quantifies the reduction in variation represented in r_g(.) vs g(.), but the argument that the kernel of r_f(.) can be no larger than the kernel f(.) in terms of trace (that is, the proportionality constant \\alpha is not greater than 1) does not make sense. If h_NN(x_i) is simply -f(x_i), then these arguments would not go through. At the very least, conditions need to be articulated about the properties of h_NN(.). Some of the strangeness comes from the fact that this is a poor model of most prediction problems, where the main issue with fitting a GP is not \u201cindistinguishability\u201d, but misspecification. Consider a process y_i that is non-stationary; say g(.) has a linear trend in some component of x. A GP with a stationary covariance kernel fit to this process (such as RBF) will attempt to explain the variation due to the linear trend with a variance kernel that encodes long-range dependence. On the other hand, if this trend were removed by a base model like an NN, the residuals would have a very different structure (perhaps they would be stationary), and in this case, the GP would fit the data with a very different covariance kernel. Unfortunately, it does not seem like the formalism here can express a notion of misspecification at all. In the theory, it is assumed that the GP will only model the portion of the labels y_i for which it is property specified (in this case, f(.)). This generally does not occur in practice, as in the example above. It might be possible for this to apply in some circumstances, but the authors give no conditions (e.g., that the process y_i be stationary). Based on this assumption, the authors assert that the fitted GP to f(.) and r_f(.) will have the same covariance kernel parameters up to some proportionality constant \\alpha. Much of their theoretical argument depends on this proportionality. But this proportionality cannot apply in general, and again, no conditions are given for when we might expect this to hold. It would be far more compelling if the authors proposed the very standard approach to modeling data via covariance kernels, where one first models non-stationary portions of the data with a base model, then models the correlation in the residuals with something like a GP. This is the bread-and-butter approach in, say, timeseries analysis (see, e.g., the Shumway and Stoffer textbook https://www.stat.pitt.edu/stoffer/tsa4/tsa4.htm), and the approach in this paper could be framed similarly. ## Demos I Wish I Had Seen I wish the authors had presented some demonstrations of what the GP does to the fitted values of an NN. Giving a demonstration of how the output kernel modifies predicted values, for example, would give some nice intuition the value added by this portion. I suspect that this step essentially performs something like Platt scaling, but for continuous outcomes, by shrinking predictions together so that they better match the overall distribution of observed labels. Perhaps the mechanism is different. At any rate, it would be useful to understand where the information gain is coming from, and this would be far better expressed concretely in terms of a toy data example than the theoretical arguments that are given. ## Coverage Experiments I wish the coverage experiments evaluating predictive intervals were included in the main text. As far as uncertainty quantification evaluations go, coverage is one of the few assessments that does not rely on the model itself (unlike NPLD, which uses the model\u2019s own log-likelihood), and can be phrased as a concrete performance guarantee. Here, the goal for predictive intervals is to cover the true prediction value _at least as often_ as the nominal rate (95% intervals should cover the truth _at least_ 95% of the time), not merely that coverage be \u201cclose\u201d to the nominal rate. This asymmetric evaluation gives you a concrete guarantee that the uncertainty estimate is conservative. The coverage experiments show that this method quite systematically under-covers compared to the end-to-end SVGP method, which generally satisfies this coverage property. I think this is important information to include about the model, and generally I think this behavior results from the fact that uncertainty is not propagated from the NN fit. This should be presented clearly in the main text.", "rating": "6: Weak Accept", "reply_text": "Thanks for this thorough and detailed review of our work , particularly with regards to the theory . The overarching concern was that the motivation , details , and implications of the theory were unclear , and it would be more compelling if the detailed behaviors of RIO can be demonstrated using concrete examples . To address these concerns , we have added more concrete empirical demonstrations of the detailed behaviors of RIO , regarding both output correction and confidence interval coverage . We have also rewritten Section 2.2 in the newly uploaded version of the paper , aiming to clarify the assumptions , the motivation of each step , and the conclusions drawn . We believe this update addresses the overarching concern , and addresses many of the specific comments in the process . We will respond to your concerns regarding \u201c # # Demos I Wish I Had Seen \u201d and \u201c # # Coverage Experiments \u201d first , then reply to all your concerns related to theory . Q : comments within \u201c # # Demos I Wish I Had Seen \u201d section A : Thanks for these very insightful comments . We have added two empirical studies to analyze what RIO actually does during the correction of NN outputs . The first one demonstrates that RIO does n't always shrink predictions together , but instead performs different calibrations on each point in order to move the predictions closer to the ground truth . The second one demonstrates that most of these calibrations are indeed improvements . We have included detailed description of these studies in the appendix , and mention the conclusions in the main text . More details on the first study : In the first empirical analysis , we randomly pick a run for each tested dataset , and plot the distributions of ground truth labels ( outcomes ) , original NN predictions and predictions corrected after RIO . The results are summarized in Figure 9 of Appendix D.3 . Based on the results , it is clear that RIO is not simply shrinking predictions together . Instead , RIO tends to calibrate each NN prediction accordingly . The distribution of outputs after RIO calibration may be a shift , or shrinkage , or expansion , or even more complex modifications of the original NN predictions , depending on how different are NN predictions from ground truths . As a result , the distribution of RIO calibrated outputs are always closer to the distribution of ground truths . One interesting behavior can be observed for \u201c protein \u201d dataset ( row 3 , rightmost plot ) : after applying RIO , the range of whiskers shrunk and the outliers disappeared , but the box ( indicating 25 to 75 percentile of the data ) expanded . This behavior shows that RIO is actually trying to calibrate each point differently . To provide more details , the point-wise comparisons between NN outputs and RIO-corrected outputs for the same experimental runs as in Figure 9 are shown in Figure 10 of Appendix D.3 . From Figure 10 , RIO shows different calibration behaviors accordingly . If we compare the plots in Figure 10 to the corresponding ones in Figure 9 ( they are for the same run on the same dataset ) , it is clear that all these different calibration behaviors actually make sense , and they are generally leading to more accurate predictions of ground truths . More details on the second study : In the second empirical study , we define a new performance metric called \u201c improvement ratio \u201d ( IR ) , which is the ratio between number of successful corrections ( successfully reducing the error ) and total number of data points . For each run on each dataset , we calculate this IR value , and the distribution of IR values over 100 independent runs ( random dataset split except for MSD , random NN initialization and training ) on each dataset is plotted in Figure 11 of Appendix D.3 . According to the results , the IR values for RIO are above 0.5 in most cases . For 7 datasets , IR values are above 0.5 in all 100 independent runs . For some runs in \u201c yacht \u201d , \u201c ENB/h \u201d , \u201c CT \u201d , and \u201c MSD \u201d , the IR values are above 0.8 or even above 0.9 . All these observations show that RIO is making meaningful corrections instead of random perturbations . Results in Figure 11 also provides useful information for practitioners : Although not all RIO calibrations improve the result , most of them do . Q : comments within \u201c # # Coverage Experiments \u201d section A : Confidence interval ( CI ) coverage indeed is a concrete and straightforward performance metric , which is why we included the 95 % /90 % /68 % CI coverages for all algorithms in all datasets in the Appendix . However , after a deeper investigation , including an additional experiment ( Figure 6 , 7 and 8 in Appendix D.2 ) , we found this performance metric to be noisy and potentially misleading . Drawing conclusions from it requires lengthy qualifications ; given the page limits of the main text , we believe such discussions are better presented in the appendix . In contrast , NLPD loss is more reliable , which is why it is the primary measure in this paper . This choice is now explained in the main text , and a justification given in the appendix ."}, {"review_id": "rkxNh1Stvr-1", "review_text": "This paper proposes a new framework (RIO) to estimate uncertainty in pretrained neural networks. For this purpose, RIO employs Gaussian Processes whose kernels are calculated by kernel functions of input and output samples and the corresponding target values. - The proposed approach is interesting and the initial results are promising. However, there are various major and minor problems with the paper: - The proposed method can be applied to any machine learning algorithm. It is not clear why you focus on employment of the proposed method for vanilla NNs. - Have you applied RIO for other learning algorithms as well? - Could you please explain more precisely, how you utilize which particular properties of NNs in RIO, and/or how RIO helps quantification and improvement of uncertainty of NNs particularly? - Following equation (7), you claim that \u201cIn other words, RIO not only adds uncertainty estimation to a standard NN\u2014it also makes its predictions more accurate, without any modification to its architecture or training\u201d. Could you please verify and justify how RIO makes predictions of NNs more accurate? In this statement, I guess that you consider the results given in Theorem 2.6. However, you should not that the error functions given in Theorem 2.6 are calculated in a cascaded manner, i.e., by applying a GP at the output of a NN. - The main proposal of the paper is that RIO makes it possible to estimate uncertainty in any pretrained standard NN. In order to verify that proposal, you should improve the experiments, esp. using larger datasets with larger neural networks, including deep neural networks. After Rebuttal: I read the comments of the other reviewers and response of the authors. Most of my questions were addressed in the rebuttal, and the paper was improved. However, there is still room to improve the paper with additional analysis using state-of-the-art algorithms on benchmark datasets, and to improve presentation of the work. Therefore, I improve my rating to Weak Accept.", "rating": "6: Weak Accept", "reply_text": "Thank you for your constructive comments . Please see our responses to each of your concerns below : Q1 : \u201c The proposed method can be applied to any machine learning algorithm . It is not clear why you focus on employment of the proposed method for vanilla NNs. \u201d A1 : RIO can indeed be applied to other machine learning algorithms , but we believe vanilla NNs are a good choice for this paper for two reasons : ( 1 ) As the first paper on RIO , it makes sense to focus it on the analysis and demonstration of RIO \u2019 s abilities without the complexity of multiple platforms , and ( 2 ) vanilla NNs are very common model used by practitioners , making the results relevant to many people . We have discussed the motivation and reasons for which we choose standard NN as the focus in the main paper . However , since it is insightful to also test the generality of RIO , we have added a whole set of experiments that instead use random forest models , as described in A2 below . In more details : 1 . Since this is the very first paper that introduces RIO , focusing on one widely used model allows us to do a thorough and deep investigation into the new approach , both theoretically and empirically . These detailed analysis and results should be very informative for practitioners who are using vanilla NNs . Including different approaches may lose this focus and depth . 2.Vanilla NN is arguably the most commonly used model among practitioners for making point predictions , but it also creates a lot of inconvenience and risks due to the lack of uncertainty information . Our target is to develop a tool that is practical and useful for the practitioner community , so choosing vanilla NN to demonstrate the effectiveness of RIO would be most appropriate as the first milestone . Q2 : \u201c Have you applied RIO for other learning algorithms as well ? \u201d A2 : We have added the experimental results on Random Forests for all RIO variants and all datasets . Please see Table 7 in Appendix D.6 for full details of the experiments and results . To summarize , RIO performs the best or equals the best method ( based on statistical tests ) in 9 out of 12 datasets in terms of both RMSE and NLPD . In addition , RIO significantly improves the performance of original RF in 11 out of 12 datasets . These empirical results verifies the robustness and broad applicability of RIO . Full details of the results are included in the appendix , and we also referred to this as a concrete example when we discuss the extensibility of RIO in future work . Q3 : \u201c Could you please explain more precisely , how you utilize which particular properties of NNs in RIO , and/or how RIO helps quantification and improvement of uncertainty of NNs particularly ? \u201d A3 : We use the expressivity of NNs , which means that they can learn complex structure that a GP would treat as noise . This point has been clarified in the revised version of Section 2.2 . Similarly , RIO is particularly well-suited for NNs , because their expressivity makes it difficult to quantify their uncertainty with simpler analytical methods . However , RIO can be easily extended to other kinds of regression models as well , e.g. , the new experiments in Appendix D.6 show that they work with random forests ."}, {"review_id": "rkxNh1Stvr-2", "review_text": "This paper solves an interesting scientific and applied problem: can we construct an algorithm to predict uncertainties without re-training/modifying existing neural network training algos? The authors propose a novel technique (called RIO) which leverages existing neural network but use both the input as well as the output of the neural net as an input to a GP which regresses on the residual error of the neural network. The authors describe the theoretical foundations as well as show empirical results on multiple datasets. My thoughts on the paper: - The paper is well written and from section 2.1 it is clear how one could re-produce their method. - The theoretical section 2.2 feels a bit rushed, I think it would be worth sharing the high level intuition behind some of the theory first before going into the details. - Section 2.4 could be more explicit about what \"large scale\" means. I.o.w. from a practical point of view, the method is only limited by approximate inference for Gaussian processes. Anno 2019 this is ... - The empirical section is particularly strong and contains a wide variety of experiments with detailed analysis. As a result, I think this is a good piece of scientific work that could be interesting to the wider community. Although I did not re-run the results, the authors do share full source code for their results.", "rating": "8: Accept", "reply_text": "Many thanks for your recognition of our work ! We really appreciate your encouraging words about our contributions . Please see below for our responses to your concerns : Q1 : \u201c The theoretical section 2.2 feels a bit rushed , I think it would be worth sharing the high level intuition behind some of the theory first before going into the details. \u201d A1 : Thanks for this constructive suggestion . We have rewritten Section 2.2 to make the high level intuition and motivation more clear . A big picture summary was added to the beginning of section , followed by an intuitive discussion of the approach . Prose has also been added to improve the flow of the section and clarify the predictions and conclusions drawn from the theoretical model . Q2 : \u201c Section 2.4 could be more explicit about what `` large scale '' means . I.o.w.from a practical point of view , the method is only limited by approximate inference for Gaussian processes . Anno 2019 this is ... \u201d A2 : Thanks for bringing up this point . Yes , the scalability of RIO is only limited by the approximate GP method . In order to quantitatively define what is a \u201c large scale \u201d dataset , we analyzed existing public regression datasets ( as of November 2019 ) . Based on the distribution of their sizes , a regression dataset can be considered \u201c large scale \u201d ( ~top 10 % in size ) if the product of its number of data points and number of features is larger than 1 million . We have added a clarification in Section 2.4 to make the definition of \u201c large scale \u201d more explicit . Among the datasets tested in this paper , 3 of them ( \u201c SC \u201d , \u201c CT \u201d , \u201c MSD \u201d ) fulfill this criterion , and they are ~1.7 million , ~20 million and ~46 million , respectively . RIO shows strong performance in all three \u201c large scale \u201d datasets , so the scalability of RIO is demonstrated ."}, {"review_id": "rkxNh1Stvr-3", "review_text": "The paper focuses on the model inference of neural networks (NN). The authors propose to use NN for the model, and fit the prediction residuals with a Gaussian process with input/output (IO) kernel. This kernel considers both input x and output y. The authors show that the NN+GP scheme has lower generalization error compared with solely using GP or NN to fit the model. Also, the IO kernel generalizes better than input kernel I, and output kernel O, in Gaussian process modeling. In experiments, the authors evaluate various methods in terms of several metrics to show that the proposed procedure gives better uncertainty estimation and more accurate point estimation. In general it is a good paper, with good applications. The motivation is clear. The key idea of this paper is pretty common in statistical inference. 1. In more practical settings we cannot assume that NN is always trained well. In this case, does the proposed method perform much worse than GP? 2. Is this the only proposal for fitting the residuals for uncertainty estimation? Is there any other similar approach? I would like to see more discussions on other related methods and how the idea is different. 3. Summarizing the whole procedure in an algorithm could make things clearer. ", "rating": "6: Weak Accept", "reply_text": "Thank you for your positive evaluation of our work . Please see our point-to-point responses to your comments : Q1 : \u201c In more practical settings we can not assume that NN is always trained well . In this case , does the proposed method perform much worse than GP ? \u201d A1 : No . The study did actually include several cases where the original NN performs poorly , and RIO still performed better than or comparably to GP . This result was not emphasized in the original paper ; we have made it clear in the revised version . In more details : We paid special attention to evaluating the robustness of RIO during the design of the experiments . As stated in the experimental setups , for each dataset ( except for MSD , in which the dataset split is strictly predefined by the provider ) , 100 independent runs are conducted . During each run , the dataset is randomly split , and the NN is randomly initialized . Moreover , we are using a standard training procedure without over-tuning that are commonly used by practitioners . All these steps enable us to cover different training situations and generate NNs with different qualities . The performance distributions of original NN and corresponding RIO/GP are plotted in Figure 3 in the original paper . From Figure 3 , the trained NNs show diverse performance in terms of prediction RMSE ( horizontal axis ) , and RIO is able to consistently improve the performance of NN into a level that is better or comparable to GP even though the original performance of NN is poor . For the datasets in which original NN performs much worse than GP , namely \u201c airfoil \u201d , \u201c CCPP \u201d and \u201c MSD \u201d , the performance after applying RIO becomes better than GP instead . More specifically , for \u201c airfoil \u201d , the original RMSEs of some NNs are above 5.5 ( dots on the right side ) while corresponding GP in the same runs only have RMSEs below 4.0 , applying RIO to these NNs achieves RMSEs below 3.5 . Similar pattern can be observed in \u201c CCPP \u201d . For \u201c MSD \u201d , although the original RMSEs of NN are above 17.0 in some cases , comparing to ~9.6 for GP , RIO is able to reduce these RMSEs to similar level ( ~9.8 ) as GP or even better ( ~9.4 ) . These experimental results demonstrate that RIO is still robust even in the cases where NN are not well trained . Q2 : \u201c Is this the only proposal for fitting the residuals for uncertainty estimation ? Is there any other similar approach ? I would like to see more discussions on other related methods and how the idea is different. \u201d A2 : We have done a thorough literature review , and to the best of our knowledge , this is the only work that fits residuals for uncertainty estimation . The unique characteristic of RIO is that it is designed as a supporting tool to augment pre-trained NNs . In contrast , all other existing methods are designed as independent models that need to be trained from scratch . Considering the popularity of NNs among practitioners and the lack of uncertainty information in NN predictions , we do think a tool that can be directly applied on top of pre-trained NNs provides practical value . We have expanded the discussions in \u201c Introduction \u201d section and \u201c Related Work \u201d section to emphasize this point . Q3 : \u201c Summarizing the whole procedure in an algorithm could make things clearer. \u201d A3 : Thanks for your constructive comment . We have added an algorithm in the Appendix ( Algorithm 1 in Section C ) that describes the procedure of RIO . We have added a note in the main paper to refer interested readers to the algorithm ."}], "0": {"review_id": "rkxNh1Stvr-0", "review_text": "# Summary The authors propose a method for post-hoc correction and predictive variance estimation for neural network models. The method fits a GP to the model residuals, and learns a composite kernel that combines two kernels defined on the input space and the model\u2019s output space (called RIO, R for residual, and IO for the input-output kernel). The authors suggest that residual means and variances at test points can then be calculated explicitly using predictive distributions from the GP. The authors run a large panel of experiments across a number of datasets, and compare to a number of methods that draw connections between neural networks and GP\u2019s. In addition, the full method is compared to a number of methods that utilize only some components of the full RIO method. In these experiments, the RIO method generally shows strong performance in both RMSE and NLPD compared to these baselines. # Feedback Overall, this is a neat method. It has the flavor of a number of other composite ML methods that have worked well in the past---e.g., boosting and platt scaling---but is different enough to stand on its own. The experimental results are quite promising. However, I am torn about the paper, because the theoretical discussion of the method is quite convoluted and seems either irrelevant or incorrect. I wish that the authors had spent more time with small demonstrations of what the procedure does in some simple settings. This would give practitioners considering the method far more intuition about when they would expect it to work and fail than the current theoretical discussion. ## Uncertainty Discussion is Lacking The motivation and discussion sell this method as an uncertainty quantification method, but almost all of the theoretical development revolves around prediction correction. The methods properties as an uncertainty quantification tool are underdeveloped. The only theoretical point made about uncertainty estimation is Theorem 2.7, which states that the scalar variance of the GP \u201cnugget\u201d is positively correlated with the variance of the NN\u2019s residuals. Providing a scalar summary of noise is not particularly compelling for a method advertised as a point-prediction uncertainty quantification method. In addition, it is not clear what probability distribution the \u201ccorrelation\u201d is defined over. The argument made in the proof seems quite obvious: if a GP is used to model a noisier process (i.e., residuals with a larger variance), it will in some cases classify that variability as independent noise. If the authors wanted to focus on the properties of their method as an uncertainty quantification tool, they could discuss the assumptions underlying the GP error estimates, and when they would be likely to diverge from practical properties like predictive interval coverage. For example, because the base NN predictor is treated as fixed, it seems that this method ignore uncertainty that stems from the NN fit due to random initialization. Likewise, it seems that this method would not quantify uncertainty from resampling the data and obtaining a new NN predictor. )The coverage experiments in the appendix seem to confirm this -- generally, the predictive intervals generally under-cover the predicted values.) It\u2019s fine if the method doesn\u2019t quantify these types of uncertainty, but discussion of these types of issues would be far more welcome than the current convoluted theory in Section 2. This discussion might not yield theorems, but it would give practitioners useful guidelines for deciding whether the particular scheme would likely work for this application. ## Problems with the Error Correction Argument The theory section, especially 2.2, was very difficult to parse. First, as a matter of style, a sequence of Lemma and Theorem statements are given without defining most of the notation used therein, and with almost no prose providing context or intuition. In the buildup to the theorems, it is also unclear which assertions about the decompositions of y_i are assumptions about the true data generating process, and which assertions are specifications of a particular GP model. The substance also has some issues. I think the intention in this section is to get to a rather simple variance decomposition of the labels y. The question is how much variation in y or the residual is represented in the posterior predictive mean of a particular GP. It seems reasonable that in some cases, the structure in the residual may be more amenable to modeling with a stationary GP than the structure in the raw labels y. It is not clear that all of the theoretical complexity here is necessary to make this point. Instead, the authors make a convoluted argument that attempts to establish that the errors from the NN + GP approach will be smaller under very general circumstances. The argument is phrased somewhat ambiguously (it is not clear exactly what is being assumed, and what is corresponds to the specification of a working model), but depending on how one reads this section, the argument makes statements that are either too broad to be correct, or too narrow to be relevant. The argument decomposes for the raw labels and the residuals into pieces that a GP can \u201ccapture\u201d or \u201crepresent\u201d, and parts that it cannot. The two equations are: y_i = f(x_i) + g(x_i) + \\xi_i R_i = (y_i - h_NN(x_i)) = r_f(x_i) + r_g(x_i) + \\xi_i f(.) and r_f(.) represent the portions of the label and residual processes, respectively, that the GP \"captures\". It is assumed that the GP will model this portion correctly, and leave the \u201cepsilon-indistinguishable\u201d portion g(.) or r_g(.) untouched. The argument then assumes that f(.) and r_f(.) will have proportional kernels, and so it is possible to show that the predictions of residuals based on r_f(.) will have smaller predictive variance than predictions based on f(.) as long as the variation represented by r_g(.) is smaller than the variation represented by g(.). On its face, this argument raises some red flags. Because h_NN(.) is allowed to be an arbitrary function, the argument here should be symmetric. Why can\u2019t we also get a guaranteed variance reduction by adding h_NN(.) to y rather than subtracting it? Perhaps some of this is captured in the parameter \\delta, which quantifies the reduction in variation represented in r_g(.) vs g(.), but the argument that the kernel of r_f(.) can be no larger than the kernel f(.) in terms of trace (that is, the proportionality constant \\alpha is not greater than 1) does not make sense. If h_NN(x_i) is simply -f(x_i), then these arguments would not go through. At the very least, conditions need to be articulated about the properties of h_NN(.). Some of the strangeness comes from the fact that this is a poor model of most prediction problems, where the main issue with fitting a GP is not \u201cindistinguishability\u201d, but misspecification. Consider a process y_i that is non-stationary; say g(.) has a linear trend in some component of x. A GP with a stationary covariance kernel fit to this process (such as RBF) will attempt to explain the variation due to the linear trend with a variance kernel that encodes long-range dependence. On the other hand, if this trend were removed by a base model like an NN, the residuals would have a very different structure (perhaps they would be stationary), and in this case, the GP would fit the data with a very different covariance kernel. Unfortunately, it does not seem like the formalism here can express a notion of misspecification at all. In the theory, it is assumed that the GP will only model the portion of the labels y_i for which it is property specified (in this case, f(.)). This generally does not occur in practice, as in the example above. It might be possible for this to apply in some circumstances, but the authors give no conditions (e.g., that the process y_i be stationary). Based on this assumption, the authors assert that the fitted GP to f(.) and r_f(.) will have the same covariance kernel parameters up to some proportionality constant \\alpha. Much of their theoretical argument depends on this proportionality. But this proportionality cannot apply in general, and again, no conditions are given for when we might expect this to hold. It would be far more compelling if the authors proposed the very standard approach to modeling data via covariance kernels, where one first models non-stationary portions of the data with a base model, then models the correlation in the residuals with something like a GP. This is the bread-and-butter approach in, say, timeseries analysis (see, e.g., the Shumway and Stoffer textbook https://www.stat.pitt.edu/stoffer/tsa4/tsa4.htm), and the approach in this paper could be framed similarly. ## Demos I Wish I Had Seen I wish the authors had presented some demonstrations of what the GP does to the fitted values of an NN. Giving a demonstration of how the output kernel modifies predicted values, for example, would give some nice intuition the value added by this portion. I suspect that this step essentially performs something like Platt scaling, but for continuous outcomes, by shrinking predictions together so that they better match the overall distribution of observed labels. Perhaps the mechanism is different. At any rate, it would be useful to understand where the information gain is coming from, and this would be far better expressed concretely in terms of a toy data example than the theoretical arguments that are given. ## Coverage Experiments I wish the coverage experiments evaluating predictive intervals were included in the main text. As far as uncertainty quantification evaluations go, coverage is one of the few assessments that does not rely on the model itself (unlike NPLD, which uses the model\u2019s own log-likelihood), and can be phrased as a concrete performance guarantee. Here, the goal for predictive intervals is to cover the true prediction value _at least as often_ as the nominal rate (95% intervals should cover the truth _at least_ 95% of the time), not merely that coverage be \u201cclose\u201d to the nominal rate. This asymmetric evaluation gives you a concrete guarantee that the uncertainty estimate is conservative. The coverage experiments show that this method quite systematically under-covers compared to the end-to-end SVGP method, which generally satisfies this coverage property. I think this is important information to include about the model, and generally I think this behavior results from the fact that uncertainty is not propagated from the NN fit. This should be presented clearly in the main text.", "rating": "6: Weak Accept", "reply_text": "Thanks for this thorough and detailed review of our work , particularly with regards to the theory . The overarching concern was that the motivation , details , and implications of the theory were unclear , and it would be more compelling if the detailed behaviors of RIO can be demonstrated using concrete examples . To address these concerns , we have added more concrete empirical demonstrations of the detailed behaviors of RIO , regarding both output correction and confidence interval coverage . We have also rewritten Section 2.2 in the newly uploaded version of the paper , aiming to clarify the assumptions , the motivation of each step , and the conclusions drawn . We believe this update addresses the overarching concern , and addresses many of the specific comments in the process . We will respond to your concerns regarding \u201c # # Demos I Wish I Had Seen \u201d and \u201c # # Coverage Experiments \u201d first , then reply to all your concerns related to theory . Q : comments within \u201c # # Demos I Wish I Had Seen \u201d section A : Thanks for these very insightful comments . We have added two empirical studies to analyze what RIO actually does during the correction of NN outputs . The first one demonstrates that RIO does n't always shrink predictions together , but instead performs different calibrations on each point in order to move the predictions closer to the ground truth . The second one demonstrates that most of these calibrations are indeed improvements . We have included detailed description of these studies in the appendix , and mention the conclusions in the main text . More details on the first study : In the first empirical analysis , we randomly pick a run for each tested dataset , and plot the distributions of ground truth labels ( outcomes ) , original NN predictions and predictions corrected after RIO . The results are summarized in Figure 9 of Appendix D.3 . Based on the results , it is clear that RIO is not simply shrinking predictions together . Instead , RIO tends to calibrate each NN prediction accordingly . The distribution of outputs after RIO calibration may be a shift , or shrinkage , or expansion , or even more complex modifications of the original NN predictions , depending on how different are NN predictions from ground truths . As a result , the distribution of RIO calibrated outputs are always closer to the distribution of ground truths . One interesting behavior can be observed for \u201c protein \u201d dataset ( row 3 , rightmost plot ) : after applying RIO , the range of whiskers shrunk and the outliers disappeared , but the box ( indicating 25 to 75 percentile of the data ) expanded . This behavior shows that RIO is actually trying to calibrate each point differently . To provide more details , the point-wise comparisons between NN outputs and RIO-corrected outputs for the same experimental runs as in Figure 9 are shown in Figure 10 of Appendix D.3 . From Figure 10 , RIO shows different calibration behaviors accordingly . If we compare the plots in Figure 10 to the corresponding ones in Figure 9 ( they are for the same run on the same dataset ) , it is clear that all these different calibration behaviors actually make sense , and they are generally leading to more accurate predictions of ground truths . More details on the second study : In the second empirical study , we define a new performance metric called \u201c improvement ratio \u201d ( IR ) , which is the ratio between number of successful corrections ( successfully reducing the error ) and total number of data points . For each run on each dataset , we calculate this IR value , and the distribution of IR values over 100 independent runs ( random dataset split except for MSD , random NN initialization and training ) on each dataset is plotted in Figure 11 of Appendix D.3 . According to the results , the IR values for RIO are above 0.5 in most cases . For 7 datasets , IR values are above 0.5 in all 100 independent runs . For some runs in \u201c yacht \u201d , \u201c ENB/h \u201d , \u201c CT \u201d , and \u201c MSD \u201d , the IR values are above 0.8 or even above 0.9 . All these observations show that RIO is making meaningful corrections instead of random perturbations . Results in Figure 11 also provides useful information for practitioners : Although not all RIO calibrations improve the result , most of them do . Q : comments within \u201c # # Coverage Experiments \u201d section A : Confidence interval ( CI ) coverage indeed is a concrete and straightforward performance metric , which is why we included the 95 % /90 % /68 % CI coverages for all algorithms in all datasets in the Appendix . However , after a deeper investigation , including an additional experiment ( Figure 6 , 7 and 8 in Appendix D.2 ) , we found this performance metric to be noisy and potentially misleading . Drawing conclusions from it requires lengthy qualifications ; given the page limits of the main text , we believe such discussions are better presented in the appendix . In contrast , NLPD loss is more reliable , which is why it is the primary measure in this paper . This choice is now explained in the main text , and a justification given in the appendix ."}, "1": {"review_id": "rkxNh1Stvr-1", "review_text": "This paper proposes a new framework (RIO) to estimate uncertainty in pretrained neural networks. For this purpose, RIO employs Gaussian Processes whose kernels are calculated by kernel functions of input and output samples and the corresponding target values. - The proposed approach is interesting and the initial results are promising. However, there are various major and minor problems with the paper: - The proposed method can be applied to any machine learning algorithm. It is not clear why you focus on employment of the proposed method for vanilla NNs. - Have you applied RIO for other learning algorithms as well? - Could you please explain more precisely, how you utilize which particular properties of NNs in RIO, and/or how RIO helps quantification and improvement of uncertainty of NNs particularly? - Following equation (7), you claim that \u201cIn other words, RIO not only adds uncertainty estimation to a standard NN\u2014it also makes its predictions more accurate, without any modification to its architecture or training\u201d. Could you please verify and justify how RIO makes predictions of NNs more accurate? In this statement, I guess that you consider the results given in Theorem 2.6. However, you should not that the error functions given in Theorem 2.6 are calculated in a cascaded manner, i.e., by applying a GP at the output of a NN. - The main proposal of the paper is that RIO makes it possible to estimate uncertainty in any pretrained standard NN. In order to verify that proposal, you should improve the experiments, esp. using larger datasets with larger neural networks, including deep neural networks. After Rebuttal: I read the comments of the other reviewers and response of the authors. Most of my questions were addressed in the rebuttal, and the paper was improved. However, there is still room to improve the paper with additional analysis using state-of-the-art algorithms on benchmark datasets, and to improve presentation of the work. Therefore, I improve my rating to Weak Accept.", "rating": "6: Weak Accept", "reply_text": "Thank you for your constructive comments . Please see our responses to each of your concerns below : Q1 : \u201c The proposed method can be applied to any machine learning algorithm . It is not clear why you focus on employment of the proposed method for vanilla NNs. \u201d A1 : RIO can indeed be applied to other machine learning algorithms , but we believe vanilla NNs are a good choice for this paper for two reasons : ( 1 ) As the first paper on RIO , it makes sense to focus it on the analysis and demonstration of RIO \u2019 s abilities without the complexity of multiple platforms , and ( 2 ) vanilla NNs are very common model used by practitioners , making the results relevant to many people . We have discussed the motivation and reasons for which we choose standard NN as the focus in the main paper . However , since it is insightful to also test the generality of RIO , we have added a whole set of experiments that instead use random forest models , as described in A2 below . In more details : 1 . Since this is the very first paper that introduces RIO , focusing on one widely used model allows us to do a thorough and deep investigation into the new approach , both theoretically and empirically . These detailed analysis and results should be very informative for practitioners who are using vanilla NNs . Including different approaches may lose this focus and depth . 2.Vanilla NN is arguably the most commonly used model among practitioners for making point predictions , but it also creates a lot of inconvenience and risks due to the lack of uncertainty information . Our target is to develop a tool that is practical and useful for the practitioner community , so choosing vanilla NN to demonstrate the effectiveness of RIO would be most appropriate as the first milestone . Q2 : \u201c Have you applied RIO for other learning algorithms as well ? \u201d A2 : We have added the experimental results on Random Forests for all RIO variants and all datasets . Please see Table 7 in Appendix D.6 for full details of the experiments and results . To summarize , RIO performs the best or equals the best method ( based on statistical tests ) in 9 out of 12 datasets in terms of both RMSE and NLPD . In addition , RIO significantly improves the performance of original RF in 11 out of 12 datasets . These empirical results verifies the robustness and broad applicability of RIO . Full details of the results are included in the appendix , and we also referred to this as a concrete example when we discuss the extensibility of RIO in future work . Q3 : \u201c Could you please explain more precisely , how you utilize which particular properties of NNs in RIO , and/or how RIO helps quantification and improvement of uncertainty of NNs particularly ? \u201d A3 : We use the expressivity of NNs , which means that they can learn complex structure that a GP would treat as noise . This point has been clarified in the revised version of Section 2.2 . Similarly , RIO is particularly well-suited for NNs , because their expressivity makes it difficult to quantify their uncertainty with simpler analytical methods . However , RIO can be easily extended to other kinds of regression models as well , e.g. , the new experiments in Appendix D.6 show that they work with random forests ."}, "2": {"review_id": "rkxNh1Stvr-2", "review_text": "This paper solves an interesting scientific and applied problem: can we construct an algorithm to predict uncertainties without re-training/modifying existing neural network training algos? The authors propose a novel technique (called RIO) which leverages existing neural network but use both the input as well as the output of the neural net as an input to a GP which regresses on the residual error of the neural network. The authors describe the theoretical foundations as well as show empirical results on multiple datasets. My thoughts on the paper: - The paper is well written and from section 2.1 it is clear how one could re-produce their method. - The theoretical section 2.2 feels a bit rushed, I think it would be worth sharing the high level intuition behind some of the theory first before going into the details. - Section 2.4 could be more explicit about what \"large scale\" means. I.o.w. from a practical point of view, the method is only limited by approximate inference for Gaussian processes. Anno 2019 this is ... - The empirical section is particularly strong and contains a wide variety of experiments with detailed analysis. As a result, I think this is a good piece of scientific work that could be interesting to the wider community. Although I did not re-run the results, the authors do share full source code for their results.", "rating": "8: Accept", "reply_text": "Many thanks for your recognition of our work ! We really appreciate your encouraging words about our contributions . Please see below for our responses to your concerns : Q1 : \u201c The theoretical section 2.2 feels a bit rushed , I think it would be worth sharing the high level intuition behind some of the theory first before going into the details. \u201d A1 : Thanks for this constructive suggestion . We have rewritten Section 2.2 to make the high level intuition and motivation more clear . A big picture summary was added to the beginning of section , followed by an intuitive discussion of the approach . Prose has also been added to improve the flow of the section and clarify the predictions and conclusions drawn from the theoretical model . Q2 : \u201c Section 2.4 could be more explicit about what `` large scale '' means . I.o.w.from a practical point of view , the method is only limited by approximate inference for Gaussian processes . Anno 2019 this is ... \u201d A2 : Thanks for bringing up this point . Yes , the scalability of RIO is only limited by the approximate GP method . In order to quantitatively define what is a \u201c large scale \u201d dataset , we analyzed existing public regression datasets ( as of November 2019 ) . Based on the distribution of their sizes , a regression dataset can be considered \u201c large scale \u201d ( ~top 10 % in size ) if the product of its number of data points and number of features is larger than 1 million . We have added a clarification in Section 2.4 to make the definition of \u201c large scale \u201d more explicit . Among the datasets tested in this paper , 3 of them ( \u201c SC \u201d , \u201c CT \u201d , \u201c MSD \u201d ) fulfill this criterion , and they are ~1.7 million , ~20 million and ~46 million , respectively . RIO shows strong performance in all three \u201c large scale \u201d datasets , so the scalability of RIO is demonstrated ."}, "3": {"review_id": "rkxNh1Stvr-3", "review_text": "The paper focuses on the model inference of neural networks (NN). The authors propose to use NN for the model, and fit the prediction residuals with a Gaussian process with input/output (IO) kernel. This kernel considers both input x and output y. The authors show that the NN+GP scheme has lower generalization error compared with solely using GP or NN to fit the model. Also, the IO kernel generalizes better than input kernel I, and output kernel O, in Gaussian process modeling. In experiments, the authors evaluate various methods in terms of several metrics to show that the proposed procedure gives better uncertainty estimation and more accurate point estimation. In general it is a good paper, with good applications. The motivation is clear. The key idea of this paper is pretty common in statistical inference. 1. In more practical settings we cannot assume that NN is always trained well. In this case, does the proposed method perform much worse than GP? 2. Is this the only proposal for fitting the residuals for uncertainty estimation? Is there any other similar approach? I would like to see more discussions on other related methods and how the idea is different. 3. Summarizing the whole procedure in an algorithm could make things clearer. ", "rating": "6: Weak Accept", "reply_text": "Thank you for your positive evaluation of our work . Please see our point-to-point responses to your comments : Q1 : \u201c In more practical settings we can not assume that NN is always trained well . In this case , does the proposed method perform much worse than GP ? \u201d A1 : No . The study did actually include several cases where the original NN performs poorly , and RIO still performed better than or comparably to GP . This result was not emphasized in the original paper ; we have made it clear in the revised version . In more details : We paid special attention to evaluating the robustness of RIO during the design of the experiments . As stated in the experimental setups , for each dataset ( except for MSD , in which the dataset split is strictly predefined by the provider ) , 100 independent runs are conducted . During each run , the dataset is randomly split , and the NN is randomly initialized . Moreover , we are using a standard training procedure without over-tuning that are commonly used by practitioners . All these steps enable us to cover different training situations and generate NNs with different qualities . The performance distributions of original NN and corresponding RIO/GP are plotted in Figure 3 in the original paper . From Figure 3 , the trained NNs show diverse performance in terms of prediction RMSE ( horizontal axis ) , and RIO is able to consistently improve the performance of NN into a level that is better or comparable to GP even though the original performance of NN is poor . For the datasets in which original NN performs much worse than GP , namely \u201c airfoil \u201d , \u201c CCPP \u201d and \u201c MSD \u201d , the performance after applying RIO becomes better than GP instead . More specifically , for \u201c airfoil \u201d , the original RMSEs of some NNs are above 5.5 ( dots on the right side ) while corresponding GP in the same runs only have RMSEs below 4.0 , applying RIO to these NNs achieves RMSEs below 3.5 . Similar pattern can be observed in \u201c CCPP \u201d . For \u201c MSD \u201d , although the original RMSEs of NN are above 17.0 in some cases , comparing to ~9.6 for GP , RIO is able to reduce these RMSEs to similar level ( ~9.8 ) as GP or even better ( ~9.4 ) . These experimental results demonstrate that RIO is still robust even in the cases where NN are not well trained . Q2 : \u201c Is this the only proposal for fitting the residuals for uncertainty estimation ? Is there any other similar approach ? I would like to see more discussions on other related methods and how the idea is different. \u201d A2 : We have done a thorough literature review , and to the best of our knowledge , this is the only work that fits residuals for uncertainty estimation . The unique characteristic of RIO is that it is designed as a supporting tool to augment pre-trained NNs . In contrast , all other existing methods are designed as independent models that need to be trained from scratch . Considering the popularity of NNs among practitioners and the lack of uncertainty information in NN predictions , we do think a tool that can be directly applied on top of pre-trained NNs provides practical value . We have expanded the discussions in \u201c Introduction \u201d section and \u201c Related Work \u201d section to emphasize this point . Q3 : \u201c Summarizing the whole procedure in an algorithm could make things clearer. \u201d A3 : Thanks for your constructive comment . We have added an algorithm in the Appendix ( Algorithm 1 in Section C ) that describes the procedure of RIO . We have added a note in the main paper to refer interested readers to the algorithm ."}}