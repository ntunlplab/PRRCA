{"year": "2019", "forum": "r1gl7hC5Km", "title": "Adapting Auxiliary Losses Using Gradient Similarity", "decision": "Reject", "meta_review": "This paper tackles the problem of using auxiliary losses to help regularize and aid the learning of a \"goal\" task. The approach proposes avoiding the learning of irrelevant or contradictory details from the auxiliary task at the expense of the \"goal\" tasks by observing cosine similarity between the auxiliary and main tasks and ignore those gradients which are too dissimilar. \n\nTo justify such a setup one must first show that such negative interference occurs in practice, warranting explicit attention. Then one must show that their algorithm effectively mitigates this interference and at the same time provides some useful signal in combination with the main learning objective. \n\nDuring the review process there was a significant discussion as to whether the proposed approach sufficiently justified its need and usefulness as defined above. One major point of contention is whether to compare against the multi-task literature. The authors claim that prior multi-task learning literature is out of scope of this work since their goal is not to measure performance on all tasks used during learning. However, this claim does not invalidate the reviewer's request for comparison against multi-task learning work. In fact, the authors *should* verify that their method outperforms state-of-the-art multi-task learning methods. Not because they too are studying performance across all tasks, but because their method which knows to prioritize one task during training should certainly outperform the learning paradigms which have no special preference to one of the tasks. \n\nA main issue with the current draft centers around the usefulness of the proposed algorithm. First, whether the gradient co-sine similarity is a necessary condition to avoid negative interference and 2) to show at least empirically that auxiliary losses do offer improved performance over optimizing the goal task alone. Based on the experiments now available the answers to these questions remains unclear and thus the paper is not yet recommended for publication.", "reviews": [{"review_id": "r1gl7hC5Km-0", "review_text": "The paper is addressing the problem of a specific multi-task learning setup such that there are two tasks namely main task and auxiliary task. Auxiliary task is used for the sole purpose of helping the main one. In other words, auxiliary task performance is not of interest. The simple and sensible approach proposed in the paper is using cosine similarity between the gradients of two loss functions and incorporating the auxiliary one if it is positively aligned with the main gradient. Authors suggest to further scale loss functions using the cosine similarity but it only experiments with the simpler case of binary decision of using both gradients or only the main one. Authors provide a convergence guarantee (without any convergence rate) by simply extending the convergence of gradient method. The paper is definitely addressing an important problem as the authors cite many previous work which uses the setup of set of auxiliary tasks helping a main one. The method is simple and easy to implement. Hence, it has a potential to be useful for the community. One major issue for me is the experimental setup. The authors cite many interesting, realistic and practical setups (Zhang et al., 2016; Jaderberg et al., 2017; Mirowski et al., 2017; Papoudakis et al., 2018), but do not use any of these setups in their experiments. Instead, paper uses set of toy experiments. This is very puzzling to me as all these papers set existing baselines for interesting problems which authors can easily compare. I think the paper needs to be experimented and compared with these established methods. Another major issue is the weak multi-task learning baseline used in the paper. There have been many interesting developments in adaptive scaling of multiple loss functions in the literature. However, paper does not compare with them. Example of these methods are: [GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks, ICML 2018] and [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics, CVPR 2018]. Although these methods addresses the case of all tasks being important, it is a valid baseline and need to be compared. Similar to my first points, these papers also use very realistic and interesting experiments which would fit better than the toy experiments in the paper. Final major issue is the fact that experimental results are suggesting the method is not effective. In ImageNet experiment, auxiliary tasks actually hurt the final performance as the single task is better than all methods including the proposed one. Proposed method does not guarantee that auxiliary tasks will have no harm. The GridWorld experiment is sort of a sanity check to me as it is very hand-crafted. For Breakout experiment, single task actually outperforms all baselines and this means the proposed method results in a harm similar to ImageNet case. For Breakout+MSPacMan experiment, multi task and the proposed method performs almost exactly same. I do not get why the performance on Breakout is relevant for this case since it is not a main task. The paper clearly states that only performance of an interest is the main one which is MSPacMan in this case. Also, in this experiment clearly all methods are still learning as the curve did not plateau yet. I am curious, why the learning is stop there. I do not think we need the method to be effective to be published; but, the negative result should be explained properly. MINOR NITPICKS - Algorithm 1&2 are crucial to understand the paper, they should be in main text - ImageNet class IDs change between years. So, actual wordnet IDs or class names is a better thing to state - What happens if there are multiple auxiliary tasks? - Does the theory still hold for loss functions which are not Lipschitz as the Cauchy's gradient method requires that for convergence In summary, the paper is proposing a sensible method for an important problem. However, it is only tested for toy problems although there are interesting existing setups which would be ideal for the method to be tested. Moreover, it is only compared with the most-naive multi task learning baselines. Even this limited experimental setup does not confirm what the paper is claiming (using auxiliary tasks only when they help). And the paper fails to explain this failure cases. The method needs to be experimented with a more realistic setup with more realistic baselines. ------ After rebuttal: I gave detailed responses to each part of the rebuttal below. Here is the summary: Although the response addresses some of my concerns. There are still major issues with the experimental study. 1) there are existing, relevant and well-studied multi-task setups with negative interference. Method should be experimented with some of those setups. 2) Multi-task baseline in the paper is naive and far from state-of-the-art. Paper need strong baselines as discussed. Hence, I am keeping my score. Paper needs to be improved with a stronger experimental study and need to be re-submitted.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank Reviewer 3 for their detailed feedback ! We have clarified our problem setup in Section 1.1 : The goal is to devise an algorithm that can automatically ( i ) leverage the auxiliary task when it is helpful ( e.g.learn faster ) and ( ii ) block negative transfer when the auxiliary task is not helpful ( i.e.recover the performance of training only on the main task ) . We have updated captions of figures to clarify our experimental setup . We address the major issues one by one . 1. \u201c One major issue for me is the experimental setup. \u201d We handpicked these tasks because they show rich behaviors in a way that * the auxiliary task is helpful to the main task initially , but hurt later on * -- -this is the setting we care about and our adaptive mechanism is reasonable under this scenario . In contrast , the established methods choose their auxiliary tasks to be the ones that always help . These tasks are usually simple , converge fast , and there is no significant negative interference that can happen during the training phase . For example , the auxiliary task in Mirowski et al.is a depth prediction task which predicts an extremely low dimensional version of the depth map , instead of trying to construct the full depth map -- -even though the latter might seems to be a more natural task . Our approach is meant to reduce the pressure on finding a suitable auxiliary task ; if a task always helps , then simple multi-task could already work and there is no need for using our method to compute their gradient cosine similarities . We respectfully disagree that all of our experiments are \u201c toy \u201d . We experimented with ImageNet dataset , which even in the form of our modified binary task version is not an easy task . We also tested in the Atari domain , which is a difficult task for RL agents . Given the variety of our experimental designs ( cross-domain and cross-task , supervised learning and reinforcement learning ) , we think it \u2019 s unfair to say that \u201c paper uses set of toy experiments \u201d ."}, {"review_id": "r1gl7hC5Km-1", "review_text": "The paper studies the problem of how to measure the similarity between an auxiliary task and the target tasks, and further decide when to use the auxiliary loss in the training epoches. The proposed cosine simiarity based soft gradient update scheme seems reasonable. The author(s) also experiment the proposed method on three tasks, one supervised learning image classification task, two reinforcement learning tasks, and show improved results respectively. The paper is in generally well-written. However it would be great if the concerns below could be addressed or discussed in the paper. 1) The proposed method is based on the intuition: if the gradients of the target and auxiliary loss are in the same direction, the auxiliary loss will help the main/target task. Some examples are showed in the paper to support this argument, however it would be helpful if there is some theoritical gurantee on this. So a more general question would be: rather than define the similarity measure to measure the gradient similarity of the target and auxiliary loss, it would be more useful to try to learn or define whether the auxiliary task is good for the target task beforehand. 2) In proposition 1, if the concerns in 1) are reasonable, the equation would be doubtful. For example, one can simply try (g(target task)-g(auxiliary task)) in the equation. Besides, more similarity metrics are expected to be compared here to show why cosine is the optimal choice. For example, L2. 3) Too much content is embedded in appendix, for example, it would be helpful to move the two algorithms or at least discussed the two variants of the gradient updates in the experimental section. Since it is not clear to me whether hard cosine mixing or soft cosine mixing is used to produce the results in the image classification task. 4) In the image classification task, a quantitative analysis would be more convincing since the semantics of the near and far is really hard to define. Even the authors can show a vague definition, it will be helpful. In figure 2b), why the cosine method performs worse compared the other methods before 5000 in x-axis? Is this because of the noise of the gradient? Plus, what is the optimizer used in this experiment? 5) In the first reinforcement learning task, since cosine similarity is the only method used to measure the similarity between auxiliary task and the target task, it would be useful to show the comparison among other task relatedness method in reinforcement learning. For 'This is expected as the noise in the gradients make it hard to measure if the two tasks are a good fit or not', why is this? Since cosine similarity would be zero if the two tasks are not good fit.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 1 for the feedback ! We have revised the paper based on your suggestions and we also address your concerns individually below . In the first review point , the reviewer asked for a theoretical guarantee of our method . We have shown in section 2 that our method has a convergence guarantee ( although there is no guarantee of an improvement of the speed of convergence ) . Proof details were presented in Appendix A.1 . We agree that defining the usefulness of an auxiliary task beforehand is an interesting future direction . We believe that the level of usefulness has to be conditioned on the model ( or at least a family of models ) and potentially on the initialization of parameters . In some regard , our proposed approach relies on conditioning on all of this information ( e.g.the value of theta ) and it would be interesting if some of this can be efficiently marginalized away . For the second review point , it is unclear to us that another metric ( and definitely not true for L2 ) can guarantee convergence on the task of interest . Based on our theoretical proof in section 2 , cosine similarity is the metric for which we can prove the convergence and hence the only one that is applicable for our approach . In particular , we believe that instead of thinking of cosine as a metric , a fruitful perspective is to see it as a projection of the gradient of the auxiliary loss in the subspace of decent directions of the main loss . For the third review point , we have revised our paper and included Algorithm 1 in the main text . We will move some more content from appendix to the main text for the final camera ready . For the fourth review point , we did not identify the near or far class pairs in ImageNet based on the semantic similarity of class names . Instead , we used two semantic quantitative measures , the lowest common ancestor ( LCA ) in the tree hierarchy and the Frechet Inception Distance ( FID ) of pre-trained image embeddings . The procedure is described briefly in section 3.1 and detailed in Appendix E. We believe they have quantitatively defined a good similarity metric for our setting . In figure 2b , our cosine method did not perform worse before step 5000 . In fact , the cosine method has shown a jumpstart at the beginning of training compared to the other methods . We used RMSProp with momentum as the optimizer for image classification tasks . For the fifth review point , we are not sure what does the reviewer mean by \u201c other relatedness method in reinforcement learning \u201d . As mentioned in section 4 , to the best of our knowledge , so far there has not been a working method that could quantify task relatedness in RL ( Carroll and Seppi , 2005 ; Ammar et al. , 2014 ) . We would appreciate more suggestions from the reviewer on this . Regarding the reviewer \u2019 s question about noise in gradient , we have explained this in footnote 4 of our paper : \u201c ... we compute cosine similarity between a distillation gradient and a single sample of the policy gradient estimator , meaning that we are using a high variance estimate of the similarity ... \u201d . Specifically , in this RL experiment of distilling then transfer between the * same * task , the noise of the gradient in a single sample makes the tasks less similar -- -but they are actually the same ( e.g. , their cosine similarity should be very close to 1 , but due to the noise , it could be much lower than 1 for a single sample ) ."}, {"review_id": "r1gl7hC5Km-2", "review_text": "The paper proposes a method for using auxiliary tasks to support the optimization with respect to a main task. In particular, the method assumes the existence of a loss function for the main task that we are interested in, and a loss function for an auxiliary task that shares at least some of the parameters with the main loss function. When optimizing for the main loss function, the gradient of the auxiliary loss function is also used to update the shared parameters in cases of high cosine similarity with the main task. The method is demonstrated on image classification and a few reinforcement learning settings. The idea of the paper is simple, and the method has a nice property of (if ignoring some caveats) guaranteeing steps that are directionally correct with respect to the main task. In that sense it is useful in practice, as it limits the potential damage the auxiliary task does to the optimization of the main task. As the authors also note, the method suffers from some drawbacks. Although the method limits the negative effect of the auxiliary task on the optimization of the main loss function, it can still slow down optimization if the auxiliary task is not well chosen. In that sense, the method is no silver bullet. In addition, the method seems fairly computationally expensive (it would be interesting to understand how much it slows down an update, I would assume the added complexity is roughly a constant multiplier). However, as an alternative to naively adding an auxiliary task, the proposed method is a welcome addition to the tool box of practitioners. Although the experiments presented in the paper are quite different from each other, I would have wished for even more experiments. The reason is that as the method does not guarantee faster convergence, its applicability is mainly an empirical question. Especially experiments where auxiliary tasks have been used before would be interesting to test with the only addition being introducing the method proposed. The paper is generally well written and the results are fairly clearly presented. As a minor comment, the authors might want to check that articles (such as \"the\") are not missing in the text. All in all, the main merit of the proposed method is its conceptual simplicity and easy to understand value in practical applications where an auxiliary loss function is available. The method also seems to work well enough in the experiments presented.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 2 for the feedback ! Regarding the reviewer \u2019 s concern on computation expenses of our method , our method does not add expensive computation because the only additional step is to compute a one-step cosine similarity between gradients . Since computing cosine similarity is of O ( D ) time complexity where D is the dimensionality of the shared parameters , it is just a constant multiplier , as already noted by the reviewer . Regarding the reviewer \u2019 s suggestion on running more experiments : we believe that our experiments support our main claims and as the reviewer noted , we already report a diverse set of experiments . For the suggestion of \u201c experiments where auxiliary tasks have been used before would be interesting to test with the only addition being introducing the method proposed. \u201d , note that this may not be necessarily the best setup to illustrate our method as some of the prior work could have selected tasks such that the auxiliary task always helps ( i.e.the cosine similarity is always greater than 0 ) . Also the problem setup and motivations are slightly different in some of the prior work . For example , in Mirowski et al. , the use of depth prediction task as the auxiliary task was meant to assist \u201c representation learning \u201d , which is different from the goal of our method that the auxiliary task seeks \u201c alignment \u201d with the main task in their gradient space ( e.g. , in the RL GridWorld task , our setting has no representation learning at all since policies are tabular ) . We believe that this method is a useful addition to the tool box ( as the reviewer also observed ) and opens up the possibilities of using auxiliary tasks which may help initially but hurt in the end . We hope that the simplicity of our method will encourage the community to try these on other domains and investigate extensions that further improve performance . Thanks for pointing out the writing mistakes . We have fixed them in the revised version ."}], "0": {"review_id": "r1gl7hC5Km-0", "review_text": "The paper is addressing the problem of a specific multi-task learning setup such that there are two tasks namely main task and auxiliary task. Auxiliary task is used for the sole purpose of helping the main one. In other words, auxiliary task performance is not of interest. The simple and sensible approach proposed in the paper is using cosine similarity between the gradients of two loss functions and incorporating the auxiliary one if it is positively aligned with the main gradient. Authors suggest to further scale loss functions using the cosine similarity but it only experiments with the simpler case of binary decision of using both gradients or only the main one. Authors provide a convergence guarantee (without any convergence rate) by simply extending the convergence of gradient method. The paper is definitely addressing an important problem as the authors cite many previous work which uses the setup of set of auxiliary tasks helping a main one. The method is simple and easy to implement. Hence, it has a potential to be useful for the community. One major issue for me is the experimental setup. The authors cite many interesting, realistic and practical setups (Zhang et al., 2016; Jaderberg et al., 2017; Mirowski et al., 2017; Papoudakis et al., 2018), but do not use any of these setups in their experiments. Instead, paper uses set of toy experiments. This is very puzzling to me as all these papers set existing baselines for interesting problems which authors can easily compare. I think the paper needs to be experimented and compared with these established methods. Another major issue is the weak multi-task learning baseline used in the paper. There have been many interesting developments in adaptive scaling of multiple loss functions in the literature. However, paper does not compare with them. Example of these methods are: [GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks, ICML 2018] and [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics, CVPR 2018]. Although these methods addresses the case of all tasks being important, it is a valid baseline and need to be compared. Similar to my first points, these papers also use very realistic and interesting experiments which would fit better than the toy experiments in the paper. Final major issue is the fact that experimental results are suggesting the method is not effective. In ImageNet experiment, auxiliary tasks actually hurt the final performance as the single task is better than all methods including the proposed one. Proposed method does not guarantee that auxiliary tasks will have no harm. The GridWorld experiment is sort of a sanity check to me as it is very hand-crafted. For Breakout experiment, single task actually outperforms all baselines and this means the proposed method results in a harm similar to ImageNet case. For Breakout+MSPacMan experiment, multi task and the proposed method performs almost exactly same. I do not get why the performance on Breakout is relevant for this case since it is not a main task. The paper clearly states that only performance of an interest is the main one which is MSPacMan in this case. Also, in this experiment clearly all methods are still learning as the curve did not plateau yet. I am curious, why the learning is stop there. I do not think we need the method to be effective to be published; but, the negative result should be explained properly. MINOR NITPICKS - Algorithm 1&2 are crucial to understand the paper, they should be in main text - ImageNet class IDs change between years. So, actual wordnet IDs or class names is a better thing to state - What happens if there are multiple auxiliary tasks? - Does the theory still hold for loss functions which are not Lipschitz as the Cauchy's gradient method requires that for convergence In summary, the paper is proposing a sensible method for an important problem. However, it is only tested for toy problems although there are interesting existing setups which would be ideal for the method to be tested. Moreover, it is only compared with the most-naive multi task learning baselines. Even this limited experimental setup does not confirm what the paper is claiming (using auxiliary tasks only when they help). And the paper fails to explain this failure cases. The method needs to be experimented with a more realistic setup with more realistic baselines. ------ After rebuttal: I gave detailed responses to each part of the rebuttal below. Here is the summary: Although the response addresses some of my concerns. There are still major issues with the experimental study. 1) there are existing, relevant and well-studied multi-task setups with negative interference. Method should be experimented with some of those setups. 2) Multi-task baseline in the paper is naive and far from state-of-the-art. Paper need strong baselines as discussed. Hence, I am keeping my score. Paper needs to be improved with a stronger experimental study and need to be re-submitted.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank Reviewer 3 for their detailed feedback ! We have clarified our problem setup in Section 1.1 : The goal is to devise an algorithm that can automatically ( i ) leverage the auxiliary task when it is helpful ( e.g.learn faster ) and ( ii ) block negative transfer when the auxiliary task is not helpful ( i.e.recover the performance of training only on the main task ) . We have updated captions of figures to clarify our experimental setup . We address the major issues one by one . 1. \u201c One major issue for me is the experimental setup. \u201d We handpicked these tasks because they show rich behaviors in a way that * the auxiliary task is helpful to the main task initially , but hurt later on * -- -this is the setting we care about and our adaptive mechanism is reasonable under this scenario . In contrast , the established methods choose their auxiliary tasks to be the ones that always help . These tasks are usually simple , converge fast , and there is no significant negative interference that can happen during the training phase . For example , the auxiliary task in Mirowski et al.is a depth prediction task which predicts an extremely low dimensional version of the depth map , instead of trying to construct the full depth map -- -even though the latter might seems to be a more natural task . Our approach is meant to reduce the pressure on finding a suitable auxiliary task ; if a task always helps , then simple multi-task could already work and there is no need for using our method to compute their gradient cosine similarities . We respectfully disagree that all of our experiments are \u201c toy \u201d . We experimented with ImageNet dataset , which even in the form of our modified binary task version is not an easy task . We also tested in the Atari domain , which is a difficult task for RL agents . Given the variety of our experimental designs ( cross-domain and cross-task , supervised learning and reinforcement learning ) , we think it \u2019 s unfair to say that \u201c paper uses set of toy experiments \u201d ."}, "1": {"review_id": "r1gl7hC5Km-1", "review_text": "The paper studies the problem of how to measure the similarity between an auxiliary task and the target tasks, and further decide when to use the auxiliary loss in the training epoches. The proposed cosine simiarity based soft gradient update scheme seems reasonable. The author(s) also experiment the proposed method on three tasks, one supervised learning image classification task, two reinforcement learning tasks, and show improved results respectively. The paper is in generally well-written. However it would be great if the concerns below could be addressed or discussed in the paper. 1) The proposed method is based on the intuition: if the gradients of the target and auxiliary loss are in the same direction, the auxiliary loss will help the main/target task. Some examples are showed in the paper to support this argument, however it would be helpful if there is some theoritical gurantee on this. So a more general question would be: rather than define the similarity measure to measure the gradient similarity of the target and auxiliary loss, it would be more useful to try to learn or define whether the auxiliary task is good for the target task beforehand. 2) In proposition 1, if the concerns in 1) are reasonable, the equation would be doubtful. For example, one can simply try (g(target task)-g(auxiliary task)) in the equation. Besides, more similarity metrics are expected to be compared here to show why cosine is the optimal choice. For example, L2. 3) Too much content is embedded in appendix, for example, it would be helpful to move the two algorithms or at least discussed the two variants of the gradient updates in the experimental section. Since it is not clear to me whether hard cosine mixing or soft cosine mixing is used to produce the results in the image classification task. 4) In the image classification task, a quantitative analysis would be more convincing since the semantics of the near and far is really hard to define. Even the authors can show a vague definition, it will be helpful. In figure 2b), why the cosine method performs worse compared the other methods before 5000 in x-axis? Is this because of the noise of the gradient? Plus, what is the optimizer used in this experiment? 5) In the first reinforcement learning task, since cosine similarity is the only method used to measure the similarity between auxiliary task and the target task, it would be useful to show the comparison among other task relatedness method in reinforcement learning. For 'This is expected as the noise in the gradients make it hard to measure if the two tasks are a good fit or not', why is this? Since cosine similarity would be zero if the two tasks are not good fit.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 1 for the feedback ! We have revised the paper based on your suggestions and we also address your concerns individually below . In the first review point , the reviewer asked for a theoretical guarantee of our method . We have shown in section 2 that our method has a convergence guarantee ( although there is no guarantee of an improvement of the speed of convergence ) . Proof details were presented in Appendix A.1 . We agree that defining the usefulness of an auxiliary task beforehand is an interesting future direction . We believe that the level of usefulness has to be conditioned on the model ( or at least a family of models ) and potentially on the initialization of parameters . In some regard , our proposed approach relies on conditioning on all of this information ( e.g.the value of theta ) and it would be interesting if some of this can be efficiently marginalized away . For the second review point , it is unclear to us that another metric ( and definitely not true for L2 ) can guarantee convergence on the task of interest . Based on our theoretical proof in section 2 , cosine similarity is the metric for which we can prove the convergence and hence the only one that is applicable for our approach . In particular , we believe that instead of thinking of cosine as a metric , a fruitful perspective is to see it as a projection of the gradient of the auxiliary loss in the subspace of decent directions of the main loss . For the third review point , we have revised our paper and included Algorithm 1 in the main text . We will move some more content from appendix to the main text for the final camera ready . For the fourth review point , we did not identify the near or far class pairs in ImageNet based on the semantic similarity of class names . Instead , we used two semantic quantitative measures , the lowest common ancestor ( LCA ) in the tree hierarchy and the Frechet Inception Distance ( FID ) of pre-trained image embeddings . The procedure is described briefly in section 3.1 and detailed in Appendix E. We believe they have quantitatively defined a good similarity metric for our setting . In figure 2b , our cosine method did not perform worse before step 5000 . In fact , the cosine method has shown a jumpstart at the beginning of training compared to the other methods . We used RMSProp with momentum as the optimizer for image classification tasks . For the fifth review point , we are not sure what does the reviewer mean by \u201c other relatedness method in reinforcement learning \u201d . As mentioned in section 4 , to the best of our knowledge , so far there has not been a working method that could quantify task relatedness in RL ( Carroll and Seppi , 2005 ; Ammar et al. , 2014 ) . We would appreciate more suggestions from the reviewer on this . Regarding the reviewer \u2019 s question about noise in gradient , we have explained this in footnote 4 of our paper : \u201c ... we compute cosine similarity between a distillation gradient and a single sample of the policy gradient estimator , meaning that we are using a high variance estimate of the similarity ... \u201d . Specifically , in this RL experiment of distilling then transfer between the * same * task , the noise of the gradient in a single sample makes the tasks less similar -- -but they are actually the same ( e.g. , their cosine similarity should be very close to 1 , but due to the noise , it could be much lower than 1 for a single sample ) ."}, "2": {"review_id": "r1gl7hC5Km-2", "review_text": "The paper proposes a method for using auxiliary tasks to support the optimization with respect to a main task. In particular, the method assumes the existence of a loss function for the main task that we are interested in, and a loss function for an auxiliary task that shares at least some of the parameters with the main loss function. When optimizing for the main loss function, the gradient of the auxiliary loss function is also used to update the shared parameters in cases of high cosine similarity with the main task. The method is demonstrated on image classification and a few reinforcement learning settings. The idea of the paper is simple, and the method has a nice property of (if ignoring some caveats) guaranteeing steps that are directionally correct with respect to the main task. In that sense it is useful in practice, as it limits the potential damage the auxiliary task does to the optimization of the main task. As the authors also note, the method suffers from some drawbacks. Although the method limits the negative effect of the auxiliary task on the optimization of the main loss function, it can still slow down optimization if the auxiliary task is not well chosen. In that sense, the method is no silver bullet. In addition, the method seems fairly computationally expensive (it would be interesting to understand how much it slows down an update, I would assume the added complexity is roughly a constant multiplier). However, as an alternative to naively adding an auxiliary task, the proposed method is a welcome addition to the tool box of practitioners. Although the experiments presented in the paper are quite different from each other, I would have wished for even more experiments. The reason is that as the method does not guarantee faster convergence, its applicability is mainly an empirical question. Especially experiments where auxiliary tasks have been used before would be interesting to test with the only addition being introducing the method proposed. The paper is generally well written and the results are fairly clearly presented. As a minor comment, the authors might want to check that articles (such as \"the\") are not missing in the text. All in all, the main merit of the proposed method is its conceptual simplicity and easy to understand value in practical applications where an auxiliary loss function is available. The method also seems to work well enough in the experiments presented.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 2 for the feedback ! Regarding the reviewer \u2019 s concern on computation expenses of our method , our method does not add expensive computation because the only additional step is to compute a one-step cosine similarity between gradients . Since computing cosine similarity is of O ( D ) time complexity where D is the dimensionality of the shared parameters , it is just a constant multiplier , as already noted by the reviewer . Regarding the reviewer \u2019 s suggestion on running more experiments : we believe that our experiments support our main claims and as the reviewer noted , we already report a diverse set of experiments . For the suggestion of \u201c experiments where auxiliary tasks have been used before would be interesting to test with the only addition being introducing the method proposed. \u201d , note that this may not be necessarily the best setup to illustrate our method as some of the prior work could have selected tasks such that the auxiliary task always helps ( i.e.the cosine similarity is always greater than 0 ) . Also the problem setup and motivations are slightly different in some of the prior work . For example , in Mirowski et al. , the use of depth prediction task as the auxiliary task was meant to assist \u201c representation learning \u201d , which is different from the goal of our method that the auxiliary task seeks \u201c alignment \u201d with the main task in their gradient space ( e.g. , in the RL GridWorld task , our setting has no representation learning at all since policies are tabular ) . We believe that this method is a useful addition to the tool box ( as the reviewer also observed ) and opens up the possibilities of using auxiliary tasks which may help initially but hurt in the end . We hope that the simplicity of our method will encourage the community to try these on other domains and investigate extensions that further improve performance . Thanks for pointing out the writing mistakes . We have fixed them in the revised version ."}}