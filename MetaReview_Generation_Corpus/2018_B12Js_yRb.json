{"year": "2018", "forum": "B12Js_yRb", "title": "Learning to Count Objects in Natural Images for Visual Question Answering", "decision": "Accept (Poster)", "meta_review": "Initially this paper received mixed reviews. After reading the author response, R1 and and R3 recommend acceptance.\n\nR2, who recommended rejecting the paper, did not participate in discussions, did not respond to author explanations, did not respond to AC emails, and did not submit a final recommendation. This AC does not agree with the concerns raised by R2 (e.g. I don't find this model to be unprincipled).\n\nThe concerns raised by R1 and R3 were important (especially e.g. comparisons to NMS) and the authors have done a good job adding the required experiments and providing explanations.\n\nPlease update the manuscript incorporating all feedback received here, including comparisons reported to the concurrent ICLR submission on counting. ", "reviews": [{"review_id": "B12Js_yRb-0", "review_text": " Summary: - This paper proposes a hand-designed network architecture on a graph of object proposals to perform soft non-maximum suppression to get object count. Contribution: - This paper proposes a new object counting module which operates on a graph of object proposals. Clarity: - The paper is well written and clarity is good. Figure 2 & 3 helps the readers understand the core algorithm. Pros: - De-duplication modules of inter and intra object edges are interesting. - The proposed method improves the baseline by 5% on counting questions. Cons: - The proposed model is pretty hand-crafted. I would recommend the authors to use something more general, like graph convolutional neural networks (Kipf & Welling, 2017) or graph gated neural networks (Li et al., 2016). - One major bottleneck of the model is that the proposals are not jointly finetuned. So if the proposals are missing a single object, this cannot really be counted. In short, if the proposals don\u2019t have 100% recall, then the model is then trained with a biased loss function which asks it to count all the objects even if some are already missing from the proposals. The paper didn\u2019t study what is the recall of the proposals and how sensitive the threshold is. - The paper doesn\u2019t study a simple baseline that just does NMS on the proposal domain. - The paper doesn\u2019t compare experiment numbers with (Chattopadhyay et al., 2017). - The proposed algorithm doesn\u2019t handle symmetry breaking when two edges are equally confident (in 4.2.2 it basically scales down both edges). This is similar to a density map approach and the problem is that the model doesn\u2019t develop a notion of instance. - Compared to (Zhou et al., 2017), the proposed model does not improve much on the counting questions. - Since the authors have mentioned in the related work, it would also be more convincing if they show experimental results on CL Conclusion: - I feel that the motivation is good, but the proposed model is too hand-crafted. Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work (Chattopadhyay et al., 2017). Therefore I recommend reject. References: - Kipf, T.N., Welling, M., Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017. - Li, Y., Tarlow, D., Brockschmidt, M., Zemel, R. Gated Graph Sequence Neural Networks. ICLR 2016. Update: Thank you for the rebuttal. The paper is revised and I saw NMS baseline is added. I understood the reason not to compare with certain related work. The rebuttal is convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy. However, I am a little worried that the proposed model may be hard to reproduce due to its complexity and therefore choose to give a 6.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review . We are happy to see that you think the paper is well written and that the deduplication steps in the module are interesting . Given the aptness of your comments , it seems like you understand the paper better than you are giving yourself credit for . In summary to your main complaints : We argue that a hand-crafted approach is reasonable for the current state of VQA , NMS baselines will be supplied , and comparisons to ( Chattopadhyay et al. , 2017 ) are not useful . - Proposed model is pretty hand-crafted , would recommend the authors to use something more general , like graph convolutional neural networks . In summary , we think that with current VQA models , counting needs to be hand-crafted to some extent , hand-crafting counting has various useful properties , and that we tried a non-handcrafted approach similar to graph convolutional networks in the past without success . We think that with the current state of VQA models on real images , it is unreasonable to expect a general model to learn to count without hand-designing some aspect of it in order for the model to learn . Pointed out many times such as in ( Jabri et al. , 2016 ) , [ 1 ] , and seen from the balanced pair accuracies in Table 2 , much of current VQA performance is due to fitting better to spurious dataset biases with little `` actual '' learning of how to answer the questions . The necessity for a modularized approach is also recognized in a recently published work in NIPS [ 2 ] , where they combine a variety of different types of models , each suited to a different pre-defined task ( e.g.one face detection network , one scene classification network , etc . ) . The aspect that makes the counting task within VQA special is that there is some relatively easy-to-isolate logic to it , which is the focus of our module through soft deduplication and aggregation . Even in humans , counting is a highly structured process when going beyond the range where humans can subitize . While it would certainly be better if a neural network could discover the logic required for counting by itself , we think that a hand-engineered approach is perfectly valid for solving this problem given the current state of research and performance on VQA . The hand-crafted nature gives the component several useful properties . Due to the structure of the component , it performs more-or-less correct counting by default , even when none of the parameters in it have been learnt yet . This allows it to generalize more easily to a test set with fewer training samples and under much noise , as is the case for VQA . Since all steps within the component have a clear motivation , the parameters that it learns are interpretable and can be used for explaining why it predicted a certain count . Changing the input has a predictable effect on the output due to the component structure enforcing monotonicity . This is particularly useful in comparison to a general deep neural network , which suffers from adversarial inputs causing unexpected predictions . The simple nature of the module with relatively few parameters keeps the computational costs low and allows it to be integrated into non-VQA tasks fairly easily . Note that the modeling assumptions that we make are not specific to VQA , but are assumptions about what a sensible counting method should do in ideal cases . In our experience , integrating other types of models into VQA models is difficult without either inhibiting general performance or simply achieving essentially the same level of performance . As far as we are aware , there has not been any work which successfully uses a graph-based approach to VQA on real images . We did try to integrate relation networks ( Santoro et al. , 2017 ) into a VQA model , without much success in terms of performance on counting nor in any other category ( though this obviously does not mean that a successful integration is not possible ) . Relation networks are a natural choice for VQA v2 , perhaps more so than the neural networks for arbitrary graphs you suggest : they have been shown to work well for VQA on the CLEVR dataset and treat objects as nodes in a complete graph , similar to what our module uses as input . With our module , we at least show that a graph-based representation can find some use in VQA on real images in the first place and might motivate further research into graph-based approaches . In general , the sorts of graph-based approaches that you mention have only been successfully applied on the abstract VQA dataset so far [ 3 ] , where a precise scene graph of synthetic images is used as input , not real images . On that dataset , good improvements in counting have been achieved by a general graph-based network . We imagine that this is due to the much less noisy nature of scene graphs on synthetic data compared to using pixel-based representations or object proposals on real images , making counting a much easier task in the abstract VQA case ."}, {"review_id": "B12Js_yRb-1", "review_text": "Summary - This paper mainly focuses on a counting problem in visual question answering (VQA) using attention mechanism. The authors propose a differentiable counting component, which explicitly counts the number of objects. Given attention weights and corresponding proposals, the model deduplicates overlapping proposals by eliminating intra-object edges and inter-object edges using graph representation for proposals. In experiments, the effectiveness of proposed model is clearly shown in counting questions on both a synthetic toy dataset and the widely used VQA v2 dataset. Strengths - The proposed model begins with reasonable motivation and shows its effectiveness in experiments clearly. - The architecture of the proposed model looks natural and all components seem to have clear contribution to the model. - The proposed model can be easily applied to any VQA model using soft attention. - The paper is well written and the contribution is clear. Weaknesses - Although the proposed model is helpful to model counting information in VQA, it fails to show improvement with respect to a couple of important baselines: prediction from image representation only and from the combination of image representation and attention weights. - Qualitative examples of intermediate values in counting component--adjacency matrix (A), distance matrix (D) and count matrix (C)--need to be presented to show the contribution of each part, especially in the real examples that are not compatible with the strong assumptions in modeling counting component. Comments - It is not clear if the value of count \"c\" is same with the final answer in counting questions. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for the review . We are glad to hear that you think that everything is reasonably motivated , the results are good , and that there is a clear contribution with good writing . - Fails to show improvement with respect to a couple of important baselines Can you elaborate on what you mean with `` image representation only '' and `` combination of image representation and attention weights '' ? We are not sure whether you are referring to existing experiments in the paper or experiments that you would like to see ( we are happy to include these baselines if reasonable ) . Just to clarify the existing baselines that we already compare against : all the models in Table 1 and Table 2 use soft attention with softmax normalization on object proposal features . We did not list models using pixel representations , since they are outperformed by models using object proposals in all question categories of VQA ( Andersen et al. , 2017 ) . Models with attention have been shown to outperform models without attention many times in the literature ( e.g.survey in [ 1 ] ) . - Qualitative examples of matrices A , D , and C are needed Thank you for the good idea . We will include some examples of these in a revision of the paper . - Unclear whether c is the same as the predicted answer c is not necessarily the predicted answer ; it is just a feature ( which gets turned into a linear interpolation of appropriate one-hot encoded vectors as per equation 8 ) that the answer classifier makes use of . Since not all questions in VQA are counting questions , the model learns how and when to use this feature . The existing model descriptions in 5.1 and 5.2 , along with the diagram of the VQA model architecture , should make this clear . Additional references : [ 1 ] Damien Teney , Qi Wu , and Anton van den Hengel . Visual Question Answering : A Tutorial . In IEEE Signal Processing Magazine , vol . 34 , no.6 , pp.63-75 . http : //ieeexplore.ieee.org/stamp/stamp.jsp ? tp= & arnumber=8103161 & isnumber=8103076"}, {"review_id": "B12Js_yRb-2", "review_text": "This paper tackles the object counting problem in visual question answering. It is based on the two-stage method that object proposals are generated from the first stage with attention. It proposes many heuristics to use the object feature and attention weights to find the correct count. In general, it treats all object proposals as nodes on the graph. With various agreement measures, it removes or merges edges and count the final nodes. The method is evaluated on one synthetic toy dataset and one VQA v2 benchmark dataset. The experimental results on counting are promising. Although counting is important in VQA, the method is solving a very specific problem which cannot be generalized to other representation learning problems. Additionally, this method is built on a series of heuristics without sound theoretically justification, and these heuristics cannot be easily adapted to other machine learning applications. I thus believe the overall contribution is not sufficient for ICLR. Pros: 1. Well written paper with clear presentation of the method. 2. Useful for object counting problem. 3. Experimental performance is convincing. Cons: 1. The application range of the method is very limited. 2. The technique is built on a lot of heuristics without theoretical consideration. Other comments and questions: 1. The determinantal point processes [1] should be able to help with the correct counting the objects with proper construction of the similarity kernel. It may also lead to simpler solutions. For example, it can be used for deduplication using A (eq 1) as the similarity matrix. 2. Can the author provide analysis on scalability the proposed method? When the number of objects is very large, the graph could be huge. What are the memory requirements and computational complexity of the proposed method? In the end of section 3, it mentioned that \"without normalization,\" the method will not scale to an arbitrary number of objects. I think that it will only be a problem for extremely large numbers. I wonder whether the proposed method scales. 3. Could the authors provide more insights on why the structured attention (etc) did not significantly improve the result? Theoritically, it solves the soft attention problems. 4. The definition of output confidence (section 4.3.1) needs more motivation and theoretical justification. [1] Kulesza, Alex, and Ben Taskar. \"Determinantal point processes for machine learning.\" Foundations and Trends\u00ae in Machine Learning 5.2\u20133 (2012): 123-286.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . We are glad to see that you think the paper is well written and that the evidence for the usefulness to object counting is convincing . Given this , we are slightly surprised by the low rating as we think that the pros you list are very concrete compared to the cons . In summary , we disagree with the main claims that the application range is very limited and that it is built on heuristics without theoretical considerations . - Method is solving a very specific problem which can not be generalized to other representation learning problems / application range of the method is very limited We disagree that the application of this method is limited to VQA . In fact , the toy task that we perform experiments on is clearly not a VQA task and shows that the component is applicable beyond VQA . Counting tasks have many practical real-world applications on their own . An immediate research area wherein it can be used aside from VQA is image caption generation , where an attention LSTM can be used to attend over objects ( Anderson et al , 2017 ) . In this task , counting information should be useful for generating good captions and the attention mechanism has the same limitations as we discuss in section 3 , which our counting component can be used for . Any task where counting of specific objects ( without necessarily conditioning on a question input ) is required but no ground truth bounding boxes are available -- which limits the use of some conventional methods for training counting models -- can use a pre-trained region proposal network . The score of a binary classification on each proposal whether it shows the object to count can be used as attention weight in the component to eliminate duplicates without the need for post-processing with non-maximum suppression and score thresholding , both of which require hyper-parameter tuning and disallow end-to-end training . This system can be trained end-to-end with the counting module , allowing a sensible approach for handling duplicate and overlapping bounding boxes . More generally , tasks where a set of potential objects ( wherein each object is given a score of how relevant it is ) with possible duplicates needs to be counted , and duplicates can be identified through a pairwise distance metric ( in the image case these are the 1 - IoU distances of bounding boxes ) , the component can be used for counting the objects with duplicates eliminated in a fully differentiable manner . Most importantly , appropriate relevancy scores and distances do not need to be specified explicitly as they can be learnt from data . As we have shown in the paper , the component is robust enough to count without per-object ground-truth as supervision ; only the aggregate count is needed . This makes it applicable to a wide variety of counting tasks beyond VQA . - Heuristics can not be easily adapted to other machine learning applications While the properties that we use are specifically targeted towards counting , we think that there is value to be gained for the wider research community from our general approach to the problem . Our insight about the necessity of using the attention map itself , not just the feature vector coming out of the attention , may lead to recognition of problems that soft attention can introduce in other domains such as NLP , which in turn can lead to new solutions . The approach of a learned interpolation between correct behaviours , enforced by the network structure through monotonicity , may also be useful . For the monotonicity property , networks with more nonlinearities such as Deep Lattice Networks ( You et al. , 2017 ) can be used as well as we mention in Appendix A . Our way of treating the counting problem as a graphical problem and decomposing it into intra- and inter-object relations may find use in problems where there is some notion of object under uncertainty . The approach of creating a fully differentiable model despite many operations naively being non-differentiable , in particular when we want to remove certain edges but instead use equivalence under a sum to our benefit , contributes to the growing literature ( e.g . ( Jaderberg et al. , 2015 ) ) of making operations required for certain tasks differentiable and thus trainable in a deep neural network setting ."}], "0": {"review_id": "B12Js_yRb-0", "review_text": " Summary: - This paper proposes a hand-designed network architecture on a graph of object proposals to perform soft non-maximum suppression to get object count. Contribution: - This paper proposes a new object counting module which operates on a graph of object proposals. Clarity: - The paper is well written and clarity is good. Figure 2 & 3 helps the readers understand the core algorithm. Pros: - De-duplication modules of inter and intra object edges are interesting. - The proposed method improves the baseline by 5% on counting questions. Cons: - The proposed model is pretty hand-crafted. I would recommend the authors to use something more general, like graph convolutional neural networks (Kipf & Welling, 2017) or graph gated neural networks (Li et al., 2016). - One major bottleneck of the model is that the proposals are not jointly finetuned. So if the proposals are missing a single object, this cannot really be counted. In short, if the proposals don\u2019t have 100% recall, then the model is then trained with a biased loss function which asks it to count all the objects even if some are already missing from the proposals. The paper didn\u2019t study what is the recall of the proposals and how sensitive the threshold is. - The paper doesn\u2019t study a simple baseline that just does NMS on the proposal domain. - The paper doesn\u2019t compare experiment numbers with (Chattopadhyay et al., 2017). - The proposed algorithm doesn\u2019t handle symmetry breaking when two edges are equally confident (in 4.2.2 it basically scales down both edges). This is similar to a density map approach and the problem is that the model doesn\u2019t develop a notion of instance. - Compared to (Zhou et al., 2017), the proposed model does not improve much on the counting questions. - Since the authors have mentioned in the related work, it would also be more convincing if they show experimental results on CL Conclusion: - I feel that the motivation is good, but the proposed model is too hand-crafted. Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work (Chattopadhyay et al., 2017). Therefore I recommend reject. References: - Kipf, T.N., Welling, M., Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017. - Li, Y., Tarlow, D., Brockschmidt, M., Zemel, R. Gated Graph Sequence Neural Networks. ICLR 2016. Update: Thank you for the rebuttal. The paper is revised and I saw NMS baseline is added. I understood the reason not to compare with certain related work. The rebuttal is convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy. However, I am a little worried that the proposed model may be hard to reproduce due to its complexity and therefore choose to give a 6.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review . We are happy to see that you think the paper is well written and that the deduplication steps in the module are interesting . Given the aptness of your comments , it seems like you understand the paper better than you are giving yourself credit for . In summary to your main complaints : We argue that a hand-crafted approach is reasonable for the current state of VQA , NMS baselines will be supplied , and comparisons to ( Chattopadhyay et al. , 2017 ) are not useful . - Proposed model is pretty hand-crafted , would recommend the authors to use something more general , like graph convolutional neural networks . In summary , we think that with current VQA models , counting needs to be hand-crafted to some extent , hand-crafting counting has various useful properties , and that we tried a non-handcrafted approach similar to graph convolutional networks in the past without success . We think that with the current state of VQA models on real images , it is unreasonable to expect a general model to learn to count without hand-designing some aspect of it in order for the model to learn . Pointed out many times such as in ( Jabri et al. , 2016 ) , [ 1 ] , and seen from the balanced pair accuracies in Table 2 , much of current VQA performance is due to fitting better to spurious dataset biases with little `` actual '' learning of how to answer the questions . The necessity for a modularized approach is also recognized in a recently published work in NIPS [ 2 ] , where they combine a variety of different types of models , each suited to a different pre-defined task ( e.g.one face detection network , one scene classification network , etc . ) . The aspect that makes the counting task within VQA special is that there is some relatively easy-to-isolate logic to it , which is the focus of our module through soft deduplication and aggregation . Even in humans , counting is a highly structured process when going beyond the range where humans can subitize . While it would certainly be better if a neural network could discover the logic required for counting by itself , we think that a hand-engineered approach is perfectly valid for solving this problem given the current state of research and performance on VQA . The hand-crafted nature gives the component several useful properties . Due to the structure of the component , it performs more-or-less correct counting by default , even when none of the parameters in it have been learnt yet . This allows it to generalize more easily to a test set with fewer training samples and under much noise , as is the case for VQA . Since all steps within the component have a clear motivation , the parameters that it learns are interpretable and can be used for explaining why it predicted a certain count . Changing the input has a predictable effect on the output due to the component structure enforcing monotonicity . This is particularly useful in comparison to a general deep neural network , which suffers from adversarial inputs causing unexpected predictions . The simple nature of the module with relatively few parameters keeps the computational costs low and allows it to be integrated into non-VQA tasks fairly easily . Note that the modeling assumptions that we make are not specific to VQA , but are assumptions about what a sensible counting method should do in ideal cases . In our experience , integrating other types of models into VQA models is difficult without either inhibiting general performance or simply achieving essentially the same level of performance . As far as we are aware , there has not been any work which successfully uses a graph-based approach to VQA on real images . We did try to integrate relation networks ( Santoro et al. , 2017 ) into a VQA model , without much success in terms of performance on counting nor in any other category ( though this obviously does not mean that a successful integration is not possible ) . Relation networks are a natural choice for VQA v2 , perhaps more so than the neural networks for arbitrary graphs you suggest : they have been shown to work well for VQA on the CLEVR dataset and treat objects as nodes in a complete graph , similar to what our module uses as input . With our module , we at least show that a graph-based representation can find some use in VQA on real images in the first place and might motivate further research into graph-based approaches . In general , the sorts of graph-based approaches that you mention have only been successfully applied on the abstract VQA dataset so far [ 3 ] , where a precise scene graph of synthetic images is used as input , not real images . On that dataset , good improvements in counting have been achieved by a general graph-based network . We imagine that this is due to the much less noisy nature of scene graphs on synthetic data compared to using pixel-based representations or object proposals on real images , making counting a much easier task in the abstract VQA case ."}, "1": {"review_id": "B12Js_yRb-1", "review_text": "Summary - This paper mainly focuses on a counting problem in visual question answering (VQA) using attention mechanism. The authors propose a differentiable counting component, which explicitly counts the number of objects. Given attention weights and corresponding proposals, the model deduplicates overlapping proposals by eliminating intra-object edges and inter-object edges using graph representation for proposals. In experiments, the effectiveness of proposed model is clearly shown in counting questions on both a synthetic toy dataset and the widely used VQA v2 dataset. Strengths - The proposed model begins with reasonable motivation and shows its effectiveness in experiments clearly. - The architecture of the proposed model looks natural and all components seem to have clear contribution to the model. - The proposed model can be easily applied to any VQA model using soft attention. - The paper is well written and the contribution is clear. Weaknesses - Although the proposed model is helpful to model counting information in VQA, it fails to show improvement with respect to a couple of important baselines: prediction from image representation only and from the combination of image representation and attention weights. - Qualitative examples of intermediate values in counting component--adjacency matrix (A), distance matrix (D) and count matrix (C)--need to be presented to show the contribution of each part, especially in the real examples that are not compatible with the strong assumptions in modeling counting component. Comments - It is not clear if the value of count \"c\" is same with the final answer in counting questions. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for the review . We are glad to hear that you think that everything is reasonably motivated , the results are good , and that there is a clear contribution with good writing . - Fails to show improvement with respect to a couple of important baselines Can you elaborate on what you mean with `` image representation only '' and `` combination of image representation and attention weights '' ? We are not sure whether you are referring to existing experiments in the paper or experiments that you would like to see ( we are happy to include these baselines if reasonable ) . Just to clarify the existing baselines that we already compare against : all the models in Table 1 and Table 2 use soft attention with softmax normalization on object proposal features . We did not list models using pixel representations , since they are outperformed by models using object proposals in all question categories of VQA ( Andersen et al. , 2017 ) . Models with attention have been shown to outperform models without attention many times in the literature ( e.g.survey in [ 1 ] ) . - Qualitative examples of matrices A , D , and C are needed Thank you for the good idea . We will include some examples of these in a revision of the paper . - Unclear whether c is the same as the predicted answer c is not necessarily the predicted answer ; it is just a feature ( which gets turned into a linear interpolation of appropriate one-hot encoded vectors as per equation 8 ) that the answer classifier makes use of . Since not all questions in VQA are counting questions , the model learns how and when to use this feature . The existing model descriptions in 5.1 and 5.2 , along with the diagram of the VQA model architecture , should make this clear . Additional references : [ 1 ] Damien Teney , Qi Wu , and Anton van den Hengel . Visual Question Answering : A Tutorial . In IEEE Signal Processing Magazine , vol . 34 , no.6 , pp.63-75 . http : //ieeexplore.ieee.org/stamp/stamp.jsp ? tp= & arnumber=8103161 & isnumber=8103076"}, "2": {"review_id": "B12Js_yRb-2", "review_text": "This paper tackles the object counting problem in visual question answering. It is based on the two-stage method that object proposals are generated from the first stage with attention. It proposes many heuristics to use the object feature and attention weights to find the correct count. In general, it treats all object proposals as nodes on the graph. With various agreement measures, it removes or merges edges and count the final nodes. The method is evaluated on one synthetic toy dataset and one VQA v2 benchmark dataset. The experimental results on counting are promising. Although counting is important in VQA, the method is solving a very specific problem which cannot be generalized to other representation learning problems. Additionally, this method is built on a series of heuristics without sound theoretically justification, and these heuristics cannot be easily adapted to other machine learning applications. I thus believe the overall contribution is not sufficient for ICLR. Pros: 1. Well written paper with clear presentation of the method. 2. Useful for object counting problem. 3. Experimental performance is convincing. Cons: 1. The application range of the method is very limited. 2. The technique is built on a lot of heuristics without theoretical consideration. Other comments and questions: 1. The determinantal point processes [1] should be able to help with the correct counting the objects with proper construction of the similarity kernel. It may also lead to simpler solutions. For example, it can be used for deduplication using A (eq 1) as the similarity matrix. 2. Can the author provide analysis on scalability the proposed method? When the number of objects is very large, the graph could be huge. What are the memory requirements and computational complexity of the proposed method? In the end of section 3, it mentioned that \"without normalization,\" the method will not scale to an arbitrary number of objects. I think that it will only be a problem for extremely large numbers. I wonder whether the proposed method scales. 3. Could the authors provide more insights on why the structured attention (etc) did not significantly improve the result? Theoritically, it solves the soft attention problems. 4. The definition of output confidence (section 4.3.1) needs more motivation and theoretical justification. [1] Kulesza, Alex, and Ben Taskar. \"Determinantal point processes for machine learning.\" Foundations and Trends\u00ae in Machine Learning 5.2\u20133 (2012): 123-286.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . We are glad to see that you think the paper is well written and that the evidence for the usefulness to object counting is convincing . Given this , we are slightly surprised by the low rating as we think that the pros you list are very concrete compared to the cons . In summary , we disagree with the main claims that the application range is very limited and that it is built on heuristics without theoretical considerations . - Method is solving a very specific problem which can not be generalized to other representation learning problems / application range of the method is very limited We disagree that the application of this method is limited to VQA . In fact , the toy task that we perform experiments on is clearly not a VQA task and shows that the component is applicable beyond VQA . Counting tasks have many practical real-world applications on their own . An immediate research area wherein it can be used aside from VQA is image caption generation , where an attention LSTM can be used to attend over objects ( Anderson et al , 2017 ) . In this task , counting information should be useful for generating good captions and the attention mechanism has the same limitations as we discuss in section 3 , which our counting component can be used for . Any task where counting of specific objects ( without necessarily conditioning on a question input ) is required but no ground truth bounding boxes are available -- which limits the use of some conventional methods for training counting models -- can use a pre-trained region proposal network . The score of a binary classification on each proposal whether it shows the object to count can be used as attention weight in the component to eliminate duplicates without the need for post-processing with non-maximum suppression and score thresholding , both of which require hyper-parameter tuning and disallow end-to-end training . This system can be trained end-to-end with the counting module , allowing a sensible approach for handling duplicate and overlapping bounding boxes . More generally , tasks where a set of potential objects ( wherein each object is given a score of how relevant it is ) with possible duplicates needs to be counted , and duplicates can be identified through a pairwise distance metric ( in the image case these are the 1 - IoU distances of bounding boxes ) , the component can be used for counting the objects with duplicates eliminated in a fully differentiable manner . Most importantly , appropriate relevancy scores and distances do not need to be specified explicitly as they can be learnt from data . As we have shown in the paper , the component is robust enough to count without per-object ground-truth as supervision ; only the aggregate count is needed . This makes it applicable to a wide variety of counting tasks beyond VQA . - Heuristics can not be easily adapted to other machine learning applications While the properties that we use are specifically targeted towards counting , we think that there is value to be gained for the wider research community from our general approach to the problem . Our insight about the necessity of using the attention map itself , not just the feature vector coming out of the attention , may lead to recognition of problems that soft attention can introduce in other domains such as NLP , which in turn can lead to new solutions . The approach of a learned interpolation between correct behaviours , enforced by the network structure through monotonicity , may also be useful . For the monotonicity property , networks with more nonlinearities such as Deep Lattice Networks ( You et al. , 2017 ) can be used as well as we mention in Appendix A . Our way of treating the counting problem as a graphical problem and decomposing it into intra- and inter-object relations may find use in problems where there is some notion of object under uncertainty . The approach of creating a fully differentiable model despite many operations naively being non-differentiable , in particular when we want to remove certain edges but instead use equivalence under a sum to our benefit , contributes to the growing literature ( e.g . ( Jaderberg et al. , 2015 ) ) of making operations required for certain tasks differentiable and thus trainable in a deep neural network setting ."}}