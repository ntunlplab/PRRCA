{"year": "2018", "forum": "BkLhaGZRW", "title": "Improving GAN Training via Binarized Representation Entropy (BRE) Regularization", "decision": "Accept (Poster)", "meta_review": "  + Original regularizer that encourages discriminator representation entropy is shown to improve GAN training.\n  + good supporting empirical validation\n  - While intuitively reasonable, no compelling theory is given to justify the approach\n  - The regularizer used in practice is a heap of heuristic approximations (continuous relaxation of a rough approximate measure of the joint entropy of a binarized activation vector)\n  - The writing and the mathematical exposition could be clearer and more precise", "reviews": [{"review_id": "BkLhaGZRW-0", "review_text": "The paper proposes a regularizer that encourages a GAN discriminator to focus its capacity in the region around the manifolds of real and generated data points, even when it would be easy to discriminate between these manifolds using only a fraction of its capacity, so that the discriminator provides a more informative signal to the generator. The regularizer rewards high entropy in the signs of discriminator activations. Experiments show that this helps to prevent mode collapse on synthetic Gaussian mixture data and improves Inception scores on CIFAR10. The high-level idea of guiding model capacity by rewarding high-entropy activations is interesting and novel to my knowledge (though I am not an expert in this space). Figure `1 is a fantastic illustration that presents the core idea very clearly. That said I found the intuitive story a little bit difficult to follow -- it's true that in Figure 1b the discriminator won't communicate the detailed structure of the data manifold to the generator, but it's not clear why this would be a problem -- the gradients should still pull the generator *towards* the manifold of real data, and as this happens and the manifolds begin to overlap, the discriminator will naturally be forced to allocate its capacity towards finer-grained details. Is the implicit assumption that for real, high-dimensional data the generator and data manifolds will *never* overlap? But in that case much of the theoretical story goes out the window. I'd also appreciate further discussion of the relationship of this approach to Wasserstein GANs, which also attempt to provide a clearer training gradient when the data and generator manifolds do not overlap. More generally I'd like to better understand what effect we'd expect this regularizer to have. It appears to be motivated by improving training dynamics, which is understandably a significant concern. Does it also change the location of the Nash equilibria? (or equivalently, the optimal generator under the density-ratio-estimator interpretation of discriminators proposed by https://arxiv.org/abs/1610.03483). I'd expect that it would but the effects of this changed objective are not discussed in the paper. The experimental results seem promising, although not earthshattering. I would have appreciated a comparison to other methods for guiding discriminator representation capacity, e.g. autoencoding (I'd also imagine that learning an inference network (e.g. BiGAN) might serve as a useful auxiliary task?). Overall this feels like an cute hack, supported by plausible intuition but without deep theory or compelling results on real tasks (yet). As such I'd rate it as borderline; though perhaps interesting enough to be worth presenting and discussing. A final note: this paper was difficult to read due to many grammatical errors and unclear or misleading constructions, as well as missing citations (e.g. sec 2.1). From the second paragraph alone: \"impede their wider applications in new data domain\" -> domains \"extreme collapse and heavily oscillation\" -> heavy oscillation \"modes of real data distribution\" -> modes of the real data distribution \"while D fails to exploit the failure to provide better training signal to G\" -> should be \"this failure\" to refer to the previously-described generator mode collapse, or rewrite entirely \"even when they are their Jensen-Shannon divergence\" -> even when their Jensen-Shannon divergence I'm sympathetic to the authors who are presumably non-native English speakers; many good papers contain mistakes, but in my opinion the level in this paper goes beyond what is appropriate for published work. I encourage the authors to have the work proofread by a native speaker; clearer writing will ultimately increase the reach and impact of the paper. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your detailed feedbacks and suggestions . We have made improvements in the presentation of the paper in its new version . In particular Sec.2 is rewritten to discuss the effects of the regularizer with better clarity . We also have more compelling and comprehensive experimental results supporting the intuition . Please see the summary of change about the updates in the experiment section . To address your specific questions/comments : 1 . \u201c it 's true that in Figure 1b the discriminator wo n't communicate the detailed structure of the data manifold to the generator , but it 's not clear why this would be a problem -- [ \u2026 ] '' Ideally , when GAN training is stable , the min-max game eventually forces D to represent subtle variations in the real data distribution and passes the information to G. But when the internal representation of D is degenerate , two problems happen : 1 ) G under-explores , as all training signals from D could be co-linear if the fake points are in one linear region . It is unclear if G can always recover from collapsed mass caused by this . It is much more desirable for G to better explore the space from the beginning . And even if G could recover , the convergence is slowed down due to the need to correct initial mistakes . 2 ) large linear regions could cause the learning of G to bluntly extrapolate , resulting in large updates , which in turn drop already discovered real data modes and/or lead to oscillations . Both of these intuitions are captured in the updated 2D synthetic plots , as well as more detailed frames in Fig.12 and 13 . Furthermore , our updated results on the convergence speed for DCGAN confirms that improved initial exploration makes convergence faster even if the dynamics were stable already . 2. \u201c location of Nash equilibrium \u201d The locations of the Nash equilibria would change . Since D is assigned a different reward objective , there is no reason to believe that D would still have the same values for the Nash equilibria . Annealing the coefficients of the regularizer may be able to maintain these locations ( which depends on the uniform convergence property of the problem and the annealing strategy , which is beyond the scope of this paper . ) . Our preliminary studies for annealing the regularization coefficients produced marginally inferior Inception score . We have not explored different annealing strategies yet in the experiments . 3 \u201c discussion and comparison to Wasserstein GAN \u201d Thank you for the suggestion . We \u2019 ve added a discussion in Sec.\\ 2.1 on other WGAN-GP and other methods that regularize gradient norm . We \u2019 ve also added comprehesive comparison in the experiments ( Table 1 . ) showing that BRE outperforms WGAN-GP on all architectures tested . 4. \u201c auxiliary tasks \u201d Indeed certain auxiliary tasks can regularize GAN training . For example , predicting image classes in semi-supervised learning GAN . BRE regularizer is compatible with semi-supervised GAN as well , and as shown in Sec.4.3 , can further improve the results . We tested out reconstructing real data as auxiliary task to regularize D , and found that it worsens results consistently . A brief discussion is added in Sec.5 ( DISCUSSION AND FUTURE WORK ) , and results are shown in a table in the Appendix . We believe this is an interesting direction worth further experimentations and analysis in future work . There are a few other GAN works that use auto-encoder , such as Energy-Based GAN ( Zhao et al. , 2016 ) and Boundary Equilibrium GAN ( Berthelot et al. , 2017 ) , or learning an inference network as the reviewer suggested , ( Donahue et al. , 2016 ; Dumoulin et al. , 2016 ) . It is unclear if their benefits stem from the regularization effects or the fact that other parts of GAN ( such as the objective ) are modified . We added a disccussion about this in Sec.2.1 ."}, {"review_id": "BkLhaGZRW-1", "review_text": "The paper proposed a novel regularizer that is to be applied to the (rectifier) discriminators in GAN in order to encourage a better allocation of the \"model capacity\" of the discriminators over the (potentially multi-modal) generated / real data points, which might in turn helps with learning a more faithful generator. The paper is in general very well written, with intuitions and technical details well explained and empirical studies carefully designed and executed. Some detailed comments / questions: 1. It seems the concept of \"binarized activation patterns\", which the proposed regularizer is designed upon, is closely coupled with rectifier nets. I would therefore suggest the authors to highlight this assumption / constraint more clearly e.g. in the abstract. 2. In order for the paper to be more self-contained, maybe list at least once the formula for \"rectifier net\" (sth. like \"a^T max(0, wx + b) + c\") ? This might also help the readers better understand where the polytopes in Figure 1 come from. 3. In section 3.1, when presenting random variables (U_1, ..., U_d), I find the word \"Bernourlli\" a bit misleading because typically people would expect U_i to take values from {0, 1} whereas here you assume {-1, +1}. This can be made clear with just one sentence yet would greatly help with clearing away confusions for subsequent derivations. Also, \"K\" is already used to denote the mini-batch size, so it's a slight abuse to reuse \"k\" to denote the \"kth marginal\". 4. In section 3.2, it may be clearer to explicitly point out the use of the \"3-sigma\" rule for Gaussian distributions here. But I don't find it justified anywhere why \"leave 99.7% of i, j pairs unpenalized\" is sth. to be sought for here? 5. In section 3.3, when presenting Corollary 3.3 of Gavinsky & Pudlak (2015), \"n\" abruptly appears without proper introduction / context. 6. For the empirical study with 2D MoG, would an imbalanced mixture make it harder for the BRE-regularized GAN to escape from modal collapse? 7. Figure 3 is missing the sub-labels (a), (b), (c), (d).", "rating": "7: Good paper, accept", "reply_text": "Thank you for your insightful suggestions . We have made improvements to the presentation of the paper according to the comments . \u201c For the empirical study with 2D MoG , would an imbalanced mixture make it harder for the BRE-regularized GAN to escape from modal collapse ? \u201d Thank you for the suggestion . We have added one more set of results for imbalanced mixture distributions in the appendix of the revised paper . We find that on imbalanced mixture distributions , BRE-regularized GAN can still discover the support of infrequent modes most of the time , however , sometimes the probability mass assigned to those modes is not correct ( usually under represented ) ."}, {"review_id": "BkLhaGZRW-2", "review_text": "The paper presents a method for improving the diversity of Generative Adversarial Network (GAN) by promoting the Gnet's weights to be as informative as possible. This is achieved by penalizing the correlation between responses of hidden nodes and promoting low entropy intra node. Numerical experiments that demonstrate the diversity increment on the generated samples are shown. Concerns. The paper is hard do tear and it is deficit to identify the precise contribution of the authors. Such contribution can, in my opinion, be summarized in a potential of the form with $$ R_BRE = a R_ME+ b R_AC = a \\sum_k \\sum_i s_{ki}^2 + b \\sum_{<k,l>} \\sum_i \\{ s_{ki} s_{li} \\} $$ (Note that my version of R_ME is different to the one proposed by the authors, but it could have the same effect) Where a and b are parameters that weight the relative contribution of each term (maybe computed as suggested in the paper). In this formulation: Then R_ME has a high response if the node has saturated responses -1\u2019s or 1\"s, as one desire such saturated responses, a should be negative. The R_AC, penalizes correlation between responses of different nodes. The point is, a) The second term will introduce low correlation in saturated vectors, then the will be informative. b) why the authors use the softsign instead the tanh: $tahnh \\in C^2 $! Meanwhile the derivative id softsign is discontinuous. c) It is not clear is the softsign is used besides the activation function: In page 5 is said \u201cR_BRE can be applied on ant rectified layer before the nolinearity\u201d . This seems tt the authors propose to add a second activation function (the softsign), why not use the one is in teh layer? d) The authors found hard to regularize the gradient $\\nabla_x D(x)$, even they tray tanh and cosine based activations. It seems that effectively, the introduce their additional softsign in the process. e) En the definition of R_AC, I denoted by <k,l> the pair of nodes (k \\ne l). However, I think that it should be for pair in the same layer. It is not clear in the paper. f) It is supposed that the L_1 regularization motes the weights to be informative, this work is doing something similar. How is it compared the L_1 regularization vs. the proposal? Recommendation I tried to read the paper several times and I accept that it was very hard to me. The most difficult part is the lack of precision on the maths, it is hard to figure out what the authors contribution indeed are. I think there is some merit in the work. However, it is not very well organized and many points are not defined. In my opinion, the paper is in a preliminary stage and should be refined. I recommend a \u201cSOFT\u201d REJECT ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your comments . We have improved the explanation about the motivation of this regularizer , and the math presentation of its formal definition in the revised paper . We believe that there are a few misunderstandings of our method , and we will clarify them and address the reviewer \u2019 s questions below . * * Concerning the use of softsign : * * \u201c ( b ) why the authors use the softsign instead the tanh : $ tanh \\in C^2 $ ! Meanwhile the derivative id softsign is discontinuous. \u201d Using the softsign function to replace the sign function is to prevent null computation when $ $ h=0 $ $ . Theoretically tanh with high temperature could also work . In the revised paper , we have also included the experimental results when using tanh , which shows decreased effectiveness in regularizing the GAN training comparing to softsign . We believe the reason why our version softsign is better empirically than tanh when used in BRE is due to the scale-invariance achieved by the adaptive \\epsilon . This is discussed at the end of the first paragraph in Sec.3.3.Also , the derivative of the softsign function is continuous ( although its 2nd order derivative is not continuous at a single point , but does not really matter for SGD ) . \u201c c ) It is not clear is the softsign is used besides the activation function : In page 5 is said \u201c R_BRE can be applied on ant rectified layer before the nolinearity \u201d . This seems tt the authors propose to add a second activation function ( the softsign ) , why not use the one is in teh layer ? \u201d No , we compute the value of R_BRE from the immediate pre-nonlinearity layer , and add this value to the objective function . The nonlinearity of the networks are not changed . We have added a figure ( Figure 2 ) in the revised paper to clarify this . \u201c d ) The authors found hard to regularize the gradient $ \\nabla_x D ( x ) $ , even they tray tanh and cosine based activations . It seems that effectively , the introduce their additional softsign in the process. \u201d Regularizing the diversity of $ \\nabla_x D ( x ) $ is a straightforward naive approach if we want rich diverse training signal for G. However , this does not work for rectifier nets , for reason analysed in Sec.5 ( Discussion ) , and hence one of the significance of our contribution . The use of softsign is unrelated to this issue ."}], "0": {"review_id": "BkLhaGZRW-0", "review_text": "The paper proposes a regularizer that encourages a GAN discriminator to focus its capacity in the region around the manifolds of real and generated data points, even when it would be easy to discriminate between these manifolds using only a fraction of its capacity, so that the discriminator provides a more informative signal to the generator. The regularizer rewards high entropy in the signs of discriminator activations. Experiments show that this helps to prevent mode collapse on synthetic Gaussian mixture data and improves Inception scores on CIFAR10. The high-level idea of guiding model capacity by rewarding high-entropy activations is interesting and novel to my knowledge (though I am not an expert in this space). Figure `1 is a fantastic illustration that presents the core idea very clearly. That said I found the intuitive story a little bit difficult to follow -- it's true that in Figure 1b the discriminator won't communicate the detailed structure of the data manifold to the generator, but it's not clear why this would be a problem -- the gradients should still pull the generator *towards* the manifold of real data, and as this happens and the manifolds begin to overlap, the discriminator will naturally be forced to allocate its capacity towards finer-grained details. Is the implicit assumption that for real, high-dimensional data the generator and data manifolds will *never* overlap? But in that case much of the theoretical story goes out the window. I'd also appreciate further discussion of the relationship of this approach to Wasserstein GANs, which also attempt to provide a clearer training gradient when the data and generator manifolds do not overlap. More generally I'd like to better understand what effect we'd expect this regularizer to have. It appears to be motivated by improving training dynamics, which is understandably a significant concern. Does it also change the location of the Nash equilibria? (or equivalently, the optimal generator under the density-ratio-estimator interpretation of discriminators proposed by https://arxiv.org/abs/1610.03483). I'd expect that it would but the effects of this changed objective are not discussed in the paper. The experimental results seem promising, although not earthshattering. I would have appreciated a comparison to other methods for guiding discriminator representation capacity, e.g. autoencoding (I'd also imagine that learning an inference network (e.g. BiGAN) might serve as a useful auxiliary task?). Overall this feels like an cute hack, supported by plausible intuition but without deep theory or compelling results on real tasks (yet). As such I'd rate it as borderline; though perhaps interesting enough to be worth presenting and discussing. A final note: this paper was difficult to read due to many grammatical errors and unclear or misleading constructions, as well as missing citations (e.g. sec 2.1). From the second paragraph alone: \"impede their wider applications in new data domain\" -> domains \"extreme collapse and heavily oscillation\" -> heavy oscillation \"modes of real data distribution\" -> modes of the real data distribution \"while D fails to exploit the failure to provide better training signal to G\" -> should be \"this failure\" to refer to the previously-described generator mode collapse, or rewrite entirely \"even when they are their Jensen-Shannon divergence\" -> even when their Jensen-Shannon divergence I'm sympathetic to the authors who are presumably non-native English speakers; many good papers contain mistakes, but in my opinion the level in this paper goes beyond what is appropriate for published work. I encourage the authors to have the work proofread by a native speaker; clearer writing will ultimately increase the reach and impact of the paper. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your detailed feedbacks and suggestions . We have made improvements in the presentation of the paper in its new version . In particular Sec.2 is rewritten to discuss the effects of the regularizer with better clarity . We also have more compelling and comprehensive experimental results supporting the intuition . Please see the summary of change about the updates in the experiment section . To address your specific questions/comments : 1 . \u201c it 's true that in Figure 1b the discriminator wo n't communicate the detailed structure of the data manifold to the generator , but it 's not clear why this would be a problem -- [ \u2026 ] '' Ideally , when GAN training is stable , the min-max game eventually forces D to represent subtle variations in the real data distribution and passes the information to G. But when the internal representation of D is degenerate , two problems happen : 1 ) G under-explores , as all training signals from D could be co-linear if the fake points are in one linear region . It is unclear if G can always recover from collapsed mass caused by this . It is much more desirable for G to better explore the space from the beginning . And even if G could recover , the convergence is slowed down due to the need to correct initial mistakes . 2 ) large linear regions could cause the learning of G to bluntly extrapolate , resulting in large updates , which in turn drop already discovered real data modes and/or lead to oscillations . Both of these intuitions are captured in the updated 2D synthetic plots , as well as more detailed frames in Fig.12 and 13 . Furthermore , our updated results on the convergence speed for DCGAN confirms that improved initial exploration makes convergence faster even if the dynamics were stable already . 2. \u201c location of Nash equilibrium \u201d The locations of the Nash equilibria would change . Since D is assigned a different reward objective , there is no reason to believe that D would still have the same values for the Nash equilibria . Annealing the coefficients of the regularizer may be able to maintain these locations ( which depends on the uniform convergence property of the problem and the annealing strategy , which is beyond the scope of this paper . ) . Our preliminary studies for annealing the regularization coefficients produced marginally inferior Inception score . We have not explored different annealing strategies yet in the experiments . 3 \u201c discussion and comparison to Wasserstein GAN \u201d Thank you for the suggestion . We \u2019 ve added a discussion in Sec.\\ 2.1 on other WGAN-GP and other methods that regularize gradient norm . We \u2019 ve also added comprehesive comparison in the experiments ( Table 1 . ) showing that BRE outperforms WGAN-GP on all architectures tested . 4. \u201c auxiliary tasks \u201d Indeed certain auxiliary tasks can regularize GAN training . For example , predicting image classes in semi-supervised learning GAN . BRE regularizer is compatible with semi-supervised GAN as well , and as shown in Sec.4.3 , can further improve the results . We tested out reconstructing real data as auxiliary task to regularize D , and found that it worsens results consistently . A brief discussion is added in Sec.5 ( DISCUSSION AND FUTURE WORK ) , and results are shown in a table in the Appendix . We believe this is an interesting direction worth further experimentations and analysis in future work . There are a few other GAN works that use auto-encoder , such as Energy-Based GAN ( Zhao et al. , 2016 ) and Boundary Equilibrium GAN ( Berthelot et al. , 2017 ) , or learning an inference network as the reviewer suggested , ( Donahue et al. , 2016 ; Dumoulin et al. , 2016 ) . It is unclear if their benefits stem from the regularization effects or the fact that other parts of GAN ( such as the objective ) are modified . We added a disccussion about this in Sec.2.1 ."}, "1": {"review_id": "BkLhaGZRW-1", "review_text": "The paper proposed a novel regularizer that is to be applied to the (rectifier) discriminators in GAN in order to encourage a better allocation of the \"model capacity\" of the discriminators over the (potentially multi-modal) generated / real data points, which might in turn helps with learning a more faithful generator. The paper is in general very well written, with intuitions and technical details well explained and empirical studies carefully designed and executed. Some detailed comments / questions: 1. It seems the concept of \"binarized activation patterns\", which the proposed regularizer is designed upon, is closely coupled with rectifier nets. I would therefore suggest the authors to highlight this assumption / constraint more clearly e.g. in the abstract. 2. In order for the paper to be more self-contained, maybe list at least once the formula for \"rectifier net\" (sth. like \"a^T max(0, wx + b) + c\") ? This might also help the readers better understand where the polytopes in Figure 1 come from. 3. In section 3.1, when presenting random variables (U_1, ..., U_d), I find the word \"Bernourlli\" a bit misleading because typically people would expect U_i to take values from {0, 1} whereas here you assume {-1, +1}. This can be made clear with just one sentence yet would greatly help with clearing away confusions for subsequent derivations. Also, \"K\" is already used to denote the mini-batch size, so it's a slight abuse to reuse \"k\" to denote the \"kth marginal\". 4. In section 3.2, it may be clearer to explicitly point out the use of the \"3-sigma\" rule for Gaussian distributions here. But I don't find it justified anywhere why \"leave 99.7% of i, j pairs unpenalized\" is sth. to be sought for here? 5. In section 3.3, when presenting Corollary 3.3 of Gavinsky & Pudlak (2015), \"n\" abruptly appears without proper introduction / context. 6. For the empirical study with 2D MoG, would an imbalanced mixture make it harder for the BRE-regularized GAN to escape from modal collapse? 7. Figure 3 is missing the sub-labels (a), (b), (c), (d).", "rating": "7: Good paper, accept", "reply_text": "Thank you for your insightful suggestions . We have made improvements to the presentation of the paper according to the comments . \u201c For the empirical study with 2D MoG , would an imbalanced mixture make it harder for the BRE-regularized GAN to escape from modal collapse ? \u201d Thank you for the suggestion . We have added one more set of results for imbalanced mixture distributions in the appendix of the revised paper . We find that on imbalanced mixture distributions , BRE-regularized GAN can still discover the support of infrequent modes most of the time , however , sometimes the probability mass assigned to those modes is not correct ( usually under represented ) ."}, "2": {"review_id": "BkLhaGZRW-2", "review_text": "The paper presents a method for improving the diversity of Generative Adversarial Network (GAN) by promoting the Gnet's weights to be as informative as possible. This is achieved by penalizing the correlation between responses of hidden nodes and promoting low entropy intra node. Numerical experiments that demonstrate the diversity increment on the generated samples are shown. Concerns. The paper is hard do tear and it is deficit to identify the precise contribution of the authors. Such contribution can, in my opinion, be summarized in a potential of the form with $$ R_BRE = a R_ME+ b R_AC = a \\sum_k \\sum_i s_{ki}^2 + b \\sum_{<k,l>} \\sum_i \\{ s_{ki} s_{li} \\} $$ (Note that my version of R_ME is different to the one proposed by the authors, but it could have the same effect) Where a and b are parameters that weight the relative contribution of each term (maybe computed as suggested in the paper). In this formulation: Then R_ME has a high response if the node has saturated responses -1\u2019s or 1\"s, as one desire such saturated responses, a should be negative. The R_AC, penalizes correlation between responses of different nodes. The point is, a) The second term will introduce low correlation in saturated vectors, then the will be informative. b) why the authors use the softsign instead the tanh: $tahnh \\in C^2 $! Meanwhile the derivative id softsign is discontinuous. c) It is not clear is the softsign is used besides the activation function: In page 5 is said \u201cR_BRE can be applied on ant rectified layer before the nolinearity\u201d . This seems tt the authors propose to add a second activation function (the softsign), why not use the one is in teh layer? d) The authors found hard to regularize the gradient $\\nabla_x D(x)$, even they tray tanh and cosine based activations. It seems that effectively, the introduce their additional softsign in the process. e) En the definition of R_AC, I denoted by <k,l> the pair of nodes (k \\ne l). However, I think that it should be for pair in the same layer. It is not clear in the paper. f) It is supposed that the L_1 regularization motes the weights to be informative, this work is doing something similar. How is it compared the L_1 regularization vs. the proposal? Recommendation I tried to read the paper several times and I accept that it was very hard to me. The most difficult part is the lack of precision on the maths, it is hard to figure out what the authors contribution indeed are. I think there is some merit in the work. However, it is not very well organized and many points are not defined. In my opinion, the paper is in a preliminary stage and should be refined. I recommend a \u201cSOFT\u201d REJECT ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your comments . We have improved the explanation about the motivation of this regularizer , and the math presentation of its formal definition in the revised paper . We believe that there are a few misunderstandings of our method , and we will clarify them and address the reviewer \u2019 s questions below . * * Concerning the use of softsign : * * \u201c ( b ) why the authors use the softsign instead the tanh : $ tanh \\in C^2 $ ! Meanwhile the derivative id softsign is discontinuous. \u201d Using the softsign function to replace the sign function is to prevent null computation when $ $ h=0 $ $ . Theoretically tanh with high temperature could also work . In the revised paper , we have also included the experimental results when using tanh , which shows decreased effectiveness in regularizing the GAN training comparing to softsign . We believe the reason why our version softsign is better empirically than tanh when used in BRE is due to the scale-invariance achieved by the adaptive \\epsilon . This is discussed at the end of the first paragraph in Sec.3.3.Also , the derivative of the softsign function is continuous ( although its 2nd order derivative is not continuous at a single point , but does not really matter for SGD ) . \u201c c ) It is not clear is the softsign is used besides the activation function : In page 5 is said \u201c R_BRE can be applied on ant rectified layer before the nolinearity \u201d . This seems tt the authors propose to add a second activation function ( the softsign ) , why not use the one is in teh layer ? \u201d No , we compute the value of R_BRE from the immediate pre-nonlinearity layer , and add this value to the objective function . The nonlinearity of the networks are not changed . We have added a figure ( Figure 2 ) in the revised paper to clarify this . \u201c d ) The authors found hard to regularize the gradient $ \\nabla_x D ( x ) $ , even they tray tanh and cosine based activations . It seems that effectively , the introduce their additional softsign in the process. \u201d Regularizing the diversity of $ \\nabla_x D ( x ) $ is a straightforward naive approach if we want rich diverse training signal for G. However , this does not work for rectifier nets , for reason analysed in Sec.5 ( Discussion ) , and hence one of the significance of our contribution . The use of softsign is unrelated to this issue ."}}