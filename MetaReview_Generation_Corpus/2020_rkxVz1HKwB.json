{"year": "2020", "forum": "rkxVz1HKwB", "title": "Certifiably Robust Interpretation in Deep Learning", "decision": "Reject", "meta_review": "This paper discusses new methods to perform adversarial attacks on salience maps.\n\nIn its current form, this paper in its current form has unfortunately has not convinced several of the reviewers/commenters of the motivation behind proposing such a method. I tend to share the same opinion. I would encourage the authors to re-think the motivation of the work, and if there are indeed solid use cases to express them explicitly in the next version of the paper.", "reviews": [{"review_id": "rkxVz1HKwB-0", "review_text": "This paper introduces an extension of Cohen et al. (2019)\u2019s result that allows one to derive robustness certificates for interpretation methods, as well as a bound on the top-K overlap of saliency methods. These results motivate the introduction of Sparsified SmoothGrad and a relaxation of this method that has differentiable elements. These introduced approaches adapt previous methods so the derived bounds are applicable. The proposed methods are shown to perform as well as Quadratic SmoothGrad (Smilkov et al. 2017) in CIFAR-10 experiments. I\u2019m not familiar with the field so it is hard for me to judge how novel the presented results are or whether the used baselines are the proper ones. That being said, the paper presents an interesting idea and it is relatively easy to read (I really appreciate the fact that for every theorem there is an interpretation, in words, for it). The only thing that sometimes makes the paper hard to read is when it starts to refer to too many constants without remind the reader what they are about. I have two complaints/questions about the relevance of the introduced bounds though. Right now, to me, it seems that the derived theoretical guarantees are not that relevant, hopefully the questions below will help clarify that. In page 6, before introducing the \u201cSparsified SmoothGrad and its Relaxations\u201d, it is said that q is set to 2^13 because otherwise the gap would be too large in images from ImageNet, for example, when comparing to traditional values of q. However, ImageNet is never revisited in the paper. I was expecting to see ImageNet results in the experimental section but they are not there (or maybe some correlation between the gap and performance -- robustness). More than that, the Quadratic SmoothGrad, which doesn\u2019t have any theoretical guarantee, seems to perform as well as the proposed methods. So where is the gap/theoretical result relevant? What are the settings in which having a method with the derived theoretical guarantees shine? What are the limitations of Quadratic SmoothGrad? Right now, it seems to me that the \u201cSparsified SmoothGrad and its Relaxations\u201d and its empirical analysis weaken the paper, because they take a big chunk of it when there is not enough evidence to claim them as an important contribution. Am I missing something? I gave this paper a relatively low score because I\u2019m not certain about the relevance of its results, but if my questions are satisfactory answered, I\u2019ll be happy to update my score. ------ >>> Update after rebuttal: I stand by my score after the rebuttal. Unfortunately I'm not an expert in this area and I don't feel confident in having a very strong opinion about this paper. That being said, enough presentation issues were raised that make me uneasy about raising my score. I do agree with some of the concerns raised by other reviewers. ", "rating": "3: Weak Reject", "reply_text": "We thank you for your feedback . We evaluate our robustness certificates on ImageNet samples in Figure 2 . To address the concern about the gap between empirical and certified robustness , we show this gap on CIFAR samples in Appendix J . While the size of perturbations with certified robustness is small compared to the empirical robustness on these samples , our main contribution is to demonstrate that a minor variation on the commonly-used SmoothGrad technique does in fact have a robustness guarantee : furthermore , this is the first robustness certificate for interpretation that can be evaluated at the ImageNet scale . This minor modification to SmoothGrad has little effect on the visual output ( Figure 3 ) . Additionally , in testing the empirical attacks ( Figure 4 ) , we show that both quadratic SmoothGrad and our variant are empirically robust . Therefore , the variant ( sparsified SmoothGrad ) combines the visual quality and empirical robustness of Quadratic SmoothGrad with an additional theoretical guarantee of robustness ."}, {"review_id": "rkxVz1HKwB-1", "review_text": "This paper proposes a way to testify how much a SmoothGrad saliency can vary from the true saliency attesting to the adversarial robustness but with the goal of interpretation. At the premise of this work I do not think the paper motivates the value of such a robustness certificate. Using the gradient (with SmoothGrad), while providing a reasonable interpretation of the model, is just a linear approximation of the true explanation of the prediction. So saying we have the correct approximation is not so useful. I also am not sure we need such a method. For example imagine a doctor is looking at a saliency map and we are sure that it is correct first order approximation because of some method. What were the negative cases where this would fail? How would this method improve that? I believe right now just the basic gradient is sufficient to indicate the region of interest. ", "rating": "1: Reject", "reply_text": "We respectfully disagree . We believe that you may have misunderstood the main point of the paper . You mention that : \u201c I believe right now just the basic gradient is sufficient to indicate the region of interest. \u201d The central issue here is that basic gradient methods may NOT in fact indicate the region of interest in an image . A small adversarial noise can keep the label as is but change the basic gradient result significantly . This is the problem that we are addressing in this paper . As you mention , gradient-based saliency maps represent only a local first order approximation to the true influence of each feature on the decision . This leads to two issues : * Low quality natural interpretations : as noted by Smilkov , et al . ( 2017 ) the gradient with respect to a particular pixel may \u201c fluctuate sharply at small scales \u201d and therefore be \u201c less meaningful than a local average of gradient values. \u201d This observation led to the development of SmoothGrad . To put this simply , a large gradient value over a ( very ) small range of input values of a feature represents in total a small influence on the class score by that feature . However , if the input image happens to be within this interval where the gradient is large , the feature will erroneously appear to be highly salient . In practice , this leads to simple gradient-based interpretations looking \u201c noisy , \u201d as apparently random pixels appear to be highly salient . * Adversarial attacks on interpretation : as demonstrated by Ghorbani , et al . ( 2019 ) , one can adversarially craft examples where the basic gradient interpretation is in fact very different from the true region of interest . This is a direct consequence of the saliency map being a \u201c first order approximation \u201d : it is therefore possible to make this approximation adversarially bad , by crafting a small perturbation to the input . As detailed in the paper , saliency maps are used in a broad range of highly sensitive downstream applications , including in medical imaging and object localization . Because an adversarial attack has been proposed by Ghorbani et al . ( 2019 ) which can distort saliency maps , it is therefore a topic of interest to defend against this type of adversarial attack ."}, {"review_id": "rkxVz1HKwB-2", "review_text": "The work addresses an important problem of robustness of interpretation methods against adversarial perturbations. The problem is well motivated as several gradient-based interpretations are sensitive to small adversarial perturbations. The authors present a framework to compute the robustness certificate (more precisely, a lower bound to the actual robustness) of any general saliency map over an input example. They further propose variants of SmoothGrad interpretation method which are claimed to be more robust. The empirical validation of the underlying theory and use of the sparsified (and relaxed) SmoothGradient interpretation methods is unconvincing because of the following reasons: 1. In the demonstrated experiment, the proposed alternative to SmoothGrad involves setting the lowest 90% of the saliency values to zero, and the top 10% (for sparsified SmoothGrad) or top 1% (in the case of relaxed sparsified SmoothGrad) to one. The problem with clamping most of the lower values to zero and the remainder (or most of the remainder) higher values to one is that it defeats the purpose of having a saliency map in the first place, which exist to characterize the relative importance of the input features. 2. The paper claims that the proposed variant maintains the high visual quality of SmoothGrad, however, the claim is unsubstantiated. With the current setup, there is a clear trade-off between robustness and fidelity of interpretation, which the paper fails to acknowledge. In principle, one can always build extremely sparse or dense interpretation methods (close to all zeros or all ones), which would produce high robustness certificates but would be much less meaningful as they are not faithful to the underlying mechanism of prediction, and the characteristics of the input. 3. The authors present empirical evidence on just one set of sparsification parameters and K. It would be more conclusive to evaluate the robustness of the proposed variations with different values of sparsification parameters, and K. ", "rating": "3: Weak Reject", "reply_text": "We thank you for your constructive feedback . To address your comments : 1 and 2 . Note that we sparsify the saliency maps before smoothing : in other words , the final smoothed saliency map will be non-sparse , because pixels which are less salient overall may still occur in the top 10 % in a minority of random samples . Empirically , we find that this sparsification prior to averaging has little effect on the final smoothed interpretation : in particular , the results are visually very similar to the quadratic SmoothGrad proposed by ( Smilkov et al.2017 ) .This was shown in Figure 3 on an ImageNet sample , as well as on additional CIFAR samples in Appendix G. To address this comment , we have added additional ImageNet samples both in the body of the paper ( Figure 3 ) and in the appendix ( Appendix G ) . 3 : We have added empirical tests using additional values of the sparsification parameter to Figure 4 ."}], "0": {"review_id": "rkxVz1HKwB-0", "review_text": "This paper introduces an extension of Cohen et al. (2019)\u2019s result that allows one to derive robustness certificates for interpretation methods, as well as a bound on the top-K overlap of saliency methods. These results motivate the introduction of Sparsified SmoothGrad and a relaxation of this method that has differentiable elements. These introduced approaches adapt previous methods so the derived bounds are applicable. The proposed methods are shown to perform as well as Quadratic SmoothGrad (Smilkov et al. 2017) in CIFAR-10 experiments. I\u2019m not familiar with the field so it is hard for me to judge how novel the presented results are or whether the used baselines are the proper ones. That being said, the paper presents an interesting idea and it is relatively easy to read (I really appreciate the fact that for every theorem there is an interpretation, in words, for it). The only thing that sometimes makes the paper hard to read is when it starts to refer to too many constants without remind the reader what they are about. I have two complaints/questions about the relevance of the introduced bounds though. Right now, to me, it seems that the derived theoretical guarantees are not that relevant, hopefully the questions below will help clarify that. In page 6, before introducing the \u201cSparsified SmoothGrad and its Relaxations\u201d, it is said that q is set to 2^13 because otherwise the gap would be too large in images from ImageNet, for example, when comparing to traditional values of q. However, ImageNet is never revisited in the paper. I was expecting to see ImageNet results in the experimental section but they are not there (or maybe some correlation between the gap and performance -- robustness). More than that, the Quadratic SmoothGrad, which doesn\u2019t have any theoretical guarantee, seems to perform as well as the proposed methods. So where is the gap/theoretical result relevant? What are the settings in which having a method with the derived theoretical guarantees shine? What are the limitations of Quadratic SmoothGrad? Right now, it seems to me that the \u201cSparsified SmoothGrad and its Relaxations\u201d and its empirical analysis weaken the paper, because they take a big chunk of it when there is not enough evidence to claim them as an important contribution. Am I missing something? I gave this paper a relatively low score because I\u2019m not certain about the relevance of its results, but if my questions are satisfactory answered, I\u2019ll be happy to update my score. ------ >>> Update after rebuttal: I stand by my score after the rebuttal. Unfortunately I'm not an expert in this area and I don't feel confident in having a very strong opinion about this paper. That being said, enough presentation issues were raised that make me uneasy about raising my score. I do agree with some of the concerns raised by other reviewers. ", "rating": "3: Weak Reject", "reply_text": "We thank you for your feedback . We evaluate our robustness certificates on ImageNet samples in Figure 2 . To address the concern about the gap between empirical and certified robustness , we show this gap on CIFAR samples in Appendix J . While the size of perturbations with certified robustness is small compared to the empirical robustness on these samples , our main contribution is to demonstrate that a minor variation on the commonly-used SmoothGrad technique does in fact have a robustness guarantee : furthermore , this is the first robustness certificate for interpretation that can be evaluated at the ImageNet scale . This minor modification to SmoothGrad has little effect on the visual output ( Figure 3 ) . Additionally , in testing the empirical attacks ( Figure 4 ) , we show that both quadratic SmoothGrad and our variant are empirically robust . Therefore , the variant ( sparsified SmoothGrad ) combines the visual quality and empirical robustness of Quadratic SmoothGrad with an additional theoretical guarantee of robustness ."}, "1": {"review_id": "rkxVz1HKwB-1", "review_text": "This paper proposes a way to testify how much a SmoothGrad saliency can vary from the true saliency attesting to the adversarial robustness but with the goal of interpretation. At the premise of this work I do not think the paper motivates the value of such a robustness certificate. Using the gradient (with SmoothGrad), while providing a reasonable interpretation of the model, is just a linear approximation of the true explanation of the prediction. So saying we have the correct approximation is not so useful. I also am not sure we need such a method. For example imagine a doctor is looking at a saliency map and we are sure that it is correct first order approximation because of some method. What were the negative cases where this would fail? How would this method improve that? I believe right now just the basic gradient is sufficient to indicate the region of interest. ", "rating": "1: Reject", "reply_text": "We respectfully disagree . We believe that you may have misunderstood the main point of the paper . You mention that : \u201c I believe right now just the basic gradient is sufficient to indicate the region of interest. \u201d The central issue here is that basic gradient methods may NOT in fact indicate the region of interest in an image . A small adversarial noise can keep the label as is but change the basic gradient result significantly . This is the problem that we are addressing in this paper . As you mention , gradient-based saliency maps represent only a local first order approximation to the true influence of each feature on the decision . This leads to two issues : * Low quality natural interpretations : as noted by Smilkov , et al . ( 2017 ) the gradient with respect to a particular pixel may \u201c fluctuate sharply at small scales \u201d and therefore be \u201c less meaningful than a local average of gradient values. \u201d This observation led to the development of SmoothGrad . To put this simply , a large gradient value over a ( very ) small range of input values of a feature represents in total a small influence on the class score by that feature . However , if the input image happens to be within this interval where the gradient is large , the feature will erroneously appear to be highly salient . In practice , this leads to simple gradient-based interpretations looking \u201c noisy , \u201d as apparently random pixels appear to be highly salient . * Adversarial attacks on interpretation : as demonstrated by Ghorbani , et al . ( 2019 ) , one can adversarially craft examples where the basic gradient interpretation is in fact very different from the true region of interest . This is a direct consequence of the saliency map being a \u201c first order approximation \u201d : it is therefore possible to make this approximation adversarially bad , by crafting a small perturbation to the input . As detailed in the paper , saliency maps are used in a broad range of highly sensitive downstream applications , including in medical imaging and object localization . Because an adversarial attack has been proposed by Ghorbani et al . ( 2019 ) which can distort saliency maps , it is therefore a topic of interest to defend against this type of adversarial attack ."}, "2": {"review_id": "rkxVz1HKwB-2", "review_text": "The work addresses an important problem of robustness of interpretation methods against adversarial perturbations. The problem is well motivated as several gradient-based interpretations are sensitive to small adversarial perturbations. The authors present a framework to compute the robustness certificate (more precisely, a lower bound to the actual robustness) of any general saliency map over an input example. They further propose variants of SmoothGrad interpretation method which are claimed to be more robust. The empirical validation of the underlying theory and use of the sparsified (and relaxed) SmoothGradient interpretation methods is unconvincing because of the following reasons: 1. In the demonstrated experiment, the proposed alternative to SmoothGrad involves setting the lowest 90% of the saliency values to zero, and the top 10% (for sparsified SmoothGrad) or top 1% (in the case of relaxed sparsified SmoothGrad) to one. The problem with clamping most of the lower values to zero and the remainder (or most of the remainder) higher values to one is that it defeats the purpose of having a saliency map in the first place, which exist to characterize the relative importance of the input features. 2. The paper claims that the proposed variant maintains the high visual quality of SmoothGrad, however, the claim is unsubstantiated. With the current setup, there is a clear trade-off between robustness and fidelity of interpretation, which the paper fails to acknowledge. In principle, one can always build extremely sparse or dense interpretation methods (close to all zeros or all ones), which would produce high robustness certificates but would be much less meaningful as they are not faithful to the underlying mechanism of prediction, and the characteristics of the input. 3. The authors present empirical evidence on just one set of sparsification parameters and K. It would be more conclusive to evaluate the robustness of the proposed variations with different values of sparsification parameters, and K. ", "rating": "3: Weak Reject", "reply_text": "We thank you for your constructive feedback . To address your comments : 1 and 2 . Note that we sparsify the saliency maps before smoothing : in other words , the final smoothed saliency map will be non-sparse , because pixels which are less salient overall may still occur in the top 10 % in a minority of random samples . Empirically , we find that this sparsification prior to averaging has little effect on the final smoothed interpretation : in particular , the results are visually very similar to the quadratic SmoothGrad proposed by ( Smilkov et al.2017 ) .This was shown in Figure 3 on an ImageNet sample , as well as on additional CIFAR samples in Appendix G. To address this comment , we have added additional ImageNet samples both in the body of the paper ( Figure 3 ) and in the appendix ( Appendix G ) . 3 : We have added empirical tests using additional values of the sparsification parameter to Figure 4 ."}}