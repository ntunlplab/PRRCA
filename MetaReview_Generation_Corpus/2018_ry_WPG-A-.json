{"year": "2018", "forum": "ry_WPG-A-", "title": "On the Information Bottleneck Theory of Deep Learning", "decision": "Accept (Poster)", "meta_review": "\nThis submission explores recent theoretical work by Shwartz-Ziv and Tishby on explaining the generalization ability of deep networks. The paper gives counter-examples that suggest aspects of the theory might not be relevant for all neural networks.\n\nThere is some uncertainty surrounding the results where mutual information is estimated empirically. Even state-of-the-art estimation methods might lead to misleading empirical results. However, the submission appears to follow reasonable practice following previous work, making the reported results at least suggestive. They warrant reporting for further study and discussion.\n\nThe reviewers generally found the paper interesting enough for acceptance, however strong objections were posted by Tishby. A lengthy public exchange resulted between the groups of authors. Not every part of this exchange is resolved. It is not clear whether Tishby's group would be able to fix the full-connected ReLU demonstration in this paper, or whether the authors of this submission have anything to say about Tishby's ReLU+convnet demonstration. By accepting this work, we are not declaring where this debate will end. However, we felt the current submission is a constructive part of ongoing discussion in the literature on furthering our theoretical understanding of neural networks.", "reviews": [{"review_id": "ry_WPG-A--0", "review_text": "This paper presents a study on the Information Bottleneck (IB) theory of deep learning, providing results in contrasts to the main theory claims. According to the authors, the IB theory suggests that the network generalization is mainly due to a \u2018compression phase\u2019 in the information plane occurring after a \u2018fitting phase\u2019 and that the \u2018compression phase\u2019 is due to the stochastic gradient decent (SDG). Instead, the results provided by this paper show that: the generalization can happen even without compression; that SDG is not the primary factor in compression; and that the compression does not necessarily occur after the \u2018fitting phase\u2019. Overall, the paper tackles the IB theory claims with consistent methodology, thus providing substantial arguments against the IB theory. The main concern is that the paper is built to argue against another theoretical work, raising a substantial discussion with the authors of the IB theory. This paper should carefully address all the raised arguments in the main text. There are, moreover, some open questions that are not fully clear in this contribution: 1) To evaluate the mutual information in the ReLu networks (sec. 2) the authors discretize the output activity in their range. Should the non-linearity of ReLu be considered as a form of compression? Do you check the ratio of ReLus that are not active during training or the ratio of inputs that fall into the negative domain of each ReLu? 2) Since one of today common topics is the training of deep neural networks with lower representational precision, could the quantization error due to the low precision be considered as a form of noise inserted in the network layers that influences the generalization performance in deep neural networks? 3) What are the main conclusions or impact of the present study in the theory of neural networks? Is it the authors aim to just demonstrate that the IB theory is not correct? Perhaps, the paper should empathize the obtained results not just in contrast to the other theory, but proactively in agreement with a new proposal. Finally, a small issue comes from the Figures that need some improvement. In most of the cases (Figure 3 C, D; Figure 4 A, B, C; Figure 5 C, D; Figure 6) the axes font is too small to be read. Figure 3C is also very unclear. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Please also see our comments to all reviewers above . -This paper presents a study on the Information Bottleneck ( IB ) theory of deep learning , providing results in contrasts to the main theory claims . According to the authors , the IB theory suggests that the network generalization is mainly due to a \u2018 compression phase \u2019 in the information plane occurring after a \u2018 fitting phase \u2019 and that the \u2018 compression phase \u2019 is due to the stochastic gradient decent ( SDG ) . Instead , the results provided by this paper show that : the generalization can happen even without compression ; that SDG is not the primary factor in compression ; and that the compression does not necessarily occur after the \u2018 fitting phase \u2019 . Overall , the paper tackles the IB theory claims with consistent methodology , thus providing substantial arguments against the IB theory . Thank you ! -The main concern is that the paper is built to argue against another theoretical work , raising a substantial discussion with the authors of the IB theory . This paper should carefully address all the raised arguments in the main text . The revision now addresses these arguments in the main text . We believe the conclusions in our original submission still stand , and are now supported by additional experiments . -There are , moreover , some open questions that are not fully clear in this contribution : -1 ) To evaluate the mutual information in the ReLu networks ( sec.2 ) the authors discretize the output activity in their range . Should the non-linearity of ReLu be considered as a form of compression ? Do you check the ratio of ReLus that are not active during training or the ratio of inputs that fall into the negative domain of each ReLu ? Our discretization does consider the nonlinearity of ReLU , which could in principle lead to compression if ReLUs tended to inactivate over the course of training . However they do not seem to in practice , which can be seen from the histograms of activity over training in Fig.17.The bottom-most bin contains zero , the ReLU saturation value . There is no consistent trend in the number of saturated ReLU activations over training , with most layers ending up about where they started , with neurons inactive on roughly 50 % of examples . -2 ) Since one of today common topics is the training of deep neural networks with lower representational precision , could the quantization error due to the low precision be considered as a form of noise inserted in the network layers that influences the generalization performance in deep neural networks ? Thank you for the suggestion , we now point to this possibility in the discussion . For networks which explicitly incorporate noise in their architecture ( either through quantization or noise injection ) , the broader information bottleneck theory may apply and yield potentially new training algorithms . Our point in this paper is that the specific claims of the information bottleneck theory of deep learning , which attempt to explain the performance of \u201c vanilla \u201d deep networks with no quantization or noise , do not in fact explain the generalization performance of these networks . -3 ) What are the main conclusions or impact of the present study in the theory of neural networks ? Is it the authors aim to just demonstrate that the IB theory is not correct ? Perhaps , the paper should empathize the obtained results not just in contrast to the other theory , but proactively in agreement with a new proposal . There are a variety of theories ( several cited in our introduction ) which may be consistent with all of the results reported in this paper . Most directly , the results in Advani & Saxe , 2017 successfully account for generalization behavior in the linear models we study . However even there , it remains to be seen how those ideas might apply to deep nonlinear networks . It is outside the scope of this paper to provide strong support for any one of these theories , as singling out one theory as better would require experiments designed to specifically test them , which must be left for future work . Our aim rather was to carefully and fairly inspect an exciting and , it seemed to us , promising theory , and the result turned out to be somewhat negative . In our view , negative results are a critical component of a healthy research ecosystem , and on occasion science advances through falsification . The impact of the present study on the theory of neural networks is to help narrow the field of plausible candidate theories . We expect our results to be important to researchers currently building off of the information bottleneck theory of deep learning . -Finally , a small issue comes from the Figures that need some improvement . In most of the cases ( Figure 3 C , D ; Figure 4 A , B , C ; Figure 5 C , D ; Figure 6 ) the axes font is too small to be read . Figure 3C is also very unclear . We apologize for this issue , we have increased the size of several figures and are working towards a revision with the rest corrected ."}, {"review_id": "ry_WPG-A--1", "review_text": "The authors address the issue of whether the information bottleneck (IB) theory can provide insight into the working of deep networks. They show, using some counter-examples, that the previous understanding of IB theory and its application to deep networks is limited. PROS: The paper is very well written and makes its points very clearly. To the extent of my knowledge, the content is original. Since it clearly elucidates the limitations of IB theory in its ability to analyse deep networks, I think it is a significant contribution worthy of acceptance. The experiments are also well designed and executed. CONS: On the downside, the limitations exposed are done so empirically, but the underlying theoretical causes are not explored (although this could be potentially because this is hard to do). Also, the paper exposes the limitations of another paper published in a non-peer reviewed location (arXiv) which potentially limits its applicability and significance. Some detailed comments: In section 2, the influence of binning on how the mutual information is calculated should be made clear. Since the comparison is between a bounded non-linearity and an unbounded one, it is not self-evident how the binning in the latter case should be done. A justification for the choice made for binning the relu case would be helpful. In the same section, it is claimed that the dependence of the mutual information I(X; T) on the magnitude of the weights of the network explains why a tanh non-linearity shows the compression effect (non-monotonicity vs I(X; T)) in the information plane dynamics. But the claim that large weights are required for doing anything useful is unsubstantiated and would benefit from having citations to papaers that discuss this issue. If networks with small weights are able to learn most datasets, the arguments given in this section wouldn't be applicable in its entirety. Additionally, figures that show the phase plane dynamics for other non-linearities e.g. relu+ or sigmoid, should be added, at least in the supplementary section. This is important to complete the overall picture of how the compression effect depends on having specific activation functions. In section 3, a sentence or two should be added to describe what a \"teacher-student setup\" is, and how it is relevant/interesting. Also in section 3, the cases where batch gradient descent is used and where stochastic gradient descent is used should be pointed out much more clearly. It is mentioned in the first line of page 7 that batch gradient descent is used, but it is not clear why SGD couldn't have been used to keep things consistent. This applies to figure 4 too. In section 4, it seems inconsistent that the comparison of SGD vs BGD is done using linear network as opposed to a relu network which is what's used in Section 2. At the least, a comparison using relu should be added to the supplementary section. Minor comments The different figure styles using in Fig 4A and C that have the same quantities plotted makes it confusing. An additional minor comment on the figures: some of the labels are hard to read on the manuscript.", "rating": "7: Good paper, accept", "reply_text": "Please also see our comments to all reviewers above . -PROS : The paper is very well written and makes its points very clearly . To the extent of my knowledge , the content is original . Since it clearly elucidates the limitations of IB theory in its ability to analyse deep networks , I think it is a significant contribution worthy of acceptance . The experiments are also well designed and executed . Thank you ! -CONS : On the downside , the limitations exposed are done so empirically , but the underlying theoretical causes are not explored ( although this could be potentially because this is hard to do ) . Also , the paper exposes the limitations of another paper published in a non-peer reviewed location ( arXiv ) which potentially limits its applicability and significance . While we agree that we have not been able to prove theoretically that , for instance , ReLUs will not compress , we do believe we have elucidated some of the theoretical causes : we present a minimal three neuron model that exhibits the compression phenomenon and give an explicit formula for the binning-based MI estimate ; and we give exact calculations of the MI for the linear case , for which the generalization behavior is known . Finally , we now directly discuss the fact that SGD does not necessarily behave like BGD plus additive noise ( and hence there is no stochastic relaxation to a Gibbs distribution ) . Although the information bottleneck theory of deep learning has appeared only as an arXiv paper , it has achieved attention through video lectures and articles in the popular press . Most importantly from our perspective , researchers are actively attempting to build new methods off of the ideas in the information bottleneck theory , and we believe our results could be significant to those efforts\u2014this , in our view , is the main value in our present work ."}, {"review_id": "ry_WPG-A--2", "review_text": "A thorough investigation on Info Bottleneck and deep learning, nice to read with interesting experiments and references. Even though not all of the approach is uncontroversial (as the discussion shows), the paper contributes to much needed theory of deep learning rather than just another architecture. Estimating the mutual information could have been handled in a more sophisticated way (eg using a Kraskov estimator rather than simple binning), and given that no noise is usually added the discussion about noise and generalisation doesn't seem to make too much sense to me. It would have been good to see a discussion whether another measurement that would be useful for single-sided saturating nonlinearities that do show a compression (eg information from a combination of layers), from learnt representations that are different to representations learnt using double-sided nonlinearities. Regarding the finite representation of units (as in the discussion) it might be helpful to also consider an implementation of a network with arbitrary precision arithmetic as an additional experiment. Overall I think it would be nice to see the paper accepted at the very least to continue the discussion. ", "rating": "7: Good paper, accept", "reply_text": "Please also note our comments to all reviewers above . -A thorough investigation on Info Bottleneck and deep learning , nice to read with interesting experiments and references . Even though not all of the approach is uncontroversial ( as the discussion shows ) , the paper contributes to much needed theory of deep learning rather than just another architecture . Thanks for the encouraging comments ! -Estimating the mutual information could have been handled in a more sophisticated way ( eg using a Kraskov estimator rather than simple binning ) , and given that no noise is usually added the discussion about noise and generalisation does n't seem to make too much sense to me . We now include the Kraskov estimator as well as a nonparametric KDE estimator , which show similar results to the binning-based estimate . We have revised the text to clarify that the ` `` noise '' in the student-teacher section on generalization is fundamentally different from the noise added to representations for analysis . It represents approximation error ( i.e. , aspects of the target function which even the best neural network of a given architecture can not model ) , and is part of generating an interesting dataset based on a teacher . The noise added to representations for analysis , by contrast , is an assumption which affects the student network itself , and is not part of the operation of the student network in practice . -It would have been good to see a discussion whether another measurement that would be useful for single-sided saturating nonlinearities that do show a compression ( eg information from a combination of layers ) , from learnt representations that are different to representations learnt using double-sided nonlinearities . So long as hidden activities are continuous , we believe that MI between the input and multiple layers simultaneously should show similar dynamics . Given our results , it seems that single-sided saturating nonlinearities do not in general compress , and this would carry through to measures that combine multiple layers ( because these layers form a Markov chain ) . -Regarding the finite representation of units ( as in the discussion ) it might be helpful to also consider an implementation of a network with arbitrary precision arithmetic as an additional experiment . Overall I think it would be nice to see the paper accepted at the very least to continue the discussion . Thank you for the suggestion , we considered doing an experiment with arbitrary precision but were able to rule out this concern through another route : if noise in batch gradient descent from numerical precision causes the weights to converge to a Gibbs distribution , and this in turn causes compression , then we should see compression in ReLU or linear networks trained with BGD . However we do not , as we now show in Fig.5D , which makes this explanation unlikely in our eyes . Moreover , even the noise in SGD appears insufficient to cause compression for ReLU or linear networks , and hence is unlikely to be the source of compression more generally ."}], "0": {"review_id": "ry_WPG-A--0", "review_text": "This paper presents a study on the Information Bottleneck (IB) theory of deep learning, providing results in contrasts to the main theory claims. According to the authors, the IB theory suggests that the network generalization is mainly due to a \u2018compression phase\u2019 in the information plane occurring after a \u2018fitting phase\u2019 and that the \u2018compression phase\u2019 is due to the stochastic gradient decent (SDG). Instead, the results provided by this paper show that: the generalization can happen even without compression; that SDG is not the primary factor in compression; and that the compression does not necessarily occur after the \u2018fitting phase\u2019. Overall, the paper tackles the IB theory claims with consistent methodology, thus providing substantial arguments against the IB theory. The main concern is that the paper is built to argue against another theoretical work, raising a substantial discussion with the authors of the IB theory. This paper should carefully address all the raised arguments in the main text. There are, moreover, some open questions that are not fully clear in this contribution: 1) To evaluate the mutual information in the ReLu networks (sec. 2) the authors discretize the output activity in their range. Should the non-linearity of ReLu be considered as a form of compression? Do you check the ratio of ReLus that are not active during training or the ratio of inputs that fall into the negative domain of each ReLu? 2) Since one of today common topics is the training of deep neural networks with lower representational precision, could the quantization error due to the low precision be considered as a form of noise inserted in the network layers that influences the generalization performance in deep neural networks? 3) What are the main conclusions or impact of the present study in the theory of neural networks? Is it the authors aim to just demonstrate that the IB theory is not correct? Perhaps, the paper should empathize the obtained results not just in contrast to the other theory, but proactively in agreement with a new proposal. Finally, a small issue comes from the Figures that need some improvement. In most of the cases (Figure 3 C, D; Figure 4 A, B, C; Figure 5 C, D; Figure 6) the axes font is too small to be read. Figure 3C is also very unclear. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Please also see our comments to all reviewers above . -This paper presents a study on the Information Bottleneck ( IB ) theory of deep learning , providing results in contrasts to the main theory claims . According to the authors , the IB theory suggests that the network generalization is mainly due to a \u2018 compression phase \u2019 in the information plane occurring after a \u2018 fitting phase \u2019 and that the \u2018 compression phase \u2019 is due to the stochastic gradient decent ( SDG ) . Instead , the results provided by this paper show that : the generalization can happen even without compression ; that SDG is not the primary factor in compression ; and that the compression does not necessarily occur after the \u2018 fitting phase \u2019 . Overall , the paper tackles the IB theory claims with consistent methodology , thus providing substantial arguments against the IB theory . Thank you ! -The main concern is that the paper is built to argue against another theoretical work , raising a substantial discussion with the authors of the IB theory . This paper should carefully address all the raised arguments in the main text . The revision now addresses these arguments in the main text . We believe the conclusions in our original submission still stand , and are now supported by additional experiments . -There are , moreover , some open questions that are not fully clear in this contribution : -1 ) To evaluate the mutual information in the ReLu networks ( sec.2 ) the authors discretize the output activity in their range . Should the non-linearity of ReLu be considered as a form of compression ? Do you check the ratio of ReLus that are not active during training or the ratio of inputs that fall into the negative domain of each ReLu ? Our discretization does consider the nonlinearity of ReLU , which could in principle lead to compression if ReLUs tended to inactivate over the course of training . However they do not seem to in practice , which can be seen from the histograms of activity over training in Fig.17.The bottom-most bin contains zero , the ReLU saturation value . There is no consistent trend in the number of saturated ReLU activations over training , with most layers ending up about where they started , with neurons inactive on roughly 50 % of examples . -2 ) Since one of today common topics is the training of deep neural networks with lower representational precision , could the quantization error due to the low precision be considered as a form of noise inserted in the network layers that influences the generalization performance in deep neural networks ? Thank you for the suggestion , we now point to this possibility in the discussion . For networks which explicitly incorporate noise in their architecture ( either through quantization or noise injection ) , the broader information bottleneck theory may apply and yield potentially new training algorithms . Our point in this paper is that the specific claims of the information bottleneck theory of deep learning , which attempt to explain the performance of \u201c vanilla \u201d deep networks with no quantization or noise , do not in fact explain the generalization performance of these networks . -3 ) What are the main conclusions or impact of the present study in the theory of neural networks ? Is it the authors aim to just demonstrate that the IB theory is not correct ? Perhaps , the paper should empathize the obtained results not just in contrast to the other theory , but proactively in agreement with a new proposal . There are a variety of theories ( several cited in our introduction ) which may be consistent with all of the results reported in this paper . Most directly , the results in Advani & Saxe , 2017 successfully account for generalization behavior in the linear models we study . However even there , it remains to be seen how those ideas might apply to deep nonlinear networks . It is outside the scope of this paper to provide strong support for any one of these theories , as singling out one theory as better would require experiments designed to specifically test them , which must be left for future work . Our aim rather was to carefully and fairly inspect an exciting and , it seemed to us , promising theory , and the result turned out to be somewhat negative . In our view , negative results are a critical component of a healthy research ecosystem , and on occasion science advances through falsification . The impact of the present study on the theory of neural networks is to help narrow the field of plausible candidate theories . We expect our results to be important to researchers currently building off of the information bottleneck theory of deep learning . -Finally , a small issue comes from the Figures that need some improvement . In most of the cases ( Figure 3 C , D ; Figure 4 A , B , C ; Figure 5 C , D ; Figure 6 ) the axes font is too small to be read . Figure 3C is also very unclear . We apologize for this issue , we have increased the size of several figures and are working towards a revision with the rest corrected ."}, "1": {"review_id": "ry_WPG-A--1", "review_text": "The authors address the issue of whether the information bottleneck (IB) theory can provide insight into the working of deep networks. They show, using some counter-examples, that the previous understanding of IB theory and its application to deep networks is limited. PROS: The paper is very well written and makes its points very clearly. To the extent of my knowledge, the content is original. Since it clearly elucidates the limitations of IB theory in its ability to analyse deep networks, I think it is a significant contribution worthy of acceptance. The experiments are also well designed and executed. CONS: On the downside, the limitations exposed are done so empirically, but the underlying theoretical causes are not explored (although this could be potentially because this is hard to do). Also, the paper exposes the limitations of another paper published in a non-peer reviewed location (arXiv) which potentially limits its applicability and significance. Some detailed comments: In section 2, the influence of binning on how the mutual information is calculated should be made clear. Since the comparison is between a bounded non-linearity and an unbounded one, it is not self-evident how the binning in the latter case should be done. A justification for the choice made for binning the relu case would be helpful. In the same section, it is claimed that the dependence of the mutual information I(X; T) on the magnitude of the weights of the network explains why a tanh non-linearity shows the compression effect (non-monotonicity vs I(X; T)) in the information plane dynamics. But the claim that large weights are required for doing anything useful is unsubstantiated and would benefit from having citations to papaers that discuss this issue. If networks with small weights are able to learn most datasets, the arguments given in this section wouldn't be applicable in its entirety. Additionally, figures that show the phase plane dynamics for other non-linearities e.g. relu+ or sigmoid, should be added, at least in the supplementary section. This is important to complete the overall picture of how the compression effect depends on having specific activation functions. In section 3, a sentence or two should be added to describe what a \"teacher-student setup\" is, and how it is relevant/interesting. Also in section 3, the cases where batch gradient descent is used and where stochastic gradient descent is used should be pointed out much more clearly. It is mentioned in the first line of page 7 that batch gradient descent is used, but it is not clear why SGD couldn't have been used to keep things consistent. This applies to figure 4 too. In section 4, it seems inconsistent that the comparison of SGD vs BGD is done using linear network as opposed to a relu network which is what's used in Section 2. At the least, a comparison using relu should be added to the supplementary section. Minor comments The different figure styles using in Fig 4A and C that have the same quantities plotted makes it confusing. An additional minor comment on the figures: some of the labels are hard to read on the manuscript.", "rating": "7: Good paper, accept", "reply_text": "Please also see our comments to all reviewers above . -PROS : The paper is very well written and makes its points very clearly . To the extent of my knowledge , the content is original . Since it clearly elucidates the limitations of IB theory in its ability to analyse deep networks , I think it is a significant contribution worthy of acceptance . The experiments are also well designed and executed . Thank you ! -CONS : On the downside , the limitations exposed are done so empirically , but the underlying theoretical causes are not explored ( although this could be potentially because this is hard to do ) . Also , the paper exposes the limitations of another paper published in a non-peer reviewed location ( arXiv ) which potentially limits its applicability and significance . While we agree that we have not been able to prove theoretically that , for instance , ReLUs will not compress , we do believe we have elucidated some of the theoretical causes : we present a minimal three neuron model that exhibits the compression phenomenon and give an explicit formula for the binning-based MI estimate ; and we give exact calculations of the MI for the linear case , for which the generalization behavior is known . Finally , we now directly discuss the fact that SGD does not necessarily behave like BGD plus additive noise ( and hence there is no stochastic relaxation to a Gibbs distribution ) . Although the information bottleneck theory of deep learning has appeared only as an arXiv paper , it has achieved attention through video lectures and articles in the popular press . Most importantly from our perspective , researchers are actively attempting to build new methods off of the ideas in the information bottleneck theory , and we believe our results could be significant to those efforts\u2014this , in our view , is the main value in our present work ."}, "2": {"review_id": "ry_WPG-A--2", "review_text": "A thorough investigation on Info Bottleneck and deep learning, nice to read with interesting experiments and references. Even though not all of the approach is uncontroversial (as the discussion shows), the paper contributes to much needed theory of deep learning rather than just another architecture. Estimating the mutual information could have been handled in a more sophisticated way (eg using a Kraskov estimator rather than simple binning), and given that no noise is usually added the discussion about noise and generalisation doesn't seem to make too much sense to me. It would have been good to see a discussion whether another measurement that would be useful for single-sided saturating nonlinearities that do show a compression (eg information from a combination of layers), from learnt representations that are different to representations learnt using double-sided nonlinearities. Regarding the finite representation of units (as in the discussion) it might be helpful to also consider an implementation of a network with arbitrary precision arithmetic as an additional experiment. Overall I think it would be nice to see the paper accepted at the very least to continue the discussion. ", "rating": "7: Good paper, accept", "reply_text": "Please also note our comments to all reviewers above . -A thorough investigation on Info Bottleneck and deep learning , nice to read with interesting experiments and references . Even though not all of the approach is uncontroversial ( as the discussion shows ) , the paper contributes to much needed theory of deep learning rather than just another architecture . Thanks for the encouraging comments ! -Estimating the mutual information could have been handled in a more sophisticated way ( eg using a Kraskov estimator rather than simple binning ) , and given that no noise is usually added the discussion about noise and generalisation does n't seem to make too much sense to me . We now include the Kraskov estimator as well as a nonparametric KDE estimator , which show similar results to the binning-based estimate . We have revised the text to clarify that the ` `` noise '' in the student-teacher section on generalization is fundamentally different from the noise added to representations for analysis . It represents approximation error ( i.e. , aspects of the target function which even the best neural network of a given architecture can not model ) , and is part of generating an interesting dataset based on a teacher . The noise added to representations for analysis , by contrast , is an assumption which affects the student network itself , and is not part of the operation of the student network in practice . -It would have been good to see a discussion whether another measurement that would be useful for single-sided saturating nonlinearities that do show a compression ( eg information from a combination of layers ) , from learnt representations that are different to representations learnt using double-sided nonlinearities . So long as hidden activities are continuous , we believe that MI between the input and multiple layers simultaneously should show similar dynamics . Given our results , it seems that single-sided saturating nonlinearities do not in general compress , and this would carry through to measures that combine multiple layers ( because these layers form a Markov chain ) . -Regarding the finite representation of units ( as in the discussion ) it might be helpful to also consider an implementation of a network with arbitrary precision arithmetic as an additional experiment . Overall I think it would be nice to see the paper accepted at the very least to continue the discussion . Thank you for the suggestion , we considered doing an experiment with arbitrary precision but were able to rule out this concern through another route : if noise in batch gradient descent from numerical precision causes the weights to converge to a Gibbs distribution , and this in turn causes compression , then we should see compression in ReLU or linear networks trained with BGD . However we do not , as we now show in Fig.5D , which makes this explanation unlikely in our eyes . Moreover , even the noise in SGD appears insufficient to cause compression for ReLU or linear networks , and hence is unlikely to be the source of compression more generally ."}}