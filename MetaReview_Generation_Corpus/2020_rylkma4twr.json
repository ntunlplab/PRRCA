{"year": "2020", "forum": "rylkma4twr", "title": "Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML", "decision": "Reject", "meta_review": "This paper proposes convergence results for zeroth-order optimization.\n\nOne of the main complaints was that ZO has limited use in ML. I appreciate the authors' response that there are cases where gradients are not easily available, especially for black-box attacks.\n\nHowever, I find the limited applicability an issue for ICLR and I encourage the authors to find a conference that is more suited to that work.", "reviews": [{"review_id": "rylkma4twr-0", "review_text": "The authors aim to propose new algorithms for min-max optimization problem when the gradients are not available and establish sublinear convergence of the algorithm. I don't think this paper can be accepted for ICLR for the following reasons: 1. For Setting (a) (One-sided black-box), the theory can be established by the same analysis for ZO optimization by optimizing y. Even by a proximal step for y, the analysis is essentially the same as ZO where an estimation of the gradient for x is conducted. 2. The assumptions A1 and A2 are hardly satisfied in ML applications, where the objective is essentially smooth. The authors should at least analyze the case where a sub/super-gradients is available. 3. Also, for most ML problems we have today, I don't find many applications where the gradients are not available, and I thus feel that it is not interesting to consider ZO optimizations.", "rating": "3: Weak Reject", "reply_text": "Many thanks for the constructive comments . We answered your questions as below . # Question : For Setting ( a ) ( One-sided black-box ) , the theory can be established by the same analysis for ZO optimization by optimizing y . Even by a proximal step for y , the analysis is essentially the same as ZO where an estimation of the gradient for x is conducted . # Response : In the revision , we have further clarified the technique challenges in convergence analysis of ZO-Min-Max . We provide more details as below . First , we would like to clarify that even at the one-sided black-box setting , ZO-Min-Max conducts alternating optimization using one-step ZO-PGD and PGA with respect to $ x $ and $ y $ respectively . This is different from a reduced ZO optimization problem with respect to x , namely , problem $ \\min_ { x } h ( x ) \\triangleq \\min_y f ( x , y ) $ , which requires the algorithm to access $ h ( x ) $ for a ZO gradient estimation , namely , obtaining the solution to problem $ \\min_y f ( x , y ) $ given $ x $ . However , it is usually non-trivial or computationally intensive to solve $ \\min_y f ( x , y ) $ directly . Thus , ZO-Min-Max is lighter in computation and is much simpler in implementation . Even by a proximal step for $ y $ , our analysis is also NOT the same as ZO where an estimation of the gradient for $ x $ is conducted . Suppose that one manages to consider the min-max objective as a function like $ h^ { \\prime } ( x ) = f ( x , g ( x , y^ { t-1 } ) ) $ , where $ g ( x , y^ { t-1 } ) $ is the proximal step , in the conventional ZO analysis , the query of $ h^ { \\prime } $ over $ x = \\tilde x $ for gradient estimation relies on querying $ g ( x , y^ { t-1 } ) $ at $ x = \\tilde x $ . This is different from our algorithm , where an estimation of the gradient for $ x $ is conducted by fixing $ y $ as a constant , leading to simpler gradient estimation but more involved convergence analysis , which is elaborated on in the following . The key difficulty stems from the alternating algorithmic nature ( namely , primal-dual framework ) as the problem is in the min-max form , which leads to opposite optimization directions ( minimization vs maximization ) over variable x and y respectively . Even applying ZO optimization to one side ( say x ) , it needs to quantify the effect of ZO gradient estimation on the descent over both x and y ; see the detailed technical reasons : Gradient estimate bias mitigation : classic ZO analysis is to quantify the gradient estimate $ \\nabla f ( x^t ) $ at iteration t in the sense that iterates simply move from $ x^t $ to $ x^ { t+1 } $ . However , in min-max optimization , note that both $ \\nabla_x f ( x^ { t+1 } , y^t ) $ and $ \\nabla_y f ( x^ { t+1 } , y^ { t+1 } ) $ are evaluated at x and y , thus , the trajectory of the proposed algorithm from t to t+1 , i.e. , $ ( x^t , y^t ) - > ( x^ { t+1 } , y^t ) - > ( x^ { t+1 } , y^ { t+1 } ) $ , is different from the classic ZO minimization . If we directly applied the ZO convergence analysis , it becomes quite difficult to quantify the change of the objective value caused by optimizing y since the iterates have an intermediate state which is ( x^ { t+1 } , y^t ) , making the convergence analysis of min-max optimization different from the standard ZO minimization analysis . Potential function construction : Since optimizing y will increase the objective value , in this work , a new potential/Lyapunov-like function is constructed to show that the ascent of optimizing y is dominated by the descent of performing minimization over x based on this new function , where the stepsizes of both sides must be chosen properly . Therefore , the convergence analysis of ZO-Min-Max for solving one-sided black-box problem can not be simply established using the same analysis of ZO optimization after optimizing y . Also , our one-sided black-box analysis is served as the preliminary results for our more general analysis in the two-sided black-box case , where the ZO gradient estimation errors in both minimization and maximization affects the convergence rate"}, {"review_id": "rylkma4twr-1", "review_text": "The paper presents an algorithm for performing min-max optimisation without gradients and analyses its convergence. The algorithm is evaluated for the min-max problems that arise in the context of adversarial attacks. The presented algorithm is a natural application of a zeroth-order gradient estimator and the authors also prove that the algorithm has a sublinear convergence rate (in a specific sense). Considering that the algorithm merely applies the zeroth-order gradient estimator to min-max problems, the algorithm itself only makes up a somewhat novel contribution. However, to the best of my knowledge, it has not been used in this context before and personally I find the algorithm quite appealing. In fact, due to its simplicity it is essentially something that anyone could implement from scratch. Perhaps a more important contribution is that the authors provide a fairly extensive convergence analysis, which is an important tool in analysing the algorithm and its properties. Unfortunately, it is not trivial to understand the presented convergence results and their practical implications (if any). For instance, equation (10), which is arguably one of the key equations in the paper, contains variables zeta, nu and P1, all of which depend on a number of other variables in a fairly complicated manner. The expression in (10) also contains terms that do not depend on T and it is not obvious how large these terms might be in practice (in the event that the assumptions are at least approximately true in a local region). Even though I am somewhat sceptical to the practical relevance of this convergence analysis, I recognise that it is an interesting and fascinating achievement that the authors have managed to provide a convergence analysis of an algorithm which is based on black-box min-max optimisation. ", "rating": "6: Weak Accept", "reply_text": "Many thanks for the positive comments about our work . We addressed your questions as below . # Question : Complicated parameters and practical relevance of this convergence analysis . # Response : In the revised version , we made a table in Appendix A.1 to clarify the parameters involved in our convergence rate , and have provided the practical relevance of this convergence analysis . We summarize our main points as below . 1 ) Parameter $ \\zeta $ : Since $ \\zeta $ appears in the denominator of the derived convergence error , it is necessary to show a non-trivial lower bound on $ \\zeta $ . Remark 1 after Theorem 1 made a clarification on it : Such a lower bound exists under appropriate choices of the learning rates $ \\alpha $ and $ \\beta $ . 2 ) Parameter $ c $ : Since $ c $ is inversely proportional to learning rates $ \\alpha $ and $ \\beta $ , to guarantee the constant effect of the ratio $ c/\\xi $ , it is better not to set these learning rate too small ; see a specification of learning rates in Remark 1 & 2 . 3 ) Parameter $ \\nu $ : Since $ \\nu $ is non-negative and appears in terms of $ -\\nu R^2 $ , it will not make convergence rate worse . 4 ) Parameter $ P_1 $ : $ P_1 $ is the initial value of the potential function in ( 8 ) . By setting the learning rate $ \\beta $ as Remark 2 , P1 is then upper bounded by a constant determined by the initial value of the objective function , the distance of the first two updates , Lipschitz constant $ L_y $ and strongly concave parameter $ \\gamma $ . Local region bias and practical relevance : Remark 3 showed that the local region bias ( namely , stationary gap ) is controlled by the mini-batch size b and the number of random direction vectors q . Thus , a large b or q can improve the iteration complexity of ZO-Min-Max , but would require $ O ( bq ) $ times more function queries per iteration from Eq . ( 2 ) .This shows the tradeoff between iteration complexity and function query complexity in ZO optimization ."}, {"review_id": "rylkma4twr-2", "review_text": "This paper considers zeroth-order method for min-max optimization (ZO-MIN-MAX) in two cases: one-sided black box (for outer minimization) and two-sided black box (for both inner maximization and outer minimization). Convergence analysis is carefully provided to show that ZO-MIN-MAX converges to a neighborhood of stationary points. Then, the authors empirically compare several methods on 1) adversarial attack on ImageNet with deep networks, and 2) black-box poisoning attack on logistic regression. The results show that ZO-MIN-MAX can provide satisfactory performance on these tasks. In general a good paper with dense content, clear organization and writing. However, the experiment part does not seem truly convincing. 1. What is the relationship between Eqn.(13) and the proposed ZO-MIN-MAX? It seem that in the experiment you compare using this loss ( Eqn.(13) ) against finite-sum loss, but both with ZO-MIN-MAX algorithm? In figure 1 and 2, I don\u2019t see a competing method. So the point here is that the loss Eqn.(13) is better, but not the proposed algorithm? I think you should compare different optimization algorithm under same loss, e.g. something like Eqn.(13)+ZO-MIN-MAX vs. Eqn.(13)+FO-MIN-MAX. This is not evident to show that ZO-MIN-MAX is better than other zero-th order methods. 2. I would suggest comparing to more zeroth-order methods in the experiment. From the experiments I cannot tell whether ZO-MIN-MAX is good enough compared with other methods", "rating": "6: Weak Accept", "reply_text": "Many thanks for the positive comments about our work . We addressed your questions as below . # Question : What is the relationship between Eqn . ( 13 ) and the proposed ZO-MIN-MAX ? # Response : We apologize for the confusion on Eq . ( 13 ) , which is in the form of one-sided black-box optimization problem and was solved by ZO-Min-Max . The objective function of ( 13 ) is a black-box function with respect to the universal adversarial perturbation variable $ x $ since the attacker in practice has no access to the configuration of a neural network model , and thus can not perform back-propagation to obtain gradients . This is known as the balck-box attack [ Ilyas , Andrew , et al ; Chen , Pin-Yu , et al ] . Ilyas , Andrew , et al . `` Black-box adversarial attacks with limited queries and information . '' ICML18 Chen , Pin-Yu , et al . `` Zoo : Zeroth order optimization based black-box attacks to deep neural networks without training substitute models . '' Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security . ACM , 2017 . # Question : It seems that in the experiment you compare using this loss ( Eqn . ( 13 ) ) against finite-sum loss , but both with ZO-MIN-MAX algorithm ? In figure 1 and 2 , I don \u2019 t see a competing method . So the point here is that the loss Eqn . ( 13 ) is better , but not the proposed algorithm ? # Reponse : We apologize for the confusion on our first experiment to compare with the finite-sum ( averaging ) attack loss . First , when the finite-sum loss is applied , problem ( 13 ) reduces to the black-box optimization problem with a single objective function . It is thus not in the form of min-max optimization , and we solved it using the standard ZO gradient descent method rather than ZO-Min-Max . Second , although ZO-Min-Max and ZO-Finite-Sum correspond to different losses , they are competing methods in terms of attack performance to misclassify a neural network model . This comparison was motivated by the previous work on designing the adversarial perturbation against model ensembles [ Liu et al. , 2018 ] in which the averaging attack loss over multiple models was considered . Thus , the proposed comparison with ZO-Finite-Sum aims to verify that the min-max formulation in ( 13 ) is reasonable ensemble attack formulation and in fact , it outperforms the conventional formulation design ( using the averaging attack loss ) . Such a conclusion is supported by 1 ) the fast convergence of individual attack loss under each model-class pair ( Figure 1-c ) and 2 ) self-adjusted importance weights ( in terms of w ) in ensemble attack generation ( Figure A2 ) , which shows that imposing equal importance ( namely , averaging ) over individual attack losses might not be a good strategy for the design of ensemble attack . Moreover , Figure A3 was used to compare the success or failure of our obtained universal perturbation with the attacking difficulty of using per-image PGD attack baseline ( Madry et al. , 2017b ) . Both ZO-Finite-Sum and the per-image PGD attack are competing methods to ZO-Finite-Sum since all of them enjoy the same purpose to misclassify a neural network model although they use different attack loss functions . Besides , to the best of our knowledge , we are not aware of any existing black-box min-max solver that is able to scale to problem ( 13 ) of size $ 157323 $ ( corresponding to the pixel number of an ImageNet image ) J. Liu , Weiming Zhang , and Nenghai Yu . Iterative ensemble adversarial attack . 2018 Aleksander Madry , Aleksandar Makelov , Ludwig Schmidt , Dimitris Tsipras , and Adrian Vladu . Towards deep learning models resistant to adversarial attacks . arXiv preprint arXiv:1706.06083 , 2017b . # Question : I think you should compare different optimization algorithm under same loss , e.g.something like Eqn . ( 13 ) +ZO-MIN-MAX vs . Eqn . ( 13 ) +FO-MIN-MAX . # Response : Thanks for the valuable suggestion . We have added new results in Figure 1a-1b and Figure A2 by comparing ZO-Min-Max with FO-Min-Max . As expected , FO-Min-Max yields faster convergence than ZO-Min-Max , however , the former has to access the full knowledge on the target neural network for computing the gradient of the attack loss . This is not a practical black-box attack setting . Moreover , it is also expected that ZO-Min-Max may converge to a neighborhood of the stationary point ."}], "0": {"review_id": "rylkma4twr-0", "review_text": "The authors aim to propose new algorithms for min-max optimization problem when the gradients are not available and establish sublinear convergence of the algorithm. I don't think this paper can be accepted for ICLR for the following reasons: 1. For Setting (a) (One-sided black-box), the theory can be established by the same analysis for ZO optimization by optimizing y. Even by a proximal step for y, the analysis is essentially the same as ZO where an estimation of the gradient for x is conducted. 2. The assumptions A1 and A2 are hardly satisfied in ML applications, where the objective is essentially smooth. The authors should at least analyze the case where a sub/super-gradients is available. 3. Also, for most ML problems we have today, I don't find many applications where the gradients are not available, and I thus feel that it is not interesting to consider ZO optimizations.", "rating": "3: Weak Reject", "reply_text": "Many thanks for the constructive comments . We answered your questions as below . # Question : For Setting ( a ) ( One-sided black-box ) , the theory can be established by the same analysis for ZO optimization by optimizing y . Even by a proximal step for y , the analysis is essentially the same as ZO where an estimation of the gradient for x is conducted . # Response : In the revision , we have further clarified the technique challenges in convergence analysis of ZO-Min-Max . We provide more details as below . First , we would like to clarify that even at the one-sided black-box setting , ZO-Min-Max conducts alternating optimization using one-step ZO-PGD and PGA with respect to $ x $ and $ y $ respectively . This is different from a reduced ZO optimization problem with respect to x , namely , problem $ \\min_ { x } h ( x ) \\triangleq \\min_y f ( x , y ) $ , which requires the algorithm to access $ h ( x ) $ for a ZO gradient estimation , namely , obtaining the solution to problem $ \\min_y f ( x , y ) $ given $ x $ . However , it is usually non-trivial or computationally intensive to solve $ \\min_y f ( x , y ) $ directly . Thus , ZO-Min-Max is lighter in computation and is much simpler in implementation . Even by a proximal step for $ y $ , our analysis is also NOT the same as ZO where an estimation of the gradient for $ x $ is conducted . Suppose that one manages to consider the min-max objective as a function like $ h^ { \\prime } ( x ) = f ( x , g ( x , y^ { t-1 } ) ) $ , where $ g ( x , y^ { t-1 } ) $ is the proximal step , in the conventional ZO analysis , the query of $ h^ { \\prime } $ over $ x = \\tilde x $ for gradient estimation relies on querying $ g ( x , y^ { t-1 } ) $ at $ x = \\tilde x $ . This is different from our algorithm , where an estimation of the gradient for $ x $ is conducted by fixing $ y $ as a constant , leading to simpler gradient estimation but more involved convergence analysis , which is elaborated on in the following . The key difficulty stems from the alternating algorithmic nature ( namely , primal-dual framework ) as the problem is in the min-max form , which leads to opposite optimization directions ( minimization vs maximization ) over variable x and y respectively . Even applying ZO optimization to one side ( say x ) , it needs to quantify the effect of ZO gradient estimation on the descent over both x and y ; see the detailed technical reasons : Gradient estimate bias mitigation : classic ZO analysis is to quantify the gradient estimate $ \\nabla f ( x^t ) $ at iteration t in the sense that iterates simply move from $ x^t $ to $ x^ { t+1 } $ . However , in min-max optimization , note that both $ \\nabla_x f ( x^ { t+1 } , y^t ) $ and $ \\nabla_y f ( x^ { t+1 } , y^ { t+1 } ) $ are evaluated at x and y , thus , the trajectory of the proposed algorithm from t to t+1 , i.e. , $ ( x^t , y^t ) - > ( x^ { t+1 } , y^t ) - > ( x^ { t+1 } , y^ { t+1 } ) $ , is different from the classic ZO minimization . If we directly applied the ZO convergence analysis , it becomes quite difficult to quantify the change of the objective value caused by optimizing y since the iterates have an intermediate state which is ( x^ { t+1 } , y^t ) , making the convergence analysis of min-max optimization different from the standard ZO minimization analysis . Potential function construction : Since optimizing y will increase the objective value , in this work , a new potential/Lyapunov-like function is constructed to show that the ascent of optimizing y is dominated by the descent of performing minimization over x based on this new function , where the stepsizes of both sides must be chosen properly . Therefore , the convergence analysis of ZO-Min-Max for solving one-sided black-box problem can not be simply established using the same analysis of ZO optimization after optimizing y . Also , our one-sided black-box analysis is served as the preliminary results for our more general analysis in the two-sided black-box case , where the ZO gradient estimation errors in both minimization and maximization affects the convergence rate"}, "1": {"review_id": "rylkma4twr-1", "review_text": "The paper presents an algorithm for performing min-max optimisation without gradients and analyses its convergence. The algorithm is evaluated for the min-max problems that arise in the context of adversarial attacks. The presented algorithm is a natural application of a zeroth-order gradient estimator and the authors also prove that the algorithm has a sublinear convergence rate (in a specific sense). Considering that the algorithm merely applies the zeroth-order gradient estimator to min-max problems, the algorithm itself only makes up a somewhat novel contribution. However, to the best of my knowledge, it has not been used in this context before and personally I find the algorithm quite appealing. In fact, due to its simplicity it is essentially something that anyone could implement from scratch. Perhaps a more important contribution is that the authors provide a fairly extensive convergence analysis, which is an important tool in analysing the algorithm and its properties. Unfortunately, it is not trivial to understand the presented convergence results and their practical implications (if any). For instance, equation (10), which is arguably one of the key equations in the paper, contains variables zeta, nu and P1, all of which depend on a number of other variables in a fairly complicated manner. The expression in (10) also contains terms that do not depend on T and it is not obvious how large these terms might be in practice (in the event that the assumptions are at least approximately true in a local region). Even though I am somewhat sceptical to the practical relevance of this convergence analysis, I recognise that it is an interesting and fascinating achievement that the authors have managed to provide a convergence analysis of an algorithm which is based on black-box min-max optimisation. ", "rating": "6: Weak Accept", "reply_text": "Many thanks for the positive comments about our work . We addressed your questions as below . # Question : Complicated parameters and practical relevance of this convergence analysis . # Response : In the revised version , we made a table in Appendix A.1 to clarify the parameters involved in our convergence rate , and have provided the practical relevance of this convergence analysis . We summarize our main points as below . 1 ) Parameter $ \\zeta $ : Since $ \\zeta $ appears in the denominator of the derived convergence error , it is necessary to show a non-trivial lower bound on $ \\zeta $ . Remark 1 after Theorem 1 made a clarification on it : Such a lower bound exists under appropriate choices of the learning rates $ \\alpha $ and $ \\beta $ . 2 ) Parameter $ c $ : Since $ c $ is inversely proportional to learning rates $ \\alpha $ and $ \\beta $ , to guarantee the constant effect of the ratio $ c/\\xi $ , it is better not to set these learning rate too small ; see a specification of learning rates in Remark 1 & 2 . 3 ) Parameter $ \\nu $ : Since $ \\nu $ is non-negative and appears in terms of $ -\\nu R^2 $ , it will not make convergence rate worse . 4 ) Parameter $ P_1 $ : $ P_1 $ is the initial value of the potential function in ( 8 ) . By setting the learning rate $ \\beta $ as Remark 2 , P1 is then upper bounded by a constant determined by the initial value of the objective function , the distance of the first two updates , Lipschitz constant $ L_y $ and strongly concave parameter $ \\gamma $ . Local region bias and practical relevance : Remark 3 showed that the local region bias ( namely , stationary gap ) is controlled by the mini-batch size b and the number of random direction vectors q . Thus , a large b or q can improve the iteration complexity of ZO-Min-Max , but would require $ O ( bq ) $ times more function queries per iteration from Eq . ( 2 ) .This shows the tradeoff between iteration complexity and function query complexity in ZO optimization ."}, "2": {"review_id": "rylkma4twr-2", "review_text": "This paper considers zeroth-order method for min-max optimization (ZO-MIN-MAX) in two cases: one-sided black box (for outer minimization) and two-sided black box (for both inner maximization and outer minimization). Convergence analysis is carefully provided to show that ZO-MIN-MAX converges to a neighborhood of stationary points. Then, the authors empirically compare several methods on 1) adversarial attack on ImageNet with deep networks, and 2) black-box poisoning attack on logistic regression. The results show that ZO-MIN-MAX can provide satisfactory performance on these tasks. In general a good paper with dense content, clear organization and writing. However, the experiment part does not seem truly convincing. 1. What is the relationship between Eqn.(13) and the proposed ZO-MIN-MAX? It seem that in the experiment you compare using this loss ( Eqn.(13) ) against finite-sum loss, but both with ZO-MIN-MAX algorithm? In figure 1 and 2, I don\u2019t see a competing method. So the point here is that the loss Eqn.(13) is better, but not the proposed algorithm? I think you should compare different optimization algorithm under same loss, e.g. something like Eqn.(13)+ZO-MIN-MAX vs. Eqn.(13)+FO-MIN-MAX. This is not evident to show that ZO-MIN-MAX is better than other zero-th order methods. 2. I would suggest comparing to more zeroth-order methods in the experiment. From the experiments I cannot tell whether ZO-MIN-MAX is good enough compared with other methods", "rating": "6: Weak Accept", "reply_text": "Many thanks for the positive comments about our work . We addressed your questions as below . # Question : What is the relationship between Eqn . ( 13 ) and the proposed ZO-MIN-MAX ? # Response : We apologize for the confusion on Eq . ( 13 ) , which is in the form of one-sided black-box optimization problem and was solved by ZO-Min-Max . The objective function of ( 13 ) is a black-box function with respect to the universal adversarial perturbation variable $ x $ since the attacker in practice has no access to the configuration of a neural network model , and thus can not perform back-propagation to obtain gradients . This is known as the balck-box attack [ Ilyas , Andrew , et al ; Chen , Pin-Yu , et al ] . Ilyas , Andrew , et al . `` Black-box adversarial attacks with limited queries and information . '' ICML18 Chen , Pin-Yu , et al . `` Zoo : Zeroth order optimization based black-box attacks to deep neural networks without training substitute models . '' Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security . ACM , 2017 . # Question : It seems that in the experiment you compare using this loss ( Eqn . ( 13 ) ) against finite-sum loss , but both with ZO-MIN-MAX algorithm ? In figure 1 and 2 , I don \u2019 t see a competing method . So the point here is that the loss Eqn . ( 13 ) is better , but not the proposed algorithm ? # Reponse : We apologize for the confusion on our first experiment to compare with the finite-sum ( averaging ) attack loss . First , when the finite-sum loss is applied , problem ( 13 ) reduces to the black-box optimization problem with a single objective function . It is thus not in the form of min-max optimization , and we solved it using the standard ZO gradient descent method rather than ZO-Min-Max . Second , although ZO-Min-Max and ZO-Finite-Sum correspond to different losses , they are competing methods in terms of attack performance to misclassify a neural network model . This comparison was motivated by the previous work on designing the adversarial perturbation against model ensembles [ Liu et al. , 2018 ] in which the averaging attack loss over multiple models was considered . Thus , the proposed comparison with ZO-Finite-Sum aims to verify that the min-max formulation in ( 13 ) is reasonable ensemble attack formulation and in fact , it outperforms the conventional formulation design ( using the averaging attack loss ) . Such a conclusion is supported by 1 ) the fast convergence of individual attack loss under each model-class pair ( Figure 1-c ) and 2 ) self-adjusted importance weights ( in terms of w ) in ensemble attack generation ( Figure A2 ) , which shows that imposing equal importance ( namely , averaging ) over individual attack losses might not be a good strategy for the design of ensemble attack . Moreover , Figure A3 was used to compare the success or failure of our obtained universal perturbation with the attacking difficulty of using per-image PGD attack baseline ( Madry et al. , 2017b ) . Both ZO-Finite-Sum and the per-image PGD attack are competing methods to ZO-Finite-Sum since all of them enjoy the same purpose to misclassify a neural network model although they use different attack loss functions . Besides , to the best of our knowledge , we are not aware of any existing black-box min-max solver that is able to scale to problem ( 13 ) of size $ 157323 $ ( corresponding to the pixel number of an ImageNet image ) J. Liu , Weiming Zhang , and Nenghai Yu . Iterative ensemble adversarial attack . 2018 Aleksander Madry , Aleksandar Makelov , Ludwig Schmidt , Dimitris Tsipras , and Adrian Vladu . Towards deep learning models resistant to adversarial attacks . arXiv preprint arXiv:1706.06083 , 2017b . # Question : I think you should compare different optimization algorithm under same loss , e.g.something like Eqn . ( 13 ) +ZO-MIN-MAX vs . Eqn . ( 13 ) +FO-MIN-MAX . # Response : Thanks for the valuable suggestion . We have added new results in Figure 1a-1b and Figure A2 by comparing ZO-Min-Max with FO-Min-Max . As expected , FO-Min-Max yields faster convergence than ZO-Min-Max , however , the former has to access the full knowledge on the target neural network for computing the gradient of the attack loss . This is not a practical black-box attack setting . Moreover , it is also expected that ZO-Min-Max may converge to a neighborhood of the stationary point ."}}