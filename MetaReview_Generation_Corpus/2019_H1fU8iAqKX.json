{"year": "2019", "forum": "H1fU8iAqKX", "title": "A rotation-equivariant convolutional neural network model of primary visual cortex", "decision": "Accept (Poster)", "meta_review": "The overall consensus after an extended discussion of the paper is that this work should be accepted to ICLR. The back-and-forth between reviewers and authors was very productive, and resulted in substantial clarification of the work, and modification (trending positive) of the reviewer scores.", "reviews": [{"review_id": "H1fU8iAqKX-0", "review_text": "\ufeffThis paper applies a rotation-equivariant convolutional neural network model to a dataset of neural responses from mouse primary visual cortex. This submission follows a series of recent papers using deep convolutional neural networks to model visual responses, either in the retina (Batty et al., 2016; McIntosh et al., 2016) or V1 (Cadena et al., 2017; Kindel et al., 2017; Klindt et al., 2017). The authors show that adding rotation equivariance improves the explanatory power of the model compared to non-rotation-equivariant models with similar numbers of parameters, but the performance is not better than other CNN-based models (e.g. Klindt et al., 2017). The main potential contributions of the paper are therefore the neuroscientific insights obtained from the model. However, I have concerns about the presented data and the validity of rotation equivariance in modeling visual responses in general (below). Together with the fact that the model does not provide better explanatory power than other models, I cannot recommend acceptance. I am open to discussions with the authors, but do not anticipate a major change in the rating. Update after revisions: The authors performed extensive work to address my concerns. This showed that some concerns (RF appearance) were valid, and the authors removed them from the final manuscript. I raised my score accordingly. 1. As noted by the authors, the finding that \u201cFeature weights are sparse\u201d (page 6) could be due to the sparsity-inducing L1 penalty. The fact that a model without L1 penalty performs worse does not mean that there is sparsity in the underlying data. For example, the unregularized model could be overfitting. A more careful model selection analysis is necessary to show that the data is better fit by a sparse than a dense model. 2. The finding that there are center-surround or asymmetric (non-gabor) RFs in mouse V1 is not novel and not specific to this model (e.g. Antolik et al., 2016). 3. Many of the receptive fields in Figure 6 look pathological (overfitted?) compared to typical V1 receptive fields in the literature. I understand that sensitivity to previously undetected RF features is a goal of the present work. However, given how unusual the RFs look, more controls are necessary to ensure they are not an artefact of the method, e.g. the activation maximization approach with gradient preconditioning, the sparsity constraints, or overfitting. Perhaps a comparison of RFs learned on two disjoint subsets of the training set would help to determine which features are reproducible. 4. Should orientation be treated as a nuisance variable? Natural image statistics are not rotation-invariant. In the visual system, especially in mice, it is not clear whether orientation is completely disentangled from other RF properties. The orientation space is not uniformly covered, and some directions have special meaning (e.g. cardinal directions), such that it might be invalid to assume that the visual system is equivariant to rotation. (The same concern applies to the translation equivariance assumed when modeling visual RFs with standard CNNs.) Of course, there is a tradeoff between model expressiveness and the need to make assumptions to fit the model with realistic amounts of data. However, this concern should at least be discussed. 5. Some more details about the neural recordings would be good. What calcium indicator? How was the recording targeted to V1? Perhaps some example traces.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for reviewing our paper . We would like to make a quick clarification right away , which we hope will change your assessment . We will provide a more detailed response to the other comments later . There seems to be a misunderstanding about the performance of the model . As shown in Table 1 , our rotation-equivariant CNN does outperform a regular CNN ( Klindt et al.2017 ) .A couple of more detailed points to also keep in mind in this respect : - We are quite conservative with the model comparison : Table 1 shows the rotation-equivariant model with 16 features , which is not even the best-performing one among all the rotation-equivariant ones we tested ( Fig.2 ) .- Related to above , the regular CNN has been subjected to an equally rigorous hyperparameter search , with the range of hyperparameters taken from Klindt et al ( 2017 ) . Thus , the comparison is as fair as we can make it . - The performance in absolute numbers is lower than that in Klindt et al . ( 2017 ) , but these numbers are not comparable because different datasets are used . There is quite some variability across datasets ( see , e.g. , Table 1 in Klindt et al.2017 ) ."}, {"review_id": "H1fU8iAqKX-1", "review_text": "In this interesting study, the authors show that incorporating rotation-equivariant filters (i.e. enforcing weight sharing across filters with different orientations) in a CNN model of the visual system is a useful prior to predict responses in V1. After fitting this model to data, they find that the RFs of model V1 cells do not resemble the simple Gabor filters of textbooks, and they present other quantitative results about V1 receptive fields. The article is clearly written and the claims are supported by their analyses. It is the first time to my knowledge that a rotation-equivariant CNN is used to model V1 cells. The article would benefit from the following clarifications: 1. The first paragraph of the introduction discusses functional cell types in V1, but the article does not seem to reach any new conclusion about the existence of well-defined clusters of functional cell types in V1. If this last statement is correct, I believe it is misleading to begin the article with considerations about functional cell types in V1. Please clarify. 2. For clarity, it would help the reader to mention in the abstract, introduction and/or methods that the CNN is trained on reproducing V1 neuron activations, not on an image classification task as in many other studies (Yamins 2014, etc). 3. \u201cAs a first step, we simply assume that each of the 16 features corresponds to one functional cell type and classify all neurons into one of these types based on their strongest feature weight.\u201d and \u201cThe resulting preferred stimuli of each functional type are shown in Fig. 6.\u201c Again, I think these statements are misleading because they suggest that V1 cells indeed cluster in distinct functional cell types rather than form a continuum. However, from the data shown, it is unclear whether the V1 cells recorded form a continuum or distinct clusters. Unless this question is clarified and the authors show the existence of functionally distinct clusters in their data, they should preferably not mention \"cell types\" in the text. Suggestions for improvement and questions (may not necessarily be addressed in this paper): 4. \u201cwe apply batch normalization\u201d What is the importance of batch normalization for successfully training the model? Do you think that a sort of batch normalization is implemented by the visual system? 5. \u201cThe second interesting aspect is that many of the resulting preferred stimuli do not look typical standard textbook V1 neurons which are Gabor filters. \u201d OK but the analysis consists of iteratively ascending the gradient of activation of the neuron from an initial image. This cannot be compared directly to the linear approximation of the V1 filter that is computed experimentally from doing a spike-triggered average (STA) from white noise. A better comparison would be to do a single-step gradient ascent from a blank image. In this case, do the filters look like Gabors? 6. Did you find any evidence that individual V1 neurons are themselves invariant to a rotation? 7. The article could be more self-contained. There are a lot of references to Klindt et al. (2017) on which this work is based, but it would be nice to make the article understandable without having to read this other article. Typo: Number of fearture maps in last layer Conclusion: I believe this work is significant and of interest for the rest of the community studying the visual system with deep networks, in particular because it finds an interesting prior for modeling V1 neurons, that can probably be extended to the rest of the visual system. However, it would benefit from the clarifications mentioned above.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your thoughtful and constructive review . Below we respond to your seven comments : 1 . [ Functional cell types ] Finding out whether V1 is organized in distinct , well-defined clusters of functional cell types is indeed the big biological question we \u2019 re after . As you point out correctly , we do not answer this question in the present paper . The contribution of the present paper is not the biological finding that there are such well-defined cell types , but instead the development and verification of methods that allow us to address this question . With current methods ( i.e.Klindt et al.2017 ) we could not answer this question , because two Gabor filters with identical parameters except orientation would be considered two different cell types , which is undesirable from a biological perspective . The methods presented in our paper overcome this gap and let us treat preferred orientation as a nuisance just like receptive location . Therefore , we think it is appropriate to start the paper with these considerations , as they put our work in context by stating the long-term goals . We rephrased the introduction ( third paragraph ) to state the contributions more clearly . Please let us know if this revision addresses your concern or if you think that a more substantial revision of the introduction is necessary . 2 . [ CNN trained on neural data , not image categorization ] Thank you . We revised the abstract ( 2nd sentence ) , introduction ( third paragraph ) and Section 3 ( last sentence of first paragraph ) . Let us know if it \u2019 s still not clear . 3 . [ Functional cell types # 2 ] You have a point . We changed the wording to \u201c functional groups \u201d wherever we describe what we did . The only place where we refer to functional cell types is the introduction where we provide the background/context of our work . 4 . [ Batch norm ] Batch normalization serves two purposes here : ( 1 ) it helps training and ( 2 ) it ensures the features of the last CNN layer have unit variance , which is useful given the L1 penalty on the readout weights . Note that at test time , it does not have an effect . The normalization constants can be fully absorbed into the linear weights . In other words , if we gave you a trained model , you would not be able to tell whether it was trained with batch normalization or without , because they are indistinguishable at test time . 5 . [ Non-standard filters ] We agree that they are not directly comparable . The point is that this model-based procedure reveals deviations from the linear models . It not only shows that spike-triggered average from white noise is insufficient for characterizing V1 neurons , but also provides a means for characterizing them . Regarding your question about a single gradient step from a blank image : these indeed tend to look more similar to standard Gabor filters ( we performed such a comparison in a different project not using rotation equivariance and not published yet ) . We can create a new Figure analogous to Fig.6 but using a single gradient step and add it to the final version of the paper . 6 . [ Rotation-invariant neurons ] No , except for the trivial ones that have circularly symmetric center-surround receptive fields ( or preferred stimuli ) , we did not find any evidence for rotation invariant neurons ."}, {"review_id": "H1fU8iAqKX-2", "review_text": "The paper analyses the data collected from 6005 neurons in a mouse brain. Visual stimuli are presented and the responses of the neurons recorded. In the next step, a rotational equivariant neural network architecture together with a sparse coding read-out layer is trained to predict the neuron responses from the stimuli. Results show a decent correlation between neuron responses and trained network. Moreover, the rotational equivariant architecture beats a standard CNN with similar number of feature maps. The analysis and discussion of the results is interesting. Overall, the methodological approach is good. I have trouble understanding the plot in Figure 4, it also does not print well and is barely readable on paper. I have a small problem Figure 6 where \"optimal\" response-maps are presented. From my understanding, many of those feature maps are not looking similar to feature maps that are usually considered. Given the limited data available and the non-perfect modeling of neurons, the computed optimal response-map might include features that are not present in the dataset. Therefore, it would be interesting to compare those results with the stimuli used to gather the data. E.g. for a subset of neurons, one could pick the stimulus that created the maximum response and compare that to what the stimulus with the maximum response of the trained neuron was. It might be useful to include the average correlation of the neurons belong to each of the 16 groups(if there are any meaningful differences), especially as the cut-off of \"correlation 0.2 on the validation set\" is rather low. Note: I am not an expert in the neural-computation literature, I am adapting the confidence rating accordingly.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for reviewing our paper and providing constructive comments . Regarding the optimal stimuli presented in Fig.6 : Thank you for this suggestion . We will investigate whether an analysis of the optimal stimulus in the training set is helpful . Unfortunately , this may not be the case , because neural responses are highly variable and therefore the stimulus that happened to elicit the strongest response may not actually be the one the drives the neuron most on average . In addition , we have done such analysis in the past on networks trained for large-scale object recognition and found that one needs several hundred thousand image patches to find examples close to the optimum ( and these networks do not have observation noise ) . Note , however , that the variability across neurons within one group is a good indicator of which aspects of the optimal stimuli are reproducible vs. noise , because the neurons have different receptive field locations and have therefore seen different stimuli during the experiment . See also the suggestion by AnonReviewer1 to split the data in two halves , which we will perform for the final version . We will add the average correlations of the neurons shown in Fig.6 as you suggested . Regarding your trouble with Fig.4 : We will make it full width , so it is more legible . Overall , the point of the figure is to show that for a large fraction of neurons the weights are very sparse . We are open to any suggestions on how to improve the Figure ."}], "0": {"review_id": "H1fU8iAqKX-0", "review_text": "\ufeffThis paper applies a rotation-equivariant convolutional neural network model to a dataset of neural responses from mouse primary visual cortex. This submission follows a series of recent papers using deep convolutional neural networks to model visual responses, either in the retina (Batty et al., 2016; McIntosh et al., 2016) or V1 (Cadena et al., 2017; Kindel et al., 2017; Klindt et al., 2017). The authors show that adding rotation equivariance improves the explanatory power of the model compared to non-rotation-equivariant models with similar numbers of parameters, but the performance is not better than other CNN-based models (e.g. Klindt et al., 2017). The main potential contributions of the paper are therefore the neuroscientific insights obtained from the model. However, I have concerns about the presented data and the validity of rotation equivariance in modeling visual responses in general (below). Together with the fact that the model does not provide better explanatory power than other models, I cannot recommend acceptance. I am open to discussions with the authors, but do not anticipate a major change in the rating. Update after revisions: The authors performed extensive work to address my concerns. This showed that some concerns (RF appearance) were valid, and the authors removed them from the final manuscript. I raised my score accordingly. 1. As noted by the authors, the finding that \u201cFeature weights are sparse\u201d (page 6) could be due to the sparsity-inducing L1 penalty. The fact that a model without L1 penalty performs worse does not mean that there is sparsity in the underlying data. For example, the unregularized model could be overfitting. A more careful model selection analysis is necessary to show that the data is better fit by a sparse than a dense model. 2. The finding that there are center-surround or asymmetric (non-gabor) RFs in mouse V1 is not novel and not specific to this model (e.g. Antolik et al., 2016). 3. Many of the receptive fields in Figure 6 look pathological (overfitted?) compared to typical V1 receptive fields in the literature. I understand that sensitivity to previously undetected RF features is a goal of the present work. However, given how unusual the RFs look, more controls are necessary to ensure they are not an artefact of the method, e.g. the activation maximization approach with gradient preconditioning, the sparsity constraints, or overfitting. Perhaps a comparison of RFs learned on two disjoint subsets of the training set would help to determine which features are reproducible. 4. Should orientation be treated as a nuisance variable? Natural image statistics are not rotation-invariant. In the visual system, especially in mice, it is not clear whether orientation is completely disentangled from other RF properties. The orientation space is not uniformly covered, and some directions have special meaning (e.g. cardinal directions), such that it might be invalid to assume that the visual system is equivariant to rotation. (The same concern applies to the translation equivariance assumed when modeling visual RFs with standard CNNs.) Of course, there is a tradeoff between model expressiveness and the need to make assumptions to fit the model with realistic amounts of data. However, this concern should at least be discussed. 5. Some more details about the neural recordings would be good. What calcium indicator? How was the recording targeted to V1? Perhaps some example traces.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for reviewing our paper . We would like to make a quick clarification right away , which we hope will change your assessment . We will provide a more detailed response to the other comments later . There seems to be a misunderstanding about the performance of the model . As shown in Table 1 , our rotation-equivariant CNN does outperform a regular CNN ( Klindt et al.2017 ) .A couple of more detailed points to also keep in mind in this respect : - We are quite conservative with the model comparison : Table 1 shows the rotation-equivariant model with 16 features , which is not even the best-performing one among all the rotation-equivariant ones we tested ( Fig.2 ) .- Related to above , the regular CNN has been subjected to an equally rigorous hyperparameter search , with the range of hyperparameters taken from Klindt et al ( 2017 ) . Thus , the comparison is as fair as we can make it . - The performance in absolute numbers is lower than that in Klindt et al . ( 2017 ) , but these numbers are not comparable because different datasets are used . There is quite some variability across datasets ( see , e.g. , Table 1 in Klindt et al.2017 ) ."}, "1": {"review_id": "H1fU8iAqKX-1", "review_text": "In this interesting study, the authors show that incorporating rotation-equivariant filters (i.e. enforcing weight sharing across filters with different orientations) in a CNN model of the visual system is a useful prior to predict responses in V1. After fitting this model to data, they find that the RFs of model V1 cells do not resemble the simple Gabor filters of textbooks, and they present other quantitative results about V1 receptive fields. The article is clearly written and the claims are supported by their analyses. It is the first time to my knowledge that a rotation-equivariant CNN is used to model V1 cells. The article would benefit from the following clarifications: 1. The first paragraph of the introduction discusses functional cell types in V1, but the article does not seem to reach any new conclusion about the existence of well-defined clusters of functional cell types in V1. If this last statement is correct, I believe it is misleading to begin the article with considerations about functional cell types in V1. Please clarify. 2. For clarity, it would help the reader to mention in the abstract, introduction and/or methods that the CNN is trained on reproducing V1 neuron activations, not on an image classification task as in many other studies (Yamins 2014, etc). 3. \u201cAs a first step, we simply assume that each of the 16 features corresponds to one functional cell type and classify all neurons into one of these types based on their strongest feature weight.\u201d and \u201cThe resulting preferred stimuli of each functional type are shown in Fig. 6.\u201c Again, I think these statements are misleading because they suggest that V1 cells indeed cluster in distinct functional cell types rather than form a continuum. However, from the data shown, it is unclear whether the V1 cells recorded form a continuum or distinct clusters. Unless this question is clarified and the authors show the existence of functionally distinct clusters in their data, they should preferably not mention \"cell types\" in the text. Suggestions for improvement and questions (may not necessarily be addressed in this paper): 4. \u201cwe apply batch normalization\u201d What is the importance of batch normalization for successfully training the model? Do you think that a sort of batch normalization is implemented by the visual system? 5. \u201cThe second interesting aspect is that many of the resulting preferred stimuli do not look typical standard textbook V1 neurons which are Gabor filters. \u201d OK but the analysis consists of iteratively ascending the gradient of activation of the neuron from an initial image. This cannot be compared directly to the linear approximation of the V1 filter that is computed experimentally from doing a spike-triggered average (STA) from white noise. A better comparison would be to do a single-step gradient ascent from a blank image. In this case, do the filters look like Gabors? 6. Did you find any evidence that individual V1 neurons are themselves invariant to a rotation? 7. The article could be more self-contained. There are a lot of references to Klindt et al. (2017) on which this work is based, but it would be nice to make the article understandable without having to read this other article. Typo: Number of fearture maps in last layer Conclusion: I believe this work is significant and of interest for the rest of the community studying the visual system with deep networks, in particular because it finds an interesting prior for modeling V1 neurons, that can probably be extended to the rest of the visual system. However, it would benefit from the clarifications mentioned above.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your thoughtful and constructive review . Below we respond to your seven comments : 1 . [ Functional cell types ] Finding out whether V1 is organized in distinct , well-defined clusters of functional cell types is indeed the big biological question we \u2019 re after . As you point out correctly , we do not answer this question in the present paper . The contribution of the present paper is not the biological finding that there are such well-defined cell types , but instead the development and verification of methods that allow us to address this question . With current methods ( i.e.Klindt et al.2017 ) we could not answer this question , because two Gabor filters with identical parameters except orientation would be considered two different cell types , which is undesirable from a biological perspective . The methods presented in our paper overcome this gap and let us treat preferred orientation as a nuisance just like receptive location . Therefore , we think it is appropriate to start the paper with these considerations , as they put our work in context by stating the long-term goals . We rephrased the introduction ( third paragraph ) to state the contributions more clearly . Please let us know if this revision addresses your concern or if you think that a more substantial revision of the introduction is necessary . 2 . [ CNN trained on neural data , not image categorization ] Thank you . We revised the abstract ( 2nd sentence ) , introduction ( third paragraph ) and Section 3 ( last sentence of first paragraph ) . Let us know if it \u2019 s still not clear . 3 . [ Functional cell types # 2 ] You have a point . We changed the wording to \u201c functional groups \u201d wherever we describe what we did . The only place where we refer to functional cell types is the introduction where we provide the background/context of our work . 4 . [ Batch norm ] Batch normalization serves two purposes here : ( 1 ) it helps training and ( 2 ) it ensures the features of the last CNN layer have unit variance , which is useful given the L1 penalty on the readout weights . Note that at test time , it does not have an effect . The normalization constants can be fully absorbed into the linear weights . In other words , if we gave you a trained model , you would not be able to tell whether it was trained with batch normalization or without , because they are indistinguishable at test time . 5 . [ Non-standard filters ] We agree that they are not directly comparable . The point is that this model-based procedure reveals deviations from the linear models . It not only shows that spike-triggered average from white noise is insufficient for characterizing V1 neurons , but also provides a means for characterizing them . Regarding your question about a single gradient step from a blank image : these indeed tend to look more similar to standard Gabor filters ( we performed such a comparison in a different project not using rotation equivariance and not published yet ) . We can create a new Figure analogous to Fig.6 but using a single gradient step and add it to the final version of the paper . 6 . [ Rotation-invariant neurons ] No , except for the trivial ones that have circularly symmetric center-surround receptive fields ( or preferred stimuli ) , we did not find any evidence for rotation invariant neurons ."}, "2": {"review_id": "H1fU8iAqKX-2", "review_text": "The paper analyses the data collected from 6005 neurons in a mouse brain. Visual stimuli are presented and the responses of the neurons recorded. In the next step, a rotational equivariant neural network architecture together with a sparse coding read-out layer is trained to predict the neuron responses from the stimuli. Results show a decent correlation between neuron responses and trained network. Moreover, the rotational equivariant architecture beats a standard CNN with similar number of feature maps. The analysis and discussion of the results is interesting. Overall, the methodological approach is good. I have trouble understanding the plot in Figure 4, it also does not print well and is barely readable on paper. I have a small problem Figure 6 where \"optimal\" response-maps are presented. From my understanding, many of those feature maps are not looking similar to feature maps that are usually considered. Given the limited data available and the non-perfect modeling of neurons, the computed optimal response-map might include features that are not present in the dataset. Therefore, it would be interesting to compare those results with the stimuli used to gather the data. E.g. for a subset of neurons, one could pick the stimulus that created the maximum response and compare that to what the stimulus with the maximum response of the trained neuron was. It might be useful to include the average correlation of the neurons belong to each of the 16 groups(if there are any meaningful differences), especially as the cut-off of \"correlation 0.2 on the validation set\" is rather low. Note: I am not an expert in the neural-computation literature, I am adapting the confidence rating accordingly.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for reviewing our paper and providing constructive comments . Regarding the optimal stimuli presented in Fig.6 : Thank you for this suggestion . We will investigate whether an analysis of the optimal stimulus in the training set is helpful . Unfortunately , this may not be the case , because neural responses are highly variable and therefore the stimulus that happened to elicit the strongest response may not actually be the one the drives the neuron most on average . In addition , we have done such analysis in the past on networks trained for large-scale object recognition and found that one needs several hundred thousand image patches to find examples close to the optimum ( and these networks do not have observation noise ) . Note , however , that the variability across neurons within one group is a good indicator of which aspects of the optimal stimuli are reproducible vs. noise , because the neurons have different receptive field locations and have therefore seen different stimuli during the experiment . See also the suggestion by AnonReviewer1 to split the data in two halves , which we will perform for the final version . We will add the average correlations of the neurons shown in Fig.6 as you suggested . Regarding your trouble with Fig.4 : We will make it full width , so it is more legible . Overall , the point of the figure is to show that for a large fraction of neurons the weights are very sparse . We are open to any suggestions on how to improve the Figure ."}}