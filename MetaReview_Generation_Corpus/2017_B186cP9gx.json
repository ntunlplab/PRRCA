{"year": "2017", "forum": "B186cP9gx", "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond", "decision": "Reject", "meta_review": "This is quite an important topic to understand, and I think the spectrum of the Hessian in deep learning deserves more attention. However, all 3 official reviewers (and the public reviewer) comment that the paper needs more work. In particular, there are some concerns that the experiments are too preliminary/controlled and about whether the algorithm has actually converged. One reviewer also comments that the work is lacking a key insight/conclusion. I like the topic of the paper and would encourage the authors to pursue it more deeply, but at this time all reviewers have recommended rejection.", "reviews": [{"review_id": "B186cP9gx-0", "review_text": "This paper investigates the hessian of small deep networks near the end of training. The main result is that many eigenvalues are approximately zero, such that the Hessian is highly singular, which means that a wide amount of theory does not apply. The overall point that deep learning algorithms are singular, and that this undercuts many theoretical results, is important but it has already been made: Watanabe. \u201cAlmost All Learning Machines are Singular\u201d, FOCI 2007. This is one paper in a growing body of work investigating this phenomenon. In general, the references for this paper could be fleshed out much further\u2014a variety of prior work has examined the Hessian in deep learning, e.g., Dauphin et al. \u201cIdentifying and attacking the saddle point problem in high dimensional non-convex optimization\u201d NIPS 2014 or the work of Amari and others. Experimentally, it is hard to tell how results from the small sized networks considered here might translate to much larger networks. It seems likely that the behavior for much larger networks would be different. A reason for optimism, though, is the fact that a clear bulk/outlier behavior emerges even in these networks. Characterizing this behavior for simple systems is valuable. Overall, the results feel preliminary but likely to be of interest when further fleshed out. This paper is attacking an important problem, but should do a better job situating itself in the related literature and undertaking experiments of sufficient size to reveal large-scale behavior relevant to practice. ", "rating": "3: Clear rejection", "reply_text": "Thank you very much for pointing out at the FOCI 2007 paper , it is certainly relevant , even though the main object is the Fisher information matrix rather than the Hessian of the cost function . Dauphin et al.is interested only in saddle points near the path of training . These two works are indeed remotely related to the line of research that our work is invested in . However , their objective and results are different . We have added more references and clarified our contributions ."}, {"review_id": "B186cP9gx-1", "review_text": "The paper analyzes the properties of the Hessian of the training objective for various neural networks and data distributions. The authors study in particular, the eigenspectrum of the Hessian, which relates to the difficulty and the local convexity of the optimization problem. While there are several interesting insights discussed in this paper such as the local flatness of the objective function, as well as the study of the relation between data distribution and Hessian, a somewhat lacking aspect of the paper is that most described effects are presented as general, while tested only in a specific setting, without control experiments, or mathematical analysis. For example, regarding the concentration of eigenvalues to zero in Figure 6, it is unclear whether the concentration effect is really caused by training (e.g. increasing insensitivity to local perturbations), or the consequence of a specific choice of scale for the initial parameters. In Figure 8, the complexity of the data is not defined. It is not clear whether two fully overlapping distributions (the Hessian would then become zero?) is considered as complex or simple data. Some of the plots legends (Fig. 1 and 2) and labels are unreadable in printed format. Plots of Figure 3 don't have the same range for the x-axis. The image of Hessian matrix of Figure 1 does not render properly in printed format.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We realized that the text has n't been clear in the experiments that we performed . We clarified the text . Figure 1 and figure 2 ( left ) show the beginning and the end of the model with 10-hidden units which is consistent with figure 6 . In both cases of the simple data and MNIST the initial point is chosen randomly on the surface of a sphere centered at zero with fixed radius ( the radius is depends on the number of hidden units ) . The complexity of data can be tricky to describe , a data can be more complex for a certain model but less so for another one . Thank you for pointing this out , we clarified this point on the data complexity by the ease of separability in the text . We also updated the axes and labels in fig 1 and 2 . We changed the rendering format for the Hessian matrix increasing the sharpness and resolution . For figure 4 we would like to emphesize the two components of the spectrum , therefore we picked the widest possible representation for each case separately . However , we would also like to note that another series of experiments will explore the scale of eigenvalues depending on the iteration number during the training ."}, {"review_id": "B186cP9gx-2", "review_text": "Studying the Hessian in deep learning, the experiments in this paper suggest that the eigenvalue distribution is concentrated around zero and the non zero eigenvalues are related to the complexity of the input data. I find most of the discussions and experiments to be interesting and insightful. However, the current paper could be significantly improved. Quality: It seems that the arguments in the paper could be enhanced by more effort and more comprehensive experiments. Performing some of the experiments discussed in the conclusion could certainly help a lot. Some other suggestions: 1- It would be very helpful to add other plots showing the distribution of eigenvalues for some other machine learning method for the purpose of comparison to deep learning. 2- There are some issues about the scaling of the weights and it make sense to normalize the weights each time before calculating the Hessian otherwise the result might be misleading. 3- It might worth trying to find a quantity that measures the singularity of Hessian because it is difficult to visually conclude something from the plots. 4- Adding some plots for the Hessian during the optimization is definitely needed because we mostly care about the Hessian during the optimization not after the convergence. Clarity: 1- There is no reference to figures in the main text which makes it confusing for the reading to know the context for each figure. For example, when looking at Figure 1, it is not clear that the Hessian is calculated at the beginning of optimization or after convergence. 2- The texts in the figures are very small and hard to read.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for the comments and the review . Quantification of singularity is crucial but it may be tricky and even misleading given the degenerate structure , therefore we thought it would be equally important to lay out the observations first , and then as a separate work consider the quantification . We revised the paper in an attempt to address most of the issues mentioned above and in other comments . Also , we will add a comparison with another ML method , very soon ."}], "0": {"review_id": "B186cP9gx-0", "review_text": "This paper investigates the hessian of small deep networks near the end of training. The main result is that many eigenvalues are approximately zero, such that the Hessian is highly singular, which means that a wide amount of theory does not apply. The overall point that deep learning algorithms are singular, and that this undercuts many theoretical results, is important but it has already been made: Watanabe. \u201cAlmost All Learning Machines are Singular\u201d, FOCI 2007. This is one paper in a growing body of work investigating this phenomenon. In general, the references for this paper could be fleshed out much further\u2014a variety of prior work has examined the Hessian in deep learning, e.g., Dauphin et al. \u201cIdentifying and attacking the saddle point problem in high dimensional non-convex optimization\u201d NIPS 2014 or the work of Amari and others. Experimentally, it is hard to tell how results from the small sized networks considered here might translate to much larger networks. It seems likely that the behavior for much larger networks would be different. A reason for optimism, though, is the fact that a clear bulk/outlier behavior emerges even in these networks. Characterizing this behavior for simple systems is valuable. Overall, the results feel preliminary but likely to be of interest when further fleshed out. This paper is attacking an important problem, but should do a better job situating itself in the related literature and undertaking experiments of sufficient size to reveal large-scale behavior relevant to practice. ", "rating": "3: Clear rejection", "reply_text": "Thank you very much for pointing out at the FOCI 2007 paper , it is certainly relevant , even though the main object is the Fisher information matrix rather than the Hessian of the cost function . Dauphin et al.is interested only in saddle points near the path of training . These two works are indeed remotely related to the line of research that our work is invested in . However , their objective and results are different . We have added more references and clarified our contributions ."}, "1": {"review_id": "B186cP9gx-1", "review_text": "The paper analyzes the properties of the Hessian of the training objective for various neural networks and data distributions. The authors study in particular, the eigenspectrum of the Hessian, which relates to the difficulty and the local convexity of the optimization problem. While there are several interesting insights discussed in this paper such as the local flatness of the objective function, as well as the study of the relation between data distribution and Hessian, a somewhat lacking aspect of the paper is that most described effects are presented as general, while tested only in a specific setting, without control experiments, or mathematical analysis. For example, regarding the concentration of eigenvalues to zero in Figure 6, it is unclear whether the concentration effect is really caused by training (e.g. increasing insensitivity to local perturbations), or the consequence of a specific choice of scale for the initial parameters. In Figure 8, the complexity of the data is not defined. It is not clear whether two fully overlapping distributions (the Hessian would then become zero?) is considered as complex or simple data. Some of the plots legends (Fig. 1 and 2) and labels are unreadable in printed format. Plots of Figure 3 don't have the same range for the x-axis. The image of Hessian matrix of Figure 1 does not render properly in printed format.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We realized that the text has n't been clear in the experiments that we performed . We clarified the text . Figure 1 and figure 2 ( left ) show the beginning and the end of the model with 10-hidden units which is consistent with figure 6 . In both cases of the simple data and MNIST the initial point is chosen randomly on the surface of a sphere centered at zero with fixed radius ( the radius is depends on the number of hidden units ) . The complexity of data can be tricky to describe , a data can be more complex for a certain model but less so for another one . Thank you for pointing this out , we clarified this point on the data complexity by the ease of separability in the text . We also updated the axes and labels in fig 1 and 2 . We changed the rendering format for the Hessian matrix increasing the sharpness and resolution . For figure 4 we would like to emphesize the two components of the spectrum , therefore we picked the widest possible representation for each case separately . However , we would also like to note that another series of experiments will explore the scale of eigenvalues depending on the iteration number during the training ."}, "2": {"review_id": "B186cP9gx-2", "review_text": "Studying the Hessian in deep learning, the experiments in this paper suggest that the eigenvalue distribution is concentrated around zero and the non zero eigenvalues are related to the complexity of the input data. I find most of the discussions and experiments to be interesting and insightful. However, the current paper could be significantly improved. Quality: It seems that the arguments in the paper could be enhanced by more effort and more comprehensive experiments. Performing some of the experiments discussed in the conclusion could certainly help a lot. Some other suggestions: 1- It would be very helpful to add other plots showing the distribution of eigenvalues for some other machine learning method for the purpose of comparison to deep learning. 2- There are some issues about the scaling of the weights and it make sense to normalize the weights each time before calculating the Hessian otherwise the result might be misleading. 3- It might worth trying to find a quantity that measures the singularity of Hessian because it is difficult to visually conclude something from the plots. 4- Adding some plots for the Hessian during the optimization is definitely needed because we mostly care about the Hessian during the optimization not after the convergence. Clarity: 1- There is no reference to figures in the main text which makes it confusing for the reading to know the context for each figure. For example, when looking at Figure 1, it is not clear that the Hessian is calculated at the beginning of optimization or after convergence. 2- The texts in the figures are very small and hard to read.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for the comments and the review . Quantification of singularity is crucial but it may be tricky and even misleading given the degenerate structure , therefore we thought it would be equally important to lay out the observations first , and then as a separate work consider the quantification . We revised the paper in an attempt to address most of the issues mentioned above and in other comments . Also , we will add a comparison with another ML method , very soon ."}}