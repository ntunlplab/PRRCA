{"year": "2019", "forum": "H1MW72AcK7", "title": "Optimal Control Via Neural Networks: A Convex Approach", "decision": "Accept (Poster)", "meta_review": "The paper makes progress on a problem that is still largely unexplored, presents promising results, and builds bridges with \nprior work on optimal control.  It designs input convex recurrent neural networks to capture temporal behavior of \ndynamical systems; this then allows optimal controllers to be computed by solving a convex model predictive control problem.\n\nThere were initial critiques regarding some of the claims. These have now been clarified.\nAlso, there is in the end a compromise between the (necessary) approximations of the input-convex model and the true dynamics, and being able to compute an optimal result. \n\nOverall, all reviewers and the AC are in agreement to see this paper accepted.\nThere was extensive and productive interaction between the reviewers and authors.\nIt makes contributions that will be of interest to many, and builds interesting bridges with known control methods.", "reviews": [{"review_id": "H1MW72AcK7-0", "review_text": "This is a well-motived paper that considers bridging the gap in discrete-time continuous-state/action optimal control by approximating the system dynamics with a convex model class. The convex model class has more representational power than linear model classes while likely being more tractable and stable than non-convex model classes. They show empirical results in Mujoco continuous-control environments and in an HVAC example. I think this setup is a promising direction but I have significant concerns with some of the details and claims in this work: 1. Proposition 2 is wrong and the proposed input-convex recurrent neural network architecture not input-convex. To fix this, the D1 parameters should also be non-negative. To show why the proposition is wrong, consider the convexity of y2 with respect to x1, using g to denote the activation function: z1 = g(U x1 + ...) y2 = g(D1 z1 + ...) Thus making y2 = g(D1 g(U x1 + ...) + ...) y2 is *not* necessarily convex with respect to x1 because D1 takes an unrestricted weighted sum of the convex functions g(U x1 + ...) With the ICRNN architecture as described in the paper not being input-convex, I do not know how to interpret the empirical findings in Section 4.2 that use this architecture. 2. I think a stronger and more formal argument should be used to show that Equation (5) is a convex optimization problem as claimed. It has arbitrary convex functions on the equality constraints that are composed with each other and then used in the objective. Even with parts of the objective being convex and non-decreasing as the text mentions, it's not clear that this is sufficient when combined with the composed functions in the constraints. 3. I have similar concerns with the convexity of Equation (6). Consider the convexity of x3 with respect to u1, where g is now an input-convex neural network (that is not recurrent): x3 = g(g(x1, u1), u2) This composes two convex functions that do *not* have non-decreasing properties and therefore introduces an equality constraint that is not necessarily even convex, almost certainly making the domain of this problem non-convex. I think a similar argument can be used to show why Equation (5) is not convex. In addition to these significant concerns, I have a few other minor comments. 1. Figure 1 hides too much information. It would be useful to know, for example, that the ICNN portion at the bottom right is solving a control optimization problem with an ICNN as part of the constraints. 2. The theoretical results in Section 3 seem slightly out-of-place within the broader context of this paper but are perhaps of standalone interest. Due to my concerns above I did not go into the details in this portion. 3. I think more information should be added to the last paragraph of Section 1 as it's claimed that the representational power of ICNNs and \"a nice mathematical property\" help improve the computational time of the method, but it's not clear why this is and this connection is not made anywhere else in the paper. 4. What method are you using to solve the control problems in Eq (5) and (6)? 5. The empirical setup and tasks seems identical to [Nagabandi et al.]. Figure 3 directly compares to the K=100 case of their method. Why does Fig 6 of [Nagabandi et al.] have significantly higher rewards for their method, even in the K=5 case? 6. In Figure 5, f_NN seems surprisingly bad in the red region of the data on the left side. Is this because the model is not using many parameters? What are the sizes of the networks used?", "rating": "6: Marginally above acceptance threshold", "reply_text": "We are grateful to the reviewer for carefully reading our paper and providing many helpful suggestions and comments that have significantly improved the revised version . We also appreciate the opportunity to clarify our presentation of theorems , figures and experiment setups , as well as some unclear writing in the manuscript . We agree with the reviewer that the original manuscript contained several parts that were not clear and some typos , and it resulted in some confusion on the technical results . Overall , we note that the results of the paper remain unchanged : deep ( recurrent ) neural networks can be made input convex and effectively used in control of complex systems . Based on the comments made by the reviewers , we have made the figures more illustrative , and the formulations and the theorems more rigorous . Our implementation of the algorithms is consistent with the updated manuscript , so we stress that these changes are made to clarify the writing of the paper and all of the simulation and numerical results remain unchanged . Below we provide a point-by-point account of the comments . - Concerns on the correctness of Proposition 2 We thank the reviewer for bringing up this important question and agree this was a point of confusion in our original manuscript . In Proposition 2 of the original submission , we stated that we only need to keep V and W non-negative and this will result in a network that is convex from input to output . This is true for a single step , but as the reviewer correctly points out , negative weights can not go through composition and maintain convexity . Actually , Proposition 1 and Proposition 2 in our original submission give the sufficient condition for a network to be input-convex for a single step ; when used for control purpose , these network structures ( both ICNN and ICRNN ) should be modified to their equivalent variants : restricting all weight matrices to be non-negative ( element-wise ) and augmenting the input to include its negation . Such network structure variants and \u201c duplicate trick \u201d have been mentioned in Section 3.1 Sketch of proof for Theorem 1 in our original manuscript , \u201c We first construct a neural network with ReLU activation functions and both positive and negative weights , then we show that the weights between different layers of the network can be restricted to be nonnegative by a simple duplication trick . Specifically , since the weights in the input layer and passthrough layers can be negative , we simply add a negation of each input variable ( e.g.both x and \u2212x are given as inputs ) to the network \u201d . We apologize for not making this point clear and the notational confusions in our previous manuscript . To clarify , for both the MuJoCo locomotion tasks and the building control experiments , we used the modified input-convex network structures with all weights non-negative and input negation duplicates instead of the conventional input-convex structure for single step ( but these two structures could be equivalently transformed ) . In the revised paper , we explicitly explain the sufficient conditions for ICNN/ICRNN variants that can be used for control purpose . We also update Proposition 1 and 2 to ease the confusions of convexity under control settings . Also , we have updated Figure 2 accordingly to demonstrate the modified ICNN/ICRNN structure , input duplication , operations and activation functions used for our control settings . For all the empirical experiments , we will release our code after the openreview process for result validation , which demonstrated that proposed control framework via input-convex networks obtain both good identification accuracies and better control performance compared with regular neural networks or linear models ."}, {"review_id": "H1MW72AcK7-1", "review_text": "This paper proposes to use input convex neural networks (ICNN) to capture a complex relationship between control inputs and system dynamics, and then use trained ICNN to form a model predictive control (MPC) problem for control tasks. The paper is well-written and bridges the gap between neural networks and MPC. The main contribution of this paper is to use ICNN for learning system dynamics. ICNN is a neural network that only contains non-negative weights. Thanks to this constraint, ICNN is convex with respect to an input, therefore MPC problem with an ICNN model and additional convex constraints on control inputs is a convex optimization problem. While it is not easy to solve such a convex problem, it has a global optimum, and a gradient descent algorithm will eventually reach such a point. It should also be noted that a convex problem has a robustness with respect to an initial starting point and an ICNN model itself as well. The latter is pretty important, since training ICNN (or NN) is a non-convex optimization, so the parameters in trained ICNN (or NN) model can vary depending on the initial random weights and learning rates, etc. Since a convex MPC has some robustness (or margin) over an error or deviation in system dynamics, while non-convex MPC does not, using ICNN can also stabilize the control inputs in MPC. Overall, I believe that using ICNN to from convex MPC is a sample-efficient, non-intrusive way of constructing a controller with unknown dynamics. Below are some minor suggestions to improve this paper. -- Page 18, there is Fig.??. Please fix this. -- In experiments, could you compare the result with a conventional end-to-end RL approach? I know this is not a main point of this paper, but it can be more compelling.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank the reviewer for the encouraging words , and we are also expecting our work would be able to serve as an efficient framework for incorporating deep learning into real-world control problems . The reviewer \u2019 s comments on the robustness of proposed convex MPC are also quite valuable . We would try to explore in details about the learning errors and control robustness in the future work . Here are some responses to the reviewer \u2019 s comments : -The miss-replacement of Figure in Page 18 We thank the reviewer for pointing this out . In the revised version , we have added the fitting result comparison ( Fig.7 in Appendix D.4 ) for ICNN and a normal neural network , which shows that ICNN is able to learn the MuJoCo dynamics efficiently . -The comparison with end-to-end RL approach We thank the reviewer for this helpful suggestion . Conventional end-to-end RL approach directly learns the mapping from observations to actions without learning a system dynamics model . Such algorithms could achieve better performances , but are at the expense of much higher sample complexity . The model-free approach we compare with is the rllab implementation of trust region policy optimization ( TRPO ) [ JL ] , which has obtained state-of-the-art results on MuJuCo tasks . We added Fig.9 in Appendix D of the revised paper to compare our results with TRPO method and random shooting method [ Nagabandi et al ] . TRPO suffers from very high sample complexity and often requires millions of samples to achieve good performance . But here we only provided very few rollouts ( since for physical system control , the sample collection might be limited by real-time operations , or it is difficult to explore the whole design space because suboptimal actions would lead to disastrous results ) , therefore , the performance by ICNN is much better than TRPO . Similarly to the model-based , model-free ( MBMF ) approach mentioned in [ Nagabandi et al ] , the learned controller via ICNN could also provide good rollout samples and serve as a good initialization point for model-free RL method . References [ JL ] Schulman , John , Sergey Levine , Pieter Abbeel , Michael Jordan , and Philipp Moritz . `` Trust region policy optimization . '' In International Conference on Machine Learning , pp . 1889-1897 . 2015 ."}, {"review_id": "H1MW72AcK7-2", "review_text": "The paper proposes neural networks which are convex on inputs data to control problems. These types of networks, constructed based on either MLP or RNN, are shown to have similar representation power as their non-convex versions, thus are potentially able to better capture the dynamics behind complex systems compared with linear models. On the other hand, convexity on inputs brings much convenience to the later optimization part, because there are no worries on global/local minimum or escaping saddle points. In other words, convex but nonlinear provides not only enough search space, but also fast and tractable optimization. The compromise here is the size of memory, since 1) more weights and biases are needed to connect inputs and hidden layers in such nets and 2) we need to store also the negative parts on a portion of weights. Even though the idea of convex networks were not new, this work is novel in extending input convex RNN and applying it into dynamic control problems. As the main theoretical contribution, Theorem 2 shows that to have same representation power, input convex nets use polynomial number of activation functions, compared with exponential from using a set of affine functions. Experiments also show such effectiveness. The paper is clearly and nicely written. These are reasons I suggest accept. Questions and suggestions: 1) For Lemma 1 and Theorem 1, I wonder whether similar results can be established for non-convex functions. Intuitively, it seems that as long as assuming Lipschiz continuous, we can always approximate a function by a maximum of many affine functions, no matter it is convex or not. Is this right or something is missing? 2) In the main paper, all experiments were aimed to address ICNN and ICRNN have good accuracy, but not they are easier to optimize due to convexity. In the abstract, it is mentioned \"... using 5X less time\", but I can only see this through appendix. A suggestion is at least describing some results on the comparison with training time in the main paper. 3) In Appendix A, it seems the NN is not trained very well as shown in the left figure. Is this because the number of parameters of NN is restricted to be the same as in ICNN? Do training on both spend the same resource, ie, number of epoch? Such descriptions are necessary here. 4) In Table 2 in appendix, why the running time of ICNN increases by a magnitude for large H in Ant case? Typos: Page 1 \"simple control algorithms HAS ...\" Page 7 paragraph \"Baselines\": \"Such (a) method\". In the last line of Table 2, 979.73 should be bold instead of 5577. There is a ?? in appendix D.4. ", "rating": "7: Good paper, accept", "reply_text": "We are grateful to the reviewer for thoroughly reading our paper and providing these encouraging words . Below , we respond to the comments in detail . 1 ) For Lemma 1 and Theorem 1 , I wonder whether similar results can be established for non-convex functions . Intuitively , it seems that as long as assuming Lipschiz continuous , we can always approximate a function by a maximum of many affine functions , no matter it is convex or not . Is this right or something is missing ? This is an interesting and subtle question . If we restrict ourselves to \u201c maximum \u201d of affine functions , then we can not construct functions that are not convex . This is from the fact that a pointwise max of convex functions ( which include affine functions ) is convex . As the reviewer points out , if we allow other types of operations , we can construct other types of functions . For example , if we change the pointwise max to the pointwise min , then we can approximate all Lipschiz concave functions . If we allow both max and min , we get all Lipschiz functions , but this just recover the result that neural networks can approximate most function types . We anticipate that different applications may require different function types to be approximated , and this is an active research direction for us . 2 ) In the main paper , all experiments were aimed to address ICNN and ICRNN have good accuracy , but not they are easier to optimize due to convexity . In the abstract , it is mentioned `` ... using 5X less time '' , but I can only see this through appendix . A suggestion is at least describing some results on the comparison with training time in the main paper . We thank the reviewer for pointing out this piece of missing information on running time in the main text . In the revised manuscript , we have added discussions on computation time in Section 4.1 to show our controller design would achieve both computation efficiency and performance improvement . 3 ) In Appendix A , it seems the NN is not trained very well as shown in the left figure . Is this because the number of parameters of NN is restricted to be the same as in ICNN ? Do training on both spend the same resource , ie , number of epoch ? Such descriptions are necessary here . In the toy example on classifying points in 2D grid , we used a 2-layer neural networks for both conventional neural networks and ICNN , with 200 neurons in each layer . We simulate the case when training data is small ( 100 training samples ) . We observe the results given by conventional neural networks are quite unstable by using different random seeds and are prone to be overfitting . On the contrary , by adding constraints on model weights to train the ICNN , fitting result is better using this small-size training data , while the learned landscape is also beneficial to the optimization problem . In the revised manuscript , we added more details on the model and training setup , the learning task , and the optimization task to address the confusion . 4 ) In Table 2 in appendix , why the running time of ICNN increases by a magnitude for large H in Ant case ? We apologize for the typo in the case of Ant for computation time and the confusion it caused . We wanted to report everything in minutes but forgot to convert the time for the Ant case from seconds to minutes . In the revised version we have unified the running time under minutes . We also thank the reviewer for carefully proofreading the paper and extracting the typos ."}], "0": {"review_id": "H1MW72AcK7-0", "review_text": "This is a well-motived paper that considers bridging the gap in discrete-time continuous-state/action optimal control by approximating the system dynamics with a convex model class. The convex model class has more representational power than linear model classes while likely being more tractable and stable than non-convex model classes. They show empirical results in Mujoco continuous-control environments and in an HVAC example. I think this setup is a promising direction but I have significant concerns with some of the details and claims in this work: 1. Proposition 2 is wrong and the proposed input-convex recurrent neural network architecture not input-convex. To fix this, the D1 parameters should also be non-negative. To show why the proposition is wrong, consider the convexity of y2 with respect to x1, using g to denote the activation function: z1 = g(U x1 + ...) y2 = g(D1 z1 + ...) Thus making y2 = g(D1 g(U x1 + ...) + ...) y2 is *not* necessarily convex with respect to x1 because D1 takes an unrestricted weighted sum of the convex functions g(U x1 + ...) With the ICRNN architecture as described in the paper not being input-convex, I do not know how to interpret the empirical findings in Section 4.2 that use this architecture. 2. I think a stronger and more formal argument should be used to show that Equation (5) is a convex optimization problem as claimed. It has arbitrary convex functions on the equality constraints that are composed with each other and then used in the objective. Even with parts of the objective being convex and non-decreasing as the text mentions, it's not clear that this is sufficient when combined with the composed functions in the constraints. 3. I have similar concerns with the convexity of Equation (6). Consider the convexity of x3 with respect to u1, where g is now an input-convex neural network (that is not recurrent): x3 = g(g(x1, u1), u2) This composes two convex functions that do *not* have non-decreasing properties and therefore introduces an equality constraint that is not necessarily even convex, almost certainly making the domain of this problem non-convex. I think a similar argument can be used to show why Equation (5) is not convex. In addition to these significant concerns, I have a few other minor comments. 1. Figure 1 hides too much information. It would be useful to know, for example, that the ICNN portion at the bottom right is solving a control optimization problem with an ICNN as part of the constraints. 2. The theoretical results in Section 3 seem slightly out-of-place within the broader context of this paper but are perhaps of standalone interest. Due to my concerns above I did not go into the details in this portion. 3. I think more information should be added to the last paragraph of Section 1 as it's claimed that the representational power of ICNNs and \"a nice mathematical property\" help improve the computational time of the method, but it's not clear why this is and this connection is not made anywhere else in the paper. 4. What method are you using to solve the control problems in Eq (5) and (6)? 5. The empirical setup and tasks seems identical to [Nagabandi et al.]. Figure 3 directly compares to the K=100 case of their method. Why does Fig 6 of [Nagabandi et al.] have significantly higher rewards for their method, even in the K=5 case? 6. In Figure 5, f_NN seems surprisingly bad in the red region of the data on the left side. Is this because the model is not using many parameters? What are the sizes of the networks used?", "rating": "6: Marginally above acceptance threshold", "reply_text": "We are grateful to the reviewer for carefully reading our paper and providing many helpful suggestions and comments that have significantly improved the revised version . We also appreciate the opportunity to clarify our presentation of theorems , figures and experiment setups , as well as some unclear writing in the manuscript . We agree with the reviewer that the original manuscript contained several parts that were not clear and some typos , and it resulted in some confusion on the technical results . Overall , we note that the results of the paper remain unchanged : deep ( recurrent ) neural networks can be made input convex and effectively used in control of complex systems . Based on the comments made by the reviewers , we have made the figures more illustrative , and the formulations and the theorems more rigorous . Our implementation of the algorithms is consistent with the updated manuscript , so we stress that these changes are made to clarify the writing of the paper and all of the simulation and numerical results remain unchanged . Below we provide a point-by-point account of the comments . - Concerns on the correctness of Proposition 2 We thank the reviewer for bringing up this important question and agree this was a point of confusion in our original manuscript . In Proposition 2 of the original submission , we stated that we only need to keep V and W non-negative and this will result in a network that is convex from input to output . This is true for a single step , but as the reviewer correctly points out , negative weights can not go through composition and maintain convexity . Actually , Proposition 1 and Proposition 2 in our original submission give the sufficient condition for a network to be input-convex for a single step ; when used for control purpose , these network structures ( both ICNN and ICRNN ) should be modified to their equivalent variants : restricting all weight matrices to be non-negative ( element-wise ) and augmenting the input to include its negation . Such network structure variants and \u201c duplicate trick \u201d have been mentioned in Section 3.1 Sketch of proof for Theorem 1 in our original manuscript , \u201c We first construct a neural network with ReLU activation functions and both positive and negative weights , then we show that the weights between different layers of the network can be restricted to be nonnegative by a simple duplication trick . Specifically , since the weights in the input layer and passthrough layers can be negative , we simply add a negation of each input variable ( e.g.both x and \u2212x are given as inputs ) to the network \u201d . We apologize for not making this point clear and the notational confusions in our previous manuscript . To clarify , for both the MuJoCo locomotion tasks and the building control experiments , we used the modified input-convex network structures with all weights non-negative and input negation duplicates instead of the conventional input-convex structure for single step ( but these two structures could be equivalently transformed ) . In the revised paper , we explicitly explain the sufficient conditions for ICNN/ICRNN variants that can be used for control purpose . We also update Proposition 1 and 2 to ease the confusions of convexity under control settings . Also , we have updated Figure 2 accordingly to demonstrate the modified ICNN/ICRNN structure , input duplication , operations and activation functions used for our control settings . For all the empirical experiments , we will release our code after the openreview process for result validation , which demonstrated that proposed control framework via input-convex networks obtain both good identification accuracies and better control performance compared with regular neural networks or linear models ."}, "1": {"review_id": "H1MW72AcK7-1", "review_text": "This paper proposes to use input convex neural networks (ICNN) to capture a complex relationship between control inputs and system dynamics, and then use trained ICNN to form a model predictive control (MPC) problem for control tasks. The paper is well-written and bridges the gap between neural networks and MPC. The main contribution of this paper is to use ICNN for learning system dynamics. ICNN is a neural network that only contains non-negative weights. Thanks to this constraint, ICNN is convex with respect to an input, therefore MPC problem with an ICNN model and additional convex constraints on control inputs is a convex optimization problem. While it is not easy to solve such a convex problem, it has a global optimum, and a gradient descent algorithm will eventually reach such a point. It should also be noted that a convex problem has a robustness with respect to an initial starting point and an ICNN model itself as well. The latter is pretty important, since training ICNN (or NN) is a non-convex optimization, so the parameters in trained ICNN (or NN) model can vary depending on the initial random weights and learning rates, etc. Since a convex MPC has some robustness (or margin) over an error or deviation in system dynamics, while non-convex MPC does not, using ICNN can also stabilize the control inputs in MPC. Overall, I believe that using ICNN to from convex MPC is a sample-efficient, non-intrusive way of constructing a controller with unknown dynamics. Below are some minor suggestions to improve this paper. -- Page 18, there is Fig.??. Please fix this. -- In experiments, could you compare the result with a conventional end-to-end RL approach? I know this is not a main point of this paper, but it can be more compelling.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank the reviewer for the encouraging words , and we are also expecting our work would be able to serve as an efficient framework for incorporating deep learning into real-world control problems . The reviewer \u2019 s comments on the robustness of proposed convex MPC are also quite valuable . We would try to explore in details about the learning errors and control robustness in the future work . Here are some responses to the reviewer \u2019 s comments : -The miss-replacement of Figure in Page 18 We thank the reviewer for pointing this out . In the revised version , we have added the fitting result comparison ( Fig.7 in Appendix D.4 ) for ICNN and a normal neural network , which shows that ICNN is able to learn the MuJoCo dynamics efficiently . -The comparison with end-to-end RL approach We thank the reviewer for this helpful suggestion . Conventional end-to-end RL approach directly learns the mapping from observations to actions without learning a system dynamics model . Such algorithms could achieve better performances , but are at the expense of much higher sample complexity . The model-free approach we compare with is the rllab implementation of trust region policy optimization ( TRPO ) [ JL ] , which has obtained state-of-the-art results on MuJuCo tasks . We added Fig.9 in Appendix D of the revised paper to compare our results with TRPO method and random shooting method [ Nagabandi et al ] . TRPO suffers from very high sample complexity and often requires millions of samples to achieve good performance . But here we only provided very few rollouts ( since for physical system control , the sample collection might be limited by real-time operations , or it is difficult to explore the whole design space because suboptimal actions would lead to disastrous results ) , therefore , the performance by ICNN is much better than TRPO . Similarly to the model-based , model-free ( MBMF ) approach mentioned in [ Nagabandi et al ] , the learned controller via ICNN could also provide good rollout samples and serve as a good initialization point for model-free RL method . References [ JL ] Schulman , John , Sergey Levine , Pieter Abbeel , Michael Jordan , and Philipp Moritz . `` Trust region policy optimization . '' In International Conference on Machine Learning , pp . 1889-1897 . 2015 ."}, "2": {"review_id": "H1MW72AcK7-2", "review_text": "The paper proposes neural networks which are convex on inputs data to control problems. These types of networks, constructed based on either MLP or RNN, are shown to have similar representation power as their non-convex versions, thus are potentially able to better capture the dynamics behind complex systems compared with linear models. On the other hand, convexity on inputs brings much convenience to the later optimization part, because there are no worries on global/local minimum or escaping saddle points. In other words, convex but nonlinear provides not only enough search space, but also fast and tractable optimization. The compromise here is the size of memory, since 1) more weights and biases are needed to connect inputs and hidden layers in such nets and 2) we need to store also the negative parts on a portion of weights. Even though the idea of convex networks were not new, this work is novel in extending input convex RNN and applying it into dynamic control problems. As the main theoretical contribution, Theorem 2 shows that to have same representation power, input convex nets use polynomial number of activation functions, compared with exponential from using a set of affine functions. Experiments also show such effectiveness. The paper is clearly and nicely written. These are reasons I suggest accept. Questions and suggestions: 1) For Lemma 1 and Theorem 1, I wonder whether similar results can be established for non-convex functions. Intuitively, it seems that as long as assuming Lipschiz continuous, we can always approximate a function by a maximum of many affine functions, no matter it is convex or not. Is this right or something is missing? 2) In the main paper, all experiments were aimed to address ICNN and ICRNN have good accuracy, but not they are easier to optimize due to convexity. In the abstract, it is mentioned \"... using 5X less time\", but I can only see this through appendix. A suggestion is at least describing some results on the comparison with training time in the main paper. 3) In Appendix A, it seems the NN is not trained very well as shown in the left figure. Is this because the number of parameters of NN is restricted to be the same as in ICNN? Do training on both spend the same resource, ie, number of epoch? Such descriptions are necessary here. 4) In Table 2 in appendix, why the running time of ICNN increases by a magnitude for large H in Ant case? Typos: Page 1 \"simple control algorithms HAS ...\" Page 7 paragraph \"Baselines\": \"Such (a) method\". In the last line of Table 2, 979.73 should be bold instead of 5577. There is a ?? in appendix D.4. ", "rating": "7: Good paper, accept", "reply_text": "We are grateful to the reviewer for thoroughly reading our paper and providing these encouraging words . Below , we respond to the comments in detail . 1 ) For Lemma 1 and Theorem 1 , I wonder whether similar results can be established for non-convex functions . Intuitively , it seems that as long as assuming Lipschiz continuous , we can always approximate a function by a maximum of many affine functions , no matter it is convex or not . Is this right or something is missing ? This is an interesting and subtle question . If we restrict ourselves to \u201c maximum \u201d of affine functions , then we can not construct functions that are not convex . This is from the fact that a pointwise max of convex functions ( which include affine functions ) is convex . As the reviewer points out , if we allow other types of operations , we can construct other types of functions . For example , if we change the pointwise max to the pointwise min , then we can approximate all Lipschiz concave functions . If we allow both max and min , we get all Lipschiz functions , but this just recover the result that neural networks can approximate most function types . We anticipate that different applications may require different function types to be approximated , and this is an active research direction for us . 2 ) In the main paper , all experiments were aimed to address ICNN and ICRNN have good accuracy , but not they are easier to optimize due to convexity . In the abstract , it is mentioned `` ... using 5X less time '' , but I can only see this through appendix . A suggestion is at least describing some results on the comparison with training time in the main paper . We thank the reviewer for pointing out this piece of missing information on running time in the main text . In the revised manuscript , we have added discussions on computation time in Section 4.1 to show our controller design would achieve both computation efficiency and performance improvement . 3 ) In Appendix A , it seems the NN is not trained very well as shown in the left figure . Is this because the number of parameters of NN is restricted to be the same as in ICNN ? Do training on both spend the same resource , ie , number of epoch ? Such descriptions are necessary here . In the toy example on classifying points in 2D grid , we used a 2-layer neural networks for both conventional neural networks and ICNN , with 200 neurons in each layer . We simulate the case when training data is small ( 100 training samples ) . We observe the results given by conventional neural networks are quite unstable by using different random seeds and are prone to be overfitting . On the contrary , by adding constraints on model weights to train the ICNN , fitting result is better using this small-size training data , while the learned landscape is also beneficial to the optimization problem . In the revised manuscript , we added more details on the model and training setup , the learning task , and the optimization task to address the confusion . 4 ) In Table 2 in appendix , why the running time of ICNN increases by a magnitude for large H in Ant case ? We apologize for the typo in the case of Ant for computation time and the confusion it caused . We wanted to report everything in minutes but forgot to convert the time for the Ant case from seconds to minutes . In the revised version we have unified the running time under minutes . We also thank the reviewer for carefully proofreading the paper and extracting the typos ."}}