{"year": "2021", "forum": "jN5y-zb5Q7m", "title": "Uncertainty Estimation in Autoregressive Structured Prediction", "decision": "Accept (Poster)", "meta_review": "This paper proposes information-theoretic quantification of epistemic uncertainty in autoregressive models. \n\nThis is a difficult problem that receives much less attention than the unstructured case. The paper is well-written, contributes novel and tractable-to-estimate measures which are analysed formally and empirically with convincing experiments on ASR and NMT. \n\nThe reviewers and myself are overall pleased by this submission. The discussion phase went well and most concerns have been resolved. \n", "reviews": [{"review_id": "jN5y-zb5Q7m-0", "review_text": "This paper proposes two different measures of knowledge ( epistemic ) uncertainty in structured prediction with an autoregressive model and discusses how to compute their approximations . The main contribution is the proposed reverse mutual information ( RMI ) as a measure of epistemic uncertainty in structured prediction . Experiments on benchmark datasets demonstrate the effectiveness of the proposed method in error detection and OOD detection . # # # Clarity # # # # Pros - This paper clearly states the main contributions , assumptions , experimental settings . # # # # Cons - The naming of reverse mutual information is confusing since mutual information itself is symmetric , unlike KL-divergence . - Table 1 shows the predictive performance with an ensemble of autoregressive models , however , it is unrelated to the main contribution of the paper . The proposed RMI is not used to improve the performance of the ensemble of autoregressive models . - Eq ( 4 ) , $ \\tilde { \\theta } $ is used without definition . And there is no $ \\mathcal { D } $ on the right side of the equation . Why is $ q ( \\theta ) = q ( \\tilde { \\theta } ) $ ? - In Eq ( 12 ) , how is $ y $ sampled from $ P ( y\\mid x , \\mathcal { D } ) $ ? Do you mean to sample from $ q ( \\theta ) $ instead of $ p ( \\theta\\mid \\mathcal { D } ) $ ? - Though the two ways , EP and PE , for combination of the ensemble of autoregressive models are both reasonable , only EP can be derived from assumptions in Eq ( 7 ) . PE assumes the probability $ P_ { PE } ( \\boldsymbol { y } \\mid \\boldsymbol { x } , \\mathcal { D } ) $ factorizes over the conditional probability $ { P } ( y_ { l } \\mid \\boldsymbol { y } _ { < l } , \\boldsymbol { x } , \\mathcal { D } ) $ . This should be made clear , otherwise can be confusing . - On page 4 , above Eq ( 10 ) , it is claimed that > ( 8 ) only considers the probabilities of individual tokens $ y_ { l } ^ { ( s ) } $ along a hypothesis $ y^ { ( s ) } $ while ( 9 ) considers the entire conditional distribution over each $ y_ { l } $ . It is not clear why this is the case . In my understanding , ( 8 ) computes the entropy of the joint distribution $ P ( \\boldsymbol { y } \\mid \\boldsymbol { x } , \\mathcal { D } ) $ , which considers all the conditional distribution $ \\mathrm { P } \\left ( y_ { l } \\mid \\boldsymbol { y } _ { < l } , \\boldsymbol { x } \\right ) $ , no matter using EP or PE . Correct me if I am wrong . - ( Minor ) Typos : - Page 4 , above Eq ( 15 ) , practical considerations as it yields poor predictive performance ? - > remove ? - Page 4 , above Eq ( 10 ) , while ( 8 ) yields A - > while ( 8 ) yields a - Page 4 , below Eq ( 13 ) , like ( 8 ) ( 9 ) - > like ( 8 ) ( 10 ) - Page 5 , above Eq ( 16 ) , the models can combined - > the models can be combined # # # Originality # # # # Pros - The paper makes clear its main contributions , including introductions of different measures of uncertainty in structured prediction , the examination of two choices of the combination of ensemble models . The proposed reverse mutual information ( RMI ) improves the performance in OOD detection in structured prediction . # # # # Cons - The contribution of the paper is minor with the proposed RMI measure . - The proposed RMI for epistemic uncertainty estimation is not used to improve the performance of the ensemble of autoregressive models . # # # Significance # # # # Pros - Experimental results show improvement of the proposed method over baseline methods . # # # # Cons - The paper presents ablation studies of different methods for knowledge uncertainty estimation , but it is unclear whether the proposed method achieves state-of-the-art performance on different datasets for error detection and OOD detection . For example , compare to MC-dropout and other recently proposed methods without structured prediction with autoregressive models . - The contribution is not very significant , but mostly an extension and application of uncertainty measures to autoregressive models . For example , the reverse mutual information ( RMI ) , seems to be related to the Reverse KL-divergence proposed in [ 1 ] . More discussion is suggested on how the reverse version improves over the original version as is done in [ 1 ] . - Besides OOD detection , it is also interesting to show whether the proposed uncertainty measure can improve other tasks , such as adversarial sample detection , and active learning . For example , [ 2 ] presents more thorough experiments in these different tasks . - The paper proposes two ways to combine the ensemble of autoregressive models , EP or PE . Experimental results are provided on these two ways of combination . However , it would be better if more theoretical analysis to compare these two could be given based on different assumptions . For example , analysis of the computational complexity of the two choices . - Similarly , it would be better if complexity analysis can be provided for computing approximations of the entropy using relative-entropy chain-rule in Eq ( 9 ) , ( 11 ) , ( 13 ) , and using the traditional ways in Eq ( 8 ) , ( 10 ) , ( 12 ) . Since it is claimed at `` no extra cost '' in the paper . - It is discussed in the paper that EPKL , RMI , MI all measures knowledge uncertainty , and RMI = EPKL - MI . And only MI 'cleanly ' decomposes into total and data uncertainty . A natural question is that if we decompose total uncertainty using RMI , i.e.Total uncertainty = data uncertainty + RMI + res , what does the remaining term res represent ? For example , if RMI gives a better measure of knowledge uncertainty as shown empirically in the paper , then the remaining term in the total uncertainty may measure other types of uncertainty rather than data uncertainty or knowledge uncertainty ? Or there are other ways to represent total uncertainty and/or data uncertainty correspondingly ? Correct me if I am wrong . And it would be better if more discussion can be provided in the paper . [ 1 ] Reverse kl-divergence training of prior networks : Improved uncertainty and adversarial robustness [ 2 ] SDE-Net : Equipping Deep Neural Networks with Uncertainty Estimates", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer1 , we are grateful for your hard work and detailed review . However , we feel that we have failed to properly convey the significance of our contribution to you . Let us attempt to resolve this misunderstanding . While ensemble approaches and information-theoretical measures of uncertainty have been examined in the past , * no prior work * has ever rigorously examined ensemble based uncertainty estimation in the context of structured prediction tasks . The key contribution of our work is \u201c the examination of the attributes of ensemble-based uncertainty estimation for autoregressive structured prediction tasks \u201d , which is novel because it has never been rigorously studied before , especially not for ASR . Furthermore , this work represents the largest-scale application of Bayesian-inspired uncertainty estimation , which in itself is significant . This is the key novelty and contribution of our work . Though we feel that it is an * important * contribution , the proposal of a new uncertainty measure ( RMI ) is NOT our * main * contribution . We will also agree each of your comments point-by-point . CLARITY 1 . We chose the name Reverse Mutual Information because we have flipped the direction of the KL-divergence ( which is non-symmetric ) , relative to standard MI . 2.While predictive performance is not the main contribution of the paper , it is always necessary to quote predictive performance in order to demonstrate that the models under consideration are sensible . In addition , we use this to explore the impact of how an ensemble is combined . 3.This is a notational convenience . This is supposed to indicate a different dummy variable , as we are comparing pairwise KL divergence between samples from the same distribution over models ( from the same ensemble ) . D is absorbed into q ( \\theta ) 4 . We sample translation/transcription hypotheses from P ( y\u2223x , D ) via beam-search decoding . Beam-search decoding can be interpreted as a form of importance sampling . 5.We will address the confusion regarding eq.7 and PE vs EP in the text . 8.Equations 8 and 9 represent Monte-Carlo estimators of entropy which yield the same values * in the limit as S - > infinity * . However , when we consider a finite number of hypotheses , 8 only considers the probabilities of tokens which occur along the hypothesis . On the other hand , 9 estimates the conditional entropy over the full conditional distribution over the next token ( over the entire vocabulary ) at each step along the hypothesis . Thus , 8 consider LS values , while 9 consider LSK values ( K is the size of vocabulary ) . 9.Typos - Many thanks for finding these typos ! Already fixed . ORIGINALITY 1 . As stated above , the main contribution is not RMI , but the examination of general ensemble-based uncertainty estimation in the context of structured prediction . 2.The goal of uncertainty estimation is orthogonal to improving the predictive performance of a system . RMI is a measure of knowledge uncertainty for which an asymptotically exact Monte-Carlo estimator can be obtained , and yields the most competitive OOD detection performance . SIGNIFICANCE - responses in second part ."}, {"review_id": "jN5y-zb5Q7m-1", "review_text": "After rebuttal : I would like to thank the authors for paying attention to the comments and providing additional experiments and results . I updated my score . = This paper investigates uncertainty estimation for autoregressive structured prediction models . The authors explored several metrics for computing uncertainty in structured neural network based models , such as expected pair-wise KL-divergence , mutual information , and reverse mutual information ( RMI ) . The authors demonstrated the efficiency of the proposed RMI using machine translation and speech recognition models for error detection and out-of-distribution detection . Overall this paper is clearly written and investigates highly relevant topic . However , some clarifications are needed . First , I find the name of the paper a bit misleading , there are plenty of structured prediction models , and the authors investigated only neural based and autoregressive ones . Second , I know the authors mentioned that they did not compare to prior work since it did not consider auto-regressive models , however , I feel that a comparison is still needed . There are a few papers ( some of which the authors already mentioned ) , that suggest different ways to estimate uncertainties in AST and MT . I would expect to see a comparison to some of these methods . Comments to the authors : 1 ) In `` Practical Considerations '' there is a question mark , probably a missing citation ? 2 ) The improvements in Table 1 seems pretty marginal . Can the authors report the variance of the estimator too ? 3 ) `` The results also show that uncertainty-based rejection works better for ASR for NMT . '' \u2192 `` The results also show that uncertainty-based rejection works better for ASR than NMT . '' 4 ) `` A better , but more expensive , approach to assess uncertainty estimates in NMT is whether they correlate well with human assessment of translation quality . '' \u2192 did the authors try to use subjective evaluations ? 5 ) `` Three OOD datasets are considered , each covering a different form of domain shift . First , LibriSpeech test-other ( LTO ) ... '' \u2192 I find this definition of OOD a bit problematic . LTO is still part of librispeech , so I would not consider that as OOD . 6 ) `` Notably , it was found that token-level Bayesian model averaging consistently yields both marginally better predictive performance and more robust estimates of uncertainty . '' \u2192 One reason for that is maybe since the authors are normalizing their probabilities at the token level and not at the sequence level ? did the authors investigate such models that are normalizing at the seq level such as : [ 1 ] . I 'm willing to increase my score if the above questions will be answered [ 1 ] Collobert , Ronan , Christian Puhrsch , and Gabriel Synnaeve . `` Wav2letter : an end-to-end convnet-based speech recognition system . '' arXiv preprint arXiv:1609.03193 ( 2016 ) .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your comments ! 1.Regarding the name : We understand where you 're coming from - this generated a lot of internal debate . However , we settled on `` Uncertainty in Structured Prediction '' rather than `` Uncertainty in Autoregressive Prediction '' because we felt that we were tackling the most general model which made the fewest conditional independence assumptions . If we were to consider non-autoregressive models ( such as CTC , HMM , etc ... ) , for example , which make stronger conditional-independence assumptions , then the proposed methods would be as applicable , and there would also be no need for Monte-Carlo approximations . 2.Baselines We understand the desire for additional benchmarks , and are happy to provide ones which we feel are appropriate . Let us clarify what we feel is appropriate : Ensemble based uncertainty estimation is both * general * ( not task specific ) and * unsupervised * , which means we have no supervision regarding where errors are and what is in-domain or out-of-domain . This is a very desirable setup . We have made comparisons with prior heuristic approaches to unsupervised ensemble-based uncertainty estimation in NMT ( and have adapted those methods to ASR ) , the comparison is provided in appendix H table 15 . We show that the proposed methods outperform prior heuristics . We will move these results to the main paper , as space now allows for this . Regarding prior work in confidence-score estimation in ASR - all of it is basically * supervised * - here either a separate classifier is built on top of an ASR system or some kind of mapping is used to transform the acoustic-model likelihoods into probability of insertions/substitutions at each work position . The ground truth error labels are obtained by aligning the true transcription on a validation set to the ASR system \u2019 s hypotheses and training relative to that supervision . This has advantages - that this explicitly targets error detection . However , this additional model is also sensitive to various domain shift , does not allow separation of uncertainty into total/knowledge , and requires supervision which itself can be noisy . Thus , we do not believe that a comparison of general , unsupervised ensemble-based uncertainty estimation to supervised methods is appropriate . However , the basis of these supervised systems are ASR system likelihoods , to which * we are already comparing * every time we consider $ \\mathcal { \\hat H } _ { \\text { S-IW } } ^ { ( 1 ) } $ from the top beam search hypothesis . We will make this clear in the text using the additional page made available . REGARDING COMMENTS : 1 . Yes , broken citation . Will fix.2.+/- 2 * sigma is reported in the ablation study in figures 1 and 2 in the appendices . Here we leave one or more elements of the ensemble out and compute mean/variance across possible sub-ensembles . This is the best we can do for providing confidence bounds for ensemble performances , as we have limited compute to train multiple large ensembles . 3.Thanks for finding , will fix . 4.Regarding human-eval - We have n't done this , but it is something we are very much considering doing as part of a future shared task . 5.Regarding LibriSpeech - You are correct in that LTO is also a part of LibriSpeech , and perhaps we should not strictly refer to it as OOD . This really boils down to how one defines OOD/anomalies . To our understanding , LTO is a dataset collected from samples that were challenging to correctly transcribe . This may have been due to a higher level of minor anomalies and datashifts . AS LTO is a dataset on which , for whatever reason , the ASR system makes more errors , and we would like the model to be able to distinguish between data on which it is likely to make more errors from data on which it makes fewer errors . We felt the cleaner comparison would have been to treat it as anomaly detection , rather than sequence-error detection ( lumping LTC and LTO into one big dataset ) . 6.Global vs Local Norm - The locally normalized nature of autoregressive models may indeed be part of the problem . This may also be a consequence of the fact that the model \u2019 s representation of context is imperfect . As discussed above , we haven \u2019 t considered non-autoregressive sequence-trained globally normalized state-space models , and it would definitely be interesting to do so ! Unfortunately , setting this up and training an ensemble would require more time than is available in the rebuttal ."}, {"review_id": "jN5y-zb5Q7m-2", "review_text": "* * * Summary * * : This work introduce rigorous information-theoretic measures for structured prediction tasks . It proposed metrics for both ` `` total uncertainty '' ( entropy ) and `` knowledge uncertainty '' ( MI , EPKL and RMI ) on the sequence level , introduced efficient Monte-Carlo approaches to estimate them in practice . Finally , author conducted thorough experiment to evaluate the effect of ensemble strategy and choice of metric for error detection and OOD detection in ASR and NMT . * * * Strength and Weakness * * : * ( Strength ) Uncertainty quantification in structured prediction is an important but less explored topic . This work provided a much needed , information-theoretic framework to both conceptually quantify and empirically compute uncertainty measures for different sources of uncertainty . * ( Strength ) Thorough experiment on two tasks ( ASR and NMT ) , where authors designed experiments to quantitatively measure uncertainty quality ( Sequence-level Error Detection and OOD Detection ) under different metrics and ensemble strategies . * ( Weakness ) The experiment conducted are mostly empirical where the ground truth is not necessarily known . Given the theoretical nature of this work , it might be good to conduct simulation study under known truth to examine the estimation quality of different metrics . * * * Recommendation * * : Acceptance . I believe this work provided a nice theoretical framing of different uncertainty measures for an important and less-explored area ( structured prediction ) . It also conducted thorough empirical investigation showing the relative merit of different modeling and measure choices on two standard structure prediction task . The information contained in this paper should be of sufficient interest to ICLR community . * * * Minor Comments * * : * Missing reference on bottom of page 4 : `` rarely used in practice as it yields poor predictive performance ? . '' * Middle of page 6 : `` Rejection curves are summarised using the Prediction Rejection Ratio ( PRR ) '' . Make sure to mention PRR is introduced in detail in Appendix D. * Top of page 3 `` As will be shown later , RMI is particularly attractive .. '' . It might be helpful to point to the section where the `` attractiveness '' of RMI is illustrated ( Equation 12-13 ? ) .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your comments ! We agree and would have also liked to run a small synthetic task which allows us to do analysis in a scenario which we fully control . However , it is difficult to construct a synthetic task where it is possible to BOTH obtain the ground truth uncertainty , and which is still meaningfully complex . We would be happy to consider any suggestions you have ! Typos are fixed and we will shortly update the submission ."}], "0": {"review_id": "jN5y-zb5Q7m-0", "review_text": "This paper proposes two different measures of knowledge ( epistemic ) uncertainty in structured prediction with an autoregressive model and discusses how to compute their approximations . The main contribution is the proposed reverse mutual information ( RMI ) as a measure of epistemic uncertainty in structured prediction . Experiments on benchmark datasets demonstrate the effectiveness of the proposed method in error detection and OOD detection . # # # Clarity # # # # Pros - This paper clearly states the main contributions , assumptions , experimental settings . # # # # Cons - The naming of reverse mutual information is confusing since mutual information itself is symmetric , unlike KL-divergence . - Table 1 shows the predictive performance with an ensemble of autoregressive models , however , it is unrelated to the main contribution of the paper . The proposed RMI is not used to improve the performance of the ensemble of autoregressive models . - Eq ( 4 ) , $ \\tilde { \\theta } $ is used without definition . And there is no $ \\mathcal { D } $ on the right side of the equation . Why is $ q ( \\theta ) = q ( \\tilde { \\theta } ) $ ? - In Eq ( 12 ) , how is $ y $ sampled from $ P ( y\\mid x , \\mathcal { D } ) $ ? Do you mean to sample from $ q ( \\theta ) $ instead of $ p ( \\theta\\mid \\mathcal { D } ) $ ? - Though the two ways , EP and PE , for combination of the ensemble of autoregressive models are both reasonable , only EP can be derived from assumptions in Eq ( 7 ) . PE assumes the probability $ P_ { PE } ( \\boldsymbol { y } \\mid \\boldsymbol { x } , \\mathcal { D } ) $ factorizes over the conditional probability $ { P } ( y_ { l } \\mid \\boldsymbol { y } _ { < l } , \\boldsymbol { x } , \\mathcal { D } ) $ . This should be made clear , otherwise can be confusing . - On page 4 , above Eq ( 10 ) , it is claimed that > ( 8 ) only considers the probabilities of individual tokens $ y_ { l } ^ { ( s ) } $ along a hypothesis $ y^ { ( s ) } $ while ( 9 ) considers the entire conditional distribution over each $ y_ { l } $ . It is not clear why this is the case . In my understanding , ( 8 ) computes the entropy of the joint distribution $ P ( \\boldsymbol { y } \\mid \\boldsymbol { x } , \\mathcal { D } ) $ , which considers all the conditional distribution $ \\mathrm { P } \\left ( y_ { l } \\mid \\boldsymbol { y } _ { < l } , \\boldsymbol { x } \\right ) $ , no matter using EP or PE . Correct me if I am wrong . - ( Minor ) Typos : - Page 4 , above Eq ( 15 ) , practical considerations as it yields poor predictive performance ? - > remove ? - Page 4 , above Eq ( 10 ) , while ( 8 ) yields A - > while ( 8 ) yields a - Page 4 , below Eq ( 13 ) , like ( 8 ) ( 9 ) - > like ( 8 ) ( 10 ) - Page 5 , above Eq ( 16 ) , the models can combined - > the models can be combined # # # Originality # # # # Pros - The paper makes clear its main contributions , including introductions of different measures of uncertainty in structured prediction , the examination of two choices of the combination of ensemble models . The proposed reverse mutual information ( RMI ) improves the performance in OOD detection in structured prediction . # # # # Cons - The contribution of the paper is minor with the proposed RMI measure . - The proposed RMI for epistemic uncertainty estimation is not used to improve the performance of the ensemble of autoregressive models . # # # Significance # # # # Pros - Experimental results show improvement of the proposed method over baseline methods . # # # # Cons - The paper presents ablation studies of different methods for knowledge uncertainty estimation , but it is unclear whether the proposed method achieves state-of-the-art performance on different datasets for error detection and OOD detection . For example , compare to MC-dropout and other recently proposed methods without structured prediction with autoregressive models . - The contribution is not very significant , but mostly an extension and application of uncertainty measures to autoregressive models . For example , the reverse mutual information ( RMI ) , seems to be related to the Reverse KL-divergence proposed in [ 1 ] . More discussion is suggested on how the reverse version improves over the original version as is done in [ 1 ] . - Besides OOD detection , it is also interesting to show whether the proposed uncertainty measure can improve other tasks , such as adversarial sample detection , and active learning . For example , [ 2 ] presents more thorough experiments in these different tasks . - The paper proposes two ways to combine the ensemble of autoregressive models , EP or PE . Experimental results are provided on these two ways of combination . However , it would be better if more theoretical analysis to compare these two could be given based on different assumptions . For example , analysis of the computational complexity of the two choices . - Similarly , it would be better if complexity analysis can be provided for computing approximations of the entropy using relative-entropy chain-rule in Eq ( 9 ) , ( 11 ) , ( 13 ) , and using the traditional ways in Eq ( 8 ) , ( 10 ) , ( 12 ) . Since it is claimed at `` no extra cost '' in the paper . - It is discussed in the paper that EPKL , RMI , MI all measures knowledge uncertainty , and RMI = EPKL - MI . And only MI 'cleanly ' decomposes into total and data uncertainty . A natural question is that if we decompose total uncertainty using RMI , i.e.Total uncertainty = data uncertainty + RMI + res , what does the remaining term res represent ? For example , if RMI gives a better measure of knowledge uncertainty as shown empirically in the paper , then the remaining term in the total uncertainty may measure other types of uncertainty rather than data uncertainty or knowledge uncertainty ? Or there are other ways to represent total uncertainty and/or data uncertainty correspondingly ? Correct me if I am wrong . And it would be better if more discussion can be provided in the paper . [ 1 ] Reverse kl-divergence training of prior networks : Improved uncertainty and adversarial robustness [ 2 ] SDE-Net : Equipping Deep Neural Networks with Uncertainty Estimates", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer1 , we are grateful for your hard work and detailed review . However , we feel that we have failed to properly convey the significance of our contribution to you . Let us attempt to resolve this misunderstanding . While ensemble approaches and information-theoretical measures of uncertainty have been examined in the past , * no prior work * has ever rigorously examined ensemble based uncertainty estimation in the context of structured prediction tasks . The key contribution of our work is \u201c the examination of the attributes of ensemble-based uncertainty estimation for autoregressive structured prediction tasks \u201d , which is novel because it has never been rigorously studied before , especially not for ASR . Furthermore , this work represents the largest-scale application of Bayesian-inspired uncertainty estimation , which in itself is significant . This is the key novelty and contribution of our work . Though we feel that it is an * important * contribution , the proposal of a new uncertainty measure ( RMI ) is NOT our * main * contribution . We will also agree each of your comments point-by-point . CLARITY 1 . We chose the name Reverse Mutual Information because we have flipped the direction of the KL-divergence ( which is non-symmetric ) , relative to standard MI . 2.While predictive performance is not the main contribution of the paper , it is always necessary to quote predictive performance in order to demonstrate that the models under consideration are sensible . In addition , we use this to explore the impact of how an ensemble is combined . 3.This is a notational convenience . This is supposed to indicate a different dummy variable , as we are comparing pairwise KL divergence between samples from the same distribution over models ( from the same ensemble ) . D is absorbed into q ( \\theta ) 4 . We sample translation/transcription hypotheses from P ( y\u2223x , D ) via beam-search decoding . Beam-search decoding can be interpreted as a form of importance sampling . 5.We will address the confusion regarding eq.7 and PE vs EP in the text . 8.Equations 8 and 9 represent Monte-Carlo estimators of entropy which yield the same values * in the limit as S - > infinity * . However , when we consider a finite number of hypotheses , 8 only considers the probabilities of tokens which occur along the hypothesis . On the other hand , 9 estimates the conditional entropy over the full conditional distribution over the next token ( over the entire vocabulary ) at each step along the hypothesis . Thus , 8 consider LS values , while 9 consider LSK values ( K is the size of vocabulary ) . 9.Typos - Many thanks for finding these typos ! Already fixed . ORIGINALITY 1 . As stated above , the main contribution is not RMI , but the examination of general ensemble-based uncertainty estimation in the context of structured prediction . 2.The goal of uncertainty estimation is orthogonal to improving the predictive performance of a system . RMI is a measure of knowledge uncertainty for which an asymptotically exact Monte-Carlo estimator can be obtained , and yields the most competitive OOD detection performance . SIGNIFICANCE - responses in second part ."}, "1": {"review_id": "jN5y-zb5Q7m-1", "review_text": "After rebuttal : I would like to thank the authors for paying attention to the comments and providing additional experiments and results . I updated my score . = This paper investigates uncertainty estimation for autoregressive structured prediction models . The authors explored several metrics for computing uncertainty in structured neural network based models , such as expected pair-wise KL-divergence , mutual information , and reverse mutual information ( RMI ) . The authors demonstrated the efficiency of the proposed RMI using machine translation and speech recognition models for error detection and out-of-distribution detection . Overall this paper is clearly written and investigates highly relevant topic . However , some clarifications are needed . First , I find the name of the paper a bit misleading , there are plenty of structured prediction models , and the authors investigated only neural based and autoregressive ones . Second , I know the authors mentioned that they did not compare to prior work since it did not consider auto-regressive models , however , I feel that a comparison is still needed . There are a few papers ( some of which the authors already mentioned ) , that suggest different ways to estimate uncertainties in AST and MT . I would expect to see a comparison to some of these methods . Comments to the authors : 1 ) In `` Practical Considerations '' there is a question mark , probably a missing citation ? 2 ) The improvements in Table 1 seems pretty marginal . Can the authors report the variance of the estimator too ? 3 ) `` The results also show that uncertainty-based rejection works better for ASR for NMT . '' \u2192 `` The results also show that uncertainty-based rejection works better for ASR than NMT . '' 4 ) `` A better , but more expensive , approach to assess uncertainty estimates in NMT is whether they correlate well with human assessment of translation quality . '' \u2192 did the authors try to use subjective evaluations ? 5 ) `` Three OOD datasets are considered , each covering a different form of domain shift . First , LibriSpeech test-other ( LTO ) ... '' \u2192 I find this definition of OOD a bit problematic . LTO is still part of librispeech , so I would not consider that as OOD . 6 ) `` Notably , it was found that token-level Bayesian model averaging consistently yields both marginally better predictive performance and more robust estimates of uncertainty . '' \u2192 One reason for that is maybe since the authors are normalizing their probabilities at the token level and not at the sequence level ? did the authors investigate such models that are normalizing at the seq level such as : [ 1 ] . I 'm willing to increase my score if the above questions will be answered [ 1 ] Collobert , Ronan , Christian Puhrsch , and Gabriel Synnaeve . `` Wav2letter : an end-to-end convnet-based speech recognition system . '' arXiv preprint arXiv:1609.03193 ( 2016 ) .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your comments ! 1.Regarding the name : We understand where you 're coming from - this generated a lot of internal debate . However , we settled on `` Uncertainty in Structured Prediction '' rather than `` Uncertainty in Autoregressive Prediction '' because we felt that we were tackling the most general model which made the fewest conditional independence assumptions . If we were to consider non-autoregressive models ( such as CTC , HMM , etc ... ) , for example , which make stronger conditional-independence assumptions , then the proposed methods would be as applicable , and there would also be no need for Monte-Carlo approximations . 2.Baselines We understand the desire for additional benchmarks , and are happy to provide ones which we feel are appropriate . Let us clarify what we feel is appropriate : Ensemble based uncertainty estimation is both * general * ( not task specific ) and * unsupervised * , which means we have no supervision regarding where errors are and what is in-domain or out-of-domain . This is a very desirable setup . We have made comparisons with prior heuristic approaches to unsupervised ensemble-based uncertainty estimation in NMT ( and have adapted those methods to ASR ) , the comparison is provided in appendix H table 15 . We show that the proposed methods outperform prior heuristics . We will move these results to the main paper , as space now allows for this . Regarding prior work in confidence-score estimation in ASR - all of it is basically * supervised * - here either a separate classifier is built on top of an ASR system or some kind of mapping is used to transform the acoustic-model likelihoods into probability of insertions/substitutions at each work position . The ground truth error labels are obtained by aligning the true transcription on a validation set to the ASR system \u2019 s hypotheses and training relative to that supervision . This has advantages - that this explicitly targets error detection . However , this additional model is also sensitive to various domain shift , does not allow separation of uncertainty into total/knowledge , and requires supervision which itself can be noisy . Thus , we do not believe that a comparison of general , unsupervised ensemble-based uncertainty estimation to supervised methods is appropriate . However , the basis of these supervised systems are ASR system likelihoods , to which * we are already comparing * every time we consider $ \\mathcal { \\hat H } _ { \\text { S-IW } } ^ { ( 1 ) } $ from the top beam search hypothesis . We will make this clear in the text using the additional page made available . REGARDING COMMENTS : 1 . Yes , broken citation . Will fix.2.+/- 2 * sigma is reported in the ablation study in figures 1 and 2 in the appendices . Here we leave one or more elements of the ensemble out and compute mean/variance across possible sub-ensembles . This is the best we can do for providing confidence bounds for ensemble performances , as we have limited compute to train multiple large ensembles . 3.Thanks for finding , will fix . 4.Regarding human-eval - We have n't done this , but it is something we are very much considering doing as part of a future shared task . 5.Regarding LibriSpeech - You are correct in that LTO is also a part of LibriSpeech , and perhaps we should not strictly refer to it as OOD . This really boils down to how one defines OOD/anomalies . To our understanding , LTO is a dataset collected from samples that were challenging to correctly transcribe . This may have been due to a higher level of minor anomalies and datashifts . AS LTO is a dataset on which , for whatever reason , the ASR system makes more errors , and we would like the model to be able to distinguish between data on which it is likely to make more errors from data on which it makes fewer errors . We felt the cleaner comparison would have been to treat it as anomaly detection , rather than sequence-error detection ( lumping LTC and LTO into one big dataset ) . 6.Global vs Local Norm - The locally normalized nature of autoregressive models may indeed be part of the problem . This may also be a consequence of the fact that the model \u2019 s representation of context is imperfect . As discussed above , we haven \u2019 t considered non-autoregressive sequence-trained globally normalized state-space models , and it would definitely be interesting to do so ! Unfortunately , setting this up and training an ensemble would require more time than is available in the rebuttal ."}, "2": {"review_id": "jN5y-zb5Q7m-2", "review_text": "* * * Summary * * : This work introduce rigorous information-theoretic measures for structured prediction tasks . It proposed metrics for both ` `` total uncertainty '' ( entropy ) and `` knowledge uncertainty '' ( MI , EPKL and RMI ) on the sequence level , introduced efficient Monte-Carlo approaches to estimate them in practice . Finally , author conducted thorough experiment to evaluate the effect of ensemble strategy and choice of metric for error detection and OOD detection in ASR and NMT . * * * Strength and Weakness * * : * ( Strength ) Uncertainty quantification in structured prediction is an important but less explored topic . This work provided a much needed , information-theoretic framework to both conceptually quantify and empirically compute uncertainty measures for different sources of uncertainty . * ( Strength ) Thorough experiment on two tasks ( ASR and NMT ) , where authors designed experiments to quantitatively measure uncertainty quality ( Sequence-level Error Detection and OOD Detection ) under different metrics and ensemble strategies . * ( Weakness ) The experiment conducted are mostly empirical where the ground truth is not necessarily known . Given the theoretical nature of this work , it might be good to conduct simulation study under known truth to examine the estimation quality of different metrics . * * * Recommendation * * : Acceptance . I believe this work provided a nice theoretical framing of different uncertainty measures for an important and less-explored area ( structured prediction ) . It also conducted thorough empirical investigation showing the relative merit of different modeling and measure choices on two standard structure prediction task . The information contained in this paper should be of sufficient interest to ICLR community . * * * Minor Comments * * : * Missing reference on bottom of page 4 : `` rarely used in practice as it yields poor predictive performance ? . '' * Middle of page 6 : `` Rejection curves are summarised using the Prediction Rejection Ratio ( PRR ) '' . Make sure to mention PRR is introduced in detail in Appendix D. * Top of page 3 `` As will be shown later , RMI is particularly attractive .. '' . It might be helpful to point to the section where the `` attractiveness '' of RMI is illustrated ( Equation 12-13 ? ) .", "rating": "7: Good paper, accept", "reply_text": "Thank you for your comments ! We agree and would have also liked to run a small synthetic task which allows us to do analysis in a scenario which we fully control . However , it is difficult to construct a synthetic task where it is possible to BOTH obtain the ground truth uncertainty , and which is still meaningfully complex . We would be happy to consider any suggestions you have ! Typos are fixed and we will shortly update the submission ."}}