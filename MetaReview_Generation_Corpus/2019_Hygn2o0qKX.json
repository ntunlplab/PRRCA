{"year": "2019", "forum": "Hygn2o0qKX", "title": "Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience", "decision": "Accept (Poster)", "meta_review": "Existing PAC Bayes analysis gives generalization bounds for stochastic networks/classifiers. This paper develops a new approach to obtain generalization bounds for the original network, by generalizing noise resilience property from training data to test data.  All reviewers agree that the techniques  developed in the paper (namely Theorem 3.1) are novel and interesting.  There was disagreement between reviewers on the usefulness of the new generalization bound (Theorem 4.1) shown in this paper using the above techniques. I believe authors have sufficiently addressed these concerns in their response and updated draft. Hence, despite the concerns of R3 on limitations of this bound and its dependence on pre-activation values, I agree with R2 and R4 that the techniques developed in the paper are of interest to the community and deserve publication. I suggest authors to keep comments of R3 in mind while preparing the final version. ", "reviews": [{"review_id": "Hygn2o0qKX-0", "review_text": "The authors demonstrate the generalization bound for deep neural networks using the PAC-Bayesian approach. They adopt the idea of noise resilience in the analysis and obtain a result that has improved dependence in terms of the network dimensions, but involves parameters (e.g., pre-activation) that may be large potentially. My major concern is also regarding the dependence on the pre-activation that can be very large in practice. This is also shown in the numerical experiments. Therefore, the overall generalization bound can be larger than existing results, though the later have stronger dependence on the network sizes. By examining the analysis for the main result, it seems to me that the reason the authors can induce weaker dependence on network sizes is essentially they involved the pre-activation parameters. This can be viewed as a trade-off how strong the generalization bound depend on the network sizes and other related parameters (like the pre-activation here) rather than strictly tighten the error bound from a more refined/structured way. I also suggest that the authors provide the comparison of their bound and existing ones to see the quantitative difference of the results. Regarding the noise resilience, it is not clear to where the noise resilience shows up from the analysis or the result. From the proof of the main result, the analysis seems to be standard as in the PAC-Bayesian analysis, which is based on bounding the difference of the network before and after injecting randomness into the parameters. The difference with respect to the previous result due to the different way of bounding such a gap, where the Jacobian, the pre-activation and function output pop up. But this does not explain how well a network can tolerate the noise, either in the parameter space of the data space. This is different with the previous analysis based on the noise resilience, such as [1]. So, the title and the way the authors explain as noise resilience is somewhat misleading. More detailed explanation will help. [1] Arora et al. Stronger generalization bounds for deep nets via a compression approach. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for you comments ! In this response , we 'll address the second half of your comment and explain the contributions of the paper , which we believe has been misunderstood . We first note that our contribution is not just about getting rid of the dependence on the products of the spectral norms of the weight matrices ; our contribution is also that we arrive at such a bound on the * original network * and not just a compressed network/stochastic network . While compression-based bounds like [ 1 ] or other PAC-Bayes based bounds like [ 2,3 ] numerically evaluate to smaller values , and provide a partial answer for why deep networks generalize well , these bounds are not on the original network learned by SGD . An extremely important and * * non-trivial * * piece of the puzzle is to extend the benefits of these bounds ( or at least some of its benefits -- in this case the lack of a product-of-spectral-norm dependence ) over to the original network . We do this by presenting a structured and novel technique which `` generalizes noise-resilience '' presented in Section 3 . Thus we disagree with the observation that our bound does not `` strictly tighten the error bound from a more refined/structured way . '' Below we describe what we mean by `` generalizing noise-resilience '' , in effect justifying our title , and also clarifying what exactly our contribution is . Like in [ 1,2 ] , we model noise-resilience in terms of certain `` conditions '' . For example , [ 1 ] assume conditions like `` the interlayer smoothness of the network is sufficiently large on training data '' . We assume similar conditions ( e.g. , `` the output of each layer has small l2 norm on the training data '' ) this allows us to bound the output perturbation of the network without incurring a product-of-spectral-norm dependence . Crucially , our theory and the theory in [ 1,2 ] assume these conditions to hold only * * on training data * * . With reference to your comment : `` The difference with ... previous result due to the different way of bounding such a gap ... But this does not explain how well a network can tolerate the noise '' : While there are technical differences in how these conditions are formulated in [ 1,2 ] vs. our work , and how the perturbation in the output is bounded in terms of these conditions , the exact formulation of the conditions is NOT our key contribution . As mentioned in Page 3 under our contributions , our conditions are in fact philosophically similar to those in [ 1 ] and [ 2 ] and at a high level essentially characterize how the activated parts of the weight matrices in the network interact with each other . We strongly emphasize the following points : ===== > The novelty in our paper is NOT primarily about explaining why a network is noise-resilient ( on training data ) . ===== > Our main contribution , when compared to [ 1 ] or [ 2 ] , is that we take a step beyond these existing approaches and present an approach to how conditions assumed about the network on the training data * can be generalized to test data * . This step is crucial and allows us to claim that the network is noise-resilient on test data as well . The key reason [ 1,2 ] were not able to present product-of-spectral-norm independent bounds on the original network ( but only on a modified network ) was that they did not generalize these conditions about the behavior of the network from the training data to test data . To achieve this , we present a structured approach that iterates through the layers and generalizes these conditions one after the other , in a specific order . It requires a lot of care to not incur product-of-spectral-norm dependency ( or other extra dependencies on the width ) while generalizing any of these multiple O ( depth^2 ) conditions . Besides , to generalize each condition , we require a particular style of reducing PAC-Bayesian bounds to deterministic bounds . Overall , we hope you understand that our analysis is quite far from `` standard as in the PAC-Bayesian analysis , which is based on bounding the difference of the network before and after injecting randomness into the parameters '' . The idea of generalizing these conditions is novel and is an important step to explain the noise-resilience of these networks on testing data . Besides being refined and structured , most importantly , our approach is general and leaves scope for future work to use it as a hammer on different sets of conditions ( hopefully one that does n't assume large preactivation values on all units ! ) . We hope our detailed response better explains the contribution of our work to answering the generalization puzzle , in the context of the results in [ 1,2 ] . [ 1 ] Arora et al. , `` Stronger generalization bounds for deep nets via a compression approach . '' [ 2 ] Neyshabur et al. , `` Exploring gen- eralization in deep learning . '' [ 3 ] Dziugaite et al. , `` Computing nonvacuous generalization bounds ... than training data . ''"}, {"review_id": "Hygn2o0qKX-1", "review_text": "The fact that a number of current generalization bounds for (deep) neural networks are not expressed on the deterministic predictor at stake is arguably an issue. This is notably the case of many recent PAC-Bayesian studies of neural networks stochastic surrogates (typically, a Gaussian noise is applied to the network weight parameters). The paper proposes to make these PAC-Bayesian bounds deterministic by studying their \"noise-resilience\" properties. The proposed generalization result bounds the margin of a (ReLU) neural network classifier from the empirical margin and a complexity term relying on conditions on the values of each layer (e.g., via layer Jacobian norm, the layer output norm, and the smallest pre-activation value). I have difficulty to attest if the proposed conditions are sound. Namely, the authors genuinely admit that the empirically observed pre-activation values are not large enough to make the bound informative (I must say that I truly appreciate the authors' candor when it comes to analyzing their result). That being said, the fact that the bounds does not scale with the spectral norm of the weight matrices, like previous PAC-Bayesian result for neural networks, is an asset of the current analysis. I must say that I had only a quick look to it the proofs, all of them being in the supplementary material along most of the technical details. Nevertheless, it appears to me as an honest, original and rigorous theoretical study, and I think it deserves to be presented to the community. It can bring interesting discussion and suggest new paths to explore to explain the generalization properties of neural networks. Minor comment: For the reader benefit, Theorem F.1 in page 7 should quickly recall the meaning of some notation, even if it's the \"short version\" of the theorem statement. ==== update: The bound comparison added value to the paper. It strengthens my opinion that this work deserves to be published. I therefore increase my score to 7. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your positive response ! We are glad you agree that many of the current generalization bounds for deep networks apply only to a compressed/stochastic network ; indeed , even though these bounds provide valuable intuition about generalization , we believe that an extremely important and non-trivial piece of the puzzle is to extend the benefits of these bounds ( or at least some of its benefits -- in this case the lack of a product-of-spectral-norm dependence ) over to the original network . And we achieve this through an approach that `` generalizes noise resilience '' . With regards to your suspicion about the proposed `` conditions '' , the only pesky condition in our result is the one involving the pre-activation values . The other bounds on the other quantities certainly hold favorably in practice as seen in our plots . We must also note that these conditions themselves are not the main contribution of our paper ( and we have stated this point in `` Our Contribution '' in Page 3 ) ; the main contribution lies in how we generalize these conditions assumed about the network on the training data , to test data ( without ever incurring a product-of-spectral-norms dependence ) . The conditions themselves are in fact philosophically similar to conditions examined and verified in prior work [ 1,2 ] ; in essence , they dictate how the parts of the weight matrices activated by a particular datapoint , interact with each other . Even as far as the condition involving the pre-activation values are concerned , it appears in our analysis to ensure that the hidden units do n't jump their non-linearity under parameter perturbations ; the assumption that only a small proportion of the hidden units do not jump the non-linearity under perturbations has been made in prior works , although in a more relaxed form e.g. , `` Interlayer Smoothness '' in [ 1 ] or condition C2 in [ 2 ] , and * these have been verified in practice * . Intuitively , we believe that this assumption allows one to argue that the network is `` linear '' in a small local neighborhood in the parameter space , and this local linearity helps imply that the network has lesser complexity . Again , we thank the reviewer for appreciating our contributions . We hope that the community finds our approach of generalizing noise-resilience useful . Our framework is general in that one could think of designing different sets of conditions that imply noise-resilience of the network , and argue how these conditions would generalize ; with a better understanding of the source of noise-resilience in deep networks , we might identify better sets of conditions which can be generalized this way to obtain tighter bounds on the original network . We will take note of the reviewer 's comment about Theorem F.1 ! [ 1 ] Arora et al. , `` Stronger generalization bounds for deep nets via a compression approach . '' [ 2 ] Neyshabur et al. , `` Exploring gen- eralization in deep learning . ''"}, {"review_id": "Hygn2o0qKX-2", "review_text": "This paper presents a PAC-Bayesian framework that bounds the generalization error of the learned model. While PAC-Bayesian bounds have been studied before, the focus of this paper is to study how different conditions in the network (e.g. behavior of activations) generalize from training set to the distribution. This is important since prior work have not been able to handle this issue properly and as a consequence, previous bounds are either on the networks with perturbed weights or with unrealistic assumptions on the behavior of the network for any input in the domain. I think the paper could have been written more clearly. I had a hard time following the arguments in the paper. For example, I had to start reading from the Appendix to understand what is going on and found the appendix more helpful than the main text. Moreover, the constraints should be discussed more clearly and verified through experiments. I see Constraint 2 as a major shortcoming of the paper. The promise of the paper was to avoid making assumptions on the input domain (one of the drawbacks in Neyshabur et al 2018) but the constraint 2 is on any input in the domain. In my view, this makes the result less interesting. Finally, as authors mention themselves, I think conditions in Theorem F.1 (the label should be 4.1 since it is in Section 4) could be improved with more work. More specifically, it seems that the condition on the pre-activation value can be improved by rebalancing using the positive homogeneity of ReLU activations. Overall, while I find the motivation and the approach interesting, I think this is not a complete piece of work and it can be improved significantly. =========== Update: Authors have addressed my main concern, improved the presentation and added extra experiments that improve the quality of the paper. I recommend accepting this paper. ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer , thanks for your precise summary of the paper 's approach and your thoughts about it ! We strongly disagree with your remark that Constraint 2 is `` a major shortcoming of the paper '' . Here 's why : Constraint 2 is not restrictive and is in fact a very natural/intuitive constraint of the properties in the network -- and it provably holds good . At a high level , all the constraint says is the following : * * For a given point x * * for which the first r-1 sets of properties are bounded ( say the first 3 layers have small l2 norm ) , the r-th property is noise-resilient ( i.e. , under noise injected into the parameters , the 4th layer 's l2 norm does not suffer much change under parameter perturbation ) . This is a pretty natural constraint * * which provably holds * * for networks because of how the output of a particular layer depends only on the output of the preceeding layers . We make NO assumption of the form that something about the network holds good for ALL inputs in the domain . As you can see in Theorem 3.1 , we say `` if W satisfies T_r ( W , x , y ) > Delta_r^ * ... for all ( x , y ) in S '' which means that these properties are bounded only for the training data . We hope this clears the misunderstanding surrounding the constraint and convinces you that this is not at a drawback at all ! The drawback that we acknowledge is regarding the dependence on the pre-activations , which we hope to improve upon in the future . But as it is , we believe the paper makes a conceptual contribution in terms of a new methodology of generalizing noise-resilience , and accomplishes a PAC-Bayes based product-of-spectral-norm independent bound in specific settings where it was n't possible . As you 've suggested , we will improve the discussion of the constraints ; thanks for your comment !"}, {"review_id": "Hygn2o0qKX-3", "review_text": "This paper provides new generalization bounds for deep neural networks using the PAC-Bayesian framework. Recent efforts along these lines have proved bounds that either apply to a classifier drawn from a distribution or to a compressed form of the trained classifier. In contrast, the paper uses PAC Bayesian bounds to provide generalization bounds for the original trained network. At this same time, the goal is to provide bounds that do not scale exponentially in the depth of the network and depend on more nuanced parameters such as the noise-stability of the network. In order to do that the paper formalizes properties that a classifier must satisfy on the training data. While these are a little difficult to understand in general, in the context of ReLU networks these boil down to bounding the l2-norms of the Jacobian and the hidden layer outputs on each data point. Additionally, the paper also requires the pre-activations to be sufficiently large, which as the authors acknowledge, is an unrealistic assumption that is not true in practice. Despite that, the paper makes an important contribution towards our current understanding of generalization of deep nets. It would have been helpful if the authors had a more detailed discussion on how their assumptions relate to the specific assumptions in the papers of Arora et al. and Neyshabur et al. This would help when comparing the results of the paper with existing ones. ", "rating": "7: Good paper, accept", "reply_text": "Dear Reviewer , Thanks for your positive feedback ! We have uploaded a revised version with Appendix G where we have added a one-page discussion relating our noise-resilience conditions and the conditions in prior work . We hope this provides you better context to understand our assumptions . Happy to provide more details if needed ."}], "0": {"review_id": "Hygn2o0qKX-0", "review_text": "The authors demonstrate the generalization bound for deep neural networks using the PAC-Bayesian approach. They adopt the idea of noise resilience in the analysis and obtain a result that has improved dependence in terms of the network dimensions, but involves parameters (e.g., pre-activation) that may be large potentially. My major concern is also regarding the dependence on the pre-activation that can be very large in practice. This is also shown in the numerical experiments. Therefore, the overall generalization bound can be larger than existing results, though the later have stronger dependence on the network sizes. By examining the analysis for the main result, it seems to me that the reason the authors can induce weaker dependence on network sizes is essentially they involved the pre-activation parameters. This can be viewed as a trade-off how strong the generalization bound depend on the network sizes and other related parameters (like the pre-activation here) rather than strictly tighten the error bound from a more refined/structured way. I also suggest that the authors provide the comparison of their bound and existing ones to see the quantitative difference of the results. Regarding the noise resilience, it is not clear to where the noise resilience shows up from the analysis or the result. From the proof of the main result, the analysis seems to be standard as in the PAC-Bayesian analysis, which is based on bounding the difference of the network before and after injecting randomness into the parameters. The difference with respect to the previous result due to the different way of bounding such a gap, where the Jacobian, the pre-activation and function output pop up. But this does not explain how well a network can tolerate the noise, either in the parameter space of the data space. This is different with the previous analysis based on the noise resilience, such as [1]. So, the title and the way the authors explain as noise resilience is somewhat misleading. More detailed explanation will help. [1] Arora et al. Stronger generalization bounds for deep nets via a compression approach. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for you comments ! In this response , we 'll address the second half of your comment and explain the contributions of the paper , which we believe has been misunderstood . We first note that our contribution is not just about getting rid of the dependence on the products of the spectral norms of the weight matrices ; our contribution is also that we arrive at such a bound on the * original network * and not just a compressed network/stochastic network . While compression-based bounds like [ 1 ] or other PAC-Bayes based bounds like [ 2,3 ] numerically evaluate to smaller values , and provide a partial answer for why deep networks generalize well , these bounds are not on the original network learned by SGD . An extremely important and * * non-trivial * * piece of the puzzle is to extend the benefits of these bounds ( or at least some of its benefits -- in this case the lack of a product-of-spectral-norm dependence ) over to the original network . We do this by presenting a structured and novel technique which `` generalizes noise-resilience '' presented in Section 3 . Thus we disagree with the observation that our bound does not `` strictly tighten the error bound from a more refined/structured way . '' Below we describe what we mean by `` generalizing noise-resilience '' , in effect justifying our title , and also clarifying what exactly our contribution is . Like in [ 1,2 ] , we model noise-resilience in terms of certain `` conditions '' . For example , [ 1 ] assume conditions like `` the interlayer smoothness of the network is sufficiently large on training data '' . We assume similar conditions ( e.g. , `` the output of each layer has small l2 norm on the training data '' ) this allows us to bound the output perturbation of the network without incurring a product-of-spectral-norm dependence . Crucially , our theory and the theory in [ 1,2 ] assume these conditions to hold only * * on training data * * . With reference to your comment : `` The difference with ... previous result due to the different way of bounding such a gap ... But this does not explain how well a network can tolerate the noise '' : While there are technical differences in how these conditions are formulated in [ 1,2 ] vs. our work , and how the perturbation in the output is bounded in terms of these conditions , the exact formulation of the conditions is NOT our key contribution . As mentioned in Page 3 under our contributions , our conditions are in fact philosophically similar to those in [ 1 ] and [ 2 ] and at a high level essentially characterize how the activated parts of the weight matrices in the network interact with each other . We strongly emphasize the following points : ===== > The novelty in our paper is NOT primarily about explaining why a network is noise-resilient ( on training data ) . ===== > Our main contribution , when compared to [ 1 ] or [ 2 ] , is that we take a step beyond these existing approaches and present an approach to how conditions assumed about the network on the training data * can be generalized to test data * . This step is crucial and allows us to claim that the network is noise-resilient on test data as well . The key reason [ 1,2 ] were not able to present product-of-spectral-norm independent bounds on the original network ( but only on a modified network ) was that they did not generalize these conditions about the behavior of the network from the training data to test data . To achieve this , we present a structured approach that iterates through the layers and generalizes these conditions one after the other , in a specific order . It requires a lot of care to not incur product-of-spectral-norm dependency ( or other extra dependencies on the width ) while generalizing any of these multiple O ( depth^2 ) conditions . Besides , to generalize each condition , we require a particular style of reducing PAC-Bayesian bounds to deterministic bounds . Overall , we hope you understand that our analysis is quite far from `` standard as in the PAC-Bayesian analysis , which is based on bounding the difference of the network before and after injecting randomness into the parameters '' . The idea of generalizing these conditions is novel and is an important step to explain the noise-resilience of these networks on testing data . Besides being refined and structured , most importantly , our approach is general and leaves scope for future work to use it as a hammer on different sets of conditions ( hopefully one that does n't assume large preactivation values on all units ! ) . We hope our detailed response better explains the contribution of our work to answering the generalization puzzle , in the context of the results in [ 1,2 ] . [ 1 ] Arora et al. , `` Stronger generalization bounds for deep nets via a compression approach . '' [ 2 ] Neyshabur et al. , `` Exploring gen- eralization in deep learning . '' [ 3 ] Dziugaite et al. , `` Computing nonvacuous generalization bounds ... than training data . ''"}, "1": {"review_id": "Hygn2o0qKX-1", "review_text": "The fact that a number of current generalization bounds for (deep) neural networks are not expressed on the deterministic predictor at stake is arguably an issue. This is notably the case of many recent PAC-Bayesian studies of neural networks stochastic surrogates (typically, a Gaussian noise is applied to the network weight parameters). The paper proposes to make these PAC-Bayesian bounds deterministic by studying their \"noise-resilience\" properties. The proposed generalization result bounds the margin of a (ReLU) neural network classifier from the empirical margin and a complexity term relying on conditions on the values of each layer (e.g., via layer Jacobian norm, the layer output norm, and the smallest pre-activation value). I have difficulty to attest if the proposed conditions are sound. Namely, the authors genuinely admit that the empirically observed pre-activation values are not large enough to make the bound informative (I must say that I truly appreciate the authors' candor when it comes to analyzing their result). That being said, the fact that the bounds does not scale with the spectral norm of the weight matrices, like previous PAC-Bayesian result for neural networks, is an asset of the current analysis. I must say that I had only a quick look to it the proofs, all of them being in the supplementary material along most of the technical details. Nevertheless, it appears to me as an honest, original and rigorous theoretical study, and I think it deserves to be presented to the community. It can bring interesting discussion and suggest new paths to explore to explain the generalization properties of neural networks. Minor comment: For the reader benefit, Theorem F.1 in page 7 should quickly recall the meaning of some notation, even if it's the \"short version\" of the theorem statement. ==== update: The bound comparison added value to the paper. It strengthens my opinion that this work deserves to be published. I therefore increase my score to 7. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your positive response ! We are glad you agree that many of the current generalization bounds for deep networks apply only to a compressed/stochastic network ; indeed , even though these bounds provide valuable intuition about generalization , we believe that an extremely important and non-trivial piece of the puzzle is to extend the benefits of these bounds ( or at least some of its benefits -- in this case the lack of a product-of-spectral-norm dependence ) over to the original network . And we achieve this through an approach that `` generalizes noise resilience '' . With regards to your suspicion about the proposed `` conditions '' , the only pesky condition in our result is the one involving the pre-activation values . The other bounds on the other quantities certainly hold favorably in practice as seen in our plots . We must also note that these conditions themselves are not the main contribution of our paper ( and we have stated this point in `` Our Contribution '' in Page 3 ) ; the main contribution lies in how we generalize these conditions assumed about the network on the training data , to test data ( without ever incurring a product-of-spectral-norms dependence ) . The conditions themselves are in fact philosophically similar to conditions examined and verified in prior work [ 1,2 ] ; in essence , they dictate how the parts of the weight matrices activated by a particular datapoint , interact with each other . Even as far as the condition involving the pre-activation values are concerned , it appears in our analysis to ensure that the hidden units do n't jump their non-linearity under parameter perturbations ; the assumption that only a small proportion of the hidden units do not jump the non-linearity under perturbations has been made in prior works , although in a more relaxed form e.g. , `` Interlayer Smoothness '' in [ 1 ] or condition C2 in [ 2 ] , and * these have been verified in practice * . Intuitively , we believe that this assumption allows one to argue that the network is `` linear '' in a small local neighborhood in the parameter space , and this local linearity helps imply that the network has lesser complexity . Again , we thank the reviewer for appreciating our contributions . We hope that the community finds our approach of generalizing noise-resilience useful . Our framework is general in that one could think of designing different sets of conditions that imply noise-resilience of the network , and argue how these conditions would generalize ; with a better understanding of the source of noise-resilience in deep networks , we might identify better sets of conditions which can be generalized this way to obtain tighter bounds on the original network . We will take note of the reviewer 's comment about Theorem F.1 ! [ 1 ] Arora et al. , `` Stronger generalization bounds for deep nets via a compression approach . '' [ 2 ] Neyshabur et al. , `` Exploring gen- eralization in deep learning . ''"}, "2": {"review_id": "Hygn2o0qKX-2", "review_text": "This paper presents a PAC-Bayesian framework that bounds the generalization error of the learned model. While PAC-Bayesian bounds have been studied before, the focus of this paper is to study how different conditions in the network (e.g. behavior of activations) generalize from training set to the distribution. This is important since prior work have not been able to handle this issue properly and as a consequence, previous bounds are either on the networks with perturbed weights or with unrealistic assumptions on the behavior of the network for any input in the domain. I think the paper could have been written more clearly. I had a hard time following the arguments in the paper. For example, I had to start reading from the Appendix to understand what is going on and found the appendix more helpful than the main text. Moreover, the constraints should be discussed more clearly and verified through experiments. I see Constraint 2 as a major shortcoming of the paper. The promise of the paper was to avoid making assumptions on the input domain (one of the drawbacks in Neyshabur et al 2018) but the constraint 2 is on any input in the domain. In my view, this makes the result less interesting. Finally, as authors mention themselves, I think conditions in Theorem F.1 (the label should be 4.1 since it is in Section 4) could be improved with more work. More specifically, it seems that the condition on the pre-activation value can be improved by rebalancing using the positive homogeneity of ReLU activations. Overall, while I find the motivation and the approach interesting, I think this is not a complete piece of work and it can be improved significantly. =========== Update: Authors have addressed my main concern, improved the presentation and added extra experiments that improve the quality of the paper. I recommend accepting this paper. ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Dear Reviewer , thanks for your precise summary of the paper 's approach and your thoughts about it ! We strongly disagree with your remark that Constraint 2 is `` a major shortcoming of the paper '' . Here 's why : Constraint 2 is not restrictive and is in fact a very natural/intuitive constraint of the properties in the network -- and it provably holds good . At a high level , all the constraint says is the following : * * For a given point x * * for which the first r-1 sets of properties are bounded ( say the first 3 layers have small l2 norm ) , the r-th property is noise-resilient ( i.e. , under noise injected into the parameters , the 4th layer 's l2 norm does not suffer much change under parameter perturbation ) . This is a pretty natural constraint * * which provably holds * * for networks because of how the output of a particular layer depends only on the output of the preceeding layers . We make NO assumption of the form that something about the network holds good for ALL inputs in the domain . As you can see in Theorem 3.1 , we say `` if W satisfies T_r ( W , x , y ) > Delta_r^ * ... for all ( x , y ) in S '' which means that these properties are bounded only for the training data . We hope this clears the misunderstanding surrounding the constraint and convinces you that this is not at a drawback at all ! The drawback that we acknowledge is regarding the dependence on the pre-activations , which we hope to improve upon in the future . But as it is , we believe the paper makes a conceptual contribution in terms of a new methodology of generalizing noise-resilience , and accomplishes a PAC-Bayes based product-of-spectral-norm independent bound in specific settings where it was n't possible . As you 've suggested , we will improve the discussion of the constraints ; thanks for your comment !"}, "3": {"review_id": "Hygn2o0qKX-3", "review_text": "This paper provides new generalization bounds for deep neural networks using the PAC-Bayesian framework. Recent efforts along these lines have proved bounds that either apply to a classifier drawn from a distribution or to a compressed form of the trained classifier. In contrast, the paper uses PAC Bayesian bounds to provide generalization bounds for the original trained network. At this same time, the goal is to provide bounds that do not scale exponentially in the depth of the network and depend on more nuanced parameters such as the noise-stability of the network. In order to do that the paper formalizes properties that a classifier must satisfy on the training data. While these are a little difficult to understand in general, in the context of ReLU networks these boil down to bounding the l2-norms of the Jacobian and the hidden layer outputs on each data point. Additionally, the paper also requires the pre-activations to be sufficiently large, which as the authors acknowledge, is an unrealistic assumption that is not true in practice. Despite that, the paper makes an important contribution towards our current understanding of generalization of deep nets. It would have been helpful if the authors had a more detailed discussion on how their assumptions relate to the specific assumptions in the papers of Arora et al. and Neyshabur et al. This would help when comparing the results of the paper with existing ones. ", "rating": "7: Good paper, accept", "reply_text": "Dear Reviewer , Thanks for your positive feedback ! We have uploaded a revised version with Appendix G where we have added a one-page discussion relating our noise-resilience conditions and the conditions in prior work . We hope this provides you better context to understand our assumptions . Happy to provide more details if needed ."}}