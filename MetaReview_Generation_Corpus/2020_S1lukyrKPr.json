{"year": "2020", "forum": "S1lukyrKPr", "title": "LEX-GAN: Layered Explainable Rumor Detector Based on Generative Adversarial Networks", "decision": "Reject", "meta_review": "The paper is well-written and presents an extensive set of experiments. The architecture is a simple yet interesting attempt at learning explainable rumour detection models. Some reviewers worry about the novelty of the approach, and whether the explainability of the model is in fact properly evaluated. The authors responded to the reviews and provided detailed feedback. A major limitation of this work is that explanations are at the level of input words. This is common in interpretability (LIME, etc), but it is not clear that explanations/interpretations are best provided at this level and not, say, at the level of training instances or at a more abstract level. It is also not clear that this approach would scale to languages that are morphologically rich and/or harder to segment into words. Since modern approaches to this problem would likely include pretrained language models, it is an interesting problem to make such architectures interpretable. ", "reviews": [{"review_id": "S1lukyrKPr-0", "review_text": "In the paper, authors proposed a generative adversarial network-based rumor detection model that can label short text like Twitter posts as rumor or not. The model can further highlight the words that are responsible for the rumor accusation. Proposed model consists of 4 sub models: a G_Where model finds the word to replace so to create an artificial rumor; a G_replace model decides what the replacement word should be; a D_classify model detects if a sequence is a rumor; a final D_explain model pinpoints the word of concern. D_ models and G_ models are trained in an adversarial competing way. Experiments showed that the LEX-GAN model outperforms other non-GAN models by a large margin on a previously published rumor dataset (PHEME) and in a gene classification task. My questions: 1) The task modeled is essentially a word replacement detection problem. Is this equivalent to rumor detection? Even if it performs really well on a static dataset, it could be very vulnerable to attackers. Various previous works mentioned in the paper, including the PHEME paper by Kochkina et al, used supporting evidence for detection, which sounds like a more robust approach. 2) Authors didn't explain the rationale behind the choice of model structure, e.g. GRU vs LSTM vs Conv. The different structures have been used in mix in the paper. Are those choices irrelevant or critical? 3) I would like to see more discussion on the nature of errors from those models, but it's lacking in the paper. This could be critical to understand the model\u2019s ability and limitation, esp given that it\u2019s not looking at supporting evidences from other sequences. Small errors noticed: The citation for PHEME paper (Kochkina et al) points to a preprint version, while an ACL Anthology published version exists.", "rating": "3: Weak Reject", "reply_text": "We are very thankful to the reviewer for the comments . 1.We use the word replacement to augment the available dataset and use both the generated data and original data to train the model . Therefore , the model is essentially trained to recognize rumor and detect detailed glitches . Compared to other works , LEX-GAN uses GAN and essentially adversarial training techniques are utilized as well , hence it is more robust to attacks . Kochkina \u2019 s work includes rumor detection and stance classification . The support evidence you pointed out is used in stance classification . In stance classification , posts and comments are labeled as support , deny , comment , or query due to their orientation toward rumor \u2019 s veracity . Stance classification and rumor detection are two different components in rumor classification system , which include four steps : rumor detection , tracking , stance classification , and veracity classification . LEX-GAN realizes rumor detection task based on the assumption that the rumor detection is done in the early stage when its veracity is unverified , and the comments are unavailable . 2.We thank the reviewer for this important suggestion . To explain the model choice , we start with human thinking process while reading text . When we read a sentence , we don \u2019 t think from scratch , instead , we understand words based on previous words . This is the fundamental reason why we choose RNN models over ordinary neural network . LSTM and GRU are two commonly used RNN models in text data processing . Gwhere chooses which words in a sentence to be replaced and it has to consider the past words and the whole sentence , hence we choose LSTM to realize this function . The choice of Dexplain follows a similar reasoning . Greplace does the actual word-replacing work , the choice of GRU considers both performance and efficiency . GRU is computationally more efficient than LSTM and provides better results when used in Greplace in this work . CNN is also frequently applied in nantural language processing applications to do classification . Dclassify utilizes a CNN to realize a classification between rumor and non-rumor . In summary , RNN models and CNN models are not mutual exclusive under text data , the choice of a hybrid model structure follows the consideration of both performance and efficiency . One of the strengths of LEX-GAN is that under the delicate layered structure that we designed , the choice of model structure effects the results but not significantly , hence LEX-GAN can by deployed into a broad range of applications while maintaining a high level of performance . We generate a variation of LEX-GAN as a baseline to showcase the ability of our layered structure . LEX-LSTM is generated by replacing LEX-GAN \u2019 s Greplace with a LSTM model . The performance of LEX-LSTM is added in Table 1 . 3.The limitation and error cases were briefly discussed in Appendix . We follow the reviewer \u2019 s suggestion and add a limitation analysis in Section 5.3 . We fixed the reference issue . We appreciate the important and inspiring comments and suggestions from the reviewer . In addition to the response to the reviews and the modification of the manuscript , we would like to further provide a gentle summary of the contributions of our work : 1 . We would like to clarify the difference between explainable rumor detection and explainable fake news detection . Explainable fake news detection has been studied in the literature . However , extension of existing explainable fake news detection works into rumor detection can not be done because a rumor is defined as an unverified information at the time of posting . Hence , a verified news database can not be established for explainable rumor detection . To the best of our knowledge , LEX-GAN is the first explainable rumor detection work with demonstrated high accuracy . 2.We would like to provide a quick review of rumor detection and state the strength of our work . Putting aside the explainability , rumor detection has been studied for decades . However , the accuracy of state-of-the-art methods is not promising , which reflects the difficulty of this problem . As we mentioned in the manuscript , to the best of our knowledge , one of the state-of-the-art works GAN-GRU [ 1 ] reaches the highest accuracy of 78.1 % on a bench-marking rumor dataset PHEME . The average accuracy of other state-of-the-art works on this dataset is around 70 % . Our proposed LEX-GAN outperforms all the baselines and achieves 82.4 % in terms of accuracy . 3.In addition to rumor detection , we also provide a set of gene mutation detection experiments as an extended application of the proposed LEX-GAN , which showcases the text mining and textual mutation detection power of our framework . We believe our proposed framework could be exploited to make contributions to other domains . [ 1 ] Ma , Jing , Wei Gao , and Kam-Fai Wong . `` Detect Rumors on Twitter by Promoting Information Campaigns with Generative Adversarial Learning . '' The World Wide Web Conference . ACM , 2019 ."}, {"review_id": "S1lukyrKPr-1", "review_text": "The paper presents a method for detecting rumours in text. Early on in the paper, the authors claim that this method: 1) is more accurate in rumour detection than prior work, 2) can provide explainability, and 3) does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\". All three of these statements are problematic. The experimental evaluation uses a small dataset of rumour classification (about 15000 tweet related to 14 news topics) and an even smaller dataset of gene classification. The rationale is to use the gene classification task as a proxy for rumour detection. This is not valid. The gene classification task does not contribute to the evaluation of the rumour detection method. The rumour classification dataset is relatively small, but even more importantly, the experimental results on that dataset are not thoroughly analysed, for instance through an ablation test. Explainability is not evaluated experimentally, nor formally proven. The claim that the method does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\" is shaky, because 1) one could train the method on labelled data, and 2) it is not clear how \"non-rumour looking rumours\" are guaranteed in the synthesis phase (how are they defined? how are they evaluated to be \"non-rumour looking rumours\"? etc). Note that there is no definition of what sort of data representation corresponds to a \"rumour\" in the paper. ", "rating": "1: Reject", "reply_text": "We thank the reviewer \u2019 s suggestions . 1.The PHEME dataset we used in rumor detection task is a state-of-the-art rumor dataset , unanimously used in a lot of prior works . Here we select some recent publications that used PHEME dataset : a. Han , Sooji , Jie Gao , and Fabio Ciravegna . `` Data Augmentation for Rumor Detection Using Context-Sensitive Neural Language Model With Large-Scale Credibility Corpus . '' ( ICLR 2019 ) . b. Zhang , Qiang , et al . `` Reply-Aided Detection of Misinformation via Bayesian Deep Learning . '' The World Wide Web Conference . ACM , 2019. c. Nguyen , Duc Minh , et al . `` Fake news detection using deep markov random fields . '' Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) . 2019. d. Bondielli , Alessandro , and Francesco Marcelloni . `` A survey on fake news and rumour detection techniques . '' Information Sciences 497 ( 2019 ) : 38-55. e. Conforti , Costanza , Mohammad Taher Pilehvar , and Nigel Collier . `` Towards Automatic Fake News Detection : Cross-Level Stance Detection in News Articles . '' Proceedings of the First Workshop on Fact Extraction and VERification ( FEVER ) . 2018. f. Li , Jing , et al . `` A joint model of conversational discourse and latent topics on microblogs . '' Computational Linguistics 44.4 ( 2018 ) : 719-754. g. Zubiaga , Arkaitz , et al . `` Analysing how people orient to and spread rumours in social media by looking at conversational threads . '' PloS one 11.3 ( 2016 ) : e0150989 . Rumor detection and gene mutation detection are two independent evaluation case studies and are not used as one proxy for the other . While initially we were not aware of a larger gene dataset , we now added a set of experiments with a larger benchmarking gene dataset . We present the results in Section 5.2 . We follow the reviewer \u2019 s suggestion and added one more set of experiments in rumor detection task that uses leave-one-out rule to test the generalization ability of the model . Our leave-one-out rule works as follows : train the model on some news and test on another news , which essentially provide a realistic testing environment . The experimental results of rumor detection task under leave-one-out rule are shown in Table 1 . 2.The explainability of LEX-GAN is evaluated experimentally in both rumor detection and gene mutation detection tasks by reporting Dexplain \u2019 s performance . In rumor detection task , Dexplain achieves 80.42 % and 81.23 % macro-f1 on PHEME \u2019 v5 and PHEME \u2019 v9 , respectively . In table 2 , Dexplain \u2019 s prediction of suspicious statements in rumors is reported . The explainability of LEX-GAN in rumor detection task is therefore addressed . In gene mutation detection task , Dexplain achieves 89.49 % macro-f1 score . In table 4 , Dexplain \u2019 s prediction of gene mutation is shown and therefore addresses the explainability of LEX-GAN in gene mutation task . Additional results of Dexplain can be found in appendix . 3.We would like to clarify that we didn \u2019 t claim LEX-GAN doesn \u2019 t need labelled data . We use both real data and generated data to train the model . Rumor is complicated and hard to distinguish since there is no uniform data representation that corresponds to a rumor . LEX-GAN is designed learn the complicated high-dimensional rumor representation . Generated data are used to augment the available dataset and therefore enhance the detection ability of LEX-GAN ."}, {"review_id": "S1lukyrKPr-2", "review_text": "In this paper, the authors proposed an interesting model to solve rumor detection problem. The LEX-GAN model takes the advantage of GAN in generating high-quality fake examples by substitute few works in original tweets. It achieved excellent performance on two kinds of dataset. The term \u2018layered\u2019 was a little confusing to me at the very beginning, though it is strengthened in many places around the paper. Maybe the author could use some other word to better summarize the two layers. Another question is about the extended dataset with generated data, are they generated using the same distribution from G of the final model? What the result would it be if we use real, out-of-domain data? I would like to see this paper accepted to motivate future works on fake news detection and rumor detection.. ", "rating": "8: Accept", "reply_text": "We thank the reviewer for these important comments . As for the term \u201c layered \u201d we used it because in many applications , such as protocols and standards , the term layered is used to imply the breakdown of the steps of the work in multiple steps , called layers . E.g. , the TCP/IP layers , etc . We will think and do some more search to see whether a better term could replace \u201c layered \u201d . About the extended dataset , they are generated using the same G in order to ensure the fairness of the comparison between LEX-GAN and all the baselines . We added one more set of experiments that use leave-one-out rule to test the generalization ability of the model . Leave-one-out rule works as follows : train the model on some news and test on another news , which essentially provide a realistic testing environment that contains real , out-of-domain data . The experimental results of rumor detection task under leave-one-out rule are shown in Table 1 . We appreciate the important and inspiring comments and suggestions from the reviewer . In addition to the response to the reviews and the modification of the manuscript , we would like to further provide a gentle summary of the contributions of our work : 1 . We would like to clarify the difference between explainable rumor detection and explainable fake news detection . Explainable fake news detection has been studied in the literature . However , extension of existing explainable fake news detection works into rumor detection can not be done because a rumor is defined as an unverified information at the time of posting . Hence , a verified news database can not be established for explainable rumor detection . To the best of our knowledge , LEX-GAN is the first explainable rumor detection work with demonstrated high accuracy . 2.We would like to provide a quick review of rumor detection and state the strength of our work . Putting aside the explainability , rumor detection has been studied for decades . However , the accuracy of state-of-the-art methods is not promising , which reflects the difficulty of this problem . As we mentioned in the manuscript , to the best of our knowledge , one of the state-of-the-art works GAN-GRU [ 1 ] reaches the highest accuracy of 78.1 % on a bench-marking rumor dataset PHEME . The average accuracy of other state-of-the-art works on this dataset is around 70 % . Our proposed LEX-GAN outperforms all the baselines and achieves 82.4 % in terms of accuracy . 3.In addition to rumor detection , we also provide a set of gene mutation detection experiments as an extended application of the proposed LEX-GAN , which showcases the text mining and textual mutation detection power of our framework . We therefore believe our proposed framework could be exploited to make contributions to other domains . [ 1 ] Ma , Jing , Wei Gao , and Kam-Fai Wong . `` Detect Rumors on Twitter by Promoting Information Campaigns with Generative Adversarial Learning . '' In The World Wide Web Conference , pp . 3049-3055 . ACM , 2019 ."}, {"review_id": "S1lukyrKPr-3", "review_text": "Three strengths: 1. This paper has been well written and easy to follow. Adequate details have been provided to help easily reproduce the experimental results. 2. The technical part is sound - the authors apply GAN for rumor detection and propose to use model-where and model-replace to extend conventional GAN models. 3. Experiments are conducted on real-world data. Weaknesses: 1. Contributions of novelty are limited. The idea of using GAN to detect misinformation such as rumors and fake news has been studied in the literature several times, and the proposed method does not differ from them significantly. The problem of explainable rumor and fake news detection has also been well studied. Therefore, this piece of work is more a marginal extension of existing solutions. 2. The technical solution can be very limited. The generator can only manipulate content by replacing something from a true statement. The hidden assumption that misinformation is mostly generated by replacing some word definitely underestimates the complicated nature of fake news/rumor detection problem. If the assumption holds, the rumor detection problem can be easily done by collecting and comparing against true statements. 3. The limited experimental results cannot resolve my concerns. The rumor dataset is very small for a typical deep learning model. I am also curious about how many rumors in the dataset are generated by replacing words. ", "rating": "1: Reject", "reply_text": "We thank the reviewer for all the insightful comments . 1.We would like to clarify the novel contributions of our work : a . We are not aware of any research on explainable rumor detection . We agree with the reviewer that explainable misinformation and fake news detection has been studied in the literature . However , extension of existing explainable fake news detection works into rumor detection can not be done because a rumor is defined as an unverified information at the time of posting . Hence , a verified news database can not be established for explainable rumor detection . To the best of our knowledge , LEX-GAN is the first explainable rumor detection work with demonstrated high accuracy . b.We further clarify the distinction between explainable fake news work and rumor detection . In explainable fake news or misinformation detection , a larger verified background knowledge set and training dataset are needed to provide explainability . For example , in work [ 1 ] , a verified news set needs to be collected to provide explainability . In work [ 2-3 ] , explainability relies on the comments of the fake news and/or metainformation of users . Without these additional information and verified veracity of sentences , the explainable fake news detection problem becomes a rumor detection problem . However , these explainable fake new detection methods can not be deployed directly because the shortage of these additional data . LEX-GAN , on the contrary , proposes a solution to explainable rumor detection without requesting additional background information and can easily be extended to explainable fake news detection , if these additional data are available . c. Putting aside the explainability , rumor detection has been studied for decades . However , the accuracy of state-of-the-art methods is not promising , which reflects the difficulty of this problem . As we mentioned in the manuscript , to the best of our knowledge , one of the state-of-the-art works GAN-GRU [ 4 ] reaches the highest accuracy of 78.1 % on a bench-marking rumor dataset PHEME . The average accuracy of other state-of-the-art works on this dataset is around 70 % . Our proposed LEX-GAN outperforms all these prior approaches on state-of-the-art benchmarks and achieves 82.4 % in terms of accuracy . d. In addition to rumor detection , we also provide a set of gene mutation detection experiments as an extended application of the proposed LEX-GAN , which showcases the text mining and textual mutation detection power of our framework . We believe our proposed framework could be exploited and make contributions to other domains . 2.Content manipulation is a way of augmenting the available data , hence improves the detection ability of LEX-GAN . We did not assume that rumor is mostly generated by replacing some words in a sentence . We acknowledge the complicated nature of the rumor and LEX-GAN captures it by training on both original complicated rumors and generated rumors . Here we provide two examples to demonstrate the rumor detection power of LEX-GAN compared to baselines . a.A rumor example that are correctly detected by LEX-GAN but incorrectly detected by other baselines . e.g. \u201c who 's your pick for worst contribution to sydneysiege mamamia uber or the daily tele \u201d LEX-GAN predicted suspicious words ( in parenthesis ) : \u201c ( who \u2019 s ) your pick for worst ( contribution ) to sydneysiege ( mamamia uber ) or the daily tele \u201d LEX-GAN score : 0.1579 Baseline CNN score : 0.9802 Baseline LSTM score : 0.9863 Baseline VAE-CNN score : 0.4917 Baseline VAE-LSTM score : 0.5138 Score 0 and 1 represent the model predicts the sentence as rumor and non-rumor , respectively . b.A non-rumor example that are correctly detected by LEX-GAN but incorrectly detected by other baselines , as a rumor , i.e. , with low scores . e.g. \u201c glad to hear the sydneysiege is over but saddened that it even happened to begin with my heart goes out to all those affected \ud83d\udc9c \u201d LEX-GAN score : 0.8558 Baseline CNN score : 0.0029 Baseline LSTM score : 0.1316 Baseline VAE-CNN score : 0.6150 Baseline VAE-LSTM score : 0.4768 As we can see in example a , LEX-GAN provides a very low score for a rumor , while other baselines all generated relatively high scores , and even detect it as non-rumor . This is a very difficult example since from the sentence itself , we as human rumor detection agents even can not pick the suspicious parts confidently . However , LEX-GAN gives a reasonable prediction and shows that it has the ability to understand and analyze complicated rumors . In example b , a non-rumor sentence gains a high score from LEX-GAN , but several relatively low scores from the baselines . This example again confirms that our proposed LEX-GAN indeed captures the complicated nature of rumors and non-rumors ."}], "0": {"review_id": "S1lukyrKPr-0", "review_text": "In the paper, authors proposed a generative adversarial network-based rumor detection model that can label short text like Twitter posts as rumor or not. The model can further highlight the words that are responsible for the rumor accusation. Proposed model consists of 4 sub models: a G_Where model finds the word to replace so to create an artificial rumor; a G_replace model decides what the replacement word should be; a D_classify model detects if a sequence is a rumor; a final D_explain model pinpoints the word of concern. D_ models and G_ models are trained in an adversarial competing way. Experiments showed that the LEX-GAN model outperforms other non-GAN models by a large margin on a previously published rumor dataset (PHEME) and in a gene classification task. My questions: 1) The task modeled is essentially a word replacement detection problem. Is this equivalent to rumor detection? Even if it performs really well on a static dataset, it could be very vulnerable to attackers. Various previous works mentioned in the paper, including the PHEME paper by Kochkina et al, used supporting evidence for detection, which sounds like a more robust approach. 2) Authors didn't explain the rationale behind the choice of model structure, e.g. GRU vs LSTM vs Conv. The different structures have been used in mix in the paper. Are those choices irrelevant or critical? 3) I would like to see more discussion on the nature of errors from those models, but it's lacking in the paper. This could be critical to understand the model\u2019s ability and limitation, esp given that it\u2019s not looking at supporting evidences from other sequences. Small errors noticed: The citation for PHEME paper (Kochkina et al) points to a preprint version, while an ACL Anthology published version exists.", "rating": "3: Weak Reject", "reply_text": "We are very thankful to the reviewer for the comments . 1.We use the word replacement to augment the available dataset and use both the generated data and original data to train the model . Therefore , the model is essentially trained to recognize rumor and detect detailed glitches . Compared to other works , LEX-GAN uses GAN and essentially adversarial training techniques are utilized as well , hence it is more robust to attacks . Kochkina \u2019 s work includes rumor detection and stance classification . The support evidence you pointed out is used in stance classification . In stance classification , posts and comments are labeled as support , deny , comment , or query due to their orientation toward rumor \u2019 s veracity . Stance classification and rumor detection are two different components in rumor classification system , which include four steps : rumor detection , tracking , stance classification , and veracity classification . LEX-GAN realizes rumor detection task based on the assumption that the rumor detection is done in the early stage when its veracity is unverified , and the comments are unavailable . 2.We thank the reviewer for this important suggestion . To explain the model choice , we start with human thinking process while reading text . When we read a sentence , we don \u2019 t think from scratch , instead , we understand words based on previous words . This is the fundamental reason why we choose RNN models over ordinary neural network . LSTM and GRU are two commonly used RNN models in text data processing . Gwhere chooses which words in a sentence to be replaced and it has to consider the past words and the whole sentence , hence we choose LSTM to realize this function . The choice of Dexplain follows a similar reasoning . Greplace does the actual word-replacing work , the choice of GRU considers both performance and efficiency . GRU is computationally more efficient than LSTM and provides better results when used in Greplace in this work . CNN is also frequently applied in nantural language processing applications to do classification . Dclassify utilizes a CNN to realize a classification between rumor and non-rumor . In summary , RNN models and CNN models are not mutual exclusive under text data , the choice of a hybrid model structure follows the consideration of both performance and efficiency . One of the strengths of LEX-GAN is that under the delicate layered structure that we designed , the choice of model structure effects the results but not significantly , hence LEX-GAN can by deployed into a broad range of applications while maintaining a high level of performance . We generate a variation of LEX-GAN as a baseline to showcase the ability of our layered structure . LEX-LSTM is generated by replacing LEX-GAN \u2019 s Greplace with a LSTM model . The performance of LEX-LSTM is added in Table 1 . 3.The limitation and error cases were briefly discussed in Appendix . We follow the reviewer \u2019 s suggestion and add a limitation analysis in Section 5.3 . We fixed the reference issue . We appreciate the important and inspiring comments and suggestions from the reviewer . In addition to the response to the reviews and the modification of the manuscript , we would like to further provide a gentle summary of the contributions of our work : 1 . We would like to clarify the difference between explainable rumor detection and explainable fake news detection . Explainable fake news detection has been studied in the literature . However , extension of existing explainable fake news detection works into rumor detection can not be done because a rumor is defined as an unverified information at the time of posting . Hence , a verified news database can not be established for explainable rumor detection . To the best of our knowledge , LEX-GAN is the first explainable rumor detection work with demonstrated high accuracy . 2.We would like to provide a quick review of rumor detection and state the strength of our work . Putting aside the explainability , rumor detection has been studied for decades . However , the accuracy of state-of-the-art methods is not promising , which reflects the difficulty of this problem . As we mentioned in the manuscript , to the best of our knowledge , one of the state-of-the-art works GAN-GRU [ 1 ] reaches the highest accuracy of 78.1 % on a bench-marking rumor dataset PHEME . The average accuracy of other state-of-the-art works on this dataset is around 70 % . Our proposed LEX-GAN outperforms all the baselines and achieves 82.4 % in terms of accuracy . 3.In addition to rumor detection , we also provide a set of gene mutation detection experiments as an extended application of the proposed LEX-GAN , which showcases the text mining and textual mutation detection power of our framework . We believe our proposed framework could be exploited to make contributions to other domains . [ 1 ] Ma , Jing , Wei Gao , and Kam-Fai Wong . `` Detect Rumors on Twitter by Promoting Information Campaigns with Generative Adversarial Learning . '' The World Wide Web Conference . ACM , 2019 ."}, "1": {"review_id": "S1lukyrKPr-1", "review_text": "The paper presents a method for detecting rumours in text. Early on in the paper, the authors claim that this method: 1) is more accurate in rumour detection than prior work, 2) can provide explainability, and 3) does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\". All three of these statements are problematic. The experimental evaluation uses a small dataset of rumour classification (about 15000 tweet related to 14 news topics) and an even smaller dataset of gene classification. The rationale is to use the gene classification task as a proxy for rumour detection. This is not valid. The gene classification task does not contribute to the evaluation of the rumour detection method. The rumour classification dataset is relatively small, but even more importantly, the experimental results on that dataset are not thoroughly analysed, for instance through an ablation test. Explainability is not evaluated experimentally, nor formally proven. The claim that the method does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\" is shaky, because 1) one could train the method on labelled data, and 2) it is not clear how \"non-rumour looking rumours\" are guaranteed in the synthesis phase (how are they defined? how are they evaluated to be \"non-rumour looking rumours\"? etc). Note that there is no definition of what sort of data representation corresponds to a \"rumour\" in the paper. ", "rating": "1: Reject", "reply_text": "We thank the reviewer \u2019 s suggestions . 1.The PHEME dataset we used in rumor detection task is a state-of-the-art rumor dataset , unanimously used in a lot of prior works . Here we select some recent publications that used PHEME dataset : a. Han , Sooji , Jie Gao , and Fabio Ciravegna . `` Data Augmentation for Rumor Detection Using Context-Sensitive Neural Language Model With Large-Scale Credibility Corpus . '' ( ICLR 2019 ) . b. Zhang , Qiang , et al . `` Reply-Aided Detection of Misinformation via Bayesian Deep Learning . '' The World Wide Web Conference . ACM , 2019. c. Nguyen , Duc Minh , et al . `` Fake news detection using deep markov random fields . '' Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long and Short Papers ) . 2019. d. Bondielli , Alessandro , and Francesco Marcelloni . `` A survey on fake news and rumour detection techniques . '' Information Sciences 497 ( 2019 ) : 38-55. e. Conforti , Costanza , Mohammad Taher Pilehvar , and Nigel Collier . `` Towards Automatic Fake News Detection : Cross-Level Stance Detection in News Articles . '' Proceedings of the First Workshop on Fact Extraction and VERification ( FEVER ) . 2018. f. Li , Jing , et al . `` A joint model of conversational discourse and latent topics on microblogs . '' Computational Linguistics 44.4 ( 2018 ) : 719-754. g. Zubiaga , Arkaitz , et al . `` Analysing how people orient to and spread rumours in social media by looking at conversational threads . '' PloS one 11.3 ( 2016 ) : e0150989 . Rumor detection and gene mutation detection are two independent evaluation case studies and are not used as one proxy for the other . While initially we were not aware of a larger gene dataset , we now added a set of experiments with a larger benchmarking gene dataset . We present the results in Section 5.2 . We follow the reviewer \u2019 s suggestion and added one more set of experiments in rumor detection task that uses leave-one-out rule to test the generalization ability of the model . Our leave-one-out rule works as follows : train the model on some news and test on another news , which essentially provide a realistic testing environment . The experimental results of rumor detection task under leave-one-out rule are shown in Table 1 . 2.The explainability of LEX-GAN is evaluated experimentally in both rumor detection and gene mutation detection tasks by reporting Dexplain \u2019 s performance . In rumor detection task , Dexplain achieves 80.42 % and 81.23 % macro-f1 on PHEME \u2019 v5 and PHEME \u2019 v9 , respectively . In table 2 , Dexplain \u2019 s prediction of suspicious statements in rumors is reported . The explainability of LEX-GAN in rumor detection task is therefore addressed . In gene mutation detection task , Dexplain achieves 89.49 % macro-f1 score . In table 4 , Dexplain \u2019 s prediction of gene mutation is shown and therefore addresses the explainability of LEX-GAN in gene mutation task . Additional results of Dexplain can be found in appendix . 3.We would like to clarify that we didn \u2019 t claim LEX-GAN doesn \u2019 t need labelled data . We use both real data and generated data to train the model . Rumor is complicated and hard to distinguish since there is no uniform data representation that corresponds to a rumor . LEX-GAN is designed learn the complicated high-dimensional rumor representation . Generated data are used to augment the available dataset and therefore enhance the detection ability of LEX-GAN ."}, "2": {"review_id": "S1lukyrKPr-2", "review_text": "In this paper, the authors proposed an interesting model to solve rumor detection problem. The LEX-GAN model takes the advantage of GAN in generating high-quality fake examples by substitute few works in original tweets. It achieved excellent performance on two kinds of dataset. The term \u2018layered\u2019 was a little confusing to me at the very beginning, though it is strengthened in many places around the paper. Maybe the author could use some other word to better summarize the two layers. Another question is about the extended dataset with generated data, are they generated using the same distribution from G of the final model? What the result would it be if we use real, out-of-domain data? I would like to see this paper accepted to motivate future works on fake news detection and rumor detection.. ", "rating": "8: Accept", "reply_text": "We thank the reviewer for these important comments . As for the term \u201c layered \u201d we used it because in many applications , such as protocols and standards , the term layered is used to imply the breakdown of the steps of the work in multiple steps , called layers . E.g. , the TCP/IP layers , etc . We will think and do some more search to see whether a better term could replace \u201c layered \u201d . About the extended dataset , they are generated using the same G in order to ensure the fairness of the comparison between LEX-GAN and all the baselines . We added one more set of experiments that use leave-one-out rule to test the generalization ability of the model . Leave-one-out rule works as follows : train the model on some news and test on another news , which essentially provide a realistic testing environment that contains real , out-of-domain data . The experimental results of rumor detection task under leave-one-out rule are shown in Table 1 . We appreciate the important and inspiring comments and suggestions from the reviewer . In addition to the response to the reviews and the modification of the manuscript , we would like to further provide a gentle summary of the contributions of our work : 1 . We would like to clarify the difference between explainable rumor detection and explainable fake news detection . Explainable fake news detection has been studied in the literature . However , extension of existing explainable fake news detection works into rumor detection can not be done because a rumor is defined as an unverified information at the time of posting . Hence , a verified news database can not be established for explainable rumor detection . To the best of our knowledge , LEX-GAN is the first explainable rumor detection work with demonstrated high accuracy . 2.We would like to provide a quick review of rumor detection and state the strength of our work . Putting aside the explainability , rumor detection has been studied for decades . However , the accuracy of state-of-the-art methods is not promising , which reflects the difficulty of this problem . As we mentioned in the manuscript , to the best of our knowledge , one of the state-of-the-art works GAN-GRU [ 1 ] reaches the highest accuracy of 78.1 % on a bench-marking rumor dataset PHEME . The average accuracy of other state-of-the-art works on this dataset is around 70 % . Our proposed LEX-GAN outperforms all the baselines and achieves 82.4 % in terms of accuracy . 3.In addition to rumor detection , we also provide a set of gene mutation detection experiments as an extended application of the proposed LEX-GAN , which showcases the text mining and textual mutation detection power of our framework . We therefore believe our proposed framework could be exploited to make contributions to other domains . [ 1 ] Ma , Jing , Wei Gao , and Kam-Fai Wong . `` Detect Rumors on Twitter by Promoting Information Campaigns with Generative Adversarial Learning . '' In The World Wide Web Conference , pp . 3049-3055 . ACM , 2019 ."}, "3": {"review_id": "S1lukyrKPr-3", "review_text": "Three strengths: 1. This paper has been well written and easy to follow. Adequate details have been provided to help easily reproduce the experimental results. 2. The technical part is sound - the authors apply GAN for rumor detection and propose to use model-where and model-replace to extend conventional GAN models. 3. Experiments are conducted on real-world data. Weaknesses: 1. Contributions of novelty are limited. The idea of using GAN to detect misinformation such as rumors and fake news has been studied in the literature several times, and the proposed method does not differ from them significantly. The problem of explainable rumor and fake news detection has also been well studied. Therefore, this piece of work is more a marginal extension of existing solutions. 2. The technical solution can be very limited. The generator can only manipulate content by replacing something from a true statement. The hidden assumption that misinformation is mostly generated by replacing some word definitely underestimates the complicated nature of fake news/rumor detection problem. If the assumption holds, the rumor detection problem can be easily done by collecting and comparing against true statements. 3. The limited experimental results cannot resolve my concerns. The rumor dataset is very small for a typical deep learning model. I am also curious about how many rumors in the dataset are generated by replacing words. ", "rating": "1: Reject", "reply_text": "We thank the reviewer for all the insightful comments . 1.We would like to clarify the novel contributions of our work : a . We are not aware of any research on explainable rumor detection . We agree with the reviewer that explainable misinformation and fake news detection has been studied in the literature . However , extension of existing explainable fake news detection works into rumor detection can not be done because a rumor is defined as an unverified information at the time of posting . Hence , a verified news database can not be established for explainable rumor detection . To the best of our knowledge , LEX-GAN is the first explainable rumor detection work with demonstrated high accuracy . b.We further clarify the distinction between explainable fake news work and rumor detection . In explainable fake news or misinformation detection , a larger verified background knowledge set and training dataset are needed to provide explainability . For example , in work [ 1 ] , a verified news set needs to be collected to provide explainability . In work [ 2-3 ] , explainability relies on the comments of the fake news and/or metainformation of users . Without these additional information and verified veracity of sentences , the explainable fake news detection problem becomes a rumor detection problem . However , these explainable fake new detection methods can not be deployed directly because the shortage of these additional data . LEX-GAN , on the contrary , proposes a solution to explainable rumor detection without requesting additional background information and can easily be extended to explainable fake news detection , if these additional data are available . c. Putting aside the explainability , rumor detection has been studied for decades . However , the accuracy of state-of-the-art methods is not promising , which reflects the difficulty of this problem . As we mentioned in the manuscript , to the best of our knowledge , one of the state-of-the-art works GAN-GRU [ 4 ] reaches the highest accuracy of 78.1 % on a bench-marking rumor dataset PHEME . The average accuracy of other state-of-the-art works on this dataset is around 70 % . Our proposed LEX-GAN outperforms all these prior approaches on state-of-the-art benchmarks and achieves 82.4 % in terms of accuracy . d. In addition to rumor detection , we also provide a set of gene mutation detection experiments as an extended application of the proposed LEX-GAN , which showcases the text mining and textual mutation detection power of our framework . We believe our proposed framework could be exploited and make contributions to other domains . 2.Content manipulation is a way of augmenting the available data , hence improves the detection ability of LEX-GAN . We did not assume that rumor is mostly generated by replacing some words in a sentence . We acknowledge the complicated nature of the rumor and LEX-GAN captures it by training on both original complicated rumors and generated rumors . Here we provide two examples to demonstrate the rumor detection power of LEX-GAN compared to baselines . a.A rumor example that are correctly detected by LEX-GAN but incorrectly detected by other baselines . e.g. \u201c who 's your pick for worst contribution to sydneysiege mamamia uber or the daily tele \u201d LEX-GAN predicted suspicious words ( in parenthesis ) : \u201c ( who \u2019 s ) your pick for worst ( contribution ) to sydneysiege ( mamamia uber ) or the daily tele \u201d LEX-GAN score : 0.1579 Baseline CNN score : 0.9802 Baseline LSTM score : 0.9863 Baseline VAE-CNN score : 0.4917 Baseline VAE-LSTM score : 0.5138 Score 0 and 1 represent the model predicts the sentence as rumor and non-rumor , respectively . b.A non-rumor example that are correctly detected by LEX-GAN but incorrectly detected by other baselines , as a rumor , i.e. , with low scores . e.g. \u201c glad to hear the sydneysiege is over but saddened that it even happened to begin with my heart goes out to all those affected \ud83d\udc9c \u201d LEX-GAN score : 0.8558 Baseline CNN score : 0.0029 Baseline LSTM score : 0.1316 Baseline VAE-CNN score : 0.6150 Baseline VAE-LSTM score : 0.4768 As we can see in example a , LEX-GAN provides a very low score for a rumor , while other baselines all generated relatively high scores , and even detect it as non-rumor . This is a very difficult example since from the sentence itself , we as human rumor detection agents even can not pick the suspicious parts confidently . However , LEX-GAN gives a reasonable prediction and shows that it has the ability to understand and analyze complicated rumors . In example b , a non-rumor sentence gains a high score from LEX-GAN , but several relatively low scores from the baselines . This example again confirms that our proposed LEX-GAN indeed captures the complicated nature of rumors and non-rumors ."}}