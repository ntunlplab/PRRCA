{"year": "2017", "forum": "r1Usiwcex", "title": "Counterpoint by Convolution", "decision": "Reject", "meta_review": "This paper applies an existing idea (Yao's block Gibbs sampling of NADE) to a music model. There is also prior art for applying NADE to music. The main novel and interesting result is that block Gibbs sampling (an approximation) actually improves performance, highlighting problems with NADE.\n \n This work is borderline for inclusion. The paper is mainly an application of existing ideas. The implications of the interesting results could perhaps have been explored further for a paper at a meeting on learning representations.", "reviews": [{"review_id": "r1Usiwcex-0", "review_text": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral sampling of the original NADE model to generate better pieces of music. The experimental results showed that the NLL of COCONET is better than the other baselines and the human evaluation task by Amazon\u2019s Mechanical Turk illustrated that the model can generate compelling music. In general, I think the paper is good. Using NADE based model with convolution operations on music generation tasks and using blocked Gibbs sampling contains some kind of novelty. However, the novelty of the paper is incremental, since the blocked Gibbs sampling for NADE model is already proposed by Yao et al., (2014) and the using NADE based model for music modeling has also been proposed by Boulanger-Lewandowski et al., (2012). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review ! To clarify a few points : There are two ways in which NADEs ( Larochelle & Murray , 2011 ) are used in Boulanger-Lewandowski et al . ( 2012 ) , both of which are different from our approach . As a baseline , NADE was used to model distribution of chords/simultaneities , without considering temporal dynamics . Then , as an alternative to RNN-RBMs , NADE was used to model the output distribution of RNNs , giving rise to RNN-NADEs . Temporally , RNN-NADE factorizes sequences chronologically , and hence can only generate left to right . As only one ordering is modeled , Gibbs sampling can not be used to improve sample quality . In contrast , we adopt an orderless NADE ( Uria et al. , 2014 ) which is trained to learn all possible orders of factorization , making it possible to use Gibbs sampling to improve sample quality . Furthermore , this approach frees music models from generating left to right , and can support tasks such as partial score completion that requires the versatility of conditioning on arbitrary context and to generate in any order . Yao et al ( 2014 ) only expected independent blocked Gibbs to perform as well as ancestral sampling at best in terms of sample quality . Their work focused on MNIST . For the more intricate domain of music , we report the surprising observation that independent blocked Gibbs actually beats ancestral sampling . We investigate why this might be the case . Our finding softens the main drawback of autoregressive models , which is that sampling from them is slow . We believe our contribution is especially relevant given the recent popularity of autoregressive models ( such as PixelCNN and WaveNet ( van den Oord et al. , 2016 ) etc . ) ."}, {"review_id": "r1Usiwcex-1", "review_text": "The paper tackles the task of music generation. They use an orderless NADE model for the task of \"fill in the notes\". Given a roll of T timesteps of pitches, they randomly mask out some pitches, and the model is trained to predict the missing notes. This follows how the orderless NADE model can be trained. During sampling, one normally follows an ancestral sampling procedure. For this, an ordering is defined over outputs, and one runs the model on the current input, samples one of the outputs according to the order, adds this output to the next input, and continues this procedure until all outputs have been sampled. The key point of the paper is that this is a bad sampling strategy. Instead, they suggest the strategy of Yao et al. 2014, which uses a blocked Gibbs sampling approach. The blocked Gibbs strategy instead masks N inputs randomly and independently, samples them, and repeats this procedure. The point of this strategy is the make sure the sampling chain mixes well, which will happen for large N. However, since the samples are independent, having a large N gives incoherent samples. Thus, the authors follow an annealed schedule for N, making it smaller over time, which will eventually reduce to ancestral sampling (giving global structure to the sample). They conduct a variety of experiments involving both normal metrics and human evaluations, and find that this blocked Gibbs sampling outperforms other sampling procedures. This is a well written paper - great job. My main problem with the paper is that having read Uria and Yao, I don't know how much I have learned from this work in the context of this being an ICLR submission. If this was submitted to some computational music / art conference, this paper would be a clear accept. However, for ICLR, I don't see enough novelty compared with previous works this builds upon. Orderless NADE is an established model. The blocked Gibbs sampling and annealing scheme are basically the exact same one used in Yao. Thus, the main novelty of this paper is its application to the music domain, and finding that Yao's method works better for sampling music. This is a good contribution, but more tailored to those working in the music domain. If the authors found that these results also hold for other domains like images (e.g. on CIFAR / tiny Imagenet) and text (e.g. document generation), then I would change my mind and accept this paper for ICLR. Even just trying musical domains other than Bach chorales would be useful. However, as it stands, the experiments are not convincing enough.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review . We respond to your question above ."}, {"review_id": "r1Usiwcex-2", "review_text": "The paper presents a way to model the distribution of four-part Bach chorales using Convolutional Neural Networks. Furthermore it addresses the task of artificial music generation by sampling from the model using blocked Gibbs sampling and shows The CNN model for the distribution seems very appropriate for the data at hand. Also the analysis of the proposed sampling schemes with the analogy between Gibbs sampling and human music composition are very interesting. I am not too sure about the evaluation though. Since the reported likelihoods are not directly comparable to previous work, I have difficulties judging the quality of the quantitative results. For the human evaluation I would like to see the data for the direct comparisons between the models. E.g. How did NADE vs. Bach perform. Also I find the question: \u2018what piece of music do you prefer\u2019 a stronger test than the question \u2018what piece is more musical to you\u2019 because I don\u2019t really know what \u2018musical\u2019 means to the AMT workers. Finally, while I think the Bach Chorales are interesting musical pieces that deserve to be subject of the analysis but I find it hard to judge how well this modelling approach will transfer to other types of music which might have a very different data distribution. Nevertheless, in conclusion, I believe this is an exciting model for an interesting task that produces non-trivial musical data. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "In previous rounds of human evaluation , we did use your proposed question : `` which piece do you prefer ? `` . However , users ' stated reasons revealed that they based their ratings on ( to us ) irrelevant properties such as mood and synthesis details . The question `` which piece is more musical ? '' reduced but did not eliminate this effect . We have added more details on the human evaluation , including direct comparisons , in an appendix . We are responding to your other questions in the response at the top of this page ."}], "0": {"review_id": "r1Usiwcex-0", "review_text": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral sampling of the original NADE model to generate better pieces of music. The experimental results showed that the NLL of COCONET is better than the other baselines and the human evaluation task by Amazon\u2019s Mechanical Turk illustrated that the model can generate compelling music. In general, I think the paper is good. Using NADE based model with convolution operations on music generation tasks and using blocked Gibbs sampling contains some kind of novelty. However, the novelty of the paper is incremental, since the blocked Gibbs sampling for NADE model is already proposed by Yao et al., (2014) and the using NADE based model for music modeling has also been proposed by Boulanger-Lewandowski et al., (2012). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review ! To clarify a few points : There are two ways in which NADEs ( Larochelle & Murray , 2011 ) are used in Boulanger-Lewandowski et al . ( 2012 ) , both of which are different from our approach . As a baseline , NADE was used to model distribution of chords/simultaneities , without considering temporal dynamics . Then , as an alternative to RNN-RBMs , NADE was used to model the output distribution of RNNs , giving rise to RNN-NADEs . Temporally , RNN-NADE factorizes sequences chronologically , and hence can only generate left to right . As only one ordering is modeled , Gibbs sampling can not be used to improve sample quality . In contrast , we adopt an orderless NADE ( Uria et al. , 2014 ) which is trained to learn all possible orders of factorization , making it possible to use Gibbs sampling to improve sample quality . Furthermore , this approach frees music models from generating left to right , and can support tasks such as partial score completion that requires the versatility of conditioning on arbitrary context and to generate in any order . Yao et al ( 2014 ) only expected independent blocked Gibbs to perform as well as ancestral sampling at best in terms of sample quality . Their work focused on MNIST . For the more intricate domain of music , we report the surprising observation that independent blocked Gibbs actually beats ancestral sampling . We investigate why this might be the case . Our finding softens the main drawback of autoregressive models , which is that sampling from them is slow . We believe our contribution is especially relevant given the recent popularity of autoregressive models ( such as PixelCNN and WaveNet ( van den Oord et al. , 2016 ) etc . ) ."}, "1": {"review_id": "r1Usiwcex-1", "review_text": "The paper tackles the task of music generation. They use an orderless NADE model for the task of \"fill in the notes\". Given a roll of T timesteps of pitches, they randomly mask out some pitches, and the model is trained to predict the missing notes. This follows how the orderless NADE model can be trained. During sampling, one normally follows an ancestral sampling procedure. For this, an ordering is defined over outputs, and one runs the model on the current input, samples one of the outputs according to the order, adds this output to the next input, and continues this procedure until all outputs have been sampled. The key point of the paper is that this is a bad sampling strategy. Instead, they suggest the strategy of Yao et al. 2014, which uses a blocked Gibbs sampling approach. The blocked Gibbs strategy instead masks N inputs randomly and independently, samples them, and repeats this procedure. The point of this strategy is the make sure the sampling chain mixes well, which will happen for large N. However, since the samples are independent, having a large N gives incoherent samples. Thus, the authors follow an annealed schedule for N, making it smaller over time, which will eventually reduce to ancestral sampling (giving global structure to the sample). They conduct a variety of experiments involving both normal metrics and human evaluations, and find that this blocked Gibbs sampling outperforms other sampling procedures. This is a well written paper - great job. My main problem with the paper is that having read Uria and Yao, I don't know how much I have learned from this work in the context of this being an ICLR submission. If this was submitted to some computational music / art conference, this paper would be a clear accept. However, for ICLR, I don't see enough novelty compared with previous works this builds upon. Orderless NADE is an established model. The blocked Gibbs sampling and annealing scheme are basically the exact same one used in Yao. Thus, the main novelty of this paper is its application to the music domain, and finding that Yao's method works better for sampling music. This is a good contribution, but more tailored to those working in the music domain. If the authors found that these results also hold for other domains like images (e.g. on CIFAR / tiny Imagenet) and text (e.g. document generation), then I would change my mind and accept this paper for ICLR. Even just trying musical domains other than Bach chorales would be useful. However, as it stands, the experiments are not convincing enough.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review . We respond to your question above ."}, "2": {"review_id": "r1Usiwcex-2", "review_text": "The paper presents a way to model the distribution of four-part Bach chorales using Convolutional Neural Networks. Furthermore it addresses the task of artificial music generation by sampling from the model using blocked Gibbs sampling and shows The CNN model for the distribution seems very appropriate for the data at hand. Also the analysis of the proposed sampling schemes with the analogy between Gibbs sampling and human music composition are very interesting. I am not too sure about the evaluation though. Since the reported likelihoods are not directly comparable to previous work, I have difficulties judging the quality of the quantitative results. For the human evaluation I would like to see the data for the direct comparisons between the models. E.g. How did NADE vs. Bach perform. Also I find the question: \u2018what piece of music do you prefer\u2019 a stronger test than the question \u2018what piece is more musical to you\u2019 because I don\u2019t really know what \u2018musical\u2019 means to the AMT workers. Finally, while I think the Bach Chorales are interesting musical pieces that deserve to be subject of the analysis but I find it hard to judge how well this modelling approach will transfer to other types of music which might have a very different data distribution. Nevertheless, in conclusion, I believe this is an exciting model for an interesting task that produces non-trivial musical data. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "In previous rounds of human evaluation , we did use your proposed question : `` which piece do you prefer ? `` . However , users ' stated reasons revealed that they based their ratings on ( to us ) irrelevant properties such as mood and synthesis details . The question `` which piece is more musical ? '' reduced but did not eliminate this effect . We have added more details on the human evaluation , including direct comparisons , in an appendix . We are responding to your other questions in the response at the top of this page ."}}