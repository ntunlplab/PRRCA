{"year": "2019", "forum": "SJz6MnC5YQ", "title": "DEEP GRAPH TRANSLATION", "decision": "Reject", "meta_review": "Although one reviewer recommended accepting this paper, they were not willing to champion it during the discussion phase and did not seem to truly believe it is currently ready for publication. Thus I am recommending rejecting this submission.", "reviews": [{"review_id": "SJz6MnC5YQ-0", "review_text": "The paper presents a novel idea of generating discrete data such as graphs that is conditional on input data to control the graph structure that is being generated. Given an input graph, the proposed method infers a target graph by learning their underlying translation mapping by using new graph convolution and deconvolution layers to learn the global and local translation mapping. The idea of learning generic shared common and latent implicit patterns across different graph structure is brilliant. Their method learns a distribution over graphs conditioned on the input graph whilst allowing the network to learn latent and implicit properties. The authors claim that their method is applicable for large graphs. However, it seems the experiments do not seem to support this. It is not clear how the noise is introduced in the graphs. I would have expected to see some analysis and results on the translation quality over systematic noise applied to the input graph. It is also not clear what are the assumptions made on the connectivity of the input graph and the target graph. Do we know how does the connectedness of the input graph affect the translation quality in the case of strongly connected directed graphs? Or what happens if the target graph has a strong connectivity? Towards this, how does the computational complexity scale wrt to the connectedness? A lot of clarity is required on the choice of evaluation metric; for example choice of distance measure ? What is the L1 norm applied on? I did not completely follow the arguments towards directed graph deconvolution operators. There is lack of clarity and the explanation seems lacking in parts in this particular section; especially since this is the key contribution of this work Typo:. The \u201cInf\u201d in Tabel 1 ", "rating": "5: Marginally below acceptance threshold", "reply_text": "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Q\uff1aA lot of clarity is required on the choice of evaluation metric ; for example , choice of distance measure ? What is the L1 norm applied on ? A : Answer about Evaluation metrics : ( 1 ) We want to evaluate if the generated graphs are scale-free graphs in the direct evaluation for dataset scale-free graphs . If the degree distribution of generated graphs is the same to the degree distribution of real target graphs , the generated graphs are good . ( 2 ) There are many classical evaluation metrics focusing on measuring the similarities or distance of two distributions . The four metrics in this paper are among the most authoritative and commonly used ones in existing works , e.g. , [ 2 ] [ 3 ] [ 4 ] [ 5 ] . Answer about L1 norm : ( 1 ) L1 norm is applied to the weight adjacent matrix of the graph . Our methodology is achieved by a trade-off between L1 loss and adversarial loss ( GAN-D ) . Specifically , L1 makes generated graphs share the same rough outline of sparsity pattern like generated graphs , while under this outline , adversarial loss allows them to vary to some degree . ( 2 ) L1 norm is commonly used in GAN in relevant domains , e.g. , in image-translation domain , for example , reference [ 1 ] ( with 600+ citations ) and reference [ 6 ] ( with 1300+ citations ) . They have done extensive experiments to show the advantage of such a strategy . ( 3 ) The experiment demonstrates its effectiveness . Specifically , the proposed GT-GAN that uses L1 norm outperformed all the other comparison methods shown in Table 2,3 and 4 . -- -- -- - [ 2 ] Schieber , T. A. , Carpi , L. , D\u00edaz-Guilera , A. , Pardalos , P. M. , Masoller , C. , & Ravetti , M. G. ( 2017 ) . Quantification of network structural dissimilarities . Nature Communications , 8 , 13928 . -- -- -- - [ 3 ] Bauckhage , C. , Kersting , K. , & Hadiji , F. ( 2015 , July ) . Parameterizing the Distance Distribution of Undirected Networks . In UAI ( pp.121-130 ) . -- -- -- - [ 4 ] Chiang , S. , Cassese , A. , Guindani , M. , Vannucci , M. , Yeh , H. J. , Haneef , Z. , & Stern , J. M. ( 2016 ) . Time-dependence of graph theory metrics in functional connectivity analysis . NeuroImage , 125 , 601-615 . -- -- -- - [ 5 ] You , J. , Ying , R. , Ren , X. , Hamilton , W. L. , & Leskovec , J . ( 2018 ) .GraphRNN : A Deep Generative Model for Graphs . arXiv preprint arXiv:1802.08773 . -- -- -- - [ 6 ] Isola , P. , Zhu , J. Y. , Zhou , T. , & Efros , A . A . ( 2017 ) .Image-to-image translation with conditional adversarial networks . arXiv preprint . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Q\uff1aI did not completely follow the arguments towards directed graph deconvolution operators . There is lack of clarity and the explanation seems lacking in parts in this particular section ; especially since this is the key contribution of this work . A : ( 1 ) Our decoder is symmetric to the encoder in their architectures . The encoder does n-hop edge information aggregation from the input graphs and learns the latent representation of nodes . Then , we first decode the node embedding to get the n-hop aggregated information on edges by node-to-edge layer and then we further decode the n-hop aggregated information layer by layer by n-layers back to get the output adjacency matrix . ( 2 ) Different from image deconvolution , for each hidden channel , we have two filters vertical to each other , i.e. , one is a column vector while the other is a row vector . To get the nth hop information of edge < i , j > , row filter decodes all the ( n+1 ) -th hop information of outgoing edges of node i and column filter decodes all the ( n+1 ) -th hop information of incoming edges of node j . ( 3 ) To make our description clearer , we have updated our paper in Section 3.2.2 , e.g , by adding \u201c To get the nth hop information Aij , row filter decodes all the ( n+1 ) -th hop information of outgoing edges of Vi and column filter decodes all the ( n+1 ) -th hop information of incoming edges of Vj. \u201d -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Q : Typo : . The \u201c Inf \u201d in Tabel 1 A : As explained in Section 4.2.4 \u201c Results on Scale-Free Graphs \u201d , the \u201c Inf \u201d in Tabel 1 represents the distance more than 1000 . We really hope that we have explained every confused point clearly and please let us know if there are any other points . Thank you once again for your reviews ."}, {"review_id": "SJz6MnC5YQ-1", "review_text": "This paper addresses the important / open problem of graph generation, and specifically in a conditional/transductive setting. Graph generations is a new topic, it is difficult, and has many important applications, for instance generating new molecules for drug development. As stated by the authors, this is a relatively open field: there are not many papers in this area, with most approaches today resorting to domain specific encodinings, or \"flattening\" of graphs into sequences to then allow for the use recurrence (like in MT); this which per se is an rather coarse approximation to graph topology representations, thus fully motivating the need for new solutions that take graph-structure into account. The setting / application of this method to graph synthesis of suspicious behaviours of network users, to detect intrusion, effectively a Zero-shot problem, is super interesting. The main architectural contribution of this paper are graph-deconvolutions, practically a graph-equivalent of CNN's depth-to-space - achieved by means of transposed structural matrix multiplication of the hidden GNN (graph-NN) activation - simple, reasonable and effective. While better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs. Results are provided on relatively new tasks so it's hard to compare fully to previous methods, but the authors do make an attempt to provide comparisons on synthetic graphs and intrusion detection data. The authors do published their code on GitHub with a link to the datasets as well. As previously mentioned in public comments on this forum, some points in the paper are not very clear; specifically regarding the loss function, the definition of \"edge-to-edge\" convolutions and generally the architectural choice related to the conditional GAN discriminator. Clarifications of these points, and more in general the philosophy behind the architectural choices made, would make this paper a much clearer accept. Thank you! ps // next my previous public comments, in detail, repeated ... -- - the general architecture, and specifically the logic behind the edge-to-edge convolution, and generally the different blocks in fig.1 \"graph translator\". - how exactly do you do a L1 loss on graphs? I'd have to assume the topology of the graph is unchanged between Gy and T(Gx) ~ and then maybe take L1 of weight matrix? But then is this general enough ~ given your stated goal of modeling different topologies? Either ways, more explanation / and perhaps equations to clarify this loss would be very helpful. - why do you need a conditional GAN discriminator, if you already model similarity by L1? Typically one would use a GAN-D() to model \"proximity\" to the source-distribution, and then a similarity loss (L1 in your case) to model \"proximity\" to the actual input sample, in the case of trasductional domains. Instead here you seem to suggest to use L1 and GAN to do basically the same thing, or with significant overlap anyways. This is confusing to me. Please explain the logic for this architectural choice. - could you please explain the setting for the \u201cgold standard\u201d experiment. I'd have to assume, for instance, you train a GNN in a supervised way by using both source (non-suspicious) and target (suspicious) behaviour, and label accordingly? That said I am not 100% sure of this problem setting. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Dear Reviewer : Thanks very much for your comments and questions . We would like to explain them in detail and modify our paper accordingly . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Q : First , the general architecture , and specifically the logic behind the edge-to-edge convolution , and generally the different blocks in fig.1 `` graph translator '' . A : General architecture : The whole framework includes a translator and a discriminator . ( 1 ) Translator . Translator consists of an encoder , a decoder , and a skip network , which first learn the representation of the graph and then decode it back to the target graph . See details in the third part of the answer . ( 2 ) Discriminator . Our discriminator aims to classify the generated graphs and the real target graphs given the input graph . ( 3 ) The translator and discriminator are trained together , and the final goal is that the discriminator can not distinguish the generated graphs and real target graphs . After training such a model , the translator will be used in the test phase . The logic behind edge-to-edge convolution : ( 1 ) Generally speaking , the purpose of edge-to-edge convolution layers is to aggregate the neighborhood information of nodes . Specifically , the n-th edge-to-edge convolution layer aggregates the n-th hop connection information of nodes related to each edge . ( 2 ) Different from image convolution , for each hidden channel , we have two filters , one is a column vector while the other is a row vector . To learn the nth hop information of edge < i , j > , row filter aggregates all the ( n-1 ) -th hop information of outgoing edges of node i and column filter aggregates all the ( n-1 ) -th hop information of incoming edges of node j . ( 3 ) Edge-to-edge layers are important to extract some higher-level graph features , e.g. , the n-hop reachability from a node to another ; n-hop in-degree and out-degree , and many other higher-order patterns . Different blocks in the graph translator : Translator consists of an encoder , a decoder , and a skip network . ( 1 ) Encoder . The encoder does n-hop edge information aggregation from the input graphs using edge-to-edge layers and then uses the edge-to-node layer to learn the latent representation of nodes . ( 2 ) Decoder . Reversely , the graph decoder first uses node-to-edge layers to decode the node representations to aggregated edge information and then further decode that into adjacency matrix , which is the final generated graphs . ( 3 ) Skip-network . Over the encoder-decoder framework , we also added skip-network ( the black line of Fig.1 ) which can directly map the edge aggregation information in every hop from the input graph to the output graph so that can preserve the local information in every resolution ( i.e. , every hop ) . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Q : how exactly do you do a L1 loss on graphs ? I 'd have to assume the topology of the graph is unchanged between Gy and T ( Gx ) ~ and then maybe take L1 of weight matrix ? But then is this general enough ~ given your stated goal of modeling different topologies ? Either ways , more explanation / and perhaps equations to clarify this loss would be very helpful . A : ( 1 ) L1 norm is applied to the weight matrix . Our methodology is still general enough which is achieved by a trade-off between L1 loss and adversarial loss ( GAN-D ) , which jointly enforces Gy and T ( Gx ) to follow a similar topological pattern but may not necessarily the same . Specifically , L1 makes T ( Gx ) share the same rough outline of sparsity pattern like Gy , while under this outline , adversarial loss allows the T ( Gx ) to vary to some degree . ( 2 ) Combining L1 loss and adversarial loss is well-recognized and validated . Works on image-translation have proposed and utilized L1 loss and adversarial loss jointly in GAN , for example , reference [ 1 ] ( with 600+ citations ) and reference [ 2 ] ( with 1300+ citations ) . They have done extensive experiments to show the advantage of such a strategy . Furthermore , in our experiments , we found the performance when using L1 loss and adversarial loss jointly is better than using either of them . -- -- -- [ 1 ] Pathak , D. , Krahenbuhl , P. , Donahue , J. , Darrell , T. , & Efros , A . A . ( 2016 ) .Context encoders : Feature learning by inpainting . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ( pp.2536-2544 ) . -- -- -- [ 2 ] Isola , P. , Zhu , J. Y. , Zhou , T. , & Efros , A . A . ( 2017 ) .Image-to-image translation with conditional adversarial networks . arXiv preprint ."}, {"review_id": "SJz6MnC5YQ-2", "review_text": "The paper presents an approach for translating graphs in one domain to graphs in the same domain using a GAN approach. A graph Translator approach is defined and a number of synthetic data sets and one real-world data set are used to evaluate the approach. Most of the paper is written well, though there are some odd sentence structure issues in places. The paper could do with a thorough check for grammatical and spelling mistakes. For example you miss-spell NVIDIA. The main concerns with the work: 1) Equation 2 is used to minimise the distance between graphs from X and graphs in Y. Yet, the main metric which is used to evaluate the paper is this distance. This would seem to give an unfair advantage to your approach. I would also be concerned about the fact that later you use this for stating if a graph represents good or hacker activity. If you have drawn translated graphs towards real graphs, how do you know that you haven\u2019t pulled a good graph closer to a hacker graph? This is more concerning considering work which came out of NIPS which suggested that GAN\u2019s tend to favour producing similar output rather than spreading it evenly over the domain. 2) It isn\u2019t entirely clear what your results are trying to show. Presumably P, R, AUC and F1 are generated from the results produced from your Discriminator? Were each of the other approaches optimised against your discriminator or not? Also, it is unclear as to what the Gold Standard method is - we\u2019re only told that its a classifier, but what type and how constructed? 3) Your approach seems to be \u2018fixed\u2019 in the set of nodes which are in both in the input and output graphs - needing to be the same. This would seem significantly limiting as graphs are rarely of the same node set. 4) Although you comment on other graphs approaches being limited to very small graphs, you do not test your approach on graphs with over 150 nodes. These would also seem to be very small graphs in comparison to real-world graphs. Further evaluation on larger graphs would seem to be essential - how long would it take on graphs with 10^6 nodes? 5) The real-world dataset seems rather odd and not fully explored. Given that you have this data it is surprising that you didn\u2019t complete the loop by showing that you could take data from before a hack attempt and show that you could predict that in the future you had a hack attempt. Perhaps this is due to the fact that you didn\u2019t have the ground-truth data in here to show a graph going from good to bad? But if not it would have been good to have shown, either through this data or some other, how your approach does match in with real-world results. Given the points above, I would be very concerned on an approach which used the above to identify a future hacking attempt. Some more specific comments on the paper: - \"The tremendous success of deep generative models on generating continuous data like image and audio\u201d - it is not clear what this continuous data is. - Hard to parse : \u201cwhich barely can be available for the accounts worth being monitored.\u201d - \u201cThis requires us to learn the generic distribution of theft behaviors from historical attacks and synthesize the possible malicious authentication graphs for the other accounts conditioning on their current computer networks\u201d - given that these historical attacks are (hopefully) rare, is there enough data here to construct a model? - Please define GCNN - \u201cOur GT-GAN is highly extensible where underlying building blocks, GCNN and distance measure in discriminator, can be replaced by other techniques such as (Kipf & Welling, 2017; Arjovsky et al., 2017) or their extensions.\u201d - this sounds more like a feature of what you have contributed rather than a contribution in its own right. - In the context of synthetic data, what is ground-truth? - Hard to parse \u201cModern deep learning techniques operating on graphs is a new trending topic in recent years.\u201d - Hard to parse \u201cHowever, these methods are highly tailored to only address the graph generation in a specific type of applications such as molecules generation\u201d - Hard to parse \u201cExisting works are basically all proposed in the most recent year,\u201d - \u201cTypically we focus on learning the translation from one topological patterns to the other one\u201d -> \u201cTypically we focus on learning the translation from one topological pattern to the other\u201d - It\u2019s not clear in equation 1 how you represent G_X. Only much later is it mentioned about adjacency matrix. - Hard to parse \u201cDifferent and more difficult than graph generation designed only for learning the distribution of graph representations, for graph translation one needs to learn not only the latent graph presentation but also the generic translation mapping from input graph to the target graph simultaneously.\u201c - Hard to parse \u201cgraph translation requires to learn\u201d - Hard to parse \u201cin most of them the input signal is given over node with a static set of edge and their weights fixed for all samples\u201d - \u201cwe propose an graph\u201d -> \u201cwe propose a graph\u201d - Hard to parse \u201cThe two components of the formula refers to direction filters as talked above\u201d - Hard to parse \u201cNext, graph translator requires to\u201d - \u201cas shown in Equations equation 7 and Equations equation 6,\u201d -> \u201cas shown in Equation 6 and Equation 7\u201d - Hard to parse \u201cThe challenge is that we need not only to learn the\u201d - Figure 2 would seem to need more explanation. - The end of section 3.3 is a bit vague and lacks enough detail to reproduce. - \u201cour GT-GAN is able to provide a scalable (i.e., O(N2)) algorithm that can generate general graphs.\u201d - what sizes have you tested this up to? - Hard to parse \u201cwe randomly add another kjEj edges on it to form the target graph\u201d - \u201cThe goal is to forecast and synthesize the future potential malicious authentication graphs of the users without any historical malicious behaviors, by the graph translator from normal to malicious graph trained based on the users with historical malicious-behavior records.\u201d - This isn\u2019t entirely clear. Are you trying to create new malicious graphs or show that a current graph will eventually go malicious? - \u201cAll the comparison methods are directly trained by the malicious graphs without the conditions of input graphs as they can only do graph generation instead of translation.\u201d - not clear. For the synthetic data sets how did you choose which ones were malicious? - \u201cGraphRNN is tested with graph size within 150. GraphGMG, GraphVAE is tested within size 10 and RandomVAE is tested on graphs within size 150.\u201d -> \u201cGraphRNN and RandomVAE are tested with graph up to size 150. GraphGMG, GraphVAE is tested with graphs up to size 10.\u201d - \u201cHere, beyond label imbalance, we are interested in \u201clabel missing\u201d which is more challenging.\u201d - \u201cmissing labels\u201d? - \u201cIn addition, we have also trained a \u201cgold standard\u201d classifier based on input graphs and real target graphs.\u201d - need to say more about this.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer : Thanks very much for your comments and questions . We would like to first explain your concerns . -- -- -- -- -- -- -- -- -- -- -- -- - Q : Equation 2 is used to minimize the distance between graphs from X and graphs in Y . Yet , the main metric which is used to evaluate the paper is this distance . This would seem to give an unfair advantage to your approach . I would also be concerned about the fact that later you use this for stating if a graph represents good or hacker activity . If you have drawn translated graphs towards real graphs , how do you know that you haven \u2019 t pulled a good graph closer to a hacker graph ? This is more concerning considering work which came out of NIPS which suggested that GAN \u2019 s tend to favour producing similar output rather than spreading it evenly over the domain . A : ( 1 ) We minimize the distance between generated graphs and real target graphs in Y , not graphs from X and graphs from Y . The comparison methods also minimize the distance between their generated graphs and real graphs , which are the same as us . ( 2 ) We have done both direct and indirect evaluations in all the datasets , which comprehensively demonstrate the good performance of the proposed methods . Moreover , the indirect evaluations ( see Table 2-4 ) do not use distance to evaluate the performance but the classification metrics ( precision , recall , ACU and F1-score ) . Even in direct evaluation , the metrics contain degree distribution distance , MSE of adjacent matrix comparison and repository comparing , while the loss function in equation 2 is applied only on the MSE of the adjacent matrix of graphs . For the statement \u201c NIPS which suggested that GAN \u2019 s tend to favor producing similar output \u201d . Our answers are three-fold : ( 1 ) As we have done an extensive survey and did not find papers using GAN for graph generation yet , we doubt if the experience in GAN on other data still applies exactly the same for graph data . This is because as we know , graphs are highly different types of data than images which are continuous-valued ( e.g. , RGB ) . In graphs , nodes can have arbitrary connectivity . ( 2 ) Moreover , our experiments suggest that there is indeed nontrivial variance in the generated graphs . As shown in Figure 5 in Appendix , we can see the difference among the degree distributions of different graphs we generated is obvious . ( 3 ) We can tune the dropout ratio to control the degree of variation of generated output . The noise is introduced by the dropout function in each convolution layer , which functions by randomly ignoring certain ratio of neuron \u2019 s output of a network . -- -- -- -- -- -- -- -- -- -- -- -- - Q : It isn \u2019 t entirely clear what your results are trying to show . Presumably P , R , AUC and F1 are generated from the results produced from your Discriminator ? Were each of the other approaches optimized against your discriminator or not ? Also , it is unclear as to what the Gold Standard method is - we \u2019 re only told that it \u2019 s a classifier , but what type and how constructed ? A : ( 1 ) P , R , AUC and F1 are metrics to indirectly evaluate the generated graphs by comparison models . Since all the comparison methods in our paper are generative models which generate graphs , and hence our experiment is to evaluate how good the generated graphs are . One way to evaluate this is by \u201c indirect evaluation \u201d , where we use the graphs generated by different comparison methods as training data to train a classifier ( all are based on KCNN for fairness ) , and then compare which classifier is better . The flowchart of the indirect evaluation is shown in Figure 9 , in Appendix D. ( 2 ) \u201c Gold standard \u201d is the classifier trained directly by the real target graphs , instead of generated graphs . As it directly uses the real graphs to train the classifier ( still based on KCNN ) , it is expected to get the best performance . Therefore , \u201c gold standard \u201d method acts as the \u201c best-possible-performer \u201d , and is used as a benchmark to evaluate all the different generative models on how \u201c real \u201d the graphs they can generate : the closer ( and better ) their performance is to the \u201c gold standard \u201d one , the \u201c more real \u201d their generated graphs are . -- -- -- -- -- -- -- -- -- -- -- -- - Q : Your approach seems to be \u2018 fixed \u2019 in the set of nodes which are in both in the input and output graphs - needing to be the same . This would seem significantly limiting as graphs are rarely of the same node set . A : Yes , we admit that our model has a limitation in dealing with the variable-size input graphs . This limitation largely exists in the existing deep graph learning methods , especially those based on graph convolution . This problem itself is a challenging open problem that requires significant future efforts in the community . However , the focus of our work in this paper is the translation mapping establishment , optimization , and evaluation . We are indeed considering one of our next extensions to deal with this problem . Thanks for the comments ."}], "0": {"review_id": "SJz6MnC5YQ-0", "review_text": "The paper presents a novel idea of generating discrete data such as graphs that is conditional on input data to control the graph structure that is being generated. Given an input graph, the proposed method infers a target graph by learning their underlying translation mapping by using new graph convolution and deconvolution layers to learn the global and local translation mapping. The idea of learning generic shared common and latent implicit patterns across different graph structure is brilliant. Their method learns a distribution over graphs conditioned on the input graph whilst allowing the network to learn latent and implicit properties. The authors claim that their method is applicable for large graphs. However, it seems the experiments do not seem to support this. It is not clear how the noise is introduced in the graphs. I would have expected to see some analysis and results on the translation quality over systematic noise applied to the input graph. It is also not clear what are the assumptions made on the connectivity of the input graph and the target graph. Do we know how does the connectedness of the input graph affect the translation quality in the case of strongly connected directed graphs? Or what happens if the target graph has a strong connectivity? Towards this, how does the computational complexity scale wrt to the connectedness? A lot of clarity is required on the choice of evaluation metric; for example choice of distance measure ? What is the L1 norm applied on? I did not completely follow the arguments towards directed graph deconvolution operators. There is lack of clarity and the explanation seems lacking in parts in this particular section; especially since this is the key contribution of this work Typo:. The \u201cInf\u201d in Tabel 1 ", "rating": "5: Marginally below acceptance threshold", "reply_text": "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Q\uff1aA lot of clarity is required on the choice of evaluation metric ; for example , choice of distance measure ? What is the L1 norm applied on ? A : Answer about Evaluation metrics : ( 1 ) We want to evaluate if the generated graphs are scale-free graphs in the direct evaluation for dataset scale-free graphs . If the degree distribution of generated graphs is the same to the degree distribution of real target graphs , the generated graphs are good . ( 2 ) There are many classical evaluation metrics focusing on measuring the similarities or distance of two distributions . The four metrics in this paper are among the most authoritative and commonly used ones in existing works , e.g. , [ 2 ] [ 3 ] [ 4 ] [ 5 ] . Answer about L1 norm : ( 1 ) L1 norm is applied to the weight adjacent matrix of the graph . Our methodology is achieved by a trade-off between L1 loss and adversarial loss ( GAN-D ) . Specifically , L1 makes generated graphs share the same rough outline of sparsity pattern like generated graphs , while under this outline , adversarial loss allows them to vary to some degree . ( 2 ) L1 norm is commonly used in GAN in relevant domains , e.g. , in image-translation domain , for example , reference [ 1 ] ( with 600+ citations ) and reference [ 6 ] ( with 1300+ citations ) . They have done extensive experiments to show the advantage of such a strategy . ( 3 ) The experiment demonstrates its effectiveness . Specifically , the proposed GT-GAN that uses L1 norm outperformed all the other comparison methods shown in Table 2,3 and 4 . -- -- -- - [ 2 ] Schieber , T. A. , Carpi , L. , D\u00edaz-Guilera , A. , Pardalos , P. M. , Masoller , C. , & Ravetti , M. G. ( 2017 ) . Quantification of network structural dissimilarities . Nature Communications , 8 , 13928 . -- -- -- - [ 3 ] Bauckhage , C. , Kersting , K. , & Hadiji , F. ( 2015 , July ) . Parameterizing the Distance Distribution of Undirected Networks . In UAI ( pp.121-130 ) . -- -- -- - [ 4 ] Chiang , S. , Cassese , A. , Guindani , M. , Vannucci , M. , Yeh , H. J. , Haneef , Z. , & Stern , J. M. ( 2016 ) . Time-dependence of graph theory metrics in functional connectivity analysis . NeuroImage , 125 , 601-615 . -- -- -- - [ 5 ] You , J. , Ying , R. , Ren , X. , Hamilton , W. L. , & Leskovec , J . ( 2018 ) .GraphRNN : A Deep Generative Model for Graphs . arXiv preprint arXiv:1802.08773 . -- -- -- - [ 6 ] Isola , P. , Zhu , J. Y. , Zhou , T. , & Efros , A . A . ( 2017 ) .Image-to-image translation with conditional adversarial networks . arXiv preprint . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Q\uff1aI did not completely follow the arguments towards directed graph deconvolution operators . There is lack of clarity and the explanation seems lacking in parts in this particular section ; especially since this is the key contribution of this work . A : ( 1 ) Our decoder is symmetric to the encoder in their architectures . The encoder does n-hop edge information aggregation from the input graphs and learns the latent representation of nodes . Then , we first decode the node embedding to get the n-hop aggregated information on edges by node-to-edge layer and then we further decode the n-hop aggregated information layer by layer by n-layers back to get the output adjacency matrix . ( 2 ) Different from image deconvolution , for each hidden channel , we have two filters vertical to each other , i.e. , one is a column vector while the other is a row vector . To get the nth hop information of edge < i , j > , row filter decodes all the ( n+1 ) -th hop information of outgoing edges of node i and column filter decodes all the ( n+1 ) -th hop information of incoming edges of node j . ( 3 ) To make our description clearer , we have updated our paper in Section 3.2.2 , e.g , by adding \u201c To get the nth hop information Aij , row filter decodes all the ( n+1 ) -th hop information of outgoing edges of Vi and column filter decodes all the ( n+1 ) -th hop information of incoming edges of Vj. \u201d -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - Q : Typo : . The \u201c Inf \u201d in Tabel 1 A : As explained in Section 4.2.4 \u201c Results on Scale-Free Graphs \u201d , the \u201c Inf \u201d in Tabel 1 represents the distance more than 1000 . We really hope that we have explained every confused point clearly and please let us know if there are any other points . Thank you once again for your reviews ."}, "1": {"review_id": "SJz6MnC5YQ-1", "review_text": "This paper addresses the important / open problem of graph generation, and specifically in a conditional/transductive setting. Graph generations is a new topic, it is difficult, and has many important applications, for instance generating new molecules for drug development. As stated by the authors, this is a relatively open field: there are not many papers in this area, with most approaches today resorting to domain specific encodinings, or \"flattening\" of graphs into sequences to then allow for the use recurrence (like in MT); this which per se is an rather coarse approximation to graph topology representations, thus fully motivating the need for new solutions that take graph-structure into account. The setting / application of this method to graph synthesis of suspicious behaviours of network users, to detect intrusion, effectively a Zero-shot problem, is super interesting. The main architectural contribution of this paper are graph-deconvolutions, practically a graph-equivalent of CNN's depth-to-space - achieved by means of transposed structural matrix multiplication of the hidden GNN (graph-NN) activation - simple, reasonable and effective. While better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs. Results are provided on relatively new tasks so it's hard to compare fully to previous methods, but the authors do make an attempt to provide comparisons on synthetic graphs and intrusion detection data. The authors do published their code on GitHub with a link to the datasets as well. As previously mentioned in public comments on this forum, some points in the paper are not very clear; specifically regarding the loss function, the definition of \"edge-to-edge\" convolutions and generally the architectural choice related to the conditional GAN discriminator. Clarifications of these points, and more in general the philosophy behind the architectural choices made, would make this paper a much clearer accept. Thank you! ps // next my previous public comments, in detail, repeated ... -- - the general architecture, and specifically the logic behind the edge-to-edge convolution, and generally the different blocks in fig.1 \"graph translator\". - how exactly do you do a L1 loss on graphs? I'd have to assume the topology of the graph is unchanged between Gy and T(Gx) ~ and then maybe take L1 of weight matrix? But then is this general enough ~ given your stated goal of modeling different topologies? Either ways, more explanation / and perhaps equations to clarify this loss would be very helpful. - why do you need a conditional GAN discriminator, if you already model similarity by L1? Typically one would use a GAN-D() to model \"proximity\" to the source-distribution, and then a similarity loss (L1 in your case) to model \"proximity\" to the actual input sample, in the case of trasductional domains. Instead here you seem to suggest to use L1 and GAN to do basically the same thing, or with significant overlap anyways. This is confusing to me. Please explain the logic for this architectural choice. - could you please explain the setting for the \u201cgold standard\u201d experiment. I'd have to assume, for instance, you train a GNN in a supervised way by using both source (non-suspicious) and target (suspicious) behaviour, and label accordingly? That said I am not 100% sure of this problem setting. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Dear Reviewer : Thanks very much for your comments and questions . We would like to explain them in detail and modify our paper accordingly . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Q : First , the general architecture , and specifically the logic behind the edge-to-edge convolution , and generally the different blocks in fig.1 `` graph translator '' . A : General architecture : The whole framework includes a translator and a discriminator . ( 1 ) Translator . Translator consists of an encoder , a decoder , and a skip network , which first learn the representation of the graph and then decode it back to the target graph . See details in the third part of the answer . ( 2 ) Discriminator . Our discriminator aims to classify the generated graphs and the real target graphs given the input graph . ( 3 ) The translator and discriminator are trained together , and the final goal is that the discriminator can not distinguish the generated graphs and real target graphs . After training such a model , the translator will be used in the test phase . The logic behind edge-to-edge convolution : ( 1 ) Generally speaking , the purpose of edge-to-edge convolution layers is to aggregate the neighborhood information of nodes . Specifically , the n-th edge-to-edge convolution layer aggregates the n-th hop connection information of nodes related to each edge . ( 2 ) Different from image convolution , for each hidden channel , we have two filters , one is a column vector while the other is a row vector . To learn the nth hop information of edge < i , j > , row filter aggregates all the ( n-1 ) -th hop information of outgoing edges of node i and column filter aggregates all the ( n-1 ) -th hop information of incoming edges of node j . ( 3 ) Edge-to-edge layers are important to extract some higher-level graph features , e.g. , the n-hop reachability from a node to another ; n-hop in-degree and out-degree , and many other higher-order patterns . Different blocks in the graph translator : Translator consists of an encoder , a decoder , and a skip network . ( 1 ) Encoder . The encoder does n-hop edge information aggregation from the input graphs using edge-to-edge layers and then uses the edge-to-node layer to learn the latent representation of nodes . ( 2 ) Decoder . Reversely , the graph decoder first uses node-to-edge layers to decode the node representations to aggregated edge information and then further decode that into adjacency matrix , which is the final generated graphs . ( 3 ) Skip-network . Over the encoder-decoder framework , we also added skip-network ( the black line of Fig.1 ) which can directly map the edge aggregation information in every hop from the input graph to the output graph so that can preserve the local information in every resolution ( i.e. , every hop ) . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Q : how exactly do you do a L1 loss on graphs ? I 'd have to assume the topology of the graph is unchanged between Gy and T ( Gx ) ~ and then maybe take L1 of weight matrix ? But then is this general enough ~ given your stated goal of modeling different topologies ? Either ways , more explanation / and perhaps equations to clarify this loss would be very helpful . A : ( 1 ) L1 norm is applied to the weight matrix . Our methodology is still general enough which is achieved by a trade-off between L1 loss and adversarial loss ( GAN-D ) , which jointly enforces Gy and T ( Gx ) to follow a similar topological pattern but may not necessarily the same . Specifically , L1 makes T ( Gx ) share the same rough outline of sparsity pattern like Gy , while under this outline , adversarial loss allows the T ( Gx ) to vary to some degree . ( 2 ) Combining L1 loss and adversarial loss is well-recognized and validated . Works on image-translation have proposed and utilized L1 loss and adversarial loss jointly in GAN , for example , reference [ 1 ] ( with 600+ citations ) and reference [ 2 ] ( with 1300+ citations ) . They have done extensive experiments to show the advantage of such a strategy . Furthermore , in our experiments , we found the performance when using L1 loss and adversarial loss jointly is better than using either of them . -- -- -- [ 1 ] Pathak , D. , Krahenbuhl , P. , Donahue , J. , Darrell , T. , & Efros , A . A . ( 2016 ) .Context encoders : Feature learning by inpainting . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ( pp.2536-2544 ) . -- -- -- [ 2 ] Isola , P. , Zhu , J. Y. , Zhou , T. , & Efros , A . A . ( 2017 ) .Image-to-image translation with conditional adversarial networks . arXiv preprint ."}, "2": {"review_id": "SJz6MnC5YQ-2", "review_text": "The paper presents an approach for translating graphs in one domain to graphs in the same domain using a GAN approach. A graph Translator approach is defined and a number of synthetic data sets and one real-world data set are used to evaluate the approach. Most of the paper is written well, though there are some odd sentence structure issues in places. The paper could do with a thorough check for grammatical and spelling mistakes. For example you miss-spell NVIDIA. The main concerns with the work: 1) Equation 2 is used to minimise the distance between graphs from X and graphs in Y. Yet, the main metric which is used to evaluate the paper is this distance. This would seem to give an unfair advantage to your approach. I would also be concerned about the fact that later you use this for stating if a graph represents good or hacker activity. If you have drawn translated graphs towards real graphs, how do you know that you haven\u2019t pulled a good graph closer to a hacker graph? This is more concerning considering work which came out of NIPS which suggested that GAN\u2019s tend to favour producing similar output rather than spreading it evenly over the domain. 2) It isn\u2019t entirely clear what your results are trying to show. Presumably P, R, AUC and F1 are generated from the results produced from your Discriminator? Were each of the other approaches optimised against your discriminator or not? Also, it is unclear as to what the Gold Standard method is - we\u2019re only told that its a classifier, but what type and how constructed? 3) Your approach seems to be \u2018fixed\u2019 in the set of nodes which are in both in the input and output graphs - needing to be the same. This would seem significantly limiting as graphs are rarely of the same node set. 4) Although you comment on other graphs approaches being limited to very small graphs, you do not test your approach on graphs with over 150 nodes. These would also seem to be very small graphs in comparison to real-world graphs. Further evaluation on larger graphs would seem to be essential - how long would it take on graphs with 10^6 nodes? 5) The real-world dataset seems rather odd and not fully explored. Given that you have this data it is surprising that you didn\u2019t complete the loop by showing that you could take data from before a hack attempt and show that you could predict that in the future you had a hack attempt. Perhaps this is due to the fact that you didn\u2019t have the ground-truth data in here to show a graph going from good to bad? But if not it would have been good to have shown, either through this data or some other, how your approach does match in with real-world results. Given the points above, I would be very concerned on an approach which used the above to identify a future hacking attempt. Some more specific comments on the paper: - \"The tremendous success of deep generative models on generating continuous data like image and audio\u201d - it is not clear what this continuous data is. - Hard to parse : \u201cwhich barely can be available for the accounts worth being monitored.\u201d - \u201cThis requires us to learn the generic distribution of theft behaviors from historical attacks and synthesize the possible malicious authentication graphs for the other accounts conditioning on their current computer networks\u201d - given that these historical attacks are (hopefully) rare, is there enough data here to construct a model? - Please define GCNN - \u201cOur GT-GAN is highly extensible where underlying building blocks, GCNN and distance measure in discriminator, can be replaced by other techniques such as (Kipf & Welling, 2017; Arjovsky et al., 2017) or their extensions.\u201d - this sounds more like a feature of what you have contributed rather than a contribution in its own right. - In the context of synthetic data, what is ground-truth? - Hard to parse \u201cModern deep learning techniques operating on graphs is a new trending topic in recent years.\u201d - Hard to parse \u201cHowever, these methods are highly tailored to only address the graph generation in a specific type of applications such as molecules generation\u201d - Hard to parse \u201cExisting works are basically all proposed in the most recent year,\u201d - \u201cTypically we focus on learning the translation from one topological patterns to the other one\u201d -> \u201cTypically we focus on learning the translation from one topological pattern to the other\u201d - It\u2019s not clear in equation 1 how you represent G_X. Only much later is it mentioned about adjacency matrix. - Hard to parse \u201cDifferent and more difficult than graph generation designed only for learning the distribution of graph representations, for graph translation one needs to learn not only the latent graph presentation but also the generic translation mapping from input graph to the target graph simultaneously.\u201c - Hard to parse \u201cgraph translation requires to learn\u201d - Hard to parse \u201cin most of them the input signal is given over node with a static set of edge and their weights fixed for all samples\u201d - \u201cwe propose an graph\u201d -> \u201cwe propose a graph\u201d - Hard to parse \u201cThe two components of the formula refers to direction filters as talked above\u201d - Hard to parse \u201cNext, graph translator requires to\u201d - \u201cas shown in Equations equation 7 and Equations equation 6,\u201d -> \u201cas shown in Equation 6 and Equation 7\u201d - Hard to parse \u201cThe challenge is that we need not only to learn the\u201d - Figure 2 would seem to need more explanation. - The end of section 3.3 is a bit vague and lacks enough detail to reproduce. - \u201cour GT-GAN is able to provide a scalable (i.e., O(N2)) algorithm that can generate general graphs.\u201d - what sizes have you tested this up to? - Hard to parse \u201cwe randomly add another kjEj edges on it to form the target graph\u201d - \u201cThe goal is to forecast and synthesize the future potential malicious authentication graphs of the users without any historical malicious behaviors, by the graph translator from normal to malicious graph trained based on the users with historical malicious-behavior records.\u201d - This isn\u2019t entirely clear. Are you trying to create new malicious graphs or show that a current graph will eventually go malicious? - \u201cAll the comparison methods are directly trained by the malicious graphs without the conditions of input graphs as they can only do graph generation instead of translation.\u201d - not clear. For the synthetic data sets how did you choose which ones were malicious? - \u201cGraphRNN is tested with graph size within 150. GraphGMG, GraphVAE is tested within size 10 and RandomVAE is tested on graphs within size 150.\u201d -> \u201cGraphRNN and RandomVAE are tested with graph up to size 150. GraphGMG, GraphVAE is tested with graphs up to size 10.\u201d - \u201cHere, beyond label imbalance, we are interested in \u201clabel missing\u201d which is more challenging.\u201d - \u201cmissing labels\u201d? - \u201cIn addition, we have also trained a \u201cgold standard\u201d classifier based on input graphs and real target graphs.\u201d - need to say more about this.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer : Thanks very much for your comments and questions . We would like to first explain your concerns . -- -- -- -- -- -- -- -- -- -- -- -- - Q : Equation 2 is used to minimize the distance between graphs from X and graphs in Y . Yet , the main metric which is used to evaluate the paper is this distance . This would seem to give an unfair advantage to your approach . I would also be concerned about the fact that later you use this for stating if a graph represents good or hacker activity . If you have drawn translated graphs towards real graphs , how do you know that you haven \u2019 t pulled a good graph closer to a hacker graph ? This is more concerning considering work which came out of NIPS which suggested that GAN \u2019 s tend to favour producing similar output rather than spreading it evenly over the domain . A : ( 1 ) We minimize the distance between generated graphs and real target graphs in Y , not graphs from X and graphs from Y . The comparison methods also minimize the distance between their generated graphs and real graphs , which are the same as us . ( 2 ) We have done both direct and indirect evaluations in all the datasets , which comprehensively demonstrate the good performance of the proposed methods . Moreover , the indirect evaluations ( see Table 2-4 ) do not use distance to evaluate the performance but the classification metrics ( precision , recall , ACU and F1-score ) . Even in direct evaluation , the metrics contain degree distribution distance , MSE of adjacent matrix comparison and repository comparing , while the loss function in equation 2 is applied only on the MSE of the adjacent matrix of graphs . For the statement \u201c NIPS which suggested that GAN \u2019 s tend to favor producing similar output \u201d . Our answers are three-fold : ( 1 ) As we have done an extensive survey and did not find papers using GAN for graph generation yet , we doubt if the experience in GAN on other data still applies exactly the same for graph data . This is because as we know , graphs are highly different types of data than images which are continuous-valued ( e.g. , RGB ) . In graphs , nodes can have arbitrary connectivity . ( 2 ) Moreover , our experiments suggest that there is indeed nontrivial variance in the generated graphs . As shown in Figure 5 in Appendix , we can see the difference among the degree distributions of different graphs we generated is obvious . ( 3 ) We can tune the dropout ratio to control the degree of variation of generated output . The noise is introduced by the dropout function in each convolution layer , which functions by randomly ignoring certain ratio of neuron \u2019 s output of a network . -- -- -- -- -- -- -- -- -- -- -- -- - Q : It isn \u2019 t entirely clear what your results are trying to show . Presumably P , R , AUC and F1 are generated from the results produced from your Discriminator ? Were each of the other approaches optimized against your discriminator or not ? Also , it is unclear as to what the Gold Standard method is - we \u2019 re only told that it \u2019 s a classifier , but what type and how constructed ? A : ( 1 ) P , R , AUC and F1 are metrics to indirectly evaluate the generated graphs by comparison models . Since all the comparison methods in our paper are generative models which generate graphs , and hence our experiment is to evaluate how good the generated graphs are . One way to evaluate this is by \u201c indirect evaluation \u201d , where we use the graphs generated by different comparison methods as training data to train a classifier ( all are based on KCNN for fairness ) , and then compare which classifier is better . The flowchart of the indirect evaluation is shown in Figure 9 , in Appendix D. ( 2 ) \u201c Gold standard \u201d is the classifier trained directly by the real target graphs , instead of generated graphs . As it directly uses the real graphs to train the classifier ( still based on KCNN ) , it is expected to get the best performance . Therefore , \u201c gold standard \u201d method acts as the \u201c best-possible-performer \u201d , and is used as a benchmark to evaluate all the different generative models on how \u201c real \u201d the graphs they can generate : the closer ( and better ) their performance is to the \u201c gold standard \u201d one , the \u201c more real \u201d their generated graphs are . -- -- -- -- -- -- -- -- -- -- -- -- - Q : Your approach seems to be \u2018 fixed \u2019 in the set of nodes which are in both in the input and output graphs - needing to be the same . This would seem significantly limiting as graphs are rarely of the same node set . A : Yes , we admit that our model has a limitation in dealing with the variable-size input graphs . This limitation largely exists in the existing deep graph learning methods , especially those based on graph convolution . This problem itself is a challenging open problem that requires significant future efforts in the community . However , the focus of our work in this paper is the translation mapping establishment , optimization , and evaluation . We are indeed considering one of our next extensions to deal with this problem . Thanks for the comments ."}}