{"year": "2019", "forum": "SkEqro0ctQ", "title": "Hierarchical interpretations for neural network predictions", "decision": "Accept (Poster)", "meta_review": "The paper receives a unanimous accept over reviewers, though some concerns on novelty exist. So it is suggested to be a probable accept. ", "reviews": [{"review_id": "SkEqro0ctQ-0", "review_text": "This paper proposes a novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction. The proposed method is a straightforward extension of the contextual decomposition work by (Murdoch et. al. 2018) which estimates feature interpretability for LSTMs. This work extends (Murdoch et. al. '18) to more general NN architectures and further employs agglomerative clustering to identify groups of features-- as opposed to individual features--that are predictive of the output. Results are shown using a LSTM trained on the standard Stanford sentiment task and a VCG DNN trained on ImageNet which show the superior performance of the proposed approach. In addition, the paper also provides some survey results where \"humans\" were asked to pick more interpretable models. The paper is nicely written and puts itself nicely in context of the previous work. Though, I have several concerns: 1). Biggest concern: Conditioning on the (Murdoch et. al. 18) paper, the methodological novelty of the proposed approach is minimal. Though, the experimental gains on the vision and NLP tasks are nice. 2). It was unclear to me how the agglomerative algorithm (Algorithm 1) was run. That is, was it run as part of the LSTM estimation for instance for the sentiment task OR was it run post-hoc after getting the model estimates from LSTM? If it was run post-hoc then I am unsure if we can assume that the \"agglomeratively grouped CD scores of individual features\" are the same as the \"CD scores for the groups/interactions of features\" in terms of their contribution to the final prediction. 3). Though, the paper mentions several times regarding generalizing (Murdoch et. al. 18) to architectures other than LSTMs but still the experimental results on the sentiment task uses an LSTM as the model. It would have been nice to show the comparative strength of the proposed approach on a different architecture even for the sentiment task. (I understand that the paper uses a different DNN architecture for the vision task). 4). The paper talks several times about diagnosing why a model went wrong e.g. the \"negation\" in the case of the LSTM model in Figure 2, but never discusses the bigger and more interesting problem. How can we build an improved LSTM model for the sentiment task which classifies that incorrect prediction correctly? ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for the exceptionally detailed and thoughtful review . We address your concerns below 1 ) We \u2019 d like to emphasize that our main source of novelty lies in moving from the word/pixel-level heat maps ( e.g.Figure 5 in [ 1 ] ) , which are the current SOTA for interpreting individual DNN predictions , to hierarchical interpretations , such as Figure 2 in our paper . In our human experiments , we compare our hierarchical interpretations against three non-hierarchical baselines , ultimately concluding that the hierarchy is in fact beneficial . Given that the experimental gains across NLP and vision are meaningful , we feel that the simplicity of our method should be an argument for its acceptance , not against . In machine learning , there is often the temptation to propose complicated \u201c highly novel \u201d approaches , many of which are never adopted . In contrast , we explicitly tried to identify the simplest approach that could produce a meaningful improvement over the current SOTA . In interpretability , we feel simplicity is particularly important , as we must consider the human component in providing simple , easy to understand insights into the model . We have found that the more complicated the interpretation method , the harder it is to convince users to use , understand , and trust the method \u2019 s output . 2 ) As R2 also pointed out , section 3.2 was too heavy with mathematical details and lacking intuition . We have now added a paragraph to the beginning of section 3.2 , which should hopefully make it clearer . To answer your question , the agglomeration algorithm was run post-hoc - ACD does not modify the original prediction of the LSTM . The agglomeration algorithm is simply an approach for constructing the hierarchy of phrases/pixels , but does not alter the CD scores produced for each node in the hierarchy . That is , the score for each node in the hierarchy is simply the CD score for that particular phrase/pixel-blob , which I believe is what you mean by \u201c CD scores for the groups/interactions of features '' . By `` agglomeratively grouped CD scores of individual features '' , I think you \u2019 re referring to the sum of the CD scores for the sub-phrases/words contained within a phrase . This value isn \u2019 t displayed in the hierarchy , as summing importance scores can \u2019 t capture interactions , such as the negation between \u201c n \u2019 t lift \u201d and \u201c this heartfelt enterprise out of the familiar. \u201d that occurs in Figure 2 . 3 ) We agree that it could be interesting to see whether CNNs and LSTMs produce similar importance scores and/or hierarchies on the same dataset , and this is something we have thought about for future work ( e.g. \u201c Do LSTMs and CNNs capture different kinds of interactions ? \u201d ) . Unfortunately , in a conference paper we don \u2019 t feel we have the space to do such an analysis in a defensible manner . Moreover , we feel the existing results are more important to justifying the main part of the paper - hierarchical interpretations . 4 ) The problem of using interpretations to improve accuracy is quite interesting , and one that we have spent a lot of time thinking about it . The short answer is that it is not immediately clear how to do so , but we are optimistic that improved interpretations like ACD should prove useful in improving model \u2019 s accuracy However , even if ACD never leads to increased prediction performance , we think it \u2019 s important to stress that there are many uses for interpretations that have no effect on predictive performance . As we discuss in the first paragraph of our introduction , in scientific applications [ 2-4 ] , it is the interpretations themselves which are the findings , and are ultimately reported in publications . In industry , interpretability is important in determining the fairness of a model [ 5 ] , and satisfying regulatory concerns [ 6 ] . Finally , as we show in our human experiments , improved interpretations help users to better trust the predictions of their models , which is helpful even if it does not change the predictions themselves . [ 1 ] https : //arxiv.org/pdf/1612.08220.pdf [ 2 ] https : //arxiv.org/abs/1702.05747 [ 3 ] https : //www.researchgate.net/publication/261538344_The_Emergence_of_Machine_Learning_Techniques_in_Criminology [ 4 ] http : //msb.embopress.org/content/12/7/878 [ 5 ] https : //arxiv.org/abs/1104.3913 [ 6 ] https : //arxiv.org/abs/1606.08813"}, {"review_id": "SkEqro0ctQ-1", "review_text": "**Summary** In this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs. They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction. **Strength** 1. Splitting information into binary groups at each layer is a neat approach to segregate interpretations. 2. Experiments are elaborate and cover the breadth of the proposed method well. 3. The paper is well presented and fairly easy to follow. **Weakness** 1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](https://arxiv.org/abs/1801.05453). 2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the helpful comments . We would like to address your concerns about the novelty of the work . \u201c 1.Limited contributions in terms of novelty . This approach for RNNs is presented fairly well in the previous paper. \u201d As you correctly noted , one of the two contributions of this paper is to generalize CD from LSTMs to generic DNNs . However , we would like to clarify that the most important contribution of this paper is not generalizing CD , but introducing the concept ( and implementation ) of hierarchical importance for interpreting neural network predictions . The current state of the art for interpreting neural network predictions is word/pixel-level heat-maps , such as Figure 5 in [ 1 ] . Our main contribution is to introduce hierarchical interpretations , such as Figure 2 in our paper , and show that they improve over heat maps , the prior SOTA . In our human experiments , we compare our hierarchical interpretations ( agglomerative CD , or ACD ) against three non-hierarchical baselines , ultimately concluding that the hierarchy is in fact beneficial . We hope that we have clarified that hierarchical interpretations are the main contribution of our paper , and that this addresses your concern around the novelty of this work . To address this , we have ( slightly ) modified our introduction and method sections . We tried to make this clear throughout the paper and would welcome suggestions on how to avoid similar misunderstandings for future readers . \u201c 2.It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers. \u201d Thanks for pointing this out - we realize we omitted much of our justification in making the modifications for convolution and pooling layers . To address this , we have added some intuition in the fifth paragraph of section 3.1 . Additionally , we have added a figure in page 27 of the supplement ( Fig S5 ) showing the effect of our modifications to the update equations for convolution and ReLU layers . [ 1 ] https : //arxiv.org/pdf/1612.08220.pdf"}, {"review_id": "SkEqro0ctQ-2", "review_text": "This paper proposes a hierarchical extension of contextual decomposition. The approach is validated in qualitative examples and a small scale usability study Quality, The paper is well motivated. Contextual decomposition is briefly described but detailed enough to self-contained. The experimental evaluation produces usability evidence. Uncertainty could have been better explained, Clarity, The main methodological contribution (hierarchical CD) is well motivated but only provided in the form of an algorithm. Could have been more precisely described and optimality discussed. Originality & significance The work builds heavily on CD but has the hierarchical extension is original and significant. Uncertainty estimates could have improved the significance of the usability study pros and cons + interesting problem + well-motivated algorithmic extension of CD - uncertainty of usability experiment? ", "rating": "7: Good paper, accept", "reply_text": "Thanks for the helpful comments and positive feedback . We \u2019 re glad you agree that the hierarchical notion of importance is important and well validated . We address some of your concerns below . \u201c The main methodological contribution ( hierarchical CD ) is well motivated but only provided in the form of an algorithm . Could have been more precisely described and optimality discussed. \u201d This is great feedback , we agree that we were missing a bigger picture , non-mathematical description of the algorithm . We have added a paragraph at the beginning of Section 3.2 giving intuition for our method before jumping into the technical details . \u201c Uncertainty estimates could have improved the significance of the usability study. \u201d We agree , and have updated the paper to include statistical significance results . We \u2019 ve provided the details below , but the summary is that most of the big jumps in our plots were significant , with the exception of ImageNet in plot A , where the results were only \u201c suggestive \u201d ( p values ranged from 0.07 to 0.15 ) . Overall , it seems like the benefits of ACD are in fact statistically meaningful . Statistical significance results summary : Identifying an accurate model ( one-sided two-proportion t-test ) Sentiment : gaps between ACD and IG , break-down are significant , ACD to CD is not MNIST : nothing is significant ImageNet : gaps between ACD and others are suggestive , but not significant ( p values range from 0.07 to 0.15 ) Ranking trust in model ( permutation test with mean rank test statistic ) Sentiment/ImageNet : ACD \u2019 s mean rank is significantly higher than all other methods MNIST : ACD is significantly higher than break down , everything else is not ."}], "0": {"review_id": "SkEqro0ctQ-0", "review_text": "This paper proposes a novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction. The proposed method is a straightforward extension of the contextual decomposition work by (Murdoch et. al. 2018) which estimates feature interpretability for LSTMs. This work extends (Murdoch et. al. '18) to more general NN architectures and further employs agglomerative clustering to identify groups of features-- as opposed to individual features--that are predictive of the output. Results are shown using a LSTM trained on the standard Stanford sentiment task and a VCG DNN trained on ImageNet which show the superior performance of the proposed approach. In addition, the paper also provides some survey results where \"humans\" were asked to pick more interpretable models. The paper is nicely written and puts itself nicely in context of the previous work. Though, I have several concerns: 1). Biggest concern: Conditioning on the (Murdoch et. al. 18) paper, the methodological novelty of the proposed approach is minimal. Though, the experimental gains on the vision and NLP tasks are nice. 2). It was unclear to me how the agglomerative algorithm (Algorithm 1) was run. That is, was it run as part of the LSTM estimation for instance for the sentiment task OR was it run post-hoc after getting the model estimates from LSTM? If it was run post-hoc then I am unsure if we can assume that the \"agglomeratively grouped CD scores of individual features\" are the same as the \"CD scores for the groups/interactions of features\" in terms of their contribution to the final prediction. 3). Though, the paper mentions several times regarding generalizing (Murdoch et. al. 18) to architectures other than LSTMs but still the experimental results on the sentiment task uses an LSTM as the model. It would have been nice to show the comparative strength of the proposed approach on a different architecture even for the sentiment task. (I understand that the paper uses a different DNN architecture for the vision task). 4). The paper talks several times about diagnosing why a model went wrong e.g. the \"negation\" in the case of the LSTM model in Figure 2, but never discusses the bigger and more interesting problem. How can we build an improved LSTM model for the sentiment task which classifies that incorrect prediction correctly? ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you very much for the exceptionally detailed and thoughtful review . We address your concerns below 1 ) We \u2019 d like to emphasize that our main source of novelty lies in moving from the word/pixel-level heat maps ( e.g.Figure 5 in [ 1 ] ) , which are the current SOTA for interpreting individual DNN predictions , to hierarchical interpretations , such as Figure 2 in our paper . In our human experiments , we compare our hierarchical interpretations against three non-hierarchical baselines , ultimately concluding that the hierarchy is in fact beneficial . Given that the experimental gains across NLP and vision are meaningful , we feel that the simplicity of our method should be an argument for its acceptance , not against . In machine learning , there is often the temptation to propose complicated \u201c highly novel \u201d approaches , many of which are never adopted . In contrast , we explicitly tried to identify the simplest approach that could produce a meaningful improvement over the current SOTA . In interpretability , we feel simplicity is particularly important , as we must consider the human component in providing simple , easy to understand insights into the model . We have found that the more complicated the interpretation method , the harder it is to convince users to use , understand , and trust the method \u2019 s output . 2 ) As R2 also pointed out , section 3.2 was too heavy with mathematical details and lacking intuition . We have now added a paragraph to the beginning of section 3.2 , which should hopefully make it clearer . To answer your question , the agglomeration algorithm was run post-hoc - ACD does not modify the original prediction of the LSTM . The agglomeration algorithm is simply an approach for constructing the hierarchy of phrases/pixels , but does not alter the CD scores produced for each node in the hierarchy . That is , the score for each node in the hierarchy is simply the CD score for that particular phrase/pixel-blob , which I believe is what you mean by \u201c CD scores for the groups/interactions of features '' . By `` agglomeratively grouped CD scores of individual features '' , I think you \u2019 re referring to the sum of the CD scores for the sub-phrases/words contained within a phrase . This value isn \u2019 t displayed in the hierarchy , as summing importance scores can \u2019 t capture interactions , such as the negation between \u201c n \u2019 t lift \u201d and \u201c this heartfelt enterprise out of the familiar. \u201d that occurs in Figure 2 . 3 ) We agree that it could be interesting to see whether CNNs and LSTMs produce similar importance scores and/or hierarchies on the same dataset , and this is something we have thought about for future work ( e.g. \u201c Do LSTMs and CNNs capture different kinds of interactions ? \u201d ) . Unfortunately , in a conference paper we don \u2019 t feel we have the space to do such an analysis in a defensible manner . Moreover , we feel the existing results are more important to justifying the main part of the paper - hierarchical interpretations . 4 ) The problem of using interpretations to improve accuracy is quite interesting , and one that we have spent a lot of time thinking about it . The short answer is that it is not immediately clear how to do so , but we are optimistic that improved interpretations like ACD should prove useful in improving model \u2019 s accuracy However , even if ACD never leads to increased prediction performance , we think it \u2019 s important to stress that there are many uses for interpretations that have no effect on predictive performance . As we discuss in the first paragraph of our introduction , in scientific applications [ 2-4 ] , it is the interpretations themselves which are the findings , and are ultimately reported in publications . In industry , interpretability is important in determining the fairness of a model [ 5 ] , and satisfying regulatory concerns [ 6 ] . Finally , as we show in our human experiments , improved interpretations help users to better trust the predictions of their models , which is helpful even if it does not change the predictions themselves . [ 1 ] https : //arxiv.org/pdf/1612.08220.pdf [ 2 ] https : //arxiv.org/abs/1702.05747 [ 3 ] https : //www.researchgate.net/publication/261538344_The_Emergence_of_Machine_Learning_Techniques_in_Criminology [ 4 ] http : //msb.embopress.org/content/12/7/878 [ 5 ] https : //arxiv.org/abs/1104.3913 [ 6 ] https : //arxiv.org/abs/1606.08813"}, "1": {"review_id": "SkEqro0ctQ-1", "review_text": "**Summary** In this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs. They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction. **Strength** 1. Splitting information into binary groups at each layer is a neat approach to segregate interpretations. 2. Experiments are elaborate and cover the breadth of the proposed method well. 3. The paper is well presented and fairly easy to follow. **Weakness** 1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](https://arxiv.org/abs/1801.05453). 2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the helpful comments . We would like to address your concerns about the novelty of the work . \u201c 1.Limited contributions in terms of novelty . This approach for RNNs is presented fairly well in the previous paper. \u201d As you correctly noted , one of the two contributions of this paper is to generalize CD from LSTMs to generic DNNs . However , we would like to clarify that the most important contribution of this paper is not generalizing CD , but introducing the concept ( and implementation ) of hierarchical importance for interpreting neural network predictions . The current state of the art for interpreting neural network predictions is word/pixel-level heat-maps , such as Figure 5 in [ 1 ] . Our main contribution is to introduce hierarchical interpretations , such as Figure 2 in our paper , and show that they improve over heat maps , the prior SOTA . In our human experiments , we compare our hierarchical interpretations ( agglomerative CD , or ACD ) against three non-hierarchical baselines , ultimately concluding that the hierarchy is in fact beneficial . We hope that we have clarified that hierarchical interpretations are the main contribution of our paper , and that this addresses your concern around the novelty of this work . To address this , we have ( slightly ) modified our introduction and method sections . We tried to make this clear throughout the paper and would welcome suggestions on how to avoid similar misunderstandings for future readers . \u201c 2.It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers. \u201d Thanks for pointing this out - we realize we omitted much of our justification in making the modifications for convolution and pooling layers . To address this , we have added some intuition in the fifth paragraph of section 3.1 . Additionally , we have added a figure in page 27 of the supplement ( Fig S5 ) showing the effect of our modifications to the update equations for convolution and ReLU layers . [ 1 ] https : //arxiv.org/pdf/1612.08220.pdf"}, "2": {"review_id": "SkEqro0ctQ-2", "review_text": "This paper proposes a hierarchical extension of contextual decomposition. The approach is validated in qualitative examples and a small scale usability study Quality, The paper is well motivated. Contextual decomposition is briefly described but detailed enough to self-contained. The experimental evaluation produces usability evidence. Uncertainty could have been better explained, Clarity, The main methodological contribution (hierarchical CD) is well motivated but only provided in the form of an algorithm. Could have been more precisely described and optimality discussed. Originality & significance The work builds heavily on CD but has the hierarchical extension is original and significant. Uncertainty estimates could have improved the significance of the usability study pros and cons + interesting problem + well-motivated algorithmic extension of CD - uncertainty of usability experiment? ", "rating": "7: Good paper, accept", "reply_text": "Thanks for the helpful comments and positive feedback . We \u2019 re glad you agree that the hierarchical notion of importance is important and well validated . We address some of your concerns below . \u201c The main methodological contribution ( hierarchical CD ) is well motivated but only provided in the form of an algorithm . Could have been more precisely described and optimality discussed. \u201d This is great feedback , we agree that we were missing a bigger picture , non-mathematical description of the algorithm . We have added a paragraph at the beginning of Section 3.2 giving intuition for our method before jumping into the technical details . \u201c Uncertainty estimates could have improved the significance of the usability study. \u201d We agree , and have updated the paper to include statistical significance results . We \u2019 ve provided the details below , but the summary is that most of the big jumps in our plots were significant , with the exception of ImageNet in plot A , where the results were only \u201c suggestive \u201d ( p values ranged from 0.07 to 0.15 ) . Overall , it seems like the benefits of ACD are in fact statistically meaningful . Statistical significance results summary : Identifying an accurate model ( one-sided two-proportion t-test ) Sentiment : gaps between ACD and IG , break-down are significant , ACD to CD is not MNIST : nothing is significant ImageNet : gaps between ACD and others are suggestive , but not significant ( p values range from 0.07 to 0.15 ) Ranking trust in model ( permutation test with mean rank test statistic ) Sentiment/ImageNet : ACD \u2019 s mean rank is significantly higher than all other methods MNIST : ACD is significantly higher than break down , everything else is not ."}}