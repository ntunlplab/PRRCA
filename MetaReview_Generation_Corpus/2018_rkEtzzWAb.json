{"year": "2018", "forum": "rkEtzzWAb", "title": "Parametric Adversarial Divergences are Good Task Losses for Generative Modeling", "decision": "Invite to Workshop Track", "meta_review": "Pros:\n - The paper proposes interesting new ideas on evaluating generative models.\n - Paper provides hints at interesting links between structural prediction and adversarial learning.\n - Authors propose a new dataset called Thin-8 to demonstrate the new ideas and argue that it is useful in general to study generative models.\n - The paper is well written and the authors have made a good attempt to update the paper after reviewer comments.\n\nCons:\n- The proposed ideas are high level and the paper lack deeper analysis.\n- Apart from demonstrating that the parametric divergences perform better than non-parametric divergences are interesting, but the reviewers think that practical importance of the results are weak in comparison to previous works.\nWith this analysis, the committee recommends this paper for workshop.", "reviews": [{"review_id": "rkEtzzWAb-0", "review_text": "This paper is in some sense a \"position paper,\" giving a framework for thinking about the loss functions implicitly used by the generator of GAN-type models. It advocates thinking about the loss in a way similar to how it is considered in structured prediction. It also proposes that approximating the dual formulation of various divergences with functions from a parametric class, as is typically done in GAN-type setups, is not only more tractable (computationally and in sample complexity) than the full nonparametric estimation, but also gives a better actual loss. Overall, I like the argument here, and think that it is a useful framework for thinking about these things. My main concern is that the practical contribution on top of Liu et al. (2017) might be somewhat limited. A few small points: - f-divergences can actually be nonparametrically estimated purely from samples, e.g. with the k-nearest neighbor estimator of https://arxiv.org/abs/1411.2045, or (for certain f-divergences) the kernel density based estimator of https://arxiv.org/abs/1402.2966. These are unlikely to lead to a practical learning algorithm, but could be mentioned in Table 1. - The discussion of MMD in the end of section 3.1 is a little off. MMD is fundamentally defined by the kernel choice; Dziugaite et al. (2015) only demonstrated that the Gaussian RBF kernel is a poor choice for MNIST modeling, while the samples of Li et al. (2015) simply by using a mixture of Gaussian kernels were much better. No reasonable fixed kernel is likely to yield good results on a harder image modeling problem, but that is a slightly different message than the one this paragraph conveys. - It would be interesting to replicate the analysis of Danihelka et al. (2017) on the Thin-8 dataset. This might help clarify which of the undesirable effects observed in the VAE model here are due to likelihood, and which due to other aspects of VAEs (like the use of the lower bound).", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for taking the time to review our paper , and for evaluating our paper as a position paper - which is indeed what we intended our paper to be . Concerning the difference with the work of Liu et al . ( 2017 ) , we refer the reviewer to Shuang Liu 's comment `` Mathematical View vs . Philosophical View '' , as well as our comment `` Difference with Liu et al . ( 2017 ) and Arora et al . ( 2017 ) '' .We have updated our related work section to better contrast our work with those works ( see the revised version ) . The bottom line is that while Liu et al . ( 2017 ) concentrate more on the mathematical properties of parametric adversarial divergences , they do not attempt to study the meaning and practical properties of parametric divergences . In our paper , we start by introducing the notion of final task , which is our true goal , but is often difficult to formalize and hard to learn from directly . We then give arguments why parametric divergences can be good approximations/surrogates for the final task at hand . To do that , we review results from the literature , establish links with structured prediction theory , and perform a series of preliminary experiments to better understand parametric divergences by attempting to answer the following questions . How are they affected by various factors : discriminator family , transformations of the dataset ? How important is the sample complexity ? How good are they at dealing with challenging datasets such as high-dimensional data , or data with abstract structure and constraints ? As you have noted , we are not claiming that we have a complete theory of parametric divergences . Rather , we are proposing new ways to think of parametric divergences , and more generally of the ( final ) task of generative modeling . We now answer the reviewer 's questions : R : `` f-divergences can actually be nonparametrically estimated purely from samples , e.g.with the k-nearest neighbor estimator of https : //arxiv.org/abs/1411.2045 , or ( for certain f-divergences ) the kernel density based estimator of https : //arxiv.org/abs/1402.2966 . These are unlikely to lead to a practical learning algorithm , but could be mentioned in Table 1 . '' A : Thank you for pointing out that there is a rich literature on estimating f-divergences from samples . We have updated section 3.1 to include some of those techniques . However , one should note that those techniques all make additional ( implicit or explicit ) assumptions on the densities . We updated the table caption and Section 3.1 to reflect that ."}, {"review_id": "rkEtzzWAb-1", "review_text": "This paper introduces a family of \"parametric adversarial divergences\" and argue that they have advantages over other divergences in generative modelling, specially for structured outputs. There's clear value in having good inductive biases (e.g. expressed in the form of the discriminator architecture) when defining divergences for practical applications. However, I think that the paper would be much more valuable if its focus shifted from presenting a new notion of divergence to deep-diving into the effect of inductive biases and presenting more specific results (theoretical and / or empirical) in structured prediction or other problems. In its current form the paper doesn't seem particularly strong for either the divergence or GAN literatures. Some reasons below: * There are no specific results on properties of the divergences, or axioms that justify them. I think that presenting a very all-encompassing formulation without a strong foundation does not add value. * There's abundant literature on f-divergences which show that there's a 1-1 relationship between divergences and optimal (Bayes) risks of classification problems (e.g. Reid at al. Information, Divergence and Risk for Binary Experiments in JMLR and Garcia-Garcia et al. Divergences and Risks for Multiclass Experiments in COLT). This disproves the point that the authors make that it's not possible to encode information about the final task in the divergence. If the loss for the task is proper, then it's well known how to construct a divergence which coincides with the optimal risk. * The divergences presented in this work are different from the above since the risk is minimised over a parametric class instead of over the whole set of integrable functions. However, practical estimators of f-divergences also reduce the optimization space (e.g. unit ball in a RKHS as in Nguyen et al. Estimating Divergence Functionals and the Likelihood Ratio by Convex Risk Minimization or Ruderman et al. Tighter Variational Representations of f-Divergences via Restriction to Probability Measures). So, given the lack of strong foundation for the formulation, \"parametric adversarial divergences\" feel more like estimators of other divergences than a relevant new family. * There are many estimators for f-divergences (like the ones cited above and many others based e.g. on nearest-neighbors) that are sample-based and thus correspond to the \"implicit\" case that the authors discuss. They don't necessarily need to use the dual form. So table 1 and the first part of Section 3.1 are not accurate. * The experiments are few and too specific, specially given that the paper presents a very general framework. The first experiment just shows that Wasserstein GANs don't perform well in an specific dataset and use that to validate a point about those GANs not being good for high dimensions due to their sample complexity. That feels like confirmation bias and also does not really say anything about the parametric adversarial GANs, which are the focus of the paper. In summary, I like the authors idea to explore the restriction of the function class of dual representations to produce useful-in-practice divergences, but the paper feels a bit middle of the road. The theory is not strong and the experiments don't necessary support the intuitive claims made in the paper.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their long and thorough review . Before we start addressing the reviewer 's concerns , we would like to make it clear that we are a position paper . We are not claiming to introduce a new family of divergences . Rather , we are giving the name of `` parametric adversarial divergence '' to the divergences which have been used recently in GANs , and attempting to better understand why they are good candidates for generative modeling . We now answer the reviewer 's points : R : `` There are no specific results on properties of the divergences , or axioms that justify them . I think that presenting a very all-encompassing formulation without a strong foundation does not add value . '' A : It 's actually very hard to obtain theoretical results for our work . What we claim is that parametric divergences can be a good approximation of our final task , which in the case of generation , is to generate realistic and diverse samples . It is not something that can be easily evaluated or proved : it is notoriously difficult to mathematically define a perceptual loss , so it 's not obvious how to prove rigorously that parametric divergences approximate the perceptual loss well , other than by looking at samples , or using meaningful but debatable proxies such as inception score . R : `` There 's abundant literature on f-divergences which show that there 's a 1-1 relationship between divergences and optimal ( Bayes ) risks of classification problems ( e.g.Reid at al . Information , Divergence and Risk for Binary Experiments in JMLR and Garcia-Garcia et al.Divergences and Risks for Multiclass Experiments in COLT ) . This disproves the point that the authors make that it 's not possible to encode information about the final task in the divergence . If the loss for the task is proper , then it 's well known how to construct a divergence which coincides with the optimal risk . '' A : What you are referring to is the equivalence between computing a divergence and solving a classification problem . This is seen in GANs as the discriminator is solving a classification problem with the appropriate loss between two distributions p and q , the loss of which corresponds to the divergence between p and q . In fact , by choosing the appropriate losses one can recover any f-divergence and any IPM ( it corresponds to choosing the Delta in equation 1 of our paper ) . However the binary loss here is very different from what we call task loss or final loss . The final loss is what we actually care about ( images that respect perspective , that are not blurry , made of full objects ) . Instead the loss you are referring to is a loss that defines the binary classification problem between p and q . We updated the paper to include your references . Originally we were based on the work of Sriperumbudur et al 2012 . Thank you for helping us complete the references ."}, {"review_id": "rkEtzzWAb-2", "review_text": "This paper takes some steps in the direction of understanding adversarial learning/GAN and relating GANs and structured prediction under statistical decision theory framework. One of the main contribution of the paper is to study/analyze parametric adversarial divergences and link it with structured losses. Although, I see a value in the idea considered in the paper, it is not clear to me how much novelty does this work bring on top of the following two papers: 1) S. Liu. Approximation and convergence properties of generative adversarial learning. In NIPS, 2017. 2) S. Arora. Generalization and equilibrium in generative adversarial nets (GANs). In ICML, 2017. Most of their theoretical results seems to be already existing in literature (Liu, Arora, Arjovsky) in some form of other and it is claimed that this paper put these result in perspective in an attempt to provide a more principled view of the nature and usefulness of adversarial divergences, in comparison to traditional divergences. However, it seems to me that the paper is limited both in theoretical novelty and practical usefulness of these results. Especially, I could not see any novel contribution for GAN literature or adversarial divergences. I would suggests authors to clearly specify novelties and contrast their work with 1) GAN literature: ([2] Arora's results) 2) Adversarial divergences literature: ([1] Liu) Also, provide more experiments to support several claims (without any rigorous theoretical justifications) made in the paper.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for taking the time to review our paper . We now answer the reviewer \u2019 s comments and questions . R : \u201c Most of their theoretical results seems to be already existing in literature ( Liu , Arora , Arjovsky ) in some form of other and it is claimed that this paper put these result in perspective in an attempt to provide a more principled view of the nature and usefulness of adversarial divergences , in comparison to traditional divergences. \u201d Concerning the difference with the work of Liu et al . ( 2017 ) , we refer the reviewer to Shuang Liu 's comment `` Mathematical View vs . Philosophical View '' , as well as our comment `` Difference with Liu et al . ( 2017 ) and Arora et al . ( 2017 ) '' .Concerning the difference with the work of Arora et al . ( 2017 ) , we also refer the reviewer to our comment `` Difference with Liu et al . ( 2017 ) and Arora et al . ( 2017 ) '' .We have updated our related work section to better contrast our work with those works . The bottom line is that those works focus on specific mathematical properties of parametric divergences . Arora et al . ( 2017 ) focus on statistical efficiency of parametric divergences . Liu et al . ( 2017 ) focus on topological properties of adversarial divergences and the mathematical interpretation of minimizing neural divergences ( in a nutshell : matching moments ) . However , neither of those works attempts to study the meaning and practical properties of parametric divergences . In our paper , we start by introducing the notion of final task , which is our true goal , but is often difficult to formalize and hard to learn from directly . We then give arguments why parametric divergences can be good approximations/surrogates for the final task at hand . To do that , we review results from the literature , establish links with structured prediction theory , and perform a series of preliminary experiments to better understand parametric divergences by attempting to answer the following questions . How are they affected by various factors : discriminator family , transformations of the dataset ? How important is the sample complexity ? How good are they at dealing with challenging datasets such as high-dimensional data , or data with abstract structure and constraints ? R : \u201c However , it seems to me that the paper is limited both in theoretical novelty and practical usefulness of these results . Especially , I could not see any novel contribution for GAN literature or adversarial divergences. \u201d A : Here are some potential contributions to the adversarial divergence literature : - it is often believed in the GAN literature that weaker losses ( in the topological sense ) are easier to learn than stronger losses . There has indeed been work in the adversarial divergence literature on the relative strength and convergence properties of adversarial divergences . However , to the best of our knowledge , there is no rigorous theory that explains why weaker losses are easier to learn . By relating adversarial divergences used in generative modeling with the task losses used in structured prediction , we put into perspective some theoretical results from structured prediction theory that actually show and quantify how the strength of the objective affects the ease of learning the model . Because those results are consistent with the intuition that weaker divergences are easier to learn , they give additional reasons to think that this intuition is correct . We take this opportunity to emphasize that it is highly non-trivial to derive a rigorous theory on quantifying which divergences are better for learning . Unlike structured prediction , where the task loss is also used for evaluating the learned model , there is no one good way of evaluating generative models yet . Because a rigorous theory should study the influence of minimizing a divergence on minimizing the evaluation metric , any theory that is derived on divergences can only be as meaningful as the evaluation metric considered ."}], "0": {"review_id": "rkEtzzWAb-0", "review_text": "This paper is in some sense a \"position paper,\" giving a framework for thinking about the loss functions implicitly used by the generator of GAN-type models. It advocates thinking about the loss in a way similar to how it is considered in structured prediction. It also proposes that approximating the dual formulation of various divergences with functions from a parametric class, as is typically done in GAN-type setups, is not only more tractable (computationally and in sample complexity) than the full nonparametric estimation, but also gives a better actual loss. Overall, I like the argument here, and think that it is a useful framework for thinking about these things. My main concern is that the practical contribution on top of Liu et al. (2017) might be somewhat limited. A few small points: - f-divergences can actually be nonparametrically estimated purely from samples, e.g. with the k-nearest neighbor estimator of https://arxiv.org/abs/1411.2045, or (for certain f-divergences) the kernel density based estimator of https://arxiv.org/abs/1402.2966. These are unlikely to lead to a practical learning algorithm, but could be mentioned in Table 1. - The discussion of MMD in the end of section 3.1 is a little off. MMD is fundamentally defined by the kernel choice; Dziugaite et al. (2015) only demonstrated that the Gaussian RBF kernel is a poor choice for MNIST modeling, while the samples of Li et al. (2015) simply by using a mixture of Gaussian kernels were much better. No reasonable fixed kernel is likely to yield good results on a harder image modeling problem, but that is a slightly different message than the one this paragraph conveys. - It would be interesting to replicate the analysis of Danihelka et al. (2017) on the Thin-8 dataset. This might help clarify which of the undesirable effects observed in the VAE model here are due to likelihood, and which due to other aspects of VAEs (like the use of the lower bound).", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for taking the time to review our paper , and for evaluating our paper as a position paper - which is indeed what we intended our paper to be . Concerning the difference with the work of Liu et al . ( 2017 ) , we refer the reviewer to Shuang Liu 's comment `` Mathematical View vs . Philosophical View '' , as well as our comment `` Difference with Liu et al . ( 2017 ) and Arora et al . ( 2017 ) '' .We have updated our related work section to better contrast our work with those works ( see the revised version ) . The bottom line is that while Liu et al . ( 2017 ) concentrate more on the mathematical properties of parametric adversarial divergences , they do not attempt to study the meaning and practical properties of parametric divergences . In our paper , we start by introducing the notion of final task , which is our true goal , but is often difficult to formalize and hard to learn from directly . We then give arguments why parametric divergences can be good approximations/surrogates for the final task at hand . To do that , we review results from the literature , establish links with structured prediction theory , and perform a series of preliminary experiments to better understand parametric divergences by attempting to answer the following questions . How are they affected by various factors : discriminator family , transformations of the dataset ? How important is the sample complexity ? How good are they at dealing with challenging datasets such as high-dimensional data , or data with abstract structure and constraints ? As you have noted , we are not claiming that we have a complete theory of parametric divergences . Rather , we are proposing new ways to think of parametric divergences , and more generally of the ( final ) task of generative modeling . We now answer the reviewer 's questions : R : `` f-divergences can actually be nonparametrically estimated purely from samples , e.g.with the k-nearest neighbor estimator of https : //arxiv.org/abs/1411.2045 , or ( for certain f-divergences ) the kernel density based estimator of https : //arxiv.org/abs/1402.2966 . These are unlikely to lead to a practical learning algorithm , but could be mentioned in Table 1 . '' A : Thank you for pointing out that there is a rich literature on estimating f-divergences from samples . We have updated section 3.1 to include some of those techniques . However , one should note that those techniques all make additional ( implicit or explicit ) assumptions on the densities . We updated the table caption and Section 3.1 to reflect that ."}, "1": {"review_id": "rkEtzzWAb-1", "review_text": "This paper introduces a family of \"parametric adversarial divergences\" and argue that they have advantages over other divergences in generative modelling, specially for structured outputs. There's clear value in having good inductive biases (e.g. expressed in the form of the discriminator architecture) when defining divergences for practical applications. However, I think that the paper would be much more valuable if its focus shifted from presenting a new notion of divergence to deep-diving into the effect of inductive biases and presenting more specific results (theoretical and / or empirical) in structured prediction or other problems. In its current form the paper doesn't seem particularly strong for either the divergence or GAN literatures. Some reasons below: * There are no specific results on properties of the divergences, or axioms that justify them. I think that presenting a very all-encompassing formulation without a strong foundation does not add value. * There's abundant literature on f-divergences which show that there's a 1-1 relationship between divergences and optimal (Bayes) risks of classification problems (e.g. Reid at al. Information, Divergence and Risk for Binary Experiments in JMLR and Garcia-Garcia et al. Divergences and Risks for Multiclass Experiments in COLT). This disproves the point that the authors make that it's not possible to encode information about the final task in the divergence. If the loss for the task is proper, then it's well known how to construct a divergence which coincides with the optimal risk. * The divergences presented in this work are different from the above since the risk is minimised over a parametric class instead of over the whole set of integrable functions. However, practical estimators of f-divergences also reduce the optimization space (e.g. unit ball in a RKHS as in Nguyen et al. Estimating Divergence Functionals and the Likelihood Ratio by Convex Risk Minimization or Ruderman et al. Tighter Variational Representations of f-Divergences via Restriction to Probability Measures). So, given the lack of strong foundation for the formulation, \"parametric adversarial divergences\" feel more like estimators of other divergences than a relevant new family. * There are many estimators for f-divergences (like the ones cited above and many others based e.g. on nearest-neighbors) that are sample-based and thus correspond to the \"implicit\" case that the authors discuss. They don't necessarily need to use the dual form. So table 1 and the first part of Section 3.1 are not accurate. * The experiments are few and too specific, specially given that the paper presents a very general framework. The first experiment just shows that Wasserstein GANs don't perform well in an specific dataset and use that to validate a point about those GANs not being good for high dimensions due to their sample complexity. That feels like confirmation bias and also does not really say anything about the parametric adversarial GANs, which are the focus of the paper. In summary, I like the authors idea to explore the restriction of the function class of dual representations to produce useful-in-practice divergences, but the paper feels a bit middle of the road. The theory is not strong and the experiments don't necessary support the intuitive claims made in the paper.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their long and thorough review . Before we start addressing the reviewer 's concerns , we would like to make it clear that we are a position paper . We are not claiming to introduce a new family of divergences . Rather , we are giving the name of `` parametric adversarial divergence '' to the divergences which have been used recently in GANs , and attempting to better understand why they are good candidates for generative modeling . We now answer the reviewer 's points : R : `` There are no specific results on properties of the divergences , or axioms that justify them . I think that presenting a very all-encompassing formulation without a strong foundation does not add value . '' A : It 's actually very hard to obtain theoretical results for our work . What we claim is that parametric divergences can be a good approximation of our final task , which in the case of generation , is to generate realistic and diverse samples . It is not something that can be easily evaluated or proved : it is notoriously difficult to mathematically define a perceptual loss , so it 's not obvious how to prove rigorously that parametric divergences approximate the perceptual loss well , other than by looking at samples , or using meaningful but debatable proxies such as inception score . R : `` There 's abundant literature on f-divergences which show that there 's a 1-1 relationship between divergences and optimal ( Bayes ) risks of classification problems ( e.g.Reid at al . Information , Divergence and Risk for Binary Experiments in JMLR and Garcia-Garcia et al.Divergences and Risks for Multiclass Experiments in COLT ) . This disproves the point that the authors make that it 's not possible to encode information about the final task in the divergence . If the loss for the task is proper , then it 's well known how to construct a divergence which coincides with the optimal risk . '' A : What you are referring to is the equivalence between computing a divergence and solving a classification problem . This is seen in GANs as the discriminator is solving a classification problem with the appropriate loss between two distributions p and q , the loss of which corresponds to the divergence between p and q . In fact , by choosing the appropriate losses one can recover any f-divergence and any IPM ( it corresponds to choosing the Delta in equation 1 of our paper ) . However the binary loss here is very different from what we call task loss or final loss . The final loss is what we actually care about ( images that respect perspective , that are not blurry , made of full objects ) . Instead the loss you are referring to is a loss that defines the binary classification problem between p and q . We updated the paper to include your references . Originally we were based on the work of Sriperumbudur et al 2012 . Thank you for helping us complete the references ."}, "2": {"review_id": "rkEtzzWAb-2", "review_text": "This paper takes some steps in the direction of understanding adversarial learning/GAN and relating GANs and structured prediction under statistical decision theory framework. One of the main contribution of the paper is to study/analyze parametric adversarial divergences and link it with structured losses. Although, I see a value in the idea considered in the paper, it is not clear to me how much novelty does this work bring on top of the following two papers: 1) S. Liu. Approximation and convergence properties of generative adversarial learning. In NIPS, 2017. 2) S. Arora. Generalization and equilibrium in generative adversarial nets (GANs). In ICML, 2017. Most of their theoretical results seems to be already existing in literature (Liu, Arora, Arjovsky) in some form of other and it is claimed that this paper put these result in perspective in an attempt to provide a more principled view of the nature and usefulness of adversarial divergences, in comparison to traditional divergences. However, it seems to me that the paper is limited both in theoretical novelty and practical usefulness of these results. Especially, I could not see any novel contribution for GAN literature or adversarial divergences. I would suggests authors to clearly specify novelties and contrast their work with 1) GAN literature: ([2] Arora's results) 2) Adversarial divergences literature: ([1] Liu) Also, provide more experiments to support several claims (without any rigorous theoretical justifications) made in the paper.", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for taking the time to review our paper . We now answer the reviewer \u2019 s comments and questions . R : \u201c Most of their theoretical results seems to be already existing in literature ( Liu , Arora , Arjovsky ) in some form of other and it is claimed that this paper put these result in perspective in an attempt to provide a more principled view of the nature and usefulness of adversarial divergences , in comparison to traditional divergences. \u201d Concerning the difference with the work of Liu et al . ( 2017 ) , we refer the reviewer to Shuang Liu 's comment `` Mathematical View vs . Philosophical View '' , as well as our comment `` Difference with Liu et al . ( 2017 ) and Arora et al . ( 2017 ) '' .Concerning the difference with the work of Arora et al . ( 2017 ) , we also refer the reviewer to our comment `` Difference with Liu et al . ( 2017 ) and Arora et al . ( 2017 ) '' .We have updated our related work section to better contrast our work with those works . The bottom line is that those works focus on specific mathematical properties of parametric divergences . Arora et al . ( 2017 ) focus on statistical efficiency of parametric divergences . Liu et al . ( 2017 ) focus on topological properties of adversarial divergences and the mathematical interpretation of minimizing neural divergences ( in a nutshell : matching moments ) . However , neither of those works attempts to study the meaning and practical properties of parametric divergences . In our paper , we start by introducing the notion of final task , which is our true goal , but is often difficult to formalize and hard to learn from directly . We then give arguments why parametric divergences can be good approximations/surrogates for the final task at hand . To do that , we review results from the literature , establish links with structured prediction theory , and perform a series of preliminary experiments to better understand parametric divergences by attempting to answer the following questions . How are they affected by various factors : discriminator family , transformations of the dataset ? How important is the sample complexity ? How good are they at dealing with challenging datasets such as high-dimensional data , or data with abstract structure and constraints ? R : \u201c However , it seems to me that the paper is limited both in theoretical novelty and practical usefulness of these results . Especially , I could not see any novel contribution for GAN literature or adversarial divergences. \u201d A : Here are some potential contributions to the adversarial divergence literature : - it is often believed in the GAN literature that weaker losses ( in the topological sense ) are easier to learn than stronger losses . There has indeed been work in the adversarial divergence literature on the relative strength and convergence properties of adversarial divergences . However , to the best of our knowledge , there is no rigorous theory that explains why weaker losses are easier to learn . By relating adversarial divergences used in generative modeling with the task losses used in structured prediction , we put into perspective some theoretical results from structured prediction theory that actually show and quantify how the strength of the objective affects the ease of learning the model . Because those results are consistent with the intuition that weaker divergences are easier to learn , they give additional reasons to think that this intuition is correct . We take this opportunity to emphasize that it is highly non-trivial to derive a rigorous theory on quantifying which divergences are better for learning . Unlike structured prediction , where the task loss is also used for evaluating the learned model , there is no one good way of evaluating generative models yet . Because a rigorous theory should study the influence of minimizing a divergence on minimizing the evaluation metric , any theory that is derived on divergences can only be as meaningful as the evaluation metric considered ."}}