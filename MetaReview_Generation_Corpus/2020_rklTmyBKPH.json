{"year": "2020", "forum": "rklTmyBKPH", "title": "Fast Neural Network Adaptation via Parameter Remapping and Architecture Search", "decision": "Accept (Poster)", "meta_review": "Main content: Paper proposes a fast network adaptation (FNA) method, which takes a pre-trained image classification network, and produces a network for the task of object detection/semantic segmentation\n\nSummary of discussion:\nreviewer1: interesting paper with good results, specifically without the need to do pre-training on Imagenet. Cons are better comparisons to existing methods and run on more datasets. \nreviewer2:  interesting idea on adapting source network network via parameter re-mapping that offers good results in both performance and training time.\nreviewer3: novel method overall, though some concerns on the concrete parameter remapping scheme. Results are impressive\nRecommendation: Interesting idea and good results. Paper could be improved with better comparison to existing techniques. Overall recommend weak accept.", "reviews": [{"review_id": "rklTmyBKPH-0", "review_text": "In this paper, the authors take a MobileNet v2 trained for ImageNet classification, and adapt it either (i) semantic segmentation on Cityscapes, or (ii) object detection on COCO. They do this by first expanding the network into a \"supernet\" and copy weights in an ad-hoc manner, then, they perform DARTS-style architecture search before fine-tuning for the task at hand. There is no TLDR for this paper, and I must admit, on reading the abstract and introduction I wasn't entirely sure what this paper was doing at first. Perhaps I was being slow. From a narrative perspective, one of the main selling points is not needing to perform any expensive ImageNet pre-training; however, a pre-trained MobileNetv2 is being utilised. While this was off-the-shelf, it still incurred an initial training cost, so it isn't really fair in e.g. Table 4 to put pre-training cost as zero. On a related note, the authors write that this network is used for its \"generality\". I'd argue that MobileNetv2 is a highly engineered network specialised for mobile computation; a standard ResNet-50 would be more general really. I would like to see a comparison to a random search, as there are several papers (https://arxiv.org/abs/1902.07638, https://arxiv.org/abs/1902.08142) indicating that this is a very strong baseline. As mentioned earlier, the choices for remapping weights seem very ad-hoc. I can't really tell what's going on in Table 5 (why is PR in the NE and PA row?) so the ablation study of how effective this weight mapping is lost on me. The stuff in Table 6 is pretty interesting however, if convoluted. I find the odd choices of hyperparameters (tau as 45, gamma as 10, lambda as 9e-3) rather alarming. How important are these? Would this technique work under any other circumstances? Error bars would be a welcome inclusion, particularly in Table 3 where you have 0.1% separating FNA and MNasnet-92. I appreciate that this can be expensive however. Pros: - Some promising results - Good figures Cons: - Ad-hoc design choices - Not a fair comparison regarding pre-training. - Very specific to one network choice - Lack of error bars or comparison to random search. I am giving this paper a weak reject, as there is insufficient experimental evidence that the technique works, or generalises beyond Mobilenetv2. I am also concerned about the ad-hoc hyperparmaters or weight-mapping. A comprehensive ablation study, along with error bars, and another choice of seed network would do much to strengthen this paper. ", "rating": "6: Weak Accept", "reply_text": "We sincerely thank you for your detailed review and constructive suggestions . Our proposed FNA aims at adapting the pre-trained neural network to new tasks efficiently with a novel parameter remapping mechanism . Inspired by the influential work Net2Net [ 1 ] which proposes an effective method for mapping the parameters of one network to a deeper and wider one , we propose a novel and effective parameter remapping scheme . With the remapping scheme , the parameters of one seed network can be remapped to the super network or the target network . The mapping dimension is further extended to the kernel level . And the proposed parameter remapping method can map parameters to shallower and narrower networks while Net2Net does not cover these perspectives . It is not an ad-hoc design choice as we explore various reasonable strategies in the experiments . The results show that our method achieves superior performances and our mechanism is more convenient to implement compared to others . Our proposed FNA is not only a NAS method , while it is a general framework to adapt the network to various tasks . FNA demonstrates the effectiveness of both segmentation and detection tasks in the experiments and beats state-of-the-art NAS-based detection and segmentation methods , while prior works mostly focus on only one task as Reviewer1 also mentions this . FNA is meaningful for researchers to carry out network optimization on various new tasks that bear the unaffordable pre-training cost as there are lots of available pre-trained models in the community . We hope our statement can clarify the core value of our work . > > > Response to `` no TLDR for this paper '' : We are sorry that our abstract and introduction do not illustrate our main idea or contribution clearly . We will revise the paper detailedly in the next version . We supplement the TLDR as follows . We propose a fast neural network adaptation ( FNA ) method to adapt a seed network with pre-trained weights to other new tasks . A parameter remapping mechanism is designed to accelerate the whole adaptation process which takes full advantage of the knowledge from the seed network . > > > Response to `` it is n't really fair in Table 4 to put pre-training cost as zero '' : Firstly , our proposed method aims at the available pre-trained models in the community as there are many of them . Secondly , the seed network in FNA has strong reusability . For example , if the search space changes due to the need for the task , the super network in other methods , e.g.DetNAS , needs to be pre-trained again . But the super network of FNA does not need to be pre-trained . All the pre-trained weights of the super network are remapped from the same seed network . It is totally a once-for-all manner . Even though we take the pre-trained cost of the seed network into consideration , FNA still holds a huge advantage with the perspective of both performance and computation cost . We show the comparison as follows . | Method | Total Cost | Super Network | Target Network | |_____________|____________| Pre-training |Finetuning | Search | Pre-training | Finetuning | | DetNAS [ 2 ] | 68 GDs | 12 GDs |12 GDs | 20 GDs | 12 GDs | 12 GDs | | FNA | 15.9 GDs | 6.7 GDs | - | 6 GDs | - | 3.2 GDs | > > > Response to `` the generality of the seed network '' : Sorry for this unclearness of the description of the seed network choice . We choose MobileNetV2 because it is widely used for the search space design in many NAS methods [ 3 , 4 , 5 , 6 ] . But we would like to try our best to implement the FNA method on the ResNet model before the rebuttal deadline . > > > Response to `` a comparison to a random search '' : We will provide the experiment result of the random search . Thanks for your constructive advice . Besides , our method aims to adapt the off-the-shelf network to other new tasks . NAS is only an implementation tool for architecture adaptation . Which NAS method we use is not the focus of our method indeed ."}, {"review_id": "rklTmyBKPH-1", "review_text": "This paper provides a new technique to adapt a source neural network performed well on classification task to image segmentation and objective detection tasks via the author called parameter-remapping trick. The parameter remapping uses weights from the source neural network to the two-stages: architecture adaption phase and parameter adaption phase. The technique results in improvements in both performance and training time. I like the direction this paper takes, NAS is too expensive and we need faster methods through meta learning/transfer learning. The paper is also clearly organized and written. To the best of my knowledge, the experiments setting is sensible and the results are good. But I am not in the Computer Vision field and I am not so familiar with NAS, I may missed something. Thus, I am less confident about my rating.", "rating": "6: Weak Accept", "reply_text": "We sincerely thank you for your review and assessment of our work . Our proposed FNA method can adapt a network with pre-trained weights to other new tasks efficiently . The total computation cost of FNA is far smaller compared to other SOTA methods . We conduct sufficient experiments to demonstrate the effectiveness of our method and FNA achieves superior performances on various tasks . Moreover , it is convenient to apply FNA on more other tasks , e.g. , pose estimation , face detection , NLP , speech recognition , etc . As there are lots of pre-trained models available in the community , FNA can help researchers who can not afford expensive computation cost explore the model optimization on all kinds of tasks . FNA even makes NAS more accessible for more researchers ."}, {"review_id": "rklTmyBKPH-2", "review_text": " The paper proposes a method called FNA (fast network adaptation), which takes a pretrained image classification network, and produces a network for the task of object detection/semantic segmentation. The process consists of three phases: Network Expansion, Architecture Adaptation and Parameters Adaptation, and uses the developed parameter remapping scheme twice. Experiments show that it outperforms recent other NAS methods for these two tasks with same or less computation. Concrete comments 1. The paper's overall method is a novel one, unifying NAS on det/seg tasks, while prior works mostly only focus on one task. It also \"eliminates\" the need for pretraining each instance of the subnetwork. But no one ever pretrain every classification network for searching on det/seg tasks right? It's an insane amount of computation after all. I'm afraid the emphasis of advantage over prior method here is not very accurate. 2. The concrete parameter remapping scheme is not entirely novel. It is similar to the Net2Net method, while seems more naive than that. It does not preserve the mapping function like Net2Net. It seems like a very coarse effort, since mostly what you do is to copy weights, remove weights or fill in zeros. But it is also interesting to see that this naive method works, and actually beat some of the more advanced alternatives in Section 4. 3. The results are quite impressive. On segmentation, the adapted model achieves ~1% mIOU improvement using similar or less iterations and similar size of model with the methods it compared to, and GPU hours' saving is more significant. If the authors faithfully compared with state-of-the-art methods in search det/seg architectures, but I'm not super familiar with this literature. On object detection the method does not improve the model size or accuracy, but reduces the search time a lot compared with DetNAS. Could the authors clarify that you compared with every recent high-performance NAS method on seg/det tasks? 4. Though the improvement over prior methods is good, the experiments lack an apple-to-apple comparison. For example, using exactly the same NAS search method and supernet, and comparing the FNA method with that not using a pretrained model (i.e., directly search on det/seg) could be a good experiment to showcase the importance of adaptation. Overall I find the method is effective and experiments convincing and I recommend weak accept in my rating. I hope authors can address my concerns in the rebuttal. ", "rating": "6: Weak Accept", "reply_text": "We sincerely thank you for your detailed and constructive comments . 1.We would like to revise the description part of the advantages over prior methods . Our main point aims at taking full advantage of the pre-trained weights of the seed network , which is essential for fast neural architecture search and parameter adaptation . Our parameter remapping mechanism accelerates the whole procedures greatly which makes it easy to conduct the network adaptation on different tasks . 2.Our parameter remapping method does have some similar effects with Net2Net . However , they are quite different . Net2Net aims at deepening and widening the network and accelerates the training procedure . In Net2Net , parameters can only be mapped on the depth and width level . We extend the mapping dimension with the kernel level . Parameters can be also mapped to a shallower or narrower network with our remapping scheme , while Net2Net only maps parameters to a deeper and wider network . We deploy FNA in the popular efficient model MobileNetV2 . Compared with those seemingly more advanced methods , the parameter remapping mechanism of FNA is easier to implement and achieves the best results . Moreover , exploring more effective parameter remapping methods is actually a valuable topic , as we do in Sec.4.4.3.DetNAS [ 1 ] is the latest detection backbone search work that achieves SOTA results and has been accepted in NeurIPS 2019 . Our comparison is sufficient and fair . Furthermore , in RetinaNet , FNA achieves 0.6 accuracy promotion and MAdds is 0.23B smaller compared with DetNAS . In SSDLite , FNA achieves 0.1 accuracy promotion with 100M fewer MAdds compared with MnasNet [ 2 ] . MnasNet takes a huge cost ( around 3,800 GPU days ) to search the architecture on the ImageNet classification task . MnasNet also achieves SOTA results on the SSDLite framework . The computation cost of FNA is apparently smaller , 176x less than MnasNet . 4.We are sorry for the vagueness of Tab . 5 in the paper . Actually , we conduct sufficient apple-to-apple comparison experiments in Sec.4.3 to showcase the effectiveness of parameter remapping in the network adaptation . We revise Tab . 5 as follows for clearer illustration . Row Num Method MAdds ( G ) mIOU ( % ) ( 1 ) Remap - > ArchAdapt - > Remap - > ParamAdapt ( FNA ) 24.17 76.6 ( 2 ) RandInit - > ArchAdapt - > Remap - > ParamAdapt 24.29 76.0 ( 3 ) Remap - > ArchAdapt - > RandInit - > ParamAdapt 24.17 73.0 ( 4 ) RandInit - > ArchAdapt - > RandInit - > ParamAdapt 24.29 72.4 ( 5 ) Remap - > ArchAdapt - > Retrain - > ParamAdapt 24.17 76.5 Remap : Parameter Remapping . ArchAdapt : Architecture Adaptation . RandInit : Random Initialization . Pretrain : ImageNet Pretrain . ParamAdapt : Parameter Adaptation . We attempt to optionally remove the parameter remapping process before the two stages , i.e.architecture adaptation and parameter adaptation . In Row ( 2 ) we remove the parameter remapping process before architecture adaptation . In other words , the search is performed from scratch without using the pre-trained network . The mIOU in Row ( 2 ) drops by 0.6 % compared to FNA in Row ( 1 ) . Then we remove the parameter remapping before parameter adaptation in Row ( 3 ) , i.e.training the target architecture from scratch on the target task . The mIOU decreases by 3.6 % compared to the result of FNA . When we remove the parameter remapping before both stages in Row ( 4 ) , it gets the worst performance . In Row ( 5 ) , we first pre-train the searched architecture on ImageNet and then fine-tune it on the target task . It is worth noting that FNA even achieves a higher mIOU by a narrow margin ( 0.1 % ) than the ImageNet pre-trained one in Row ( 5 ) . We conjecture that this may benefit from the regularization effect of parameter remapping before the parameter adaptation stage . All the experiments are conducted using the same searching and training settings for fair comparisons . With parameters remapping applied on both stages , the adaptation achieves the best results . Especially , the remapping process before parameter adaptation tends to provide greater performance gains than the remapping before architecture adaptation . All the experimental results demonstrate the importance and effectiveness of the proposed parameter remapping scheme . We revise this part in the new version of our paper . We thank for your detailed review once again and hope that our response can address your concerns . [ 1 ] Chen Y , Yang T , Zhang X , et al.Detnas : Neural architecture search on object detection [ J ] . NeurIPS , 2019 . [ 2 ] Tan M , Chen B , Pang R , et al.Mnasnet : Platform-aware neural architecture search for mobile [ C ] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 2019 : 2820-2828 ."}], "0": {"review_id": "rklTmyBKPH-0", "review_text": "In this paper, the authors take a MobileNet v2 trained for ImageNet classification, and adapt it either (i) semantic segmentation on Cityscapes, or (ii) object detection on COCO. They do this by first expanding the network into a \"supernet\" and copy weights in an ad-hoc manner, then, they perform DARTS-style architecture search before fine-tuning for the task at hand. There is no TLDR for this paper, and I must admit, on reading the abstract and introduction I wasn't entirely sure what this paper was doing at first. Perhaps I was being slow. From a narrative perspective, one of the main selling points is not needing to perform any expensive ImageNet pre-training; however, a pre-trained MobileNetv2 is being utilised. While this was off-the-shelf, it still incurred an initial training cost, so it isn't really fair in e.g. Table 4 to put pre-training cost as zero. On a related note, the authors write that this network is used for its \"generality\". I'd argue that MobileNetv2 is a highly engineered network specialised for mobile computation; a standard ResNet-50 would be more general really. I would like to see a comparison to a random search, as there are several papers (https://arxiv.org/abs/1902.07638, https://arxiv.org/abs/1902.08142) indicating that this is a very strong baseline. As mentioned earlier, the choices for remapping weights seem very ad-hoc. I can't really tell what's going on in Table 5 (why is PR in the NE and PA row?) so the ablation study of how effective this weight mapping is lost on me. The stuff in Table 6 is pretty interesting however, if convoluted. I find the odd choices of hyperparameters (tau as 45, gamma as 10, lambda as 9e-3) rather alarming. How important are these? Would this technique work under any other circumstances? Error bars would be a welcome inclusion, particularly in Table 3 where you have 0.1% separating FNA and MNasnet-92. I appreciate that this can be expensive however. Pros: - Some promising results - Good figures Cons: - Ad-hoc design choices - Not a fair comparison regarding pre-training. - Very specific to one network choice - Lack of error bars or comparison to random search. I am giving this paper a weak reject, as there is insufficient experimental evidence that the technique works, or generalises beyond Mobilenetv2. I am also concerned about the ad-hoc hyperparmaters or weight-mapping. A comprehensive ablation study, along with error bars, and another choice of seed network would do much to strengthen this paper. ", "rating": "6: Weak Accept", "reply_text": "We sincerely thank you for your detailed review and constructive suggestions . Our proposed FNA aims at adapting the pre-trained neural network to new tasks efficiently with a novel parameter remapping mechanism . Inspired by the influential work Net2Net [ 1 ] which proposes an effective method for mapping the parameters of one network to a deeper and wider one , we propose a novel and effective parameter remapping scheme . With the remapping scheme , the parameters of one seed network can be remapped to the super network or the target network . The mapping dimension is further extended to the kernel level . And the proposed parameter remapping method can map parameters to shallower and narrower networks while Net2Net does not cover these perspectives . It is not an ad-hoc design choice as we explore various reasonable strategies in the experiments . The results show that our method achieves superior performances and our mechanism is more convenient to implement compared to others . Our proposed FNA is not only a NAS method , while it is a general framework to adapt the network to various tasks . FNA demonstrates the effectiveness of both segmentation and detection tasks in the experiments and beats state-of-the-art NAS-based detection and segmentation methods , while prior works mostly focus on only one task as Reviewer1 also mentions this . FNA is meaningful for researchers to carry out network optimization on various new tasks that bear the unaffordable pre-training cost as there are lots of available pre-trained models in the community . We hope our statement can clarify the core value of our work . > > > Response to `` no TLDR for this paper '' : We are sorry that our abstract and introduction do not illustrate our main idea or contribution clearly . We will revise the paper detailedly in the next version . We supplement the TLDR as follows . We propose a fast neural network adaptation ( FNA ) method to adapt a seed network with pre-trained weights to other new tasks . A parameter remapping mechanism is designed to accelerate the whole adaptation process which takes full advantage of the knowledge from the seed network . > > > Response to `` it is n't really fair in Table 4 to put pre-training cost as zero '' : Firstly , our proposed method aims at the available pre-trained models in the community as there are many of them . Secondly , the seed network in FNA has strong reusability . For example , if the search space changes due to the need for the task , the super network in other methods , e.g.DetNAS , needs to be pre-trained again . But the super network of FNA does not need to be pre-trained . All the pre-trained weights of the super network are remapped from the same seed network . It is totally a once-for-all manner . Even though we take the pre-trained cost of the seed network into consideration , FNA still holds a huge advantage with the perspective of both performance and computation cost . We show the comparison as follows . | Method | Total Cost | Super Network | Target Network | |_____________|____________| Pre-training |Finetuning | Search | Pre-training | Finetuning | | DetNAS [ 2 ] | 68 GDs | 12 GDs |12 GDs | 20 GDs | 12 GDs | 12 GDs | | FNA | 15.9 GDs | 6.7 GDs | - | 6 GDs | - | 3.2 GDs | > > > Response to `` the generality of the seed network '' : Sorry for this unclearness of the description of the seed network choice . We choose MobileNetV2 because it is widely used for the search space design in many NAS methods [ 3 , 4 , 5 , 6 ] . But we would like to try our best to implement the FNA method on the ResNet model before the rebuttal deadline . > > > Response to `` a comparison to a random search '' : We will provide the experiment result of the random search . Thanks for your constructive advice . Besides , our method aims to adapt the off-the-shelf network to other new tasks . NAS is only an implementation tool for architecture adaptation . Which NAS method we use is not the focus of our method indeed ."}, "1": {"review_id": "rklTmyBKPH-1", "review_text": "This paper provides a new technique to adapt a source neural network performed well on classification task to image segmentation and objective detection tasks via the author called parameter-remapping trick. The parameter remapping uses weights from the source neural network to the two-stages: architecture adaption phase and parameter adaption phase. The technique results in improvements in both performance and training time. I like the direction this paper takes, NAS is too expensive and we need faster methods through meta learning/transfer learning. The paper is also clearly organized and written. To the best of my knowledge, the experiments setting is sensible and the results are good. But I am not in the Computer Vision field and I am not so familiar with NAS, I may missed something. Thus, I am less confident about my rating.", "rating": "6: Weak Accept", "reply_text": "We sincerely thank you for your review and assessment of our work . Our proposed FNA method can adapt a network with pre-trained weights to other new tasks efficiently . The total computation cost of FNA is far smaller compared to other SOTA methods . We conduct sufficient experiments to demonstrate the effectiveness of our method and FNA achieves superior performances on various tasks . Moreover , it is convenient to apply FNA on more other tasks , e.g. , pose estimation , face detection , NLP , speech recognition , etc . As there are lots of pre-trained models available in the community , FNA can help researchers who can not afford expensive computation cost explore the model optimization on all kinds of tasks . FNA even makes NAS more accessible for more researchers ."}, "2": {"review_id": "rklTmyBKPH-2", "review_text": " The paper proposes a method called FNA (fast network adaptation), which takes a pretrained image classification network, and produces a network for the task of object detection/semantic segmentation. The process consists of three phases: Network Expansion, Architecture Adaptation and Parameters Adaptation, and uses the developed parameter remapping scheme twice. Experiments show that it outperforms recent other NAS methods for these two tasks with same or less computation. Concrete comments 1. The paper's overall method is a novel one, unifying NAS on det/seg tasks, while prior works mostly only focus on one task. It also \"eliminates\" the need for pretraining each instance of the subnetwork. But no one ever pretrain every classification network for searching on det/seg tasks right? It's an insane amount of computation after all. I'm afraid the emphasis of advantage over prior method here is not very accurate. 2. The concrete parameter remapping scheme is not entirely novel. It is similar to the Net2Net method, while seems more naive than that. It does not preserve the mapping function like Net2Net. It seems like a very coarse effort, since mostly what you do is to copy weights, remove weights or fill in zeros. But it is also interesting to see that this naive method works, and actually beat some of the more advanced alternatives in Section 4. 3. The results are quite impressive. On segmentation, the adapted model achieves ~1% mIOU improvement using similar or less iterations and similar size of model with the methods it compared to, and GPU hours' saving is more significant. If the authors faithfully compared with state-of-the-art methods in search det/seg architectures, but I'm not super familiar with this literature. On object detection the method does not improve the model size or accuracy, but reduces the search time a lot compared with DetNAS. Could the authors clarify that you compared with every recent high-performance NAS method on seg/det tasks? 4. Though the improvement over prior methods is good, the experiments lack an apple-to-apple comparison. For example, using exactly the same NAS search method and supernet, and comparing the FNA method with that not using a pretrained model (i.e., directly search on det/seg) could be a good experiment to showcase the importance of adaptation. Overall I find the method is effective and experiments convincing and I recommend weak accept in my rating. I hope authors can address my concerns in the rebuttal. ", "rating": "6: Weak Accept", "reply_text": "We sincerely thank you for your detailed and constructive comments . 1.We would like to revise the description part of the advantages over prior methods . Our main point aims at taking full advantage of the pre-trained weights of the seed network , which is essential for fast neural architecture search and parameter adaptation . Our parameter remapping mechanism accelerates the whole procedures greatly which makes it easy to conduct the network adaptation on different tasks . 2.Our parameter remapping method does have some similar effects with Net2Net . However , they are quite different . Net2Net aims at deepening and widening the network and accelerates the training procedure . In Net2Net , parameters can only be mapped on the depth and width level . We extend the mapping dimension with the kernel level . Parameters can be also mapped to a shallower or narrower network with our remapping scheme , while Net2Net only maps parameters to a deeper and wider network . We deploy FNA in the popular efficient model MobileNetV2 . Compared with those seemingly more advanced methods , the parameter remapping mechanism of FNA is easier to implement and achieves the best results . Moreover , exploring more effective parameter remapping methods is actually a valuable topic , as we do in Sec.4.4.3.DetNAS [ 1 ] is the latest detection backbone search work that achieves SOTA results and has been accepted in NeurIPS 2019 . Our comparison is sufficient and fair . Furthermore , in RetinaNet , FNA achieves 0.6 accuracy promotion and MAdds is 0.23B smaller compared with DetNAS . In SSDLite , FNA achieves 0.1 accuracy promotion with 100M fewer MAdds compared with MnasNet [ 2 ] . MnasNet takes a huge cost ( around 3,800 GPU days ) to search the architecture on the ImageNet classification task . MnasNet also achieves SOTA results on the SSDLite framework . The computation cost of FNA is apparently smaller , 176x less than MnasNet . 4.We are sorry for the vagueness of Tab . 5 in the paper . Actually , we conduct sufficient apple-to-apple comparison experiments in Sec.4.3 to showcase the effectiveness of parameter remapping in the network adaptation . We revise Tab . 5 as follows for clearer illustration . Row Num Method MAdds ( G ) mIOU ( % ) ( 1 ) Remap - > ArchAdapt - > Remap - > ParamAdapt ( FNA ) 24.17 76.6 ( 2 ) RandInit - > ArchAdapt - > Remap - > ParamAdapt 24.29 76.0 ( 3 ) Remap - > ArchAdapt - > RandInit - > ParamAdapt 24.17 73.0 ( 4 ) RandInit - > ArchAdapt - > RandInit - > ParamAdapt 24.29 72.4 ( 5 ) Remap - > ArchAdapt - > Retrain - > ParamAdapt 24.17 76.5 Remap : Parameter Remapping . ArchAdapt : Architecture Adaptation . RandInit : Random Initialization . Pretrain : ImageNet Pretrain . ParamAdapt : Parameter Adaptation . We attempt to optionally remove the parameter remapping process before the two stages , i.e.architecture adaptation and parameter adaptation . In Row ( 2 ) we remove the parameter remapping process before architecture adaptation . In other words , the search is performed from scratch without using the pre-trained network . The mIOU in Row ( 2 ) drops by 0.6 % compared to FNA in Row ( 1 ) . Then we remove the parameter remapping before parameter adaptation in Row ( 3 ) , i.e.training the target architecture from scratch on the target task . The mIOU decreases by 3.6 % compared to the result of FNA . When we remove the parameter remapping before both stages in Row ( 4 ) , it gets the worst performance . In Row ( 5 ) , we first pre-train the searched architecture on ImageNet and then fine-tune it on the target task . It is worth noting that FNA even achieves a higher mIOU by a narrow margin ( 0.1 % ) than the ImageNet pre-trained one in Row ( 5 ) . We conjecture that this may benefit from the regularization effect of parameter remapping before the parameter adaptation stage . All the experiments are conducted using the same searching and training settings for fair comparisons . With parameters remapping applied on both stages , the adaptation achieves the best results . Especially , the remapping process before parameter adaptation tends to provide greater performance gains than the remapping before architecture adaptation . All the experimental results demonstrate the importance and effectiveness of the proposed parameter remapping scheme . We revise this part in the new version of our paper . We thank for your detailed review once again and hope that our response can address your concerns . [ 1 ] Chen Y , Yang T , Zhang X , et al.Detnas : Neural architecture search on object detection [ J ] . NeurIPS , 2019 . [ 2 ] Tan M , Chen B , Pang R , et al.Mnasnet : Platform-aware neural architecture search for mobile [ C ] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 2019 : 2820-2828 ."}}