{"year": "2021", "forum": "uUAuBTcIIwq", "title": "Unsupervised Learning of Global Factors in Deep Generative Models", "decision": "Reject", "meta_review": "This paper aims at learning disentangled representation at different level without the supervision signal of group information. To achieve this, the proposed UG-VAE model uses both global variable $\\beta$ to represent common information shared across all data, as well as a mixture of Gaussian prior for the local latent variable $p(z) = \\int p(z|d)p(d)d$ where $d$ represents the assignment of the group for a particular datapoint. Experiments considered evaluation on unsupervised global factor learning, domain alignment and a downstream application task on batch classification.\n\nReviewers agreed that the proposed model seems interesting and novel, however some reviewers raised clarity concerns on how to interpret the learned representation by UG-VAE. Revision has addressed this clarity issue to some extent, although some doubts from some reviewers still exists. Also reviewers raised concerns on less competitive experimental results, and the authors have updated the manuscript with improved results. \n\nTo me the main issues of the experimental section are (1) no quantitative result is provided regarding global factor learning and domain alignment, and (2) there is no other benchmark being studied in the experimental section. In my view, at least some other VAE representation learning baselines can be included in the batch classification section in order to demonstrate the real benefit of learning global factor based representations in downstream tasks. ", "reviews": [{"review_id": "uUAuBTcIIwq-0", "review_text": "This paper proposed a deep generative model based on the non i.i.d.VAE framework in an unsupervised version . The model which combines a mixture prior in the local latent space with global latent space has three advantages : First , the latent space can capture interpretable features . Second , the model performs domain alignment . Third , the model can discriminate among their global posterior representations . Although this paper has mild improvement on the basic VAE structure , the model displays a good interpretability power , and the setup of the latent variables are illustrated reasonably in the paper . Strength : 1 . This paper models on non-i.i.d data in an unsupervised version , which provides a flexible model . 2.This model provides a good interpretability power . This paper demonstrates how the features are controlled by the global and local variables , and also it shows the necessary of including the mixture prior in the local space to acquire interpretable information . 3.This model performs domain alignment , the global variable \u03b2 can capture domain knowledge . Critiques : 1 . The paper only discussed one prior distribution for the latent variable d and \u03b2 . The power of choosing other types of prior distribution is unknown . 2.For the domain alignment experiment , only two datasets are used , it will be more convincing to include more datasets . I have read authors ' feedback and will keep my original score .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank the reviewer for the positive feedback and thoughtful comments . In the following , we carefully address all the critiques . 1.Certainly , a more flexible choice for these priors would drive into more powerful/interpretable models . Our following work will probably be centered on the discussion mentioned by the reviewer about how choosing different priors might improve results provided . Nevertheless , as the idea of the paper is to introduce our model and remark the novelty , we believe it is out of the scope of the paper at this point . Thank you for your suggestion . 2.Following your comment and a similar one by another reviewer , we have expanded these results with another two new examples in section 4.2 ."}, {"review_id": "uUAuBTcIIwq-1", "review_text": "Response to rebuttal : the authors have drastically improved the quality of the submission with the new experiments and clarifications , I have therefore increased the score to a weak accept . - This paper introduces a non-iid VAE architecture that uses a mixture of gaussian latent space and a global latent variables shared among all the elements of a mini batch to capture global information in correlated datapoints in an unsupervised way . Overall the paper in well written , and I believe in focuses on two important research directions , namely unsupervised learning of disentangled representations and domain alignment . The model itself is novel and well explained , but I feel the technical explanation is missing intuition on how the model can learn disentanglement in beta from purely random batches , which is not obvious to me . My biggest concern is in the experimental section , that I did not find convincing enough for a number of reasons : 1 . I find it hard to understand if the improvements come from the introduction of the d or the beta latent variables , or a combination of both . How does the model perform in ablation studies in which you remove just one of this components while leaving the others unchanged ? 2.In the single-datasets experiment in section 4.1 how do you define what constitutes a local vs global factors ? Currently some of the chosen factors in Figure 3 seem quite arbitrary . Why is light a local factor but contrast a global one ? Why is hair local but beard global ? 3.The quality of the images is not great to be honest ( beta-VAE paper has more convincing ones , just to name a single work ) , and it is not easy to understand whether the low quality results are due to the fact that as you say you have not validated in depth the networks used or because of flaws in the methodology 4 . How would a beta-VAE perform with the same setup of the experiment in 4.1 ? I would not be surprised if it could capture the same features as your model . It is true as you claim that your method does not require the tuning of the beta hyperparameter in the ELBO , but the UG-VAE needs tuning of the dimensionality of d and beta , and is a more complex architecture than a beta-VAE so it is harder to implement and will take longer to train . 5.It is not clear to me in Figure 4.1. why you are traversing z space in this way , but perhaps I misunderstood what you are doing . How are you guaranteed that you will follow the data manifold ? The ML-VAE results might be off just because of this . 6.I believe the more exciting application of this model would be for domain alignment . Why have n't you focused on more multi-datasets experiments ? 7.How would a gm-vae baseline with 2 clusters perform with the same setup of the experiment in section 4.2 ? In its current state I believe this paper is not ready for acceptance , but I hope the authors will be able to clarify some of my concerns in which case I will increase the score . Minor comment : * The second paragraph of the introduction is giving a lot of details on related work . I would recommend to move this discussion to the related work section , and leave the introduction for higher level discussions that only aim at giving intuition to the reader .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the detailed feedback and thoughtful recommendation . We have incorporated more detailed explanations and experiments . We address all the concerns below . 1.The improvement comes from the combination of both variables . In comparison with ML-VAE ( where they feed the model with grouped data ) , the hidden variable $ d $ allows us to infer the group that each sample might belong to when the data is feeded randomly . The latent $ d $ can find correlations between samples from different batches by assigning them to the same cluster . If the $ d $ is removed , we obtain the ML-VAE , and this type of global information can only be captured in the case we include semi-supervision ( Figure 4 corroborates this , as the disentanglement effect of variations in both $ \\boldsymbol { \\beta } $ and $ \\textbf { z } $ is mild and hard to interpret ) . The global $ \\boldsymbol { \\beta } $ is able to control shared features among random groups of samples . The key point in the experiment 4.1 is that if we fix $ d $ , the global information tuned by $ \\boldsymbol { \\beta } $ in a particular cluster is more interpretable . If the global $ \\boldsymbol { \\beta } $ was ignored , we would end up in a standard VAE with Gaussian Mixture priors that is not capable of encoding global information , and thus , neither semi-supervised nor unsupervised approaches could be deployed . We have included a clarification in section 3.1 ( second paragraph ) with the role that both local $ d $ and global $ \\boldsymbol { \\beta } $ play in our model . 2.The concept of local and global , in our work , lies on the fact that the information is extracted from a single image or from a group of images , independently on the semantics of the generative factor . We understand that in other works ( like [ 1 ] , [ 2 ] , [ 3 ] ) , these concepts are based on the nature of the features , and the global-local features are referred , for example , as style-content . In our experiment , we use the generative model for sampling a batch of images ( fixing $ d $ to help the interpretations ) . The reason why we call \u2018 light \u2019 or \u2018 hair \u2019 a local factor is that we interpret this disentanglement after varying the local latent variable and keeping beta fixed for every image within a batch , for $ d=15 $ and $ d=7 $ , respectively . On the other hand , \u2018 contrast \u2019 is defined as a global factor after interpreting how every image within a batch changes when varying $ \\boldsymbol { \\beta } $ and keeping fixed local latent variables . In the second plot top row in Figure 3 , we selected the 7th cluster ( out of 20 ) and from samples we can interpret that for $ \\mathbf { z } $ fixed , the variation of $ \\boldsymbol { \\beta } $ happens to control the presence of beard , hence we assume it is a global factor , and for $ \\boldsymbol { \\beta } $ fixed , the variation of $ \\mathbf { z } $ controls the amount of hair the person has . This is an interpretation that we draw from samples of the model as we move around each of the two latent spaces . We have extended the second paragraph of section 4.1 with this explanation . 3.We want to stress the novelty of the design methodology of the probabilistic model , which we show it is able to capture interpretable global effects in an unsupervised way . The fact that this is no longer possible when we disable certain parts of the model to reproduce other proposals in the literature ( such as ML-VAE in Figure 4 ) , corroborate our claims . We believe that this is the main contribution of the paper . Beyond that , certainly a deeper network validation and hyperparameter selection would help to obtain more visually appealing images , but that was not our primary goal , which was always more oriented to latent feature analysis . In this line of work , we could even extrapolate these ideas to other deep generative models such as conditional flow-based models , which have demonstrated superior ability to generate quality images . References : [ 1 ] Diane Bouchacourt , Ryota Tomioka , and Sebastian Nowozin . Multi-level variational autoencoder : Learning disentangled representations from grouped observations . In * Thirty-Second AAAI Conference on Artificial Intelligence * , 2018 . [ 2 ] Hosoya , H. ( 2019 , August ) . Group-based Learning of Disentangled Representations with Generalizability for Novel Contents . In * IJCAI * ( pp.2506-2513 ) . [ 3 ] Gatys , L. A. , Ecker , A. S. , & Bethge , M. ( 2016 ) . Image style transfer using convolutional neural networks . In * Proceedings of the IEEE conference on computer vision and pattern recognition * ( pp.2414-2423 ) ."}, {"review_id": "uUAuBTcIIwq-2", "review_text": "This article introduces a VAE-based method for separating local variation factors from global variation factors in the data in an unsupervised manner . It achieves so by designing a graphical model with a mix of example-local and batch-shared variables , and training it using the ELBO . The article provide an detailed experimental analysis on MNIST and CelebA , and experimental evidence that all parts of the model ( notably the discrete d variable ) are relevant . The article provides a well detailed description of the proposed UG-VAE , and how it compare to similar models from the literature ( notably ML-VAE , from which it is inspired ) . The experimental analysis is reasonably convincing , though the interpretation of the provided figures in the text is a little more optimistic than I would agree . There is however one point in particular I would like to see clarified for this paper to be accepted : the justification of the structural design . I have several questions/remarks regarding it : 1 . Equation 8 shows that q ( \u03b2 | X , d ) actually depends on the categorical parameters of q ( d|Z ) , rather than the value of d itself . As such , from a correctness perspective , the distribution is q ( \u03b2 | X , Z ) ( with weight sharing with q ( d | Z ) ) : it does not depend on the value of d. I suspect this choice was made to escape the computational cost of marginalizing the whole batch of variables d in the joint distribution for \u03b2 , but this changes the meaning of the model . 2.The analysis of what features get stored in \u03b2 versus Z is not very insightful . The text of the paper present this as if it was obvious , but does not seem that obvious to me why `` beard '' is a global feature but `` hair '' is a local one . The same non-obviousness applies to all examples . 3.I do n't get why the training procedure is supposed to work . It empirically does to some extent , but there is no clear theoretical justification . If the same \u03b2 is used for the whole batch , given the batch is randomly sampled , what part of the dynamic would indeed drive the model toward extracting some `` common '' features into this variable ? For this last point in particular , the proposed structure seems pretty close to an other one that would be I believe much more natural : have the global parameter \u03b2 not shared across the entire batch , but depending on the class d the encoder assigned to the datapoint . Is that something that has been considered , and if yes why was it not satisfactory compared to the proposed model ? I believe it is necessary to clearly address these points for the article to be accepted . -- Small remarks & typos : - Just after equation 9 , there is a ^-1 missing on the sigma in the text - the notation for the KL-divergence is inconsistent between equations 10 and 11 ( D_KL ( ... ) vs KL ( ... ) ) - the text in 4.A about how the z feature is explored in figure 3 is not completely clear . Is the interpolation done only along the diagonal , moving from ( \u03bc1 - 3 , \u03bc2 - 3 , ... ) to ( \u03bc1 + 3 , \u03bc2 + 3 , ... ) ? If so , why ? If it is rather only moved along one particular dimension , then I suggest rewording this sentence to make it clear .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank the reviewer for the valuable feedback and comments . Regarding the justification of the structural design : 1 . The reviewer is right , the notation might result confusing . We have replaced $ q ( \\boldsymbol { \\beta } | \\mathbf { X } , \\mathbf { d } ) $ by $ q ( \\boldsymbol { \\beta } | \\mathbf { X } , \\mathbf { Z } ) $ , and the diagram of the inference model has also been corrected . Thanks for pointing out this issue . 2.The concept of local and global , in our work , lies on the fact that the information is extracted from a single image or from a group of images , independently on the semantics of the generative factor . We understand that in other works ( like [ 1 ] , [ 2 ] , [ 3 ] ) , these concepts are based on the nature of the features , and the global-local features are referred , for example , as style-content . In our experiment , we use the generative model for sampling a batch of images ( fixing $ d $ to help the interpretations ) . The reason why we call \u2018 light \u2019 or \u2018 hair \u2019 a local factor is that we interpret this disentanglement after varying the local latent variable and fixing the global $ \\boldsymbol { \\beta } $ for every image within a batch , for $ d=15 $ and $ d=7 $ , respectively . On the other hand , \u2018 contrast \u2019 is defined as a global factor after interpreting how every image within a batch changes when varying $ \\boldsymbol { \\beta } $ with $ \\mathbf { z } $ fixed . In the second plot top row in Figure 3 , we selected the 7th cluster ( out of 20 ) and from samples we can interpret that for $ \\mathbf { z } $ fixed , the variation of $ \\boldsymbol { \\beta } $ happens to control the presence of beard , hence we assume it is a global factor , and for $ \\boldsymbol { \\beta } $ fixed , the variation of $ \\mathbf { z } $ controls the amount of hair the person has . This is an interpretation that we draw from samples of the model as we move around each of the two latent spaces . We have extended the second paragraph of section 4.1 with this explanation . 3.The global latent variable $ \\boldsymbol { \\beta } $ controls the cluster means and variances of the Gaussian mixture prior we use to sample every image . As such , it provides additional flexibility to group data points in the same minibatch . Furthermore , the generation of each image depends on both $ \\mathbf { z } $ and $ \\boldsymbol { \\beta } $ , and this enables a direct control of the image features according to the global feature . When we mix two types of datapoints ( e.g.CelebA and FACES in Section 4.2 ) , for a certain region of the $ \\boldsymbol { \\beta } $ space , the clusters are merely separating CelebA faces , while for other $ \\boldsymbol { \\beta } $ values they might be clustering according to correlations between images in CelebA and images in FACES . On the other hand , the posterior distribution of $ \\boldsymbol { \\beta } $ in equation ( 8 ) is an additive contribution of all the local embedding $ \\mathbf { z } $ values in the mini-batch . We believe this is crucial to extract common features into the $ \\boldsymbol { \\beta } $ variable . In comparison with ML-VAE ( where they feed the model with grouped data ) , the hidden variable $ d $ allows us to infer the group that each sample might belong to when the data is feeded randomly . The $ d $ can find correlations between samples from different batches by assigning them to the same cluster . If the $ d $ is removed , we obtain the ML-VAE , and this type of global information can only be captured in the case we include semi-supervision ( Figure 4 corroborates this , as the disentanglement effect of variations in both $ \\boldsymbol { \\beta } $ and $ \\mathbf { z } $ is mild and hard to interpret ) . The global $ \\boldsymbol { \\beta } $ is able to control shared features among random groups of samples . The key point in the experiment 4.1 is that if we fix $ d $ , the global information tuned by $ \\boldsymbol { \\beta } $ in a concrete cluster is clearly interpretable . The motivation to our design is to let a unique $ \\boldsymbol { \\beta } $ control the basic Gaussian mixture priors ( means and covariances ) . But we fully agree that this proposal is interesting . Correlating samples within the same cluster through a different global variable actually generalizes our model , with potential improved cluster interpretability . This model has not been considered so far , but it is certainly something we plan to do in the near future . Thank you for the suggestion . References : [ 1 ] Diane Bouchacourt , Ryota Tomioka , and Sebastian Nowozin . Multi-level variational autoencoder : Learning disentangled representations from grouped observations . In Thirty-Second AAAI Conference on Artificial Intelligence , 2018 . [ 2 ] Hosoya , H. ( 2019 , August ) . Group-based Learning of Disentangled Representations with Generalizability for Novel Contents . In IJCAI ( pp.2506-2513 ) . [ 3 ] Gatys , L. A. , Ecker , A. S. , & Bethge , M. ( 2016 ) . Image style transfer using convolutional neural networks . In Proceedings of the IEEE conference on computer vision and pattern recognition ( pp.2414-2423 ) ."}, {"review_id": "uUAuBTcIIwq-3", "review_text": "This paper presents a novel deep generative model based on noni.i.d.variational autoencoders that captures global dependencies among observations in a fully unsupervised fashion . The proposed model combines a mixture model in the local or data-dependent space and a global Gaussian latent variable , which captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound . The proposed model is being evaluated in two tasks : ( 1 ) disentanglement , and ( 2 ) domain alignment . Pros : ( 1 ) The paper is very well-written and easy to understand . Especially the model figures ( figure 1 and 2 ) are very intuitive and makes it much easier to understand the intuition and difference between the proposed model and previous related works . ( 2 ) The paper is trying to handle a very interesting task , which is to relax the assumption in a lot of previous works in VAE field . The i.i.d data assumption destroys the correlation between data points in the same dataset . Relaxing this constraint will enable wider adoption of this line of models , which can be very useful . Cons : My major concern on this paper is the quality of the evaluation section . ( 1 ) first of all , there is no quantitative or qualitative comparison between the proposed method and previous works . Although disentanglement is a task that is hard to quantify , it is hard to show that UG-VAE outperforms other methods . ( 2 ) One of the contribution mentioned is that UG-VAE does not need to tune a bete parameter as in beta-VAEs . But tuning a hyper-parameter for the disentanglement task is not necessarily a negative thing , as UG-VAE also needs to set the total number of lusters . When setting K= 10 , it is inducing prior knowledge , and not completely unsupervised anymore . ( 3 ) It is not convincing that the global disentanglement features are learned in the global latent variables . From Figure 3 , it just shows some dimensions control certain attributes . It is also not clearly discussed what is defined as `` global attributes '' and waht is `` local attributes '' . ( 4 ) `` Composing graphical models with neural networks for structured representations and fast inference '' from NeurIPS 2016 also has a mixture model as latent space . It will provide readers more insight if the authors could discuss the similarities and differences between these two papers .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for the careful analysis and positive feedback . We have addressed your suggestions with the aim at improving the evaluations section . Experiments with more datasets and baselines are included . All the answers to your comments are provided below . ( 1 ) Certainly , disentanglement is a task where we lack proper metrics to compare models . With the experiments of 4.1 , our goal is to demonstrate the ability of UG-VAE to capture global factors in an unsupervised fashion . Related to the domain alignment experiment , we have expanded the results with two new examples in section 4.2 in which we combine databases of 3D cars , 3D chairs and 2D cars . Note however that in section 4.3 we provide quantitative results , in which we classify using the global projection batches of data points containing different common features . ( 2 ) Unlike beta-VAE , once the generative model is proposed , we do not have to further introduce a hyperparameter in the ELBO lower bound . In UG-VAE , if it were possible , we would like to train our model using maximum likelihood , but that would not be the case in beta-VAE as in that model we intentionally optimize a lower-bound to the ELBO . We have included this clarification on paragraph below Equation 10 ( Section 3.3 ) . We are aware that certain parameters in the generative model ( such as the number $ K $ of clusters , the $ \\boldsymbol { \\beta } $ dimension and all network parameters ) still have to be cross validated , but that also applies to $ \\beta $ -VAE and to any deep generative model . ( 3 ) The concept of local and global , in our work , lies on the fact that the information is extracted from a single image or from a group of images , independently on the semantics of the generative factor . We understand that in other works ( like [ 1 ] , [ 2 ] , [ 3 ] ) , these concepts are based on the nature of the features , and the global-local features are referred , for example , as style-content . In our experiment , we use the generative model for sampling a batch of images ( fixing $ d $ to help the interpretations ) . The reason why we call \u2018 light \u2019 or \u2018 hair \u2019 a local factor is that we interpret this disentanglement after varying the local latent variable for every image within a batch , for $ d=15 $ and $ d=7 $ , respectively . On the other hand , \u2018 contrast \u2019 is defined as a global factor after interpreting how every image within a batch changes when varying $ \\boldsymbol { \\beta } $ . In the second plot top row in Figure 3 , we selected the 7th cluster ( out of 20 ) and from samples we can interpret that for $ \\mathbf { z } $ fixed , the variation of $ \\boldsymbol { \\beta } $ happens to control the presence of beard , hence we assume it is a global factor , and for $ \\boldsymbol { \\beta } $ fixed , the variation of $ \\mathbf { z } $ controls the amount of hair the person has . This is an interpretation that we draw from samples of the model as we move around each of the two latent spaces . We have extended the second paragraph of section 4.1 with this explanation . ( 4 ) Thanks for the suggestion . We have included a reference to this paper in Section II . Indeed , in section 3.1 , we point out the differences with our work . References : [ 1 ] Diane Bouchacourt , Ryota Tomioka , and Sebastian Nowozin . Multi-level variational autoencoder : Learning disentangled representations from grouped observations . In * Thirty-Second AAAI Conference on Artificial Intelligence * , 2018 . [ 2 ] Hosoya , H. ( 2019 , August ) . Group-based Learning of Disentangled Representations with Generalizability for Novel Contents . In * IJCAI * ( pp.2506-2513 ) . [ 3 ] Gatys , L. A. , Ecker , A. S. , & Bethge , M. ( 2016 ) . Image style transfer using convolutional neural networks . In * Proceedings of the IEEE conference on computer vision and pattern recognition * ( pp.2414-2423 ) ."}], "0": {"review_id": "uUAuBTcIIwq-0", "review_text": "This paper proposed a deep generative model based on the non i.i.d.VAE framework in an unsupervised version . The model which combines a mixture prior in the local latent space with global latent space has three advantages : First , the latent space can capture interpretable features . Second , the model performs domain alignment . Third , the model can discriminate among their global posterior representations . Although this paper has mild improvement on the basic VAE structure , the model displays a good interpretability power , and the setup of the latent variables are illustrated reasonably in the paper . Strength : 1 . This paper models on non-i.i.d data in an unsupervised version , which provides a flexible model . 2.This model provides a good interpretability power . This paper demonstrates how the features are controlled by the global and local variables , and also it shows the necessary of including the mixture prior in the local space to acquire interpretable information . 3.This model performs domain alignment , the global variable \u03b2 can capture domain knowledge . Critiques : 1 . The paper only discussed one prior distribution for the latent variable d and \u03b2 . The power of choosing other types of prior distribution is unknown . 2.For the domain alignment experiment , only two datasets are used , it will be more convincing to include more datasets . I have read authors ' feedback and will keep my original score .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We would like to thank the reviewer for the positive feedback and thoughtful comments . In the following , we carefully address all the critiques . 1.Certainly , a more flexible choice for these priors would drive into more powerful/interpretable models . Our following work will probably be centered on the discussion mentioned by the reviewer about how choosing different priors might improve results provided . Nevertheless , as the idea of the paper is to introduce our model and remark the novelty , we believe it is out of the scope of the paper at this point . Thank you for your suggestion . 2.Following your comment and a similar one by another reviewer , we have expanded these results with another two new examples in section 4.2 ."}, "1": {"review_id": "uUAuBTcIIwq-1", "review_text": "Response to rebuttal : the authors have drastically improved the quality of the submission with the new experiments and clarifications , I have therefore increased the score to a weak accept . - This paper introduces a non-iid VAE architecture that uses a mixture of gaussian latent space and a global latent variables shared among all the elements of a mini batch to capture global information in correlated datapoints in an unsupervised way . Overall the paper in well written , and I believe in focuses on two important research directions , namely unsupervised learning of disentangled representations and domain alignment . The model itself is novel and well explained , but I feel the technical explanation is missing intuition on how the model can learn disentanglement in beta from purely random batches , which is not obvious to me . My biggest concern is in the experimental section , that I did not find convincing enough for a number of reasons : 1 . I find it hard to understand if the improvements come from the introduction of the d or the beta latent variables , or a combination of both . How does the model perform in ablation studies in which you remove just one of this components while leaving the others unchanged ? 2.In the single-datasets experiment in section 4.1 how do you define what constitutes a local vs global factors ? Currently some of the chosen factors in Figure 3 seem quite arbitrary . Why is light a local factor but contrast a global one ? Why is hair local but beard global ? 3.The quality of the images is not great to be honest ( beta-VAE paper has more convincing ones , just to name a single work ) , and it is not easy to understand whether the low quality results are due to the fact that as you say you have not validated in depth the networks used or because of flaws in the methodology 4 . How would a beta-VAE perform with the same setup of the experiment in 4.1 ? I would not be surprised if it could capture the same features as your model . It is true as you claim that your method does not require the tuning of the beta hyperparameter in the ELBO , but the UG-VAE needs tuning of the dimensionality of d and beta , and is a more complex architecture than a beta-VAE so it is harder to implement and will take longer to train . 5.It is not clear to me in Figure 4.1. why you are traversing z space in this way , but perhaps I misunderstood what you are doing . How are you guaranteed that you will follow the data manifold ? The ML-VAE results might be off just because of this . 6.I believe the more exciting application of this model would be for domain alignment . Why have n't you focused on more multi-datasets experiments ? 7.How would a gm-vae baseline with 2 clusters perform with the same setup of the experiment in section 4.2 ? In its current state I believe this paper is not ready for acceptance , but I hope the authors will be able to clarify some of my concerns in which case I will increase the score . Minor comment : * The second paragraph of the introduction is giving a lot of details on related work . I would recommend to move this discussion to the related work section , and leave the introduction for higher level discussions that only aim at giving intuition to the reader .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the detailed feedback and thoughtful recommendation . We have incorporated more detailed explanations and experiments . We address all the concerns below . 1.The improvement comes from the combination of both variables . In comparison with ML-VAE ( where they feed the model with grouped data ) , the hidden variable $ d $ allows us to infer the group that each sample might belong to when the data is feeded randomly . The latent $ d $ can find correlations between samples from different batches by assigning them to the same cluster . If the $ d $ is removed , we obtain the ML-VAE , and this type of global information can only be captured in the case we include semi-supervision ( Figure 4 corroborates this , as the disentanglement effect of variations in both $ \\boldsymbol { \\beta } $ and $ \\textbf { z } $ is mild and hard to interpret ) . The global $ \\boldsymbol { \\beta } $ is able to control shared features among random groups of samples . The key point in the experiment 4.1 is that if we fix $ d $ , the global information tuned by $ \\boldsymbol { \\beta } $ in a particular cluster is more interpretable . If the global $ \\boldsymbol { \\beta } $ was ignored , we would end up in a standard VAE with Gaussian Mixture priors that is not capable of encoding global information , and thus , neither semi-supervised nor unsupervised approaches could be deployed . We have included a clarification in section 3.1 ( second paragraph ) with the role that both local $ d $ and global $ \\boldsymbol { \\beta } $ play in our model . 2.The concept of local and global , in our work , lies on the fact that the information is extracted from a single image or from a group of images , independently on the semantics of the generative factor . We understand that in other works ( like [ 1 ] , [ 2 ] , [ 3 ] ) , these concepts are based on the nature of the features , and the global-local features are referred , for example , as style-content . In our experiment , we use the generative model for sampling a batch of images ( fixing $ d $ to help the interpretations ) . The reason why we call \u2018 light \u2019 or \u2018 hair \u2019 a local factor is that we interpret this disentanglement after varying the local latent variable and keeping beta fixed for every image within a batch , for $ d=15 $ and $ d=7 $ , respectively . On the other hand , \u2018 contrast \u2019 is defined as a global factor after interpreting how every image within a batch changes when varying $ \\boldsymbol { \\beta } $ and keeping fixed local latent variables . In the second plot top row in Figure 3 , we selected the 7th cluster ( out of 20 ) and from samples we can interpret that for $ \\mathbf { z } $ fixed , the variation of $ \\boldsymbol { \\beta } $ happens to control the presence of beard , hence we assume it is a global factor , and for $ \\boldsymbol { \\beta } $ fixed , the variation of $ \\mathbf { z } $ controls the amount of hair the person has . This is an interpretation that we draw from samples of the model as we move around each of the two latent spaces . We have extended the second paragraph of section 4.1 with this explanation . 3.We want to stress the novelty of the design methodology of the probabilistic model , which we show it is able to capture interpretable global effects in an unsupervised way . The fact that this is no longer possible when we disable certain parts of the model to reproduce other proposals in the literature ( such as ML-VAE in Figure 4 ) , corroborate our claims . We believe that this is the main contribution of the paper . Beyond that , certainly a deeper network validation and hyperparameter selection would help to obtain more visually appealing images , but that was not our primary goal , which was always more oriented to latent feature analysis . In this line of work , we could even extrapolate these ideas to other deep generative models such as conditional flow-based models , which have demonstrated superior ability to generate quality images . References : [ 1 ] Diane Bouchacourt , Ryota Tomioka , and Sebastian Nowozin . Multi-level variational autoencoder : Learning disentangled representations from grouped observations . In * Thirty-Second AAAI Conference on Artificial Intelligence * , 2018 . [ 2 ] Hosoya , H. ( 2019 , August ) . Group-based Learning of Disentangled Representations with Generalizability for Novel Contents . In * IJCAI * ( pp.2506-2513 ) . [ 3 ] Gatys , L. A. , Ecker , A. S. , & Bethge , M. ( 2016 ) . Image style transfer using convolutional neural networks . In * Proceedings of the IEEE conference on computer vision and pattern recognition * ( pp.2414-2423 ) ."}, "2": {"review_id": "uUAuBTcIIwq-2", "review_text": "This article introduces a VAE-based method for separating local variation factors from global variation factors in the data in an unsupervised manner . It achieves so by designing a graphical model with a mix of example-local and batch-shared variables , and training it using the ELBO . The article provide an detailed experimental analysis on MNIST and CelebA , and experimental evidence that all parts of the model ( notably the discrete d variable ) are relevant . The article provides a well detailed description of the proposed UG-VAE , and how it compare to similar models from the literature ( notably ML-VAE , from which it is inspired ) . The experimental analysis is reasonably convincing , though the interpretation of the provided figures in the text is a little more optimistic than I would agree . There is however one point in particular I would like to see clarified for this paper to be accepted : the justification of the structural design . I have several questions/remarks regarding it : 1 . Equation 8 shows that q ( \u03b2 | X , d ) actually depends on the categorical parameters of q ( d|Z ) , rather than the value of d itself . As such , from a correctness perspective , the distribution is q ( \u03b2 | X , Z ) ( with weight sharing with q ( d | Z ) ) : it does not depend on the value of d. I suspect this choice was made to escape the computational cost of marginalizing the whole batch of variables d in the joint distribution for \u03b2 , but this changes the meaning of the model . 2.The analysis of what features get stored in \u03b2 versus Z is not very insightful . The text of the paper present this as if it was obvious , but does not seem that obvious to me why `` beard '' is a global feature but `` hair '' is a local one . The same non-obviousness applies to all examples . 3.I do n't get why the training procedure is supposed to work . It empirically does to some extent , but there is no clear theoretical justification . If the same \u03b2 is used for the whole batch , given the batch is randomly sampled , what part of the dynamic would indeed drive the model toward extracting some `` common '' features into this variable ? For this last point in particular , the proposed structure seems pretty close to an other one that would be I believe much more natural : have the global parameter \u03b2 not shared across the entire batch , but depending on the class d the encoder assigned to the datapoint . Is that something that has been considered , and if yes why was it not satisfactory compared to the proposed model ? I believe it is necessary to clearly address these points for the article to be accepted . -- Small remarks & typos : - Just after equation 9 , there is a ^-1 missing on the sigma in the text - the notation for the KL-divergence is inconsistent between equations 10 and 11 ( D_KL ( ... ) vs KL ( ... ) ) - the text in 4.A about how the z feature is explored in figure 3 is not completely clear . Is the interpolation done only along the diagonal , moving from ( \u03bc1 - 3 , \u03bc2 - 3 , ... ) to ( \u03bc1 + 3 , \u03bc2 + 3 , ... ) ? If so , why ? If it is rather only moved along one particular dimension , then I suggest rewording this sentence to make it clear .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank the reviewer for the valuable feedback and comments . Regarding the justification of the structural design : 1 . The reviewer is right , the notation might result confusing . We have replaced $ q ( \\boldsymbol { \\beta } | \\mathbf { X } , \\mathbf { d } ) $ by $ q ( \\boldsymbol { \\beta } | \\mathbf { X } , \\mathbf { Z } ) $ , and the diagram of the inference model has also been corrected . Thanks for pointing out this issue . 2.The concept of local and global , in our work , lies on the fact that the information is extracted from a single image or from a group of images , independently on the semantics of the generative factor . We understand that in other works ( like [ 1 ] , [ 2 ] , [ 3 ] ) , these concepts are based on the nature of the features , and the global-local features are referred , for example , as style-content . In our experiment , we use the generative model for sampling a batch of images ( fixing $ d $ to help the interpretations ) . The reason why we call \u2018 light \u2019 or \u2018 hair \u2019 a local factor is that we interpret this disentanglement after varying the local latent variable and fixing the global $ \\boldsymbol { \\beta } $ for every image within a batch , for $ d=15 $ and $ d=7 $ , respectively . On the other hand , \u2018 contrast \u2019 is defined as a global factor after interpreting how every image within a batch changes when varying $ \\boldsymbol { \\beta } $ with $ \\mathbf { z } $ fixed . In the second plot top row in Figure 3 , we selected the 7th cluster ( out of 20 ) and from samples we can interpret that for $ \\mathbf { z } $ fixed , the variation of $ \\boldsymbol { \\beta } $ happens to control the presence of beard , hence we assume it is a global factor , and for $ \\boldsymbol { \\beta } $ fixed , the variation of $ \\mathbf { z } $ controls the amount of hair the person has . This is an interpretation that we draw from samples of the model as we move around each of the two latent spaces . We have extended the second paragraph of section 4.1 with this explanation . 3.The global latent variable $ \\boldsymbol { \\beta } $ controls the cluster means and variances of the Gaussian mixture prior we use to sample every image . As such , it provides additional flexibility to group data points in the same minibatch . Furthermore , the generation of each image depends on both $ \\mathbf { z } $ and $ \\boldsymbol { \\beta } $ , and this enables a direct control of the image features according to the global feature . When we mix two types of datapoints ( e.g.CelebA and FACES in Section 4.2 ) , for a certain region of the $ \\boldsymbol { \\beta } $ space , the clusters are merely separating CelebA faces , while for other $ \\boldsymbol { \\beta } $ values they might be clustering according to correlations between images in CelebA and images in FACES . On the other hand , the posterior distribution of $ \\boldsymbol { \\beta } $ in equation ( 8 ) is an additive contribution of all the local embedding $ \\mathbf { z } $ values in the mini-batch . We believe this is crucial to extract common features into the $ \\boldsymbol { \\beta } $ variable . In comparison with ML-VAE ( where they feed the model with grouped data ) , the hidden variable $ d $ allows us to infer the group that each sample might belong to when the data is feeded randomly . The $ d $ can find correlations between samples from different batches by assigning them to the same cluster . If the $ d $ is removed , we obtain the ML-VAE , and this type of global information can only be captured in the case we include semi-supervision ( Figure 4 corroborates this , as the disentanglement effect of variations in both $ \\boldsymbol { \\beta } $ and $ \\mathbf { z } $ is mild and hard to interpret ) . The global $ \\boldsymbol { \\beta } $ is able to control shared features among random groups of samples . The key point in the experiment 4.1 is that if we fix $ d $ , the global information tuned by $ \\boldsymbol { \\beta } $ in a concrete cluster is clearly interpretable . The motivation to our design is to let a unique $ \\boldsymbol { \\beta } $ control the basic Gaussian mixture priors ( means and covariances ) . But we fully agree that this proposal is interesting . Correlating samples within the same cluster through a different global variable actually generalizes our model , with potential improved cluster interpretability . This model has not been considered so far , but it is certainly something we plan to do in the near future . Thank you for the suggestion . References : [ 1 ] Diane Bouchacourt , Ryota Tomioka , and Sebastian Nowozin . Multi-level variational autoencoder : Learning disentangled representations from grouped observations . In Thirty-Second AAAI Conference on Artificial Intelligence , 2018 . [ 2 ] Hosoya , H. ( 2019 , August ) . Group-based Learning of Disentangled Representations with Generalizability for Novel Contents . In IJCAI ( pp.2506-2513 ) . [ 3 ] Gatys , L. A. , Ecker , A. S. , & Bethge , M. ( 2016 ) . Image style transfer using convolutional neural networks . In Proceedings of the IEEE conference on computer vision and pattern recognition ( pp.2414-2423 ) ."}, "3": {"review_id": "uUAuBTcIIwq-3", "review_text": "This paper presents a novel deep generative model based on noni.i.d.variational autoencoders that captures global dependencies among observations in a fully unsupervised fashion . The proposed model combines a mixture model in the local or data-dependent space and a global Gaussian latent variable , which captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound . The proposed model is being evaluated in two tasks : ( 1 ) disentanglement , and ( 2 ) domain alignment . Pros : ( 1 ) The paper is very well-written and easy to understand . Especially the model figures ( figure 1 and 2 ) are very intuitive and makes it much easier to understand the intuition and difference between the proposed model and previous related works . ( 2 ) The paper is trying to handle a very interesting task , which is to relax the assumption in a lot of previous works in VAE field . The i.i.d data assumption destroys the correlation between data points in the same dataset . Relaxing this constraint will enable wider adoption of this line of models , which can be very useful . Cons : My major concern on this paper is the quality of the evaluation section . ( 1 ) first of all , there is no quantitative or qualitative comparison between the proposed method and previous works . Although disentanglement is a task that is hard to quantify , it is hard to show that UG-VAE outperforms other methods . ( 2 ) One of the contribution mentioned is that UG-VAE does not need to tune a bete parameter as in beta-VAEs . But tuning a hyper-parameter for the disentanglement task is not necessarily a negative thing , as UG-VAE also needs to set the total number of lusters . When setting K= 10 , it is inducing prior knowledge , and not completely unsupervised anymore . ( 3 ) It is not convincing that the global disentanglement features are learned in the global latent variables . From Figure 3 , it just shows some dimensions control certain attributes . It is also not clearly discussed what is defined as `` global attributes '' and waht is `` local attributes '' . ( 4 ) `` Composing graphical models with neural networks for structured representations and fast inference '' from NeurIPS 2016 also has a mixture model as latent space . It will provide readers more insight if the authors could discuss the similarities and differences between these two papers .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank the reviewer for the careful analysis and positive feedback . We have addressed your suggestions with the aim at improving the evaluations section . Experiments with more datasets and baselines are included . All the answers to your comments are provided below . ( 1 ) Certainly , disentanglement is a task where we lack proper metrics to compare models . With the experiments of 4.1 , our goal is to demonstrate the ability of UG-VAE to capture global factors in an unsupervised fashion . Related to the domain alignment experiment , we have expanded the results with two new examples in section 4.2 in which we combine databases of 3D cars , 3D chairs and 2D cars . Note however that in section 4.3 we provide quantitative results , in which we classify using the global projection batches of data points containing different common features . ( 2 ) Unlike beta-VAE , once the generative model is proposed , we do not have to further introduce a hyperparameter in the ELBO lower bound . In UG-VAE , if it were possible , we would like to train our model using maximum likelihood , but that would not be the case in beta-VAE as in that model we intentionally optimize a lower-bound to the ELBO . We have included this clarification on paragraph below Equation 10 ( Section 3.3 ) . We are aware that certain parameters in the generative model ( such as the number $ K $ of clusters , the $ \\boldsymbol { \\beta } $ dimension and all network parameters ) still have to be cross validated , but that also applies to $ \\beta $ -VAE and to any deep generative model . ( 3 ) The concept of local and global , in our work , lies on the fact that the information is extracted from a single image or from a group of images , independently on the semantics of the generative factor . We understand that in other works ( like [ 1 ] , [ 2 ] , [ 3 ] ) , these concepts are based on the nature of the features , and the global-local features are referred , for example , as style-content . In our experiment , we use the generative model for sampling a batch of images ( fixing $ d $ to help the interpretations ) . The reason why we call \u2018 light \u2019 or \u2018 hair \u2019 a local factor is that we interpret this disentanglement after varying the local latent variable for every image within a batch , for $ d=15 $ and $ d=7 $ , respectively . On the other hand , \u2018 contrast \u2019 is defined as a global factor after interpreting how every image within a batch changes when varying $ \\boldsymbol { \\beta } $ . In the second plot top row in Figure 3 , we selected the 7th cluster ( out of 20 ) and from samples we can interpret that for $ \\mathbf { z } $ fixed , the variation of $ \\boldsymbol { \\beta } $ happens to control the presence of beard , hence we assume it is a global factor , and for $ \\boldsymbol { \\beta } $ fixed , the variation of $ \\mathbf { z } $ controls the amount of hair the person has . This is an interpretation that we draw from samples of the model as we move around each of the two latent spaces . We have extended the second paragraph of section 4.1 with this explanation . ( 4 ) Thanks for the suggestion . We have included a reference to this paper in Section II . Indeed , in section 3.1 , we point out the differences with our work . References : [ 1 ] Diane Bouchacourt , Ryota Tomioka , and Sebastian Nowozin . Multi-level variational autoencoder : Learning disentangled representations from grouped observations . In * Thirty-Second AAAI Conference on Artificial Intelligence * , 2018 . [ 2 ] Hosoya , H. ( 2019 , August ) . Group-based Learning of Disentangled Representations with Generalizability for Novel Contents . In * IJCAI * ( pp.2506-2513 ) . [ 3 ] Gatys , L. A. , Ecker , A. S. , & Bethge , M. ( 2016 ) . Image style transfer using convolutional neural networks . In * Proceedings of the IEEE conference on computer vision and pattern recognition * ( pp.2414-2423 ) ."}}