{"year": "2021", "forum": "6jlNy83JUQ_", "title": "Low Complexity Approximate Bayesian Logistic Regression for Sparse Online Learning", "decision": "Reject", "meta_review": "This paper proposes a new approximate algorithm for Bayesian logistic regression in the online setting. The primary approximation involved in the algorithm is the use of a diagonal Gaussian approximation. (A probably more minor approximation is approximating the sigmoid with a Gaussian.) The main discussion focused on two issues: Firstly, there was some sentiment that the paper lacked theoretical guarantees. Second, there were concerns about the experimental results. I feel that it is not a serious flaw that the paper lacks a theoretical regret bound. Given the current state of algorithms for this problem practical algorithms remain very much of interest. However, the general sentiment of reviewers was that the experimental results were not as strong (or as numerous) as would be hoped. For an algorithm without a theoretical regret bound, I do agree that stronger empirical evidence would be expected. This was partially addressed in a revision but still I agree with the consensus that more extensive numerical evidence should be expected, and for that reason I am recommending rejection.\n\nFinally, I'll mention some other issues that I view as not counting substantially against the paper. Firstly is the dependence on the prior. Here I am in agreement with the authors that this is an aspect shared by all Bayesian methods. This issue is a (valid) argument about the value of all Bayesian methods, but not one I think we will resolve here. Second, there were suggestions from the reviewers about improvements that could be made to the baseline methods. Here I don't feel that it's fair that we ask the authors to make novel improvements to other algorithms, unless those improvements are very \"obvious\".", "reviews": [{"review_id": "6jlNy83JUQ_-0", "review_text": "This paper proposes an algorithm for online logistic regression based on analytical formulas that approximate the Bayesian predictive posterior . These approximations are based on assuming a diagonal covariance Gaussian form for the posterior at each iteration that is optimized to fit the true posterior . Two alternatives are proposed for the optimization : one based on Newton 's method and the other based on a Taylor series approximation , which experimentally yields similar results . Thanks to these closed formula approximations , the resulting algorithm has a constant low cost per observation and is particularly suitable for sparse high-dimensional scenarios . It is empirically shown that the algorithm achieves a known regret lower bound on synthetic data when the true prior on the weights used to generate the data is provided to the algorithm . Strong points : - The introduction properly positions the work - A low-complexity algorithm for online prediction suitable for sparse high-dimensional features is proposed Weak points : - No theoretical guarantees on the regret - Regret is strongly dependent on the prior - No experiments on real datasets This paper proposes a low-complexity approximated bayesian algorithm that aims at attaining known regret lower bounds that have been recently shown [ Shamir 2020 ] to be achievable by exact Bayesian methods . Unfortunately , no theoretical guarantees are provided on the impact of such approximations and the empirical performance is reported to be strongly affected by the choice of the prior . In particular , it is reported that the prior has to fit the data for good regret . This strong dependence on the prior makes it of limited practical interest in real life online scenarios . Therefore , I think that the paper is not strong enough and recommend its rejection . Detailed comments : Section 3 could be better structured and a `` road map '' at the beginning of the section would help the reader to quickly understand the different steps involved in the approximation . If I understood correctly , in order to build a synthetic dataset , - you sample the weights $ w^\\star $ using some prior ( a gaussian with mean 0 and STD specified in the title of each plot ) .\\ - At time $ t $ , you sample random features $ x_ { i , t } $ using different distributions , depending on the type.\\ - You add up these features weighted by $ w^\\star $ to obtain the true log-odds that is used to define the probability distribution ( through the sigmoid ) from which $ y_t $ is sampled . Then , the following sentence is confusing : `` The \u201c true \u201d log-odds of the features drawn at t were added up , weighted by $ x_ { i , t } $ , and converted to probability with the Sigmoid function . '' In the following sentence you use $ \\tau $ that does n't appear in eq.4 : `` Results describe a time series on ( 4 ) , where summation is on $ \\tau $ up to example $ t $ at time $ t $ . '' `` We demonstrate that it is sufficient to approximate the component of the posterior which will dominate at the horizon , matching it by a diagonal Gaussian approximation , '' How is this demonstrated ? Eq 11 : ( d ) should be with $ \\approx $ instead of $ = $ Since nonparametric Bayesian methods are mentioned in the abstract , it would be interesting to see a comparison against online nonparametric Bayesian methods . In my opinion , the title should say `` online prediction '' instead of `` online learning '' , since the latter does not necessarily imply predicting at each round and cumulating the loss . Typos : \\ -- mostly a function * of * the number\\ -- Jeffery 's prior - > Jeffreys prior ==POST-REBUTTAL COMMENTS== I thank the authors for the response and the efforts in the updated draft , in particular with respect to the new experiment on the Criteo dataset . Regarding the following arguments : 1- * '' The dependence of regret on the prior applies to any Bayesian method , in the same way that tuning the learning rate for gradient methods is necessary . `` * I agree that , for batch methods , the prior can be tuned to the data . Nevertheless , in an online prediction setting , the prior needs to be chosen before observing the data and once you start predicting you ca n't go back and change the prior for the already predicted sequence . 2- * '' To the best of our knowledge , none of the literature that proposed practical ( online ) Bayesian methods proposed regret bounds or even studied regret for these methods '' * Regarding both arguments , there is recent literature that proposes a practical nonparametric online prediction method with regret guarantees for a fixed given prior : * Lh\u00e9ritier , Alix , and Frederic Cazals . `` Low-Complexity Nonparametric Bayesian Online Prediction with Universal Guarantees . '' Advances in Neural Information Processing Systems . 2019 . * Therefore , unfortunately , my first two concerns ( theoretical guarantees on the regret and strong dependence on the prior ) remain so I retain my original decision .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their time and effort , and for their invaluable comments . We revised the paper to incorporate changes motivated by the reviewer \u2019 s suggestions . Below are specific responses to some comments . - * * Theoretical guarantees : * * To the best of our knowledge , none of the literature that proposed practical ( online ) Bayesian methods proposed regret bounds or even studied regret for these methods . Loss and accuracy were considered , but it was never indicative which fraction of the loss to attribute to data uncertainty , and which to regret ( which corresponds to the model/epistemic uncertainty ) . In fact , we believe that such study in our paper is novel . While several theoretical papers ( Kakade , Ng.2005 , Foster et . al.2018 , Shamir 2020 ) showed that Bayesian methods can , in fact , be optimal for regret , the literature on practical approaches lacks such connections . Our paper intends to bring a proof of concept to a low complexity approach that appears to outperform other methods or match substantially more complex methods . Proving regret bounds for such an approach could be a theoretical COLT paper by itself , and no such bounds exist for any other practical methods . We believe that synthetic data is the first proof of concept to regret performance of such methods . The synthetic data brings a dimension that real data does not , by allowing empirical results to focus on regret , regardless of the true parameter values , which modify the loss . It also isolates the measurements from other phenomena that affect real data , such as model misspecification and nonstationarity . - * * Regret and prior : * * The dependence of regret on the prior applies to any Bayesian method , in the same way that tuning the learning rate for gradient methods is necessary . While theoretical results ( Shamir 20 ) do show that the lower bounds are achievable regardless of the prior ( as long as a comparator is confined to some space ) , performance of practical techniques is a function of the prior chosen . What we show is that if the prior used matches the data , we achieve better regret than other methods whose hyper-parameters were also tuned to attain their best performance . While it would be nice to have an algorithm whose performance is not affected by the choice of either prior or other hyper-parameters , no other known methods have such properties . We respectfully disagree with the reviewer \u2019 s claim that \u201c This strong dependence on the prior makes it of limited practical interest in real life online scenarios \u201d . Practical methods * * do tune * * learning rates and/or priors to fit the data in practical systems . Our algorithm is no different from that . Once tuned , it outperforms other methods . - * * Real datasets : * * As discussed above , it is nice to have results on real datasets , and we added such results . However , loss on these datasets reveals limited information about regret , which is what the paper attempts to minimize . Loss , relative to other methods , does indicate whether regret is better for one algorithm over another , but it doesn \u2019 t measure the regret . Furthermore , loss on real data can also be affected by properties of the data , like nonstationarity , which we do not attempt to address in this paper . To address nonstationarity , misspecification or other artifacts of real data , additional modifications may be necessary to an algorithm . The goal of the paper is to show that this method works in a clean stationary setting . This can lead to development of methods based on the foundation laid by this paper that address other properties of learning models on real data . - A road map has been added in Section 3 . - Sentences that were unclear to the reviewer were modified , and minor corrections suggested were made . - \u201c `` We demonstrate that it is sufficient to approximate the component of the posterior which will dominate at the horizon , matching it by a diagonal Gaussian approximation , '' How is this demonstrated ? \u201d - Our regret results show that the proposed algorithms are as good as or outperform methods that match the full distribution instead of the important points of the distribution . - `` Since nonparametric Bayesian methods are mentioned in the abstract , it would be interesting to see a comparison against online nonparametric Bayesian methods. \u201d - There is no mention of nonparametric methods . The reviewer refers to a comment about hyper-parameters that need to be tuned . For the theoretical Bayesian methods ( with known comparator class ) no such hyper-parameters need to be tuned . - We respectfully disagree with the name change proposed by the reviewer . The proposed methods is an online learning algorithm . We measure regret in the standard way it is measured in the online learning literature , and the algorithms learn a distribution within the uncertainty of the parameters ."}, {"review_id": "6jlNy83JUQ_-1", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper proposes an algorithm for learning the parameters of a logistic regression model in an online setting . The proposed algorithm is based on two approximations : the posterior at iteration t over the model parameters is assumed to be multivariate Gaussian distribution with a diagonal covariance matrix and the logistic/sigmoid function is approximated by the CDF of the normal distribution . The numerical results show the usefulness of the proposed algorithm . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Reason for score : My overall impression is that the proposed algorithm is of sufficient interest to warrant the acceptance of the paper . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper proposes analytical expressions for updating the parameters of the logistic regression model in an online setting . The computation cost for updating the parameter is reduced . 2.The paper is overall well written and the authors describe in detail each step in the development of the proposed algorithm . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : 1 . For me it is not clear why you settled on a logistic regression problem instead of probit regression and present the logistic regression as an extension . From my understanding , the keystones for the proposed algorithm are the approximation of the prior as a multivariate Gaussian with diagonal covariance and the marginalization step ( which itself is due to the Gaussian assumption ) . From my point of view , the introduction of the extra approximation layer due to the use of the logistic regression is detrimental to the easy understanding of the paper . I believe it would have been better to just introduce a section that describes the modifications to make in order to apply the proposed algorithm to the logistic regression problem . 2.In section 1 on page 2 you make a statement about the role of an approximation in minimizing the the uncertainty . For me it is not clear how the proposed algorithm addresses this statement . Could you please elaborate on the subject ? Also , on page 3 you say that it is sufficient to match the component of the posterior that dominates at the horizon . What do you exactly mean by the component of the posterior ? # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Miscellaneous : 1 . It 's welcoming that the proposed algorithm has very good results , however I 'm a bit surprised that the results are that good . My wariness comes from the fact that in equation 13 you match an approximation to the posterior distribution , which itself was obtained using an approximation . I would expect the errors due to the approximations to accumulate as more and more data items are processed . However , the regret seems to remain steady as you increase the number of items seen . Do you have an explanation as to why the errors due to the approximations do not accumulate ? 2.There are some typos here and there in the article , however I believe you can easily detect them with the help of a spell checker .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for their time , efforts and invaluable feedback . We revised the paper to address comments by all reviewers . We address the specific comments made by this reviewer below . - * * Probit vs. logistic regression : * * The comment by the reviewer is very relevant , and we agree that the logistic setup introduces more complexity than the probit setup . The reason we chose to focus on logistic regression is mainly the larger popularity of logistic regression in practice . One could argue about the justification of this popularity , but this is the case , especially in the machine learning literature and applied community . We also note that with probit regression , numerical tables or approximations are necessary to compute the Gaussian CDF . A decision could go either way here - the advantage of logistic regression is its popularity , and that of probit is its simplicity . We chose for the first , but we also extended the discussion on the second in a new appendix in the revised version . - * * Approximation and Uncertainty : * * One of the points we tried to emphasize in the paper is the seminal relation established by Rissanen between the minimum description length ( MDL ) and prediction error . Regret is a component of the MDL , which corresponds to the epistemic uncertainty , or in other words , to how well the parameters of the true model are estimated . Therefore , an algorithm with lower regret also estimates the unknown model parameters better ( with lower prediction error ) . It has been established ( Kakade , Ng.2005 , Foster 2018 , Shamir 2020 ) that Bayesian methods in theory can achieve the lower bounds on regret . Therefore , the role of a good approximation is to retain that property , and degrade only components of the distribution that do not affect the regret ( or that minimally affect the regret ) . The claim was made in the paper to pave the path to demonstrate that there are two ends to this . One , use an approximation that is good enough , but on the other hand , don \u2019 t use an approximation that is much more complex , but adds no value over a simple approximation in what matters . - * * Match components of posterior : * * The message in this claim is that an approximation should not scale down the effect of the prior at the point of the distribution where the algorithm converges to at the end . As epistemic uncertainty becomes smaller due to more data , the distribution of a model parameter becomes more and more like a point mass around the regret minimizing value of the parameter . A bad approximation reduces the magnitude at this point . As shown in ( Kakade , Ng.2005 , Shamir 2020 ) , the optimal regret achieves for a parameter is roughly the logarithm of the prior at this point ( or an integral around this point ) . If the approximate posterior scales down the magnitude at this point or its vicinity from the true one , there would be additional regret losses . Given all that , the idea is that we try to pick approximations that have a property that they do not scale down the posteriors at points that are likely to hand up being the convergence point of the parameter . Simple approximations , like Laplace , that focus on the peak follow this . However , complex approximations , like VB , give too much weight to points far from the peak by trying to match the full posterior , and by that also harm the regret . - * * Accumulation of approximation errors : * * We believe that this happens , and that there are some additional penalty terms to the regret . However , if you look at the approximations more carefully , while they lose in some regions , they gain in others . Attributing to the previous point , the approximation can scale down the effect of the prior in one example , but then correct it and scale it up in a subsequent example . The overall effect may hide some of these losses by correction gains that happen in the subsequent examples . It is very difficult to derive regret bounds for these approximation approaches , but such bounds could explain this better . - * * Typos : * * We are making several passes to fix typos on the revised submission ."}, {"review_id": "6jlNy83JUQ_-2", "review_text": "PAPER SUMMARY This paper proposes a new posterior approximation scheme for probabilistic logistic regression . In the online learning setup , the proposed approximation leads to a closed-form parameter update . In particular , the key ideas here include : ( 1 ) A probit approximation of the sigmoid likelihood in Eq . ( 5 ) .This , along with the assumed statistical independence among individual features and another integral approximation trick used in ( Murphy , 2012 ) , leads to a posterior representation in forms of a normalized product between a sigmoid and a normal PDF . ( 2 ) Matching the location and density of its mode to that of another Gaussian surrogate to yield the closed-form update that expresses the parameter at round ( t + 1 ) in terms of its counterpart at round ( t ) analytically in Eq . ( 15 ) NOVELTY & SIGNIFICANCE If I understand correctly , the main arguments in favor of the proposed method are : ( a ) the iterative update derived from Eq . ( 15 ) only involves a single sample at round ( t ) which is more efficient than VB 's or EM 's stochastic gradient updates that require re-iterating over multiple mini-batches of past data ; and ( b ) the new approximation scheme performs empirically better than existing method , and matches state-of-the-art regret lower-bound . Given the current form of the manuscript , these arguments , however , are not very convincing to me as I elaborated in the followings : First , regarding ( a ) , while it is true that VB 's or EM 's offline updates are more expensive than the update derived from Eq . ( 15 ) , it seems to me they can still be made more efficient in online setting with very minor modifications . For instance , in both VB and EM , the lower-bound function often factorizes additively across data point so if we cache all gradient computation in step ( t ) , the computation of new gradient in step ( t + 1 ) also involves only the latest data sample which is likely not more expensive than iteratively solving Eq . ( 15 ) -- I would like to hear the authors ' thoughts on this . Second , the claim that the new approximation scheme performs better than existing methods is not well-supported . In this regard , I wonder why the improved loss is only demonstrated in a very controlled , synthetic experiment settings . One could always argue that as far as only synthetic experiments are involved , there might exist other settings for which we might see the opposite . To me , positive results on a single set of synthetic experiments often do not speak conclusively to whether one method would be more useful than another in practice -- a better way to demonstrate this is to also evaluate the proposed method on real-world benchmark datasets ( especially those extracted from practical domains that were mentioned in the introduction ) Furthermore , the evaluation does not seem to include all the most relevant baselines ( more on this later ) as well as processing time comparison . Given that one of the key contribution claims here is the computation advantage over EM 's and VB 's , both theoretical complexity and empirical demonstration of averaged running time should be provided . In addition , I also find part of the positioning of this paper somewhat misleading , especially when it criticizes stochastic gradient methods for incurring additional losses while the target posterior keeps moving with subsequent samples . Is n't this also true for the proposed method ? While Eq . ( 15 ) is analytic , solving it for the parameter update is clearly not analytically tractable which also requires iterative update ; and then even the resulting approximated posterior has to be matched again to another Gaussian surrogate . Lastly , the conclusion surprisingly summarizes that with proper prior , the method `` matches regret lower-bound '' -- this seems like an overclaim as there is no theoretical analysis in the paper to back this up . TECHNICAL SOUNDNESS I have gone through the derivations and I do not spot any serious issues , but there are parts that seem to lack justification . For instance , could the authors please detail the steps that lead to Eq . ( 5 ) ? Also , it will be even better if the authors could provide plots to visually demonstrate how the derivative of sigmoid is close to the scaled normal CDF . I also find it a bit strange that this paper highlights the sparse aspect of data as an issue but in the end , it appears more to be a necessary setting that justifies the assumed diagonal form of the variance matrix , which is a necessity for most of the technical derivations in this paper . CLARITY While the paper is sufficiently clear , I find the introduction is a bit too long . It could have made its points using much less space . In the current form , it kind of distracts the readers from those key points by throwing in many subsidiary positionings that are better discussed & organized in related work . The claim on analytic update is also a bit exaggerating as solving Eq . ( 15 ) for an update equation is after all not tractable and we will have to resort to iterative method such as Newton 's or Taylor series expansion anyway . EXPERIMENT On the experimental evaluation , my key concern ( as mentioned above ) is the lack of evaluation of real-world dataset , and in addition , some of the more recent methods such as ( Nguyen , 2017a ; 2017b ) were not included in the baseline . The presentation of the evaluation is also problematic when the results seem to be collected on only 1 single run . As a standard practice , please re-run the same experiment multiple times and report the margin of error . It is also unclear why the Y-axis is t/log ( t ) -- first of all , do you mean r_t /log ( t ) instead ? ; and secondly , why do we divide it by log ( t ) but not t ? Are n't we ultimately interested in the limit of the average regret r_t/t ? Furthermore , despite the claim that this method is proposed for the setting with huge feature sets ( with billions of dimensions ) , the synthetic experiment is mostly around 200 ; and up to 2000 , which is a bit disappointing . On the same note , despite having a main claim of computational efficiency , there is not a single experiment that showcase this advantage over existing methods . REVIEW SUMMARY The paper aims to develop a posterior approximation scheme for sparse online logistic regression . While the key idea is to achieve faster computation time and better regret rate than existing methods , this point has not been demonstrated sufficiently due to a complete lack of complexity analysis and experiments on large-scale , real-world data with more recent benchmark . The paper also appears to overclaim on the analytic tractability of its update as I have pointed out above . Note : This is only my preliminary assessment and there is of course the possibility that I might miss some important points . In that case , I am looking forward to receiving detailed clarifications from the authors .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their time and effort , and for their invaluable comments . We revised the paper to incorporate changes motivated by the reviewer \u2019 s suggestions . Below are specific responses to some comments . We believe that some of the reviewer \u2019 s comments originate from some misconception about the content of the paper . Below we try to clarify these misconceptions and the differences between the proposed methods and some claims made by the reviewer . - Approximating of posterior in this paper is a tool for minimizing regret with a Bayesian method , and not the other way around . The purpose is not to approximate the posterior , but to minimize regret . In that , this work is different from much of the work in the literature that focused on matching the posterior . It also differs from most work by doing this online , where the problem dictates having a prediction based only on data that was observed so far . Most literature on Bayesian methods considered the batch setting , where a batch of ( training ) data is available as long as needed to update and refine predictions . This is not the case here . A datum is seen , the model must update , and move on to the next datum . - * * Key ideas : * * The reviewer identifies technical ideas that were used for the analysis . However , these are not the conceptual key ideas that motivated this work , these are technical steps that were used for the analysis . The key ideas are : A ) a properly designed Bayesian mixture over the parameter space retains the effects of the optimal ( regret minimizing ) values of the parameters , and by doing so , yields optimal regret . B ) Retaining the effect of such a mixture at the optimal point by an appropriate low-complexity approximation can retain regret optimality . Statistical independence allows retaining this effect ( or most of it ) with a diagonal approximation . Such statistical independence is justified in sparse problems unlike dense problems , where more features are correlated , or co-occur in the same examples , in the sparse problems co-occurrence is more sporadic , and then diagonalization is justified . - * * Novelty : * * \u201c the iterative update derived from Eq . ( 15 ) only involves a single sample at round ( t ) \u201d - This is NOT the message in the paper , this statement distinguishes an online scheme from a batch method . The problem considered in this paper is indeed the online problem , and most of the literature considered the batch one . However , the main aspect distinguishing this work from VB methods ( even online ones ) is the fact that the update per-example in the online setting requires O ( 1 ) operations , whereas VB methods require O ( N ) where N is the number of Monte Carlo samples drawn to apply an update for the current example . The ( b ) claim made by the reviewer is true . Despite the low-complexity the method outperforms other low-complexity or high complexity methods for the sparse problem . - * * Novelty comment ( a ) reviewer elaboration : * * The reviewer considers updates on multiple examples vs. update on a single example . In our setting , updates for all algorithms are applied for one example . We do show a VB based approach that applies such updates for comparison . In the runtime benchmarks that we added , it is shown that the algorithms with VB take orders of magnitude more time than our approach , only to give inferior results . - VB , EM , CAVI - all these algorithms are more expensive than our proposed method , as they either iterate over the features ( not necessarily over examples ) or require multiple samples to average over . They can be applied in the online setting , as we illustrate for VB in the paper , but their runtime/performance tradeoffs are inferior . And at best , since they are based on the same theory foundation of our method , they can achieve the same regret as our method with much higher complexity . - While loss can factorize across different data points , it does not across the features of the same data point , because the label prediction is a function of the weighted sum of covariate weights . This means that to apply an approach like VB over an example with 30 active features , one would need to average over X^30 samples , where X is the number of samples to get a good estimate of one dimension of the posterior . So , while we can factorize over examples , this is not the issue here . Factorizing over covariates of the same example is the issue . However , even with marginalization , as we show in the paper , applying 1000 samples to each dimension after marginalization still falls short of our method in terms of regret , but results in an algorithm whose runtime is O ( 1000 ) slower ."}, {"review_id": "6jlNy83JUQ_-3", "review_text": "The authors propose a low complexity approximation method with closed analytic forms for doing logistic regression in the sparse , online setting . They first introduce the marginalized bayesian gaussian approximation approach , which essentially replaces the sigmoidal with a gaussian . They then give approximate expressions for the prediction and marginalization terms , as well as ways to approximate/update the posterior . This is an interesting approach . The pros are clear : closed-form analytic updates that attempt to retain the core advantages of a Bayesian approach . The authors should address the following questions/concerns : Assumptions : The diagonal Gaussian assumption appears to be quite strong . Are there comments/extensions on how to incorporate this for correlated/collinear covariates ? Approximation : The approximation is based on a Gaussian approximation to the sigmoidal . Are there any theoretical/quantitative guarantees on the approximation error ? Right now the approximation is just a heuristic . Experiments : since one of the main proposed advantage of this scheme is that it is computationally faster , it would be nice to have experiments/charts showing how much faster ( in actual experiments ) does this method run when compared to competitors like VB or a Gibbs sampler . Also , there is a Newton \u2019 s method step in the algorithm . Could the authors comment on how that affects run time ? Motivation : If you are using a Gaussian to approximate the Sigmoidal , since you are using a Gaussian anyways , why not just use an online probit regression then , instead of the logistic ? Overall , I think this is a potentially useful proposal that is interesting , but I think a ) more experiments needs to be done with competitors to illustrate not just regret , but runtime comparisons b ) there needs to be more theoretical rigor as to how an approximation performs and what the approximation error/bounds/guarantees are . I also looked at the citations more closely , and I discovered that there are some mis-citations : For example , you cited Terry Anderson . The theory and practice of online learning . Athabasca University Press , 2008 , which upon further inspection is about online ( as in over-the-internet ) learning , not online learning in the machine learning sense .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their time , efforts and invaluable comments . We revised the paper to incorporate changes motivated by the suggestions of the reviewer . - * * Diagonal assumption : * * This assumption is standard in * * sparse * * problems , and in the Bayesian literature of such problems ( as variational inference methods ) , where full matrix operations are not feasible due to the dimensionality of the problem . It is also standard for similar convex optimization techniques using gradient methods . The problem we consider can allow billions of features , out of which only a different small subset is present in each example . In practice , the sparse diagonal solution works well for large scale datasets . ( Diagonalization is , in fact , the approach used in many practical systems that use gradient methods . ) We add results on the Criteo benchmark dataset to demonstrate this . Furthermore , approaches like the one we empirically compare to , that update the full matrix of nonzero covariates at a given example , degrade when there is high sparsity due to attempting to explain some of the signal by correlations that are not really there . Results we incorporate in the revised version with the Criteo dataset demonstrate that the full matrix updates are also inferior in practice for such datasets . With known collinear subsets of covariates one can use updates such as the multi-dimensional matrix update described in Appendix B.1 ( now D.1 ) . We extended the description of this method in the revision . Finally , as shown in ( Kakade , Ng.2005 , Shamir 2020 ) , a distribution over the parameter is a means of performing Bayesian mixture on the unknown value of each parameter , such that the final posterior would tend to a point mass around the regret minimizer value . Correlated covariates change the interim behavior early on , but at the horizon , even if covariates are correlated , the algorithm will converge to almost point masses . In practice , this is not the case , however , as many covariates occur a limited number of times . - * * Gaussian Approximation : * * This is standard , and appears , e.g. , in Kevin Murphy \u2019 s book and other literature . The loss due to approximating the Sigmoid by a Gaussian appears rather small relative to the approximation of the posterior as normal diagonal . We are re-incorporating some illustrations in an appendix , which we omitted from the text of the original submission , due to page limits , that show how close the approximation is to the Sigmoid . - * * Complexity/speed : * * Run times were proportional to the number of iterations . With the variational methods , even with 1000 examples per data point , regret fell short of the new approach , but the iterations were expectedly orders of magnitude slower , even when using highly optimized vector operations ( as in the Eigen package ) . Roughly , runtime increases by O ( N ) if we apply Monte Carlo on N samples . We incorporated time benchmarks in the paper that clearly demonstrate the substantial speed improvements beyond what we had explained in the original text . Benchmarks show that the Newton iterations do not noticeably slow down the first method , as they seem to converge rather fast , with a very small number of iterations ( unlike the variational methods ) . However , the second method , using further approximation ( eq . ( 17 ) instead of ( 15 ) for updating mu ) , does not require Newton iterations at all , and is as good empirically . - * * Probit Regression : * * One can certainly use this approach with probit regression . We added the equations for a similar algorithm with probit regression in an appendix . However , a ) logistic regression has been much more common in practice ( possibly due to the popularity of gradient methods , where gradients are much simpler with logistic regression ) , and b ) Probit would still require numerical methods , ( which are , however , available in programming languages , ) for evaluating the Gaussian CDF ."}], "0": {"review_id": "6jlNy83JUQ_-0", "review_text": "This paper proposes an algorithm for online logistic regression based on analytical formulas that approximate the Bayesian predictive posterior . These approximations are based on assuming a diagonal covariance Gaussian form for the posterior at each iteration that is optimized to fit the true posterior . Two alternatives are proposed for the optimization : one based on Newton 's method and the other based on a Taylor series approximation , which experimentally yields similar results . Thanks to these closed formula approximations , the resulting algorithm has a constant low cost per observation and is particularly suitable for sparse high-dimensional scenarios . It is empirically shown that the algorithm achieves a known regret lower bound on synthetic data when the true prior on the weights used to generate the data is provided to the algorithm . Strong points : - The introduction properly positions the work - A low-complexity algorithm for online prediction suitable for sparse high-dimensional features is proposed Weak points : - No theoretical guarantees on the regret - Regret is strongly dependent on the prior - No experiments on real datasets This paper proposes a low-complexity approximated bayesian algorithm that aims at attaining known regret lower bounds that have been recently shown [ Shamir 2020 ] to be achievable by exact Bayesian methods . Unfortunately , no theoretical guarantees are provided on the impact of such approximations and the empirical performance is reported to be strongly affected by the choice of the prior . In particular , it is reported that the prior has to fit the data for good regret . This strong dependence on the prior makes it of limited practical interest in real life online scenarios . Therefore , I think that the paper is not strong enough and recommend its rejection . Detailed comments : Section 3 could be better structured and a `` road map '' at the beginning of the section would help the reader to quickly understand the different steps involved in the approximation . If I understood correctly , in order to build a synthetic dataset , - you sample the weights $ w^\\star $ using some prior ( a gaussian with mean 0 and STD specified in the title of each plot ) .\\ - At time $ t $ , you sample random features $ x_ { i , t } $ using different distributions , depending on the type.\\ - You add up these features weighted by $ w^\\star $ to obtain the true log-odds that is used to define the probability distribution ( through the sigmoid ) from which $ y_t $ is sampled . Then , the following sentence is confusing : `` The \u201c true \u201d log-odds of the features drawn at t were added up , weighted by $ x_ { i , t } $ , and converted to probability with the Sigmoid function . '' In the following sentence you use $ \\tau $ that does n't appear in eq.4 : `` Results describe a time series on ( 4 ) , where summation is on $ \\tau $ up to example $ t $ at time $ t $ . '' `` We demonstrate that it is sufficient to approximate the component of the posterior which will dominate at the horizon , matching it by a diagonal Gaussian approximation , '' How is this demonstrated ? Eq 11 : ( d ) should be with $ \\approx $ instead of $ = $ Since nonparametric Bayesian methods are mentioned in the abstract , it would be interesting to see a comparison against online nonparametric Bayesian methods . In my opinion , the title should say `` online prediction '' instead of `` online learning '' , since the latter does not necessarily imply predicting at each round and cumulating the loss . Typos : \\ -- mostly a function * of * the number\\ -- Jeffery 's prior - > Jeffreys prior ==POST-REBUTTAL COMMENTS== I thank the authors for the response and the efforts in the updated draft , in particular with respect to the new experiment on the Criteo dataset . Regarding the following arguments : 1- * '' The dependence of regret on the prior applies to any Bayesian method , in the same way that tuning the learning rate for gradient methods is necessary . `` * I agree that , for batch methods , the prior can be tuned to the data . Nevertheless , in an online prediction setting , the prior needs to be chosen before observing the data and once you start predicting you ca n't go back and change the prior for the already predicted sequence . 2- * '' To the best of our knowledge , none of the literature that proposed practical ( online ) Bayesian methods proposed regret bounds or even studied regret for these methods '' * Regarding both arguments , there is recent literature that proposes a practical nonparametric online prediction method with regret guarantees for a fixed given prior : * Lh\u00e9ritier , Alix , and Frederic Cazals . `` Low-Complexity Nonparametric Bayesian Online Prediction with Universal Guarantees . '' Advances in Neural Information Processing Systems . 2019 . * Therefore , unfortunately , my first two concerns ( theoretical guarantees on the regret and strong dependence on the prior ) remain so I retain my original decision .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their time and effort , and for their invaluable comments . We revised the paper to incorporate changes motivated by the reviewer \u2019 s suggestions . Below are specific responses to some comments . - * * Theoretical guarantees : * * To the best of our knowledge , none of the literature that proposed practical ( online ) Bayesian methods proposed regret bounds or even studied regret for these methods . Loss and accuracy were considered , but it was never indicative which fraction of the loss to attribute to data uncertainty , and which to regret ( which corresponds to the model/epistemic uncertainty ) . In fact , we believe that such study in our paper is novel . While several theoretical papers ( Kakade , Ng.2005 , Foster et . al.2018 , Shamir 2020 ) showed that Bayesian methods can , in fact , be optimal for regret , the literature on practical approaches lacks such connections . Our paper intends to bring a proof of concept to a low complexity approach that appears to outperform other methods or match substantially more complex methods . Proving regret bounds for such an approach could be a theoretical COLT paper by itself , and no such bounds exist for any other practical methods . We believe that synthetic data is the first proof of concept to regret performance of such methods . The synthetic data brings a dimension that real data does not , by allowing empirical results to focus on regret , regardless of the true parameter values , which modify the loss . It also isolates the measurements from other phenomena that affect real data , such as model misspecification and nonstationarity . - * * Regret and prior : * * The dependence of regret on the prior applies to any Bayesian method , in the same way that tuning the learning rate for gradient methods is necessary . While theoretical results ( Shamir 20 ) do show that the lower bounds are achievable regardless of the prior ( as long as a comparator is confined to some space ) , performance of practical techniques is a function of the prior chosen . What we show is that if the prior used matches the data , we achieve better regret than other methods whose hyper-parameters were also tuned to attain their best performance . While it would be nice to have an algorithm whose performance is not affected by the choice of either prior or other hyper-parameters , no other known methods have such properties . We respectfully disagree with the reviewer \u2019 s claim that \u201c This strong dependence on the prior makes it of limited practical interest in real life online scenarios \u201d . Practical methods * * do tune * * learning rates and/or priors to fit the data in practical systems . Our algorithm is no different from that . Once tuned , it outperforms other methods . - * * Real datasets : * * As discussed above , it is nice to have results on real datasets , and we added such results . However , loss on these datasets reveals limited information about regret , which is what the paper attempts to minimize . Loss , relative to other methods , does indicate whether regret is better for one algorithm over another , but it doesn \u2019 t measure the regret . Furthermore , loss on real data can also be affected by properties of the data , like nonstationarity , which we do not attempt to address in this paper . To address nonstationarity , misspecification or other artifacts of real data , additional modifications may be necessary to an algorithm . The goal of the paper is to show that this method works in a clean stationary setting . This can lead to development of methods based on the foundation laid by this paper that address other properties of learning models on real data . - A road map has been added in Section 3 . - Sentences that were unclear to the reviewer were modified , and minor corrections suggested were made . - \u201c `` We demonstrate that it is sufficient to approximate the component of the posterior which will dominate at the horizon , matching it by a diagonal Gaussian approximation , '' How is this demonstrated ? \u201d - Our regret results show that the proposed algorithms are as good as or outperform methods that match the full distribution instead of the important points of the distribution . - `` Since nonparametric Bayesian methods are mentioned in the abstract , it would be interesting to see a comparison against online nonparametric Bayesian methods. \u201d - There is no mention of nonparametric methods . The reviewer refers to a comment about hyper-parameters that need to be tuned . For the theoretical Bayesian methods ( with known comparator class ) no such hyper-parameters need to be tuned . - We respectfully disagree with the name change proposed by the reviewer . The proposed methods is an online learning algorithm . We measure regret in the standard way it is measured in the online learning literature , and the algorithms learn a distribution within the uncertainty of the parameters ."}, "1": {"review_id": "6jlNy83JUQ_-1", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper proposes an algorithm for learning the parameters of a logistic regression model in an online setting . The proposed algorithm is based on two approximations : the posterior at iteration t over the model parameters is assumed to be multivariate Gaussian distribution with a diagonal covariance matrix and the logistic/sigmoid function is approximated by the CDF of the normal distribution . The numerical results show the usefulness of the proposed algorithm . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Reason for score : My overall impression is that the proposed algorithm is of sufficient interest to warrant the acceptance of the paper . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper proposes analytical expressions for updating the parameters of the logistic regression model in an online setting . The computation cost for updating the parameter is reduced . 2.The paper is overall well written and the authors describe in detail each step in the development of the proposed algorithm . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : 1 . For me it is not clear why you settled on a logistic regression problem instead of probit regression and present the logistic regression as an extension . From my understanding , the keystones for the proposed algorithm are the approximation of the prior as a multivariate Gaussian with diagonal covariance and the marginalization step ( which itself is due to the Gaussian assumption ) . From my point of view , the introduction of the extra approximation layer due to the use of the logistic regression is detrimental to the easy understanding of the paper . I believe it would have been better to just introduce a section that describes the modifications to make in order to apply the proposed algorithm to the logistic regression problem . 2.In section 1 on page 2 you make a statement about the role of an approximation in minimizing the the uncertainty . For me it is not clear how the proposed algorithm addresses this statement . Could you please elaborate on the subject ? Also , on page 3 you say that it is sufficient to match the component of the posterior that dominates at the horizon . What do you exactly mean by the component of the posterior ? # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Miscellaneous : 1 . It 's welcoming that the proposed algorithm has very good results , however I 'm a bit surprised that the results are that good . My wariness comes from the fact that in equation 13 you match an approximation to the posterior distribution , which itself was obtained using an approximation . I would expect the errors due to the approximations to accumulate as more and more data items are processed . However , the regret seems to remain steady as you increase the number of items seen . Do you have an explanation as to why the errors due to the approximations do not accumulate ? 2.There are some typos here and there in the article , however I believe you can easily detect them with the help of a spell checker .", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for their time , efforts and invaluable feedback . We revised the paper to address comments by all reviewers . We address the specific comments made by this reviewer below . - * * Probit vs. logistic regression : * * The comment by the reviewer is very relevant , and we agree that the logistic setup introduces more complexity than the probit setup . The reason we chose to focus on logistic regression is mainly the larger popularity of logistic regression in practice . One could argue about the justification of this popularity , but this is the case , especially in the machine learning literature and applied community . We also note that with probit regression , numerical tables or approximations are necessary to compute the Gaussian CDF . A decision could go either way here - the advantage of logistic regression is its popularity , and that of probit is its simplicity . We chose for the first , but we also extended the discussion on the second in a new appendix in the revised version . - * * Approximation and Uncertainty : * * One of the points we tried to emphasize in the paper is the seminal relation established by Rissanen between the minimum description length ( MDL ) and prediction error . Regret is a component of the MDL , which corresponds to the epistemic uncertainty , or in other words , to how well the parameters of the true model are estimated . Therefore , an algorithm with lower regret also estimates the unknown model parameters better ( with lower prediction error ) . It has been established ( Kakade , Ng.2005 , Foster 2018 , Shamir 2020 ) that Bayesian methods in theory can achieve the lower bounds on regret . Therefore , the role of a good approximation is to retain that property , and degrade only components of the distribution that do not affect the regret ( or that minimally affect the regret ) . The claim was made in the paper to pave the path to demonstrate that there are two ends to this . One , use an approximation that is good enough , but on the other hand , don \u2019 t use an approximation that is much more complex , but adds no value over a simple approximation in what matters . - * * Match components of posterior : * * The message in this claim is that an approximation should not scale down the effect of the prior at the point of the distribution where the algorithm converges to at the end . As epistemic uncertainty becomes smaller due to more data , the distribution of a model parameter becomes more and more like a point mass around the regret minimizing value of the parameter . A bad approximation reduces the magnitude at this point . As shown in ( Kakade , Ng.2005 , Shamir 2020 ) , the optimal regret achieves for a parameter is roughly the logarithm of the prior at this point ( or an integral around this point ) . If the approximate posterior scales down the magnitude at this point or its vicinity from the true one , there would be additional regret losses . Given all that , the idea is that we try to pick approximations that have a property that they do not scale down the posteriors at points that are likely to hand up being the convergence point of the parameter . Simple approximations , like Laplace , that focus on the peak follow this . However , complex approximations , like VB , give too much weight to points far from the peak by trying to match the full posterior , and by that also harm the regret . - * * Accumulation of approximation errors : * * We believe that this happens , and that there are some additional penalty terms to the regret . However , if you look at the approximations more carefully , while they lose in some regions , they gain in others . Attributing to the previous point , the approximation can scale down the effect of the prior in one example , but then correct it and scale it up in a subsequent example . The overall effect may hide some of these losses by correction gains that happen in the subsequent examples . It is very difficult to derive regret bounds for these approximation approaches , but such bounds could explain this better . - * * Typos : * * We are making several passes to fix typos on the revised submission ."}, "2": {"review_id": "6jlNy83JUQ_-2", "review_text": "PAPER SUMMARY This paper proposes a new posterior approximation scheme for probabilistic logistic regression . In the online learning setup , the proposed approximation leads to a closed-form parameter update . In particular , the key ideas here include : ( 1 ) A probit approximation of the sigmoid likelihood in Eq . ( 5 ) .This , along with the assumed statistical independence among individual features and another integral approximation trick used in ( Murphy , 2012 ) , leads to a posterior representation in forms of a normalized product between a sigmoid and a normal PDF . ( 2 ) Matching the location and density of its mode to that of another Gaussian surrogate to yield the closed-form update that expresses the parameter at round ( t + 1 ) in terms of its counterpart at round ( t ) analytically in Eq . ( 15 ) NOVELTY & SIGNIFICANCE If I understand correctly , the main arguments in favor of the proposed method are : ( a ) the iterative update derived from Eq . ( 15 ) only involves a single sample at round ( t ) which is more efficient than VB 's or EM 's stochastic gradient updates that require re-iterating over multiple mini-batches of past data ; and ( b ) the new approximation scheme performs empirically better than existing method , and matches state-of-the-art regret lower-bound . Given the current form of the manuscript , these arguments , however , are not very convincing to me as I elaborated in the followings : First , regarding ( a ) , while it is true that VB 's or EM 's offline updates are more expensive than the update derived from Eq . ( 15 ) , it seems to me they can still be made more efficient in online setting with very minor modifications . For instance , in both VB and EM , the lower-bound function often factorizes additively across data point so if we cache all gradient computation in step ( t ) , the computation of new gradient in step ( t + 1 ) also involves only the latest data sample which is likely not more expensive than iteratively solving Eq . ( 15 ) -- I would like to hear the authors ' thoughts on this . Second , the claim that the new approximation scheme performs better than existing methods is not well-supported . In this regard , I wonder why the improved loss is only demonstrated in a very controlled , synthetic experiment settings . One could always argue that as far as only synthetic experiments are involved , there might exist other settings for which we might see the opposite . To me , positive results on a single set of synthetic experiments often do not speak conclusively to whether one method would be more useful than another in practice -- a better way to demonstrate this is to also evaluate the proposed method on real-world benchmark datasets ( especially those extracted from practical domains that were mentioned in the introduction ) Furthermore , the evaluation does not seem to include all the most relevant baselines ( more on this later ) as well as processing time comparison . Given that one of the key contribution claims here is the computation advantage over EM 's and VB 's , both theoretical complexity and empirical demonstration of averaged running time should be provided . In addition , I also find part of the positioning of this paper somewhat misleading , especially when it criticizes stochastic gradient methods for incurring additional losses while the target posterior keeps moving with subsequent samples . Is n't this also true for the proposed method ? While Eq . ( 15 ) is analytic , solving it for the parameter update is clearly not analytically tractable which also requires iterative update ; and then even the resulting approximated posterior has to be matched again to another Gaussian surrogate . Lastly , the conclusion surprisingly summarizes that with proper prior , the method `` matches regret lower-bound '' -- this seems like an overclaim as there is no theoretical analysis in the paper to back this up . TECHNICAL SOUNDNESS I have gone through the derivations and I do not spot any serious issues , but there are parts that seem to lack justification . For instance , could the authors please detail the steps that lead to Eq . ( 5 ) ? Also , it will be even better if the authors could provide plots to visually demonstrate how the derivative of sigmoid is close to the scaled normal CDF . I also find it a bit strange that this paper highlights the sparse aspect of data as an issue but in the end , it appears more to be a necessary setting that justifies the assumed diagonal form of the variance matrix , which is a necessity for most of the technical derivations in this paper . CLARITY While the paper is sufficiently clear , I find the introduction is a bit too long . It could have made its points using much less space . In the current form , it kind of distracts the readers from those key points by throwing in many subsidiary positionings that are better discussed & organized in related work . The claim on analytic update is also a bit exaggerating as solving Eq . ( 15 ) for an update equation is after all not tractable and we will have to resort to iterative method such as Newton 's or Taylor series expansion anyway . EXPERIMENT On the experimental evaluation , my key concern ( as mentioned above ) is the lack of evaluation of real-world dataset , and in addition , some of the more recent methods such as ( Nguyen , 2017a ; 2017b ) were not included in the baseline . The presentation of the evaluation is also problematic when the results seem to be collected on only 1 single run . As a standard practice , please re-run the same experiment multiple times and report the margin of error . It is also unclear why the Y-axis is t/log ( t ) -- first of all , do you mean r_t /log ( t ) instead ? ; and secondly , why do we divide it by log ( t ) but not t ? Are n't we ultimately interested in the limit of the average regret r_t/t ? Furthermore , despite the claim that this method is proposed for the setting with huge feature sets ( with billions of dimensions ) , the synthetic experiment is mostly around 200 ; and up to 2000 , which is a bit disappointing . On the same note , despite having a main claim of computational efficiency , there is not a single experiment that showcase this advantage over existing methods . REVIEW SUMMARY The paper aims to develop a posterior approximation scheme for sparse online logistic regression . While the key idea is to achieve faster computation time and better regret rate than existing methods , this point has not been demonstrated sufficiently due to a complete lack of complexity analysis and experiments on large-scale , real-world data with more recent benchmark . The paper also appears to overclaim on the analytic tractability of its update as I have pointed out above . Note : This is only my preliminary assessment and there is of course the possibility that I might miss some important points . In that case , I am looking forward to receiving detailed clarifications from the authors .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their time and effort , and for their invaluable comments . We revised the paper to incorporate changes motivated by the reviewer \u2019 s suggestions . Below are specific responses to some comments . We believe that some of the reviewer \u2019 s comments originate from some misconception about the content of the paper . Below we try to clarify these misconceptions and the differences between the proposed methods and some claims made by the reviewer . - Approximating of posterior in this paper is a tool for minimizing regret with a Bayesian method , and not the other way around . The purpose is not to approximate the posterior , but to minimize regret . In that , this work is different from much of the work in the literature that focused on matching the posterior . It also differs from most work by doing this online , where the problem dictates having a prediction based only on data that was observed so far . Most literature on Bayesian methods considered the batch setting , where a batch of ( training ) data is available as long as needed to update and refine predictions . This is not the case here . A datum is seen , the model must update , and move on to the next datum . - * * Key ideas : * * The reviewer identifies technical ideas that were used for the analysis . However , these are not the conceptual key ideas that motivated this work , these are technical steps that were used for the analysis . The key ideas are : A ) a properly designed Bayesian mixture over the parameter space retains the effects of the optimal ( regret minimizing ) values of the parameters , and by doing so , yields optimal regret . B ) Retaining the effect of such a mixture at the optimal point by an appropriate low-complexity approximation can retain regret optimality . Statistical independence allows retaining this effect ( or most of it ) with a diagonal approximation . Such statistical independence is justified in sparse problems unlike dense problems , where more features are correlated , or co-occur in the same examples , in the sparse problems co-occurrence is more sporadic , and then diagonalization is justified . - * * Novelty : * * \u201c the iterative update derived from Eq . ( 15 ) only involves a single sample at round ( t ) \u201d - This is NOT the message in the paper , this statement distinguishes an online scheme from a batch method . The problem considered in this paper is indeed the online problem , and most of the literature considered the batch one . However , the main aspect distinguishing this work from VB methods ( even online ones ) is the fact that the update per-example in the online setting requires O ( 1 ) operations , whereas VB methods require O ( N ) where N is the number of Monte Carlo samples drawn to apply an update for the current example . The ( b ) claim made by the reviewer is true . Despite the low-complexity the method outperforms other low-complexity or high complexity methods for the sparse problem . - * * Novelty comment ( a ) reviewer elaboration : * * The reviewer considers updates on multiple examples vs. update on a single example . In our setting , updates for all algorithms are applied for one example . We do show a VB based approach that applies such updates for comparison . In the runtime benchmarks that we added , it is shown that the algorithms with VB take orders of magnitude more time than our approach , only to give inferior results . - VB , EM , CAVI - all these algorithms are more expensive than our proposed method , as they either iterate over the features ( not necessarily over examples ) or require multiple samples to average over . They can be applied in the online setting , as we illustrate for VB in the paper , but their runtime/performance tradeoffs are inferior . And at best , since they are based on the same theory foundation of our method , they can achieve the same regret as our method with much higher complexity . - While loss can factorize across different data points , it does not across the features of the same data point , because the label prediction is a function of the weighted sum of covariate weights . This means that to apply an approach like VB over an example with 30 active features , one would need to average over X^30 samples , where X is the number of samples to get a good estimate of one dimension of the posterior . So , while we can factorize over examples , this is not the issue here . Factorizing over covariates of the same example is the issue . However , even with marginalization , as we show in the paper , applying 1000 samples to each dimension after marginalization still falls short of our method in terms of regret , but results in an algorithm whose runtime is O ( 1000 ) slower ."}, "3": {"review_id": "6jlNy83JUQ_-3", "review_text": "The authors propose a low complexity approximation method with closed analytic forms for doing logistic regression in the sparse , online setting . They first introduce the marginalized bayesian gaussian approximation approach , which essentially replaces the sigmoidal with a gaussian . They then give approximate expressions for the prediction and marginalization terms , as well as ways to approximate/update the posterior . This is an interesting approach . The pros are clear : closed-form analytic updates that attempt to retain the core advantages of a Bayesian approach . The authors should address the following questions/concerns : Assumptions : The diagonal Gaussian assumption appears to be quite strong . Are there comments/extensions on how to incorporate this for correlated/collinear covariates ? Approximation : The approximation is based on a Gaussian approximation to the sigmoidal . Are there any theoretical/quantitative guarantees on the approximation error ? Right now the approximation is just a heuristic . Experiments : since one of the main proposed advantage of this scheme is that it is computationally faster , it would be nice to have experiments/charts showing how much faster ( in actual experiments ) does this method run when compared to competitors like VB or a Gibbs sampler . Also , there is a Newton \u2019 s method step in the algorithm . Could the authors comment on how that affects run time ? Motivation : If you are using a Gaussian to approximate the Sigmoidal , since you are using a Gaussian anyways , why not just use an online probit regression then , instead of the logistic ? Overall , I think this is a potentially useful proposal that is interesting , but I think a ) more experiments needs to be done with competitors to illustrate not just regret , but runtime comparisons b ) there needs to be more theoretical rigor as to how an approximation performs and what the approximation error/bounds/guarantees are . I also looked at the citations more closely , and I discovered that there are some mis-citations : For example , you cited Terry Anderson . The theory and practice of online learning . Athabasca University Press , 2008 , which upon further inspection is about online ( as in over-the-internet ) learning , not online learning in the machine learning sense .", "rating": "4: Ok but not good enough - rejection", "reply_text": "We thank the reviewer for their time , efforts and invaluable comments . We revised the paper to incorporate changes motivated by the suggestions of the reviewer . - * * Diagonal assumption : * * This assumption is standard in * * sparse * * problems , and in the Bayesian literature of such problems ( as variational inference methods ) , where full matrix operations are not feasible due to the dimensionality of the problem . It is also standard for similar convex optimization techniques using gradient methods . The problem we consider can allow billions of features , out of which only a different small subset is present in each example . In practice , the sparse diagonal solution works well for large scale datasets . ( Diagonalization is , in fact , the approach used in many practical systems that use gradient methods . ) We add results on the Criteo benchmark dataset to demonstrate this . Furthermore , approaches like the one we empirically compare to , that update the full matrix of nonzero covariates at a given example , degrade when there is high sparsity due to attempting to explain some of the signal by correlations that are not really there . Results we incorporate in the revised version with the Criteo dataset demonstrate that the full matrix updates are also inferior in practice for such datasets . With known collinear subsets of covariates one can use updates such as the multi-dimensional matrix update described in Appendix B.1 ( now D.1 ) . We extended the description of this method in the revision . Finally , as shown in ( Kakade , Ng.2005 , Shamir 2020 ) , a distribution over the parameter is a means of performing Bayesian mixture on the unknown value of each parameter , such that the final posterior would tend to a point mass around the regret minimizer value . Correlated covariates change the interim behavior early on , but at the horizon , even if covariates are correlated , the algorithm will converge to almost point masses . In practice , this is not the case , however , as many covariates occur a limited number of times . - * * Gaussian Approximation : * * This is standard , and appears , e.g. , in Kevin Murphy \u2019 s book and other literature . The loss due to approximating the Sigmoid by a Gaussian appears rather small relative to the approximation of the posterior as normal diagonal . We are re-incorporating some illustrations in an appendix , which we omitted from the text of the original submission , due to page limits , that show how close the approximation is to the Sigmoid . - * * Complexity/speed : * * Run times were proportional to the number of iterations . With the variational methods , even with 1000 examples per data point , regret fell short of the new approach , but the iterations were expectedly orders of magnitude slower , even when using highly optimized vector operations ( as in the Eigen package ) . Roughly , runtime increases by O ( N ) if we apply Monte Carlo on N samples . We incorporated time benchmarks in the paper that clearly demonstrate the substantial speed improvements beyond what we had explained in the original text . Benchmarks show that the Newton iterations do not noticeably slow down the first method , as they seem to converge rather fast , with a very small number of iterations ( unlike the variational methods ) . However , the second method , using further approximation ( eq . ( 17 ) instead of ( 15 ) for updating mu ) , does not require Newton iterations at all , and is as good empirically . - * * Probit Regression : * * One can certainly use this approach with probit regression . We added the equations for a similar algorithm with probit regression in an appendix . However , a ) logistic regression has been much more common in practice ( possibly due to the popularity of gradient methods , where gradients are much simpler with logistic regression ) , and b ) Probit would still require numerical methods , ( which are , however , available in programming languages , ) for evaluating the Gaussian CDF ."}}