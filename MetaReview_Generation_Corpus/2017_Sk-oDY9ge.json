{"year": "2017", "forum": "Sk-oDY9ge", "title": "Diet Networks: Thin Parameters for Fat Genomics", "decision": "Accept (Poster)", "meta_review": "The reviewers agreed that the paper proposed a solid and original contribution that was evaluated well. The authors would be encouraged to improve the presentation and provide a more precise mathematical presentation, as discussed by reviewer 1.", "reviews": [{"review_id": "Sk-oDY9ge-0", "review_text": "The paper presents an application of deep learning to genomic SNP data with a comparison of possible approaches for dealing with the very high data dimensionality. The approach looks very interesting but the experiments are too limited to draw firm conclusions about the strengths of different approaches. The presentation would benefit from more precise math. Quality: The basic idea of the paper is interesting and the applied deep learning methodology appears reasonable. The experimental evaluation is rather weak as it only covers a single data set and a very limited number of cross validation folds. Given the significant variation in the performances of all the methods, it seems the differences between the better-performing methods are probably not statistically significant. More comprehensive empirical validation could clearly strengthen the paper. Clarity: The writing is generally good both in terms of the biology and ML, but more mathematical rigour would make it easier to understand precisely what was done. The different architectures are explained on an intuitive level and might benefit from a clear mathematical definition. I was ultimately left unsure of what the \"raw end2end\" model is - given so few parameters it cannot work on raw 300k dimensional input but I could not figure out what kind of embedding was used. The results in Fig. 3 might be clearer if scaled so that maximum for each class is 1 to avoid confounding from different numbers of subjects in different classes. In the text, please use the standard italics math font for all symbols such as N, N_d, ... Originality: The application and the approach appear quite novel. Significance: There is clearly strong interest for deep learning in the genomics area and the paper seeks to address some of the major bottlenecks here. It is too early to tell whether the specific techniques proposed in the paper will be the ultimate solution, but at the very least the paper provides interesting new ideas for others to work on. Other comments: I think releasing the code as promised would be a must. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the nice comments and the useful observations that are helping improve the paper . 1 ) The basic idea of the paper is interesting and the applied deep learning methodology appears reasonable . The experimental evaluation is rather weak as it only covers a single data set and a very limited number of cross validation folds . Given the significant variation in the performances of all the methods , it seems the differences between the better-performing methods are probably not statistically significant . More comprehensive empirical validation could clearly strengthen the paper . A1 : Among the better performing architectures , the goal was to reduce the number of parameters of our model . Hence , we show that we are able to drastically reduce the number of free parameters in the model without hurting the performance . Moreover , to strengthen the argument on superiority of deep learning methods over classical approaches used in the genomics domain ( e.g.PCA-based ) , we performed a binomial test to compare the results achieved by classical approaches to the Diet Networks ones . When comparing the best results achieved by PCA ( with 200 pcs ) to the best Diet Networks model , the results are statistically significant ( for alpha=0.05 ) . We obtain a p-value of 2.4e-6 , highlighting the potential of deep learning approaches to handle genomic data . 2 ) The writing is generally good both in terms of the biology and ML , but more mathematical rigour would make it easier to understand precisely what was done . The different architectures are explained on an intuitive level and might benefit from a clear mathematical definition . I was ultimately left unsure of what the `` raw end2end '' model is - given so few parameters it can not work on raw 300k dimensional input but I could not figure out what kind of embedding was used . A2 : In raw end2end , the auxiliary network takes as input one SNP ( 2070 features , corresponding to training samples ) and learns a feature embedding of dimensionality 100 ( Fig.1 ( b ) Emb . ) , followed by a second feature representation of dimensionality 100 ( Fig.1 ( b ) MLP , in this case one single hidden layer ) . The second feature representation is used as We . So , the auxiliary network has 2070 * 100 + 100 + 100 * 100+100 free parameters instead of the 315345 * 100 free parameters that We in Fig.1 ( a ) would have . We thank the reviewer for pointing out this issue . We have included the following paragraph in the Feature Embedding section with the goal of improving the clarity of the presentation w.r.t.the raw end2end embedding : \u201c Embedding learnt end-to-end from raw data : In this case , we consider the feature embedding to be another MLP , whose input corresponds to the values that a SNP takes for each of the training samples and , whose parameters are learnt jointly with the rest of the network . Note that the layer ( s ) corresponding to the feature embedding are shared among auxiliary networks . For experiments reported in Section 4 , we used a single hidden layer as embedding. \u201d Moreover , we updated Table 1 such that it only includes the number of free parameters in the fat layers of the model , since the other free parameters are present in all architectures . We hope this will simplify the computation of the number of free parameters . 3 ) The results in Fig.3 might be clearer if scaled so that maximum for each class is 1 to avoid confounding from different numbers of subjects in different classes . In the text , please use the standard italics math font for all symbols such as N , N_d , ... A3 : As suggested , we have updated both Fig.3 and the notation in the most recent version of the paper . 4 ) I think releasing the code as promised would be a must . A4 : The code is now publicly available and the link to the repository has been included in the paper ( see footnote on page 6 ) . We hope we properly addressed the reviewer 's concerns and improved our paper with their comments ."}, {"review_id": "Sk-oDY9ge-1", "review_text": "The paper addresses the important problem (d>>n) in deep learning. The proposed approach, based on lower-dimensional feature embeddings, is reasonable and makes applying deep learning methods to data with large d possible. The paper is well written and the results show improvements over reasonable baselines. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the nice comments/suggestions that are helping improve the paper and hope we have properly addressed their previous questions . As suggested , we have updated Table 1 with PCA performance for different numbers of PCs and different MLP classifier architectures . We have also added an appendix section to analyze the influence of using different numbers of pcs ."}, {"review_id": "Sk-oDY9ge-2", "review_text": "The problem addressed here is practically important (supervised learning with n<<d), and as far as I know, the approach is novel. I thought their proposed solution was innovative, and I enjoyed the paper. The presentation is clear and it has nice experiments. Comments/questions: 1) What is the dimensionality of the feature embeddings? 2) SNPtoVec still requires training a very fat autoencoder network on X --- I suppose this doesn't contribute to the size of the final run-time model and overfitting is avoided because the parameters are fit in an unsupervised manner? ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review . 1 ) The 'Per class histograms ' model , as briefly described in section 2.2 , uses feature embeddings of size 78 because every feature has 3 possible values and the data contains 26 classes ( 26 * 3 = 78 ) . For the other methods , the results reported in table 1 use feature embeddings of size 100 . 2 ) Yes , exactly ."}], "0": {"review_id": "Sk-oDY9ge-0", "review_text": "The paper presents an application of deep learning to genomic SNP data with a comparison of possible approaches for dealing with the very high data dimensionality. The approach looks very interesting but the experiments are too limited to draw firm conclusions about the strengths of different approaches. The presentation would benefit from more precise math. Quality: The basic idea of the paper is interesting and the applied deep learning methodology appears reasonable. The experimental evaluation is rather weak as it only covers a single data set and a very limited number of cross validation folds. Given the significant variation in the performances of all the methods, it seems the differences between the better-performing methods are probably not statistically significant. More comprehensive empirical validation could clearly strengthen the paper. Clarity: The writing is generally good both in terms of the biology and ML, but more mathematical rigour would make it easier to understand precisely what was done. The different architectures are explained on an intuitive level and might benefit from a clear mathematical definition. I was ultimately left unsure of what the \"raw end2end\" model is - given so few parameters it cannot work on raw 300k dimensional input but I could not figure out what kind of embedding was used. The results in Fig. 3 might be clearer if scaled so that maximum for each class is 1 to avoid confounding from different numbers of subjects in different classes. In the text, please use the standard italics math font for all symbols such as N, N_d, ... Originality: The application and the approach appear quite novel. Significance: There is clearly strong interest for deep learning in the genomics area and the paper seeks to address some of the major bottlenecks here. It is too early to tell whether the specific techniques proposed in the paper will be the ultimate solution, but at the very least the paper provides interesting new ideas for others to work on. Other comments: I think releasing the code as promised would be a must. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the nice comments and the useful observations that are helping improve the paper . 1 ) The basic idea of the paper is interesting and the applied deep learning methodology appears reasonable . The experimental evaluation is rather weak as it only covers a single data set and a very limited number of cross validation folds . Given the significant variation in the performances of all the methods , it seems the differences between the better-performing methods are probably not statistically significant . More comprehensive empirical validation could clearly strengthen the paper . A1 : Among the better performing architectures , the goal was to reduce the number of parameters of our model . Hence , we show that we are able to drastically reduce the number of free parameters in the model without hurting the performance . Moreover , to strengthen the argument on superiority of deep learning methods over classical approaches used in the genomics domain ( e.g.PCA-based ) , we performed a binomial test to compare the results achieved by classical approaches to the Diet Networks ones . When comparing the best results achieved by PCA ( with 200 pcs ) to the best Diet Networks model , the results are statistically significant ( for alpha=0.05 ) . We obtain a p-value of 2.4e-6 , highlighting the potential of deep learning approaches to handle genomic data . 2 ) The writing is generally good both in terms of the biology and ML , but more mathematical rigour would make it easier to understand precisely what was done . The different architectures are explained on an intuitive level and might benefit from a clear mathematical definition . I was ultimately left unsure of what the `` raw end2end '' model is - given so few parameters it can not work on raw 300k dimensional input but I could not figure out what kind of embedding was used . A2 : In raw end2end , the auxiliary network takes as input one SNP ( 2070 features , corresponding to training samples ) and learns a feature embedding of dimensionality 100 ( Fig.1 ( b ) Emb . ) , followed by a second feature representation of dimensionality 100 ( Fig.1 ( b ) MLP , in this case one single hidden layer ) . The second feature representation is used as We . So , the auxiliary network has 2070 * 100 + 100 + 100 * 100+100 free parameters instead of the 315345 * 100 free parameters that We in Fig.1 ( a ) would have . We thank the reviewer for pointing out this issue . We have included the following paragraph in the Feature Embedding section with the goal of improving the clarity of the presentation w.r.t.the raw end2end embedding : \u201c Embedding learnt end-to-end from raw data : In this case , we consider the feature embedding to be another MLP , whose input corresponds to the values that a SNP takes for each of the training samples and , whose parameters are learnt jointly with the rest of the network . Note that the layer ( s ) corresponding to the feature embedding are shared among auxiliary networks . For experiments reported in Section 4 , we used a single hidden layer as embedding. \u201d Moreover , we updated Table 1 such that it only includes the number of free parameters in the fat layers of the model , since the other free parameters are present in all architectures . We hope this will simplify the computation of the number of free parameters . 3 ) The results in Fig.3 might be clearer if scaled so that maximum for each class is 1 to avoid confounding from different numbers of subjects in different classes . In the text , please use the standard italics math font for all symbols such as N , N_d , ... A3 : As suggested , we have updated both Fig.3 and the notation in the most recent version of the paper . 4 ) I think releasing the code as promised would be a must . A4 : The code is now publicly available and the link to the repository has been included in the paper ( see footnote on page 6 ) . We hope we properly addressed the reviewer 's concerns and improved our paper with their comments ."}, "1": {"review_id": "Sk-oDY9ge-1", "review_text": "The paper addresses the important problem (d>>n) in deep learning. The proposed approach, based on lower-dimensional feature embeddings, is reasonable and makes applying deep learning methods to data with large d possible. The paper is well written and the results show improvements over reasonable baselines. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for the nice comments/suggestions that are helping improve the paper and hope we have properly addressed their previous questions . As suggested , we have updated Table 1 with PCA performance for different numbers of PCs and different MLP classifier architectures . We have also added an appendix section to analyze the influence of using different numbers of pcs ."}, "2": {"review_id": "Sk-oDY9ge-2", "review_text": "The problem addressed here is practically important (supervised learning with n<<d), and as far as I know, the approach is novel. I thought their proposed solution was innovative, and I enjoyed the paper. The presentation is clear and it has nice experiments. Comments/questions: 1) What is the dimensionality of the feature embeddings? 2) SNPtoVec still requires training a very fat autoencoder network on X --- I suppose this doesn't contribute to the size of the final run-time model and overfitting is avoided because the parameters are fit in an unsupervised manner? ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review . 1 ) The 'Per class histograms ' model , as briefly described in section 2.2 , uses feature embeddings of size 78 because every feature has 3 possible values and the data contains 26 classes ( 26 * 3 = 78 ) . For the other methods , the results reported in table 1 use feature embeddings of size 100 . 2 ) Yes , exactly ."}}