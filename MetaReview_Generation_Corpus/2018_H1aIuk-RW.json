{"year": "2018", "forum": "H1aIuk-RW", "title": "Active Learning for Convolutional Neural Networks: A Core-Set Approach", "decision": "Accept (Poster)", "meta_review": "The effectiveness of active learning techniques for training modern deep learning pipelines in a label efficient manner is certainly a very well motivated topic. The reviewers unanimously found the contributions of this paper to be of interest, particularly nice empirical gains over several natural baselines.", "reviews": [{"review_id": "H1aIuk-RW-0", "review_text": "After reading rebuttals from the authors: The authors have addressed all of my concerns. THe additional experiments are a good addition. ************************ The authors provide an algorithm-agnostic active learning algorithm for multi-class classification. The core technique is to construct a coreset of points whose labels inform the labels of other points. The coreset construction requires one to construct a set of points which can cover the entire dataset. While this is NP-hard problem in general, the greedy algorithm is 2-approximate. The authors use a variant of the greedy algorithm along with bisection search to solve a series of feasibility problems to obtain a good cover of the dataset each time. This cover tells us which points are to be queried. The reason why choosing the cover is a good idea is because under suitable Lipschitz continuity assumption the generalization error can be controlled via an appropriate value of the covering radius in the data space. The authors use the coreset construction with a CNN to demonstrate an active learning algorithm for multi-class classification. The experimental results are convincing enough to show that it outperforms other active learning algorithms. However, I have a few major and minor comments. Major comments: 1. The proof of Lemma 1 is incomplete. We need the Lipschitz constant of the loss function. The loss function is a function of the CNN function and the true label. The proof of lemma 1 only establishes the Lipschitz constant of the CNN function. Some more extra work is needed to derive the lipschitz constant of the loss function from the CNN function. 2. The statement of Prop 1 seems a bit confusing to me. the hypothsis says that the loss on the coreset = 0. But the equation in proposition 1 also includes the loss on the coreset. Why is this term included. Is this term not equal to 0? 3. Some important works are missing. Especially works related to pool based active learning, and landmark results on labell complexity of agnostic active learning. UPAL: Unbiased Pool based active learning by Ganti & Gray. http://proceedings.mlr.press/v22/ganti12/ganti12.pdf Efficient active learning of half-spaces by Gonen et al. http://www.jmlr.org/papers/volume14/gonen13a/gonen13a.pdf A bound on the label complexity of agnostic active learning. http://www.machinelearning.org/proceedings/icml2007/papers/375.pdf 4. The authors use L_2 loss as their objective function. This is a bit of a weird choice given that they are dealing with multi-class classification and the output layer is a sigmoid layer, making it a natural fit to work with something like a cross-entropy loss function. I guess the theoretical results do not extend to cross-entropy loss, but the authors do not mention these points anywhere in the paper. For example, the ladder network, which is one of the networks used by the authors is a network that uses cross-entropy for training. Minor-comment: 1. The feasibility program in (6) is an MILP. However, the way it is written it does not look like an MILP. It would have been great had the authors mentioned that u_j \\in {0,1}. 2. The authors write on page 4, \"Moreover, zero training error can be enforced by converting average loss into maximal loss\". It is not clear to me what the authors mean here. For example, can I replace the average error in proposition 1, by maximal loss? Why can I do that? Why would that result in zero training error? On the whole this is interesting work and the results are very nice. But, the proof for Lemma 1 seems incomplete to me, and some choices (such as choice of loss function) are unjustified. Also, important references in active learning literature are missing.", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their time and effort spent providing feedback . We appreciate the encouraging comments . We address the concerns as follows : Major Points : 1 ) Proof of Lemma 1 : The reviewer is right as the current proof of the Lemma 1 is incomplete . Proposition 1 only requires the loss function to be a Lipschitz continuous function of the x ( input data point ) for a fixed true label ( y ) and parameters ( w ) . Current proof of the Lemma 1 indeed proves this more restrictive but sufficient statement . Hence , we re-stated the Lemma 1 correctly in the updated submission . We also added the final step ( reverse triangle inequality ) to the proof of the Lemma 1 for sake of completeness . 2 ) The statement of Prop 1 : We stated the proposition in this form to be consistent with equation 3 . We clarified this in the updated text 3 ) We updated the related work with the suggested references . 4 ) L_2 loss : We agree that this is unconventional as cross-entropy is the widely accepted choice of loss function for classification problems . We use L_2 loss for theoretical simplicity and used cross-entropy in the experiments . The experimental results suggest that our method is effective for cross-entropy loss as well . We explicitly discussed and clarified this choice in the updated submission . Minor Points : 1 ) MILP : We added the missing constraint -u_j \\in { 0,1 } - in the updated submission 2 ) Maximal Loss : We agree that this is a confusing statement and we removed it in the updated submission . What we meant was although 0 training error on core-set is a hard assumption , it can be directly enforced by using the maximal loss while learning the model . However , we did not use any such trick . We hope that the updated version answer the reviewer 's concerns . Moreover , we also added more details and included two additional baselines in the updated submission ."}, {"review_id": "H1aIuk-RW-1", "review_text": "Active learning for deep learning is an interesting topic and there is few useful tool available in the literature. It is happy to see such paper in the field. This paper proposes a batch mode active learning algorithm for CNN as a core-set problem. The authors provide an upper bound of the core-set loss, which is the gap between the training loss on the whole set and the core-set. By minimizing this upper bound, the problem becomes a K-center problem which can be solved by using a greedy approximation method, 2-OPT. The experiments are performed on image classification problem (CIFAR, CALTECH, SVHN datasets), under either supervised setting or weakly-supervised setting. Results show that the proposed method outperforms the random sampling and uncertainty sampling by a large margin. Moreover, the authors show that 2-OPT can save tractable amount of time in practice with a small accuracy drop. The proposed algorithm is new and writing is clear. However, the paper is not flawless. The proposed active learning framework is under ERM and cover-set, which are currently not supported by deep learning. To validate such theoretical result, a non-deep-learning model should be adopted. The ERM for active learning has been investigated in the literature, such as \"Querying discriminative and representative samples for batch mode active learning\" in KDD 2013, which also provided an upper bound loss of the batch mode active learning and seems applicable for the problem in this paper. Another interesting question is most of the competing algorithm is myoptic active learning algorithms. The comparison is not fair enough. The authors should provide more competing algorithms in batch mode active learning.", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their time and effort spent providing feedback . We appreciate the encouraging comments . We address the concerns as follows : - ERM and Core-Set for Deep Learning : Recent results ( Example 7 of Robustness and Generalization by Xu & Manor 2010 ) provides a generalization bound for neural networks . Hence , CNNs support ERM . Moreover , our upper bound on core-set is also provided directly for CNNs . In summary , we believe our theoretical analysis is valid for CNNs . We update the paper accordingly and discuss the ERM for deep learning in Section 4.1 . - Wang et al. , KDD 2013 : We thank the reviewer for pointing out this very related paper we missed in the original submission . We updated our related work section accordingly . Moreover , we also compare with this paper as well as another clustering-based batch-mode active learning baseline in the updated version . Our experiments suggest that these baselines turns out to be not effective for CNNs . We believe this is largely due to the fact that ( Wang et al. , KDD 2013 ) heavily uses uncertainty information and treating soft-max probabilities as uncertainty is misleading in general ."}, {"review_id": "H1aIuk-RW-2", "review_text": "This paper studies active learning for convolutional neural networks. Authors formulate the active learning problem as core-set selection and present a novel strategy. Experiments are performed on three datasets to validate the effectiveness of the proposed method comparing with some baselines. Theoretical analysis is presented to show the performance of any selected subset using the geometry of the data points. Authors are suggested to perform experiments on more datasets to make the results more convincing. The initialization of the CNN model is not clearly introduced, which however, may affect the performance significantly. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their time and effort spent providing feedback . We appreciate the encouraging comments . We revised the paper with the initialization details of the CNNs . Moreover , we are also planning to release the source code of our method as well as all the experiments for full reproducibility ."}], "0": {"review_id": "H1aIuk-RW-0", "review_text": "After reading rebuttals from the authors: The authors have addressed all of my concerns. THe additional experiments are a good addition. ************************ The authors provide an algorithm-agnostic active learning algorithm for multi-class classification. The core technique is to construct a coreset of points whose labels inform the labels of other points. The coreset construction requires one to construct a set of points which can cover the entire dataset. While this is NP-hard problem in general, the greedy algorithm is 2-approximate. The authors use a variant of the greedy algorithm along with bisection search to solve a series of feasibility problems to obtain a good cover of the dataset each time. This cover tells us which points are to be queried. The reason why choosing the cover is a good idea is because under suitable Lipschitz continuity assumption the generalization error can be controlled via an appropriate value of the covering radius in the data space. The authors use the coreset construction with a CNN to demonstrate an active learning algorithm for multi-class classification. The experimental results are convincing enough to show that it outperforms other active learning algorithms. However, I have a few major and minor comments. Major comments: 1. The proof of Lemma 1 is incomplete. We need the Lipschitz constant of the loss function. The loss function is a function of the CNN function and the true label. The proof of lemma 1 only establishes the Lipschitz constant of the CNN function. Some more extra work is needed to derive the lipschitz constant of the loss function from the CNN function. 2. The statement of Prop 1 seems a bit confusing to me. the hypothsis says that the loss on the coreset = 0. But the equation in proposition 1 also includes the loss on the coreset. Why is this term included. Is this term not equal to 0? 3. Some important works are missing. Especially works related to pool based active learning, and landmark results on labell complexity of agnostic active learning. UPAL: Unbiased Pool based active learning by Ganti & Gray. http://proceedings.mlr.press/v22/ganti12/ganti12.pdf Efficient active learning of half-spaces by Gonen et al. http://www.jmlr.org/papers/volume14/gonen13a/gonen13a.pdf A bound on the label complexity of agnostic active learning. http://www.machinelearning.org/proceedings/icml2007/papers/375.pdf 4. The authors use L_2 loss as their objective function. This is a bit of a weird choice given that they are dealing with multi-class classification and the output layer is a sigmoid layer, making it a natural fit to work with something like a cross-entropy loss function. I guess the theoretical results do not extend to cross-entropy loss, but the authors do not mention these points anywhere in the paper. For example, the ladder network, which is one of the networks used by the authors is a network that uses cross-entropy for training. Minor-comment: 1. The feasibility program in (6) is an MILP. However, the way it is written it does not look like an MILP. It would have been great had the authors mentioned that u_j \\in {0,1}. 2. The authors write on page 4, \"Moreover, zero training error can be enforced by converting average loss into maximal loss\". It is not clear to me what the authors mean here. For example, can I replace the average error in proposition 1, by maximal loss? Why can I do that? Why would that result in zero training error? On the whole this is interesting work and the results are very nice. But, the proof for Lemma 1 seems incomplete to me, and some choices (such as choice of loss function) are unjustified. Also, important references in active learning literature are missing.", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their time and effort spent providing feedback . We appreciate the encouraging comments . We address the concerns as follows : Major Points : 1 ) Proof of Lemma 1 : The reviewer is right as the current proof of the Lemma 1 is incomplete . Proposition 1 only requires the loss function to be a Lipschitz continuous function of the x ( input data point ) for a fixed true label ( y ) and parameters ( w ) . Current proof of the Lemma 1 indeed proves this more restrictive but sufficient statement . Hence , we re-stated the Lemma 1 correctly in the updated submission . We also added the final step ( reverse triangle inequality ) to the proof of the Lemma 1 for sake of completeness . 2 ) The statement of Prop 1 : We stated the proposition in this form to be consistent with equation 3 . We clarified this in the updated text 3 ) We updated the related work with the suggested references . 4 ) L_2 loss : We agree that this is unconventional as cross-entropy is the widely accepted choice of loss function for classification problems . We use L_2 loss for theoretical simplicity and used cross-entropy in the experiments . The experimental results suggest that our method is effective for cross-entropy loss as well . We explicitly discussed and clarified this choice in the updated submission . Minor Points : 1 ) MILP : We added the missing constraint -u_j \\in { 0,1 } - in the updated submission 2 ) Maximal Loss : We agree that this is a confusing statement and we removed it in the updated submission . What we meant was although 0 training error on core-set is a hard assumption , it can be directly enforced by using the maximal loss while learning the model . However , we did not use any such trick . We hope that the updated version answer the reviewer 's concerns . Moreover , we also added more details and included two additional baselines in the updated submission ."}, "1": {"review_id": "H1aIuk-RW-1", "review_text": "Active learning for deep learning is an interesting topic and there is few useful tool available in the literature. It is happy to see such paper in the field. This paper proposes a batch mode active learning algorithm for CNN as a core-set problem. The authors provide an upper bound of the core-set loss, which is the gap between the training loss on the whole set and the core-set. By minimizing this upper bound, the problem becomes a K-center problem which can be solved by using a greedy approximation method, 2-OPT. The experiments are performed on image classification problem (CIFAR, CALTECH, SVHN datasets), under either supervised setting or weakly-supervised setting. Results show that the proposed method outperforms the random sampling and uncertainty sampling by a large margin. Moreover, the authors show that 2-OPT can save tractable amount of time in practice with a small accuracy drop. The proposed algorithm is new and writing is clear. However, the paper is not flawless. The proposed active learning framework is under ERM and cover-set, which are currently not supported by deep learning. To validate such theoretical result, a non-deep-learning model should be adopted. The ERM for active learning has been investigated in the literature, such as \"Querying discriminative and representative samples for batch mode active learning\" in KDD 2013, which also provided an upper bound loss of the batch mode active learning and seems applicable for the problem in this paper. Another interesting question is most of the competing algorithm is myoptic active learning algorithms. The comparison is not fair enough. The authors should provide more competing algorithms in batch mode active learning.", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their time and effort spent providing feedback . We appreciate the encouraging comments . We address the concerns as follows : - ERM and Core-Set for Deep Learning : Recent results ( Example 7 of Robustness and Generalization by Xu & Manor 2010 ) provides a generalization bound for neural networks . Hence , CNNs support ERM . Moreover , our upper bound on core-set is also provided directly for CNNs . In summary , we believe our theoretical analysis is valid for CNNs . We update the paper accordingly and discuss the ERM for deep learning in Section 4.1 . - Wang et al. , KDD 2013 : We thank the reviewer for pointing out this very related paper we missed in the original submission . We updated our related work section accordingly . Moreover , we also compare with this paper as well as another clustering-based batch-mode active learning baseline in the updated version . Our experiments suggest that these baselines turns out to be not effective for CNNs . We believe this is largely due to the fact that ( Wang et al. , KDD 2013 ) heavily uses uncertainty information and treating soft-max probabilities as uncertainty is misleading in general ."}, "2": {"review_id": "H1aIuk-RW-2", "review_text": "This paper studies active learning for convolutional neural networks. Authors formulate the active learning problem as core-set selection and present a novel strategy. Experiments are performed on three datasets to validate the effectiveness of the proposed method comparing with some baselines. Theoretical analysis is presented to show the performance of any selected subset using the geometry of the data points. Authors are suggested to perform experiments on more datasets to make the results more convincing. The initialization of the CNN model is not clearly introduced, which however, may affect the performance significantly. ", "rating": "7: Good paper, accept", "reply_text": "We thank the reviewer for their time and effort spent providing feedback . We appreciate the encouraging comments . We revised the paper with the initialization details of the CNNs . Moreover , we are also planning to release the source code of our method as well as all the experiments for full reproducibility ."}}