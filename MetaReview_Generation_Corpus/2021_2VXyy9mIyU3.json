{"year": "2021", "forum": "2VXyy9mIyU3", "title": "Learning with Instance-Dependent Label Noise: A Sample Sieve Approach", "decision": "Accept (Poster)", "meta_review": "Dear Authors,\n\nThank you very much for your very detailed feedback to the reviewers. They have highly contributed to clarifying some of the concerns raised by the reviewers and improved their understanding of this paper.\n\nOverall, all the reviewers acknowledge the merit of this paper and thus I suggest acceptance of this paper.\nHowever, as Reviewer #4 pointed out, there are conceptual and theoretical issues that need to be more carefully addressed.\nPlease clarify these issues in the final version of the paper.", "reviews": [{"review_id": "2VXyy9mIyU3-0", "review_text": "Summary The paper introduces a noise-robust loss function CORES2 , motivated by peer loss . The novel loss adds a regularization term that promotes confident prediction and pushes the model prediction away from the prior of the label . Using this loss function , the authors propose a dynamic sample sieve to separate the clean data and corrupted data on-the-fly , by the magnitude of CORES2 loss . The author 's approach is to rule out samples whose losses are larger than an adaptive threshold . Importantly , the process of sieving successfully sieves out corrupted samples , both in a theory of 'better than random guess classifier ' and in practice . The authors , then show that the proposed CORES2 can be decoupled under the instance-dependent noise setting . Then CORES2 is proved to be noise-robust , which means CORES2 is equivalent to minimizing the original cross-entropy loss . They also show a principle approach for finding the hyperparameters $ \\beta $ . Further , a consistency loss is adopted after sample sieve on the corrupted samples . The author conducts extensive experiments , including CIFAR10 , CIFAR100 , and Clothing1M under different settings of noise . CORES2 achieves the SOTA results in all the experiments . Contributions i ) Proposal of a novel confidence regularized loss for image classification and a novel algorithm that dynamically sieves out corrupted samples basing on their loss . ii ) The proposed loss is proved to be noise-robust . This theoretical result is valuable since less the instance-based noise is not well studied . A principle way to choose the hyperparameter $ \\beta $ . iii ) Application to CIFAR10 , CIFAR100 , and Clothing1M ( real-world dataset ) , with the extensive comparison . Issues : i ) The motivation behind the dynamic sample sieve is unclear to me . One hypothesis is that if we set CORES2 as the objective , the model will fit clean samples much faster than corrupted samples at the beginning of training . Hence the model can sieve the corrupted samples out . However , Fig2 shows that the cross-entropy can also separate clean/corrupted samples at the early training stage . I am curiously about the performance of cross-entropy loss + dynamic sample sieve . The comparison between CORES2 and cross-entropy in Fig2 is unfair . Theoretically , the paper only shows that once the model is better than random guess , the dynamic sample sieve will not sieve clean samples out . And the assumption is $ f_ { x_n } ( y_n ) > 1/K $ . But $ f_ { x_n } ( \\tilde { y } _n ) > 1/K $ would also frequently happen , for $ y_n\\not=\\tilde { y } _n $ , which means the dynamic sample sieve will also keep these corrupted samples . Overall , I think the high-level insight into the sieving process is unclear in the paper . ii ) The training stability of the confidence regularizer : The authors show that confidence regularizer can promote confidence prediction . So some entries in $ f ( x ) $ is near 0 , and will make the optimization process unstable since the confidence regularizer - > inf in this case . There is another concern related to theorem 4 . Since the Bayes optimal classifier is $ f^ * _x [ y ] =1 $ , its CORES2 loss would be -inf , which seems problematic . iii ) Selection for $ \\beta $ , according to theorem 4 : theorem 4 provides a principal way for estimation of \\beta in different datasets . However , to estimate $ \\beta $ , we have to estimate the noise transition matrix beforehand . And there may exist some adversary samples that make the rough estimation impossible . In another perspective , we can also give some meaningful upper/lower bound for $ \\beta $ in the instance-independent noise setting . So it 's unclear to me what makes the difference in the instance-dependent setting if we do not go through all the samples but do a rough estimation . iv ) One motivation of Confidence Regularizer is that confident prediction counters the overfitting of noise labels . But if the model capacity is sufficiently large , I think it can both overfit CORES2 , and overfit those noise samples . Minors : a ) The assumption shows that CORES2 does not favor the non-diagonal dominant noise rate , which means the diagonal entries in the noise transition matrix T can be smaller than some entries in the same row . Does CORES2 fail in this setting in practice ? Overall , the paper 's approach is novel and easy to implement . I am willing to raise my score if the authors can address my issues . # # # # EDIT I think the authors replied to some of my concerns in a convincing way , hence I raise the score to 6 . Unfortunately , I think the theoretical analysis for the noise-robust loss is orthogonal to their sampling sieving approach . And the analysis for choosing $ \\beta $ does not dependent on their instance-dependent noise settings . We can get the same $ \\beta $ by very rough estimation ( their approach ) in instance-independent noise settings . In addition , I guess $ f_x^ * [ y ] =1 $ is still problematic in the theoretical analysis since CORES2=\\inf given the ideal classifier . Overall , following author 's response , I am leaning towards acceptance , but will let the AC judge the importance of the points above for the final decision .", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * A1 : compare cross-entropy loss + dynamic sample sieve : * * Thanks for your comment . The proposal `` cross-entropy loss + dynamic sample sieve '' is indeed an effective method under instance-independent label noise such as symmetric noise and asymmetric noise . There are pretty effective works adopting similar sample selection ideas ( but our thresholds $ \\alpha_n $ for sieving are novel ) : MentorNet ( Jiang et al. , 2017 ) , Co-teaching ( Han et al. , 2018 ) , Co-teaching+ ( Yu et al. , 2019 ) , etc . In this paper , we did compare our method with these approaches . For example , in Figure 3 , both Co-teaching and CORES $ ^2 $ work well in the symmetric noise setting , but performance degradation occurs in Co-teaching with $ 40\\ % $ and $ 60\\ % $ instance-dependent label noise . We agree with the reviewer that the comparison between CORES $ ^2 $ and CE in Figure 2 is unfair . The main purpose of presenting Figure 2 is visualizing the `` division '' property of our sample sieve . As we can see , with symmetric ( instance-independent ) label noise , CE also provides good division thus the `` CE + sample selection '' approaches work well as shown in Figure 3 , Table 1 , and Table 5 , 6 ( in Appendix ) . Although the current comparison might look `` unfair '' , no example is sieved out at epoch-20 since the sample sieve starts at epoch-30 in our experiments as mentioned in Appendix D.2 . Thus the comparison at epoch-20 is `` fair '' . We present the result of `` CE + dynamic sample sieve '' in Figure 2 of the revised version . From the revised Figure 2 ( b ) and Figure 2 ( f ) , `` CE+Sieve '' is hard to perfectly sieve out corrupted examples in either symmetric noise or instance-dependent noise . A lot of corrupted examples with symmetric noise are sieved out by CE Sieve in Figure 2 ( b ) while few corrupted examples with instance-dependent noise are sieved out in Figure 2 ( f ) , indicating the instance-dependent label noise is indeed more challenging . Note CE primarily helps learn a noisy distribution , while our regularized loss directs the training towards learning the underlying clean distribution , which is critical . We highlight this difference in Contribution-1 of the revised version . To be more accurate , the hypothesis in Issue-1 could be `` if we set CORES2 as the objective , the model will fit ( the underlying ) clean examples during training '' . More explanations are available in A5 . * * A2 : Motivation or high-level insights to the sieving process * * The reviewer is absolutely correct that the dynamic sample sieve may include corrupted examples ( as illustrated in Figure 1 ) . We think there are generally two different philosophies toward sample selection : picking up clean examples or ruling out corrupted examples . Both methods have their own advantages . If we have one approach that is guaranteed to only select clean examples and does not address the quality of the `` sieved out '' examples , it will keep a smaller number of clean examples than that in the original noisy dataset and some clean examples may be sieved out . This approach may work well since the remaining examples are all clean , while we may lose the information captured by those sieved-out clean examples . It is hard to quantify the importance of the dropped information while this approach may not be robust enough in the challenging instance-dependent setting . On the other hand , our theory guarantees only corrupted examples are sieved out , indicating all the clean information is preserved . When some corrupted examples are safely dropped , the overall noise rate of the new dataset is guaranteed to decrease . Then with a dynamic sample sieve , the overall noise rate will be non-increasing and the performance will expect to progressively increase . This is the high-level design intuition of the sample sieve . Note it is hard to theoretically guarantee that the performance is always non-decreasing in the former case where we keep only a part of clean examples at the cost of dropping the other clean examples ( some clean features may be completely dropped ) . In order to make the case `` ruling out corrupted examples '' optimal , we need to refer to the robustness of the regularized CE loss ( Theorem 4 ) . Theoretically , when Theorem 4 holds , the sample sieve can achieve the optimal performance ( all the corrupted examples are sieved out ) as claimed in Corollary 1 . We highlight the difference in designing philosophies at the bottom of page 4 ."}, {"review_id": "2VXyy9mIyU3-1", "review_text": "The authors of the paper propose a new method , the CORES ( COnfidence REgularized Sample Sieve ) , to tackle the important problem of learning under instance dependent label noise . The proposed method , in essence , involves the use of a confidence regularization term that encourages more confident predictions and a sieving process to remove the samples with large losses . Theoretical justification and empirical experiments were conducted to demonstrate the effectiveness of the proposed method . All in all , the paper is clearly written and easy to follow . The proposed method seems technically sound and the motivation for the proposal is explained clearly . One major complaint I have for the paper is the lack of novelty of the paper . The two important building blocks of the paper , the confidence regularizer , and the sample sieve are derived from previous papers . Specifically , in my opinion , the confidence regularizer is a marginal extension of the `` peer loss '' [ 1 ] , and the sample sieve algorithm is essentially the same as that proposed in [ 2 ] , the only difference being a different choice of loss function for training and sieving , to the best of my knowledge and understanding . I think it is worth commenting on this very relevant line of work in Section 2.2 . In addition , it would be interesting if the authors of the paper could offer some insights on why the proposed sieving strategy works better than the one previously proposed [ 2 ] based on softmax probability . All in all , with the lack of novelty addressed above , I think the submission is marginally below the acceptance threshold . Other comments : 1 . I find the intuitive justification for confidence regularization in Section 2.1 to be quite unconvincing . Specifically , it was stated that `` when model overfits to the noise , its predictions often become less confident '' . From my understanding , this is not necessarily true at all . In fact , it was previously demonstrated that deep NNs can even perfectly overfit to datasets with randomly assigned labels ? From this perspective , would n't encouraging confidence make the model overfit harder to the noisy labels ? I would appreciate if the authors of the paper could provide further insights and intuition on why the introduced confidence regularization improves noise robustness . [ 1 ] Yang Liu and Hongyi Guo . Peer loss functions : Learning from noisy labels without knowing noise rates . In Proceedings of the 37th International Conference on Machine Learning , ICML \u2019 20 , 2020 . [ 2 ] Zhilu Zhang and Mert Sabuncu . Generalized cross entropy loss for training deep neural networks with noisy labels . In Advances in neural information processing systems , pp . 8778\u20138788 , 2018 . -- The authors of the paper addressed carefully the concerns I raised above . As such , I am raising my score to a 6 , and would like to recommend accepting this paper .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your comments and suggestions . We would like to argue that our proposed method is indeed novel to the literature since we discover the novel confidence regularization property of CR by reforming peer loss , technically break through the bottlenecks of multi-class extensions and the instance-independent assumption in peer loss , and propose a novel sample sieve relying on a different philosophy ( sieving out corrupted examples ) from existing works . We summarize our novelty in * * A1 * * , compare with peer loss and GCE in * * A2 * * and * * A3 * * , give intuitive explanations on why our sieve is better than GCE in * * A4 * * , and discuss the overfitting of DNNs in * * A5 * * . * * A1 : Novelty ( in a nutshell ) * * We are happy to see that our technical contributions are appreciated . Although both the forms of loss and the sample sieve method may look `` similar '' to the existing literature , we do make critical modifications to both components . Comparing with peer loss , we would like to highlight our observed novel property of encouraging confident predictions by adding the proposed confidence regularizer ( CR ) , and the advantage of CR in handling instance-dependent label noise . Note peer loss only guarantees the performance in binary classifications and particular multi-class extension when $ T_ { ij } = T_ { kj } , \\forall j\\ne k\\ne i $ . However , in the challenging instance-dependent label noise , $ T_ { ij } ( x ) $ for each example $ x $ could be different thus this assumption adopted in peer loss does not hold . The technical breakthrough of these bottlenecks of peer loss with our CR is novel and important . Comparing with GCE , we would like to highlight our design of a sample sieve following a totally different philosophy ( sieving out corrupted examples ) , which enables the closed-form thresholds $ \\alpha_ { n , k } $ along with the application of our confidence regularized loss . Moreover , we theoretically guarantee each adaptation and their combinations . Note the quality of a sample sieving procedure is unclear without the implementation of CR . Detailed technical contributions compared with peer loss and GCE are available in the following two responses . Summarizing above , we would argue that our efforts in reforming peer loss and developing a theoretically sound sieving process are non-trivial contributions . As also acknowledged by Reviewer-2 , we believe such a simple but theoretically-guaranteed approach would contribute to the literature and can potentially inspire a line of future works ."}, {"review_id": "2VXyy9mIyU3-2", "review_text": "* * * quality * * * This paper is quite well-written . The contribution is critical in instance-dependent label noise learning . Moreover , both the theoretical and empirical justifications are convincing . * * * clarity * * * Although this paper contains heavy mathematics , it is not difficult to understand . I can see that the authors have spent a lot of efforts in paper writing . * * * originality * * * In this paper , the authors proposed a novel sample sieve approach for instance-dependent label noise learning . The proposed model is novel , and the theoretical contributions are also new to the community . * * * significance * * * The proposed algorithm is simple , but the theory behind is rich . I like this kind of work , so I feel that the significance of this paper is high for future research . * * * pros and cons * * * Pros : 1 . The topic is very important for realistic machine learning problems , and is helpful for reducing the human annotation efforts . 2.The theoretical study of this paper is quite impressive . 3.The experimental results show that the proposed method achieves SOTA performance . Cons : 1.The authors claim that their method does not need to estimate the label transition probability or noise rate , which I think is nice ! However , it would be better if the authors can explain why the proposed method can avoid this , namely which \u201c component \u201d helps to avoid the estimation for noise rate ? 2.Since this work is an extension of cross-entropy loss to dealing with label noise , I think the comparison with \u201c Symmetric Cross Entropy for Robust Learning with Noisy Labels \u201d ( ICCV 2019 ) is necessary , as this paper also aims to design a robust loss via modifying cross-entropy loss . 3.I feel that the sample sieve/filtering process ( i.e.Eqs.1-4 ) looks like self-paced learning ( SPL ) ( see \u201c Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data \u201d , AAAI 20 ) , as SPL also selects some \u201c important \u201d data for training in each iteration . Maybe the authors can discuss the relationship between these two methods ? 4.The authors misuse the terms \u201c sample \u201d and \u201c example \u201d . Statistically , we say that we have a sample X= { x_1 , x_2 , \u2026 , x_n } from some distribution , in which every x_i is an example . 5.Some recent typical works on label noise learning can be cited , such as \u201c Are Anchor Points Really Indispensable in Label-Noise Learning ? \u201d ( NeurIPS 19 ) and \u201c A Bi-level Formulation for Label Noise Learning with Spectral Cluster Discovery \u201d ( IJCAI 20 ) .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks for your recognition of our paper . Your concerns are addressed as follows . * * A1 : More explanations : * * In Theorem 3 , we provide a generic machinery for anatomizing noisy datasets . From Eq . ( 5 ) in this theorem , for instance , we can see the effects caused by $ U_ { ij } ( X ) $ ( capturing the information in the noise transition matrix $ T ( X ) $ ) may be `` canceled out '' or `` reversed '' by $ \\beta \\mathbb P ( \\widetilde Y=j ) $ with a properly tuned $ \\beta $ . Intuitively , with an appropriate $ \\beta $ , all the effects of $ U_ { ij } ( X ) , i\\ne j $ can be reversed and we will get a negative loss punishing the classifier to predict class- $ j $ when the clean label is $ i $ . We discussed similar intuitions before presenting Theorem 4 in the initial submission and polished it in the revised version . * * A2 : Related works : * * Thanks for suggesting more related works . We have just experimented with SCE [ R1 ] on CIFAR10 and CIFAR100 using instance-dependent noise , and obtained the following results : SCE CIFAR10~ Inst . 0.2 : 89.11 , Inst . 0.4 : 72.04 , Inst . 0.6 : 44.83 . SCE CIFAR100 Inst . 0.2 : 59.87 , Inst . 0.4 : 41.76 , Inst . 0.6 : 23.41 . We have added these results in Table 1 of the revised version . Most of the SPL-based methods , e.g . [ R2 ] , GCE ( Zhang \\ & Sabuncu , 2018 ) , Co-teaching ( Han et al. , 2018 ) , Co-teaching+ ( Yu et al. , 2019 ) , and JoCoR ( Wei et al. , 2020 ) , rely on critical thresholds for determining whether the example is clean or corrupted , and the thresholds are often set/tuned empirically or manually . Our closed-form thresholds $ \\alpha_ { n , t } $ can be directly calculated based on the model prediction and do not require extra estimation . It is interesting to consider further improving the dynamic sample sieve with the help of a small set of well-labeled examples with little data corruption as done in [ R2 ] . We have cited all these related works [ R1-R4 ] and addressed them properly in the revised version . Thanks for suggesting the proper use of `` sample '' and `` example '' -- we have fixed them in the revision . [ R1 ] Wang , Yisen , et al . `` Symmetric cross entropy for robust learning with noisy labels . '' CVPR 2019 . [ R2 ] Zhang , Xuchao , et al . `` Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data . '' AAAI 2020 . [ R3 ] Xia , Xiaobo , et al . `` Are Anchor Points Really Indispensable in Label-Noise Learning ? . '' Advances in Neural Information Processing Systems . 2019 . [ R4 ] Luo , Yijing , Bo Han , and Chen Gong . `` A Bi-level Formulation for Label Noise Learning with Spectral Cluster Discovery . ''"}], "0": {"review_id": "2VXyy9mIyU3-0", "review_text": "Summary The paper introduces a noise-robust loss function CORES2 , motivated by peer loss . The novel loss adds a regularization term that promotes confident prediction and pushes the model prediction away from the prior of the label . Using this loss function , the authors propose a dynamic sample sieve to separate the clean data and corrupted data on-the-fly , by the magnitude of CORES2 loss . The author 's approach is to rule out samples whose losses are larger than an adaptive threshold . Importantly , the process of sieving successfully sieves out corrupted samples , both in a theory of 'better than random guess classifier ' and in practice . The authors , then show that the proposed CORES2 can be decoupled under the instance-dependent noise setting . Then CORES2 is proved to be noise-robust , which means CORES2 is equivalent to minimizing the original cross-entropy loss . They also show a principle approach for finding the hyperparameters $ \\beta $ . Further , a consistency loss is adopted after sample sieve on the corrupted samples . The author conducts extensive experiments , including CIFAR10 , CIFAR100 , and Clothing1M under different settings of noise . CORES2 achieves the SOTA results in all the experiments . Contributions i ) Proposal of a novel confidence regularized loss for image classification and a novel algorithm that dynamically sieves out corrupted samples basing on their loss . ii ) The proposed loss is proved to be noise-robust . This theoretical result is valuable since less the instance-based noise is not well studied . A principle way to choose the hyperparameter $ \\beta $ . iii ) Application to CIFAR10 , CIFAR100 , and Clothing1M ( real-world dataset ) , with the extensive comparison . Issues : i ) The motivation behind the dynamic sample sieve is unclear to me . One hypothesis is that if we set CORES2 as the objective , the model will fit clean samples much faster than corrupted samples at the beginning of training . Hence the model can sieve the corrupted samples out . However , Fig2 shows that the cross-entropy can also separate clean/corrupted samples at the early training stage . I am curiously about the performance of cross-entropy loss + dynamic sample sieve . The comparison between CORES2 and cross-entropy in Fig2 is unfair . Theoretically , the paper only shows that once the model is better than random guess , the dynamic sample sieve will not sieve clean samples out . And the assumption is $ f_ { x_n } ( y_n ) > 1/K $ . But $ f_ { x_n } ( \\tilde { y } _n ) > 1/K $ would also frequently happen , for $ y_n\\not=\\tilde { y } _n $ , which means the dynamic sample sieve will also keep these corrupted samples . Overall , I think the high-level insight into the sieving process is unclear in the paper . ii ) The training stability of the confidence regularizer : The authors show that confidence regularizer can promote confidence prediction . So some entries in $ f ( x ) $ is near 0 , and will make the optimization process unstable since the confidence regularizer - > inf in this case . There is another concern related to theorem 4 . Since the Bayes optimal classifier is $ f^ * _x [ y ] =1 $ , its CORES2 loss would be -inf , which seems problematic . iii ) Selection for $ \\beta $ , according to theorem 4 : theorem 4 provides a principal way for estimation of \\beta in different datasets . However , to estimate $ \\beta $ , we have to estimate the noise transition matrix beforehand . And there may exist some adversary samples that make the rough estimation impossible . In another perspective , we can also give some meaningful upper/lower bound for $ \\beta $ in the instance-independent noise setting . So it 's unclear to me what makes the difference in the instance-dependent setting if we do not go through all the samples but do a rough estimation . iv ) One motivation of Confidence Regularizer is that confident prediction counters the overfitting of noise labels . But if the model capacity is sufficiently large , I think it can both overfit CORES2 , and overfit those noise samples . Minors : a ) The assumption shows that CORES2 does not favor the non-diagonal dominant noise rate , which means the diagonal entries in the noise transition matrix T can be smaller than some entries in the same row . Does CORES2 fail in this setting in practice ? Overall , the paper 's approach is novel and easy to implement . I am willing to raise my score if the authors can address my issues . # # # # EDIT I think the authors replied to some of my concerns in a convincing way , hence I raise the score to 6 . Unfortunately , I think the theoretical analysis for the noise-robust loss is orthogonal to their sampling sieving approach . And the analysis for choosing $ \\beta $ does not dependent on their instance-dependent noise settings . We can get the same $ \\beta $ by very rough estimation ( their approach ) in instance-independent noise settings . In addition , I guess $ f_x^ * [ y ] =1 $ is still problematic in the theoretical analysis since CORES2=\\inf given the ideal classifier . Overall , following author 's response , I am leaning towards acceptance , but will let the AC judge the importance of the points above for the final decision .", "rating": "6: Marginally above acceptance threshold", "reply_text": "* * A1 : compare cross-entropy loss + dynamic sample sieve : * * Thanks for your comment . The proposal `` cross-entropy loss + dynamic sample sieve '' is indeed an effective method under instance-independent label noise such as symmetric noise and asymmetric noise . There are pretty effective works adopting similar sample selection ideas ( but our thresholds $ \\alpha_n $ for sieving are novel ) : MentorNet ( Jiang et al. , 2017 ) , Co-teaching ( Han et al. , 2018 ) , Co-teaching+ ( Yu et al. , 2019 ) , etc . In this paper , we did compare our method with these approaches . For example , in Figure 3 , both Co-teaching and CORES $ ^2 $ work well in the symmetric noise setting , but performance degradation occurs in Co-teaching with $ 40\\ % $ and $ 60\\ % $ instance-dependent label noise . We agree with the reviewer that the comparison between CORES $ ^2 $ and CE in Figure 2 is unfair . The main purpose of presenting Figure 2 is visualizing the `` division '' property of our sample sieve . As we can see , with symmetric ( instance-independent ) label noise , CE also provides good division thus the `` CE + sample selection '' approaches work well as shown in Figure 3 , Table 1 , and Table 5 , 6 ( in Appendix ) . Although the current comparison might look `` unfair '' , no example is sieved out at epoch-20 since the sample sieve starts at epoch-30 in our experiments as mentioned in Appendix D.2 . Thus the comparison at epoch-20 is `` fair '' . We present the result of `` CE + dynamic sample sieve '' in Figure 2 of the revised version . From the revised Figure 2 ( b ) and Figure 2 ( f ) , `` CE+Sieve '' is hard to perfectly sieve out corrupted examples in either symmetric noise or instance-dependent noise . A lot of corrupted examples with symmetric noise are sieved out by CE Sieve in Figure 2 ( b ) while few corrupted examples with instance-dependent noise are sieved out in Figure 2 ( f ) , indicating the instance-dependent label noise is indeed more challenging . Note CE primarily helps learn a noisy distribution , while our regularized loss directs the training towards learning the underlying clean distribution , which is critical . We highlight this difference in Contribution-1 of the revised version . To be more accurate , the hypothesis in Issue-1 could be `` if we set CORES2 as the objective , the model will fit ( the underlying ) clean examples during training '' . More explanations are available in A5 . * * A2 : Motivation or high-level insights to the sieving process * * The reviewer is absolutely correct that the dynamic sample sieve may include corrupted examples ( as illustrated in Figure 1 ) . We think there are generally two different philosophies toward sample selection : picking up clean examples or ruling out corrupted examples . Both methods have their own advantages . If we have one approach that is guaranteed to only select clean examples and does not address the quality of the `` sieved out '' examples , it will keep a smaller number of clean examples than that in the original noisy dataset and some clean examples may be sieved out . This approach may work well since the remaining examples are all clean , while we may lose the information captured by those sieved-out clean examples . It is hard to quantify the importance of the dropped information while this approach may not be robust enough in the challenging instance-dependent setting . On the other hand , our theory guarantees only corrupted examples are sieved out , indicating all the clean information is preserved . When some corrupted examples are safely dropped , the overall noise rate of the new dataset is guaranteed to decrease . Then with a dynamic sample sieve , the overall noise rate will be non-increasing and the performance will expect to progressively increase . This is the high-level design intuition of the sample sieve . Note it is hard to theoretically guarantee that the performance is always non-decreasing in the former case where we keep only a part of clean examples at the cost of dropping the other clean examples ( some clean features may be completely dropped ) . In order to make the case `` ruling out corrupted examples '' optimal , we need to refer to the robustness of the regularized CE loss ( Theorem 4 ) . Theoretically , when Theorem 4 holds , the sample sieve can achieve the optimal performance ( all the corrupted examples are sieved out ) as claimed in Corollary 1 . We highlight the difference in designing philosophies at the bottom of page 4 ."}, "1": {"review_id": "2VXyy9mIyU3-1", "review_text": "The authors of the paper propose a new method , the CORES ( COnfidence REgularized Sample Sieve ) , to tackle the important problem of learning under instance dependent label noise . The proposed method , in essence , involves the use of a confidence regularization term that encourages more confident predictions and a sieving process to remove the samples with large losses . Theoretical justification and empirical experiments were conducted to demonstrate the effectiveness of the proposed method . All in all , the paper is clearly written and easy to follow . The proposed method seems technically sound and the motivation for the proposal is explained clearly . One major complaint I have for the paper is the lack of novelty of the paper . The two important building blocks of the paper , the confidence regularizer , and the sample sieve are derived from previous papers . Specifically , in my opinion , the confidence regularizer is a marginal extension of the `` peer loss '' [ 1 ] , and the sample sieve algorithm is essentially the same as that proposed in [ 2 ] , the only difference being a different choice of loss function for training and sieving , to the best of my knowledge and understanding . I think it is worth commenting on this very relevant line of work in Section 2.2 . In addition , it would be interesting if the authors of the paper could offer some insights on why the proposed sieving strategy works better than the one previously proposed [ 2 ] based on softmax probability . All in all , with the lack of novelty addressed above , I think the submission is marginally below the acceptance threshold . Other comments : 1 . I find the intuitive justification for confidence regularization in Section 2.1 to be quite unconvincing . Specifically , it was stated that `` when model overfits to the noise , its predictions often become less confident '' . From my understanding , this is not necessarily true at all . In fact , it was previously demonstrated that deep NNs can even perfectly overfit to datasets with randomly assigned labels ? From this perspective , would n't encouraging confidence make the model overfit harder to the noisy labels ? I would appreciate if the authors of the paper could provide further insights and intuition on why the introduced confidence regularization improves noise robustness . [ 1 ] Yang Liu and Hongyi Guo . Peer loss functions : Learning from noisy labels without knowing noise rates . In Proceedings of the 37th International Conference on Machine Learning , ICML \u2019 20 , 2020 . [ 2 ] Zhilu Zhang and Mert Sabuncu . Generalized cross entropy loss for training deep neural networks with noisy labels . In Advances in neural information processing systems , pp . 8778\u20138788 , 2018 . -- The authors of the paper addressed carefully the concerns I raised above . As such , I am raising my score to a 6 , and would like to recommend accepting this paper .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your comments and suggestions . We would like to argue that our proposed method is indeed novel to the literature since we discover the novel confidence regularization property of CR by reforming peer loss , technically break through the bottlenecks of multi-class extensions and the instance-independent assumption in peer loss , and propose a novel sample sieve relying on a different philosophy ( sieving out corrupted examples ) from existing works . We summarize our novelty in * * A1 * * , compare with peer loss and GCE in * * A2 * * and * * A3 * * , give intuitive explanations on why our sieve is better than GCE in * * A4 * * , and discuss the overfitting of DNNs in * * A5 * * . * * A1 : Novelty ( in a nutshell ) * * We are happy to see that our technical contributions are appreciated . Although both the forms of loss and the sample sieve method may look `` similar '' to the existing literature , we do make critical modifications to both components . Comparing with peer loss , we would like to highlight our observed novel property of encouraging confident predictions by adding the proposed confidence regularizer ( CR ) , and the advantage of CR in handling instance-dependent label noise . Note peer loss only guarantees the performance in binary classifications and particular multi-class extension when $ T_ { ij } = T_ { kj } , \\forall j\\ne k\\ne i $ . However , in the challenging instance-dependent label noise , $ T_ { ij } ( x ) $ for each example $ x $ could be different thus this assumption adopted in peer loss does not hold . The technical breakthrough of these bottlenecks of peer loss with our CR is novel and important . Comparing with GCE , we would like to highlight our design of a sample sieve following a totally different philosophy ( sieving out corrupted examples ) , which enables the closed-form thresholds $ \\alpha_ { n , k } $ along with the application of our confidence regularized loss . Moreover , we theoretically guarantee each adaptation and their combinations . Note the quality of a sample sieving procedure is unclear without the implementation of CR . Detailed technical contributions compared with peer loss and GCE are available in the following two responses . Summarizing above , we would argue that our efforts in reforming peer loss and developing a theoretically sound sieving process are non-trivial contributions . As also acknowledged by Reviewer-2 , we believe such a simple but theoretically-guaranteed approach would contribute to the literature and can potentially inspire a line of future works ."}, "2": {"review_id": "2VXyy9mIyU3-2", "review_text": "* * * quality * * * This paper is quite well-written . The contribution is critical in instance-dependent label noise learning . Moreover , both the theoretical and empirical justifications are convincing . * * * clarity * * * Although this paper contains heavy mathematics , it is not difficult to understand . I can see that the authors have spent a lot of efforts in paper writing . * * * originality * * * In this paper , the authors proposed a novel sample sieve approach for instance-dependent label noise learning . The proposed model is novel , and the theoretical contributions are also new to the community . * * * significance * * * The proposed algorithm is simple , but the theory behind is rich . I like this kind of work , so I feel that the significance of this paper is high for future research . * * * pros and cons * * * Pros : 1 . The topic is very important for realistic machine learning problems , and is helpful for reducing the human annotation efforts . 2.The theoretical study of this paper is quite impressive . 3.The experimental results show that the proposed method achieves SOTA performance . Cons : 1.The authors claim that their method does not need to estimate the label transition probability or noise rate , which I think is nice ! However , it would be better if the authors can explain why the proposed method can avoid this , namely which \u201c component \u201d helps to avoid the estimation for noise rate ? 2.Since this work is an extension of cross-entropy loss to dealing with label noise , I think the comparison with \u201c Symmetric Cross Entropy for Robust Learning with Noisy Labels \u201d ( ICCV 2019 ) is necessary , as this paper also aims to design a robust loss via modifying cross-entropy loss . 3.I feel that the sample sieve/filtering process ( i.e.Eqs.1-4 ) looks like self-paced learning ( SPL ) ( see \u201c Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data \u201d , AAAI 20 ) , as SPL also selects some \u201c important \u201d data for training in each iteration . Maybe the authors can discuss the relationship between these two methods ? 4.The authors misuse the terms \u201c sample \u201d and \u201c example \u201d . Statistically , we say that we have a sample X= { x_1 , x_2 , \u2026 , x_n } from some distribution , in which every x_i is an example . 5.Some recent typical works on label noise learning can be cited , such as \u201c Are Anchor Points Really Indispensable in Label-Noise Learning ? \u201d ( NeurIPS 19 ) and \u201c A Bi-level Formulation for Label Noise Learning with Spectral Cluster Discovery \u201d ( IJCAI 20 ) .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks for your recognition of our paper . Your concerns are addressed as follows . * * A1 : More explanations : * * In Theorem 3 , we provide a generic machinery for anatomizing noisy datasets . From Eq . ( 5 ) in this theorem , for instance , we can see the effects caused by $ U_ { ij } ( X ) $ ( capturing the information in the noise transition matrix $ T ( X ) $ ) may be `` canceled out '' or `` reversed '' by $ \\beta \\mathbb P ( \\widetilde Y=j ) $ with a properly tuned $ \\beta $ . Intuitively , with an appropriate $ \\beta $ , all the effects of $ U_ { ij } ( X ) , i\\ne j $ can be reversed and we will get a negative loss punishing the classifier to predict class- $ j $ when the clean label is $ i $ . We discussed similar intuitions before presenting Theorem 4 in the initial submission and polished it in the revised version . * * A2 : Related works : * * Thanks for suggesting more related works . We have just experimented with SCE [ R1 ] on CIFAR10 and CIFAR100 using instance-dependent noise , and obtained the following results : SCE CIFAR10~ Inst . 0.2 : 89.11 , Inst . 0.4 : 72.04 , Inst . 0.6 : 44.83 . SCE CIFAR100 Inst . 0.2 : 59.87 , Inst . 0.4 : 41.76 , Inst . 0.6 : 23.41 . We have added these results in Table 1 of the revised version . Most of the SPL-based methods , e.g . [ R2 ] , GCE ( Zhang \\ & Sabuncu , 2018 ) , Co-teaching ( Han et al. , 2018 ) , Co-teaching+ ( Yu et al. , 2019 ) , and JoCoR ( Wei et al. , 2020 ) , rely on critical thresholds for determining whether the example is clean or corrupted , and the thresholds are often set/tuned empirically or manually . Our closed-form thresholds $ \\alpha_ { n , t } $ can be directly calculated based on the model prediction and do not require extra estimation . It is interesting to consider further improving the dynamic sample sieve with the help of a small set of well-labeled examples with little data corruption as done in [ R2 ] . We have cited all these related works [ R1-R4 ] and addressed them properly in the revised version . Thanks for suggesting the proper use of `` sample '' and `` example '' -- we have fixed them in the revision . [ R1 ] Wang , Yisen , et al . `` Symmetric cross entropy for robust learning with noisy labels . '' CVPR 2019 . [ R2 ] Zhang , Xuchao , et al . `` Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data . '' AAAI 2020 . [ R3 ] Xia , Xiaobo , et al . `` Are Anchor Points Really Indispensable in Label-Noise Learning ? . '' Advances in Neural Information Processing Systems . 2019 . [ R4 ] Luo , Yijing , Bo Han , and Chen Gong . `` A Bi-level Formulation for Label Noise Learning with Spectral Cluster Discovery . ''"}}