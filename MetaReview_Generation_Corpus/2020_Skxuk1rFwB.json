{"year": "2020", "forum": "Skxuk1rFwB", "title": "Towards Stable and Efficient Training of Verifiably Robust Neural Networks", "decision": "Accept (Poster)", "meta_review": "This paper presents a method that hybridizes the strategies of linear programming and interval bound propagation to improve adversarial robustness.  While some reviewers have concerns about the novelty of the underlying ideas presented, the method is an improvement to the SOTA in certifiable robustness, and has become a benchmark method within this class of defenses.", "reviews": [{"review_id": "Skxuk1rFwB-0", "review_text": "This paper proposes a new method for training certifiably robust models that achieves better results than the previous SOTA results by IBP, with a moderate increase in training time. It uses a CROWN-based bound in the warm up phase of IBP, which serves as a better initialization for the later phase of IBP and lead to improvements in both robust and standard accuracy. The CROWN-based bound uses IBP to compute bounds for intermediate pre-activations and applies CROWN only to computing the bounds of the margins, which has a complexity between IBP and CROWN. The experimental results are verify detailed to demonstrate the improvement. The improvement is significant enough to me and I tend to accept the paper. The results on CIFAR10 with epsilon=8/255 is so far the state-of-the-art. However, it is far from being scalable enough to large networks and datasets, which has already been achieved by randomized smoothing based approaches. On CIFAR10, it takes 32 TPU cores to train a 4-conv-layer network. Still, such an approach has the advantage of making robust inferences much more efficiently than randomized smoothing, and thus still worth further explorations.", "rating": "6: Weak Accept", "reply_text": "Dear AnonReviewer2 , We thank you for recognizing the contributions of our paper and raising the discussions on randomized smoothing and concerns on expensive computations on TPUs . ( Answer 1 ) Compared to the randomized smoothing based method , our bound propagation-based approach has several theoretical and practical benefits : 1 . Recent works [ 1 ] [ 2 ] show that randomized smoothing may not scale well for the important case of L infinity robustness . They provided some preliminary theoretical evidence that even the * optimal * robustness certificate for L infinity smoothing has a dependency on dimension d , thus for high dimensional input ( e.g. , CIFAR with d=3072 ) , randomized smoothing based method can not give a good quality bound . On the other hand , for L2 norm , the randomized smoothing certificate is dimension-free . This is a fundamental limitation of randomized smoothing . For the L infinity setting like CIFAR epsilon=8/255 , bound propagation-based method like CROWN-IBP still gives the best results . 2.As also mentioned by the reviewer , randomized smoothing typically needs a large number of samples , e.g. , in Cohen et al. , 100,000 random samples for a * single * image . In contrast , our verification can be computed using IBP very fast , which is only 2x forward propagation time . Randomized smoothing costs 50,000x more during inference , and our training procedure is 500x ( pessimistically ) slower during training time . So it is really a trade-off here ; each method has its own strength . Being scalable to large networks on all important norms with less training/inference cost is still an open challenge . It is not solved by randomized smoothing , nor CROWN-IBP . For the next step , our future work will investigate how to combine the strengths from bound propagation-based certified defense ( good for L infinity norm , sample free ) and randomized smoothing based approach ( good for L2 norm , need a lot of samples ) . Thus , our contribution as the SOTA bound propagation-based certified defense is important , as it can become an ingredient of the next generation certified defense . ( Answer 2 ) Regarding computation cost , the use of 32 TPUs is not necessary . We use TPUs mainly for obtaining a completely fair comparison to IBP ( Gowal et al , 2018 ) , as their implementation was TPU-based . We additionally implemented CROWN-IBP using multi-GPUs . Training the same largest CIFAR network takes 1 day on 4x 1080 Ti GPUs ( using the same hyperparameters ) , and we can achieve similar accuracy . We think this computational cost is quite reasonable , compared to other SOTA uncertified defense like adversarial training , which is also quite slow ( 10-20x extra cost for each epoch , and needs much more epochs to converge than natural training ) . We updated new multi-GPU training results in Table H , and we will open source our multi-GPU training code to make our algorithm available to a broader audience . We hope our response addresses your concerns on TPU training and randomized smoothing , and please kindly let us know if you have any further questions . References : [ 1 ] A Unified Framework for Randomized Smoothing based Certified Defense . https : //openreview.net/pdf ? id=ryl71a4YPB [ 2 ] Filling the Soap of Bubbles : Efficient Black-Box Adversarial Certification with Non-gaussian smoothing . https : //openreview.net/pdf ? id=Skg8gJBFvr"}, {"review_id": "Skxuk1rFwB-1", "review_text": "This paper proposes a new variation on certified adversarial training method that builds on two prior works IBP and CROWN. They showed the method outperformed all previous linear relaxation and bound propagation based certified defenses. Pros: 1. The empirical results are strong. The method achieved SOTA. Cons: 1. Novelty seems small. It is a straightforward combination of prior works, by adding two bounds together. 2. Adds a new hyperparameter for tuning. 3. Lack of any theoretical insights/motivation for the proposed method. Why would we want to combine the two lower bounds? The reason given in the paper is not very convincing: \"IBP has better learning power at larger epsilon and can achieve much smaller verified error. However, it can be hard to tune due to its very imprecise bound at the beginning of training; on the other hand, linear relaxation based methods give tighter lower bounds which stabilize training, but it over-regularizes the network and forbids us to achieve good accuracy.\" My questions with regards to this: (i) Why does loose bound result in unstable training? Tighter bound stabilize training? (ii) If we're concerned with using a tighter bound could result in over-regularization, then why not just combine the natural loss with the tight bound, as natural loss can be seen as the loosest bound. Is IBP crucial? and why? ", "rating": "3: Weak Reject", "reply_text": "Dear AnonReviewer3 , Thank you for providing your helpful feedback . Sorry for the potential confusion in our paper and we would like to clarify them in our response , and we have added relevant discussions to our revision . ( Q1 ) Why does loose bounds result in unstable training ? Tighter bounds stabilize training ? Loose bounds ( lower bounds on margins $ \\underline { m } $ , as defined on page 4 \u201c verification specifications \u201d ) give a loose upper bound of the minimax loss ( Eq.4 ) ; in other words , the \u201c robust loss \u201d term in ( 9 ) will become very large . A large robust loss can be a challenge for the optimizer to minimize , and training can easily diverge or stuck at random guess level . More specifically , we will explain why a tighter bound like CROWN-IBP can help to stabilize IBP training . When taking a randomly initialized network or a naturally trained network , IBP bounds are very loose . But in Table 1 , we show that a network trained using IBP can eventually obtain quite tight IBP bounds and high verified accuracy ( i.e. , the network can adapt to IBP bounds and learn a specific set of weights to make IBP tight and also correctly classify examples ) . However , since the training has to start from weights that produce loose bounds for IBP , the beginning phase of IBP training can be challenging and is vitally important . We observe that IBP training can have a large performance variance across models and initializations . Also , IBP is more sensitive to hyper-parameters like kappa or schedule length ; as you can see in Figure 3 , many IBP models failed to converge ( large worst/median verified error ) with some kappa or schedule length settings . The reason for instability is that during the beginning phase of training , the loose bounds produced by IBP make the robust loss ( Eq.9 ) explode , and it is challenging for the optimizer to reduce this loss and find a set of good weights that produce tight IBP verified bounds in the end . Conversely , if our bounds are much tighter at the beginning , the robust loss ( Eq.9 ) always remains in a reasonable range during training , and the network can gradually learn to find a good set of weights that make IBP bounds increasingly tighter . Initially , tighter bounds can be provided by a convex relaxation-based method , and the convex relaxation bounds are gradually replaced by IBP bound ( using beta_start=1 , beta_end=0 ) , eventually leading to a model with learned tight IBP bounds in the end . To give you some intuitions on how much tighter CROWN-IBP is than IBP , in appendix B , we added a figure comparing the tightness between IBP bound and CROWN-IBP bound . We take the difference between the two bounds ( CROWN-IBP bound minus IBP bound ) and plot this difference during the training procedure . At the beginning of training , the bound difference can be very large , and the network gradually learns how to make the IBP bounds tighter during the training process . The use of tighter bounds at the beginning prevents divergence and can guide the network to learn better IBP bounds and achieve better-verified accuracy . ( Q2 ) why not just combine the natural loss with the tight bound , as natural loss can be seen as the loosest bound ? Is IBP crucial ? and why ? The natural loss does not provide a bound . The loosest bound is negative infinity , and it will explode the robust loss in Eq. ( 9 ) . ( see page 4 , verification specifications , for the definition of this lower bound on margin , and Eq ( 4 ) for how to use it to get an upper bound for the minimax loss ) . IBP is crucial because it can provide us with a bound for computing the robust loss . Natural training can not provide such bounds . Additionally , a network trained using natural loss is not robust and difficult to verify with current techniques . Models trained using IBP bounds as $ \\underline { m } $ in Eq . ( 9 ) can be quickly verified using IBP . -- to be continued"}, {"review_id": "Skxuk1rFwB-2", "review_text": "This work proposes CROWN-IBP - novel and efficient certified defense method against adversarial attacks, by combining linear relaxation methods which tend to have tighter bounds with the more efficient interval-based methods. With an attempt to augment the IBP method with its lower computation complexity with the tight CROWN bounds, to get the best of both worlds. One of the primary contributions here is that reduction of computation complexity by an order of \\Ln while maintaining similar or better bounds on error. The authors show compelling results with varied sized networks on both MNIST and CIFAR dataset, providing significant improvements over past baselines. The paper itself is very well written, lucidly articulating the key contributions of the paper and highlighting the key results. The method and rationale behind it quite easy to follow. Pros: > Show significant benefits over previous baseline with 7.02% verified test error on MNIST at \\epsilon = 0.3, and 66.94% on CIFAR-10 with \\epsilon = 8/255 > The proposed method is computationally viable, with up to 20X faster than linear relaxation methods with similar. better test errors and within 5-7X slower than the conventional IBP methods with worse errors Cons: > Extensive experiments with more advanced networks/datasets would have been more convincing, esp. given the computation efficiency that enables such experiments > More elaborate insights into the choice of the training config/hyper-params esp. with the choice of \\K_start, \\K_end across the different datasets Other comments: > For the computational efficiency studies, it would be helpful to provide a breakdown of the costs between the different layers and operations, to better asses/confirm that benefits of CROWN-IBP method > Impact of other complementary techniques such a lower precision/quantization? One fo the references compared against is the Gowal et al. 2018 for the as a baseline, however, it seems to be those results were obtained on a different HW platform (TPUs - motioned in Appendix-B), with potentially different computational accuracies (BFLOAT16 ?). So, this bears to question of the impact of precision on these methods and also the computation complexity. > Since I'm not very well versed with the current baseline and state-of-art for variable robust training of DNN, it would be good to get an additional confirmation on the validity of the used baselines.", "rating": "8: Accept", "reply_text": "We thank the reviewer for the encouraging comments and constructive feedback . We really appreciate the reviewer \u2019 s precise characterization of the contributions in our work . We provide answers to the raised questions/cons below . ( Q1 ) .Extensive experiments on advanced networks/datasets In our paper we use the same networks as the previous work ( Gowal et al.2018 ) , to stay comparable with their results , which we call DM-Small , DM-Medium , and DM-Large . During the preparation of this submission , we tried much wider networks by increasing the width of the DM-Large model twice and four times , but they did not yield significant performance improvement . Thus we decided to keep models the same as in previous work for a straightforward comparison . We plan to implement more advanced networks ( e.g. , ResNet , DenseNet , etc ) as the next step and scale to larger datasets is our future work . Besides the three models presented in the submitted version of the paper , in this revision , we additionally provide more comprehensive experiments on a large range of MNIST and CIFAR-10 models ( 18 MNIST models + 17 CIFAR models ) . The purpose of this experiment is to compare model performance statistics ( min , median , and max ) on a wide range of models , rather than a few hand-selected models . The results are presented in Appendix F , Table D. On all model structures and parameter settings , CROWN-IBP can outperform IBP in terms of best , median and worst verified errors . Especially , in many situations , the worst-case verified error improves significantly using CROWN-IBP because IBP training is not stable on some of the models . ( Q2 ) .More elaborate insights into the choice of the training config/hyper-params : This is a very good suggestion . kappa controls the trade-off between verified accuracy and standard ( clean ) accuracy and we typically recommend kappa_start=1 and kappa_end=0 . beta determines if we want to use a convex relaxation-based the bound or IBP based bound ; the general recommendation is to set beta_start=1 and beta_end=0 . We added three paragraphs at the end of Appendix B to discuss the selection of hyperparameters in detail . ( Q3 ) .Breakdown of the cost between different layers and operations : The per-layer cost for propagating the CROWN-IBP bound backward is actually quite simple : in a high level , for all operations in the neural network , it is $ n_L - 1 $ times ( $ n_L $ is the number of classes , for MNIST/CIFAR it is 10 ) more expensive than forward propagation as there are $ n_L - 1 $ specifications per example . Thus CROWN-IBP is well suited to problems where the number of classes is small ( more classes can be done efficiently by subsampling of specifications , which is left to future work ) . CROWN-IBP is significantly more efficient than CROWN ( Zhang et al. , 2018 ) and convex adversarial polytope ( Wong et al. , 2018 ) ; it is $ L n $ times faster than these approaches , where $ L $ is the number of layers and $ n $ is hidden layer size . Generally , ( ordinary ) CROWN and convex adversarial polytopes are too slow for training . Practically , CROWN-IBP training time can be much less than $ n_L - 1 $ times slower than IBP , as CROWN-IBP is typically only used during the epsilon schedule rather than the entire training process , and CROWN-IBP generally executes more efficiently than IBP on parallel hardware because it packs denser computation that utilizes hardware accelerators better . Empirically , we have further optimized the implementation of CROWN-IBP ( with roughly 2X reduction in training time in Table G ) , and we have prepared a multi-GPU version that can train the largest CIFAR-10 model in about 1 day using 4 GPUs . We have provided updated training time measurement in Appendix J and Table G. On the largest CIFAR-10 model , training using CROWN-IBP is actually only about twice slower than IBP . ( Q4 ) .Complementary techniques such as lower precision/quantization : To see if bfloat16 has any impact on training results , we additionally implement CROWN-IBP on multi-GPUs with float32 . We train the CIFAR-10 model using the same hyperparameters as on TPUs and we found that the differences between TPU and GPU training results are small . The results are provided in Table H. We see no big difference between bfloat16 and float32 training . ( Q5 ) .Confirmation on state-of-the-art verifiable training baseline : For the verification of L infinity norm perturbations , the current best baselines in most settings are IBP ( Gowal et al. , 2018 ) , except on CIFAR 2/255 where ( Wong et al.2018 ) is the best . CROWN-IBP can achieve better-verified accuracy than previous state-of-the-art works in all settings . We thank the reviewer again and will be glad to discuss with the reviewer on any parts that are still unclear , or any additional concerns raised ."}], "0": {"review_id": "Skxuk1rFwB-0", "review_text": "This paper proposes a new method for training certifiably robust models that achieves better results than the previous SOTA results by IBP, with a moderate increase in training time. It uses a CROWN-based bound in the warm up phase of IBP, which serves as a better initialization for the later phase of IBP and lead to improvements in both robust and standard accuracy. The CROWN-based bound uses IBP to compute bounds for intermediate pre-activations and applies CROWN only to computing the bounds of the margins, which has a complexity between IBP and CROWN. The experimental results are verify detailed to demonstrate the improvement. The improvement is significant enough to me and I tend to accept the paper. The results on CIFAR10 with epsilon=8/255 is so far the state-of-the-art. However, it is far from being scalable enough to large networks and datasets, which has already been achieved by randomized smoothing based approaches. On CIFAR10, it takes 32 TPU cores to train a 4-conv-layer network. Still, such an approach has the advantage of making robust inferences much more efficiently than randomized smoothing, and thus still worth further explorations.", "rating": "6: Weak Accept", "reply_text": "Dear AnonReviewer2 , We thank you for recognizing the contributions of our paper and raising the discussions on randomized smoothing and concerns on expensive computations on TPUs . ( Answer 1 ) Compared to the randomized smoothing based method , our bound propagation-based approach has several theoretical and practical benefits : 1 . Recent works [ 1 ] [ 2 ] show that randomized smoothing may not scale well for the important case of L infinity robustness . They provided some preliminary theoretical evidence that even the * optimal * robustness certificate for L infinity smoothing has a dependency on dimension d , thus for high dimensional input ( e.g. , CIFAR with d=3072 ) , randomized smoothing based method can not give a good quality bound . On the other hand , for L2 norm , the randomized smoothing certificate is dimension-free . This is a fundamental limitation of randomized smoothing . For the L infinity setting like CIFAR epsilon=8/255 , bound propagation-based method like CROWN-IBP still gives the best results . 2.As also mentioned by the reviewer , randomized smoothing typically needs a large number of samples , e.g. , in Cohen et al. , 100,000 random samples for a * single * image . In contrast , our verification can be computed using IBP very fast , which is only 2x forward propagation time . Randomized smoothing costs 50,000x more during inference , and our training procedure is 500x ( pessimistically ) slower during training time . So it is really a trade-off here ; each method has its own strength . Being scalable to large networks on all important norms with less training/inference cost is still an open challenge . It is not solved by randomized smoothing , nor CROWN-IBP . For the next step , our future work will investigate how to combine the strengths from bound propagation-based certified defense ( good for L infinity norm , sample free ) and randomized smoothing based approach ( good for L2 norm , need a lot of samples ) . Thus , our contribution as the SOTA bound propagation-based certified defense is important , as it can become an ingredient of the next generation certified defense . ( Answer 2 ) Regarding computation cost , the use of 32 TPUs is not necessary . We use TPUs mainly for obtaining a completely fair comparison to IBP ( Gowal et al , 2018 ) , as their implementation was TPU-based . We additionally implemented CROWN-IBP using multi-GPUs . Training the same largest CIFAR network takes 1 day on 4x 1080 Ti GPUs ( using the same hyperparameters ) , and we can achieve similar accuracy . We think this computational cost is quite reasonable , compared to other SOTA uncertified defense like adversarial training , which is also quite slow ( 10-20x extra cost for each epoch , and needs much more epochs to converge than natural training ) . We updated new multi-GPU training results in Table H , and we will open source our multi-GPU training code to make our algorithm available to a broader audience . We hope our response addresses your concerns on TPU training and randomized smoothing , and please kindly let us know if you have any further questions . References : [ 1 ] A Unified Framework for Randomized Smoothing based Certified Defense . https : //openreview.net/pdf ? id=ryl71a4YPB [ 2 ] Filling the Soap of Bubbles : Efficient Black-Box Adversarial Certification with Non-gaussian smoothing . https : //openreview.net/pdf ? id=Skg8gJBFvr"}, "1": {"review_id": "Skxuk1rFwB-1", "review_text": "This paper proposes a new variation on certified adversarial training method that builds on two prior works IBP and CROWN. They showed the method outperformed all previous linear relaxation and bound propagation based certified defenses. Pros: 1. The empirical results are strong. The method achieved SOTA. Cons: 1. Novelty seems small. It is a straightforward combination of prior works, by adding two bounds together. 2. Adds a new hyperparameter for tuning. 3. Lack of any theoretical insights/motivation for the proposed method. Why would we want to combine the two lower bounds? The reason given in the paper is not very convincing: \"IBP has better learning power at larger epsilon and can achieve much smaller verified error. However, it can be hard to tune due to its very imprecise bound at the beginning of training; on the other hand, linear relaxation based methods give tighter lower bounds which stabilize training, but it over-regularizes the network and forbids us to achieve good accuracy.\" My questions with regards to this: (i) Why does loose bound result in unstable training? Tighter bound stabilize training? (ii) If we're concerned with using a tighter bound could result in over-regularization, then why not just combine the natural loss with the tight bound, as natural loss can be seen as the loosest bound. Is IBP crucial? and why? ", "rating": "3: Weak Reject", "reply_text": "Dear AnonReviewer3 , Thank you for providing your helpful feedback . Sorry for the potential confusion in our paper and we would like to clarify them in our response , and we have added relevant discussions to our revision . ( Q1 ) Why does loose bounds result in unstable training ? Tighter bounds stabilize training ? Loose bounds ( lower bounds on margins $ \\underline { m } $ , as defined on page 4 \u201c verification specifications \u201d ) give a loose upper bound of the minimax loss ( Eq.4 ) ; in other words , the \u201c robust loss \u201d term in ( 9 ) will become very large . A large robust loss can be a challenge for the optimizer to minimize , and training can easily diverge or stuck at random guess level . More specifically , we will explain why a tighter bound like CROWN-IBP can help to stabilize IBP training . When taking a randomly initialized network or a naturally trained network , IBP bounds are very loose . But in Table 1 , we show that a network trained using IBP can eventually obtain quite tight IBP bounds and high verified accuracy ( i.e. , the network can adapt to IBP bounds and learn a specific set of weights to make IBP tight and also correctly classify examples ) . However , since the training has to start from weights that produce loose bounds for IBP , the beginning phase of IBP training can be challenging and is vitally important . We observe that IBP training can have a large performance variance across models and initializations . Also , IBP is more sensitive to hyper-parameters like kappa or schedule length ; as you can see in Figure 3 , many IBP models failed to converge ( large worst/median verified error ) with some kappa or schedule length settings . The reason for instability is that during the beginning phase of training , the loose bounds produced by IBP make the robust loss ( Eq.9 ) explode , and it is challenging for the optimizer to reduce this loss and find a set of good weights that produce tight IBP verified bounds in the end . Conversely , if our bounds are much tighter at the beginning , the robust loss ( Eq.9 ) always remains in a reasonable range during training , and the network can gradually learn to find a good set of weights that make IBP bounds increasingly tighter . Initially , tighter bounds can be provided by a convex relaxation-based method , and the convex relaxation bounds are gradually replaced by IBP bound ( using beta_start=1 , beta_end=0 ) , eventually leading to a model with learned tight IBP bounds in the end . To give you some intuitions on how much tighter CROWN-IBP is than IBP , in appendix B , we added a figure comparing the tightness between IBP bound and CROWN-IBP bound . We take the difference between the two bounds ( CROWN-IBP bound minus IBP bound ) and plot this difference during the training procedure . At the beginning of training , the bound difference can be very large , and the network gradually learns how to make the IBP bounds tighter during the training process . The use of tighter bounds at the beginning prevents divergence and can guide the network to learn better IBP bounds and achieve better-verified accuracy . ( Q2 ) why not just combine the natural loss with the tight bound , as natural loss can be seen as the loosest bound ? Is IBP crucial ? and why ? The natural loss does not provide a bound . The loosest bound is negative infinity , and it will explode the robust loss in Eq. ( 9 ) . ( see page 4 , verification specifications , for the definition of this lower bound on margin , and Eq ( 4 ) for how to use it to get an upper bound for the minimax loss ) . IBP is crucial because it can provide us with a bound for computing the robust loss . Natural training can not provide such bounds . Additionally , a network trained using natural loss is not robust and difficult to verify with current techniques . Models trained using IBP bounds as $ \\underline { m } $ in Eq . ( 9 ) can be quickly verified using IBP . -- to be continued"}, "2": {"review_id": "Skxuk1rFwB-2", "review_text": "This work proposes CROWN-IBP - novel and efficient certified defense method against adversarial attacks, by combining linear relaxation methods which tend to have tighter bounds with the more efficient interval-based methods. With an attempt to augment the IBP method with its lower computation complexity with the tight CROWN bounds, to get the best of both worlds. One of the primary contributions here is that reduction of computation complexity by an order of \\Ln while maintaining similar or better bounds on error. The authors show compelling results with varied sized networks on both MNIST and CIFAR dataset, providing significant improvements over past baselines. The paper itself is very well written, lucidly articulating the key contributions of the paper and highlighting the key results. The method and rationale behind it quite easy to follow. Pros: > Show significant benefits over previous baseline with 7.02% verified test error on MNIST at \\epsilon = 0.3, and 66.94% on CIFAR-10 with \\epsilon = 8/255 > The proposed method is computationally viable, with up to 20X faster than linear relaxation methods with similar. better test errors and within 5-7X slower than the conventional IBP methods with worse errors Cons: > Extensive experiments with more advanced networks/datasets would have been more convincing, esp. given the computation efficiency that enables such experiments > More elaborate insights into the choice of the training config/hyper-params esp. with the choice of \\K_start, \\K_end across the different datasets Other comments: > For the computational efficiency studies, it would be helpful to provide a breakdown of the costs between the different layers and operations, to better asses/confirm that benefits of CROWN-IBP method > Impact of other complementary techniques such a lower precision/quantization? One fo the references compared against is the Gowal et al. 2018 for the as a baseline, however, it seems to be those results were obtained on a different HW platform (TPUs - motioned in Appendix-B), with potentially different computational accuracies (BFLOAT16 ?). So, this bears to question of the impact of precision on these methods and also the computation complexity. > Since I'm not very well versed with the current baseline and state-of-art for variable robust training of DNN, it would be good to get an additional confirmation on the validity of the used baselines.", "rating": "8: Accept", "reply_text": "We thank the reviewer for the encouraging comments and constructive feedback . We really appreciate the reviewer \u2019 s precise characterization of the contributions in our work . We provide answers to the raised questions/cons below . ( Q1 ) .Extensive experiments on advanced networks/datasets In our paper we use the same networks as the previous work ( Gowal et al.2018 ) , to stay comparable with their results , which we call DM-Small , DM-Medium , and DM-Large . During the preparation of this submission , we tried much wider networks by increasing the width of the DM-Large model twice and four times , but they did not yield significant performance improvement . Thus we decided to keep models the same as in previous work for a straightforward comparison . We plan to implement more advanced networks ( e.g. , ResNet , DenseNet , etc ) as the next step and scale to larger datasets is our future work . Besides the three models presented in the submitted version of the paper , in this revision , we additionally provide more comprehensive experiments on a large range of MNIST and CIFAR-10 models ( 18 MNIST models + 17 CIFAR models ) . The purpose of this experiment is to compare model performance statistics ( min , median , and max ) on a wide range of models , rather than a few hand-selected models . The results are presented in Appendix F , Table D. On all model structures and parameter settings , CROWN-IBP can outperform IBP in terms of best , median and worst verified errors . Especially , in many situations , the worst-case verified error improves significantly using CROWN-IBP because IBP training is not stable on some of the models . ( Q2 ) .More elaborate insights into the choice of the training config/hyper-params : This is a very good suggestion . kappa controls the trade-off between verified accuracy and standard ( clean ) accuracy and we typically recommend kappa_start=1 and kappa_end=0 . beta determines if we want to use a convex relaxation-based the bound or IBP based bound ; the general recommendation is to set beta_start=1 and beta_end=0 . We added three paragraphs at the end of Appendix B to discuss the selection of hyperparameters in detail . ( Q3 ) .Breakdown of the cost between different layers and operations : The per-layer cost for propagating the CROWN-IBP bound backward is actually quite simple : in a high level , for all operations in the neural network , it is $ n_L - 1 $ times ( $ n_L $ is the number of classes , for MNIST/CIFAR it is 10 ) more expensive than forward propagation as there are $ n_L - 1 $ specifications per example . Thus CROWN-IBP is well suited to problems where the number of classes is small ( more classes can be done efficiently by subsampling of specifications , which is left to future work ) . CROWN-IBP is significantly more efficient than CROWN ( Zhang et al. , 2018 ) and convex adversarial polytope ( Wong et al. , 2018 ) ; it is $ L n $ times faster than these approaches , where $ L $ is the number of layers and $ n $ is hidden layer size . Generally , ( ordinary ) CROWN and convex adversarial polytopes are too slow for training . Practically , CROWN-IBP training time can be much less than $ n_L - 1 $ times slower than IBP , as CROWN-IBP is typically only used during the epsilon schedule rather than the entire training process , and CROWN-IBP generally executes more efficiently than IBP on parallel hardware because it packs denser computation that utilizes hardware accelerators better . Empirically , we have further optimized the implementation of CROWN-IBP ( with roughly 2X reduction in training time in Table G ) , and we have prepared a multi-GPU version that can train the largest CIFAR-10 model in about 1 day using 4 GPUs . We have provided updated training time measurement in Appendix J and Table G. On the largest CIFAR-10 model , training using CROWN-IBP is actually only about twice slower than IBP . ( Q4 ) .Complementary techniques such as lower precision/quantization : To see if bfloat16 has any impact on training results , we additionally implement CROWN-IBP on multi-GPUs with float32 . We train the CIFAR-10 model using the same hyperparameters as on TPUs and we found that the differences between TPU and GPU training results are small . The results are provided in Table H. We see no big difference between bfloat16 and float32 training . ( Q5 ) .Confirmation on state-of-the-art verifiable training baseline : For the verification of L infinity norm perturbations , the current best baselines in most settings are IBP ( Gowal et al. , 2018 ) , except on CIFAR 2/255 where ( Wong et al.2018 ) is the best . CROWN-IBP can achieve better-verified accuracy than previous state-of-the-art works in all settings . We thank the reviewer again and will be glad to discuss with the reviewer on any parts that are still unclear , or any additional concerns raised ."}}