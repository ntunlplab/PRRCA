{"year": "2019", "forum": "ryeaZhRqFm", "title": "Link Prediction in Hypergraphs using Graph Convolutional Networks", "decision": "Reject", "meta_review": "The paper describes  a method for the link prediction problem in both directed and undirected hypergraphs.  While the problem discussed in the paper is clearly importnant and interesting, all reviewers agree that the novelty of the proposed approach is somewhat limited given the prior art.", "reviews": [{"review_id": "ryeaZhRqFm-0", "review_text": "[Relevance] Is this paper relevant to the ICLR audience? yes [Significance] Are the results significant? somewhat [Novelty] Are the problems or approaches novel? rather incremental [Soundness] Is the paper technically sound? yes [Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal [Clarity] Is the paper well-organized and clearly written? okay Confidence: 2/5 Seen submission posted elsewhere: No Detailed comments: In this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs. The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual. They then use GCNs to classify the (dual) nodes. Experimentally, the proposed approach marginally outperforms existing approaches. === Major comments I found the novelty of the proposed approach rather limited. The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well). I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion. It is difficult to interpret the experimental results. Tables 3 and 6 do not include a measure of variance. Thus, it is not clear if any of the results are statistically significant. It is also not clear whether the \u201c10 trials\u201d mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else. It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do. It is also unclear to me why \u201cfake papers\u201d are needed for the citation networks; it is clear that \u201cfake author lists\u201d are needed for negative sampling, but it seems they could be attached to existing papers. Similarly, it is unclear how the set of candidate edges (\\mathcal{E}) was chosen. I appreciate that the authors made the code available. I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work. === Minor comments This work is very similar to the arXiv submission 1809.09401. To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here. According to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP. According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases. Is there some relationship between NHP\u2019s performance and the size/density of the graph? or is there some other explanation for this behavior? Related to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions. Is there some explanation for this? For example, are there qualitative differences in the size of the hypernodes? The described strategy for negative sampling seems as though it selects \u201ceasy\u201d negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary. How does the performance change if more \u201cdifficult\u201d (or just uniformly random) negative samples are chosen? I believe Recall@100 (or Precision@100, or @$\\Delta E$, etc.) is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges. That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable. === Typos, etc. In Equation (4), the \u201ck\u201d index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}. \u201ctable 2\u201d -> \u201cTable 2\u201d, and many other similar examples throughout the paper. \u201chigher-order etc.\u201d -> \u201chigher-order, etc.\u201d \u201cGCN based\u201d -> \u201cGCN-based\u201d, and similar in several places in the paper \u201ca incomplete\u201d -> \u201can incomplete\u201d ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the review On the novelty of our work : Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem . Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple , yet effective . We believe the problem settings are important and interesting ( as noted by the other reviewers too ) , and that this paper will inspire further research in this direction . On the discussion of results for directed hyperlink prediction : Both NHP-D ( joint ) and NHP-D ( sequential ) perform similarly . To appreciate the results , we have added three baselines as suggested by reviewers 2 and 3 . We request the reviewer to see below for a sample of the updated results and the paper for all updated results . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - dataset iAF692 iHN637 iAF1260b iJO1366 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - node2vec + MLP 255 +/- 5 237 +/- 5 838 +/- 13 902 +/- 11 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - CMM + MLP 253 +/- 9 241 +/- 11 757 +/- 26 848 +/- 21 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have reported variances in the number of hyperlinks recovered in all experiments . These are much more interpretable/statistically significant . On 10 trials : We report the mean values over 10 different splits of train and test . On random features : The feature initialisations are random for metabolic network experiments as we do not have any available features to exploit . We believe the neighbourhood feature aggregation of GCN causes useful node embeddings to be learnt during training . We also observe that NHP is competitive with a node2vec baseline ( suggested by reviewer 3 ) which is a featureless approach . On creation of fake papers : In these experiments , authors correspond to nodes in the ( primal ) graph , while papers correspond to hyperlinks , i.e. , sets of authors . So in this context , fake papers are the same as fake author lists and hence can not be attached to existing ( true ) papers . The set of candidate edges is the set of true papers union the set of fake papers ."}, {"review_id": "ryeaZhRqFm-1", "review_text": "This paper proposed Neural Hyperlink Predictor (NHP) to perform link prediction based on graph convolutional network (GCN). Following prior work, the hyperlink prediction is perform in the dual hypergraph, where each node represents a hyperlink in the primal hypergraph. The original problem is then equivalent to a simple node classification problem. To deal with directed hyperlink, a separate term is added to distinguish heads from tails. The problem of link prediction in hypergraph is important and interesting, especially in the chemistry domain. However from the technical point of view, this work is somewhat incremental since prior work has done link prediction using GCN (Zhang and Chen, 2018). The idea of performing hyperlink prediction in the dual hypergraph is not new, either (Lugo-Martinez and Radivojac, 2017). As for the directed hypergraph setting, it seems to be a straightforward extension once one knows how to do in the undirected setting (adding an extra term to classify head/tail). In terms of experiments, given the similarity between Lugo-Martinez and Radivojac, 2017 and NHP (both operates in the dual hypergraph), it would be better if the former could also be used as a baseline, as least in the undirected setting. It is reasonable to have a subset of links as candidate reactions in the metoboli network datasets. For CORA and DBLP, it is not clear where the \u2018actual papers\u2019 and \u2018candidate papers\u2019 come from. For example in CORA there are 1072 authors; yet there are only 5416 candidate papers. It seems the joint learning of NHP-D does not improve the accuracy in the directed setting as claimed in Sec. 5.2. Besides, there is no baseline in the directed setting. It is difficult to appreciate the performance in Sec. 6. One thing one can do is to use previous methods in the undirected setting, e.g., CMM, with the extra term L_d in Eq. (4). Minor comments: Typo: P5: atleast -> at least P5: What is GCN 2? Sec. 5: \u2018p = 32 in 1\u2019 and \u2018shown in 2\u2019 Missing references on link prediction and/or deep learning: Discriminative relational topic models. PAMI 2014. Relational deep learning: A deep latent variable model for link prediction. AAAI 2017 Neural relational topic models for scientific article analysis. CIKM 2018.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for the review . On the novelty of our work : Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem . Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple , yet effective . We believe the problem settings are important and interesting ( as noted by the other reviewers too ) , and that this paper will inspire further research in this direction . On adding an extra term to CMM as a baseline for directed hyperlink experiments : Following the reviewer \u2019 s suggestion , we have added CMM + MLP as a baseline . We have also compared NHP against node2vec + MLP and star expansion + MLP as suggested by reviewer # 3 . We report below the number of reactions recovered in the directed hypergraph experiments . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - dataset iAF692 iHN637 iAF1260b iJO1366 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - node2vec + MLP 255 +/- 5 237 +/- 5 838 +/- 13 902 +/- 11 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - CMM + MLP 253 +/- 9 241 +/- 11 757 +/- 26 848 +/- 21 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have also observed that NHP-U outperforms all its baselines in the undirected experiments and the results have been updated in our paper . On candidate papers in coauthorship networks such as cora : The standard cora dataset has 2708 papers . We sampled an equal number of fake papers at random to get the 5416 candidate papers for cora . We request the reviewer to see the appendix for more details . On comparison with Lugo-Martinez and Radivojac , 2017 : We had difficulty reproducing the results , given that the code was not available and the authors did not respond to our request emails , and the method as described in the paper is rather vague about the details ."}, {"review_id": "ryeaZhRqFm-2", "review_text": "This paper proposed to use graph convolutional neural networks for link prediction. The authors proposed to use the dual graph to simultaneously learn node and edge embeddings. The label of the edges (positive or negative) are used as supervised signal for training the GCNs. Experiments on a few small data set prove the effectiveness of the proposed approaches. Strength: - important problem Weakness: - the novelty of the proposed method is very marginal - the experiments are quite weak Details: - the novelty of the proposed method seems to be very marginal, which simply applies the GCN for link prediction. The existing GCN based method for recommendation shares similar ideas (e.g., Yin et al. 2018, PinSage), though dual hypergraph is not used. But the essential idea is very similar. - the data sets used in the experiments are too small - the node embedding based methods should be compared for link prediction, e.g., DeepWalk, LINE, and node2vec. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks for the review . On the novelty of our work : Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem . Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple , yet effective . We believe the problem settings are important and interesting ( as noted by the other reviewers too ) , and that this paper will inspire further research in this direction . On comparison with PinSage [ Ying et al.KDD 2018 ] : PinSage has been designed to work on the bipartite graph of Pinterest . The Pinterest graph can be seen as the star expansion of a hypergraph with pins ( hypernodes ) on one side of the partition and boards ( hyperlinks ) on the other side . Following the reviewer \u2019 s suggestion , we have compared NHP against star expansion below . On comparison with node2vec : Following the reviewer \u2019 s suggestion , we have compared NHP against node2vec . Node2vec has been shown to be superior to DeepWalk and LINE in [ Grover et al.KDD 2016 ] and hence we have compared only against it . We have also compared NHP against CMM+MLP as suggested by reviewer # 2 . We report only the number of reactions recovered in the undirected hypergraph experiments . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - dataset iAF692 iHN637 iAF1260b iJO1366 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - node2vec 299 +/- 10 303 +/- 4 1100 +/- 13 1221 +/- 21 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - GCN on star expansion 174 +/- 5 219 +/- 12 649 +/- 10 568 +/- 18 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have updated the results for all the other datasets and experiments and we request the reviewer to see the paper . From the table above , we can see that the star expansion of a hypergraph is less effective because there are no direct connections between chemical reactions ( because the graph is bipartite ) . Clique expansion , on the other hand , connects two chemical reactions if they share a chemical substance and hence can exploit the relationships much better . On the size of the datasets used : Our work was motivated by the task of predicting reactions , for which we used datasets already available in the literature ( given by Zhang et.al , AAAI 2018 ) . Regarding the co-authorship datasets used , we had to filter the large datasets already available to ensure that meaningful hyperlinks were obtained which led to some reduction in size . We request the reviewer to take a look at the appendix for the exact details . On simultaneous learning of node and edge embeddings : NHP , our proposed method , learns node embeddings in the dual hypergraph which is the same as learning hyperlink embeddings in the primal . While PinSage works on the Pinterest bipartite graph ( star expansion ) and hence involves simultaneous learning of node/edge embeddings , NHP works on the clique expansion and learns node embeddings of the dual ."}], "0": {"review_id": "ryeaZhRqFm-0", "review_text": "[Relevance] Is this paper relevant to the ICLR audience? yes [Significance] Are the results significant? somewhat [Novelty] Are the problems or approaches novel? rather incremental [Soundness] Is the paper technically sound? yes [Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal [Clarity] Is the paper well-organized and clearly written? okay Confidence: 2/5 Seen submission posted elsewhere: No Detailed comments: In this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs. The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual. They then use GCNs to classify the (dual) nodes. Experimentally, the proposed approach marginally outperforms existing approaches. === Major comments I found the novelty of the proposed approach rather limited. The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well). I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion. It is difficult to interpret the experimental results. Tables 3 and 6 do not include a measure of variance. Thus, it is not clear if any of the results are statistically significant. It is also not clear whether the \u201c10 trials\u201d mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else. It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do. It is also unclear to me why \u201cfake papers\u201d are needed for the citation networks; it is clear that \u201cfake author lists\u201d are needed for negative sampling, but it seems they could be attached to existing papers. Similarly, it is unclear how the set of candidate edges (\\mathcal{E}) was chosen. I appreciate that the authors made the code available. I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work. === Minor comments This work is very similar to the arXiv submission 1809.09401. To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here. According to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP. According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases. Is there some relationship between NHP\u2019s performance and the size/density of the graph? or is there some other explanation for this behavior? Related to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions. Is there some explanation for this? For example, are there qualitative differences in the size of the hypernodes? The described strategy for negative sampling seems as though it selects \u201ceasy\u201d negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary. How does the performance change if more \u201cdifficult\u201d (or just uniformly random) negative samples are chosen? I believe Recall@100 (or Precision@100, or @$\\Delta E$, etc.) is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges. That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable. === Typos, etc. In Equation (4), the \u201ck\u201d index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}. \u201ctable 2\u201d -> \u201cTable 2\u201d, and many other similar examples throughout the paper. \u201chigher-order etc.\u201d -> \u201chigher-order, etc.\u201d \u201cGCN based\u201d -> \u201cGCN-based\u201d, and similar in several places in the paper \u201ca incomplete\u201d -> \u201can incomplete\u201d ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the review On the novelty of our work : Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem . Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple , yet effective . We believe the problem settings are important and interesting ( as noted by the other reviewers too ) , and that this paper will inspire further research in this direction . On the discussion of results for directed hyperlink prediction : Both NHP-D ( joint ) and NHP-D ( sequential ) perform similarly . To appreciate the results , we have added three baselines as suggested by reviewers 2 and 3 . We request the reviewer to see below for a sample of the updated results and the paper for all updated results . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - dataset iAF692 iHN637 iAF1260b iJO1366 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - node2vec + MLP 255 +/- 5 237 +/- 5 838 +/- 13 902 +/- 11 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - CMM + MLP 253 +/- 9 241 +/- 11 757 +/- 26 848 +/- 21 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have reported variances in the number of hyperlinks recovered in all experiments . These are much more interpretable/statistically significant . On 10 trials : We report the mean values over 10 different splits of train and test . On random features : The feature initialisations are random for metabolic network experiments as we do not have any available features to exploit . We believe the neighbourhood feature aggregation of GCN causes useful node embeddings to be learnt during training . We also observe that NHP is competitive with a node2vec baseline ( suggested by reviewer 3 ) which is a featureless approach . On creation of fake papers : In these experiments , authors correspond to nodes in the ( primal ) graph , while papers correspond to hyperlinks , i.e. , sets of authors . So in this context , fake papers are the same as fake author lists and hence can not be attached to existing ( true ) papers . The set of candidate edges is the set of true papers union the set of fake papers ."}, "1": {"review_id": "ryeaZhRqFm-1", "review_text": "This paper proposed Neural Hyperlink Predictor (NHP) to perform link prediction based on graph convolutional network (GCN). Following prior work, the hyperlink prediction is perform in the dual hypergraph, where each node represents a hyperlink in the primal hypergraph. The original problem is then equivalent to a simple node classification problem. To deal with directed hyperlink, a separate term is added to distinguish heads from tails. The problem of link prediction in hypergraph is important and interesting, especially in the chemistry domain. However from the technical point of view, this work is somewhat incremental since prior work has done link prediction using GCN (Zhang and Chen, 2018). The idea of performing hyperlink prediction in the dual hypergraph is not new, either (Lugo-Martinez and Radivojac, 2017). As for the directed hypergraph setting, it seems to be a straightforward extension once one knows how to do in the undirected setting (adding an extra term to classify head/tail). In terms of experiments, given the similarity between Lugo-Martinez and Radivojac, 2017 and NHP (both operates in the dual hypergraph), it would be better if the former could also be used as a baseline, as least in the undirected setting. It is reasonable to have a subset of links as candidate reactions in the metoboli network datasets. For CORA and DBLP, it is not clear where the \u2018actual papers\u2019 and \u2018candidate papers\u2019 come from. For example in CORA there are 1072 authors; yet there are only 5416 candidate papers. It seems the joint learning of NHP-D does not improve the accuracy in the directed setting as claimed in Sec. 5.2. Besides, there is no baseline in the directed setting. It is difficult to appreciate the performance in Sec. 6. One thing one can do is to use previous methods in the undirected setting, e.g., CMM, with the extra term L_d in Eq. (4). Minor comments: Typo: P5: atleast -> at least P5: What is GCN 2? Sec. 5: \u2018p = 32 in 1\u2019 and \u2018shown in 2\u2019 Missing references on link prediction and/or deep learning: Discriminative relational topic models. PAMI 2014. Relational deep learning: A deep latent variable model for link prediction. AAAI 2017 Neural relational topic models for scientific article analysis. CIKM 2018.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for the review . On the novelty of our work : Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem . Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple , yet effective . We believe the problem settings are important and interesting ( as noted by the other reviewers too ) , and that this paper will inspire further research in this direction . On adding an extra term to CMM as a baseline for directed hyperlink experiments : Following the reviewer \u2019 s suggestion , we have added CMM + MLP as a baseline . We have also compared NHP against node2vec + MLP and star expansion + MLP as suggested by reviewer # 3 . We report below the number of reactions recovered in the directed hypergraph experiments . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - dataset iAF692 iHN637 iAF1260b iJO1366 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - node2vec + MLP 255 +/- 5 237 +/- 5 838 +/- 13 902 +/- 11 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - CMM + MLP 253 +/- 9 241 +/- 11 757 +/- 26 848 +/- 21 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have also observed that NHP-U outperforms all its baselines in the undirected experiments and the results have been updated in our paper . On candidate papers in coauthorship networks such as cora : The standard cora dataset has 2708 papers . We sampled an equal number of fake papers at random to get the 5416 candidate papers for cora . We request the reviewer to see the appendix for more details . On comparison with Lugo-Martinez and Radivojac , 2017 : We had difficulty reproducing the results , given that the code was not available and the authors did not respond to our request emails , and the method as described in the paper is rather vague about the details ."}, "2": {"review_id": "ryeaZhRqFm-2", "review_text": "This paper proposed to use graph convolutional neural networks for link prediction. The authors proposed to use the dual graph to simultaneously learn node and edge embeddings. The label of the edges (positive or negative) are used as supervised signal for training the GCNs. Experiments on a few small data set prove the effectiveness of the proposed approaches. Strength: - important problem Weakness: - the novelty of the proposed method is very marginal - the experiments are quite weak Details: - the novelty of the proposed method seems to be very marginal, which simply applies the GCN for link prediction. The existing GCN based method for recommendation shares similar ideas (e.g., Yin et al. 2018, PinSage), though dual hypergraph is not used. But the essential idea is very similar. - the data sets used in the experiments are too small - the node embedding based methods should be compared for link prediction, e.g., DeepWalk, LINE, and node2vec. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks for the review . On the novelty of our work : Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem . Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple , yet effective . We believe the problem settings are important and interesting ( as noted by the other reviewers too ) , and that this paper will inspire further research in this direction . On comparison with PinSage [ Ying et al.KDD 2018 ] : PinSage has been designed to work on the bipartite graph of Pinterest . The Pinterest graph can be seen as the star expansion of a hypergraph with pins ( hypernodes ) on one side of the partition and boards ( hyperlinks ) on the other side . Following the reviewer \u2019 s suggestion , we have compared NHP against star expansion below . On comparison with node2vec : Following the reviewer \u2019 s suggestion , we have compared NHP against node2vec . Node2vec has been shown to be superior to DeepWalk and LINE in [ Grover et al.KDD 2016 ] and hence we have compared only against it . We have also compared NHP against CMM+MLP as suggested by reviewer # 2 . We report only the number of reactions recovered in the undirected hypergraph experiments . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - dataset iAF692 iHN637 iAF1260b iJO1366 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - node2vec 299 +/- 10 303 +/- 4 1100 +/- 13 1221 +/- 21 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - GCN on star expansion 174 +/- 5 219 +/- 12 649 +/- 10 568 +/- 18 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- We have updated the results for all the other datasets and experiments and we request the reviewer to see the paper . From the table above , we can see that the star expansion of a hypergraph is less effective because there are no direct connections between chemical reactions ( because the graph is bipartite ) . Clique expansion , on the other hand , connects two chemical reactions if they share a chemical substance and hence can exploit the relationships much better . On the size of the datasets used : Our work was motivated by the task of predicting reactions , for which we used datasets already available in the literature ( given by Zhang et.al , AAAI 2018 ) . Regarding the co-authorship datasets used , we had to filter the large datasets already available to ensure that meaningful hyperlinks were obtained which led to some reduction in size . We request the reviewer to take a look at the appendix for the exact details . On simultaneous learning of node and edge embeddings : NHP , our proposed method , learns node embeddings in the dual hypergraph which is the same as learning hyperlink embeddings in the primal . While PinSage works on the Pinterest bipartite graph ( star expansion ) and hence involves simultaneous learning of node/edge embeddings , NHP works on the clique expansion and learns node embeddings of the dual ."}}