{"year": "2018", "forum": "H1rRWl-Cb", "title": "An information-theoretic analysis of deep latent-variable models", "decision": "Reject", "meta_review": "This paper gives a coding theory interpretation of VAEs and uses it to motivate an additional knob for tuning and evaluating VAEs: namely, the tradeoff between the rate and the distortion. This is a useful set of dimensions to investigate, and past work on variational models has often found it advantageous to penalize the latent variable and observation coding terms differently, for broadly similar motivations. This paper includes some careful experiments analyzing this tradeoff for various VAE formulations, and provides some interesting visualizations. However, as the reviewers point out, it's difficult to point to a single clear contribution here, as the coding theory view of variational inference is well established, and the VAE case has been discussed in various other works. Therefore, I recommend rejection.\n", "reviews": [{"review_id": "H1rRWl-Cb-0", "review_text": "Summary: This paper optimizes the beta-VAE objective and analyzes the resulting models in terms of the two components of the VAE loss: the reconstruction error (which the authors refer to as distortion, \u201cD\u201d) and the KL divergence term (which the authors refer to as rate, \u201cR\u201d). Various VAEs using either PixelCNN++ or a simpler model for the encoder, decoder, or marginal distribution of a VAE are trained on MNIST (with some additional results on OMNIGLOT) and analyzed in terms of samples, reconstructions, and their rate-distortion trade-off. Review: I find it difficult to point my finger to novel conceptual or theoretical insights in this paper. The idea of maximizing information for unsupervised learning of representations has of course been explored a lot (e.g., Bell & Sejnowski, 1995). Deeper connections between variational inference and rate-distortion have been made before (e.g., Balle et al., 2017; Theis et al., 2017), while this paper merely seems to rename the reconstruction and KL terms of the ELBO. Variational lower and upper bounds on mutual information have been used before as well (e.g., Barber & Agakov, 2003; Alemi et al., 2017), although they are introduced like new results in this paper. The derived \u201csandwich equation\u201d only seems to be used to show that H - D - R <= 0, which also follows directly from Gibbs\u2019 inequality (since the left-hand side is a negative KL divergence). The main contributions therefore seem to be the proposed analysis of models in the R-D plane, and the empirical contribution of analyzing beta-VAEs. Based on the R-D plots, the authors identify a potential problem of generative models, namely that none of the trained models appear to get close to the \u201cauto-encoding limit\u201d where the distortion is close zero. Wouldn\u2019t this gap easily be closed by a model with identity encoder, identity decoder, and PixelCNN++ for the marginal distribution? Given that autoregressive models generally perform better than VAEs in terms of log-likelihood, the model\u2019s performance would probably be closer to the true entropy than the ELBO plotted in Figure 3a). What about increasing the capacity of the used in this paper? This makes me wonder what exactly the R-D plot can teach us about building better generative models. The toy example in Figure 2 is interesting. What does it tell us about how to build our generative models? Should we be using powerful decoders but a lower beta? The authors write: \u201cwe are able to learn many models that can achieve similar generative performance but make vastly different trade-offs in terms of the usage of the latent variable\u201d. Yet in Figure 3b) it appears that changing the rate of a model can influence the generative performance (ELBO) quite a bit?", "rating": "5: Marginally below acceptance threshold", "reply_text": "Based on your feedback , we have taken more care to clarify that the core variational bounds we present at the beginning of Section 2 and in some of the appendices were originally derived in Barber and Agakov 2003 , Agakov 2006 , and Alemi et al.2017.We have kept the proofs in the appendix for clarity . We view the core contributions of our work as ( 1 ) providing a clear theoretical justification for the beta-VAE objective , and ( 2 ) demonstrating that the beta-VAE objective can be used to target a task-specific target rate independent of architecture . This alleviates a known problem with the ELBO objective : achieving different rates requires modifying the architecture and is difficult to control . We have attempted to make those points more clearly in the current version of the paper . Understanding the origin of the beta-VAE objective opens the door to other approaches for training VAEs . The updated conclusion presents some of these approaches , such as constrained optimization on the variational bounds of rate and distortion , and using more powerful mutual information predictors . Finally , analyzing the performance of VAE models in terms of the RD plane can make problems with models immediately clear ( for example , poor distortion at high rates or poor use of latent variables with complex decoders ) . We also hope that we 've clearly established some connections between information theory , latent variable models , rate-distortion theory , and compression , which could spawn new results . > Based on the R-D plots , the authors identify a potential problem of generative models , > namely that none of the trained models appear to get close to the \u201c auto-encoding limit \u201d > where the distortion is close zero . Wouldn \u2019 t this gap easily be closed by a model with identity > encoder , identity decoder , and PixelCNN++ for the marginal distribution ? We agree that models with more powerful PixelCNN++ type marginals could help to close the gap in ELBO for models at high rates . The recent VQ-VAE work shows this qualitatively , and future work should more extensively explore these models to identify their frontier in the RD plane . > The toy example in Figure 2 is interesting . What does it tell us about how to build our > generative models ? Should we be using powerful decoders but a lower beta ? The toy example shows that the most powerful models ( in this case , models that are able to perfectly represent all relevant distributions ) will perform very poorly when trained using ELBO , but constraining the optimization to some rate , either using something like a beta-VAE with beta < 1 , or explicitly targeting a known rate , can result in using the model capacity optimally . As seen on MNIST and Omniglot , it seems that the best models we currently have use powerful decoders and powerful marginals , but it is necessary to use beta < 1 to avoid rate collapse . > \u201c we are able to learn many models that can achieve similar generative performance but > make vastly different trade-offs in terms of the usage of the latent variable \u201d . We meant to speak more directly to the performance over intermediate rate values , from 0 to around 10 nats on MNIST . In terms of ELBO these models are all the same , but as demonstrated in Figure 4 , over these rates we move from an unconditional generative model to an effective compression model for MNIST that seems to preserve the salient features of the input . As we describe elsewhere in the paper , the high-rate models we explored can not attain equivalently good marginal log likelihood ."}, {"review_id": "H1rRWl-Cb-1", "review_text": "EDIT: I have reviewed the authors revisions and still recommend acceptance. Summary This paper proposes assessing VAEs via two quantities: rate R (E[ KLD[q(z|x) || p(z)] ]) and distortion D (E[ log p(x|z) ]), which can be used to bound the mutual information (MI) I(x,z) from above and below respectively (i.e. H[x] - D <= I(x,z) <= R). This fact then implies the inequality H[x] <= R + D, where H[x] is the entropy of the true data distribution, and allows for the construction of a phase diagram (Figure 1) with R and D on the x and y axis respectively. Models can be plotted on the diagram to show the degree to which they favor reconstruction (D) or sampling diversity (R). The paper then reports several experiments, the first being a simulation to show that a VAE trained with vanilla ELBO cannot recover the true rate in even a 1D example. For the second experiment, 12 models are trained by varying the encoder/decoder strength (CNN vs autoregressive) and prior (fact. Gauss vs autoregressive vs VampPrior). Plots of the D vs R and ELBO vs R are shown for the models, revealing that the same ELBO value can be decomposed into drastically different R and D values. The point is further made through qualitative results in Figure 4. Evaluation Pros: While no one facet of the paper is particularly novel (as similar observations and discussion has been made by [1-4]), the paper, as far as I\u2019m aware, is the first to formally decompose the ELBO into the R vs D tradeoff, which is natural. As someone who works with VAEs, I didn\u2019t find the conclusions surprising, but I imagine the paper would be valuable to someone learning about VAEs. Moreover, it\u2019s nice to have a clear reference for the unutilized-latent-space-behavior mentioned in various other VAE papers. The most impressive aspect of the paper is the number of models trained for the empirical investigation. Placing such varied models (CNN vs autoregressive vs VampPrior etc) onto the same plot from comparison (Figure 3) is a valuable contribution. Cons: As mentioned above, I didn\u2019t find the paper conceptually novel, but this isn\u2019t a significant detraction as its value (at least for VAE researchers) is primarily in the experiments (Figure 3). I do think the paper---as the \u2018Discussion and Further Work\u2019 section is only two sentences long---could be improved by providing a better summary of the findings and recommendations moving forward. Should generative modeling papers be reporting final R and D values in addition to marginal likelihood? How should an author demonstrate that their method isn\u2019t doing auto-decoding? The conclusion claims that \u201c[The rate-distortion tradeoff] provides new methods for training VAE-type models which can hopefully advance the state of the art in unsupervised representation learning.\u201d Is this referring to the constrained optimization problem given in Equation #4? It seems to me that the optimal R-vs-D tradeoff is application dependant; is this not always true? Miscellaneous / minor comments: Figure 3 would be easier to read if the dots better reflected their corresponding tuple (although I realize representing all tuple combinations in terms of color, shape, etc is hard). I had to keep referring to the legend, losing my place in the scatter plot. I found sections 1 and 2 rather verbose; I think some text could be cut to make room for more final discussion / recommendations. For example, I think the first two whole paragraphs could be cut or at least condensed and moved to the related works section, as they are just summarizing research history/trends. The paper\u2019s purpose clearly starts at the 3rd paragraph (\u201cWe are interested in understanding\u2026\u201d). The references need cleaned-up. There are several conference publications that are cited via ArXiv instead of the conference (IWAE should be ICLR, Bowman et al. should be CoNLL, Lossy VAE should be ICLR, Stick-Breaking VAE should be ICLR, ADAM should be ICLR, Inv Autoregressive flow should be NIPS, Normalizing Flows should be ICML, etc.), and two different versions of the VAE paper are cited (ArXiv and ICLR). Conclusions I found this paper to present valuable analysis of the ELBO objective and how it relates to representation learning in VAEs. I recommend the paper be accepted, although it could be substantially improved by including more discussion at the end. 1. S. Zhao, J. Song, and S. Ermon. \u201cInfoVAE: Information Maximizing Variational Autoencoders.\u201d ArXiv 2017. 2. X. Chen, D. Kingma, T. Salimans, Y. Duan, P. Dhariwal, J. Shulman, I. Sutskever, and P. Abbeel. \u201cVariational Lossy Autoencoder.\u201d ICLR 2017. 3. I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner. \u201cBeta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.\u201d ICLR 2017 4. S. Bowman, L. Vilnis, O. Vinyas, A. Dai, R. Jozefowicz, and S. Bengio. \u201cGenerating Sentences from a Continuous Space.\u201d CoNLL 2016.", "rating": "7: Good paper, accept", "reply_text": "Thanks to your feedback we have substantially improved our References and Discussion section . > It seems to me that the optimal R-vs-D tradeoff is application dependant ; is this not always true ? We agree , and we have clarified that in the current revision . The optimal R-D tradeoff is application specific . Originally we set out on this work and the information theoretic treatment precisely to try to investigate how current VAEs arrived at their particular rates . When we did our analysis and followed the natural steps to turn it into an easy-to-optimize objective , we discovered that the result was the beta-VAE objective . We feel that giving a principled motivation for why the beta-VAE objective itself is useful and what it can accomplish is novel . By better understanding the origin of the beta-VAE objective , we hopefully open the door to more and better work on theoretically-motivated objective functions in the future ."}, {"review_id": "H1rRWl-Cb-2", "review_text": " - I think that VAEs are rather forced to be interpreted from an information theoretic point of view for the sake of it, rather than for the sake of a clear and unequivocal contribution from the perspective of VAEs and latent-variable models themselves. How is that useful for a VAE? - \"The left vertical line corresponds to the zero rate setting. ...\": All these limits are again from an information theoretic point of view and no formulation nor demonstration is provided on how this can actually be as useful. As mentioned earlier in the paper, there are well-known problems with taking this information theory perspective, e.g. difficulties in estimating MI values, etc. - Breaking (some of) the long sentences and paragraphs in page 3 with an unequivocal mathematical formulation would smooth the flow a bit. - \"(2) an upper bound that measures the rate, or how costly it is to transmit information about the latent variable.\": I am not entirely sure about this one and why it is massively important to be compromised against the obviously big first term. - Toy Model experiment: I do not see any indication of how this is not just a lucky catch and that VAEs consistently suffer from a problem leading to such effect. - Section 5: \"can shed light on many different models and objectives that have been proposed in the literature... \": Again the contribution aspect is not so clear through the word \"shed light\". Minor - Although apparently VAEs represent the main and most influential latent-variable model example, I think switching too much between citing them as VAEs and then as latent-variable models in general was a bit confusing. I propose mentioning in the beginning (as happened) that VAEs are the seminal example of latent-variable models and then going on from this point onwards with VAEs without too much alternation between latent-variable models and VAEs. - page 8: \"as show\"", "rating": "5: Marginally below acceptance threshold", "reply_text": "> I think that VAEs are rather forced to be interpreted from an information theoretic point > of view for the sake of it , rather than for the sake of a clear and unequivocal contribution > from the perspective of VAEs and latent-variable models themselves . How is that useful for a > VAE ? Our analysis explains why VAEs with strong decoders can learn to ignore the learned latent variables . The analysis directly leads to a derivation of the beta-VAE objective , which can force any particular VAE architectural choice to make appropriate use of the latent variables . The value to practitioners using VAEs is to encourage them to use the beta-VAE objective to overcome this shortcoming of standard ELBO optimization . We believe the information theoretic perspective gives a natural motivation for the beta-VAE objective , not just as a simple modification of the objective with observed effect , but demonstrates that it allows you to explore the entire rate-distortion frontier for a particular model family . This is useful and necessary since the relative power of the encoder / decoder and marginal are hard to tune . As observed in the current literature , powerful autoregressive decoders tend to collapse to vanishing rate at beta=1 . > `` The left vertical line corresponds to the zero rate setting . ... '' : All these limits are again from > an information theoretic point of view and no formulation nor demonstration is provided on > how this can actually be as useful . All these limits are again from an information theoretic > point of view and no formulation nor demonstration is provided on how this can actually be > as useful . and > `` ( 2 ) an upper bound that measures the rate , or how costly it is to transmit information about > the latent variable . `` : I am not entirely sure about this one and why it is massively important > to be compromised against the obviously big first term . We hope that the modifications to the paper make these points more clear . We think that our experiments convincingly demonstrate that low rates and high rates give qualitatively different model behavior , as seen in Figures 4 and 6 , and it is exactly the tradeoff between rate and distortion that produces that different behavior , since the models are otherwise held constant . Very low rate models fail at reconstruction , as the information theory predicts . Low rate models manage to capture the semantics of the digits , but ignore the style in reconstruction , and higher rate models provide more precise reconstructions , but fail to provide variation during generation . > Toy Model experiment : I do not see any indication of how this is not just a lucky catch and > that VAEs consistently suffer from a problem leading to such effect . We have added some text indicating that both the VAE and target rate results were stable across all of the random initializations we performed ( many dozens ) . The core point of the toy model was to illustrate that the normal ELBO ( beta=1 VAE ) objective does not target any rate in particular . The rate it ends up at is a complicated function of the relative powers of the component models . For a given problem , we as practitioners usually have some inductive bias for how much information we believe is relevant and should be retained ; by targeting the rate we knew to be relevant in the toy model , we were able to nearly perfectly invert the true generative model . We believe our experiments on both MNIST and Omniglot further demonstrate that for most model architectures , the rates achieved optimizing ELBO with powerful models are often low . > - Section 5 : `` can shed light on many different models and objectives that have been > proposed in the literature ... `` : Again the contribution aspect is not so clear through the word > `` shed light '' . Our discussion section was lacking . We 've expanded it , thank you ."}], "0": {"review_id": "H1rRWl-Cb-0", "review_text": "Summary: This paper optimizes the beta-VAE objective and analyzes the resulting models in terms of the two components of the VAE loss: the reconstruction error (which the authors refer to as distortion, \u201cD\u201d) and the KL divergence term (which the authors refer to as rate, \u201cR\u201d). Various VAEs using either PixelCNN++ or a simpler model for the encoder, decoder, or marginal distribution of a VAE are trained on MNIST (with some additional results on OMNIGLOT) and analyzed in terms of samples, reconstructions, and their rate-distortion trade-off. Review: I find it difficult to point my finger to novel conceptual or theoretical insights in this paper. The idea of maximizing information for unsupervised learning of representations has of course been explored a lot (e.g., Bell & Sejnowski, 1995). Deeper connections between variational inference and rate-distortion have been made before (e.g., Balle et al., 2017; Theis et al., 2017), while this paper merely seems to rename the reconstruction and KL terms of the ELBO. Variational lower and upper bounds on mutual information have been used before as well (e.g., Barber & Agakov, 2003; Alemi et al., 2017), although they are introduced like new results in this paper. The derived \u201csandwich equation\u201d only seems to be used to show that H - D - R <= 0, which also follows directly from Gibbs\u2019 inequality (since the left-hand side is a negative KL divergence). The main contributions therefore seem to be the proposed analysis of models in the R-D plane, and the empirical contribution of analyzing beta-VAEs. Based on the R-D plots, the authors identify a potential problem of generative models, namely that none of the trained models appear to get close to the \u201cauto-encoding limit\u201d where the distortion is close zero. Wouldn\u2019t this gap easily be closed by a model with identity encoder, identity decoder, and PixelCNN++ for the marginal distribution? Given that autoregressive models generally perform better than VAEs in terms of log-likelihood, the model\u2019s performance would probably be closer to the true entropy than the ELBO plotted in Figure 3a). What about increasing the capacity of the used in this paper? This makes me wonder what exactly the R-D plot can teach us about building better generative models. The toy example in Figure 2 is interesting. What does it tell us about how to build our generative models? Should we be using powerful decoders but a lower beta? The authors write: \u201cwe are able to learn many models that can achieve similar generative performance but make vastly different trade-offs in terms of the usage of the latent variable\u201d. Yet in Figure 3b) it appears that changing the rate of a model can influence the generative performance (ELBO) quite a bit?", "rating": "5: Marginally below acceptance threshold", "reply_text": "Based on your feedback , we have taken more care to clarify that the core variational bounds we present at the beginning of Section 2 and in some of the appendices were originally derived in Barber and Agakov 2003 , Agakov 2006 , and Alemi et al.2017.We have kept the proofs in the appendix for clarity . We view the core contributions of our work as ( 1 ) providing a clear theoretical justification for the beta-VAE objective , and ( 2 ) demonstrating that the beta-VAE objective can be used to target a task-specific target rate independent of architecture . This alleviates a known problem with the ELBO objective : achieving different rates requires modifying the architecture and is difficult to control . We have attempted to make those points more clearly in the current version of the paper . Understanding the origin of the beta-VAE objective opens the door to other approaches for training VAEs . The updated conclusion presents some of these approaches , such as constrained optimization on the variational bounds of rate and distortion , and using more powerful mutual information predictors . Finally , analyzing the performance of VAE models in terms of the RD plane can make problems with models immediately clear ( for example , poor distortion at high rates or poor use of latent variables with complex decoders ) . We also hope that we 've clearly established some connections between information theory , latent variable models , rate-distortion theory , and compression , which could spawn new results . > Based on the R-D plots , the authors identify a potential problem of generative models , > namely that none of the trained models appear to get close to the \u201c auto-encoding limit \u201d > where the distortion is close zero . Wouldn \u2019 t this gap easily be closed by a model with identity > encoder , identity decoder , and PixelCNN++ for the marginal distribution ? We agree that models with more powerful PixelCNN++ type marginals could help to close the gap in ELBO for models at high rates . The recent VQ-VAE work shows this qualitatively , and future work should more extensively explore these models to identify their frontier in the RD plane . > The toy example in Figure 2 is interesting . What does it tell us about how to build our > generative models ? Should we be using powerful decoders but a lower beta ? The toy example shows that the most powerful models ( in this case , models that are able to perfectly represent all relevant distributions ) will perform very poorly when trained using ELBO , but constraining the optimization to some rate , either using something like a beta-VAE with beta < 1 , or explicitly targeting a known rate , can result in using the model capacity optimally . As seen on MNIST and Omniglot , it seems that the best models we currently have use powerful decoders and powerful marginals , but it is necessary to use beta < 1 to avoid rate collapse . > \u201c we are able to learn many models that can achieve similar generative performance but > make vastly different trade-offs in terms of the usage of the latent variable \u201d . We meant to speak more directly to the performance over intermediate rate values , from 0 to around 10 nats on MNIST . In terms of ELBO these models are all the same , but as demonstrated in Figure 4 , over these rates we move from an unconditional generative model to an effective compression model for MNIST that seems to preserve the salient features of the input . As we describe elsewhere in the paper , the high-rate models we explored can not attain equivalently good marginal log likelihood ."}, "1": {"review_id": "H1rRWl-Cb-1", "review_text": "EDIT: I have reviewed the authors revisions and still recommend acceptance. Summary This paper proposes assessing VAEs via two quantities: rate R (E[ KLD[q(z|x) || p(z)] ]) and distortion D (E[ log p(x|z) ]), which can be used to bound the mutual information (MI) I(x,z) from above and below respectively (i.e. H[x] - D <= I(x,z) <= R). This fact then implies the inequality H[x] <= R + D, where H[x] is the entropy of the true data distribution, and allows for the construction of a phase diagram (Figure 1) with R and D on the x and y axis respectively. Models can be plotted on the diagram to show the degree to which they favor reconstruction (D) or sampling diversity (R). The paper then reports several experiments, the first being a simulation to show that a VAE trained with vanilla ELBO cannot recover the true rate in even a 1D example. For the second experiment, 12 models are trained by varying the encoder/decoder strength (CNN vs autoregressive) and prior (fact. Gauss vs autoregressive vs VampPrior). Plots of the D vs R and ELBO vs R are shown for the models, revealing that the same ELBO value can be decomposed into drastically different R and D values. The point is further made through qualitative results in Figure 4. Evaluation Pros: While no one facet of the paper is particularly novel (as similar observations and discussion has been made by [1-4]), the paper, as far as I\u2019m aware, is the first to formally decompose the ELBO into the R vs D tradeoff, which is natural. As someone who works with VAEs, I didn\u2019t find the conclusions surprising, but I imagine the paper would be valuable to someone learning about VAEs. Moreover, it\u2019s nice to have a clear reference for the unutilized-latent-space-behavior mentioned in various other VAE papers. The most impressive aspect of the paper is the number of models trained for the empirical investigation. Placing such varied models (CNN vs autoregressive vs VampPrior etc) onto the same plot from comparison (Figure 3) is a valuable contribution. Cons: As mentioned above, I didn\u2019t find the paper conceptually novel, but this isn\u2019t a significant detraction as its value (at least for VAE researchers) is primarily in the experiments (Figure 3). I do think the paper---as the \u2018Discussion and Further Work\u2019 section is only two sentences long---could be improved by providing a better summary of the findings and recommendations moving forward. Should generative modeling papers be reporting final R and D values in addition to marginal likelihood? How should an author demonstrate that their method isn\u2019t doing auto-decoding? The conclusion claims that \u201c[The rate-distortion tradeoff] provides new methods for training VAE-type models which can hopefully advance the state of the art in unsupervised representation learning.\u201d Is this referring to the constrained optimization problem given in Equation #4? It seems to me that the optimal R-vs-D tradeoff is application dependant; is this not always true? Miscellaneous / minor comments: Figure 3 would be easier to read if the dots better reflected their corresponding tuple (although I realize representing all tuple combinations in terms of color, shape, etc is hard). I had to keep referring to the legend, losing my place in the scatter plot. I found sections 1 and 2 rather verbose; I think some text could be cut to make room for more final discussion / recommendations. For example, I think the first two whole paragraphs could be cut or at least condensed and moved to the related works section, as they are just summarizing research history/trends. The paper\u2019s purpose clearly starts at the 3rd paragraph (\u201cWe are interested in understanding\u2026\u201d). The references need cleaned-up. There are several conference publications that are cited via ArXiv instead of the conference (IWAE should be ICLR, Bowman et al. should be CoNLL, Lossy VAE should be ICLR, Stick-Breaking VAE should be ICLR, ADAM should be ICLR, Inv Autoregressive flow should be NIPS, Normalizing Flows should be ICML, etc.), and two different versions of the VAE paper are cited (ArXiv and ICLR). Conclusions I found this paper to present valuable analysis of the ELBO objective and how it relates to representation learning in VAEs. I recommend the paper be accepted, although it could be substantially improved by including more discussion at the end. 1. S. Zhao, J. Song, and S. Ermon. \u201cInfoVAE: Information Maximizing Variational Autoencoders.\u201d ArXiv 2017. 2. X. Chen, D. Kingma, T. Salimans, Y. Duan, P. Dhariwal, J. Shulman, I. Sutskever, and P. Abbeel. \u201cVariational Lossy Autoencoder.\u201d ICLR 2017. 3. I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner. \u201cBeta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.\u201d ICLR 2017 4. S. Bowman, L. Vilnis, O. Vinyas, A. Dai, R. Jozefowicz, and S. Bengio. \u201cGenerating Sentences from a Continuous Space.\u201d CoNLL 2016.", "rating": "7: Good paper, accept", "reply_text": "Thanks to your feedback we have substantially improved our References and Discussion section . > It seems to me that the optimal R-vs-D tradeoff is application dependant ; is this not always true ? We agree , and we have clarified that in the current revision . The optimal R-D tradeoff is application specific . Originally we set out on this work and the information theoretic treatment precisely to try to investigate how current VAEs arrived at their particular rates . When we did our analysis and followed the natural steps to turn it into an easy-to-optimize objective , we discovered that the result was the beta-VAE objective . We feel that giving a principled motivation for why the beta-VAE objective itself is useful and what it can accomplish is novel . By better understanding the origin of the beta-VAE objective , we hopefully open the door to more and better work on theoretically-motivated objective functions in the future ."}, "2": {"review_id": "H1rRWl-Cb-2", "review_text": " - I think that VAEs are rather forced to be interpreted from an information theoretic point of view for the sake of it, rather than for the sake of a clear and unequivocal contribution from the perspective of VAEs and latent-variable models themselves. How is that useful for a VAE? - \"The left vertical line corresponds to the zero rate setting. ...\": All these limits are again from an information theoretic point of view and no formulation nor demonstration is provided on how this can actually be as useful. As mentioned earlier in the paper, there are well-known problems with taking this information theory perspective, e.g. difficulties in estimating MI values, etc. - Breaking (some of) the long sentences and paragraphs in page 3 with an unequivocal mathematical formulation would smooth the flow a bit. - \"(2) an upper bound that measures the rate, or how costly it is to transmit information about the latent variable.\": I am not entirely sure about this one and why it is massively important to be compromised against the obviously big first term. - Toy Model experiment: I do not see any indication of how this is not just a lucky catch and that VAEs consistently suffer from a problem leading to such effect. - Section 5: \"can shed light on many different models and objectives that have been proposed in the literature... \": Again the contribution aspect is not so clear through the word \"shed light\". Minor - Although apparently VAEs represent the main and most influential latent-variable model example, I think switching too much between citing them as VAEs and then as latent-variable models in general was a bit confusing. I propose mentioning in the beginning (as happened) that VAEs are the seminal example of latent-variable models and then going on from this point onwards with VAEs without too much alternation between latent-variable models and VAEs. - page 8: \"as show\"", "rating": "5: Marginally below acceptance threshold", "reply_text": "> I think that VAEs are rather forced to be interpreted from an information theoretic point > of view for the sake of it , rather than for the sake of a clear and unequivocal contribution > from the perspective of VAEs and latent-variable models themselves . How is that useful for a > VAE ? Our analysis explains why VAEs with strong decoders can learn to ignore the learned latent variables . The analysis directly leads to a derivation of the beta-VAE objective , which can force any particular VAE architectural choice to make appropriate use of the latent variables . The value to practitioners using VAEs is to encourage them to use the beta-VAE objective to overcome this shortcoming of standard ELBO optimization . We believe the information theoretic perspective gives a natural motivation for the beta-VAE objective , not just as a simple modification of the objective with observed effect , but demonstrates that it allows you to explore the entire rate-distortion frontier for a particular model family . This is useful and necessary since the relative power of the encoder / decoder and marginal are hard to tune . As observed in the current literature , powerful autoregressive decoders tend to collapse to vanishing rate at beta=1 . > `` The left vertical line corresponds to the zero rate setting . ... '' : All these limits are again from > an information theoretic point of view and no formulation nor demonstration is provided on > how this can actually be as useful . All these limits are again from an information theoretic > point of view and no formulation nor demonstration is provided on how this can actually be > as useful . and > `` ( 2 ) an upper bound that measures the rate , or how costly it is to transmit information about > the latent variable . `` : I am not entirely sure about this one and why it is massively important > to be compromised against the obviously big first term . We hope that the modifications to the paper make these points more clear . We think that our experiments convincingly demonstrate that low rates and high rates give qualitatively different model behavior , as seen in Figures 4 and 6 , and it is exactly the tradeoff between rate and distortion that produces that different behavior , since the models are otherwise held constant . Very low rate models fail at reconstruction , as the information theory predicts . Low rate models manage to capture the semantics of the digits , but ignore the style in reconstruction , and higher rate models provide more precise reconstructions , but fail to provide variation during generation . > Toy Model experiment : I do not see any indication of how this is not just a lucky catch and > that VAEs consistently suffer from a problem leading to such effect . We have added some text indicating that both the VAE and target rate results were stable across all of the random initializations we performed ( many dozens ) . The core point of the toy model was to illustrate that the normal ELBO ( beta=1 VAE ) objective does not target any rate in particular . The rate it ends up at is a complicated function of the relative powers of the component models . For a given problem , we as practitioners usually have some inductive bias for how much information we believe is relevant and should be retained ; by targeting the rate we knew to be relevant in the toy model , we were able to nearly perfectly invert the true generative model . We believe our experiments on both MNIST and Omniglot further demonstrate that for most model architectures , the rates achieved optimizing ELBO with powerful models are often low . > - Section 5 : `` can shed light on many different models and objectives that have been > proposed in the literature ... `` : Again the contribution aspect is not so clear through the word > `` shed light '' . Our discussion section was lacking . We 've expanded it , thank you ."}}