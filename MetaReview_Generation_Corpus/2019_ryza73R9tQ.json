{"year": "2019", "forum": "ryza73R9tQ", "title": "Machine Translation With Weakly Paired Bilingual Documents", "decision": "Reject", "meta_review": "This paper proposes a new method to mine sentence from Wikipedia and use them to train an MT system, and also a topic-based loss function. In particular, the first contribution, which is the main aspect of the proposal is effective, outperforming methods for fully unsupervised learning.\n\nThe main concern with the proposed method, or at least it's description in the paper, is that it isn't framed appropriately with respect to previous work on mining parallel sentences from comparable corpora such as Wikipedia. Based on interaction in the reviews, I feel that things are now framed a bit better, and there are additional baselines, but still the explanation in the paper isn't framed with respect to this previous work, and also the baselines are not competitive, despite previous work reporting very nice results for these previous methods.\n\nI feel like this could be a very nice paper at some point if it's re-written with the appropriate references to previous work, and experimental results where the baselines are done appropriately. Thus at this time I'm not recommending that the paper be accepted, but encourage the authors to re-submit a revised version in the future.", "reviews": [{"review_id": "ryza73R9tQ-0", "review_text": "Summary The authors propose a relatively simple approach to mine noisy parallel sentences which are useful to greatly improve performance of purely unsupervised MT algorithms. The method consists of a) mining documents that refer to the same topic, b) extracting from these documents parallel sentences, c) training the usual unsup MT pipeline with two additional losses, one that encourages good translation of the extracted parallel sentences and another one forcing the distribution of words to match at the document level. Novelty: the approach is novel. Clarity: the paper is clearly written. Empirical validation: The empirical validation is solid but limited. The authors could further strengthen it by testing on low-resource language pairs (En-Ro, En-Ur). It would also be useful to report more stats about the retrieved sentences in tab. 1 (average length compared to ground truth, BLEU using as reference the translation of a SoA supervised MT method, etc.) Questions 1) Sec. 3.2 is the least clear of the paper. The notation of eq. 7 is quite unclear because of the overloading (e.g., P refers to both the model and the empirical distribution). I am also unclear about this constraint about matching the topic distribution: as far as I understood, the model gets only one gradient signal for the whole document. I find then surprising that the authors managed to get any significant improvement by adding this term. Related to this term, how is it computed? Are documents translated on the fly as training proceeds? Could the authors provide more details? 2) Have the authors considered matching sentences to any other sentence in the monolingual corpus as opposed to sentences in the comparable document? ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your reviews and comments ! 1.Regarding the empirical validation Thanks for the suggestions ! We are conducting more experiments to low-resource language pairs . However , we want to make it clear that in machine translation , the low-resource tasks are usually referred to as learning a translation model with a small set of ( or no ) supervised bilingual sentence pairs [ 1,2,3 ] . From this perspective , the task , method , and experiment ( En-De , De-En , En-Es , Es-En ) in our paper are focused on low-resource problems indeed , as we use no human-labeled bilingual sentence pairs but only use document-level information or automatically mined related sentence pairs ( maybe not exact or perfect translations ) . Our method shows that given no bilingual translation pairs but weakly paired documents ( from Wiki , news websites or books ) , we can learn a translation model which is much better than the state-of-the-art unsupervised translation methods . As you suggested , we are currently working on the En-Ro and En-Tr language pairs , but since the document aligning process is costly , we are afraid that we may not give a result by the end of the rebuttal phase . We will report the number once the experiments are finished . 2.On the quality of retrieved sentences Actually , we have no * ground truth * for the retrieved sentence pairs , so we just use a well-trained translation model from huge bilingual data and check whether the retrieved sentences are * similar * to the translated sentences in terms of BLEU score in the below table . En-De ( c1=0.7 ) De-En ( c1=0.7 ) C2=0.0 26.86 28.33 C2=0.1 30.68 32.10 C2=0.2 33.40 34.38 As we expected , the sentence pairs we mined with more strict thresholds are more * similar * to the supervised model outputs . Besides , the reasonable BLEU scores show that the sentence pairs we extracted will be good to use in NMT model training . 3.Regarding the notion of P Sorry to make you feel confused . P is generally used as a notation of * * probability * * , but not for any specific parametric function . For example , in Eqn . 7 , the first item P ( w^Y ; d^Y_i ) refers to the empirical distribution of word w in language Y , and the second item P ( w^Y ; d^X_i , \\theta ) refers to the distribution of word w translated from document X_i with parameter \\theta . We will modify the related equations to make them clearer . 4.Regarding the topic distribution implementation Your understanding is correct . In our experiments , during training , we generate the translated documents online to compute the topic distribution loss over document pairs , and the gradient signal is computed over a mini batch of document pairs . 5.Regarding sentence pairs in pure monolingual data Yes . In fact , we have tried this before the submission as it is a natural way to generalize our method to wider settings . We have tried to select sentence pairs over 50M monolingual WMT En-De dataset . According to our manual check , the quality of the sentence pairs we mined from the original monolingual dataset is not good . That \u2019 s why we mine the sentences from the weakly paired documents in our work . [ 1 ] Universal Neural Machine Translation for Extremely Low Resource Languages\uff0c Jiatao Gu\u2020\u2217 Hany Hassan\u2021 Jacob Devlin\u2217 Victor O.K . Li\u2020NAACL 2018 [ 2 ] Neural Machine Translation for Low Resource Languages using Bilingual Lexicon Induced from Comparable Corpora , Sree Harsha Ramesh and Krishna Prasad Sankaranarayanan , NAACL , workshop 2018 [ 3 ] Neural machine translation for low-resource languages , Robert Ostling \u00a8 and Jorg Tiedemann . 2017 ."}, {"review_id": "ryza73R9tQ-1", "review_text": "This paper proposes a method to train a machine translation system using weakly paired bilingual documents from Wikipedia. A pair of sentences from a weak document pair are used as training data if their cosine similarity exceeds c1, and the similarity between this sentence pair is c2 greater than any other pair in the documents, under sentence representations formed from word embeddings trained with MUSE. The neural translation model learns to translate from language X to Y, and from Y to X using the same encoder and decoder parameters, but the decoder is aware of the intended target language given an embedding of the intended language. The model is also trained to minimise the KL divergence between the distribution of terms in the target language document and the distribution of terms in the current model output. The model also uses the denoising autoencoding and reconstruction objectives of Lample et al. (2017). The results show improvements over the Lample et al. (2017) and that performance is heavily dependent on the number of sentences extracted from the weakly aligned documents. Positives - Large improvement over previous attempts at unsupervised MT for the En-De language pair. - Informative ablation study in Section 4.4 of the relative contribution of each part of the overall objective function (Eq 9). Negatives - The introduction gave the impression that this method would be applied to low-resource language pairs but it was applied to two high-resource language pairs. Because you have not evaluated on a low-resource language pair, it's not clear how your proposed method would generalise to a low-resource setting. Questions - Can you give some intuition for why you remove the first principal component from the word embeddings in Equations 1 - 3? - Are the Supervised results in Table 2 actually a fair reflection of a reasonable NMT model trained with sub-word representations and back translated data? - What is the total number of sentences in the weakly paired documents in Table 1? It would be useful to know the proportion of sentences you managed to extract to train your models. Comments - Koehn et al. (2003) is not an example of any kind of neural network architecture.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 1 for the reviews and comments ! Here are our responses to the concerns . 1.Regarding low-resource tasks We want to make it clear that in machine translation , the low-resource tasks are usually referred to as learning a translation model with a small set of ( or no ) supervised bilingual sentence pairs [ 1,2,3 ] . From this perspective , the task , method , and experiment ( En-De , De-En , En-Es , Es-En ) in our paper are focused on low-resource problems indeed , as we use no human-labeled bilingual sentence pairs but just use document-level information or automatically mined related sentence pairs ( which may be not exact or perfect translations ) . Our method shows that given no bilingual translation pairs but weakly paired documents ( e.g. , from Wiki ) , we can learn a translation model which is much better than the state-of-the-art unsupervised translation methods . 2.Regarding why to remove the first principal component of the embedding We follow the unsupervised sentence representation approach from [ 4,5 ] to remove the first principal component of sentence embedding but not word embedding , as mentioned in 4th paragraph of Section 3.1 . Intuitively , from empirical observations , the embeddings of many sentences share a large * * common vector * * . Removing the first principal component from the sentence embeddings make them more diverse and expressive in the embedding space , and thus the resulted embeddings are shown to be more effective [ 4,5 ] . 3.Regarding the supervised baseline All the supervised models are trained on the widely acknowledged WMT bilingual dataset using Transformer [ 6 ] , which is considered to be a standard baseline model of NMT tasks [ 7 ] . For our learned models and the baseline models , we do follow the common practice and use sub-word tokens ( Byte Pair Encoding ( BPE ) approach ) as in [ 6 ] . We have mentioned this in 2nd paragraph of Section 4.2 . 4.Regarding data statistics For the number of sentences in the weakly paired documents , there are 4,285,607 English sentences and 4,266,178 German sentences in English-German language pair , 2,679,278 English sentences and 2,547,358 Spanish sentences in English-Spanish language pair . Therefore , we extract a reasonable proportion of sentences from the weakly paired documents to train the model . [ 1 ] Universal Neural Machine Translation for Extremely Low Resource Languages\uff0c Jiatao Gu\u2020\u2217 Hany Hassan\u2021 Jacob Devlin\u2217 Victor O.K . Li\u2020NAACL 2018 [ 2 ] Neural Machine Translation for Low Resource Languages using Bilingual Lexicon Induced from Comparable Corpora , Sree Harsha Ramesh and Krishna Prasad Sankaranarayanan , NAACL , workshop 2018 [ 3 ] Neural machine translation for low-resource languages , Robert Ostling \u00a8 and Jorg Tiedemann , 2017 . [ 4 ] Arora , Sanjeev , Yingyu Liang , and Tengyu Ma . `` A simple but tough-to-beat baseline for sentence embeddings . '' ICLR-2017 . [ 5 ] Mu , Jiaqi , Suma Bhat , and Pramod Viswanath . `` All-but-the-top : Simple and effective postprocessing for word representations . '' ICLR-2018 . [ 6 ] Vaswani , Ashish , et al . `` Attention is all you need . '' NIPS-2017 . [ 7 ] Phrase-Based & Neural Unsupervised Machine Translation . EMNLP-2018 ."}, {"review_id": "ryza73R9tQ-2", "review_text": "The major issue in this paper is that the \"new direction\" in this paper has been explored before [1]. Therefore the introduction needs to be rewritten with arguing the difference between existing methods. The proposed method highly relies on the percentage of implicitly aligned data. I suggest the author do more experiments on different data set with a significant difference in this \"percentage\". Otherwise, we have no idea about the performance's sensitivity to the different datasets. More detailed explanations are needed. For example, what do you mean by \"p(w) as the estimated frequency\"? Why do we need to remove the first principal components? Section 3.2 title is \" aligning topic distribution\" but actually it is doing word distribution alignment. Do you do normalization for P(w^Y;d_i^X,\\theta) in eq.6 which is defined on the entire vocab's distribution? I think the measurement of the alignment accuracy and more experiments with different settings of \\alpha and \\beta are needed. Citation needed for \"Second, many previous works suggest that the word distribution ...\" [1] Munteanu et al, \"Improving Machine Translation Performance by Exploiting Non-Parallel Corpora\", 2006", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank Reviewer 3 for the reviews and comments ! Here are our responses to the concerns . 1.Regarding the related work Thanks for the reference . We are indeed aware of the related work on selecting sentence pairs from monolingual corpora . We did try some methods and found them do not work well as the scenario of related works is far different from ours . The methods in [ 1-4 ] rely on bilingual sentences to train a model and use this model to select sentence pairs . For example , [ 1-2 ] use an MT system to obtain a rough translation of a given page in one language into another and then uses word overlap or BLEU score between sentences as measures . [ 3-4 ] develop a ranking model/binary classifier to learn how likely a sentence in the target language is the translation of a sentence in the source language using parallel corpora . However , in our setting , we don \u2019 t have any bilingual sentences pair available . That is being said , we have no bilingual sentence pairs to train such a model to further select new data pairs . In order to work similarly to the previous works in the unsupervised setting , the most related model for selecting pairs is the unsupervised machine translation model . We did try to use an unsupervised translation model for sentence pair selection at the very early stage of the work . We first trained an unsupervised model followed [ 7 ] and then use the model outputs to evaluate each sentence pairs between two linked documents . We have conducted the following experiments : ( a ) . Similarly to [ 1,2 ] , for each sentence x , we generate the translation results using the unsupervised NMT model , select the most similar sentence to the translation results ( in terms of BLEU ) , and use such data pairs for NMT training . ( b ) .To build up a scoring function as used in [ 3-4 ] , we use the model-output probability as the scoring function . We select sentence pair ( x , y ) with larger translation probabilities p ( y|x ) and use such data pairs for NMT training . As the * * unsupervised translation model * * is not good enough , the selected sentence pairs are not reasonable as shown in the below table . We hypothesize this is due to that as some sentences in one Wiki pages are similar ( e.g. , a few words differ from each other ) , then 1. the BLEU ( or sentence-level BLEU ) score is very sensitive to evaluate such sentences . 2. the likelihood on similar sentences are not that trustable . Furthermore , we found training an NMT model using such poor data does not work well . On WMT De-En task , we have the following results : The BLEU score of model trained in ( a ) can only reach 22.4 . The best model trained in ( b ) can achieve only 19.8 in terms of BLEU score . Both show that the trained NMT models are not good as expected . As a summary , we find by leveraging the recent techniques ( the cross-lingual word embedding + unsupervised sentence representation ) , the selected sentences are much better . We believe our findings are important to the field of unsupervised learning and unsupervised machine translation . We will include those discussions in our paper and clarify the differences between our work and previous works . English || Selected German sentence by unsupervised translation model || Selected German sentence by our method She was one of the pioneers of Greek surrealism . || Inzwischen ist sie Mitglied der Kommunistischen Partei geworden . || Zun\u00e4chst z\u00e4hlt sie zu den Pionieren des griechischen Surrealismus . The film premiered at the 2014 Zurich Film Festival . || In Deutschland startete der Film am 10 . September 2015 . || Er hatte seine Premiere am 26 . September 2014 beim Zurich Film Festival . The eastern part is leafy and park-like . || Au\u00dferdem befindet sich hier ein Kinderspielplatz . || Der \u00f6stliche Teil ist begr\u00fcnt und park\u00e4hnlich gestaltet . Most of the remaining convicts were then relocated to Port Arthur . || Insgesamt wurden in der Strafkolonie 1200 H\u00e4ftlinge verwahrt . || Die verbliebenen H\u00e4ftlinge wurden schrittweise ins Lager nach Port Arthur verlegt . 2.Regarding more experiments on the different percentage of data pairs We are afraid that you might miss some parts of our paper . We have tested the performance with different percentage of implicitly aligned data according to the different choices of the thresholds to understand the sensitivity of the data size in Section 4.4 . As we can see from Section 4.4 , by setting different thresholds , we select data pairs from 60k to 250k . We think these results answer the question you mentioned . The different sizes of data indeed have impacts to the model performance , but all experimental results show that our model is better than the baselines ( i.e. , comparing the numbers in Figure 1 and the baselines in Table 2 ) ."}], "0": {"review_id": "ryza73R9tQ-0", "review_text": "Summary The authors propose a relatively simple approach to mine noisy parallel sentences which are useful to greatly improve performance of purely unsupervised MT algorithms. The method consists of a) mining documents that refer to the same topic, b) extracting from these documents parallel sentences, c) training the usual unsup MT pipeline with two additional losses, one that encourages good translation of the extracted parallel sentences and another one forcing the distribution of words to match at the document level. Novelty: the approach is novel. Clarity: the paper is clearly written. Empirical validation: The empirical validation is solid but limited. The authors could further strengthen it by testing on low-resource language pairs (En-Ro, En-Ur). It would also be useful to report more stats about the retrieved sentences in tab. 1 (average length compared to ground truth, BLEU using as reference the translation of a SoA supervised MT method, etc.) Questions 1) Sec. 3.2 is the least clear of the paper. The notation of eq. 7 is quite unclear because of the overloading (e.g., P refers to both the model and the empirical distribution). I am also unclear about this constraint about matching the topic distribution: as far as I understood, the model gets only one gradient signal for the whole document. I find then surprising that the authors managed to get any significant improvement by adding this term. Related to this term, how is it computed? Are documents translated on the fly as training proceeds? Could the authors provide more details? 2) Have the authors considered matching sentences to any other sentence in the monolingual corpus as opposed to sentences in the comparable document? ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your reviews and comments ! 1.Regarding the empirical validation Thanks for the suggestions ! We are conducting more experiments to low-resource language pairs . However , we want to make it clear that in machine translation , the low-resource tasks are usually referred to as learning a translation model with a small set of ( or no ) supervised bilingual sentence pairs [ 1,2,3 ] . From this perspective , the task , method , and experiment ( En-De , De-En , En-Es , Es-En ) in our paper are focused on low-resource problems indeed , as we use no human-labeled bilingual sentence pairs but only use document-level information or automatically mined related sentence pairs ( maybe not exact or perfect translations ) . Our method shows that given no bilingual translation pairs but weakly paired documents ( from Wiki , news websites or books ) , we can learn a translation model which is much better than the state-of-the-art unsupervised translation methods . As you suggested , we are currently working on the En-Ro and En-Tr language pairs , but since the document aligning process is costly , we are afraid that we may not give a result by the end of the rebuttal phase . We will report the number once the experiments are finished . 2.On the quality of retrieved sentences Actually , we have no * ground truth * for the retrieved sentence pairs , so we just use a well-trained translation model from huge bilingual data and check whether the retrieved sentences are * similar * to the translated sentences in terms of BLEU score in the below table . En-De ( c1=0.7 ) De-En ( c1=0.7 ) C2=0.0 26.86 28.33 C2=0.1 30.68 32.10 C2=0.2 33.40 34.38 As we expected , the sentence pairs we mined with more strict thresholds are more * similar * to the supervised model outputs . Besides , the reasonable BLEU scores show that the sentence pairs we extracted will be good to use in NMT model training . 3.Regarding the notion of P Sorry to make you feel confused . P is generally used as a notation of * * probability * * , but not for any specific parametric function . For example , in Eqn . 7 , the first item P ( w^Y ; d^Y_i ) refers to the empirical distribution of word w in language Y , and the second item P ( w^Y ; d^X_i , \\theta ) refers to the distribution of word w translated from document X_i with parameter \\theta . We will modify the related equations to make them clearer . 4.Regarding the topic distribution implementation Your understanding is correct . In our experiments , during training , we generate the translated documents online to compute the topic distribution loss over document pairs , and the gradient signal is computed over a mini batch of document pairs . 5.Regarding sentence pairs in pure monolingual data Yes . In fact , we have tried this before the submission as it is a natural way to generalize our method to wider settings . We have tried to select sentence pairs over 50M monolingual WMT En-De dataset . According to our manual check , the quality of the sentence pairs we mined from the original monolingual dataset is not good . That \u2019 s why we mine the sentences from the weakly paired documents in our work . [ 1 ] Universal Neural Machine Translation for Extremely Low Resource Languages\uff0c Jiatao Gu\u2020\u2217 Hany Hassan\u2021 Jacob Devlin\u2217 Victor O.K . Li\u2020NAACL 2018 [ 2 ] Neural Machine Translation for Low Resource Languages using Bilingual Lexicon Induced from Comparable Corpora , Sree Harsha Ramesh and Krishna Prasad Sankaranarayanan , NAACL , workshop 2018 [ 3 ] Neural machine translation for low-resource languages , Robert Ostling \u00a8 and Jorg Tiedemann . 2017 ."}, "1": {"review_id": "ryza73R9tQ-1", "review_text": "This paper proposes a method to train a machine translation system using weakly paired bilingual documents from Wikipedia. A pair of sentences from a weak document pair are used as training data if their cosine similarity exceeds c1, and the similarity between this sentence pair is c2 greater than any other pair in the documents, under sentence representations formed from word embeddings trained with MUSE. The neural translation model learns to translate from language X to Y, and from Y to X using the same encoder and decoder parameters, but the decoder is aware of the intended target language given an embedding of the intended language. The model is also trained to minimise the KL divergence between the distribution of terms in the target language document and the distribution of terms in the current model output. The model also uses the denoising autoencoding and reconstruction objectives of Lample et al. (2017). The results show improvements over the Lample et al. (2017) and that performance is heavily dependent on the number of sentences extracted from the weakly aligned documents. Positives - Large improvement over previous attempts at unsupervised MT for the En-De language pair. - Informative ablation study in Section 4.4 of the relative contribution of each part of the overall objective function (Eq 9). Negatives - The introduction gave the impression that this method would be applied to low-resource language pairs but it was applied to two high-resource language pairs. Because you have not evaluated on a low-resource language pair, it's not clear how your proposed method would generalise to a low-resource setting. Questions - Can you give some intuition for why you remove the first principal component from the word embeddings in Equations 1 - 3? - Are the Supervised results in Table 2 actually a fair reflection of a reasonable NMT model trained with sub-word representations and back translated data? - What is the total number of sentences in the weakly paired documents in Table 1? It would be useful to know the proportion of sentences you managed to extract to train your models. Comments - Koehn et al. (2003) is not an example of any kind of neural network architecture.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank Reviewer 1 for the reviews and comments ! Here are our responses to the concerns . 1.Regarding low-resource tasks We want to make it clear that in machine translation , the low-resource tasks are usually referred to as learning a translation model with a small set of ( or no ) supervised bilingual sentence pairs [ 1,2,3 ] . From this perspective , the task , method , and experiment ( En-De , De-En , En-Es , Es-En ) in our paper are focused on low-resource problems indeed , as we use no human-labeled bilingual sentence pairs but just use document-level information or automatically mined related sentence pairs ( which may be not exact or perfect translations ) . Our method shows that given no bilingual translation pairs but weakly paired documents ( e.g. , from Wiki ) , we can learn a translation model which is much better than the state-of-the-art unsupervised translation methods . 2.Regarding why to remove the first principal component of the embedding We follow the unsupervised sentence representation approach from [ 4,5 ] to remove the first principal component of sentence embedding but not word embedding , as mentioned in 4th paragraph of Section 3.1 . Intuitively , from empirical observations , the embeddings of many sentences share a large * * common vector * * . Removing the first principal component from the sentence embeddings make them more diverse and expressive in the embedding space , and thus the resulted embeddings are shown to be more effective [ 4,5 ] . 3.Regarding the supervised baseline All the supervised models are trained on the widely acknowledged WMT bilingual dataset using Transformer [ 6 ] , which is considered to be a standard baseline model of NMT tasks [ 7 ] . For our learned models and the baseline models , we do follow the common practice and use sub-word tokens ( Byte Pair Encoding ( BPE ) approach ) as in [ 6 ] . We have mentioned this in 2nd paragraph of Section 4.2 . 4.Regarding data statistics For the number of sentences in the weakly paired documents , there are 4,285,607 English sentences and 4,266,178 German sentences in English-German language pair , 2,679,278 English sentences and 2,547,358 Spanish sentences in English-Spanish language pair . Therefore , we extract a reasonable proportion of sentences from the weakly paired documents to train the model . [ 1 ] Universal Neural Machine Translation for Extremely Low Resource Languages\uff0c Jiatao Gu\u2020\u2217 Hany Hassan\u2021 Jacob Devlin\u2217 Victor O.K . Li\u2020NAACL 2018 [ 2 ] Neural Machine Translation for Low Resource Languages using Bilingual Lexicon Induced from Comparable Corpora , Sree Harsha Ramesh and Krishna Prasad Sankaranarayanan , NAACL , workshop 2018 [ 3 ] Neural machine translation for low-resource languages , Robert Ostling \u00a8 and Jorg Tiedemann , 2017 . [ 4 ] Arora , Sanjeev , Yingyu Liang , and Tengyu Ma . `` A simple but tough-to-beat baseline for sentence embeddings . '' ICLR-2017 . [ 5 ] Mu , Jiaqi , Suma Bhat , and Pramod Viswanath . `` All-but-the-top : Simple and effective postprocessing for word representations . '' ICLR-2018 . [ 6 ] Vaswani , Ashish , et al . `` Attention is all you need . '' NIPS-2017 . [ 7 ] Phrase-Based & Neural Unsupervised Machine Translation . EMNLP-2018 ."}, "2": {"review_id": "ryza73R9tQ-2", "review_text": "The major issue in this paper is that the \"new direction\" in this paper has been explored before [1]. Therefore the introduction needs to be rewritten with arguing the difference between existing methods. The proposed method highly relies on the percentage of implicitly aligned data. I suggest the author do more experiments on different data set with a significant difference in this \"percentage\". Otherwise, we have no idea about the performance's sensitivity to the different datasets. More detailed explanations are needed. For example, what do you mean by \"p(w) as the estimated frequency\"? Why do we need to remove the first principal components? Section 3.2 title is \" aligning topic distribution\" but actually it is doing word distribution alignment. Do you do normalization for P(w^Y;d_i^X,\\theta) in eq.6 which is defined on the entire vocab's distribution? I think the measurement of the alignment accuracy and more experiments with different settings of \\alpha and \\beta are needed. Citation needed for \"Second, many previous works suggest that the word distribution ...\" [1] Munteanu et al, \"Improving Machine Translation Performance by Exploiting Non-Parallel Corpora\", 2006", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank Reviewer 3 for the reviews and comments ! Here are our responses to the concerns . 1.Regarding the related work Thanks for the reference . We are indeed aware of the related work on selecting sentence pairs from monolingual corpora . We did try some methods and found them do not work well as the scenario of related works is far different from ours . The methods in [ 1-4 ] rely on bilingual sentences to train a model and use this model to select sentence pairs . For example , [ 1-2 ] use an MT system to obtain a rough translation of a given page in one language into another and then uses word overlap or BLEU score between sentences as measures . [ 3-4 ] develop a ranking model/binary classifier to learn how likely a sentence in the target language is the translation of a sentence in the source language using parallel corpora . However , in our setting , we don \u2019 t have any bilingual sentences pair available . That is being said , we have no bilingual sentence pairs to train such a model to further select new data pairs . In order to work similarly to the previous works in the unsupervised setting , the most related model for selecting pairs is the unsupervised machine translation model . We did try to use an unsupervised translation model for sentence pair selection at the very early stage of the work . We first trained an unsupervised model followed [ 7 ] and then use the model outputs to evaluate each sentence pairs between two linked documents . We have conducted the following experiments : ( a ) . Similarly to [ 1,2 ] , for each sentence x , we generate the translation results using the unsupervised NMT model , select the most similar sentence to the translation results ( in terms of BLEU ) , and use such data pairs for NMT training . ( b ) .To build up a scoring function as used in [ 3-4 ] , we use the model-output probability as the scoring function . We select sentence pair ( x , y ) with larger translation probabilities p ( y|x ) and use such data pairs for NMT training . As the * * unsupervised translation model * * is not good enough , the selected sentence pairs are not reasonable as shown in the below table . We hypothesize this is due to that as some sentences in one Wiki pages are similar ( e.g. , a few words differ from each other ) , then 1. the BLEU ( or sentence-level BLEU ) score is very sensitive to evaluate such sentences . 2. the likelihood on similar sentences are not that trustable . Furthermore , we found training an NMT model using such poor data does not work well . On WMT De-En task , we have the following results : The BLEU score of model trained in ( a ) can only reach 22.4 . The best model trained in ( b ) can achieve only 19.8 in terms of BLEU score . Both show that the trained NMT models are not good as expected . As a summary , we find by leveraging the recent techniques ( the cross-lingual word embedding + unsupervised sentence representation ) , the selected sentences are much better . We believe our findings are important to the field of unsupervised learning and unsupervised machine translation . We will include those discussions in our paper and clarify the differences between our work and previous works . English || Selected German sentence by unsupervised translation model || Selected German sentence by our method She was one of the pioneers of Greek surrealism . || Inzwischen ist sie Mitglied der Kommunistischen Partei geworden . || Zun\u00e4chst z\u00e4hlt sie zu den Pionieren des griechischen Surrealismus . The film premiered at the 2014 Zurich Film Festival . || In Deutschland startete der Film am 10 . September 2015 . || Er hatte seine Premiere am 26 . September 2014 beim Zurich Film Festival . The eastern part is leafy and park-like . || Au\u00dferdem befindet sich hier ein Kinderspielplatz . || Der \u00f6stliche Teil ist begr\u00fcnt und park\u00e4hnlich gestaltet . Most of the remaining convicts were then relocated to Port Arthur . || Insgesamt wurden in der Strafkolonie 1200 H\u00e4ftlinge verwahrt . || Die verbliebenen H\u00e4ftlinge wurden schrittweise ins Lager nach Port Arthur verlegt . 2.Regarding more experiments on the different percentage of data pairs We are afraid that you might miss some parts of our paper . We have tested the performance with different percentage of implicitly aligned data according to the different choices of the thresholds to understand the sensitivity of the data size in Section 4.4 . As we can see from Section 4.4 , by setting different thresholds , we select data pairs from 60k to 250k . We think these results answer the question you mentioned . The different sizes of data indeed have impacts to the model performance , but all experimental results show that our model is better than the baselines ( i.e. , comparing the numbers in Figure 1 and the baselines in Table 2 ) ."}}