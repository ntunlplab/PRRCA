{"year": "2017", "forum": "H1_EDpogx", "title": "Near-Data Processing for Machine Learning", "decision": "Reject", "meta_review": "This paper is well motivated and clearly written, and is representative of the rapidly growing interdisciplinary area of hardware-software co-design for handling large-scale Machine Learning workloads. In particular, the paper develops a detailed simulator of SSDs with onboard multicore processors so that ML computations can be done near where the data resides.\n \n Reviewers are however unanimously unconvinced about the potential impact of the simulator, and more broadly the relevance to ICLR. The empirical section of the paper is largely focused on benchmarking logistic regression models on MNIST, which reviewers find underwhelming. It is conceivable that the results reflect performance on real hardware, but the ICLR community would atleast expect to see realistic deep learning workloads on larger datasets such as Imagenet, where scalability challenges have been throughly studied. Without such results, the impact of the contribution is hard to evaluate and the claimed gains are bit of a leap of faith. \n \n The authors make several good points in their response about the paper - that their method is expected to scale, that high quality simulations can given insights that can inform hardware manufacturing, and that their approach complements other hardware and algorithmic acceleration strategies. They are encouraged to resubmit the paper with a stronger empirical section, e.g., benchmarking training and inference of Inception-like models on ImageNet.", "reviews": [{"review_id": "H1_EDpogx-0", "review_text": "For more than a decade, near data processing has been a key requirement for large scale linear learning platforms, as the time to load the data exceeds the learning time, and this has justified the introduction of approaches such as Spark Deep learning usually deals with the data that can be contained in a single machine and the bottleneck is often the CPU-GPU bus or the GPU-GPU-bus, so a method that overcomes this bottleneck could be relevant. Unfortunately, this work is still very preliminary and limited to linear training algorithms, so of little interest yet to ICLR readership. I would recommend publication to a conference where it can reach the large-scale linear ML audience first, such as ICML. This paper is clear and well written in the present form and would probably mostly need a proper benchmark on a large scale linear task. Obviously, when the authors have convincing DNN learning simulations, they are welcome to target ICLR, but can the flash memory FPGA handle it? For experiments, the choice of MNIST is somewhat bizarre: this task is small and performance is notoriously terrible when using linear approaches (the authors do not even report it)", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your constructive comments . Given that most of the mainstream DNNs are based on ( variants of ) gradient descent , we strongly believe that the proposed framework can successfully accelerate many forms of deep learning applications . We already showed how the logistic regression ( in a sense , the basic unit of DNN ) could be accelerated by our approach . We also presented how parallel SGD algorithms should be modified for better results , since the multi-channel architectures inside ISP-supporting SSDs have different communication characteristics compared with conventional distributed systems . The authors thought ( and still think ) that this paper would come within the scope of ICLR , because of the phrases `` Implementation issues , parallelization , software platforms , hardware '' included in the call for paper of ICLR . Once again , thank you for your feedback . In the future release of our framework , we will make sure to incorporate it !"}, {"review_id": "H1_EDpogx-1", "review_text": "Combining storage and processing capabilities is an interesting research topic because data transfer is a major issue for many machine learning tasks. The paper itself is well-written, but unfortunately addresses a lot of things only to medium depth (probably due length constraints). My opinion is that a journal with an in-depth discussion of the technical details would be a better target for this paper. Even though the researchers took an interesting approach to evaluate the performance of the system, it's difficult for me to grasp the expected practical improvements of this approach. With such a big focus on GPU (and more specialized hardware such as TPUs), the one question that comes to mind: By how much does this - or do you expect it to - beat the latest and greatest GPU on a real task? I don't consider myself an expert on this topic even though I have some experience with SystemC. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your comments and suggestions . As a storage device ( not a computing device ) , intelligent SSDs are meant to complement GPUs and TPUs , not to replace them . [ Please also refer to my response to your very first comment to this paper below , for more information and comparisons . ] In order to utilize GPUs , we have to pump up the data stored in HDDs or SSDs first . As you pointed out correctly , a massive amount of data transfers involved in today 's machine learning are slowing down the whole ML pipeline . The idea behind in-storage processing ( ISP ) that includes intelligent SSDs is to reduce this data transfer , sending up data upwards in the memory hierarchy selectively . As such , please understand that we are NOT proposing to use our approach in lieu of GPUs ( we can not do that ) . What we are proposing is , by adopting ISP technology , the current GPU-based computing infrastructure can get improved further , by reducing the amount of the data that need to be handled by GPUs eventually . Regarding the venue of publication , I appreciate your suggestion about sending this paper to a ( probably HW-related ) journal . I did consider that option , but I think that a conference would be a better place for presenting a new idea in a timely manner . The ICLR call for papers soliciting papers on hardware-related topics also guided my decision : the list of this year \u2019 s ICLR topics available at the website ( http : //www.iclr.cc ) clearly includes `` Implementation issues , parallelization , software platforms , hardware '' ( the second line from the bottom ) . Most importantly , there are contributions and findings in this paper that would be more valuable to the ML community than to the HW community . For instance , there are different characteristics in the multiple NAND channels that can be exploited in an intriguing manner in terms of devising a parallel training algorithm ( e.g. , negligible on-chip communication latency , using which we can devise a new parallel SGD algorithm ) . Another example is the possibility of the cross-layer optimization between in-storage processing ( ISP ) and in-host processing ( IHP ) in terms of deploying a complex models with many parameters ( such as deep neural nets ) . Evidently , there are components that can easily be accelerated by taking advantage of intelligent storage devices , while there are components that are more suitable for the conventional processing . Implementing and optimizing such cross-layer optimization requires a set of new ML algorithms . In this regard , the Discussion section of this paper presents more discussions on future directions of this research , not only in terms of system design , but also in terms of ML algorithm development . I strongly believe that this paper is within the scope of the topics the ML community can and should understand and appreciate . Thank you very much for your evaluation efforts . Please post your comments and questions if additional ones arise ."}, {"review_id": "H1_EDpogx-2", "review_text": "While the idea of moving the processing for machine learning into silicon contained within the (SSD) data storage devices is intriguing and offers the potential for low-power efficient computation, it is a rather specialized topic, so I don't feel it will be of especially wide interest to the ICLR audience. The paper describes simulation results, rather than actual hardware implementation, and describes implementations of existing algorithms. The comparisons of algorithms' train/test performance does not seem relevant (since there is no novelty in the algorithms) and the use of a single layer perceptron on MNIST calls into question the practicality of the system, since this is a tiny neural network by today's standards. I did not understand from the paper how it was thought that this could scale to contemporary scaled networks, in terms of numbers of parameters for both storage and bandwidth. I am not an expert in this area, so have not evaluated in depth. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and evaluation efforts . It is unfortunate that some of the paper contents were not clearly presented to you , probably due to the interdisciplinary nature of this paper . Below I provide a point-by-point response to each of your comments . I hope that my responses will be helpful for addressing the points you raised and for making the paper more understandable . Comment 1 : `` it is a rather specialized topic , so I do n't feel it will be of especially wide interest to the ICLR audience '' Response 1 : In recent machine learning conferences ( such as NIPS and ICML ) , ML researchers \u2019 interest in hardware-related topics is clearly growing , and a number of companies are also developing solutions for accelerating ML ( e.g. , Google \u2019 s Tensor Processing Units ) . At this year \u2019 s NIPS that took place last week , there were multiple papers and workshops related to this topic ( e.g. , the `` Efficient Methods for Machine Learning '' workshop , where I could find a large number of audience ) . The list of this year \u2019 s ICLR topics available at the website ( http : //www.iclr.cc ) also clearly includes `` Implementation issues , parallelization , software platforms , hardware '' ( the second line from the bottom ) . Given this observation , I believe that there is a growing interest of the ML community in the topic this paper is about . Comment 2 : `` The paper describes simulation results , rather than actual hardware implementation '' Response 2 : By `` hardware implementation '' do you mean chip manufacturing , given that what we are proposing is a new chip architecture ( SSD controller capable of ML ) ? Please note that we did everything we could from the designers ' side ( such as architecture exploration/design , functional verification , and low-level simulation for timing ) . Actual chip manufacturing is definitely beyond the scope of academic research and infeasible , mainly due to its prohibitively high cost . The platform we created utilizes Synopsys Platform Architect ( PA ) , which is a professional tool actually used in chip companies to manufacture a chip . Using PA we can perform very detailed and realistic hardware design activities far better than using academic , open-source system-level simulators available . Please understand that our workflow is a standard one ; no company would manufacture a semiconductor chip directly without carrying out rigorous low-level simulation . Unfortunately , asking us to show an actual hardware chip would be a request that is impossible to address . Comment 3 : `` and describes implementations of existing algorithms '' Response 3 : As already clearly indicated in the paper , the core contribution of this paper is our implementation of a fully functional , realistic , multi-channel intelligent SSD platform that can test the effectiveness of in-storage processing ( ISP ) . To compare the performance of ISP with conventional in-host processing ( IHP ) , we used widely used optimization algorithms ( especially SGD and its variants that are popular ) . If we had used our own algorithm tailored for hardware , then the review would have been something like `` the comparison is unfair , since the authors used custom algorithms optimized for hardware ; the authors should use common workloads that can run in conventional machines . '' Comment 4 : `` the use of a single layer perceptron , ... how this could scale to contemporary networks .. '' Response 4 : Please note that our platform is general and can run other workloads than SGD and single-layer perceptron for MNIST . In this paper , we wanted to report our development of this versatile platform for accelerating machine learning , which took multi-year team efforts for completion and , I believe , deserves a publication in the ML community . For proof of concept and also for unbiased comparison with the conventional in-host processing , we thus chose to use the specific algorithms ( SGD ) in the current version of the paper . Through this work , we think that we have confirmed the effectiveness and potential of ISP , and the next step would be testing more diverse sets of ML algorithms . Regarding our future work , the related explanation is already provided in the Discussion section with details . We have started extending the current work to larger scale tests including deep neural networks . This extension suggests various intriguing research directions including IHP-ISP collaboration , new memory balancing in ISP , and parallel algorithms that have distinct characteristics ( such as negligible on-chip communication latency between computing nodes , unlike conventional parallel and distributed systems ) . Once again , thank you for your reviewing this manuscript . Please post your additional comments if there remain uncertain points ."}], "0": {"review_id": "H1_EDpogx-0", "review_text": "For more than a decade, near data processing has been a key requirement for large scale linear learning platforms, as the time to load the data exceeds the learning time, and this has justified the introduction of approaches such as Spark Deep learning usually deals with the data that can be contained in a single machine and the bottleneck is often the CPU-GPU bus or the GPU-GPU-bus, so a method that overcomes this bottleneck could be relevant. Unfortunately, this work is still very preliminary and limited to linear training algorithms, so of little interest yet to ICLR readership. I would recommend publication to a conference where it can reach the large-scale linear ML audience first, such as ICML. This paper is clear and well written in the present form and would probably mostly need a proper benchmark on a large scale linear task. Obviously, when the authors have convincing DNN learning simulations, they are welcome to target ICLR, but can the flash memory FPGA handle it? For experiments, the choice of MNIST is somewhat bizarre: this task is small and performance is notoriously terrible when using linear approaches (the authors do not even report it)", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your constructive comments . Given that most of the mainstream DNNs are based on ( variants of ) gradient descent , we strongly believe that the proposed framework can successfully accelerate many forms of deep learning applications . We already showed how the logistic regression ( in a sense , the basic unit of DNN ) could be accelerated by our approach . We also presented how parallel SGD algorithms should be modified for better results , since the multi-channel architectures inside ISP-supporting SSDs have different communication characteristics compared with conventional distributed systems . The authors thought ( and still think ) that this paper would come within the scope of ICLR , because of the phrases `` Implementation issues , parallelization , software platforms , hardware '' included in the call for paper of ICLR . Once again , thank you for your feedback . In the future release of our framework , we will make sure to incorporate it !"}, "1": {"review_id": "H1_EDpogx-1", "review_text": "Combining storage and processing capabilities is an interesting research topic because data transfer is a major issue for many machine learning tasks. The paper itself is well-written, but unfortunately addresses a lot of things only to medium depth (probably due length constraints). My opinion is that a journal with an in-depth discussion of the technical details would be a better target for this paper. Even though the researchers took an interesting approach to evaluate the performance of the system, it's difficult for me to grasp the expected practical improvements of this approach. With such a big focus on GPU (and more specialized hardware such as TPUs), the one question that comes to mind: By how much does this - or do you expect it to - beat the latest and greatest GPU on a real task? I don't consider myself an expert on this topic even though I have some experience with SystemC. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your comments and suggestions . As a storage device ( not a computing device ) , intelligent SSDs are meant to complement GPUs and TPUs , not to replace them . [ Please also refer to my response to your very first comment to this paper below , for more information and comparisons . ] In order to utilize GPUs , we have to pump up the data stored in HDDs or SSDs first . As you pointed out correctly , a massive amount of data transfers involved in today 's machine learning are slowing down the whole ML pipeline . The idea behind in-storage processing ( ISP ) that includes intelligent SSDs is to reduce this data transfer , sending up data upwards in the memory hierarchy selectively . As such , please understand that we are NOT proposing to use our approach in lieu of GPUs ( we can not do that ) . What we are proposing is , by adopting ISP technology , the current GPU-based computing infrastructure can get improved further , by reducing the amount of the data that need to be handled by GPUs eventually . Regarding the venue of publication , I appreciate your suggestion about sending this paper to a ( probably HW-related ) journal . I did consider that option , but I think that a conference would be a better place for presenting a new idea in a timely manner . The ICLR call for papers soliciting papers on hardware-related topics also guided my decision : the list of this year \u2019 s ICLR topics available at the website ( http : //www.iclr.cc ) clearly includes `` Implementation issues , parallelization , software platforms , hardware '' ( the second line from the bottom ) . Most importantly , there are contributions and findings in this paper that would be more valuable to the ML community than to the HW community . For instance , there are different characteristics in the multiple NAND channels that can be exploited in an intriguing manner in terms of devising a parallel training algorithm ( e.g. , negligible on-chip communication latency , using which we can devise a new parallel SGD algorithm ) . Another example is the possibility of the cross-layer optimization between in-storage processing ( ISP ) and in-host processing ( IHP ) in terms of deploying a complex models with many parameters ( such as deep neural nets ) . Evidently , there are components that can easily be accelerated by taking advantage of intelligent storage devices , while there are components that are more suitable for the conventional processing . Implementing and optimizing such cross-layer optimization requires a set of new ML algorithms . In this regard , the Discussion section of this paper presents more discussions on future directions of this research , not only in terms of system design , but also in terms of ML algorithm development . I strongly believe that this paper is within the scope of the topics the ML community can and should understand and appreciate . Thank you very much for your evaluation efforts . Please post your comments and questions if additional ones arise ."}, "2": {"review_id": "H1_EDpogx-2", "review_text": "While the idea of moving the processing for machine learning into silicon contained within the (SSD) data storage devices is intriguing and offers the potential for low-power efficient computation, it is a rather specialized topic, so I don't feel it will be of especially wide interest to the ICLR audience. The paper describes simulation results, rather than actual hardware implementation, and describes implementations of existing algorithms. The comparisons of algorithms' train/test performance does not seem relevant (since there is no novelty in the algorithms) and the use of a single layer perceptron on MNIST calls into question the practicality of the system, since this is a tiny neural network by today's standards. I did not understand from the paper how it was thought that this could scale to contemporary scaled networks, in terms of numbers of parameters for both storage and bandwidth. I am not an expert in this area, so have not evaluated in depth. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and evaluation efforts . It is unfortunate that some of the paper contents were not clearly presented to you , probably due to the interdisciplinary nature of this paper . Below I provide a point-by-point response to each of your comments . I hope that my responses will be helpful for addressing the points you raised and for making the paper more understandable . Comment 1 : `` it is a rather specialized topic , so I do n't feel it will be of especially wide interest to the ICLR audience '' Response 1 : In recent machine learning conferences ( such as NIPS and ICML ) , ML researchers \u2019 interest in hardware-related topics is clearly growing , and a number of companies are also developing solutions for accelerating ML ( e.g. , Google \u2019 s Tensor Processing Units ) . At this year \u2019 s NIPS that took place last week , there were multiple papers and workshops related to this topic ( e.g. , the `` Efficient Methods for Machine Learning '' workshop , where I could find a large number of audience ) . The list of this year \u2019 s ICLR topics available at the website ( http : //www.iclr.cc ) also clearly includes `` Implementation issues , parallelization , software platforms , hardware '' ( the second line from the bottom ) . Given this observation , I believe that there is a growing interest of the ML community in the topic this paper is about . Comment 2 : `` The paper describes simulation results , rather than actual hardware implementation '' Response 2 : By `` hardware implementation '' do you mean chip manufacturing , given that what we are proposing is a new chip architecture ( SSD controller capable of ML ) ? Please note that we did everything we could from the designers ' side ( such as architecture exploration/design , functional verification , and low-level simulation for timing ) . Actual chip manufacturing is definitely beyond the scope of academic research and infeasible , mainly due to its prohibitively high cost . The platform we created utilizes Synopsys Platform Architect ( PA ) , which is a professional tool actually used in chip companies to manufacture a chip . Using PA we can perform very detailed and realistic hardware design activities far better than using academic , open-source system-level simulators available . Please understand that our workflow is a standard one ; no company would manufacture a semiconductor chip directly without carrying out rigorous low-level simulation . Unfortunately , asking us to show an actual hardware chip would be a request that is impossible to address . Comment 3 : `` and describes implementations of existing algorithms '' Response 3 : As already clearly indicated in the paper , the core contribution of this paper is our implementation of a fully functional , realistic , multi-channel intelligent SSD platform that can test the effectiveness of in-storage processing ( ISP ) . To compare the performance of ISP with conventional in-host processing ( IHP ) , we used widely used optimization algorithms ( especially SGD and its variants that are popular ) . If we had used our own algorithm tailored for hardware , then the review would have been something like `` the comparison is unfair , since the authors used custom algorithms optimized for hardware ; the authors should use common workloads that can run in conventional machines . '' Comment 4 : `` the use of a single layer perceptron , ... how this could scale to contemporary networks .. '' Response 4 : Please note that our platform is general and can run other workloads than SGD and single-layer perceptron for MNIST . In this paper , we wanted to report our development of this versatile platform for accelerating machine learning , which took multi-year team efforts for completion and , I believe , deserves a publication in the ML community . For proof of concept and also for unbiased comparison with the conventional in-host processing , we thus chose to use the specific algorithms ( SGD ) in the current version of the paper . Through this work , we think that we have confirmed the effectiveness and potential of ISP , and the next step would be testing more diverse sets of ML algorithms . Regarding our future work , the related explanation is already provided in the Discussion section with details . We have started extending the current work to larger scale tests including deep neural networks . This extension suggests various intriguing research directions including IHP-ISP collaboration , new memory balancing in ISP , and parallel algorithms that have distinct characteristics ( such as negligible on-chip communication latency between computing nodes , unlike conventional parallel and distributed systems ) . Once again , thank you for your reviewing this manuscript . Please post your additional comments if there remain uncertain points ."}}