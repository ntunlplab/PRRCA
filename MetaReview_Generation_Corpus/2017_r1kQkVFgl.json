{"year": "2017", "forum": "r1kQkVFgl", "title": "Learning Python Code Suggestion with a Sparse Pointer Network", "decision": "Reject", "meta_review": "This paper augments language models with attention to to capture long range dependencies through a sparse pointer network that is restricted to previously introduced identifiers, and demonstrates the proposed architecture over a new, released large-scale code suggestion corpus of 41M lines of Python code. The addition of long range attention over 20 identifiers improves perplexity compared to an LSTM with an attentional context of 50 words, but degrades accuracy (hit @1), while improving hit@5.\n The experimental validation however requires a more thorough analysis and more detailed ablation experiments and discussions, and more thorough comparison to related work. As is, many choices seem quite arbitrary and make it hard to determine if the model is really performing well (minibatch sizes, size of the memory for the LSTM, choice and number of identifiers for the sparse pointers, etc).", "reviews": [{"review_id": "r1kQkVFgl-0", "review_text": "This paper presents an improved neural language models designed for selected long-term dependency, i.e., to predict more accurately the next identifier for the dynamic programming language such as Python. The improvements are obtained by: 1) replacing the fixed-widow attention with a pointer network, in which the memory only consists of context representation of the previous K identifies introduced for the entire history. 2) a conventional neural LSTM-based language model is combined with such a sparse pointer network with a controller, which linearly combines the prediction of both components using a dynamic weights, decided by the input, hidden state, and the context representations at the time stamp. Such a model avoids the the need of large window size of the attention to predict next identifier, which usually requires a long-term dependency in the programming language. This is partly validated by the python codebase (which is another contribution of this paper) experiments in the paper. While the paper still misses some critical information that I would like to see, including how the sparse pointer network performance chances with different size of K, and how computationally efficient it is for both training and inference time compared to LSTM w/ attention of various window size, and ablation experiments about how much (1) and (2) contribute respectively, it might be of interest to the ICLR community to see it accepted. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for taking the time to review our paper !"}, {"review_id": "r1kQkVFgl-1", "review_text": "This paper uses a pointer network over a sparse window of identifiers to improve code suggestion for dynamically-typed languages. Code suggestion seems an area where attention and/or pointers truly show an advantage in capturing long term dependencies. The sparse pointer method does seem to provide better results than attention for similar window sizes - specifically, comparing a window size of 20 for the attention and sparse pointer method shows the sparse pointer winning fairly definitively across the board. Given a major advantage of the pointer method is being able to use a large window size well thanks to the supervision the pointer provides, it was unfortunate (though understandable due to potential memory issues) not to see larger window sizes. Having a different batch size for the sparse pointer and attention models is unfortunate given it complicates an otherwise straight comparison between the two models. The construction and filtering of the Python corpus sounds promising but as of now it is still inaccessible (listed in the paper as TODO). Given that code suggestion seems an interesting area for future long term dependency work, it may be promising as an avenue for future task exploration. Overall this paper and the dataset are likely an interesting contribution even though there are a few potential issues.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and feedback . We have now updated the paper to include the link to the Python corpus . Subsequent to your comment , we ran the baseline models with a batch size of 30 and noted that they achieved worse validation and test set perplexities . We have therefore chosen to continue reporting the better results of the baseline models with a batch size of 75 and have made this clear in the paper ."}, {"review_id": "r1kQkVFgl-2", "review_text": "This paper takes a standard auto-regressive model of source code and augments it with a fixed attention policy that tracks the use of certain token types, like identifiers. Additionally they release a Python open source dataset. As expected this augmentation, the fixed attention policy, improves the perplexity of the model. It seems important to dig a bit deeper into these results and show the contribution of different token types to the achieve perplexity. This is alluded to in the text, but a more thorough comparison would be welcome. The idea of an attention policy that takes advantage of expert knowledge is a nice contribution, but perhaps if limited novelty --- for example the Maddison and Tarlow 2014 paper, which the authors cite, has scoping rules that track previously used identifiers in scope. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and comments ! I just want to clarify that the attention mechanism is learned . What is fixed is the heuristic to only attend over the previous N outputs of an RNN at positions of identifiers instead of all kinds of previous tokens . As you pointed out , this heuristic of tracking previously used identifiers in scope has been used before . What we believe is novel is the following . For the previous N identifiers , the model is learning to first choose between a normal neural language or copying one of the N previously seen identifiers . When copying , the choice for one of these identifiers is modeled via a learnable attention mechanism . Also note that for this attention mechanism , the output representations at positions of identifiers is used , not the representation of the identifier in the input vocabulary . That is , the output representation at a position of an identifier can contain contextual information . We will update the paper to make this clearer ."}], "0": {"review_id": "r1kQkVFgl-0", "review_text": "This paper presents an improved neural language models designed for selected long-term dependency, i.e., to predict more accurately the next identifier for the dynamic programming language such as Python. The improvements are obtained by: 1) replacing the fixed-widow attention with a pointer network, in which the memory only consists of context representation of the previous K identifies introduced for the entire history. 2) a conventional neural LSTM-based language model is combined with such a sparse pointer network with a controller, which linearly combines the prediction of both components using a dynamic weights, decided by the input, hidden state, and the context representations at the time stamp. Such a model avoids the the need of large window size of the attention to predict next identifier, which usually requires a long-term dependency in the programming language. This is partly validated by the python codebase (which is another contribution of this paper) experiments in the paper. While the paper still misses some critical information that I would like to see, including how the sparse pointer network performance chances with different size of K, and how computationally efficient it is for both training and inference time compared to LSTM w/ attention of various window size, and ablation experiments about how much (1) and (2) contribute respectively, it might be of interest to the ICLR community to see it accepted. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for taking the time to review our paper !"}, "1": {"review_id": "r1kQkVFgl-1", "review_text": "This paper uses a pointer network over a sparse window of identifiers to improve code suggestion for dynamically-typed languages. Code suggestion seems an area where attention and/or pointers truly show an advantage in capturing long term dependencies. The sparse pointer method does seem to provide better results than attention for similar window sizes - specifically, comparing a window size of 20 for the attention and sparse pointer method shows the sparse pointer winning fairly definitively across the board. Given a major advantage of the pointer method is being able to use a large window size well thanks to the supervision the pointer provides, it was unfortunate (though understandable due to potential memory issues) not to see larger window sizes. Having a different batch size for the sparse pointer and attention models is unfortunate given it complicates an otherwise straight comparison between the two models. The construction and filtering of the Python corpus sounds promising but as of now it is still inaccessible (listed in the paper as TODO). Given that code suggestion seems an interesting area for future long term dependency work, it may be promising as an avenue for future task exploration. Overall this paper and the dataset are likely an interesting contribution even though there are a few potential issues.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and feedback . We have now updated the paper to include the link to the Python corpus . Subsequent to your comment , we ran the baseline models with a batch size of 30 and noted that they achieved worse validation and test set perplexities . We have therefore chosen to continue reporting the better results of the baseline models with a batch size of 75 and have made this clear in the paper ."}, "2": {"review_id": "r1kQkVFgl-2", "review_text": "This paper takes a standard auto-regressive model of source code and augments it with a fixed attention policy that tracks the use of certain token types, like identifiers. Additionally they release a Python open source dataset. As expected this augmentation, the fixed attention policy, improves the perplexity of the model. It seems important to dig a bit deeper into these results and show the contribution of different token types to the achieve perplexity. This is alluded to in the text, but a more thorough comparison would be welcome. The idea of an attention policy that takes advantage of expert knowledge is a nice contribution, but perhaps if limited novelty --- for example the Maddison and Tarlow 2014 paper, which the authors cite, has scoping rules that track previously used identifiers in scope. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and comments ! I just want to clarify that the attention mechanism is learned . What is fixed is the heuristic to only attend over the previous N outputs of an RNN at positions of identifiers instead of all kinds of previous tokens . As you pointed out , this heuristic of tracking previously used identifiers in scope has been used before . What we believe is novel is the following . For the previous N identifiers , the model is learning to first choose between a normal neural language or copying one of the N previously seen identifiers . When copying , the choice for one of these identifiers is modeled via a learnable attention mechanism . Also note that for this attention mechanism , the output representations at positions of identifiers is used , not the representation of the identifier in the input vocabulary . That is , the output representation at a position of an identifier can contain contextual information . We will update the paper to make this clearer ."}}