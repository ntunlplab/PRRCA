{"year": "2021", "forum": "KubHAaKdSr7", "title": "Modifying Memories in Transformer Models", "decision": "Reject", "meta_review": "All reviewers noted the significance of the problem tackled by this paper and felt that it is going in the right direction. However, they also all noted that the paper was not finalized and polished well enough to be granted publication: details missing, typos, clarifications needed. The reviewers acknowledged the large amount of work that went into improving the paper during the discussion period. R1 even increased their score to reflect that.\n\nStill the paper still needs some work to be accepted at ICLR. In particular, we encourage the authors to improve on 2 axes.\n1. Clarifying motivations and contribution: it is still unclear if the main point of the paper is to propose new methods around FTM & constrained updates, etc. or around proposing a new benchmark for catastrophic forgetting, lifelong learning.\n2. Reorganizing experimental section: the experimental section should be organized to support #1. Reviewers made a lot of suggestions, like moving Table 4 from the appendix, that should be further refined\n\nWe hope that this will allow to increase the clarity and impact of this research work.", "reviews": [{"review_id": "KubHAaKdSr7-0", "review_text": "The submission proposes and explores the task of modifying factual knowledge in transformer language models . The paper makes a convincing argument that this is a worthwhile problem , as knowledge in existing models quickly becomes out dated , and the cost of re-training from scratch on an updated corpus is prohibitive . The paper suggests several natural alternatives , finding the best results by fine-tuning the model on modified facts , but with a constraint to minimize the difference in from the original model . Surprisingly , the authors further show that it is harder to modify knowledge in the partially symbolic 'Facts as Experts ' model than it is in BERT . However , I was unable to follow some important details , and I think the paper is missing an obvious baseline , so I think it needs some more work before it can be accepted . The proposed method is based around fine-tuning the model on modified facts , with the hard constraint that the norm of the difference from the original model parameters is less than a threshold . I struggled to find any detail on how the authors enforce these constraints during optimization , and this point should be made clearer . I 'd be really interested to see some more analysis that sheds light on which parameters the transformer is using to store facts . Results in the paper touch on this by exploring fine-tuning different layers , but I think lots of interesting experiments could be added with little extra work . For example , you could try fine-tuning just the word embedding layer , or only the feed forward sub-layers . I think exploring this question would add to the paper , and might improve results . I also felt the paper was missing an obvious baseline based on kNN-LM ( Khandelwal et al.2019 ) , which is explicitly motivated as a way to add knowledge to transformer language models . For example : first , you could simply encode your the sentence modified facts with the transformer , masking out the modified words . For inference , you could copy a token from the modified facts if it is sufficiently close in representation space , and otherwise predict a token using the baseline transformer model . More generally , non-parametric methods appear to offer a relatively simple and obvious solution to the task , as facts can be updated by just changing the text . These approaches should be discussed further . Minor Points The paper contains frequent grammatical errors ( too many to list here ) , and I 'd recommend getting it thoroughly proof read before publication . This did not affect my rating .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and suggestions ! We are glad that you find the modification problem worthwhile studying . We agree that having more baselines adds to the strength of the paper , but the non-parametric kNN-LM may not be a strong baseline for the modification task . Please refer to the details below . * \u201c Surprisingly , the authors further show that it is harder to modify knowledge in the partially symbolic 'Facts as Experts ' model than it is in BERT. \u201d * To clarify , by \u201c We find that it is not easier to modify the memorized facts of memory networks like FaE \u201d , we were trying to express that modifying FaE to obtain the same level of accuracy on the modified facts ( around 78 % in the setting of modifying 32 facts ) requires almost the same or even more drop in the accuracy on the unmodified facts than the BERT-Large model in the experiments we have tried . FaE has a 10 % higher test accuracy from the beginning , so the overall ( weighted ) accuracy of FaE is still the best among the models . * \u201c I struggled to find any detail on how the authors enforce these constraints during optimization , and this point should be made clearer. \u201d * We have included the details for solving the constrained optimization with norm constraints on the weights in Appendix D in the revised version . * \u201c I 'd be really interested to see some more analysis that sheds light on which parameters the transformer is using to store facts ... For example , you could try fine-tuning just the word embedding layer , or only the feed forward sub-layers. \u201d * Our current result does shed light on which parameter the Transformer is using to \u201c store \u201d facts , indicated by the effectiveness of each Transformer block for modifying the memory . The landscape is more complicated than we have imagined . We find that it depends on the state of the model , the number of facts to modify , and the finetuning approach . First , the FT process shifts the most effective layer for modification from Block 0 to Block 11 for the BERT-Base model when modifying 32 facts on T-REx ( Table 2 and 3 in the current version ) . Second , as the number of modified facts increases , the most effective layer also changes . In Figure 4 of the current version , we find that for FTM and FT+FTM without constraints , when we modify more than 512 facts , Block 5 turns out to be the most effective one . In Figure 2 and 3 , we find that , with constraints , using 512 facts shifts the most effective block from Block 11 back to Block 0 . We had experimented with fine-tuning only the feedforward layers instead of finetuning whole Transformer blocks , and the results were not as good as the one presented in the paper . We will post results with finetuning the embedding layers when the results are available ."}, {"review_id": "KubHAaKdSr7-1", "review_text": "The paper proposes a very interesting yet practical problem of modifying the memory encoded in transformer weight to unlearn some facts and update with new facts . This paper seems to be a follow-up work from FAE , which encodes symbolic facts in memory for retrieval . Generally speaking , I like the basic idea of this paper and it might have a broad impact on the whole community . However , there are still a lot of questions about the paper . 1 ) the paper seems to be written in a rush without refining , there are numerous serious typos and spellings errors , which affect my understanding a lot . For example , in 4.5.1 , what is `` RT '' , is it supposed to be `` RI '' ? In Figure 3 , why is the 32 , the figures are a mess . Why is the left showing `` 32- > 512 '' while the right showing `` 32- > 128 '' ? Why do you say it 's sharp degrading , it 's not that sharp reflected from Figure 3 . I 'm not sure if I misunderstand something . 2 ) The results are also quite messy . The algorithm without constrained optimization has its results reported in the table , while the algorithm with constrained optimization is reported in figures . The results with FAE is yet in another table far away . It 's hard for me to compare them and draw a consistent conclusion . Is it possible to aggregate all the main results in one table and demonstrate all the ablation studies using Figures ? Currently , the figures involved in 4.5.2 are distributed from page 6 - page 8 , is it possible to aggregate them in a concentrated place ? 3 ) Besides these details , I think the proposed method is somewhat `` not novel '' . In lifelong learning or meta-learning community , such constrained optimization algorithms have been explored for a few years to prevent the mode from catastrophic forgetting . I do n't think the paper makes any significant contribution to this aspect . 4 ) Overall , I still quite like the scope of this paper . I would like to see a more structured and clear version of the paper with more fundamental algorithm innovation .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for highlighting the importance of the problem we are studying ! We have revised the paper to correct the typos . To address your concerns : * \u201c ... in 4.5.1 , what is `` RT '' , is it supposed to be `` RI '' ? In Figure 3 .... Why is the left showing `` 32- > 512 '' while the right showing `` 32- > 128 '' ? Why do you say it 's sharp degrading , it 's not that sharp reflected from Figure 3 . \u201d * 1.Yes , it was our mistake . \u201c RT \u201d should be \u201c RI \u201d . 2.Figure 3 ( now Figure 2 ) serves to show the effect of the number of modified facts on the results . For BERT-Base we compare the results of modifying 32 facts with modifying 512 facts . For BERT-Base we compared modifying 32 facts with modifying 128 facts . We will include more consistent comparisons in our future version . 3.For example , for BERT-Base , if we modify 32 facts , the accuracy on the unmodified facts is around 45 % . If we modify 512 facts , the best accuracy on unmodified facts drops to only 20 % , which we think is quite a sharp decline . Similarly , the accuracy on the unmodified facts dropped by around 10 % when modifying 128 instead of 32 facts for BERT-Large . * \u201c Is it possible to aggregate all the main results in one table and demonstrate all the ablation studies using Figures ? Currently , the figures involved in 4.5.2 are distributed from page 6 - page 8 , is it possible to aggregate them in a concentrated place ? \u201d * We have aggregated the best results of the main models and settings in Table 2 in the current version . We have also rearranged the tables and figures to be closer to their text mentions . * \u201c Besides these details , I think the proposed method is somewhat `` not novel '' . In lifelong learning or meta-learning community , such constrained optimization algorithms have been explored for a few years to prevent the mode from catastrophic forgetting. \u201d * The primary goal of our paper is to propose the research problem of how one can modify the facts ( implicitly ) memorized by Transformer models and construct benchmarks with reasonable baselines . To the best of our knowledge , this is the first work studying the reliable and efficient modification of the factual knowledge memorized by Transformers . One of our interesting findings is that the constrained optimization approach is surprisingly effective , despite its simplicity . There is still a huge room for future works to explore in this newly proposed research area though . We have added comparisons with lifelong learning to the related works section of our current version . We emphasize that our setting is different from lifelong learning in that it not only requires preserving the performance on the unmodified facts but also requires changing the predictions on the modified facts , causing conflicts with previously learned parameters . Some existing lifelong learning methods may face new challenges in our setting , e.g. , we need to update the Gradient Episodic Memory ( Lopez-Paz & Ranzato , 2017 ) or the Conceptors ( Liu et al. , 2019 ) on all previous tasks . Computing the Fisher information matrix is also challenging given the size of the models and datasets we evaluated . We have evaluated not only the constrained optimization approach but also the role of different layers and the impact of using a mixture of modified and unmodified evidences . We also consider knowledge-augmented networks in our setting , which is not a focus of existing lifelong learning methods . This part not only involves the constrained optimization but also the explicit modification of symbolic links of FaE . We provide a more detailed evaluation for knowledge modification than the original FaE paper , involving finetuning different layers of the model to achieve better results , and show that modifying the symbolic link is not enough ; we also need to modify implicit memories stored in their parameters to obtain high accuracy on modified facts . Previously , the FaE paper only reported one negative result for modifying the symbolic links on one subset of facts ."}, {"review_id": "KubHAaKdSr7-2", "review_text": "This paper studies a new problem : evaluating the ability of modifying knowledge inside the Transformer models when models memorize world knowledge inside its parameters . The contribution of this paper is two-fold : ( 1 ) introducing a new benchmark for evaluating such ability , and ( 2 ) evaluating a comprehensive list of baselines , including a new model that has a constraint term in the objective during fine-tuning . Strengths of the paper : 1 . The problem is well-motivated and of interest to the wider community . Examining the behavior of transformers given updated facts is a timely topic , given recent progress and interest in large pretrained models storing world knowledge and achieving reasonable performance on downstream tasks ( slot infilling , question answering ) without access to external knowledge sources . 2.The benchmark dataset is created in a reasonable way - it is created on top of T-REx and Zero-shot RE dataset , where a target entity is replaced by another entity that shares the same relation with the other entity . 3.The constrained objective provides a simple yet nice way of updating knowledge in the model parameters in a constrained manner . This model shows that the fine-tuned model overfits less to the modified knowledge , compared to naive baselines . Weaknesses of the paper : 1 . I am not fully convinced by the setup in the paper , where the model is pretrained on unmodified facts and then fine-tuned on a modified knowledge . First , in a natural setting , a set of knowledge sources will always contain both unmodified facts and modified facts together . Therefore , an assumption in the paper that the model can only access modified facts during fine-tuning seems to be unrealistic . Second , if the research question here is the generalization ability of the model , isn \u2019 t a zero-shot setting or a setting with small training examples ( e.g.1k ) more suitable ? 2.Although the creation process of the benchmark dataset makes sense , it is still created synthetically . Furthermore , the paper does not include data analysis or human performance estimation , making it hard to estimate the quality of the data . This is important because , when a subset of knowledge was synthetically updated , some knowledge will contradict each other . 3.Although the model with constrained objective overfits less to the modified knowledge , it still overfits a lot , achieving significantly lower numbers on unmodified facts . It is still a nice baseline , but the claim in the paper : \u201c best way to enforce the constraint in Transformer models \u201d ( Sec 1 ) seems to be overclaiming . 4.Although the paper includes comprehensive experiments , there is n't really new take-aways that are not different from naive expectations . The conclusion , `` the model overfits to modified facts and suffers from catastrophic forgetting '' is pretty naive and has been observed in a lot of prior work ( [ 1 ] is one of recent ones ) . Questions 1 . Is there a specific reason that the scope of this paper is restricted to transformers ? Looks like the general idea can be applied to any model that does not have an access to external knowledge source ? 2.The creation process of the benchmark data is strictly limited to structured KBs . Is there a way to create such a dataset for tasks based on unstructured text ? 3.Are there baseline numbers for PT+FT ( without FTM ) reported ? [ 1 ] Rolnick et al.Experience replay for continual learning . NeurIPS 2019 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for acknowledging the contributions of our paper ! Below we address your concerns . * \u201c I am not fully convinced by the setup in the paper , where the model is pretrained on unmodified facts and then fine-tuned on a modified knowledge . First , in a natural setting , a set of knowledge sources will always contain both unmodified facts and modified facts together . Therefore , an assumption in the paper that the model can only access modified facts during fine-tuning seems to be unrealistic . Second , if the research question here is the generalization ability of the model , isn \u2019 t a zero-shot setting or a setting with small training examples ( e.g.1k ) more suitable \u201d * We have definitely tried to provide the model with both modified facts and unmodified facts in the modification process , see section 4.5.3 and Table 4 ( originally in the appendix ) . Surprisingly , this did not improve the model \u2019 s performance on the averaged accuracy , compared to providing the model with only modified facts and using constrained optimization . Only using the modified facts in the modification process is a more efficient approach and it is not difficult to just pick the supporting evidences of modified facts . Also , to clarify , in the FT process , we finetuned the model on the whole original training set of T-REx/zsRE , not just the facts that will not be modified . The \u201c generalization ability \u201d in this work refers to the ability to generalize to different paraphrases of the same question , e.g. , the model generalizes well if it gives the same answers to \u201c What is the continent that Della Pia Glacier is located ? \u201d in the training set and \u201c What continent is Della Pia Glacier found on ? \u201d in the test set . Therefore , we construct datasets so that the training set covers all the facts in the test sets , but their questions are asked in different ways . It is almost impossible for a model without memory modules to answer factual questions if the model was never trained on samples entailing the fact and implicitly memorized the fact , so the traditional zero-shot setting does not seem practical in our case . We are already operating in the small-training-samples regime as you suggested . During the modification process , we indeed use only a small set ( up to thousands ) of training samples for modified facts . * \u201c ... the paper does not include data analysis or human performance estimation , making it hard to estimate the quality of the data . This is important because , when a subset of knowledge was synthetically updated , some knowledge will contradict each other. \u201d * Thanks for pointing out the need for human performance evaluation . However , we believe our current setting does not introduce conflicts with other facts , indicated by the results with FaE , where we see no drop in accuracy on unmodified facts after we modify its symbolic links for the modified facts ( Table 5 , \u201c None \u201d in current version ; also included in the previous version ) . This is probably because we only modify the object of the facts and the current datasets does not contain multiple possible objects for each subject-relation pair . * \u201c ... best way to enforce the constraint in Transformer models \u201d ( Sec 1 ) seems to be overclaiming. \u201d * We have rephrased the sentence into \u201c We formulate the knowledge modification as a constrained optimization problem with a constraint on the loss on the unmodified facts and explore better baseline methods to approximately enforce this constraint. \u201d We would like to emphasize that the simple norm constraint is not only efficient but also surprisingly effective compared to other methods we have tried . * \u201c the model overfits to modified facts and suffers from catastrophic forgetting '' is pretty naive and has been observed in a lot of prior work ( [ 1 ] is one of recent ones ) \u201d * We agree the phenomenon does look similar to prior works on continual learning , but the modification task is different from continual learning in that the modified facts conflict with the original training data , which means the model can not preserve its behavior on all the previously learned facts . It is a new challenge to existing continual learning algorithms . Please refer to the last paragraph of the related works section ( Section 2 ) in the new version for a detailed discussion ."}, {"review_id": "KubHAaKdSr7-3", "review_text": "Summary Recently , pretrained Transformer language models have been shown to capture world knowledge ( using testbeds containing facts ) . What if you want to update a fact , for example , with the current president of USA ? This paper investigates different approaches to update the weights of a Transformer model such that the model works for the modified facts but does not catastrophically forget unmodified facts . The main proposal is a simple regularization technique ( which they call constrained fine-tuning ) to minimize weight changes while fine-tuning on the supporting factual sentences that represent the modified facts . Strengths 1 . The problem of updating world knowledge in Transformers in itself is an interesting problem and novel . 2.The problem is well motivated and the first half of the paper is well-written . 3.The proposed method of fine-tuning along with regularization is simple and it seems to work better than just fine-tuning methods . Weaknesses : 1 . Confusing experimental section , and many important details are missing ( see comments ) . 2.The paper felt like it is a last-minute submission and written in haste . 3.Important related work on retrofitting literature not cited . 4.The proposed method works at the cost of forgetting unmodified facts as the number of unmodified facts increase . Comments : Although the reviewer likes the problem formulation and the main idea , they find it hard to follow the experimental section . 1.There were no details on how to find supporting sentences of target facts that one wants to change . This is a non-trivial task and without a detailed description , the paper is impossible to replicate . There were no examples anywhere including appendix . 2.Why do the authors start with pretrained + fine-tuned model ? Is n't pretrained model trained on all sentences anyways ? Do they mean separate fine-tuned data that contain factual statements ? Why does one need this data ? Is n't this against the spirit of pretrained models as knowledge bases ? 3.Results of vanilla pretrained models on unmodified and modified facts missing , i.e. , PT alone . Also , PT + FT. 4 . The notation and acronyms are confusing . The authors use a lot of acronyms like PT , FT , FTA , FTM , RT which is unnecessary . This makes the results table unreadable without reading the paper . 5.No citations on retrofitting literature which is very similar idea to this work ( e.g. , Faruqui et al.2015 ) .This limits the novelty of the work but the reviewer give credits to the problem formulation . 6.How is PT+FT+FTM different from PT + D_F ' ? 7.FTA is introduced but never used . 8.The reviewer had a hard time following experiments with FAE section . What is the main takeaway from these experiments ? The model has to be described in detail ( perhaps with a figure ) . 9.Examples , Examples , Examples . Show some examples from each dataset .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your valuable feedback . We are glad that you find this task novel and interesting . We have revised the paper and added discussions about retrofitting literature into the related works . We believe the readability of this work is significantly improved in the updated version . Below we address your concerns . * \u201c There were no details on how to find supporting sentences of target facts that one wants to change \u201d * In T-REx and zsRE , each supporting sentence is already linked to a fact so we did not need to find them . More specifically , each fact of the T-REx dataset has at least one supporting evidence and one template cloze question , and we use the supporting evidences and the cloze question to construct the training and test sets . For zsRE , we put the questions of a fact into training and test sets if the fact has multiple annotated questions , or keep it in the training set if it is the only question for the fact . We have added more details about the data creation process in Appendix A . In the future , if we were to build similar benchmarks using a completely unstructured corpus , we can use retrieval techniques to find supporting evidences for any fact within the corpus . This may not be perfect , but we can augment it with synthetic evidences constructed from various templates for the facts . Our benchmark and modification methods can work as long as we provide enough supporting evidences for the model to learn . * \u201c Why do the authors start with pretrained + fine-tuned model ? Is n't pretrained model trained on all sentences anyways ? Do they mean separate fine-tuned data that contain factual statements ? Why does one need this data ? Is n't this against the spirit of pretrained models as knowledge bases ? \u201d * The pretrained model refers to off-the-shelf BERT-Base models pretrained on the Wikipedia Corpus and the Bookcorpus . For finetuning ( FT ) , we finetune the model on all the supporting evidences of T-REx or zsRE , which improves the accuracy of BERT-Base by e.g.20 % on T-REx . The improved accuracy after the finetuning process allows us to explore the more ideal setting where a language model has good performance on the questions and is ready to be deployed in practice . This also allows us to choose the facts to be modified from a larger set of facts , because we only modify facts that the model has already learned correctly . * \u201c Results of vanilla pretrained models on unmodified and modified facts missing , i.e. , PT alone . Also , PT + FT. \u201d * We have added these results into Table 2 of the current version . * \u201c The notation and acronyms are confusing . The authors use a lot of acronyms like PT , FT , FTA , FTM , RT which is unnecessary . This makes the results table unreadable without reading the paper. \u201d * We have revised our experiment section to improve the readability . * \u201c No citations on retrofitting literature which is very similar idea to this work ( e.g. , Faruqui et al.2015 ) . \u201d * We have added discussions in the related works . While retrofitting does seem similar to our work in using facts/knowledge to finetune the models , the goals are different . We aim at changing the prediction of the models while preserving its performance on unmodified facts , whereas retrofitting aims to obtain better word representations using relations . * \u201c How is PT+FT+FTM different from PT + D_F ' ? FTA is introduced but never used. \u201d * Our previous version has results for PT+FT+FTA in Table 4 in the appendix ( now still Table 4 but denoted as FT+FTA ) . We have also added PT+FTA and PT+FTM in Table 2 ( now denoted as FTA and FTM ) . Our preliminary experiments with BERT-Base show that , in comparison with PT+FT+FTM , PT+D_F \u2019 ( drawing random batches from D_F \u2019 and finetuning on D_F \u2019 without any constraint ) has a higher accuracy on the unmodified facts ( around 50 % ) , but its accuracy on the modified facts is also around 50 % , lower than the current results on the modified facts . In our scenario , we want a higher accuracy on the modified facts . Also , as can be seen in Table 2 in the current version , if we use a mixture of the modified and unmodified facts in each minibatch from D_F \u2019 and enforce the norm constraints , we can improve the accuracy on the unmodified facts in the FT+FTA setting ( previously noted as PT+FT+FTA ) . That said , we would like to note that the result of FT+FTA ( previously denoted as PT+FT+FTA ) is still not as good as FT+FTM ( previously denoted as PT+FT+FTM ) ."}], "0": {"review_id": "KubHAaKdSr7-0", "review_text": "The submission proposes and explores the task of modifying factual knowledge in transformer language models . The paper makes a convincing argument that this is a worthwhile problem , as knowledge in existing models quickly becomes out dated , and the cost of re-training from scratch on an updated corpus is prohibitive . The paper suggests several natural alternatives , finding the best results by fine-tuning the model on modified facts , but with a constraint to minimize the difference in from the original model . Surprisingly , the authors further show that it is harder to modify knowledge in the partially symbolic 'Facts as Experts ' model than it is in BERT . However , I was unable to follow some important details , and I think the paper is missing an obvious baseline , so I think it needs some more work before it can be accepted . The proposed method is based around fine-tuning the model on modified facts , with the hard constraint that the norm of the difference from the original model parameters is less than a threshold . I struggled to find any detail on how the authors enforce these constraints during optimization , and this point should be made clearer . I 'd be really interested to see some more analysis that sheds light on which parameters the transformer is using to store facts . Results in the paper touch on this by exploring fine-tuning different layers , but I think lots of interesting experiments could be added with little extra work . For example , you could try fine-tuning just the word embedding layer , or only the feed forward sub-layers . I think exploring this question would add to the paper , and might improve results . I also felt the paper was missing an obvious baseline based on kNN-LM ( Khandelwal et al.2019 ) , which is explicitly motivated as a way to add knowledge to transformer language models . For example : first , you could simply encode your the sentence modified facts with the transformer , masking out the modified words . For inference , you could copy a token from the modified facts if it is sufficiently close in representation space , and otherwise predict a token using the baseline transformer model . More generally , non-parametric methods appear to offer a relatively simple and obvious solution to the task , as facts can be updated by just changing the text . These approaches should be discussed further . Minor Points The paper contains frequent grammatical errors ( too many to list here ) , and I 'd recommend getting it thoroughly proof read before publication . This did not affect my rating .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your review and suggestions ! We are glad that you find the modification problem worthwhile studying . We agree that having more baselines adds to the strength of the paper , but the non-parametric kNN-LM may not be a strong baseline for the modification task . Please refer to the details below . * \u201c Surprisingly , the authors further show that it is harder to modify knowledge in the partially symbolic 'Facts as Experts ' model than it is in BERT. \u201d * To clarify , by \u201c We find that it is not easier to modify the memorized facts of memory networks like FaE \u201d , we were trying to express that modifying FaE to obtain the same level of accuracy on the modified facts ( around 78 % in the setting of modifying 32 facts ) requires almost the same or even more drop in the accuracy on the unmodified facts than the BERT-Large model in the experiments we have tried . FaE has a 10 % higher test accuracy from the beginning , so the overall ( weighted ) accuracy of FaE is still the best among the models . * \u201c I struggled to find any detail on how the authors enforce these constraints during optimization , and this point should be made clearer. \u201d * We have included the details for solving the constrained optimization with norm constraints on the weights in Appendix D in the revised version . * \u201c I 'd be really interested to see some more analysis that sheds light on which parameters the transformer is using to store facts ... For example , you could try fine-tuning just the word embedding layer , or only the feed forward sub-layers. \u201d * Our current result does shed light on which parameter the Transformer is using to \u201c store \u201d facts , indicated by the effectiveness of each Transformer block for modifying the memory . The landscape is more complicated than we have imagined . We find that it depends on the state of the model , the number of facts to modify , and the finetuning approach . First , the FT process shifts the most effective layer for modification from Block 0 to Block 11 for the BERT-Base model when modifying 32 facts on T-REx ( Table 2 and 3 in the current version ) . Second , as the number of modified facts increases , the most effective layer also changes . In Figure 4 of the current version , we find that for FTM and FT+FTM without constraints , when we modify more than 512 facts , Block 5 turns out to be the most effective one . In Figure 2 and 3 , we find that , with constraints , using 512 facts shifts the most effective block from Block 11 back to Block 0 . We had experimented with fine-tuning only the feedforward layers instead of finetuning whole Transformer blocks , and the results were not as good as the one presented in the paper . We will post results with finetuning the embedding layers when the results are available ."}, "1": {"review_id": "KubHAaKdSr7-1", "review_text": "The paper proposes a very interesting yet practical problem of modifying the memory encoded in transformer weight to unlearn some facts and update with new facts . This paper seems to be a follow-up work from FAE , which encodes symbolic facts in memory for retrieval . Generally speaking , I like the basic idea of this paper and it might have a broad impact on the whole community . However , there are still a lot of questions about the paper . 1 ) the paper seems to be written in a rush without refining , there are numerous serious typos and spellings errors , which affect my understanding a lot . For example , in 4.5.1 , what is `` RT '' , is it supposed to be `` RI '' ? In Figure 3 , why is the 32 , the figures are a mess . Why is the left showing `` 32- > 512 '' while the right showing `` 32- > 128 '' ? Why do you say it 's sharp degrading , it 's not that sharp reflected from Figure 3 . I 'm not sure if I misunderstand something . 2 ) The results are also quite messy . The algorithm without constrained optimization has its results reported in the table , while the algorithm with constrained optimization is reported in figures . The results with FAE is yet in another table far away . It 's hard for me to compare them and draw a consistent conclusion . Is it possible to aggregate all the main results in one table and demonstrate all the ablation studies using Figures ? Currently , the figures involved in 4.5.2 are distributed from page 6 - page 8 , is it possible to aggregate them in a concentrated place ? 3 ) Besides these details , I think the proposed method is somewhat `` not novel '' . In lifelong learning or meta-learning community , such constrained optimization algorithms have been explored for a few years to prevent the mode from catastrophic forgetting . I do n't think the paper makes any significant contribution to this aspect . 4 ) Overall , I still quite like the scope of this paper . I would like to see a more structured and clear version of the paper with more fundamental algorithm innovation .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for highlighting the importance of the problem we are studying ! We have revised the paper to correct the typos . To address your concerns : * \u201c ... in 4.5.1 , what is `` RT '' , is it supposed to be `` RI '' ? In Figure 3 .... Why is the left showing `` 32- > 512 '' while the right showing `` 32- > 128 '' ? Why do you say it 's sharp degrading , it 's not that sharp reflected from Figure 3 . \u201d * 1.Yes , it was our mistake . \u201c RT \u201d should be \u201c RI \u201d . 2.Figure 3 ( now Figure 2 ) serves to show the effect of the number of modified facts on the results . For BERT-Base we compare the results of modifying 32 facts with modifying 512 facts . For BERT-Base we compared modifying 32 facts with modifying 128 facts . We will include more consistent comparisons in our future version . 3.For example , for BERT-Base , if we modify 32 facts , the accuracy on the unmodified facts is around 45 % . If we modify 512 facts , the best accuracy on unmodified facts drops to only 20 % , which we think is quite a sharp decline . Similarly , the accuracy on the unmodified facts dropped by around 10 % when modifying 128 instead of 32 facts for BERT-Large . * \u201c Is it possible to aggregate all the main results in one table and demonstrate all the ablation studies using Figures ? Currently , the figures involved in 4.5.2 are distributed from page 6 - page 8 , is it possible to aggregate them in a concentrated place ? \u201d * We have aggregated the best results of the main models and settings in Table 2 in the current version . We have also rearranged the tables and figures to be closer to their text mentions . * \u201c Besides these details , I think the proposed method is somewhat `` not novel '' . In lifelong learning or meta-learning community , such constrained optimization algorithms have been explored for a few years to prevent the mode from catastrophic forgetting. \u201d * The primary goal of our paper is to propose the research problem of how one can modify the facts ( implicitly ) memorized by Transformer models and construct benchmarks with reasonable baselines . To the best of our knowledge , this is the first work studying the reliable and efficient modification of the factual knowledge memorized by Transformers . One of our interesting findings is that the constrained optimization approach is surprisingly effective , despite its simplicity . There is still a huge room for future works to explore in this newly proposed research area though . We have added comparisons with lifelong learning to the related works section of our current version . We emphasize that our setting is different from lifelong learning in that it not only requires preserving the performance on the unmodified facts but also requires changing the predictions on the modified facts , causing conflicts with previously learned parameters . Some existing lifelong learning methods may face new challenges in our setting , e.g. , we need to update the Gradient Episodic Memory ( Lopez-Paz & Ranzato , 2017 ) or the Conceptors ( Liu et al. , 2019 ) on all previous tasks . Computing the Fisher information matrix is also challenging given the size of the models and datasets we evaluated . We have evaluated not only the constrained optimization approach but also the role of different layers and the impact of using a mixture of modified and unmodified evidences . We also consider knowledge-augmented networks in our setting , which is not a focus of existing lifelong learning methods . This part not only involves the constrained optimization but also the explicit modification of symbolic links of FaE . We provide a more detailed evaluation for knowledge modification than the original FaE paper , involving finetuning different layers of the model to achieve better results , and show that modifying the symbolic link is not enough ; we also need to modify implicit memories stored in their parameters to obtain high accuracy on modified facts . Previously , the FaE paper only reported one negative result for modifying the symbolic links on one subset of facts ."}, "2": {"review_id": "KubHAaKdSr7-2", "review_text": "This paper studies a new problem : evaluating the ability of modifying knowledge inside the Transformer models when models memorize world knowledge inside its parameters . The contribution of this paper is two-fold : ( 1 ) introducing a new benchmark for evaluating such ability , and ( 2 ) evaluating a comprehensive list of baselines , including a new model that has a constraint term in the objective during fine-tuning . Strengths of the paper : 1 . The problem is well-motivated and of interest to the wider community . Examining the behavior of transformers given updated facts is a timely topic , given recent progress and interest in large pretrained models storing world knowledge and achieving reasonable performance on downstream tasks ( slot infilling , question answering ) without access to external knowledge sources . 2.The benchmark dataset is created in a reasonable way - it is created on top of T-REx and Zero-shot RE dataset , where a target entity is replaced by another entity that shares the same relation with the other entity . 3.The constrained objective provides a simple yet nice way of updating knowledge in the model parameters in a constrained manner . This model shows that the fine-tuned model overfits less to the modified knowledge , compared to naive baselines . Weaknesses of the paper : 1 . I am not fully convinced by the setup in the paper , where the model is pretrained on unmodified facts and then fine-tuned on a modified knowledge . First , in a natural setting , a set of knowledge sources will always contain both unmodified facts and modified facts together . Therefore , an assumption in the paper that the model can only access modified facts during fine-tuning seems to be unrealistic . Second , if the research question here is the generalization ability of the model , isn \u2019 t a zero-shot setting or a setting with small training examples ( e.g.1k ) more suitable ? 2.Although the creation process of the benchmark dataset makes sense , it is still created synthetically . Furthermore , the paper does not include data analysis or human performance estimation , making it hard to estimate the quality of the data . This is important because , when a subset of knowledge was synthetically updated , some knowledge will contradict each other . 3.Although the model with constrained objective overfits less to the modified knowledge , it still overfits a lot , achieving significantly lower numbers on unmodified facts . It is still a nice baseline , but the claim in the paper : \u201c best way to enforce the constraint in Transformer models \u201d ( Sec 1 ) seems to be overclaiming . 4.Although the paper includes comprehensive experiments , there is n't really new take-aways that are not different from naive expectations . The conclusion , `` the model overfits to modified facts and suffers from catastrophic forgetting '' is pretty naive and has been observed in a lot of prior work ( [ 1 ] is one of recent ones ) . Questions 1 . Is there a specific reason that the scope of this paper is restricted to transformers ? Looks like the general idea can be applied to any model that does not have an access to external knowledge source ? 2.The creation process of the benchmark data is strictly limited to structured KBs . Is there a way to create such a dataset for tasks based on unstructured text ? 3.Are there baseline numbers for PT+FT ( without FTM ) reported ? [ 1 ] Rolnick et al.Experience replay for continual learning . NeurIPS 2019 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for acknowledging the contributions of our paper ! Below we address your concerns . * \u201c I am not fully convinced by the setup in the paper , where the model is pretrained on unmodified facts and then fine-tuned on a modified knowledge . First , in a natural setting , a set of knowledge sources will always contain both unmodified facts and modified facts together . Therefore , an assumption in the paper that the model can only access modified facts during fine-tuning seems to be unrealistic . Second , if the research question here is the generalization ability of the model , isn \u2019 t a zero-shot setting or a setting with small training examples ( e.g.1k ) more suitable \u201d * We have definitely tried to provide the model with both modified facts and unmodified facts in the modification process , see section 4.5.3 and Table 4 ( originally in the appendix ) . Surprisingly , this did not improve the model \u2019 s performance on the averaged accuracy , compared to providing the model with only modified facts and using constrained optimization . Only using the modified facts in the modification process is a more efficient approach and it is not difficult to just pick the supporting evidences of modified facts . Also , to clarify , in the FT process , we finetuned the model on the whole original training set of T-REx/zsRE , not just the facts that will not be modified . The \u201c generalization ability \u201d in this work refers to the ability to generalize to different paraphrases of the same question , e.g. , the model generalizes well if it gives the same answers to \u201c What is the continent that Della Pia Glacier is located ? \u201d in the training set and \u201c What continent is Della Pia Glacier found on ? \u201d in the test set . Therefore , we construct datasets so that the training set covers all the facts in the test sets , but their questions are asked in different ways . It is almost impossible for a model without memory modules to answer factual questions if the model was never trained on samples entailing the fact and implicitly memorized the fact , so the traditional zero-shot setting does not seem practical in our case . We are already operating in the small-training-samples regime as you suggested . During the modification process , we indeed use only a small set ( up to thousands ) of training samples for modified facts . * \u201c ... the paper does not include data analysis or human performance estimation , making it hard to estimate the quality of the data . This is important because , when a subset of knowledge was synthetically updated , some knowledge will contradict each other. \u201d * Thanks for pointing out the need for human performance evaluation . However , we believe our current setting does not introduce conflicts with other facts , indicated by the results with FaE , where we see no drop in accuracy on unmodified facts after we modify its symbolic links for the modified facts ( Table 5 , \u201c None \u201d in current version ; also included in the previous version ) . This is probably because we only modify the object of the facts and the current datasets does not contain multiple possible objects for each subject-relation pair . * \u201c ... best way to enforce the constraint in Transformer models \u201d ( Sec 1 ) seems to be overclaiming. \u201d * We have rephrased the sentence into \u201c We formulate the knowledge modification as a constrained optimization problem with a constraint on the loss on the unmodified facts and explore better baseline methods to approximately enforce this constraint. \u201d We would like to emphasize that the simple norm constraint is not only efficient but also surprisingly effective compared to other methods we have tried . * \u201c the model overfits to modified facts and suffers from catastrophic forgetting '' is pretty naive and has been observed in a lot of prior work ( [ 1 ] is one of recent ones ) \u201d * We agree the phenomenon does look similar to prior works on continual learning , but the modification task is different from continual learning in that the modified facts conflict with the original training data , which means the model can not preserve its behavior on all the previously learned facts . It is a new challenge to existing continual learning algorithms . Please refer to the last paragraph of the related works section ( Section 2 ) in the new version for a detailed discussion ."}, "3": {"review_id": "KubHAaKdSr7-3", "review_text": "Summary Recently , pretrained Transformer language models have been shown to capture world knowledge ( using testbeds containing facts ) . What if you want to update a fact , for example , with the current president of USA ? This paper investigates different approaches to update the weights of a Transformer model such that the model works for the modified facts but does not catastrophically forget unmodified facts . The main proposal is a simple regularization technique ( which they call constrained fine-tuning ) to minimize weight changes while fine-tuning on the supporting factual sentences that represent the modified facts . Strengths 1 . The problem of updating world knowledge in Transformers in itself is an interesting problem and novel . 2.The problem is well motivated and the first half of the paper is well-written . 3.The proposed method of fine-tuning along with regularization is simple and it seems to work better than just fine-tuning methods . Weaknesses : 1 . Confusing experimental section , and many important details are missing ( see comments ) . 2.The paper felt like it is a last-minute submission and written in haste . 3.Important related work on retrofitting literature not cited . 4.The proposed method works at the cost of forgetting unmodified facts as the number of unmodified facts increase . Comments : Although the reviewer likes the problem formulation and the main idea , they find it hard to follow the experimental section . 1.There were no details on how to find supporting sentences of target facts that one wants to change . This is a non-trivial task and without a detailed description , the paper is impossible to replicate . There were no examples anywhere including appendix . 2.Why do the authors start with pretrained + fine-tuned model ? Is n't pretrained model trained on all sentences anyways ? Do they mean separate fine-tuned data that contain factual statements ? Why does one need this data ? Is n't this against the spirit of pretrained models as knowledge bases ? 3.Results of vanilla pretrained models on unmodified and modified facts missing , i.e. , PT alone . Also , PT + FT. 4 . The notation and acronyms are confusing . The authors use a lot of acronyms like PT , FT , FTA , FTM , RT which is unnecessary . This makes the results table unreadable without reading the paper . 5.No citations on retrofitting literature which is very similar idea to this work ( e.g. , Faruqui et al.2015 ) .This limits the novelty of the work but the reviewer give credits to the problem formulation . 6.How is PT+FT+FTM different from PT + D_F ' ? 7.FTA is introduced but never used . 8.The reviewer had a hard time following experiments with FAE section . What is the main takeaway from these experiments ? The model has to be described in detail ( perhaps with a figure ) . 9.Examples , Examples , Examples . Show some examples from each dataset .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your valuable feedback . We are glad that you find this task novel and interesting . We have revised the paper and added discussions about retrofitting literature into the related works . We believe the readability of this work is significantly improved in the updated version . Below we address your concerns . * \u201c There were no details on how to find supporting sentences of target facts that one wants to change \u201d * In T-REx and zsRE , each supporting sentence is already linked to a fact so we did not need to find them . More specifically , each fact of the T-REx dataset has at least one supporting evidence and one template cloze question , and we use the supporting evidences and the cloze question to construct the training and test sets . For zsRE , we put the questions of a fact into training and test sets if the fact has multiple annotated questions , or keep it in the training set if it is the only question for the fact . We have added more details about the data creation process in Appendix A . In the future , if we were to build similar benchmarks using a completely unstructured corpus , we can use retrieval techniques to find supporting evidences for any fact within the corpus . This may not be perfect , but we can augment it with synthetic evidences constructed from various templates for the facts . Our benchmark and modification methods can work as long as we provide enough supporting evidences for the model to learn . * \u201c Why do the authors start with pretrained + fine-tuned model ? Is n't pretrained model trained on all sentences anyways ? Do they mean separate fine-tuned data that contain factual statements ? Why does one need this data ? Is n't this against the spirit of pretrained models as knowledge bases ? \u201d * The pretrained model refers to off-the-shelf BERT-Base models pretrained on the Wikipedia Corpus and the Bookcorpus . For finetuning ( FT ) , we finetune the model on all the supporting evidences of T-REx or zsRE , which improves the accuracy of BERT-Base by e.g.20 % on T-REx . The improved accuracy after the finetuning process allows us to explore the more ideal setting where a language model has good performance on the questions and is ready to be deployed in practice . This also allows us to choose the facts to be modified from a larger set of facts , because we only modify facts that the model has already learned correctly . * \u201c Results of vanilla pretrained models on unmodified and modified facts missing , i.e. , PT alone . Also , PT + FT. \u201d * We have added these results into Table 2 of the current version . * \u201c The notation and acronyms are confusing . The authors use a lot of acronyms like PT , FT , FTA , FTM , RT which is unnecessary . This makes the results table unreadable without reading the paper. \u201d * We have revised our experiment section to improve the readability . * \u201c No citations on retrofitting literature which is very similar idea to this work ( e.g. , Faruqui et al.2015 ) . \u201d * We have added discussions in the related works . While retrofitting does seem similar to our work in using facts/knowledge to finetune the models , the goals are different . We aim at changing the prediction of the models while preserving its performance on unmodified facts , whereas retrofitting aims to obtain better word representations using relations . * \u201c How is PT+FT+FTM different from PT + D_F ' ? FTA is introduced but never used. \u201d * Our previous version has results for PT+FT+FTA in Table 4 in the appendix ( now still Table 4 but denoted as FT+FTA ) . We have also added PT+FTA and PT+FTM in Table 2 ( now denoted as FTA and FTM ) . Our preliminary experiments with BERT-Base show that , in comparison with PT+FT+FTM , PT+D_F \u2019 ( drawing random batches from D_F \u2019 and finetuning on D_F \u2019 without any constraint ) has a higher accuracy on the unmodified facts ( around 50 % ) , but its accuracy on the modified facts is also around 50 % , lower than the current results on the modified facts . In our scenario , we want a higher accuracy on the modified facts . Also , as can be seen in Table 2 in the current version , if we use a mixture of the modified and unmodified facts in each minibatch from D_F \u2019 and enforce the norm constraints , we can improve the accuracy on the unmodified facts in the FT+FTA setting ( previously noted as PT+FT+FTA ) . That said , we would like to note that the result of FT+FTA ( previously denoted as PT+FT+FTA ) is still not as good as FT+FTM ( previously denoted as PT+FT+FTM ) ."}}