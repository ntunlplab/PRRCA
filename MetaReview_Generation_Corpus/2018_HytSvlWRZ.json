{"year": "2018", "forum": "HytSvlWRZ", "title": "Subspace Network: Deep Multi-Task Censored Regression for Modeling Neurodegenerative Diseases", "decision": "Reject", "meta_review": "Authors present a method for modeling neurodegenerative diseases using a multitask learning framework that considers \"censored regression\" problems (to model where the outputs have discrete values and ranges). Given the pros/cons, the committee feels this paper is not ready for acceptance in its current state.\n\n\nPro:\n- This approach to modeling discrete regression problems is interesting and may hold potential, but the evaluation is not in a state where strong meaningful conclusions can be made.\n\nCon:\n- Reviewers raise multiple concerns regarding evaluation and comparison standards for tasks. While authors have added some model comparisons in response, in other areas comparisons don't appear complete. For example, when using MRI data, networks compared all use features derived from images, rather than systems that may learn from images themselves. Authors claim dataset is too small to learn directly from pixels in this data (in comments), but transfer learning and data augmentation have been successfully applied to learn from datasets of this size. In addition, new multitask techniques in the imaging domain have also been presented that dynamically learn the network structure, rather than relying on a hand-crafted neural network design. How this approach would compare is not addressed.\n\n\n", "reviews": [{"review_id": "HytSvlWRZ-0", "review_text": "This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases. Differently from previous applications of machine learning in neurodegeneration modeling, the proposed approach models the clinical data accounting for the bounded nature of cognitive tests scores. The framework is represented by a feed-forward deep architecture analogous to a residual network. At each layer a low-rank constraint is enforced on the linear transformation, while the cost function is specified in order to differentially account for the bounds of the predicted variables. The idea of explicitly accounting for the boundedness of clinical scores is interesting, although the assumption of the proposed model is still incorrect: clinical scores are defined on discrete scales. For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application. Furthermore, while being the main methodological drive of this work, the paper does not show evidence about improved predictive performance and generalisation when accounting for the boundedness of the regression targets. The proposed algorithm is also generally compared with respect to linear methods, and the authors could have provided a more rigorous benchmark including standard non-linear prediction approaches (e.g. random forests, NN, GP, \u2026). Overall, the proposed methods seems to provide little added value to the large amount of predictive methods proposed so far for prediction in neurodegenerative disorders. Moreover, the proposed experimental paradigm appears flawed. What is the interest of predicting baseline (or 6 months at best) cognitive scores (relatively low-cost and part of any routine clinical assessment) from brain imaging data (high-cost and not routine)? Other remarks. - In section 2.2 and 4 there is some confusion between iteration indices and samples indices \u201ci\u201d. - Contrarily to what is stated in the introduction, the loss functions proposed in page 3 (first two formulas) only accounts for the lower bound of the predicted variables. - Figure 2, synthetic data. The scale of the improvement of the subspace difference is quite tiny, in the order of 1e-2 when compared to U, and of 1e-5 across iterations. The loss function of Figure 2.b also does not show a strong improvement across iterations, while indicating a rather large instability of the optimisation procedure. These aspects may be a sign of convergence issues. - The dimensionality of the subspace representation importantly depends on the choice of the rank R of U and V. This is a crucial parameters that is however not discussed nor analysed in the paper. - The synthetic example of page 7 is quite misleading and potentially biased towards the proposed model. The authors are generating the synthetic data according to the model, and it is thus not surprising that they managed to obtain the best performance. In particular, due to the nonlinear nature of (1), all the competing linear models are expected to perform poorly in this kind of setting. - The computation time for the linear model shown in Table 3 is quite surprising (~20 minutes for linear regression of 5k observations). Is there anything that I am missing? ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks very much for your suggestions . We have addressed all your concerns below . Most notably , we have significantly enriched our experiments to testify the performance advantages of SN over DNNs in real data , and to analyze how much each component ( censored , low-rank , and online feed-forward training ) accounts for this performance gain . We have also revised our paper and corrected typos . Overall , we hope that our revised version has manifested its value as a unique and effective predictive method of neurodegenerative disorders . Q1 : Clinical scores are defined on discrete scales : the Gaussian assumption for the cost function is thus not appropriate for the proposed application . A1 : As defined in ( 1 ) , the Gaussian assumption is not enforced on the scores , but on the noise \\epsilon that we assume in the latent space . It is a standard assumption in subspace sensing , and the standard deviation hyperparameter controls how accurately the low-rank subspace assumption can fit the data . It does not solely determine the distribution of y , and other noise models can also be assumed here . We apologize for the confusion and have revised the paper to make it clearer . Q2 : The paper does not show evidence about improved predictive performance and generalization when accounting for the target boundedness A2 : We extended experiments to compare results between considering target boundedness ( Censored ) and not ( Uncensored ) for both single-task and multi-task models . In either scenario , we reported the best performance ( LS+L1 for single task and Multi Trace for multi-task in our case ) in Table 2 . In the revised version , we further compared SN with several DNN baselines , where the benefit of setting censored regression goals is also found to be evident in DNN settings . Please see next response for details . Q3 : The authors should provide a more rigorous benchmark including non-linear prediction approaches A3 : As suggested , we compared with three DNN baselines ( naive , with censoring , and with censoring + low-rank ) for both synthetic and real data in the paragraph \u201c Benefits of Going deep \u201d in Section 4.1 and \u201c Performance \u201d in Section 4.2 of the revised paper , in addition to the existing nonlinear Tobit censored regression model . The comparisons of three baselines indicate that both censored regression and low-rank assumption improve DNN \u2019 s performance on the given MTL task . Meanwhile , SN clearly outperforms all three , even DNN equipped with censoring + low-rank , suggesting the advantage of our proposed online one-pass sensing and feed-forward training strategy . The performance advantage of SN over DNNs is also confirmed across different rank assumptions in Table 8 in Appendix . Q4 : What is the interest of predicting baseline ( or 6 months at best ) cognitive scores from brain imaging data ? A4 : Thanks for pointing out . We have revised the paper to refer readers interested in this setting to relevant clinical references . The predictive modeling paradigm that we used in the paper is a rather common setting in clinical studies of neurodegenerative diseases such as Alzheimer \u2019 s disease ( AD ) , e.g. , [ 1 ] Stonnington , C. M. , Chu , C. , Kl\u00f6ppel , S. , Jack , C. R. , Ashburner , J. , Frackowiak , R. S. , & Alzheimer Disease Neuroimaging Initiative . ( 2010 ) .Predicting clinical scores from magnetic resonance scans in Alzheimer 's disease . Neuroimage , 51 ( 4 ) , 1405-1413 . [ 2 ] Orr\u00f9 , G. , Pettersson-Yeo , W. , Marquand , A. F. , Sartori , G. , & Mechelli , A . ( 2012 ) .Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease : a critical review . Neuroscience & Biobehavioral Reviews , 36 ( 4 ) , 1140-1152 . [ 3 ] Zhang , D. , Shen , D. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2012 ) .Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer 's disease . NeuroImage , 59 ( 2 ) , 895-907 . [ 4 ] Zhou , J. , Liu , J. , Narayan , V. A. , Ye , J. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2013 ) .Modeling disease progression via multi-task learning . NeuroImage , 78 , 233-248 . The rationale behind this setting is as follows . For example , the diagnosis of AD requires autopsy confirmation , which is not applicable on live patients . Hence many cognitive measures have been designed to evaluate the cognitive status of a patient . These measures are important criteria for clinical diagnosis of probable AD . These cognitive status/scores can be considered as phenotypes that are tangled with complicated neurological pathologies in the brain . Currently there are many hypotheses the pathological pathways of AD progression over time , but we are far from understanding the ultimate cause and thus the studies of associations between cognitive scores and neuroimages are critical in understanding the progression and predictability of the disease . The models can reveal important insights and may lead to novel target for therapeutic intervention and drug developments ."}, {"review_id": "HytSvlWRZ-1", "review_text": "The authors propose a DNN, called subspace network, for nonlinear multi-task censored regression problem. The topic is important. Experiments on real data show improvements compared to several traditional approaches. My major concerns are as follows. 1. The paper is not self-contained. The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1. However, for some key steps in the proof, they refer to other references. If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix. 2. The experiments are unconvincing. They compare the proposed SN with other traditional approaches on a very small data set with 670 samples and 138 features. A major merit of DNN is that it can automatically extract useful features. However, in this experiment, the features are handcrafted before they are fed into the models. Thus, I would like to see a comparison between SN with vanilla DNN. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks very much for your suggestions . We have addressed all your concerns below . Q1.The paper is not self-contained . The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1 . However , for some key steps in the proof , they refer to other references . If this is due to space limitation in the main text , they may want to provide a complete proof in the appendix . A1 : Thanks very much for your comment . In Appendix of the revised paper , please find the more detailed long version of the proof outlines of both asymptotic and non-asymptotic convergence properties in Appendix . We expect that the new proof has better self-containedness . At some steps of the proof , we pointed to the important key results to refer to ( in precise forms , e.g. , Lemma 2 of Mardani et al . ( 2013 ) ) .In order to focus on the key contribution of this paper , we did not include the detailed assumptions and proofs of all those intermediate theorems/lemma that we used . The reasons are : ( 1 ) they can be very lengthy ; ( 2 ) they were well-established results in other relevant literature and were not our innovations ; ( 3 ) those intermediate results were not tightly related the main contributions of this paper ( SN model ) . We believe that the current proof outline has already captured all main proof ideas and should be easy to follow for readers of interests . Q2.The experiments are unconvincing . They compare the proposed SN with other traditional approaches on a very small data set with 670 samples and 138 features . A major merit of DNN is that it can automatically extract useful features . However , in this experiment , the features are handcrafted before they are fed into the models . Thus , I would like to see a comparison between SN with vanilla DNN . A2 : Thanks for your comments . We agree that one major merit of DNN is to automatically extract features from images , that demonstrated huge success in many domains . Such capability is based on the availability of large labeled training data . In the medical research domain , however , such labeled data is rarely available , especially in the challenging disease of neurodegenerative diseases such as Alzheimer \u2019 s disease ( AD ) and Parkinson . The ADNI data used in our paper is so far the largest cohort collected for Alzheimer \u2019 s disease study , and however has less than 1000 patients available for building predictive models due to the expensive data collection process . Due to extreme high dimension of an MRI image ( voxel size : 512x512x16 = 4,194,304 ) , most studies use region-of-interests features extracted by existing neuroimaging tools , instead of raw imaging data for studying progression of a disease . As such , a majority amount of AD study performs predictive modeling using extracted features : [ 1 ] Duchesne , S. , Caroli , A. , Geroldi , C. , Collins , D. L. , & Frisoni , G. B . ( 2009 ) .Relating one-year cognitive change in mild cognitive impairment to baseline MRI features . Neuroimage , 47 ( 4 ) , 1363-1370 . [ 2 ] Stonnington , C. M. , Chu , C. , Kl\u00f6ppel , S. , Jack , C. R. , Ashburner , J. , Frackowiak , R. S. , & Alzheimer Disease Neuroimaging Initiative . ( 2010 ) .Predicting clinical scores from magnetic resonance scans in Alzheimer 's disease . Neuroimage , 51 ( 4 ) , 1405-1413 . [ 3 ] Orr\u00f9 , G. , Pettersson-Yeo , W. , Marquand , A. F. , Sartori , G. , & Mechelli , A . ( 2012 ) .Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease : a critical review . Neuroscience & Biobehavioral Reviews , 36 ( 4 ) , 1140-1152 . [ 4 ] Zhang , D. , Shen , D. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2012 ) .Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer 's disease . NeuroImage , 59 ( 2 ) , 895-907 . [ 5 ] Zhou , J. , Liu , J. , Narayan , V. A. , Ye , J. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2013 ) .Modeling disease progression via multi-task learning . NeuroImage , 78 , 233-248 . We also improve our experiments by comparing with three DNN baselines ( naive , with censoring , and with censoring + low-rank ) in both synthetic and real data , please refer to the new paragraph \u201c Benefits of Going deep \u201d in Section 4.1 and \u201c Performance \u201d in Section 4.2 in the revised paper . The comparisons of three baselines indicate that both censored regression and low-rank assumption improve DNN \u2019 s performance on the given MTL task . Meanwhile , Subspace Network clearly outperforms all three , even DNN equipped with censoring + low-rank , suggesting the advantage of our proposed online one-pass sensing and feed-forward training strategy . The performance advantage of Subspace Network is confirmed across different rank assumptions , and across both synthetic and real data ."}, {"review_id": "HytSvlWRZ-2", "review_text": "This paper presents a new multi-task network architecture within which low-rank parameter spaces were found using matrix factorization. As carefully proved and tested, only one pass of the training data would help recover the parametric subspace, thus network could be easily trained layer-wise and expanded. Some novel contributions: 1. Layer by layer feedforward training process, no back-prop. 2. On-line settings to train parameters ( guaranteed convergence in a single pass of the data) Weakness : 1. The assumption that a low-rank parameter space exists among tasks rather than original feature spaces is not new and widely used in literature. 2. The proof part(Section 2.2) can be extended with more details in Appendix. 3. In synthetic data experiments (Table1), only small margins could be observed between SN, f-MLP and rf-MLP, and only Layer 1 of SN performs better above all others. 4. Typo: In Table2,3,5, Multi-l_{2,1} (denotes the L2,1 norm) were written wrong. 5. In the synthetic data experiments on comparison with single-task and multi-task models, counter-intuitive results (with larger training data split, ANMSE raises instead of decreases) of multi-task models may need further explanation. 6. Extra models like Deep Networks with/without matrix factorization could be added. ( As proposed model is a deep model, the lack of comparison with deep methods is dubious) 7. In Section 4.2, the real dataset is rather small thus the results on this small dataset were not convincing enough. SN model outperforms the state-of-the-art with only small margin. Extensive experiments could be added. 8. The performance on One-Layer Subspace Network (with only the input features) could be added. Conclusion: Though with a quite novel idea on solving multi-task censored regression problem, the experiments conducted on synthetic data and real data are not convincing enough to ensure the contribution of the Subspace Network. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks very much for appreciating the novelty of our work , and for your very insightful and constructive comments . We have addressed all your questions below . In particular , we have significantly enriched our experiments as suggested . All results consistently suggest the performance advantage and robustness of Subspace Network over state-of-art linear /nonlinear methods , as well as DNNs . We have also revised the paper and corrected typos . Q1 : The assumption that a low-rank parameter space exists among tasks rather than original feature spaces is not new . A1 : SN was mainly built on the work series of online subspace sensing , where low-rank assumption was enforced on the input space , e.g. , Mardani et al . ( 2015 ) , Shen et al . ( 2016 ) .Motivated by the popularity of low-rank parameter space in MTL , we introduced the first-of-its-kind combination of online subspace sensing ( mostly focusing on input space ) , and low-rank parameter assumption for MTL : we believe their marriage to be new . Q2 : The proof part ( Section 2.2 ) can be extended with more details in Appendix . A2 : We \u2019 ve extended more detailed proof outlines in Appendix . At some steps of the proofs , we point to the important key result to refer to . Proofs are provided for self-containedness only . Q3 : In synthetic data experiments ( Table1 ) , only small margins could be observed between SN , f-MLP and rf-MLP , and only Layer 1 of SN performs better above all others . A3 : We have provided additional experimental results after further tuning all three networks . In addition to subspace difference , we added two new metrics : ( 1 ) the maximum mutual coherence of all column pairs from two matrices , as a classical measurement on how correlated the two matrices ' column subspaces are ; ( 2 ) the mean mutual coherence of all column pairs from two matrices . Note that the two mutual coherence-based metrics are more robust since they are immune to linear transformations of subspace coordinates , to which the L2-based subspace difference is not immune to . Results can be found in Table 1 , showing the clear advantage of SN over f-MLP and rf-MLP under all three metrics . The performance margins of SN in terms of maximum/mean mutual coherences are remarkably more visible than under L2-based difference . Q4 : In the synthetic data experiments on comparison with single-task and multi-task models , counter-intuitive results ( with larger training data split , ANMSE raises instead of decreases ) of multi-task models may need further explanation . A4 : Thanks so much for pointing out . We found there were numerical convergence issues with the optimization algorithms for MTL models . We have fixed the problem and updated the results in Table 3 , where the performance turns now intuitive . We also extended our experiments to compare results between considering target boundedness ( Censored ) and not ( Uncensored ) for both single-task and multi-task models . In either scenario , we reported the best performance ( LS+L1 for single task linear , and Multi Trace for multi-task in our case ) in Table 2 . Q5 : Extra models like Deep Networks with/without matrix factorization could be added . A5 : Thanks very much for your suggestion . We have added them as suggested . Please refer to the new paragraph \u201c Benefits of Going deep \u201d in Section 4.1 and \u201c Performance \u201d in Section 4.2 in the revised paper . In sum , we compared with three DNN baselines ( naive , with censoring , and with censoring + low-rank ) for both synthetic and real data . The comparisons of three baselines indicated that both censored regression and low-rank assumption improved DNN \u2019 s performance on the given MTL task . Meanwhile , SN clearly outperformed all three , even DNN equipped with censoring + low-rank , suggesting the advantage of our proposed online one-pass sensing and feed-forward training strategy . The performance advantage of SN over DNNs was confirmed across different rank assumptions , and across both synthetic and real data ."}], "0": {"review_id": "HytSvlWRZ-0", "review_text": "This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases. Differently from previous applications of machine learning in neurodegeneration modeling, the proposed approach models the clinical data accounting for the bounded nature of cognitive tests scores. The framework is represented by a feed-forward deep architecture analogous to a residual network. At each layer a low-rank constraint is enforced on the linear transformation, while the cost function is specified in order to differentially account for the bounds of the predicted variables. The idea of explicitly accounting for the boundedness of clinical scores is interesting, although the assumption of the proposed model is still incorrect: clinical scores are defined on discrete scales. For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application. Furthermore, while being the main methodological drive of this work, the paper does not show evidence about improved predictive performance and generalisation when accounting for the boundedness of the regression targets. The proposed algorithm is also generally compared with respect to linear methods, and the authors could have provided a more rigorous benchmark including standard non-linear prediction approaches (e.g. random forests, NN, GP, \u2026). Overall, the proposed methods seems to provide little added value to the large amount of predictive methods proposed so far for prediction in neurodegenerative disorders. Moreover, the proposed experimental paradigm appears flawed. What is the interest of predicting baseline (or 6 months at best) cognitive scores (relatively low-cost and part of any routine clinical assessment) from brain imaging data (high-cost and not routine)? Other remarks. - In section 2.2 and 4 there is some confusion between iteration indices and samples indices \u201ci\u201d. - Contrarily to what is stated in the introduction, the loss functions proposed in page 3 (first two formulas) only accounts for the lower bound of the predicted variables. - Figure 2, synthetic data. The scale of the improvement of the subspace difference is quite tiny, in the order of 1e-2 when compared to U, and of 1e-5 across iterations. The loss function of Figure 2.b also does not show a strong improvement across iterations, while indicating a rather large instability of the optimisation procedure. These aspects may be a sign of convergence issues. - The dimensionality of the subspace representation importantly depends on the choice of the rank R of U and V. This is a crucial parameters that is however not discussed nor analysed in the paper. - The synthetic example of page 7 is quite misleading and potentially biased towards the proposed model. The authors are generating the synthetic data according to the model, and it is thus not surprising that they managed to obtain the best performance. In particular, due to the nonlinear nature of (1), all the competing linear models are expected to perform poorly in this kind of setting. - The computation time for the linear model shown in Table 3 is quite surprising (~20 minutes for linear regression of 5k observations). Is there anything that I am missing? ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks very much for your suggestions . We have addressed all your concerns below . Most notably , we have significantly enriched our experiments to testify the performance advantages of SN over DNNs in real data , and to analyze how much each component ( censored , low-rank , and online feed-forward training ) accounts for this performance gain . We have also revised our paper and corrected typos . Overall , we hope that our revised version has manifested its value as a unique and effective predictive method of neurodegenerative disorders . Q1 : Clinical scores are defined on discrete scales : the Gaussian assumption for the cost function is thus not appropriate for the proposed application . A1 : As defined in ( 1 ) , the Gaussian assumption is not enforced on the scores , but on the noise \\epsilon that we assume in the latent space . It is a standard assumption in subspace sensing , and the standard deviation hyperparameter controls how accurately the low-rank subspace assumption can fit the data . It does not solely determine the distribution of y , and other noise models can also be assumed here . We apologize for the confusion and have revised the paper to make it clearer . Q2 : The paper does not show evidence about improved predictive performance and generalization when accounting for the target boundedness A2 : We extended experiments to compare results between considering target boundedness ( Censored ) and not ( Uncensored ) for both single-task and multi-task models . In either scenario , we reported the best performance ( LS+L1 for single task and Multi Trace for multi-task in our case ) in Table 2 . In the revised version , we further compared SN with several DNN baselines , where the benefit of setting censored regression goals is also found to be evident in DNN settings . Please see next response for details . Q3 : The authors should provide a more rigorous benchmark including non-linear prediction approaches A3 : As suggested , we compared with three DNN baselines ( naive , with censoring , and with censoring + low-rank ) for both synthetic and real data in the paragraph \u201c Benefits of Going deep \u201d in Section 4.1 and \u201c Performance \u201d in Section 4.2 of the revised paper , in addition to the existing nonlinear Tobit censored regression model . The comparisons of three baselines indicate that both censored regression and low-rank assumption improve DNN \u2019 s performance on the given MTL task . Meanwhile , SN clearly outperforms all three , even DNN equipped with censoring + low-rank , suggesting the advantage of our proposed online one-pass sensing and feed-forward training strategy . The performance advantage of SN over DNNs is also confirmed across different rank assumptions in Table 8 in Appendix . Q4 : What is the interest of predicting baseline ( or 6 months at best ) cognitive scores from brain imaging data ? A4 : Thanks for pointing out . We have revised the paper to refer readers interested in this setting to relevant clinical references . The predictive modeling paradigm that we used in the paper is a rather common setting in clinical studies of neurodegenerative diseases such as Alzheimer \u2019 s disease ( AD ) , e.g. , [ 1 ] Stonnington , C. M. , Chu , C. , Kl\u00f6ppel , S. , Jack , C. R. , Ashburner , J. , Frackowiak , R. S. , & Alzheimer Disease Neuroimaging Initiative . ( 2010 ) .Predicting clinical scores from magnetic resonance scans in Alzheimer 's disease . Neuroimage , 51 ( 4 ) , 1405-1413 . [ 2 ] Orr\u00f9 , G. , Pettersson-Yeo , W. , Marquand , A. F. , Sartori , G. , & Mechelli , A . ( 2012 ) .Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease : a critical review . Neuroscience & Biobehavioral Reviews , 36 ( 4 ) , 1140-1152 . [ 3 ] Zhang , D. , Shen , D. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2012 ) .Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer 's disease . NeuroImage , 59 ( 2 ) , 895-907 . [ 4 ] Zhou , J. , Liu , J. , Narayan , V. A. , Ye , J. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2013 ) .Modeling disease progression via multi-task learning . NeuroImage , 78 , 233-248 . The rationale behind this setting is as follows . For example , the diagnosis of AD requires autopsy confirmation , which is not applicable on live patients . Hence many cognitive measures have been designed to evaluate the cognitive status of a patient . These measures are important criteria for clinical diagnosis of probable AD . These cognitive status/scores can be considered as phenotypes that are tangled with complicated neurological pathologies in the brain . Currently there are many hypotheses the pathological pathways of AD progression over time , but we are far from understanding the ultimate cause and thus the studies of associations between cognitive scores and neuroimages are critical in understanding the progression and predictability of the disease . The models can reveal important insights and may lead to novel target for therapeutic intervention and drug developments ."}, "1": {"review_id": "HytSvlWRZ-1", "review_text": "The authors propose a DNN, called subspace network, for nonlinear multi-task censored regression problem. The topic is important. Experiments on real data show improvements compared to several traditional approaches. My major concerns are as follows. 1. The paper is not self-contained. The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1. However, for some key steps in the proof, they refer to other references. If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix. 2. The experiments are unconvincing. They compare the proposed SN with other traditional approaches on a very small data set with 670 samples and 138 features. A major merit of DNN is that it can automatically extract useful features. However, in this experiment, the features are handcrafted before they are fed into the models. Thus, I would like to see a comparison between SN with vanilla DNN. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks very much for your suggestions . We have addressed all your concerns below . Q1.The paper is not self-contained . The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1 . However , for some key steps in the proof , they refer to other references . If this is due to space limitation in the main text , they may want to provide a complete proof in the appendix . A1 : Thanks very much for your comment . In Appendix of the revised paper , please find the more detailed long version of the proof outlines of both asymptotic and non-asymptotic convergence properties in Appendix . We expect that the new proof has better self-containedness . At some steps of the proof , we pointed to the important key results to refer to ( in precise forms , e.g. , Lemma 2 of Mardani et al . ( 2013 ) ) .In order to focus on the key contribution of this paper , we did not include the detailed assumptions and proofs of all those intermediate theorems/lemma that we used . The reasons are : ( 1 ) they can be very lengthy ; ( 2 ) they were well-established results in other relevant literature and were not our innovations ; ( 3 ) those intermediate results were not tightly related the main contributions of this paper ( SN model ) . We believe that the current proof outline has already captured all main proof ideas and should be easy to follow for readers of interests . Q2.The experiments are unconvincing . They compare the proposed SN with other traditional approaches on a very small data set with 670 samples and 138 features . A major merit of DNN is that it can automatically extract useful features . However , in this experiment , the features are handcrafted before they are fed into the models . Thus , I would like to see a comparison between SN with vanilla DNN . A2 : Thanks for your comments . We agree that one major merit of DNN is to automatically extract features from images , that demonstrated huge success in many domains . Such capability is based on the availability of large labeled training data . In the medical research domain , however , such labeled data is rarely available , especially in the challenging disease of neurodegenerative diseases such as Alzheimer \u2019 s disease ( AD ) and Parkinson . The ADNI data used in our paper is so far the largest cohort collected for Alzheimer \u2019 s disease study , and however has less than 1000 patients available for building predictive models due to the expensive data collection process . Due to extreme high dimension of an MRI image ( voxel size : 512x512x16 = 4,194,304 ) , most studies use region-of-interests features extracted by existing neuroimaging tools , instead of raw imaging data for studying progression of a disease . As such , a majority amount of AD study performs predictive modeling using extracted features : [ 1 ] Duchesne , S. , Caroli , A. , Geroldi , C. , Collins , D. L. , & Frisoni , G. B . ( 2009 ) .Relating one-year cognitive change in mild cognitive impairment to baseline MRI features . Neuroimage , 47 ( 4 ) , 1363-1370 . [ 2 ] Stonnington , C. M. , Chu , C. , Kl\u00f6ppel , S. , Jack , C. R. , Ashburner , J. , Frackowiak , R. S. , & Alzheimer Disease Neuroimaging Initiative . ( 2010 ) .Predicting clinical scores from magnetic resonance scans in Alzheimer 's disease . Neuroimage , 51 ( 4 ) , 1405-1413 . [ 3 ] Orr\u00f9 , G. , Pettersson-Yeo , W. , Marquand , A. F. , Sartori , G. , & Mechelli , A . ( 2012 ) .Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease : a critical review . Neuroscience & Biobehavioral Reviews , 36 ( 4 ) , 1140-1152 . [ 4 ] Zhang , D. , Shen , D. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2012 ) .Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer 's disease . NeuroImage , 59 ( 2 ) , 895-907 . [ 5 ] Zhou , J. , Liu , J. , Narayan , V. A. , Ye , J. , & Alzheimer 's Disease Neuroimaging Initiative . ( 2013 ) .Modeling disease progression via multi-task learning . NeuroImage , 78 , 233-248 . We also improve our experiments by comparing with three DNN baselines ( naive , with censoring , and with censoring + low-rank ) in both synthetic and real data , please refer to the new paragraph \u201c Benefits of Going deep \u201d in Section 4.1 and \u201c Performance \u201d in Section 4.2 in the revised paper . The comparisons of three baselines indicate that both censored regression and low-rank assumption improve DNN \u2019 s performance on the given MTL task . Meanwhile , Subspace Network clearly outperforms all three , even DNN equipped with censoring + low-rank , suggesting the advantage of our proposed online one-pass sensing and feed-forward training strategy . The performance advantage of Subspace Network is confirmed across different rank assumptions , and across both synthetic and real data ."}, "2": {"review_id": "HytSvlWRZ-2", "review_text": "This paper presents a new multi-task network architecture within which low-rank parameter spaces were found using matrix factorization. As carefully proved and tested, only one pass of the training data would help recover the parametric subspace, thus network could be easily trained layer-wise and expanded. Some novel contributions: 1. Layer by layer feedforward training process, no back-prop. 2. On-line settings to train parameters ( guaranteed convergence in a single pass of the data) Weakness : 1. The assumption that a low-rank parameter space exists among tasks rather than original feature spaces is not new and widely used in literature. 2. The proof part(Section 2.2) can be extended with more details in Appendix. 3. In synthetic data experiments (Table1), only small margins could be observed between SN, f-MLP and rf-MLP, and only Layer 1 of SN performs better above all others. 4. Typo: In Table2,3,5, Multi-l_{2,1} (denotes the L2,1 norm) were written wrong. 5. In the synthetic data experiments on comparison with single-task and multi-task models, counter-intuitive results (with larger training data split, ANMSE raises instead of decreases) of multi-task models may need further explanation. 6. Extra models like Deep Networks with/without matrix factorization could be added. ( As proposed model is a deep model, the lack of comparison with deep methods is dubious) 7. In Section 4.2, the real dataset is rather small thus the results on this small dataset were not convincing enough. SN model outperforms the state-of-the-art with only small margin. Extensive experiments could be added. 8. The performance on One-Layer Subspace Network (with only the input features) could be added. Conclusion: Though with a quite novel idea on solving multi-task censored regression problem, the experiments conducted on synthetic data and real data are not convincing enough to ensure the contribution of the Subspace Network. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks very much for appreciating the novelty of our work , and for your very insightful and constructive comments . We have addressed all your questions below . In particular , we have significantly enriched our experiments as suggested . All results consistently suggest the performance advantage and robustness of Subspace Network over state-of-art linear /nonlinear methods , as well as DNNs . We have also revised the paper and corrected typos . Q1 : The assumption that a low-rank parameter space exists among tasks rather than original feature spaces is not new . A1 : SN was mainly built on the work series of online subspace sensing , where low-rank assumption was enforced on the input space , e.g. , Mardani et al . ( 2015 ) , Shen et al . ( 2016 ) .Motivated by the popularity of low-rank parameter space in MTL , we introduced the first-of-its-kind combination of online subspace sensing ( mostly focusing on input space ) , and low-rank parameter assumption for MTL : we believe their marriage to be new . Q2 : The proof part ( Section 2.2 ) can be extended with more details in Appendix . A2 : We \u2019 ve extended more detailed proof outlines in Appendix . At some steps of the proofs , we point to the important key result to refer to . Proofs are provided for self-containedness only . Q3 : In synthetic data experiments ( Table1 ) , only small margins could be observed between SN , f-MLP and rf-MLP , and only Layer 1 of SN performs better above all others . A3 : We have provided additional experimental results after further tuning all three networks . In addition to subspace difference , we added two new metrics : ( 1 ) the maximum mutual coherence of all column pairs from two matrices , as a classical measurement on how correlated the two matrices ' column subspaces are ; ( 2 ) the mean mutual coherence of all column pairs from two matrices . Note that the two mutual coherence-based metrics are more robust since they are immune to linear transformations of subspace coordinates , to which the L2-based subspace difference is not immune to . Results can be found in Table 1 , showing the clear advantage of SN over f-MLP and rf-MLP under all three metrics . The performance margins of SN in terms of maximum/mean mutual coherences are remarkably more visible than under L2-based difference . Q4 : In the synthetic data experiments on comparison with single-task and multi-task models , counter-intuitive results ( with larger training data split , ANMSE raises instead of decreases ) of multi-task models may need further explanation . A4 : Thanks so much for pointing out . We found there were numerical convergence issues with the optimization algorithms for MTL models . We have fixed the problem and updated the results in Table 3 , where the performance turns now intuitive . We also extended our experiments to compare results between considering target boundedness ( Censored ) and not ( Uncensored ) for both single-task and multi-task models . In either scenario , we reported the best performance ( LS+L1 for single task linear , and Multi Trace for multi-task in our case ) in Table 2 . Q5 : Extra models like Deep Networks with/without matrix factorization could be added . A5 : Thanks very much for your suggestion . We have added them as suggested . Please refer to the new paragraph \u201c Benefits of Going deep \u201d in Section 4.1 and \u201c Performance \u201d in Section 4.2 in the revised paper . In sum , we compared with three DNN baselines ( naive , with censoring , and with censoring + low-rank ) for both synthetic and real data . The comparisons of three baselines indicated that both censored regression and low-rank assumption improved DNN \u2019 s performance on the given MTL task . Meanwhile , SN clearly outperformed all three , even DNN equipped with censoring + low-rank , suggesting the advantage of our proposed online one-pass sensing and feed-forward training strategy . The performance advantage of SN over DNNs was confirmed across different rank assumptions , and across both synthetic and real data ."}}