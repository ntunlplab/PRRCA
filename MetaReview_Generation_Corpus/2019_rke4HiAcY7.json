{"year": "2019", "forum": "rke4HiAcY7", "title": "Caveats for information bottleneck in deterministic scenarios", "decision": "Accept (Poster)", "meta_review": "This paper considers the information bottleneck Lagrangian as a tool for studying deep networks in the common case of supervised learning (predicting label Y from features X) with a deterministic model, and identifies a number of troublesome issues. (1) The information bottleneck curve cannot be recovered by optimizing the Lagrangian for different values of \u03b2 because in the deterministic case, the IB curve is piecewise linear, not strictly concave. (2) Uninteresting representations can lie on the IB curve, so information bottleneck optimality does not imply that a representation is useful. (3) In a multilayer model with a low probability of error, the only tradeoff that successive layers can make between compression and prediction is that deeper layers may compress more. Experiments on MNIST illustrate these issues, and supplementary material shows that these issues also apply to the deterministic information bottleneck and to stochastic models that are nearly deterministic. There was a substantial degree of disagreement between the reviewers of this paper. One reviewer (R3) suggested that all the conclusions of the paper are the consequence of P(X,Y) being degenerate. The authors responded to this criticism in their response and revision quite effectively, in the opinion of the AC. Because R3 failed to participate in the discussion, this review has been discounted in the final decision. The other two reviewers were considerably more positive about the paper, with one (R1) having basically no criticisms and the other (R2) expression some doubts about the novelty of the observations being made in the paper and their importance for practical machine learning scenarios.  Following the revision and discussion, R2 expressed general satisfaction with the paper, so the AC is recommending acceptance. The AC thinks that the final paper would be clearer if the authors were to carefully distinguish between ground-truth labels used in training and the labels estimated by the model for a given input.  At the moment, the symbol Y appears to be overloaded, standing for both.  Perhaps the authors should place a hat over Y when it is standing for estimated labels?", "reviews": [{"review_id": "rke4HiAcY7-0", "review_text": "SUMMARY: This paper is about potential problems of the information bottleneck principle in cases where the output variable Y is a deterministic function of the inputs X. Such a deterministic relationship between outputs and inputs induces the problem that the the IB \"information curve\" (i.e. I(T;Y) as a function of I(X;T)) is piece-wise linear and, thus, no longer strictly concave, which is crucial for non-degenerate (\"interesting\") solutions. The authors argue that most real classification problems indeed show such a deterministic relation between the class labels and the inputs X, and they explore several issues that result from such pathologies. EVALUATION: In my opinion, the whole story could be summarized as follows: if Y is a deterministic function of p-dimensional inputs X, then the joint distribution P(X,Y) is degenerate in that its support lies in a space of dimension p (an not p+1 as it would be in the non-degenerate situation), and this is the source of all pathologies observed. As a consequence, only the cumulative distribution is defined, but there is no density with respect to the Lebesgue measure of R^{p+1}. Thus, one has to be careful when defining the mutual information I(X,Y), which explains the problems with the IB information curve (which should asymptotically converge to I(X;Y) as I(X;T) gets large. Another consequence of this degeneracy concerns the latent variable interpretation of the IB: if T is treated as a latent variable (as, for instance, in the \"deep\" IB models) then we have the conditional independence relation \"Y independent of X given T\", which simply makes no sense if Y is deterministic in X (there is, of course, a deeper underlying problem here: the IB problem is difficult in that it is difficult to define a geneative model with a faithful DAG...). Analyzing situations in which Y = f(X) (with f being a deterministic function) is certainly interesting from a theoretic point of view, but I am not convinced that this analysis is truly relevant for practical problems. In particular, I strongly disagree with the statement that \"in most classification problems, the labels Y are a deterministic function of X\". I would rather argue that the opposite is the case, because I don't think that there are too many such problems with zero Bayes error rate. In particular, I would argue that digit recognition problems like MNIST so not have deterministic labels, since there will always be images of handwritten characters that will give room for interpretation...", "rating": "2: Strong rejection", "reply_text": "We thank the reviewer for their comments . However , there appears to be some misunderstanding , which we attempt to address with our revision and comments below ( response broken into 2 comments for space reasons ) . > EVALUATION : In my opinion , the whole story could be summarized as follows : if > Y is a deterministic function of p-dimensional inputs X , then the joint > distribution P ( X , Y ) is degenerate in that its support lies in a space of > dimension p ( an not p+1 as it would be in the non-degenerate situation ) , and > this is the source of all pathologies observed . As a consequence , only the > cumulative distribution is defined , but there is no density with respect to > the Lebesgue measure of R^ { p+1 } . Thus , one has to be careful when defining the > mutual information I ( X , Y ) , which explains the problems with the IB information > curve ( which should asymptotically converge to I ( X ; Y ) as I ( X ; T ) gets large . It is true that there has been some recent work ( Saxe et al.2018 ; Amjad et al. , 2018 ) on the degeneracies that occur when T ( the bottleneck variable , such as the hidden layer ) is a continuous-valued and deterministic function of a continuous-valued input layer . However , the caveats described in our paper are unrelated to this problem , and arise even when all mutual information terms and probability distributions are well-defined and finite . In our case , Y ( the output class ) is a discrete random variable over a finite set ( call this set [ Y ] ) and the joint distribution of X and Y is a mixed continuous-discrete distribution over R^p \\times [ Y ] . Moreover , the conditional distribution p ( y|x ) is a discrete probability distribution for every x . In this case , the mutual information is given by I ( X ; Y ) = H ( Y ) , and is bounded between 0 and log |Y| . Based on the reviewer \u2019 s comments , we have attempted to clarify our work by inserting text into the Introduction , which states that our caveats are not the result of degenerate distributions or poorly defined mutual information . > Another consequence of this degeneracy concerns the latent variable > interpretation of the IB : if T is treated as a latent variable ( as , for > instance , in the `` deep '' IB models ) then we have the conditional independence > relation `` Y independent of X given T '' , which simply makes no sense if Y is > deterministic in X Unfortunately , we are not sure we understand the reviewer \u2019 s comment . For clarity , we emphasize that the usual Markov condition for IB is \u201c Y is independent of T given X \u201d ( Y - X - T ) . This remains true in a neural network with hidden layers , where the hidden layer T separates input layer X from * predicted outputs * , since X still separates T from the true output Y ( we use Y to refer to the true output ) . We do show in our paper that when Y is deterministic in X , the IB curve will be populated by bottleneck variables on it that obey both Y - X - T ( as all bottleneck variables must ) and X - Y - T , such as our family T_alpha [ see discussion around our Eq.5 ] .Finally , it is true that T_alpha for alpha=1 ( in which case T_alpha is simply equal to Y ) does also obey the independence condition \u201c Y independent of X given T \u201d ( X - T - Y ) . This bottleneck variable sits at the \u201c corner point \u201d of the piecewise linear IB curve . However , we disagree with the reviewer that \u201c \u2018 Y independent of X given T \u2019 ... makes no sense if Y is deterministic in X \u201d . If T=Y , as in this one particular case , then Y will in fact be conditionally independent of X given T , under the usual definition of conditional independence . > ( there is , of course , a deeper underlying problem here : the > IB problem is difficult in that it is difficult to define a geneative model > with a faithful DAG ... ) . Unfortunately , we are not sure we understand the reviewer \u2019 s point . We will say , however , that in IB , one begins by assuming that X and Y are provided , then selects among T that obey T - X - Y . This fits naturally into the setting of supervised learning , where X represents the input , Y represents the true outputs , and T can refer to any intermediate representations ( e.g. , hidden layer neurons ) . The form of the mapping from X to the true output Y does not matter , nor does the form of the representation from X to T. Any standard ML discriminative model will obey this Markov condition ."}, {"review_id": "rke4HiAcY7-1", "review_text": "This paper is about issues that arise when applying Information Bottleneck (IB) concepts to machine learning, more precisely in deterministic supervised learning such as classification (deterministic in the sense that the target function to estimate is deterministic: it associates each example to one true label only, and not to a distribution over labels). Namely: (1) the \"Information Bottleneck curve\" cannot be computed with the Information Bottleneck Lagrangian approach (because of optimization landscape issues: optimization of such a piecewise-linear function with a linear penalty will always yield the same optimum whatever the slope of the penalty is [same story as L1 vs. L0]); (2) there are many solutions to the optimization of the IB Lagrangian for any given compression/performance ratio (i.e. for any given beta in the IB Lagrangian method: I(Y,T)/I(X,T)) and some of them are provably trivial; thus optimizing just the IB Lagrangian does not imply that the solution will be interesting, and better (or complementary) criteria are needed. Another point discussed also is about the successive layers of perfect classifiers (neural networks), in which I(Y,T) remains constant while I(X,T) decreases. Pros: - the paper is well written, mostly self-contained, and easy to read (for someone familiar with information theory); - all mathematical points are detailed and well explained, with sufficient introduction; - the writing is compact, the paper is dense, and given the page limit this is a good information/compression compromise;) - information bottleneck is a topic of prime interest in the community these days; - the two first problems described ((1) and (2)) are original, interesting contributions to the field, of particular interest for people interested in applying information bottleneck concepts to supervised learning; - the solution brought to the IB Lagrangian issues is simplistic though efficient (squaring I(X,T) so that it's not linear in I(X,T) anymore). Cons: - not much. Remarks: - there exist recent papers tackling the information bottleneck concept for neural networks from a variational perspective, which enables them to compute exactly the mutual informations (such as \"Compressing Neural Networks using the Variational Information Bottleneck\" by Dai & al., ICML 2018); I have not seen these papers cited in the article, nor discussed (nor used); I feel it would be appropriate, either in the general literature section, either for discussing how to compute in practice the mutual informations (exact values vs. estimates or lower bounds as here). - at first reading, I had found the tone of the beginning of the paper (first section) a bit aggressive, though this feeling disappeared later. Maybe rephrase some expressions that might be wrongly perceived? - About multilabel classification (end of section 2): multilabel classification can still be seen as with deterministic expected outputs, if considered as a task from X to P(Y) (power set of Y, i.e. set of all possible subsets of labels). - As in practice T is constrained to belong to a particular space of functions (neural network layer with predefined architecture): how does this impact the study? For instance the T_alpha in equation (5) are not reachable anymore; the optimization space for the IB Lagrangian is different; etc. Which properties/conclusions can be kept, and which ones cannot? - What about sampling on the other part of the IB curve, the horizontal one (same I(Y,T) for various I(X,T))? Would it bring any insight, and how to do it? - A side remark about applying IB to neural networks: What about neural networks that are not a \"linear\" chain of layers (i.e. most networks now)? i.e. Inception, ResNet, U-nets, etc., where computational flows are parallel, sometimes keeping full information till the end. For instance in a U-net, meant for image processing, features computed at the beginning at a full pixelic resolution are communicated to the last layer. This is not an image classification task though, as predictions are made for each pixel; still, given an input image X, there is only one correct output Y, so, still in the deterministic supervised classification problem. ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank the reviewer for their supportive words and helpful suggestions . We address the reviewer \u2019 s remarks point by point ( split into two responses for space ) . > - there exist recent papers tackling the information bottleneck concept for > neural networks from a variational perspective , which enables them to compute > exactly the mutual informations ( such as `` Compressing Neural Networks using > the Variational Information Bottleneck '' by Dai & al. , ICML 2018 ) ; I have not > seen these papers cited in the article , nor discussed ( nor used ) ; I feel it > would be appropriate , either in the general literature section , either for > discussing how to compute in practice the mutual informations ( exact values > vs. estimates or lower bounds as here ) . We have added some text to section \u201c 2 ) Supervised Classification and IB \u201d , where we highlight that our theoretical results are independent of how mutual information between neural network layers is estimated , but that this is an important and active area of research ( including recent work by Belghazi et al. , 2018 ; Goldfeld et al. , 2018 ; Dai et al. , 2018 ; Gabri\u00e9 et al. , 2018 ) . For our empirical results , we use the estimator proposed in Kolchinsky et al. , ( 2017 ) . > - at first reading , I had found the tone of the beginning of the paper ( first > section ) a bit aggressive , though this feeling disappeared later . Maybe > rephrase some expressions that might be wrongly perceived ? We appreciate this suggestion . We do not intend for our work to be viewed as an attack on IB . To soften the tone , we have rephrased several sentences in the abstract and introduction that may have been perceived as overly aggressive . Moreover , we have ( partly in response to reviewer 2 ) replaced \u2018 pathology \u2019 with \u2018 caveat \u2019 throughout the text . We believe that this wording is more appropriate , particularly for the third issue ( i.e. , the lack of strict prediction/compression trade-off between different layers of a neural net ) , which is more of an \u2018 unexpected behaviour \u2019 than it a \u2018 pathology \u2019 . > - About multilabel classification ( end of section 2 ) : multilabel classification can > still be seen as with deterministic expected outputs , if considered as a task from > X to P ( Y ) ( power set of Y , i.e.set of all possible subsets of labels ) . We fully agree with the reviewer \u2019 s point , and have updated the manuscript accordingly . > - As in practice T is constrained to belong to a particular space of functions > ( neural network layer with predefined architecture ) : how does this impact the > study ? For instance the T_alpha in equation ( 5 ) are not reachable anymore ; the > optimization space for the IB Lagrangian is different ; etc . Which > properties/conclusions can be kept , and which ones can not ? These are great questions . An in-depth analysis of the effects of model constraints on T would be very interesting , especially for the types of constraints that characterize real-world architectures . At the same time , it is hard to say something meaningful for the general case , since different constraints on the set of T can produce arbitrarily different 'constrained IB-curves ' . Due to the page limit , we must leave this topic for future work . We do note that in our experimental results , where we use a very standard MLP network architecture which does not include T_\\alpha itself in the space of model , we witness all three issues discussed in the main text . > - What about sampling on the other part of the IB curve , the horizontal one > ( same I ( Y , T ) for various I ( X , T ) ) ? Would it bring any insight , and how to do > it ? We expect it should be straightforward to design objective functions that encourage exploration of the flat part of the curve . However , points on the flat part of the curve are ( weakly ) Pareto dominated by the \u2018 corner point \u2019 . From the conceptual point of view of IB , in which it is assumed to always be better to have low I ( X ; T ) all else being equal , we can not think of why one might want to do this ."}, {"review_id": "rke4HiAcY7-2", "review_text": "This work analyses the information bottleneck (IB) method applied to the supervised learning of a deterministic rule Y=f(X). The idea as I understood it is as follows: 1) In a first section the authors discuss the relationship between supervised learning through minimization of the empirical cross entropy and the maximization of the empirical mutual information with an intermediate latent variable T. 2) They show that in the case of a deterministic rule, the information bottleneck curve has a simple shape, piecewise linear, and is not strictly concave. 3) They show that the optimization of the IB Lagrangian for different \\beta does not lead to a point by point exploration of the IB curve. 4) They propose a cure to the previous issue by introducing the squared IB Lagrangian. 5) They exhibit uninteresting representations (noisy versions of the output Y) that are on the IB curve. 6) They show that multiple successive representations (like in DNNs), have identical predicting power (mutual information with output Y) when they allow for perfect prediction. 7) They use the IB method to train a neural net on MNIST, using the Kolchinsky estimate of the mutual informations. - they show that the optimization of the squared IB reaches more different points on the IB curve, - but that these representations are possibly uninteresting (hard clustering of uneven numbers of grouped classes) - they show that for large enough value of beta, zero error is reached. The necessity of noise in the IB theory has been already pointed out by (Gilad-Bachrach et al., 2003; Shwartz-Ziv et al. 2017), although the more thorough analysis proposed here is novel. In practice, besides a few recent propositions (Kolchinsky et al., 2017; Alemi et al., 2016; Chalk et al., 2016) the IB Lagrangian is not a usual objective function for supervised learning. The motivation and impact of this work studying deterministic rules is therefore not completely convincing. Further pros and cons: Pros: - The discussion is generally well written. - This work provides in depth clarification of the counter-intuitive behaviors of the IB method in the case to the learning of a deterministic rule. - These are demonstrated with experiments conducted on the MNIST dataset for concreteness. Cons: - The fact that multiple successive representations have identical predicting power when the prediction error is zero, was already observed for example in Shwartz-Ziv et al. 2017. It is not clear why this should be considered as an issue. It also seems to be a straightforward observation when restricting to the empirical measure on the training set. - The fact that the entire IB curve is not explored point by point by the IB Lagrangian is not necessarily an issue for learning. In the experiments of the present paper, the results seem to suggest that the interesting intermediate representations (separation in 10 compact clusters of the MNIST classes) is actually easier to obtain (large range of \\beta) optimizing the IB Lagrangian rather than the proposed squared IB Lagrangian. Questions: - Do the authors know of an application where the full probing of the IB curve would be necessary? - In Section 2, when injecting the decomposition of the prediction density q(y|x) over the intermediate variable t in eq (3) was a Jensen inequality replaced by an equality? ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the thoughtful reading and comments . We address several of the reviewer \u2019 s criticisms point by point ( broken into three comments for length ) : > The necessity of noise in the IB theory has been already pointed > out by ( Gilad-Bachrach et al. , 2003 ; Shwartz-Ziv et al.2017 ) , > although the more thorough analysis proposed here is novel . We agree with the reviewer that Gilad-Bachrach et al. , 2003 and Shwartz-Ziv et al.2017 also discussed the role of noise in the mapping from X to Y in IB . Gilad-Bachrach et al. , 2003 showed that IB curve is not strictly concave without noise . However , we believe that this result may not be widely known , nor -- more importantly -- that it implies that the IB Lagrangian fails in deterministic scenarios was not appreciated . Shwartz-Ziv et al.discussed the fact that when Y=f ( X ) , mutual information between input and output doesn \u2019 t reflect the \u201c the complexity of the function f ( x ) or the class of functions it comes from \u201d ( where complexity could be understood in terms of , e.g. , VC dimension ) [ section 2.4 , \u201c The crucial role of noise \u201d ] . This is an interesting issue , but is orthogonal to the issues discussed in our paper . However , we have added a sentence in the Introduction to draw attention Shwartz-Ziv et al. \u2019 s discussion of this other , interesting caveat . We note that even without noise , the IB curve still exists and is well-defined via the constrained optimization problem ( Eq.1 in our paper , Eq.2 in Gilad-Bachrach et al . ) , or via the alternative objective function ( squared-IB Lagrangian that we propose ) . However , it has not been previously recognized that in deterministic settings , this IB curve will be full of trivial solutions . Finally , we have seen various recent articles that apply IB concepts to supervised learning in which class labels are completely deterministic and which do not seem to be aware of any of the possible caveats mentioned in our article ( or that of Gilad-Bachrach et al.or Shwartz-Ziv et al . ) . > In practice , besides a few recent propositions ( Kolchinsky et al. , 2017 ; > Alemi et al. , 2016 ; Chalk et al. , 2016 ) the IB Lagrangian is not a > usual objective function for supervised learning . The motivation > and impact of this work studying deterministic rules is therefore > not completely convincing . We see our paper as being about the fundamental properties of IB , in particular when applied to deterministic settings . Neural networks is one area where IB has recently been receiving a lot of attention , and where deterministic mappings are very common , and seems like a natural area of application . However , we believe the work can be of interest to a diverse community of researchers , including : ( 1 ) Those using IB in various applied settings . This includes not just recent work deep learning ( where the IB Lagrangian has been suggested as an objective function ) , but numerous applications of IB in speech recognition ( Yaman et al , 2012 ; Hecht et al , 2005 ) , image recognition ( Winn et al. , 2005 ) , video ( Hsu et al. , 2006 ) , distributional clustering ( Slonim et al , 2000 ) , network coding ( Zeitler et al. , 2008 ) , etc . ( 2 ) Those working in theoretical machine learning , for example by investigating the idea that stochastic gradient descent may \u201c implicitly \u201d optimize the IB Lagrangian ( Shwartz-Ziv et al. , Zhao 2018 [ arXiv:1803.07980 ] ) , or analyzing properties of IB-optimal representations ( Amjad et al.2018 , arXiv:1802.09766 ) ( 3 ) Those analyzing theoretical properties of IB in other fields , e.g. , from the point of view of rate distortion ( Harremoes et al. , 2007 ) , data compression ( Cardinal , 2003 ) , source doing ( Courtade et al.2011 , arXiv:1106.0032 ) , adaptive quantization ( Lazebnik , 2009 ) , etc . We recognize , however , that the title and tone of our article suggests that its its primary domain of application is supervised learning . We have tweaked the title and some of the article text to emphasize that we see supervised learning as one important application area of our results , among others ."}], "0": {"review_id": "rke4HiAcY7-0", "review_text": "SUMMARY: This paper is about potential problems of the information bottleneck principle in cases where the output variable Y is a deterministic function of the inputs X. Such a deterministic relationship between outputs and inputs induces the problem that the the IB \"information curve\" (i.e. I(T;Y) as a function of I(X;T)) is piece-wise linear and, thus, no longer strictly concave, which is crucial for non-degenerate (\"interesting\") solutions. The authors argue that most real classification problems indeed show such a deterministic relation between the class labels and the inputs X, and they explore several issues that result from such pathologies. EVALUATION: In my opinion, the whole story could be summarized as follows: if Y is a deterministic function of p-dimensional inputs X, then the joint distribution P(X,Y) is degenerate in that its support lies in a space of dimension p (an not p+1 as it would be in the non-degenerate situation), and this is the source of all pathologies observed. As a consequence, only the cumulative distribution is defined, but there is no density with respect to the Lebesgue measure of R^{p+1}. Thus, one has to be careful when defining the mutual information I(X,Y), which explains the problems with the IB information curve (which should asymptotically converge to I(X;Y) as I(X;T) gets large. Another consequence of this degeneracy concerns the latent variable interpretation of the IB: if T is treated as a latent variable (as, for instance, in the \"deep\" IB models) then we have the conditional independence relation \"Y independent of X given T\", which simply makes no sense if Y is deterministic in X (there is, of course, a deeper underlying problem here: the IB problem is difficult in that it is difficult to define a geneative model with a faithful DAG...). Analyzing situations in which Y = f(X) (with f being a deterministic function) is certainly interesting from a theoretic point of view, but I am not convinced that this analysis is truly relevant for practical problems. In particular, I strongly disagree with the statement that \"in most classification problems, the labels Y are a deterministic function of X\". I would rather argue that the opposite is the case, because I don't think that there are too many such problems with zero Bayes error rate. In particular, I would argue that digit recognition problems like MNIST so not have deterministic labels, since there will always be images of handwritten characters that will give room for interpretation...", "rating": "2: Strong rejection", "reply_text": "We thank the reviewer for their comments . However , there appears to be some misunderstanding , which we attempt to address with our revision and comments below ( response broken into 2 comments for space reasons ) . > EVALUATION : In my opinion , the whole story could be summarized as follows : if > Y is a deterministic function of p-dimensional inputs X , then the joint > distribution P ( X , Y ) is degenerate in that its support lies in a space of > dimension p ( an not p+1 as it would be in the non-degenerate situation ) , and > this is the source of all pathologies observed . As a consequence , only the > cumulative distribution is defined , but there is no density with respect to > the Lebesgue measure of R^ { p+1 } . Thus , one has to be careful when defining the > mutual information I ( X , Y ) , which explains the problems with the IB information > curve ( which should asymptotically converge to I ( X ; Y ) as I ( X ; T ) gets large . It is true that there has been some recent work ( Saxe et al.2018 ; Amjad et al. , 2018 ) on the degeneracies that occur when T ( the bottleneck variable , such as the hidden layer ) is a continuous-valued and deterministic function of a continuous-valued input layer . However , the caveats described in our paper are unrelated to this problem , and arise even when all mutual information terms and probability distributions are well-defined and finite . In our case , Y ( the output class ) is a discrete random variable over a finite set ( call this set [ Y ] ) and the joint distribution of X and Y is a mixed continuous-discrete distribution over R^p \\times [ Y ] . Moreover , the conditional distribution p ( y|x ) is a discrete probability distribution for every x . In this case , the mutual information is given by I ( X ; Y ) = H ( Y ) , and is bounded between 0 and log |Y| . Based on the reviewer \u2019 s comments , we have attempted to clarify our work by inserting text into the Introduction , which states that our caveats are not the result of degenerate distributions or poorly defined mutual information . > Another consequence of this degeneracy concerns the latent variable > interpretation of the IB : if T is treated as a latent variable ( as , for > instance , in the `` deep '' IB models ) then we have the conditional independence > relation `` Y independent of X given T '' , which simply makes no sense if Y is > deterministic in X Unfortunately , we are not sure we understand the reviewer \u2019 s comment . For clarity , we emphasize that the usual Markov condition for IB is \u201c Y is independent of T given X \u201d ( Y - X - T ) . This remains true in a neural network with hidden layers , where the hidden layer T separates input layer X from * predicted outputs * , since X still separates T from the true output Y ( we use Y to refer to the true output ) . We do show in our paper that when Y is deterministic in X , the IB curve will be populated by bottleneck variables on it that obey both Y - X - T ( as all bottleneck variables must ) and X - Y - T , such as our family T_alpha [ see discussion around our Eq.5 ] .Finally , it is true that T_alpha for alpha=1 ( in which case T_alpha is simply equal to Y ) does also obey the independence condition \u201c Y independent of X given T \u201d ( X - T - Y ) . This bottleneck variable sits at the \u201c corner point \u201d of the piecewise linear IB curve . However , we disagree with the reviewer that \u201c \u2018 Y independent of X given T \u2019 ... makes no sense if Y is deterministic in X \u201d . If T=Y , as in this one particular case , then Y will in fact be conditionally independent of X given T , under the usual definition of conditional independence . > ( there is , of course , a deeper underlying problem here : the > IB problem is difficult in that it is difficult to define a geneative model > with a faithful DAG ... ) . Unfortunately , we are not sure we understand the reviewer \u2019 s point . We will say , however , that in IB , one begins by assuming that X and Y are provided , then selects among T that obey T - X - Y . This fits naturally into the setting of supervised learning , where X represents the input , Y represents the true outputs , and T can refer to any intermediate representations ( e.g. , hidden layer neurons ) . The form of the mapping from X to the true output Y does not matter , nor does the form of the representation from X to T. Any standard ML discriminative model will obey this Markov condition ."}, "1": {"review_id": "rke4HiAcY7-1", "review_text": "This paper is about issues that arise when applying Information Bottleneck (IB) concepts to machine learning, more precisely in deterministic supervised learning such as classification (deterministic in the sense that the target function to estimate is deterministic: it associates each example to one true label only, and not to a distribution over labels). Namely: (1) the \"Information Bottleneck curve\" cannot be computed with the Information Bottleneck Lagrangian approach (because of optimization landscape issues: optimization of such a piecewise-linear function with a linear penalty will always yield the same optimum whatever the slope of the penalty is [same story as L1 vs. L0]); (2) there are many solutions to the optimization of the IB Lagrangian for any given compression/performance ratio (i.e. for any given beta in the IB Lagrangian method: I(Y,T)/I(X,T)) and some of them are provably trivial; thus optimizing just the IB Lagrangian does not imply that the solution will be interesting, and better (or complementary) criteria are needed. Another point discussed also is about the successive layers of perfect classifiers (neural networks), in which I(Y,T) remains constant while I(X,T) decreases. Pros: - the paper is well written, mostly self-contained, and easy to read (for someone familiar with information theory); - all mathematical points are detailed and well explained, with sufficient introduction; - the writing is compact, the paper is dense, and given the page limit this is a good information/compression compromise;) - information bottleneck is a topic of prime interest in the community these days; - the two first problems described ((1) and (2)) are original, interesting contributions to the field, of particular interest for people interested in applying information bottleneck concepts to supervised learning; - the solution brought to the IB Lagrangian issues is simplistic though efficient (squaring I(X,T) so that it's not linear in I(X,T) anymore). Cons: - not much. Remarks: - there exist recent papers tackling the information bottleneck concept for neural networks from a variational perspective, which enables them to compute exactly the mutual informations (such as \"Compressing Neural Networks using the Variational Information Bottleneck\" by Dai & al., ICML 2018); I have not seen these papers cited in the article, nor discussed (nor used); I feel it would be appropriate, either in the general literature section, either for discussing how to compute in practice the mutual informations (exact values vs. estimates or lower bounds as here). - at first reading, I had found the tone of the beginning of the paper (first section) a bit aggressive, though this feeling disappeared later. Maybe rephrase some expressions that might be wrongly perceived? - About multilabel classification (end of section 2): multilabel classification can still be seen as with deterministic expected outputs, if considered as a task from X to P(Y) (power set of Y, i.e. set of all possible subsets of labels). - As in practice T is constrained to belong to a particular space of functions (neural network layer with predefined architecture): how does this impact the study? For instance the T_alpha in equation (5) are not reachable anymore; the optimization space for the IB Lagrangian is different; etc. Which properties/conclusions can be kept, and which ones cannot? - What about sampling on the other part of the IB curve, the horizontal one (same I(Y,T) for various I(X,T))? Would it bring any insight, and how to do it? - A side remark about applying IB to neural networks: What about neural networks that are not a \"linear\" chain of layers (i.e. most networks now)? i.e. Inception, ResNet, U-nets, etc., where computational flows are parallel, sometimes keeping full information till the end. For instance in a U-net, meant for image processing, features computed at the beginning at a full pixelic resolution are communicated to the last layer. This is not an image classification task though, as predictions are made for each pixel; still, given an input image X, there is only one correct output Y, so, still in the deterministic supervised classification problem. ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank the reviewer for their supportive words and helpful suggestions . We address the reviewer \u2019 s remarks point by point ( split into two responses for space ) . > - there exist recent papers tackling the information bottleneck concept for > neural networks from a variational perspective , which enables them to compute > exactly the mutual informations ( such as `` Compressing Neural Networks using > the Variational Information Bottleneck '' by Dai & al. , ICML 2018 ) ; I have not > seen these papers cited in the article , nor discussed ( nor used ) ; I feel it > would be appropriate , either in the general literature section , either for > discussing how to compute in practice the mutual informations ( exact values > vs. estimates or lower bounds as here ) . We have added some text to section \u201c 2 ) Supervised Classification and IB \u201d , where we highlight that our theoretical results are independent of how mutual information between neural network layers is estimated , but that this is an important and active area of research ( including recent work by Belghazi et al. , 2018 ; Goldfeld et al. , 2018 ; Dai et al. , 2018 ; Gabri\u00e9 et al. , 2018 ) . For our empirical results , we use the estimator proposed in Kolchinsky et al. , ( 2017 ) . > - at first reading , I had found the tone of the beginning of the paper ( first > section ) a bit aggressive , though this feeling disappeared later . Maybe > rephrase some expressions that might be wrongly perceived ? We appreciate this suggestion . We do not intend for our work to be viewed as an attack on IB . To soften the tone , we have rephrased several sentences in the abstract and introduction that may have been perceived as overly aggressive . Moreover , we have ( partly in response to reviewer 2 ) replaced \u2018 pathology \u2019 with \u2018 caveat \u2019 throughout the text . We believe that this wording is more appropriate , particularly for the third issue ( i.e. , the lack of strict prediction/compression trade-off between different layers of a neural net ) , which is more of an \u2018 unexpected behaviour \u2019 than it a \u2018 pathology \u2019 . > - About multilabel classification ( end of section 2 ) : multilabel classification can > still be seen as with deterministic expected outputs , if considered as a task from > X to P ( Y ) ( power set of Y , i.e.set of all possible subsets of labels ) . We fully agree with the reviewer \u2019 s point , and have updated the manuscript accordingly . > - As in practice T is constrained to belong to a particular space of functions > ( neural network layer with predefined architecture ) : how does this impact the > study ? For instance the T_alpha in equation ( 5 ) are not reachable anymore ; the > optimization space for the IB Lagrangian is different ; etc . Which > properties/conclusions can be kept , and which ones can not ? These are great questions . An in-depth analysis of the effects of model constraints on T would be very interesting , especially for the types of constraints that characterize real-world architectures . At the same time , it is hard to say something meaningful for the general case , since different constraints on the set of T can produce arbitrarily different 'constrained IB-curves ' . Due to the page limit , we must leave this topic for future work . We do note that in our experimental results , where we use a very standard MLP network architecture which does not include T_\\alpha itself in the space of model , we witness all three issues discussed in the main text . > - What about sampling on the other part of the IB curve , the horizontal one > ( same I ( Y , T ) for various I ( X , T ) ) ? Would it bring any insight , and how to do > it ? We expect it should be straightforward to design objective functions that encourage exploration of the flat part of the curve . However , points on the flat part of the curve are ( weakly ) Pareto dominated by the \u2018 corner point \u2019 . From the conceptual point of view of IB , in which it is assumed to always be better to have low I ( X ; T ) all else being equal , we can not think of why one might want to do this ."}, "2": {"review_id": "rke4HiAcY7-2", "review_text": "This work analyses the information bottleneck (IB) method applied to the supervised learning of a deterministic rule Y=f(X). The idea as I understood it is as follows: 1) In a first section the authors discuss the relationship between supervised learning through minimization of the empirical cross entropy and the maximization of the empirical mutual information with an intermediate latent variable T. 2) They show that in the case of a deterministic rule, the information bottleneck curve has a simple shape, piecewise linear, and is not strictly concave. 3) They show that the optimization of the IB Lagrangian for different \\beta does not lead to a point by point exploration of the IB curve. 4) They propose a cure to the previous issue by introducing the squared IB Lagrangian. 5) They exhibit uninteresting representations (noisy versions of the output Y) that are on the IB curve. 6) They show that multiple successive representations (like in DNNs), have identical predicting power (mutual information with output Y) when they allow for perfect prediction. 7) They use the IB method to train a neural net on MNIST, using the Kolchinsky estimate of the mutual informations. - they show that the optimization of the squared IB reaches more different points on the IB curve, - but that these representations are possibly uninteresting (hard clustering of uneven numbers of grouped classes) - they show that for large enough value of beta, zero error is reached. The necessity of noise in the IB theory has been already pointed out by (Gilad-Bachrach et al., 2003; Shwartz-Ziv et al. 2017), although the more thorough analysis proposed here is novel. In practice, besides a few recent propositions (Kolchinsky et al., 2017; Alemi et al., 2016; Chalk et al., 2016) the IB Lagrangian is not a usual objective function for supervised learning. The motivation and impact of this work studying deterministic rules is therefore not completely convincing. Further pros and cons: Pros: - The discussion is generally well written. - This work provides in depth clarification of the counter-intuitive behaviors of the IB method in the case to the learning of a deterministic rule. - These are demonstrated with experiments conducted on the MNIST dataset for concreteness. Cons: - The fact that multiple successive representations have identical predicting power when the prediction error is zero, was already observed for example in Shwartz-Ziv et al. 2017. It is not clear why this should be considered as an issue. It also seems to be a straightforward observation when restricting to the empirical measure on the training set. - The fact that the entire IB curve is not explored point by point by the IB Lagrangian is not necessarily an issue for learning. In the experiments of the present paper, the results seem to suggest that the interesting intermediate representations (separation in 10 compact clusters of the MNIST classes) is actually easier to obtain (large range of \\beta) optimizing the IB Lagrangian rather than the proposed squared IB Lagrangian. Questions: - Do the authors know of an application where the full probing of the IB curve would be necessary? - In Section 2, when injecting the decomposition of the prediction density q(y|x) over the intermediate variable t in eq (3) was a Jensen inequality replaced by an equality? ", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank the reviewer for the thoughtful reading and comments . We address several of the reviewer \u2019 s criticisms point by point ( broken into three comments for length ) : > The necessity of noise in the IB theory has been already pointed > out by ( Gilad-Bachrach et al. , 2003 ; Shwartz-Ziv et al.2017 ) , > although the more thorough analysis proposed here is novel . We agree with the reviewer that Gilad-Bachrach et al. , 2003 and Shwartz-Ziv et al.2017 also discussed the role of noise in the mapping from X to Y in IB . Gilad-Bachrach et al. , 2003 showed that IB curve is not strictly concave without noise . However , we believe that this result may not be widely known , nor -- more importantly -- that it implies that the IB Lagrangian fails in deterministic scenarios was not appreciated . Shwartz-Ziv et al.discussed the fact that when Y=f ( X ) , mutual information between input and output doesn \u2019 t reflect the \u201c the complexity of the function f ( x ) or the class of functions it comes from \u201d ( where complexity could be understood in terms of , e.g. , VC dimension ) [ section 2.4 , \u201c The crucial role of noise \u201d ] . This is an interesting issue , but is orthogonal to the issues discussed in our paper . However , we have added a sentence in the Introduction to draw attention Shwartz-Ziv et al. \u2019 s discussion of this other , interesting caveat . We note that even without noise , the IB curve still exists and is well-defined via the constrained optimization problem ( Eq.1 in our paper , Eq.2 in Gilad-Bachrach et al . ) , or via the alternative objective function ( squared-IB Lagrangian that we propose ) . However , it has not been previously recognized that in deterministic settings , this IB curve will be full of trivial solutions . Finally , we have seen various recent articles that apply IB concepts to supervised learning in which class labels are completely deterministic and which do not seem to be aware of any of the possible caveats mentioned in our article ( or that of Gilad-Bachrach et al.or Shwartz-Ziv et al . ) . > In practice , besides a few recent propositions ( Kolchinsky et al. , 2017 ; > Alemi et al. , 2016 ; Chalk et al. , 2016 ) the IB Lagrangian is not a > usual objective function for supervised learning . The motivation > and impact of this work studying deterministic rules is therefore > not completely convincing . We see our paper as being about the fundamental properties of IB , in particular when applied to deterministic settings . Neural networks is one area where IB has recently been receiving a lot of attention , and where deterministic mappings are very common , and seems like a natural area of application . However , we believe the work can be of interest to a diverse community of researchers , including : ( 1 ) Those using IB in various applied settings . This includes not just recent work deep learning ( where the IB Lagrangian has been suggested as an objective function ) , but numerous applications of IB in speech recognition ( Yaman et al , 2012 ; Hecht et al , 2005 ) , image recognition ( Winn et al. , 2005 ) , video ( Hsu et al. , 2006 ) , distributional clustering ( Slonim et al , 2000 ) , network coding ( Zeitler et al. , 2008 ) , etc . ( 2 ) Those working in theoretical machine learning , for example by investigating the idea that stochastic gradient descent may \u201c implicitly \u201d optimize the IB Lagrangian ( Shwartz-Ziv et al. , Zhao 2018 [ arXiv:1803.07980 ] ) , or analyzing properties of IB-optimal representations ( Amjad et al.2018 , arXiv:1802.09766 ) ( 3 ) Those analyzing theoretical properties of IB in other fields , e.g. , from the point of view of rate distortion ( Harremoes et al. , 2007 ) , data compression ( Cardinal , 2003 ) , source doing ( Courtade et al.2011 , arXiv:1106.0032 ) , adaptive quantization ( Lazebnik , 2009 ) , etc . We recognize , however , that the title and tone of our article suggests that its its primary domain of application is supervised learning . We have tweaked the title and some of the article text to emphasize that we see supervised learning as one important application area of our results , among others ."}}