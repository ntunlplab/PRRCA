{"year": "2021", "forum": "UwOMufsTqCy", "title": "RRL: A Scalable Classifier for Interpretable Rule-Based Representation Learning", "decision": "Reject", "meta_review": "This paper falls in the borderline area and there are still some concerns (for instance by AnonReviewer5 and AnonReviewer2) that deserve further treatment. Given that most ideas can only be validated in experiments (as the results are not theoretical), some points that remain are the comparison with other approaches (there are reasonable comparisons, but there are very famous contenders missing such as xgboost, ok that LightGBM is, but why not the other?), details about the tuning, the significance of results (practical and statistical is not complete/detailed enough), and the reasoning about situations with many rules and interpretability seems to be worth exploring/discussing further.", "reviews": [{"review_id": "UwOMufsTqCy-0", "review_text": "# # Summary The authors propose a new approach for training interpretable discrete models via gradient descent . They claim three contributions : 1 ) incorporation of layers implementing logical conjunction and disjunction operations ; 2 ) the gradient grafting technique for performing gradient descent on discrete structures ; and 3 ) a logical activation function that enables models to scale to larger training datasets . Additionally , they also claim competitive performance with comparable learning methods . # # Strengths * The paper is well organised and easy to follow . * The proposed gradient grafting technique , while heuristic in nature , is novel and seems to work quite well in practice . * The proposed method achieves good accuracy compared to the other approaches considered in the experiments . # # Weaknesses * There is limited novelty in the proposed model . The continuous/discrete conjunction and disjunction operations used in the logical layers are the same as those used in Wang et al . ( 2020 ) , however they are arranged differently in this method . * The connection betweent the continuous version of the model and the discrete version is weak . One of the claimed contributions is that the discrete model is optimised directly , but this does not seem to be the case in practicethe continuous version of the model is optimised . It is also unclear how the continuous-valued weights are binarised in order to work with the discrete version of the model . * The results in Figure 2 indicate that typically a large number of rules are learned , yielding models that are unlikely to be interpreted reliably . The log scale on the x axis of the plots is somewhat deceptiveI find it hard to believe that models with between 64 -- 256 terms are interpretable . I think further investigating what tradeoff exists between accuracy and interpretability is necessary before the paper can be accepted . # # Other comments/questions * Comparing average accuracy is generally not a good idea . It is more informative to compare the average rank of each method across datasets [ 1 ] . * Can the authors elaborate on how hyperparameters for each of the competing methods are chosen ? * The computational graph for gradient grafting seems related ( yet distinct ) to the Gumbel softmax estimatorperhaps the authors could discuss this relationship further ? * The authors could do more to discuss related work on training decision trees and rules using gradient-based optimisation . E.g. , XGBoost [ 2 ] , DNDT [ 3 ] , and SGT [ 4 ] . * Given that the model is trained with gradient descent , and arbitrary loss functions , could the model be evaluated on tasks other than classification ? # # Update I thank the authors for some of the updates and response that address my concerns with clarity , but my main concern related to the interpretability aspect has not been resolved . The authors suggest that one can discard some of the rules learnt by the algorithm if the model becomes too large , using the weights in the linear layer to determine which rules should be kept . This seems like a good direction to explore , but it is unclear if a few rules typically dominate the predictions , or whether one will sacrifice significant accuracy in order to gain interpretability . As stated in my original review , I would have liked to see analysis of the * tradeoff * between interpretability and accuracy of this method . A few other things : * I still do not understand exactly how the hyperparameters were tuned . The authors have provided a list of those that were tuned , but I still do n't understand the process used for tuning them . * Some of the responses to other reviews have reinforced some of my concerns . In particular , it seems the distribution of weights attached to rules is not optimal for the proposed ( but unevaluated ) rule pruning method . Also , the authors conflate statistical significance with practical significance when replying to Reviewer 4 . [ 1 ] Dem\u0161ar , Janez . `` Statistical comparisons of classifiers over multiple data sets . '' Journal of Machine learning research ( 2006 ) . [ 2 ] Chen , Tianqi , and Carlos Guestrin . `` Xgboost : A scalable tree boosting system . '' In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( 2016 ) . [ 3 ] Yang , Yongxin , Irene Garcia Morillo , and Timothy M. Hospedales . `` Deep neural decision trees . '' arXiv preprint arXiv:1806.06988 ( 2018 ) . [ 4 ] Gouk , Henry , Bernhard Pfahringer , and Eibe Frank . `` Stochastic Gradient Trees . '' In Asian Conference on Machine Learning ( 2019 ) .", "rating": "5: Marginally below acceptance threshold", "reply_text": "> Comment 3 : The computational graph for gradient grafting seems related ( yet distinct ) to the Gumbel softmax estimatorperhaps the authors could discuss this relationship further ? Gumbel softmax is not suitable for RRL because it is used to generate a categorical distribution while the weight of the continuous RRL is not a probability . As we mentioned in Section 3.1 , one weight of the continuous RRL is used to tell how much the node it attached would affect the logical operation , and its corresponding weights in the discrete RRL is deterministic ( hard binarization with a threshold ) . Due to the particularity of logic operation , the change of one discrete weight may cause a big change of the whole model . Therefore , if we use Gumbel softmax instead , it is similar to use a soft binarization and it is hard to evaluate the loss of the discrete RRL . For the big difference between the soft binarized RRL and the hard binarized RRL , the RRL using Gumbel softmax can hardly converge during the training . Moreover , Gumbel softmax is mainly used for discrete outputs rather than discrete weights , and we usually do not use Gumbel softmax to train the binary neural networks . > Comment 4 : The authors could do more to discuss related work on training decision trees and rules using gradient-based optimisation . E.g. , XGBoost , DNDT , and SGT . Thank you for your advice . XGBoost is one implementation of GBDT , we have already discussed GBDT in our paper and used another implement of GBDT , i.e. , LightGBM [ 2 ] , in our experiments . DNDT is a tree model realised by neural networks with the help of soft binning function and Kronecker product . However , due to the use of Kronecker product , it is not scalable with respect to the number of features [ 3 ] . SGT is a stochastic gradient tree algorithm for incrementally constructing a decision tree using stochastic gradient information as the source of supervision . However , SGT mainly focuses on prediction performance rather than interpretability . What 's more , the scalability of SGT is not clear for the numbers of features of datasets in its experiments are all less than 100 [ 4 ] . [ 2 ] Guolin Ke , Qi Meng , Thomas Finley , Taifeng Wang , Wei Chen , Weidong Ma , Qiwei Ye , and Tie-Yan Liu . Lightgbm : A highly efficient gradient boosting decision tree . In Advances in Neural Information Processing Systems , pp . 3146\u20133154 , 2017 . [ 3 ] Yang , Yongxin , Irene Garcia Morillo , and Timothy M. Hospedales . `` Deep neural decision trees . '' arXiv preprint arXiv:1806.06988 ( 2018 ) . [ 4 ] Gouk , Henry , Bernhard Pfahringer , and Eibe Frank . `` Stochastic Gradient Trees . '' In Asian Conference on Machine Learning ( 2019 ) . > Comment 5 : Given that the model is trained with gradient descent , and arbitrary loss functions , could the model be evaluated on tasks other than classification ? Yes , it is easy to apply RRL to other tasks , e.g. , regression . As future work , we plan to apply RRL to tasks like regression , data generation , etc. , and evaluate the performance of RRL on these tasks ."}, {"review_id": "UwOMufsTqCy-1", "review_text": "The authors propose a classifier consisting of multiple layers . The inner layers construct rules in conjunctive normal form . The last layer is used to assign weights to the constructed rules . To train the overall model and obtain discrete solutions , the authors use a simple rounding mechanism leading to a method that they call gradient grafting . The paper concludes with a computational study , where the authors report the classification performance as well as the model complexity on a set of problems . This is an interesting paper proposing a new method to tackle the trade-off between interpretability and accuracy . Indeed , rule-based learners are considered to be more interpretable . The authors also claim that the proposed rule-learner is also scalable . Overall , introduction of a scalable , interpretable and accurate method could have been considered as a big achievement . However , I have several questions and comments about this achievement as I list below : - Are the results given for test set ? If so , what is the train-test percentage ? - What are the computation times ? Without these figures , it is hard to assess the scalability of the proposed method . - The numbers of edges that you report range from 50 to 1000 . These values seem quite large . How does this affect the interpretability ? - In Figure 4 , only five clear rules are reported . What is the distribution of the weights of the remaining rules ? - How do you decide various design parameters ; such as , number of layers ( n_l ) , number of bins for feature discretization ( k ) , number of layers ( L ) ? - As you need a binarization layer to divide the continuous features into bins , ca n't we just say that the method works only with discrete features ? This is how it would be presented by other rule-learning methods . - I guess Section 3.2 is superficial as it is straightforward to split a continuous feature into bins . Am I missing something here ? - How do your results compare against the results obtained with other rule/tree learning methods based on ( integer ) linear optimization ? Some names from that field are Bertsimas , Rudin , Gunluk . - Can you guarantee that the resulting set of rules covers the entire feature space ? In other words , is it possible that a test sample is not classified with the output set of rules ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "> Q6 : As you need a binarization layer to divide the continuous features into bins , ca n't we just say that the method works only with discrete features ? This is how it would be presented by other rule-learning methods . RRL can deal with continuous features for it realizes the continuous feature discretization in an end-to-end manner by combining the binarization layer with a logical layer . The binarization layer provides all the possible bounds and the logical layer choose the appropriate bounds to build the rules . Therefore , the binarization layer and logical layer are both important for the feature discretization , and that the difference between RRL and other rule-learning methods that can only deal with discrete features . > Q7 : I guess Section 3.2 is superficial as it is straightforward to split a continuous feature into bins . Am I missing something here ? The goal of Section 3.2 is not only to introduce the binarization layer , but also to emphasize the combination of the binarization layer and the logical layer . Indeed the binarization layer is simple , but it is effective for feature discretization with the help of one logical layer . As we mentioned in Section 4.2 , the experimental result in Table 1 indicates that the way RRL used to discretize continuous feature is better than the features discretization preprocessing used by CRS and SBRL for the preprocessing may bring bias to the data sets . > Q8 : How do your results compare against the results obtained with other rule/tree learning methods based on ( integer ) linear optimization ? Some names from that field are Bertsimas , Rudin , Gunluk . Could you please provide some paper here for these three researchers have too many works . > Q9 : Can you guarantee that the resulting set of rules covers the entire feature space ? In other words , is it possible that a test sample is not classified with the output set of rules ? If one test sample is not covered by all the rules , then the value of the last logical layer will be all zero , which means the linear layer will use the bias to classify this test sample . Therefore , there is no need to worry that one sample may not be covered by all the rules ."}, {"review_id": "UwOMufsTqCy-2", "review_text": "Authors propose a new scalable classifier , named Rule-based Representation Learner ( RRL ) , that can automatically learn interpretable rules for data representation and classification . For the particularity of RRL , the authors propose a new gradient-based discrete model training method , i.e. , Gradient Grafting , that directly optimizes the discrete model . Authors also propose an improved design of logical activation functions to increase the scalability of RRL and make RRL capable of discretizing the continuous features end-to-end . The experimental results show good performance of RRL both high classification performance and low model complexity on data sets with different scales . However , it is questionable whether the difference in accuracy between decision trees such as C4.5 and RRL in the experimental results is crucial . If the difference in accuracy is as small as this , the ease of interpretation of the decision tree may be superior to that of the RRL . Alternatively , the choice of experimental data may not be appropriate to demonstrate the superior performance of RRL . I also did n't understand why the fuzzy/soft rule sacrifices the model interpretability . Could it be that the fuzzy representation is intended to be closer to human subjectivity , and thus aid in intuitive understanding ?", "rating": "5: Marginally below acceptance threshold", "reply_text": "We appreciate the reviewer 's effort . Here are our responses to the comments . > Q1 : However , it is questionable whether the difference in accuracy between decision trees such as C4.5 and RRL in the experimental results is crucial . If the difference in accuracy is as small as this , the ease of interpretation of the decision tree may be superior to that of the RRL . Alternatively , the choice of experimental data may not be appropriate to demonstrate the superior performance of RRL . We performed a two-tailed Student \u2019 s t-test ( p < 0.001 ) for significance testing and found that our method RRL significantly outperforms decision trees on 10 out of 13 data sets in Table 1 . Therefore , it is unfair to say the difference between the accuracy of RRL and decision trees is small . What 's more , according to [ 1 ] , we can use functionally-grounded evaluation method , e.g. , total number of edges , to compare the interpretability of RRL and decision trees for they are all rule-based models and both have reused structures . Experimental results shown in Figure 2 and 6 indicate that the interpretability of RRL is close to decision trees when their accuracies are all acceptable . As we mentioned in Section 4.1 , the datasets we used are often used to test classification performance and model interpretability [ 2 ] [ 3 ] [ 4 ] [ 5 ] and the result of t-test also indicates that these datasets are appropriate to demonstrate the superior performance of RRL . [ 1 ] Doshi-Velez , Finale , and Been Kim . `` Towards a rigorous science of interpretable machine learning . '' arXiv preprint arXiv:1702.08608 ( 2017 ) . [ 2 ] Dheeru Dua and Casey Graff . UCI machine learning repository , 2017 . URL http : //archive.ics.uci.edu/ml . [ 3 ] Han Xiao , Kashif Rasul , and Roland Vollgraf . Fashion-mnist : a novel image dataset for benchmarking machine learning algorithms , 2017 . [ 4 ] Davide Anguita , Alessandro Ghio , Luca Oneto , Xavier Parra , and Jorge Luis Reyes-Ortiz . A public domain dataset for human activity recognition using smartphones . In Esann , 2013 . [ 5 ] S\u00b4ergio Moro , Paulo Rita , and Bernardo Vala . Predicting social media performance metrics and evaluation of the impact on brand building : A data mining approach . Journal of Business Research , 69 ( 9 ) :3341\u20133351 , 2016 . > Q2 : I also did n't understand why the fuzzy/soft rule sacrifices the model interpretability . Could it be that the fuzzy representation is intended to be closer to human subjectivity , and thus aid in intuitive understanding ? When we say the fuzzy/soft rule sacrifices the model interpretability , we indicate that the interpretability of discrete logical rules is better than fuzzy/soft rules . One important metric of interpretability is simulatability , which means a person can easily simulate the model or one part of the model [ 6 ] . However , the operation or computation of fuzzy/soft rules is more complex than the discrete rules . For example , one node in the soft decision tree is a logistic regression [ 7 ] while one node in the normal decision tree is just a split by feature values . The fuzzy sets used by fuzzy rules make it harder to simulate too . [ 8 ] also indicates that fuzzy knowledge representation must confront the problem of preserving the overall system accuracy , thus often yielding a trade-off between accuracy and interpretability . In practice , the fuzzy set close to human subjectivity is hard to obtain , especially for the datasets with only class labels information available . [ 6 ] Lipton , Zachary C. `` The mythos of model interpretability . '' Queue 16.3 ( 2018 ) : 31-57 . [ 7 ] Irsoy , Ozan , Olcay Taner Y\u0131ld\u0131z , and Ethem Alpayd\u0131n . `` Soft decision trees . '' Proceedings of the 21st International Conference on Pattern Recognition ( ICPR2012 ) . IEEE , 2012 . [ 8 ] Alonso , Jose M. , Ciro Castiello , and Corrado Mencar . `` Interpretability of fuzzy systems : Current research trends and prospects . '' Springer handbook of computational intelligence . Springer , Berlin , Heidelberg , 2015 . 219-237 ."}, {"review_id": "UwOMufsTqCy-3", "review_text": "Summary : This paper presents a new rule based classifier called Rule based Representation Learner ( RRL ) , that automatically learns interpretable non-fuzzy rules for data representation . In order to train this model efficiently the paper presents a learning algorithm that projects the discrete RRL model to a continuous space and hence optimise the model using gradient descent . Through experiments on 9 small and 4 large datasets shows that RRL improves over other methods , has low complexity and interpretable . Reasons for score : I think this is a Good paper and vote for accepting . This paper presents a solid contribution in learning rule based classifiers and hence to interpretable machine learning . The paper is clearly written and superiority of the presented models are backed by strong experimental results . Pros : 1.The paper is clearly written and easy to follow . 2.The paper addressees an important problem of interpretable machine learning and presents a novel model which is scalable . I find the technique of gradient grafting particularly interesting . 3.Very strong experimental results and ablation studies .", "rating": "7: Good paper, accept", "reply_text": "Many thanks for your strong review , we \u2019 re glad to hear you are pleased with the paper ! Thanks for arguing in our favor ! We believe that our paper will inspire other research on interpretable machine learning ."}], "0": {"review_id": "UwOMufsTqCy-0", "review_text": "# # Summary The authors propose a new approach for training interpretable discrete models via gradient descent . They claim three contributions : 1 ) incorporation of layers implementing logical conjunction and disjunction operations ; 2 ) the gradient grafting technique for performing gradient descent on discrete structures ; and 3 ) a logical activation function that enables models to scale to larger training datasets . Additionally , they also claim competitive performance with comparable learning methods . # # Strengths * The paper is well organised and easy to follow . * The proposed gradient grafting technique , while heuristic in nature , is novel and seems to work quite well in practice . * The proposed method achieves good accuracy compared to the other approaches considered in the experiments . # # Weaknesses * There is limited novelty in the proposed model . The continuous/discrete conjunction and disjunction operations used in the logical layers are the same as those used in Wang et al . ( 2020 ) , however they are arranged differently in this method . * The connection betweent the continuous version of the model and the discrete version is weak . One of the claimed contributions is that the discrete model is optimised directly , but this does not seem to be the case in practicethe continuous version of the model is optimised . It is also unclear how the continuous-valued weights are binarised in order to work with the discrete version of the model . * The results in Figure 2 indicate that typically a large number of rules are learned , yielding models that are unlikely to be interpreted reliably . The log scale on the x axis of the plots is somewhat deceptiveI find it hard to believe that models with between 64 -- 256 terms are interpretable . I think further investigating what tradeoff exists between accuracy and interpretability is necessary before the paper can be accepted . # # Other comments/questions * Comparing average accuracy is generally not a good idea . It is more informative to compare the average rank of each method across datasets [ 1 ] . * Can the authors elaborate on how hyperparameters for each of the competing methods are chosen ? * The computational graph for gradient grafting seems related ( yet distinct ) to the Gumbel softmax estimatorperhaps the authors could discuss this relationship further ? * The authors could do more to discuss related work on training decision trees and rules using gradient-based optimisation . E.g. , XGBoost [ 2 ] , DNDT [ 3 ] , and SGT [ 4 ] . * Given that the model is trained with gradient descent , and arbitrary loss functions , could the model be evaluated on tasks other than classification ? # # Update I thank the authors for some of the updates and response that address my concerns with clarity , but my main concern related to the interpretability aspect has not been resolved . The authors suggest that one can discard some of the rules learnt by the algorithm if the model becomes too large , using the weights in the linear layer to determine which rules should be kept . This seems like a good direction to explore , but it is unclear if a few rules typically dominate the predictions , or whether one will sacrifice significant accuracy in order to gain interpretability . As stated in my original review , I would have liked to see analysis of the * tradeoff * between interpretability and accuracy of this method . A few other things : * I still do not understand exactly how the hyperparameters were tuned . The authors have provided a list of those that were tuned , but I still do n't understand the process used for tuning them . * Some of the responses to other reviews have reinforced some of my concerns . In particular , it seems the distribution of weights attached to rules is not optimal for the proposed ( but unevaluated ) rule pruning method . Also , the authors conflate statistical significance with practical significance when replying to Reviewer 4 . [ 1 ] Dem\u0161ar , Janez . `` Statistical comparisons of classifiers over multiple data sets . '' Journal of Machine learning research ( 2006 ) . [ 2 ] Chen , Tianqi , and Carlos Guestrin . `` Xgboost : A scalable tree boosting system . '' In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( 2016 ) . [ 3 ] Yang , Yongxin , Irene Garcia Morillo , and Timothy M. Hospedales . `` Deep neural decision trees . '' arXiv preprint arXiv:1806.06988 ( 2018 ) . [ 4 ] Gouk , Henry , Bernhard Pfahringer , and Eibe Frank . `` Stochastic Gradient Trees . '' In Asian Conference on Machine Learning ( 2019 ) .", "rating": "5: Marginally below acceptance threshold", "reply_text": "> Comment 3 : The computational graph for gradient grafting seems related ( yet distinct ) to the Gumbel softmax estimatorperhaps the authors could discuss this relationship further ? Gumbel softmax is not suitable for RRL because it is used to generate a categorical distribution while the weight of the continuous RRL is not a probability . As we mentioned in Section 3.1 , one weight of the continuous RRL is used to tell how much the node it attached would affect the logical operation , and its corresponding weights in the discrete RRL is deterministic ( hard binarization with a threshold ) . Due to the particularity of logic operation , the change of one discrete weight may cause a big change of the whole model . Therefore , if we use Gumbel softmax instead , it is similar to use a soft binarization and it is hard to evaluate the loss of the discrete RRL . For the big difference between the soft binarized RRL and the hard binarized RRL , the RRL using Gumbel softmax can hardly converge during the training . Moreover , Gumbel softmax is mainly used for discrete outputs rather than discrete weights , and we usually do not use Gumbel softmax to train the binary neural networks . > Comment 4 : The authors could do more to discuss related work on training decision trees and rules using gradient-based optimisation . E.g. , XGBoost , DNDT , and SGT . Thank you for your advice . XGBoost is one implementation of GBDT , we have already discussed GBDT in our paper and used another implement of GBDT , i.e. , LightGBM [ 2 ] , in our experiments . DNDT is a tree model realised by neural networks with the help of soft binning function and Kronecker product . However , due to the use of Kronecker product , it is not scalable with respect to the number of features [ 3 ] . SGT is a stochastic gradient tree algorithm for incrementally constructing a decision tree using stochastic gradient information as the source of supervision . However , SGT mainly focuses on prediction performance rather than interpretability . What 's more , the scalability of SGT is not clear for the numbers of features of datasets in its experiments are all less than 100 [ 4 ] . [ 2 ] Guolin Ke , Qi Meng , Thomas Finley , Taifeng Wang , Wei Chen , Weidong Ma , Qiwei Ye , and Tie-Yan Liu . Lightgbm : A highly efficient gradient boosting decision tree . In Advances in Neural Information Processing Systems , pp . 3146\u20133154 , 2017 . [ 3 ] Yang , Yongxin , Irene Garcia Morillo , and Timothy M. Hospedales . `` Deep neural decision trees . '' arXiv preprint arXiv:1806.06988 ( 2018 ) . [ 4 ] Gouk , Henry , Bernhard Pfahringer , and Eibe Frank . `` Stochastic Gradient Trees . '' In Asian Conference on Machine Learning ( 2019 ) . > Comment 5 : Given that the model is trained with gradient descent , and arbitrary loss functions , could the model be evaluated on tasks other than classification ? Yes , it is easy to apply RRL to other tasks , e.g. , regression . As future work , we plan to apply RRL to tasks like regression , data generation , etc. , and evaluate the performance of RRL on these tasks ."}, "1": {"review_id": "UwOMufsTqCy-1", "review_text": "The authors propose a classifier consisting of multiple layers . The inner layers construct rules in conjunctive normal form . The last layer is used to assign weights to the constructed rules . To train the overall model and obtain discrete solutions , the authors use a simple rounding mechanism leading to a method that they call gradient grafting . The paper concludes with a computational study , where the authors report the classification performance as well as the model complexity on a set of problems . This is an interesting paper proposing a new method to tackle the trade-off between interpretability and accuracy . Indeed , rule-based learners are considered to be more interpretable . The authors also claim that the proposed rule-learner is also scalable . Overall , introduction of a scalable , interpretable and accurate method could have been considered as a big achievement . However , I have several questions and comments about this achievement as I list below : - Are the results given for test set ? If so , what is the train-test percentage ? - What are the computation times ? Without these figures , it is hard to assess the scalability of the proposed method . - The numbers of edges that you report range from 50 to 1000 . These values seem quite large . How does this affect the interpretability ? - In Figure 4 , only five clear rules are reported . What is the distribution of the weights of the remaining rules ? - How do you decide various design parameters ; such as , number of layers ( n_l ) , number of bins for feature discretization ( k ) , number of layers ( L ) ? - As you need a binarization layer to divide the continuous features into bins , ca n't we just say that the method works only with discrete features ? This is how it would be presented by other rule-learning methods . - I guess Section 3.2 is superficial as it is straightforward to split a continuous feature into bins . Am I missing something here ? - How do your results compare against the results obtained with other rule/tree learning methods based on ( integer ) linear optimization ? Some names from that field are Bertsimas , Rudin , Gunluk . - Can you guarantee that the resulting set of rules covers the entire feature space ? In other words , is it possible that a test sample is not classified with the output set of rules ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "> Q6 : As you need a binarization layer to divide the continuous features into bins , ca n't we just say that the method works only with discrete features ? This is how it would be presented by other rule-learning methods . RRL can deal with continuous features for it realizes the continuous feature discretization in an end-to-end manner by combining the binarization layer with a logical layer . The binarization layer provides all the possible bounds and the logical layer choose the appropriate bounds to build the rules . Therefore , the binarization layer and logical layer are both important for the feature discretization , and that the difference between RRL and other rule-learning methods that can only deal with discrete features . > Q7 : I guess Section 3.2 is superficial as it is straightforward to split a continuous feature into bins . Am I missing something here ? The goal of Section 3.2 is not only to introduce the binarization layer , but also to emphasize the combination of the binarization layer and the logical layer . Indeed the binarization layer is simple , but it is effective for feature discretization with the help of one logical layer . As we mentioned in Section 4.2 , the experimental result in Table 1 indicates that the way RRL used to discretize continuous feature is better than the features discretization preprocessing used by CRS and SBRL for the preprocessing may bring bias to the data sets . > Q8 : How do your results compare against the results obtained with other rule/tree learning methods based on ( integer ) linear optimization ? Some names from that field are Bertsimas , Rudin , Gunluk . Could you please provide some paper here for these three researchers have too many works . > Q9 : Can you guarantee that the resulting set of rules covers the entire feature space ? In other words , is it possible that a test sample is not classified with the output set of rules ? If one test sample is not covered by all the rules , then the value of the last logical layer will be all zero , which means the linear layer will use the bias to classify this test sample . Therefore , there is no need to worry that one sample may not be covered by all the rules ."}, "2": {"review_id": "UwOMufsTqCy-2", "review_text": "Authors propose a new scalable classifier , named Rule-based Representation Learner ( RRL ) , that can automatically learn interpretable rules for data representation and classification . For the particularity of RRL , the authors propose a new gradient-based discrete model training method , i.e. , Gradient Grafting , that directly optimizes the discrete model . Authors also propose an improved design of logical activation functions to increase the scalability of RRL and make RRL capable of discretizing the continuous features end-to-end . The experimental results show good performance of RRL both high classification performance and low model complexity on data sets with different scales . However , it is questionable whether the difference in accuracy between decision trees such as C4.5 and RRL in the experimental results is crucial . If the difference in accuracy is as small as this , the ease of interpretation of the decision tree may be superior to that of the RRL . Alternatively , the choice of experimental data may not be appropriate to demonstrate the superior performance of RRL . I also did n't understand why the fuzzy/soft rule sacrifices the model interpretability . Could it be that the fuzzy representation is intended to be closer to human subjectivity , and thus aid in intuitive understanding ?", "rating": "5: Marginally below acceptance threshold", "reply_text": "We appreciate the reviewer 's effort . Here are our responses to the comments . > Q1 : However , it is questionable whether the difference in accuracy between decision trees such as C4.5 and RRL in the experimental results is crucial . If the difference in accuracy is as small as this , the ease of interpretation of the decision tree may be superior to that of the RRL . Alternatively , the choice of experimental data may not be appropriate to demonstrate the superior performance of RRL . We performed a two-tailed Student \u2019 s t-test ( p < 0.001 ) for significance testing and found that our method RRL significantly outperforms decision trees on 10 out of 13 data sets in Table 1 . Therefore , it is unfair to say the difference between the accuracy of RRL and decision trees is small . What 's more , according to [ 1 ] , we can use functionally-grounded evaluation method , e.g. , total number of edges , to compare the interpretability of RRL and decision trees for they are all rule-based models and both have reused structures . Experimental results shown in Figure 2 and 6 indicate that the interpretability of RRL is close to decision trees when their accuracies are all acceptable . As we mentioned in Section 4.1 , the datasets we used are often used to test classification performance and model interpretability [ 2 ] [ 3 ] [ 4 ] [ 5 ] and the result of t-test also indicates that these datasets are appropriate to demonstrate the superior performance of RRL . [ 1 ] Doshi-Velez , Finale , and Been Kim . `` Towards a rigorous science of interpretable machine learning . '' arXiv preprint arXiv:1702.08608 ( 2017 ) . [ 2 ] Dheeru Dua and Casey Graff . UCI machine learning repository , 2017 . URL http : //archive.ics.uci.edu/ml . [ 3 ] Han Xiao , Kashif Rasul , and Roland Vollgraf . Fashion-mnist : a novel image dataset for benchmarking machine learning algorithms , 2017 . [ 4 ] Davide Anguita , Alessandro Ghio , Luca Oneto , Xavier Parra , and Jorge Luis Reyes-Ortiz . A public domain dataset for human activity recognition using smartphones . In Esann , 2013 . [ 5 ] S\u00b4ergio Moro , Paulo Rita , and Bernardo Vala . Predicting social media performance metrics and evaluation of the impact on brand building : A data mining approach . Journal of Business Research , 69 ( 9 ) :3341\u20133351 , 2016 . > Q2 : I also did n't understand why the fuzzy/soft rule sacrifices the model interpretability . Could it be that the fuzzy representation is intended to be closer to human subjectivity , and thus aid in intuitive understanding ? When we say the fuzzy/soft rule sacrifices the model interpretability , we indicate that the interpretability of discrete logical rules is better than fuzzy/soft rules . One important metric of interpretability is simulatability , which means a person can easily simulate the model or one part of the model [ 6 ] . However , the operation or computation of fuzzy/soft rules is more complex than the discrete rules . For example , one node in the soft decision tree is a logistic regression [ 7 ] while one node in the normal decision tree is just a split by feature values . The fuzzy sets used by fuzzy rules make it harder to simulate too . [ 8 ] also indicates that fuzzy knowledge representation must confront the problem of preserving the overall system accuracy , thus often yielding a trade-off between accuracy and interpretability . In practice , the fuzzy set close to human subjectivity is hard to obtain , especially for the datasets with only class labels information available . [ 6 ] Lipton , Zachary C. `` The mythos of model interpretability . '' Queue 16.3 ( 2018 ) : 31-57 . [ 7 ] Irsoy , Ozan , Olcay Taner Y\u0131ld\u0131z , and Ethem Alpayd\u0131n . `` Soft decision trees . '' Proceedings of the 21st International Conference on Pattern Recognition ( ICPR2012 ) . IEEE , 2012 . [ 8 ] Alonso , Jose M. , Ciro Castiello , and Corrado Mencar . `` Interpretability of fuzzy systems : Current research trends and prospects . '' Springer handbook of computational intelligence . Springer , Berlin , Heidelberg , 2015 . 219-237 ."}, "3": {"review_id": "UwOMufsTqCy-3", "review_text": "Summary : This paper presents a new rule based classifier called Rule based Representation Learner ( RRL ) , that automatically learns interpretable non-fuzzy rules for data representation . In order to train this model efficiently the paper presents a learning algorithm that projects the discrete RRL model to a continuous space and hence optimise the model using gradient descent . Through experiments on 9 small and 4 large datasets shows that RRL improves over other methods , has low complexity and interpretable . Reasons for score : I think this is a Good paper and vote for accepting . This paper presents a solid contribution in learning rule based classifiers and hence to interpretable machine learning . The paper is clearly written and superiority of the presented models are backed by strong experimental results . Pros : 1.The paper is clearly written and easy to follow . 2.The paper addressees an important problem of interpretable machine learning and presents a novel model which is scalable . I find the technique of gradient grafting particularly interesting . 3.Very strong experimental results and ablation studies .", "rating": "7: Good paper, accept", "reply_text": "Many thanks for your strong review , we \u2019 re glad to hear you are pleased with the paper ! Thanks for arguing in our favor ! We believe that our paper will inspire other research on interpretable machine learning ."}}