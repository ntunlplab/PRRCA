{"year": "2020", "forum": "S1lxKlSKPH", "title": "Consistency Regularization for Generative Adversarial Networks", "decision": "Accept (Poster)", "meta_review": "The paper proposes a simple and effective way to stabilize training by adding consistency term to discriminator. Given the stochastic augmentation procedure $T(x)$ the loss is just a penalty on $D$. The main unsolved question why it help to make discriminator \"smoother\" in the consistency case for a standard GAN (since typically, no constraints are enforced). Nevertheless, at the moment this a working heuristics that gives new SOTA, and that is the main strength. The reviewer all agree to accept, and so do I.", "reviews": [{"review_id": "S1lxKlSKPH-0", "review_text": "The topic of this paper is out of the reviewer's domain (Bayesian optimization, RL, and neuroscience). The reviewer has been reviewing ICLR for several years. Such mismatches had not happened in the past. The reviewer doesn't think this paper reached the bar of a good ICLR paper but hesitates to reject. This work proposed a training stabilizer for GANs based on the notion of Consistency Regularization. Experimentally, the authors had augmented data passed into the GAN discriminator and penalize the sensitivity of the ultimate layer of the discriminator to these augmentations. The authors claimed \"We conduct a series of ablation studies to demonstrate that the consistency regularization is compatible with various GAN architectures and loss functions. Moreover, the proposed simple regularization can consistently improve these different GANs variants significantly. \" ", "rating": "6: Weak Accept", "reply_text": "Thank you for your comments . In this paper , we propose a simple , effective , and computationally cheap method \u2013 consistency regularization \u2013 to improve the performance of GANs . We also have conducted extensive experiments to verify the proposed method . We achieved state of the art results for both conditional and unconditional image generation . Since we have substantially improved the writing of our paper and added more experiments during the rebuttal process , we would be grateful if the reviewer would take another look of the updated version . See also the other two reviews for unbiased opinions on the merits of our submission ."}, {"review_id": "S1lxKlSKPH-1", "review_text": "This paper proposes to use Consistency Regularization for training GANs, a technique known to work well in unsupervised learning. The technique consists in applying a transformation to real images and enforcing that the features of the discriminator between the transformed inputs and the original inputs are similar. The author show that using this technique enables them to improve the performance of a standard GAN significantly on CIFAR10. They also carry an ablation study studying the influence of the different part of the proposed technique. Overall I'm in favor of accepting this paper. The paper is well written, with convincing experiments and an interesting ablation study. However I have several minor issues that I think could greatly improve the paper if addressed. Minor comments: - I think an idea which is somewhat related but hasn't been mentioned in the paper, is the idea of adding noise to the input when training GANs [1]. I think this is worth mentioning in the related work. - Related to the previous point, why penalizing features and not directly output ? What about also trying to classify the transformed images as real ? Also you say that penalizing the last layer, I think including the influence of m (eq 2) in the ablation study would be interesting. - The authors provide some measure of standard deviation on some experiments but not on all of them. It would be nice to systematically report the standard deviation for every experiments. - In figure 1 the author make the hypothesis that the discriminator will output very different score to images semantically close together. Did the author verify this hypothesis experimentally ? - Also why penalizing only the samples from the real distribution and not from the generator ? have you tried both ? - When the test accuracy of the discriminator is low, it could also be that the discriminator is under-fitting, it would be nice to also report the train accuracy for the discriminator. - I think the conclusion about the effect of consistency regularization vs data augmentation is a bit vague since consistency regularization has no sense without data-augmentation. - It's quite interesting but also disappointing that combining transformations doesn't give that much of an improvement. Do the author have any intuition why this is the case ? and why learning them one after the other would work ? References: [1] Arjovsky and Bottou. \"Towards Principled Methods for Training Generative Adversarial Networks.\" (ICLR 2017)", "rating": "6: Weak Accept", "reply_text": "Thank you for all the valuable comments . Q1 : Related work [ 1 ] Thank you for pointing out the related work . We cited this paper in our revision . Q2 : Regularizing with features vs output In our method , we penalize sensitivity of the last layer ( which is one dimensional ) of the discriminator . It is actually the output for both hinge loss and Wasserstein loss . We add the consistency regularization before sigmoid activation for NS loss to be consistent with the other two losses . Since sigmoid function will squash the range of the output , we would need large regularization coefficient to mitigate this . We also verified this experimentally . On CIFAR-10 with DCGAN structure and NS loss : Setting FID CR before sigmoid ( \\lambda=10 ) 19.71\u00b10.28 CR after sigmoid ( \\lambda=10 ) 22.23\u00b10.85 CR after sigmoid ( \\lambda=100 ) 19.75\u00b10.24 The reason we did not classify the transformed images as real is that we reasoned that consistency cost is more informative than pure 0 or 1 labels . In other words , classifying with 0/1 loss will treat all real images and their transformed images with the same label as \u201c real \u201d without considering semantics , whereas our consistency cost further enforces learning implicit manifold structure that pulls semantically similar images ( original real image and the transformed image ) to be closer . We will clarify this further in the revision . We also added the ablation study for the sensitivity of different layers . Details can be seen in our reply to Q2 of Reviewer1 and Appendix G. Q3 : Measure of standard deviation in experiments We agree with the reviewer and will update the paper to report the result more systematically . It 's also worth mentioning that the box plots in our paper help to show the variance of the experiments . Q4 : Effect of CR regularization on the discriminator output Yes , we have verified it experimentally . With consistency regularization , the average output distance between real and augmented sample is 0.00449\u00b10.00149 . However , without consistency regularization , the average output distance keeps increasing during training.The final average distance is 4.50\u00b11.54 , which is roughly around 1000 times larger than the one with consistency regularization . Q5 : Consistency regularization on the images sampled from the generator Yes , we have tried to add the consistency on the generator outputs as well . In such case , the computational cost is doubled but the performance gains vary according to different experiment settings . It improves FID from 20.21\u00b10.28 to 15.51\u00b10.25 for SNDCGAN , but it also gives slightly worse results for ResNet from 14.93\u00b10.40 to 15.07\u00b10.34 and for CR-BigGAN * from 11.48\u00b10.21 to 12.51\u00b10.21 . We have added the discussion and more results in Appendix H. Q6 : Train/test accuracy of discriminator We have added the training accuracy in Figure 5 . For the vanilla GAN , training accuracy of the discriminator is over 0.7 , but the test accuracy is around 0.2 . It indicates the discriminator is overfitting in such cases ."}, {"review_id": "S1lxKlSKPH-2", "review_text": "Summary: The paper presents a new regularization technique termed consistency regularization for training GANs. The idea is the following: the authors propose to penalize the sensitivity of the last layer of the discriminator to augmented images. This idea is simple yet efficient: it is easy to implement, a regularization term is gradient-free, and its computation is up to 1.8 times faster than standard gradient-based regularization techniques. The authors tested different augmentation techniques and concluded that simple ones behave better (e.g., shifting and flipping). The experimental results show an impressive gain in FID measure, renewing the current state-of-the-art score for class conditional image generation on CIFAR-10 dataset. Pros: The proposed technique is very simple and intuitive; it easy to implement, and it is computationally cheap. The experiments were held for three runs with different random seeds, supporting its consistency. The paper is overall clearly written and easy to understand. Cons: The reported experimental results are held only for BigGAN architecture while not considering different networks to ensure the stability of the proposed regularization. Also, the paper would benefit from a clear experiment description on CelebA dataset (e.g., adding the results to Table 1). Questions: -Have you tried other transforms, which potentially keep images on the manifold, including zoom, resize, rotation, brightness adjustment, etc.? -How the number of layers in $L_{cs}$ (formulas 2-3) affects FID? -Have you considered an unconditional setting? Minor comments: -It would be more convenient if the authors explicitly numerate subplots; e.g., in Figure 2, it is confusing to refer the subplots labeled by (a)-(f) as written in caption. -Additionally, it would be nice to include say best FID scores over different loss functions (from Figure 2) to Table 1. - In section 4.3, you wrote that you tried different $\\lambda$ values: {0,1,10, 100}, but Figure 4 does not cover all of them. - It would be nice to add implementation details (e.g., optimizer, learning rate parameters, steps per discriminator, etc.) for better reproducibility. -The paper would benefit from illustrations of generated samples. -Please check the spelling of the penultimate article name in references (Zhai et al., 2019). ", "rating": "8: Accept", "reply_text": "Thank you for your valuable comments . Q1 : Effect of different types of transformations We added experiments to examine different augmentations including random flip , shift , zoom , rotation , brightness and cutout on both CIFAR-10 and CelebA dataset with SNDCGAN and NS loss . The results are listed below : Dataset shift and flip brightness zoom rotate cutout gaussian SBZR * CIFAR-10 20.50\u00b10.12 25.83\u00b10.18 30.44\u00b10.36 28.58\u00b10.14 22.52\u00b10.42 36.72\u00b11.77 27.82\u00b10.83 CelebA 18.84\u00b10.25 26.81\u00b10.61 24.51\u00b10.42 45.06\u00b16.62 24.86\u00b10.33 44.47\u00b10.45 23.80\u00b10.36 * SBZR means the combination of shift & flip , brightness , zoom and rotate . From these two datasets , shifting and flipping achieves the best result and adding gaussian noise usually achieves the worst result , which is consistent with our findings in Sec.4.2.For CIFAR-10 dataset , changing brightness is better than zooming and rotation , whereas for CelebA , zooming is better compared to rotation and changes in brightness . We think the performance for different augmentations depends on data distribution of different datasets . For example , in the CelebA dataset , zooming effect is more natural than rotation , since the face images are quite well aligned . Q2 : Effect of the number of intermediate layers on FID We added one more experiment to study the effect of different numbers of intermediate layers in CR-GAN . We add consistency regularization to the last k intermediate layers . We use two weighting variations to combine the consistency loss across different layers . In the first setting , the weight of each layer is the inverse of feature dimension in that layer . In the second setting , we give equal weight to each layer . The FID scores for both settings are shown below . number of intermediate layers weight setting1 weight setting2 k=0 19.41\u00b10.57 19.48\u00b10.41 k=1 19.76\u00b10.88 20.53\u00b11.01 k=2 19.66\u00b10.36 19.65\u00b10.57 k=3 19.31\u00b10.53 21.57\u00b10.51 k=4 19.57\u00b10.09 25.03\u00b10.95 k=5 20.61\u00b10.26 111.08\u00b1107.43 k=6 20.99\u00b10.52 411.31\u00b113.88 k=7 21.45\u00b10.46 460.83\u00b126.21 k=8 23.32\u00b10.30 386.38\u00b172.37 In both settings , we observe that consistency regularization on the final layer ( k=0 ) achieves reasonably good results . In addition , adding the consistency to the first few layers in the discriminator harms the performance . For simplicity , we only add consistency regularization in the final layer of the discriminator for the rest of our experiments . We also add more details in Appendix G. Q3 : Experiments on unconditional setting We have done experiments for both conditional and unconditional settings . We have updated the paper to make this more clear . In the updated version , Sec 3.2 is for the unconditional setting and Sec 3.3 is for the conditional setting . Regarding the minor comments : Thank you for all these valuable suggestions . We have edited our paper accordingly . For example , ( 1 ) We labeled the subplot in Figure 2 . ( 2 ) We added the best FID for each method in Table 1 . ( 3 ) We showed the results to cover all the regularization coefficient in Figure 3 . ( 4 ) We added the implementation details in Appendix A ( 5 ) We added the illustrations of generated samples in Appendix D and E. ( 6 ) We fixed the typo in the reference ."}], "0": {"review_id": "S1lxKlSKPH-0", "review_text": "The topic of this paper is out of the reviewer's domain (Bayesian optimization, RL, and neuroscience). The reviewer has been reviewing ICLR for several years. Such mismatches had not happened in the past. The reviewer doesn't think this paper reached the bar of a good ICLR paper but hesitates to reject. This work proposed a training stabilizer for GANs based on the notion of Consistency Regularization. Experimentally, the authors had augmented data passed into the GAN discriminator and penalize the sensitivity of the ultimate layer of the discriminator to these augmentations. The authors claimed \"We conduct a series of ablation studies to demonstrate that the consistency regularization is compatible with various GAN architectures and loss functions. Moreover, the proposed simple regularization can consistently improve these different GANs variants significantly. \" ", "rating": "6: Weak Accept", "reply_text": "Thank you for your comments . In this paper , we propose a simple , effective , and computationally cheap method \u2013 consistency regularization \u2013 to improve the performance of GANs . We also have conducted extensive experiments to verify the proposed method . We achieved state of the art results for both conditional and unconditional image generation . Since we have substantially improved the writing of our paper and added more experiments during the rebuttal process , we would be grateful if the reviewer would take another look of the updated version . See also the other two reviews for unbiased opinions on the merits of our submission ."}, "1": {"review_id": "S1lxKlSKPH-1", "review_text": "This paper proposes to use Consistency Regularization for training GANs, a technique known to work well in unsupervised learning. The technique consists in applying a transformation to real images and enforcing that the features of the discriminator between the transformed inputs and the original inputs are similar. The author show that using this technique enables them to improve the performance of a standard GAN significantly on CIFAR10. They also carry an ablation study studying the influence of the different part of the proposed technique. Overall I'm in favor of accepting this paper. The paper is well written, with convincing experiments and an interesting ablation study. However I have several minor issues that I think could greatly improve the paper if addressed. Minor comments: - I think an idea which is somewhat related but hasn't been mentioned in the paper, is the idea of adding noise to the input when training GANs [1]. I think this is worth mentioning in the related work. - Related to the previous point, why penalizing features and not directly output ? What about also trying to classify the transformed images as real ? Also you say that penalizing the last layer, I think including the influence of m (eq 2) in the ablation study would be interesting. - The authors provide some measure of standard deviation on some experiments but not on all of them. It would be nice to systematically report the standard deviation for every experiments. - In figure 1 the author make the hypothesis that the discriminator will output very different score to images semantically close together. Did the author verify this hypothesis experimentally ? - Also why penalizing only the samples from the real distribution and not from the generator ? have you tried both ? - When the test accuracy of the discriminator is low, it could also be that the discriminator is under-fitting, it would be nice to also report the train accuracy for the discriminator. - I think the conclusion about the effect of consistency regularization vs data augmentation is a bit vague since consistency regularization has no sense without data-augmentation. - It's quite interesting but also disappointing that combining transformations doesn't give that much of an improvement. Do the author have any intuition why this is the case ? and why learning them one after the other would work ? References: [1] Arjovsky and Bottou. \"Towards Principled Methods for Training Generative Adversarial Networks.\" (ICLR 2017)", "rating": "6: Weak Accept", "reply_text": "Thank you for all the valuable comments . Q1 : Related work [ 1 ] Thank you for pointing out the related work . We cited this paper in our revision . Q2 : Regularizing with features vs output In our method , we penalize sensitivity of the last layer ( which is one dimensional ) of the discriminator . It is actually the output for both hinge loss and Wasserstein loss . We add the consistency regularization before sigmoid activation for NS loss to be consistent with the other two losses . Since sigmoid function will squash the range of the output , we would need large regularization coefficient to mitigate this . We also verified this experimentally . On CIFAR-10 with DCGAN structure and NS loss : Setting FID CR before sigmoid ( \\lambda=10 ) 19.71\u00b10.28 CR after sigmoid ( \\lambda=10 ) 22.23\u00b10.85 CR after sigmoid ( \\lambda=100 ) 19.75\u00b10.24 The reason we did not classify the transformed images as real is that we reasoned that consistency cost is more informative than pure 0 or 1 labels . In other words , classifying with 0/1 loss will treat all real images and their transformed images with the same label as \u201c real \u201d without considering semantics , whereas our consistency cost further enforces learning implicit manifold structure that pulls semantically similar images ( original real image and the transformed image ) to be closer . We will clarify this further in the revision . We also added the ablation study for the sensitivity of different layers . Details can be seen in our reply to Q2 of Reviewer1 and Appendix G. Q3 : Measure of standard deviation in experiments We agree with the reviewer and will update the paper to report the result more systematically . It 's also worth mentioning that the box plots in our paper help to show the variance of the experiments . Q4 : Effect of CR regularization on the discriminator output Yes , we have verified it experimentally . With consistency regularization , the average output distance between real and augmented sample is 0.00449\u00b10.00149 . However , without consistency regularization , the average output distance keeps increasing during training.The final average distance is 4.50\u00b11.54 , which is roughly around 1000 times larger than the one with consistency regularization . Q5 : Consistency regularization on the images sampled from the generator Yes , we have tried to add the consistency on the generator outputs as well . In such case , the computational cost is doubled but the performance gains vary according to different experiment settings . It improves FID from 20.21\u00b10.28 to 15.51\u00b10.25 for SNDCGAN , but it also gives slightly worse results for ResNet from 14.93\u00b10.40 to 15.07\u00b10.34 and for CR-BigGAN * from 11.48\u00b10.21 to 12.51\u00b10.21 . We have added the discussion and more results in Appendix H. Q6 : Train/test accuracy of discriminator We have added the training accuracy in Figure 5 . For the vanilla GAN , training accuracy of the discriminator is over 0.7 , but the test accuracy is around 0.2 . It indicates the discriminator is overfitting in such cases ."}, "2": {"review_id": "S1lxKlSKPH-2", "review_text": "Summary: The paper presents a new regularization technique termed consistency regularization for training GANs. The idea is the following: the authors propose to penalize the sensitivity of the last layer of the discriminator to augmented images. This idea is simple yet efficient: it is easy to implement, a regularization term is gradient-free, and its computation is up to 1.8 times faster than standard gradient-based regularization techniques. The authors tested different augmentation techniques and concluded that simple ones behave better (e.g., shifting and flipping). The experimental results show an impressive gain in FID measure, renewing the current state-of-the-art score for class conditional image generation on CIFAR-10 dataset. Pros: The proposed technique is very simple and intuitive; it easy to implement, and it is computationally cheap. The experiments were held for three runs with different random seeds, supporting its consistency. The paper is overall clearly written and easy to understand. Cons: The reported experimental results are held only for BigGAN architecture while not considering different networks to ensure the stability of the proposed regularization. Also, the paper would benefit from a clear experiment description on CelebA dataset (e.g., adding the results to Table 1). Questions: -Have you tried other transforms, which potentially keep images on the manifold, including zoom, resize, rotation, brightness adjustment, etc.? -How the number of layers in $L_{cs}$ (formulas 2-3) affects FID? -Have you considered an unconditional setting? Minor comments: -It would be more convenient if the authors explicitly numerate subplots; e.g., in Figure 2, it is confusing to refer the subplots labeled by (a)-(f) as written in caption. -Additionally, it would be nice to include say best FID scores over different loss functions (from Figure 2) to Table 1. - In section 4.3, you wrote that you tried different $\\lambda$ values: {0,1,10, 100}, but Figure 4 does not cover all of them. - It would be nice to add implementation details (e.g., optimizer, learning rate parameters, steps per discriminator, etc.) for better reproducibility. -The paper would benefit from illustrations of generated samples. -Please check the spelling of the penultimate article name in references (Zhai et al., 2019). ", "rating": "8: Accept", "reply_text": "Thank you for your valuable comments . Q1 : Effect of different types of transformations We added experiments to examine different augmentations including random flip , shift , zoom , rotation , brightness and cutout on both CIFAR-10 and CelebA dataset with SNDCGAN and NS loss . The results are listed below : Dataset shift and flip brightness zoom rotate cutout gaussian SBZR * CIFAR-10 20.50\u00b10.12 25.83\u00b10.18 30.44\u00b10.36 28.58\u00b10.14 22.52\u00b10.42 36.72\u00b11.77 27.82\u00b10.83 CelebA 18.84\u00b10.25 26.81\u00b10.61 24.51\u00b10.42 45.06\u00b16.62 24.86\u00b10.33 44.47\u00b10.45 23.80\u00b10.36 * SBZR means the combination of shift & flip , brightness , zoom and rotate . From these two datasets , shifting and flipping achieves the best result and adding gaussian noise usually achieves the worst result , which is consistent with our findings in Sec.4.2.For CIFAR-10 dataset , changing brightness is better than zooming and rotation , whereas for CelebA , zooming is better compared to rotation and changes in brightness . We think the performance for different augmentations depends on data distribution of different datasets . For example , in the CelebA dataset , zooming effect is more natural than rotation , since the face images are quite well aligned . Q2 : Effect of the number of intermediate layers on FID We added one more experiment to study the effect of different numbers of intermediate layers in CR-GAN . We add consistency regularization to the last k intermediate layers . We use two weighting variations to combine the consistency loss across different layers . In the first setting , the weight of each layer is the inverse of feature dimension in that layer . In the second setting , we give equal weight to each layer . The FID scores for both settings are shown below . number of intermediate layers weight setting1 weight setting2 k=0 19.41\u00b10.57 19.48\u00b10.41 k=1 19.76\u00b10.88 20.53\u00b11.01 k=2 19.66\u00b10.36 19.65\u00b10.57 k=3 19.31\u00b10.53 21.57\u00b10.51 k=4 19.57\u00b10.09 25.03\u00b10.95 k=5 20.61\u00b10.26 111.08\u00b1107.43 k=6 20.99\u00b10.52 411.31\u00b113.88 k=7 21.45\u00b10.46 460.83\u00b126.21 k=8 23.32\u00b10.30 386.38\u00b172.37 In both settings , we observe that consistency regularization on the final layer ( k=0 ) achieves reasonably good results . In addition , adding the consistency to the first few layers in the discriminator harms the performance . For simplicity , we only add consistency regularization in the final layer of the discriminator for the rest of our experiments . We also add more details in Appendix G. Q3 : Experiments on unconditional setting We have done experiments for both conditional and unconditional settings . We have updated the paper to make this more clear . In the updated version , Sec 3.2 is for the unconditional setting and Sec 3.3 is for the conditional setting . Regarding the minor comments : Thank you for all these valuable suggestions . We have edited our paper accordingly . For example , ( 1 ) We labeled the subplot in Figure 2 . ( 2 ) We added the best FID for each method in Table 1 . ( 3 ) We showed the results to cover all the regularization coefficient in Figure 3 . ( 4 ) We added the implementation details in Appendix A ( 5 ) We added the illustrations of generated samples in Appendix D and E. ( 6 ) We fixed the typo in the reference ."}}