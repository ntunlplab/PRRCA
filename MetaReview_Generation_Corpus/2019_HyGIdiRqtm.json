{"year": "2019", "forum": "HyGIdiRqtm", "title": "Evaluating Robustness of Neural Networks with Mixed Integer Programming", "decision": "Accept (Poster)", "meta_review": "\nThe paper investigates mixed-integer linear programming methods for neural net robustness verification in presence of adversarial attckas. The paper addresses and important problem, is well-written, presents a novel approach and demonstrates empirical improvements; all reviewers agree that this is a solid contribution to the field.", "reviews": [{"review_id": "HyGIdiRqtm-0", "review_text": "The authors perform a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations. They propose three enhancements to MILP formulations of neural network verification: Asymmetric bounds, restricted domain and progressive bound tightening, which lead to significantly more scalable verification algorithms vis-a-vis prior work. They study the effectiveness of MILP solvers both in terms of verifying robustness (compared to other complete/incomplete verifiers) and generating adversarial attacks (compared to PGD attacks) and show that their approach compares favorable across a number of architectures on MNIST and CIFAR-10. They perform careful ablation studies to validate the importance of the Quality: The paper is very well written and organized. The problem is certainly of great interest to the deep learning community, given the difficulty of properly evaluating (and then improving) defenses against adversarial attacks. The experiments are done carefully with convincing ablation studies. Clarity: The authors explain the relevant concepts carefully and all the experimental results are clearly written and explained. Originality: The authors propose conceptually simple but practically significant enhancements to MILP formulations of neural network verification. However, the novelty wrt https://arxiv.org/pdf/1711.00455.pdf is not discussed carefully in my view (the asymmetric bounds were already studied in this paper, as well as a novel branch and bound strategy). The progressive bound tightening is a novel idea as far as I can see - however, the ablation experiments show that this idea is not significant in terms of performance improvement. In terms of experiments, the authors indeed obtain strong results on verified adversarial error rates and generate attacks that PGD is unable to - however, again the results do not outperform latest results (in terms of the best achievable upper bounds on verified error rates) available well before the ICLR deadline - https://arxiv.org/pdf/1805.12514.pdf . It would be great if the authors addressed these issues in a revised version of the paper. Significance: The work does establish a strong algorithm for complete verification of neural networks along with several ideas that are critical to obtain strong performance with this approach. Question: 1. I am unclear on the \"restricted domain\" contribution claimed in the paper - is this just exploiting the fact that the inputs to the classifier are normalized to a given range, in addition to being no more than eps away from the nominal input? Cons 1. The authors do not compare their approach to that of https://arxiv.org/pdf/1711.00455.pdf , both in terms of conceptual novelty and in terms of experimental results. In particular, it is not clear to me whether the authors' approach remains superior on domains where tight bounds on the neural networks inputs are not available, like the problems studied in the ACAS system in the ReLuPlex paper. 2. The authors' MILP solution approach relies on having access to the state of the art commercial MILP solver Gurobi. While Gurobi is free for academic research use, for large scale neural network verification applications, this does restrict use of the approach (particularly due to limited licenses being available). It would be interesting to see a comparison that uses a freely available MILP solver (like scip.zib.de) to see how critical the approach's scalability depends on the quality of the MILP solver. 3. The authors do not outperform the latest SOA numbers in terms of verified adversarial error rates on MNIST and CIFAR classifers. It would be good to see a comparison on results from https://arxiv.org/pdf/1711.00455.pdf (I believe the training code and trained networks are available online).", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review ; your comments will help us in revising the paper . Comparison to Bunel et al . [ a ] : We consider the ideas in our paper and those in Bunel et al.to be complementary . Both our verifier and that of Bunel et al.rely on a branch-and-bound approach , and begin by solving an LP that corresponds to the MIP we formulate , but with all integrality constraints removed . In our work , branching occurs only when we split on an unstable ReLU , producing two sub-MIPs where that ReLU is fixed as active and inactive respectively . Bunel et al.observe that it is also possible to split on the _input domain_ , producing two sub-MIPs where the input in each sub-MIP is restricted to be from a half of the input domain . Splitting on the input domain could be useful when tight bounds on the perturbed input are not available ( as in the problems studied in the ACAS system mentioned by the reviewer ) , particular where the split selected tightens bounds sufficiently to significantly reduce the number of unstable ReLUs that need to be considered . We have also reached out to the authors and are working on running their verifier on the networks for which we report results in this paper , and will provide an update as soon as one is available . Solver used : We understand the reviewer 's concern about having to use a commercial solver like Gurobi . While we were unable to run a comparison on the SCIP solver suggested , we were able to run a comparison on the Cbc [ 1 ] and GLPK [ 2 ] solvers , two open-source mixed integer programming solvers . Verification is run on the MNIST classifier network LPd-CNN , with \u03b5=0.1 . The results are as follows : | | Adv . Error | Mean | | | Lower | Upper | Time | | Approach | Bound |Bound | / s | | -- -- -- -- -- -- -- -- -- -- -- | -- -- -- -- -- -- -- -- -- -- -- | -- -- -- -- -- | | Ours w/ Gurobi | 4.38 % | 4.38 % | 3.52 | | Ours w/ Cbc | 4.30 % | 4.82 % | 18.92 | | Ours w/ GLPK | 3.50 % | 7.30 % | 35.78 | | PGD / SOA | 4.11 % | 5.82 % | -- | When we use GLPK as the solver , our performance is significantly worse than when using Gurobi , with the solver timing out on almost 4 % of samples . While we time out on some samples with Cbc , our verifier still provides a lower bound better than PGD and an upper bound significantly better than the state-of-the-art for this network . The performance of our verifier is affected by the underlying MIP solver used , but we are still able to improve on existing bounds using non-commercial solvers . We will add this table to the appendix of the paper . [ 1 ] Coin-or branch and cut ( https : //projects.coin-or.org/Cbc ) [ 2 ] GNU Linear Programming Kit ( https : //www.gnu.org/software/glpk/ ) . The results presented are estimates computed from 1,000 samples . [ a ] Rudy Bunel et al . `` A Unified View of Piecewise Linear Neural Network Verification . '' https : //arxiv.org/pdf/1711.00455.pdf"}, {"review_id": "HyGIdiRqtm-1", "review_text": "This paper studies a Mixed Integer Linear Programming (MILP) approach to verifying the robustness of neural networks with ReLU activations. The main contribution of the paper is a progressive bound tightening approach that results in significantly faster MILP solving. This in turn allows for verifying the robustness of larger networks than previously studied, and even larger datasets such as CIFAR-10. This paper is a solid contribution and should be accepted to ICLR. It is quite well-written, addresses an important problem using a principled method, and achieves strong experimental results that were previously elusive, despite the large body of work in adversarial learning. In particular, the paper has the following strengths: - Clarity: the paper is well-written and easy to read. Tables, figures and pseudocode are nice and easy to understand. - Methodology: the authors take care of a number of bottlenecks in the scalability of MIP solvers for the verification problem. This is the standard approach in the Operations Research (OR) community, and I am really glad to see it in an ICLR submission! - Results: the efficiency of the MIP on the tightened model, and the improvements in the bounds on the adversarial error as compared to very recent methods from the literature are both very strong points in favor of the paper. I do not have any further questions for the authors - good job!", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review . We are glad that you found our paper easy to read ! Addressing the bottlenecks in the scalability of the MIP solver was key in making the verification problem tractable . We look forward to utilizing other ideas from the Operations Research community ( such as computing cutting planes that exploit our knowledge of the structure of our network ) to further improve performance ."}, {"review_id": "HyGIdiRqtm-2", "review_text": "This paper presents a mixed integer programming technique for verification of piecewise linear neural networks. This work uses progressive bounds tightening approach to determine bounds for inputs to units. The authors also show that this technique speeds up the bound determination by orders of magnitude as compared to other complete and incomplete verifiers. They also compare the advercerial accuracies on MNIST and CIFAR and improve on the lower bounds as compared to PGD and upper bounds as compared to SOA. The paper is well written and presents a valuable technique for evaluating robustness of classifiers to adversarial attacks. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your positive feedback !"}], "0": {"review_id": "HyGIdiRqtm-0", "review_text": "The authors perform a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations. They propose three enhancements to MILP formulations of neural network verification: Asymmetric bounds, restricted domain and progressive bound tightening, which lead to significantly more scalable verification algorithms vis-a-vis prior work. They study the effectiveness of MILP solvers both in terms of verifying robustness (compared to other complete/incomplete verifiers) and generating adversarial attacks (compared to PGD attacks) and show that their approach compares favorable across a number of architectures on MNIST and CIFAR-10. They perform careful ablation studies to validate the importance of the Quality: The paper is very well written and organized. The problem is certainly of great interest to the deep learning community, given the difficulty of properly evaluating (and then improving) defenses against adversarial attacks. The experiments are done carefully with convincing ablation studies. Clarity: The authors explain the relevant concepts carefully and all the experimental results are clearly written and explained. Originality: The authors propose conceptually simple but practically significant enhancements to MILP formulations of neural network verification. However, the novelty wrt https://arxiv.org/pdf/1711.00455.pdf is not discussed carefully in my view (the asymmetric bounds were already studied in this paper, as well as a novel branch and bound strategy). The progressive bound tightening is a novel idea as far as I can see - however, the ablation experiments show that this idea is not significant in terms of performance improvement. In terms of experiments, the authors indeed obtain strong results on verified adversarial error rates and generate attacks that PGD is unable to - however, again the results do not outperform latest results (in terms of the best achievable upper bounds on verified error rates) available well before the ICLR deadline - https://arxiv.org/pdf/1805.12514.pdf . It would be great if the authors addressed these issues in a revised version of the paper. Significance: The work does establish a strong algorithm for complete verification of neural networks along with several ideas that are critical to obtain strong performance with this approach. Question: 1. I am unclear on the \"restricted domain\" contribution claimed in the paper - is this just exploiting the fact that the inputs to the classifier are normalized to a given range, in addition to being no more than eps away from the nominal input? Cons 1. The authors do not compare their approach to that of https://arxiv.org/pdf/1711.00455.pdf , both in terms of conceptual novelty and in terms of experimental results. In particular, it is not clear to me whether the authors' approach remains superior on domains where tight bounds on the neural networks inputs are not available, like the problems studied in the ACAS system in the ReLuPlex paper. 2. The authors' MILP solution approach relies on having access to the state of the art commercial MILP solver Gurobi. While Gurobi is free for academic research use, for large scale neural network verification applications, this does restrict use of the approach (particularly due to limited licenses being available). It would be interesting to see a comparison that uses a freely available MILP solver (like scip.zib.de) to see how critical the approach's scalability depends on the quality of the MILP solver. 3. The authors do not outperform the latest SOA numbers in terms of verified adversarial error rates on MNIST and CIFAR classifers. It would be good to see a comparison on results from https://arxiv.org/pdf/1711.00455.pdf (I believe the training code and trained networks are available online).", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review ; your comments will help us in revising the paper . Comparison to Bunel et al . [ a ] : We consider the ideas in our paper and those in Bunel et al.to be complementary . Both our verifier and that of Bunel et al.rely on a branch-and-bound approach , and begin by solving an LP that corresponds to the MIP we formulate , but with all integrality constraints removed . In our work , branching occurs only when we split on an unstable ReLU , producing two sub-MIPs where that ReLU is fixed as active and inactive respectively . Bunel et al.observe that it is also possible to split on the _input domain_ , producing two sub-MIPs where the input in each sub-MIP is restricted to be from a half of the input domain . Splitting on the input domain could be useful when tight bounds on the perturbed input are not available ( as in the problems studied in the ACAS system mentioned by the reviewer ) , particular where the split selected tightens bounds sufficiently to significantly reduce the number of unstable ReLUs that need to be considered . We have also reached out to the authors and are working on running their verifier on the networks for which we report results in this paper , and will provide an update as soon as one is available . Solver used : We understand the reviewer 's concern about having to use a commercial solver like Gurobi . While we were unable to run a comparison on the SCIP solver suggested , we were able to run a comparison on the Cbc [ 1 ] and GLPK [ 2 ] solvers , two open-source mixed integer programming solvers . Verification is run on the MNIST classifier network LPd-CNN , with \u03b5=0.1 . The results are as follows : | | Adv . Error | Mean | | | Lower | Upper | Time | | Approach | Bound |Bound | / s | | -- -- -- -- -- -- -- -- -- -- -- | -- -- -- -- -- -- -- -- -- -- -- | -- -- -- -- -- | | Ours w/ Gurobi | 4.38 % | 4.38 % | 3.52 | | Ours w/ Cbc | 4.30 % | 4.82 % | 18.92 | | Ours w/ GLPK | 3.50 % | 7.30 % | 35.78 | | PGD / SOA | 4.11 % | 5.82 % | -- | When we use GLPK as the solver , our performance is significantly worse than when using Gurobi , with the solver timing out on almost 4 % of samples . While we time out on some samples with Cbc , our verifier still provides a lower bound better than PGD and an upper bound significantly better than the state-of-the-art for this network . The performance of our verifier is affected by the underlying MIP solver used , but we are still able to improve on existing bounds using non-commercial solvers . We will add this table to the appendix of the paper . [ 1 ] Coin-or branch and cut ( https : //projects.coin-or.org/Cbc ) [ 2 ] GNU Linear Programming Kit ( https : //www.gnu.org/software/glpk/ ) . The results presented are estimates computed from 1,000 samples . [ a ] Rudy Bunel et al . `` A Unified View of Piecewise Linear Neural Network Verification . '' https : //arxiv.org/pdf/1711.00455.pdf"}, "1": {"review_id": "HyGIdiRqtm-1", "review_text": "This paper studies a Mixed Integer Linear Programming (MILP) approach to verifying the robustness of neural networks with ReLU activations. The main contribution of the paper is a progressive bound tightening approach that results in significantly faster MILP solving. This in turn allows for verifying the robustness of larger networks than previously studied, and even larger datasets such as CIFAR-10. This paper is a solid contribution and should be accepted to ICLR. It is quite well-written, addresses an important problem using a principled method, and achieves strong experimental results that were previously elusive, despite the large body of work in adversarial learning. In particular, the paper has the following strengths: - Clarity: the paper is well-written and easy to read. Tables, figures and pseudocode are nice and easy to understand. - Methodology: the authors take care of a number of bottlenecks in the scalability of MIP solvers for the verification problem. This is the standard approach in the Operations Research (OR) community, and I am really glad to see it in an ICLR submission! - Results: the efficiency of the MIP on the tightened model, and the improvements in the bounds on the adversarial error as compared to very recent methods from the literature are both very strong points in favor of the paper. I do not have any further questions for the authors - good job!", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your review . We are glad that you found our paper easy to read ! Addressing the bottlenecks in the scalability of the MIP solver was key in making the verification problem tractable . We look forward to utilizing other ideas from the Operations Research community ( such as computing cutting planes that exploit our knowledge of the structure of our network ) to further improve performance ."}, "2": {"review_id": "HyGIdiRqtm-2", "review_text": "This paper presents a mixed integer programming technique for verification of piecewise linear neural networks. This work uses progressive bounds tightening approach to determine bounds for inputs to units. The authors also show that this technique speeds up the bound determination by orders of magnitude as compared to other complete and incomplete verifiers. They also compare the advercerial accuracies on MNIST and CIFAR and improve on the lower bounds as compared to PGD and upper bounds as compared to SOA. The paper is well written and presents a valuable technique for evaluating robustness of classifiers to adversarial attacks. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your positive feedback !"}}