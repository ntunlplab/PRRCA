{"year": "2020", "forum": "BkgHWkrtPB", "title": "Where is the Information in a Deep Network?", "decision": "Reject", "meta_review": "This paper is full of ideas. However, a logical argument is only as strong as its weakest link, and I believe the current paper has some weak links. For example, the attempt to tie the behavior of SGD to free energy minimization relies on unrealistic approximations. Second, the bounds based on limiting flat priors become trivial. The authors in-depth response to my own review was much appreciated, especially given its last minute appearance. Unfortunately, I was not convinced by the arguments. In part, the authors argue that the logical argument they are making is not sensitive to certain issues that I raised, but this only highlights for me that the argument being made is not very precise.  I can imagine a version of this work with sharper claims, built on clearly stated assumptions/conjectures about SGD's dynamics, RATHER THAN being framed as the consequences of clearly inaccurate approximations. The behavior of diffusions can be presented as evidence that the assumptions/conjectures (that cannot be proven at the moment, but which are needed to complete the logical argument) are reasonable. However, I am also not convinced that it is trivial to do this, and so the community must have a chance to review a major revision.", "reviews": [{"review_id": "BkgHWkrtPB-0", "review_text": "This paper presents a theoretical account of information encoded within deep neural networks subject to information theoretic measures. In contrast to other efforts that examine information encoded in weights, this work emphasizes the effective information in the activations. This characterization is further related to information in the weights, and a theoretical justification is made for what this means with respect to properties of generalization and invariance in the network. The notion of attaching the weights that represent the training set to the activations that accord with the test set in a theoretical framework is interesting. In practice, I would have liked to see a bit more attachment of the theoretical formalisms to the empirical justification that follows the references. This, however, is a matter of personal bias as I don't typically produce papers that are principally theoretical contributions in my own work. Overall, the content of the paper seems sound and the theoretical and empirical justifications seem well founded but I also can't claim to be an expert in this area.", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the comments and suggestions . > > I would have liked to see a bit more attachment of the theoretical formalisms to the empirical justification that follows the references . We have now updated the appendix to better introduce each experiment , to hopefully better explain the connections with both theory we develop and to the previous literature ."}, {"review_id": "BkgHWkrtPB-1", "review_text": "The paper deals with where the information is in a deep network and how information is propagated when new data points are observed. The authors measure information in the weights of a DNN as the trade-off between network accuracy and weight complexity. They bring out the relationships between Shannon MI and Fisher Information and the connections to PAC-Bayes bound and invariance. The main result is that models of low information generalize better and are invariance-tolerant. The paper is very well written and concepts are theoretically-well documented. In Definition 3.1 for the \u2018Information in the Weights\u2019, how does the complexity of the task vary with \\beta? Is the Pareto curve provided in the paper? ", "rating": "8: Accept", "reply_text": "We thank the reviewer for the positive comments . > > In Definition 3.1 for the \u2018 Information in the Weights \u2019 , how does the complexity of the task vary with $ \\beta $ ? Is the Pareto curve provided in the paper ? This is partially answered empirically in Fig.2 . ( left ) , where we keep the task constant but we change the batch size of SGD , which amounts to reducing beta by Proposition 3.7 . This results in the expected increase in the Fisher Information of the weights . In ( Right ) we keep beta constant , but we increase the complexity of the task by adding more classes . This also results in an increase in the Fisher Information ."}, {"review_id": "BkgHWkrtPB-2", "review_text": "Summary of the paper: This is a theoretical paper that builds on top of Achille and Soatto (2018), Achille et al. (2019), McAllester (2013), and Berglund (2011),. The paper attempts to answer the relationship between the inductive bias of SGD, generalization of DNNs, and the invariance of learned representation from an information theoretical point of view. The paper mentioned many interesting links. In my opinion, the contributions are the following: 1. Invoking the theoretical result of Berglund (2011) to justify why Fisher information is relevant -- SGD tends to avoid local minima with high Fisher information. 2. Relating the Fisher information and the stability of SGD to I(w; D). 3. Introducing the definition of effective information in the activation, and show that which is closely related to the Fisher information. About the rating: This is basically a good paper but I have a few concerns: 1. A large fraction of this paper are taken from Achille and Soatto (2018), Achille et al. (2019). 2. In terms of impact, the paper is somehow incomplete -- it only demonstrates that the Fisher information is important, but the insights didn't lead to any substantial improvement over the current deep learning framework. Detailed comments: 1. In my opinion, defining \"information in the weights for the task D\" by KL(Q||P) is inaccurate. The weights themselves are information, which form a representation or a lossy compression of the data (which is also an information). According to the rate-distortion theory, what we care about is the amount of information the representation attains rather than \"where\" the information are. Therefore, we should talk about \"rate\" or \"amount of information\" or \"mutual information\" rather than \"information\" itself. A missing reference regarding this point: Hu et al. \"\u03b2-BNN: A Rate-Distortion Perspective on Bayesian Neural Networks.\" 2018, which derives the information Lagrangian directly from rate-distortion theory. 2. More discussions on Xu and Raginsky (2017) is expected, since it proposes to use I(w; D) as a generalization bound. It seems, in terms of generalization, minimizing I(w; D) is a sufficient condition while minimizing Fisher is a necessary condition. 3. There are in fact 4 key aspects: sufficiency, minimality, invariance and generalization. It would be great to have a theorem to summarize the relationships between them. 4. Could you elaborate on the footnote 3? ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the many thoughtful suggestions . We reply to each point in order : Concerning relations with Achille and Soatto ( JMLR 2018 ) , that paper uses Shannon 's framework and effectively considers the weights as stochastic , thus not addressing the computability of information for deterministic maps , where it is often degenerate . One interpretation of our work is to reconcile that paper with the work criticizing the use of the Information Bottleneck for deterministic networks . This requires formally connecting the Shannon Mutual Information of the weights to the Fisher ( Proposition 3.7 , which we also verify empirically in the appendix , and which replaces the much looser bound using the curvature suggested by Achille and Soatto ( 2018 ) ) and to introduce the notion of effective mutual information of the activations , which we also connect to the Fisher Information ( Proposition 4.2 ) . Second , our aim is to formally connect the dynamics with SGD ( in terms of both stability and flatness of the solution found ) with the information in a DNN . This is not done in any of the references cited . Concerning relations with Achille et al . ( 2019 ) , as we say in the opening of Sect . 3 , Sections 3.1 and 3.2 are derived from that preprint and included for completeness . The main results of our paper are in Sect . 3.3 and 4 , whereas Achille at al . ( 2019 ) focus on defining a distance between learning tasks , which we do not address here . In terms of impact , indeed , our aim was to obtain clarity around the notion of information , both in the the weights and activations of a DNN , that has caused some confusion in the literature and occasionally contradictory or ( accidentally ) misleading claims . We also introduce stronger connections between information and the optimization dynamics of a DNN . This , we believe , helps paint a more complete picture of the current landscape of information in Deep Learning . We did not set out to improve current deep learning frameworks , but we hope this work will help us and others at least understand how different fundamental quantities are related in DNN , when a model can be expected to `` work , '' hopefully quantify how `` well '' it works , and to relate this to the complexity of the learning task , which is not often formalized in deep learning . Regarding the detailed comments : > > we should talk about `` rate '' or `` amount of information '' or `` mutual information '' rather than `` information '' itself This is a good point , and we have updated the definition to reflect this . We originally tried to avoid naming it `` mutual information '' or `` rate '' to make it clear that the notion is valid even if the dataset is not considered a random variable ( like it would in rate-distortion theory ) , but we are glad to change it to the less ambiguous `` amount of information '' ."}], "0": {"review_id": "BkgHWkrtPB-0", "review_text": "This paper presents a theoretical account of information encoded within deep neural networks subject to information theoretic measures. In contrast to other efforts that examine information encoded in weights, this work emphasizes the effective information in the activations. This characterization is further related to information in the weights, and a theoretical justification is made for what this means with respect to properties of generalization and invariance in the network. The notion of attaching the weights that represent the training set to the activations that accord with the test set in a theoretical framework is interesting. In practice, I would have liked to see a bit more attachment of the theoretical formalisms to the empirical justification that follows the references. This, however, is a matter of personal bias as I don't typically produce papers that are principally theoretical contributions in my own work. Overall, the content of the paper seems sound and the theoretical and empirical justifications seem well founded but I also can't claim to be an expert in this area.", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the comments and suggestions . > > I would have liked to see a bit more attachment of the theoretical formalisms to the empirical justification that follows the references . We have now updated the appendix to better introduce each experiment , to hopefully better explain the connections with both theory we develop and to the previous literature ."}, "1": {"review_id": "BkgHWkrtPB-1", "review_text": "The paper deals with where the information is in a deep network and how information is propagated when new data points are observed. The authors measure information in the weights of a DNN as the trade-off between network accuracy and weight complexity. They bring out the relationships between Shannon MI and Fisher Information and the connections to PAC-Bayes bound and invariance. The main result is that models of low information generalize better and are invariance-tolerant. The paper is very well written and concepts are theoretically-well documented. In Definition 3.1 for the \u2018Information in the Weights\u2019, how does the complexity of the task vary with \\beta? Is the Pareto curve provided in the paper? ", "rating": "8: Accept", "reply_text": "We thank the reviewer for the positive comments . > > In Definition 3.1 for the \u2018 Information in the Weights \u2019 , how does the complexity of the task vary with $ \\beta $ ? Is the Pareto curve provided in the paper ? This is partially answered empirically in Fig.2 . ( left ) , where we keep the task constant but we change the batch size of SGD , which amounts to reducing beta by Proposition 3.7 . This results in the expected increase in the Fisher Information of the weights . In ( Right ) we keep beta constant , but we increase the complexity of the task by adding more classes . This also results in an increase in the Fisher Information ."}, "2": {"review_id": "BkgHWkrtPB-2", "review_text": "Summary of the paper: This is a theoretical paper that builds on top of Achille and Soatto (2018), Achille et al. (2019), McAllester (2013), and Berglund (2011),. The paper attempts to answer the relationship between the inductive bias of SGD, generalization of DNNs, and the invariance of learned representation from an information theoretical point of view. The paper mentioned many interesting links. In my opinion, the contributions are the following: 1. Invoking the theoretical result of Berglund (2011) to justify why Fisher information is relevant -- SGD tends to avoid local minima with high Fisher information. 2. Relating the Fisher information and the stability of SGD to I(w; D). 3. Introducing the definition of effective information in the activation, and show that which is closely related to the Fisher information. About the rating: This is basically a good paper but I have a few concerns: 1. A large fraction of this paper are taken from Achille and Soatto (2018), Achille et al. (2019). 2. In terms of impact, the paper is somehow incomplete -- it only demonstrates that the Fisher information is important, but the insights didn't lead to any substantial improvement over the current deep learning framework. Detailed comments: 1. In my opinion, defining \"information in the weights for the task D\" by KL(Q||P) is inaccurate. The weights themselves are information, which form a representation or a lossy compression of the data (which is also an information). According to the rate-distortion theory, what we care about is the amount of information the representation attains rather than \"where\" the information are. Therefore, we should talk about \"rate\" or \"amount of information\" or \"mutual information\" rather than \"information\" itself. A missing reference regarding this point: Hu et al. \"\u03b2-BNN: A Rate-Distortion Perspective on Bayesian Neural Networks.\" 2018, which derives the information Lagrangian directly from rate-distortion theory. 2. More discussions on Xu and Raginsky (2017) is expected, since it proposes to use I(w; D) as a generalization bound. It seems, in terms of generalization, minimizing I(w; D) is a sufficient condition while minimizing Fisher is a necessary condition. 3. There are in fact 4 key aspects: sufficiency, minimality, invariance and generalization. It would be great to have a theorem to summarize the relationships between them. 4. Could you elaborate on the footnote 3? ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the many thoughtful suggestions . We reply to each point in order : Concerning relations with Achille and Soatto ( JMLR 2018 ) , that paper uses Shannon 's framework and effectively considers the weights as stochastic , thus not addressing the computability of information for deterministic maps , where it is often degenerate . One interpretation of our work is to reconcile that paper with the work criticizing the use of the Information Bottleneck for deterministic networks . This requires formally connecting the Shannon Mutual Information of the weights to the Fisher ( Proposition 3.7 , which we also verify empirically in the appendix , and which replaces the much looser bound using the curvature suggested by Achille and Soatto ( 2018 ) ) and to introduce the notion of effective mutual information of the activations , which we also connect to the Fisher Information ( Proposition 4.2 ) . Second , our aim is to formally connect the dynamics with SGD ( in terms of both stability and flatness of the solution found ) with the information in a DNN . This is not done in any of the references cited . Concerning relations with Achille et al . ( 2019 ) , as we say in the opening of Sect . 3 , Sections 3.1 and 3.2 are derived from that preprint and included for completeness . The main results of our paper are in Sect . 3.3 and 4 , whereas Achille at al . ( 2019 ) focus on defining a distance between learning tasks , which we do not address here . In terms of impact , indeed , our aim was to obtain clarity around the notion of information , both in the the weights and activations of a DNN , that has caused some confusion in the literature and occasionally contradictory or ( accidentally ) misleading claims . We also introduce stronger connections between information and the optimization dynamics of a DNN . This , we believe , helps paint a more complete picture of the current landscape of information in Deep Learning . We did not set out to improve current deep learning frameworks , but we hope this work will help us and others at least understand how different fundamental quantities are related in DNN , when a model can be expected to `` work , '' hopefully quantify how `` well '' it works , and to relate this to the complexity of the learning task , which is not often formalized in deep learning . Regarding the detailed comments : > > we should talk about `` rate '' or `` amount of information '' or `` mutual information '' rather than `` information '' itself This is a good point , and we have updated the definition to reflect this . We originally tried to avoid naming it `` mutual information '' or `` rate '' to make it clear that the notion is valid even if the dataset is not considered a random variable ( like it would in rate-distortion theory ) , but we are glad to change it to the less ambiguous `` amount of information '' ."}}