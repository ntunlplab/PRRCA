{"year": "2017", "forum": "BJrFC6ceg", "title": "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications", "decision": "Accept (Poster)", "meta_review": " The authors acknowledge that the ideas in the paper are incremental, but assert these are not-trivial improvements upon prior work on pixel CNNs. The reviewers tended to agree with this characterization. The paper presents SOTA pixel likelihood results on CIFAR-10. This work is also coupled with a high quality source code contribution, which also appears to have already been well received by the github community. Reviewer 1 made the point that in terms of raw novelty this work is probably a little below the bar for an oral presentation. A public reviewer rated this paper as a strong accept. Given the statistics, quality and originality of the other papers in my AC batch I recommend poster.", "reviews": [{"review_id": "BJrFC6ceg-0", "review_text": "Apologies for the late submission of this review, and thank you for the author\u2019s responses to earlier questions. This submission proposes an improved implementation of the PixelCNN generative model. Most of the improvements are small and can be considered as specific technical details such as the use of dropout and skip connections, while others are slightly more substantial such as the use of a different likelihood model and multiscale analysis. The submission demonstrates state-of-the-art likelihood results on CIFAR-10. My summary of the main contribution: Autoregressive-type models - of which PixelCNN is an example - are a nice class of models as their likelihood can be evaluated in closed form. A main differentiator for this type of models is how the conditional likelihood of one pixel conditioned on its causal neighbourhood is modelled: - In one line of work such as (Theis et al, 2012 MCGSM, Theis et al 2015 Spatial LSTM) the conditional distribution is modelled as a continuous density over real numbers. This approach has limitations: We know that in observed data pixel intensities are quantized to a discrete integer representation so a discrete distribution could give better likelihoods. Furthermore these continuous distributions have a tail and assign some probability mass outside the valid range of pixel intensities, which may hurt the likelihood. - In more recent work by van den Oord and colleagues the conditional likelihood is modelled as an arbitrary discrete distribution over the 256 possible values for pixel intensities. This does not suffer from the limitations of continuous likelihoods, but it also seems wasteful and is not very data efficient. The authors propose something in the middle by keeping the discretized nature of the conditional likelihood, but restricting the discrete distribution to ones whose CDF that can be modeled as a linear combination of sigmoids. This approach makes sense to me, and is new in a way, but it doesn\u2019t appear to be very revolutionary or significant to me. The second somewhat significant modification is the use of downsampling and multiscale modelling (as opposed to dilated convolutions). The main motivation for the authors to do this is saving computation time while keeping the multiscale flexibility of the model. The authors also introduce shortcut connections to compensate for the potential loss of information as they perform downsampling. Again, I feel that this modification not particularly revolutionary. Multiscale image analysis with autoregressive generative models has been done for example in (Theis et al, 2012) and several other papers. Overall I felt that this submission falls short on presenting substantially new ideas, and reads more like documentation for a particular implementation of an existing idea.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for you review ! The ideas in our paper are incremental , but non-trivial , improvements upon existing work . We have deliberately been modest in the presentation of these ideas , rather than overclaiming paradigm shifting insights as already happens all too often in our field . The contributions we make are useful to many people , as evidenced by the SOTA results , the number of github stars , the papers building on our work ( e.g.https : //arxiv.org/pdf/1611.02731.pdf , https : //arxiv.org/pdf/1612.08185v1.pdf ) , and the large amount of positive personal communication I have received . Taking this into account , I feel the paper contributes more to our field than most ICLR submissions . Could you please reconsider your rating in this light ?"}, {"review_id": "BJrFC6ceg-1", "review_text": "# Review This paper proposes five modifications to improve PixelCNN, a generative model with tractable likelihood. The authors empirically showed the impact of each of their proposed modifications using a series of ablation experiments. They also reported a new state-of-the-art result on CIFAR-10. Improving generative models, especially for images, is an active research area and this paper definitely contributes to it. # Pros The authors motivate each modification well they proposed. They also used ablation experiments to show each of them is important. The authors use a discretized mixture of logistic distributions to model the conditional distribution of a sub-pixel instead of a 256-way softmax. This allows to have a lower output dimension and to be better suited at learning ordinal relationships between sub-pixel values. The authors also mentioned it speeded up training time (less computation) as well as the convergence during the optimization of the model (as shown in Fig.6). The authors make an interesting remark about how the dependencies between the color channels of a pixel are likely to be relatively simple and do not require a deep network to model. This allows them to have a simplified architecture where you don't have to separate out all feature maps in 3 groups depending on whether or not they can see the R/G/B sub-pixel of the current location. # Cons It is not clear to me what the predictive distribution for the green channel (and the blue) looks like. More precisely, how are the means of the mixture components linearly depending on the value of the red sub-pixel? I would have liked to see the equations for them. # Minor Comments In Fig.2 it is written \"Sequence of 6 layers\" but in the text (Section 2.4) it says 6 blocks of 5 ResNet layers. What is the remaining layer? In Fig.2 what does the first \"green square -> blue square\" which isn't in the white rectangle represents? Is there any reason why the mixture indicator is shared across all three channels?", "rating": "7: Good paper, accept", "reply_text": "Thanks for the review ! I will add a bit more detail to the explanation of the mixture likelihood ."}, {"review_id": "BJrFC6ceg-2", "review_text": "Summary: This paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes. Review: This is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that. My main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978). The main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has \u201cproved to be a problem for earlier models based on continuous distributions\u201d. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous). 60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content \u2013 and this can serve as a good example to demonstrate the usefulness of dropout \u2013 why not use \u201c80 million tiny images\u201d (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model\u2019s likelihood is tractable), so this data could even be used in the class-conditional case. It would be interesting to know how fast the different models are at test time (i.e., when generating images).", "rating": "7: Good paper, accept", "reply_text": "Thanks for the citation suggestions . I will add these , as well as a comparison of the proposed likelihood model to a continuous mixture likelihood . ( I have done experiments using continuous mixtures before , but not yet with the final architecture presented in the paper )"}], "0": {"review_id": "BJrFC6ceg-0", "review_text": "Apologies for the late submission of this review, and thank you for the author\u2019s responses to earlier questions. This submission proposes an improved implementation of the PixelCNN generative model. Most of the improvements are small and can be considered as specific technical details such as the use of dropout and skip connections, while others are slightly more substantial such as the use of a different likelihood model and multiscale analysis. The submission demonstrates state-of-the-art likelihood results on CIFAR-10. My summary of the main contribution: Autoregressive-type models - of which PixelCNN is an example - are a nice class of models as their likelihood can be evaluated in closed form. A main differentiator for this type of models is how the conditional likelihood of one pixel conditioned on its causal neighbourhood is modelled: - In one line of work such as (Theis et al, 2012 MCGSM, Theis et al 2015 Spatial LSTM) the conditional distribution is modelled as a continuous density over real numbers. This approach has limitations: We know that in observed data pixel intensities are quantized to a discrete integer representation so a discrete distribution could give better likelihoods. Furthermore these continuous distributions have a tail and assign some probability mass outside the valid range of pixel intensities, which may hurt the likelihood. - In more recent work by van den Oord and colleagues the conditional likelihood is modelled as an arbitrary discrete distribution over the 256 possible values for pixel intensities. This does not suffer from the limitations of continuous likelihoods, but it also seems wasteful and is not very data efficient. The authors propose something in the middle by keeping the discretized nature of the conditional likelihood, but restricting the discrete distribution to ones whose CDF that can be modeled as a linear combination of sigmoids. This approach makes sense to me, and is new in a way, but it doesn\u2019t appear to be very revolutionary or significant to me. The second somewhat significant modification is the use of downsampling and multiscale modelling (as opposed to dilated convolutions). The main motivation for the authors to do this is saving computation time while keeping the multiscale flexibility of the model. The authors also introduce shortcut connections to compensate for the potential loss of information as they perform downsampling. Again, I feel that this modification not particularly revolutionary. Multiscale image analysis with autoregressive generative models has been done for example in (Theis et al, 2012) and several other papers. Overall I felt that this submission falls short on presenting substantially new ideas, and reads more like documentation for a particular implementation of an existing idea.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for you review ! The ideas in our paper are incremental , but non-trivial , improvements upon existing work . We have deliberately been modest in the presentation of these ideas , rather than overclaiming paradigm shifting insights as already happens all too often in our field . The contributions we make are useful to many people , as evidenced by the SOTA results , the number of github stars , the papers building on our work ( e.g.https : //arxiv.org/pdf/1611.02731.pdf , https : //arxiv.org/pdf/1612.08185v1.pdf ) , and the large amount of positive personal communication I have received . Taking this into account , I feel the paper contributes more to our field than most ICLR submissions . Could you please reconsider your rating in this light ?"}, "1": {"review_id": "BJrFC6ceg-1", "review_text": "# Review This paper proposes five modifications to improve PixelCNN, a generative model with tractable likelihood. The authors empirically showed the impact of each of their proposed modifications using a series of ablation experiments. They also reported a new state-of-the-art result on CIFAR-10. Improving generative models, especially for images, is an active research area and this paper definitely contributes to it. # Pros The authors motivate each modification well they proposed. They also used ablation experiments to show each of them is important. The authors use a discretized mixture of logistic distributions to model the conditional distribution of a sub-pixel instead of a 256-way softmax. This allows to have a lower output dimension and to be better suited at learning ordinal relationships between sub-pixel values. The authors also mentioned it speeded up training time (less computation) as well as the convergence during the optimization of the model (as shown in Fig.6). The authors make an interesting remark about how the dependencies between the color channels of a pixel are likely to be relatively simple and do not require a deep network to model. This allows them to have a simplified architecture where you don't have to separate out all feature maps in 3 groups depending on whether or not they can see the R/G/B sub-pixel of the current location. # Cons It is not clear to me what the predictive distribution for the green channel (and the blue) looks like. More precisely, how are the means of the mixture components linearly depending on the value of the red sub-pixel? I would have liked to see the equations for them. # Minor Comments In Fig.2 it is written \"Sequence of 6 layers\" but in the text (Section 2.4) it says 6 blocks of 5 ResNet layers. What is the remaining layer? In Fig.2 what does the first \"green square -> blue square\" which isn't in the white rectangle represents? Is there any reason why the mixture indicator is shared across all three channels?", "rating": "7: Good paper, accept", "reply_text": "Thanks for the review ! I will add a bit more detail to the explanation of the mixture likelihood ."}, "2": {"review_id": "BJrFC6ceg-2", "review_text": "Summary: This paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout for regularization, to use downsampling to increase receptive field size, and the introduction of particular skip connections. The authors find that this allows the PixelCNN to outperform a PixelRNN on CIFAR-10, the previous state-of-the-art model. The authors further explore the performance of PixelCNNs with smaller receptive field sizes. Review: This is a useful contribution towards better tractable image models. In particular, autoregressive models can be quite slow at test time, and the more efficient architectures described here should help with that. My main criticism regards the severe neglect of related work. Mixture models have been used a lot in autoregressive image modeling, including for multivariate conditional densities and including downsampling to increase receptive field size, albeit in a different manner: Domke (2008), Hosseini et al. (2010), Theis et al. (2012), Uria et al. (2013), Theis et al. (2015). Note that the logistic distribution is a special case of the Gaussian scale mixture (West, 1978). The main difference seems to be the integration of the density to model integers. While this is clearly a good idea and the right way forward, the authors claim but do not support that not doing this has \u201cproved to be a problem for earlier models based on continuous distributions\u201d. Please elaborate, add a reference, or ideally report the performance achieved by PixelCNN++ without integration (and instead adding uniform noise to make the variables continuous). 60,000 images are not a lot in a high-dimensional space. While I can see the usefulness of regularization for specialized content \u2013 and this can serve as a good example to demonstrate the usefulness of dropout \u2013 why not use \u201c80 million tiny images\u201d (superset of CIFAR-10) for natural images? Semi-supervised learning should be fairly trivial here (because the model\u2019s likelihood is tractable), so this data could even be used in the class-conditional case. It would be interesting to know how fast the different models are at test time (i.e., when generating images).", "rating": "7: Good paper, accept", "reply_text": "Thanks for the citation suggestions . I will add these , as well as a comparison of the proposed likelihood model to a continuous mixture likelihood . ( I have done experiments using continuous mixtures before , but not yet with the final architecture presented in the paper )"}}