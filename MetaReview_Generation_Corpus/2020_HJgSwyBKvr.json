{"year": "2020", "forum": "HJgSwyBKvr", "title": "Weakly Supervised Disentanglement with Guarantees", "decision": "Accept (Poster)", "meta_review": "This paper first discusses some concepts related to disentanglement. The authors propose to decompose disentanglement into two distinct concepts: consistency and restrictiveness. Then, a calculus of disentanglement is introduced to reveal the relationship between restrictiveness and consistency. The proposed concepts are applied to analyze weak supervision methods. \n\nThe reviewers ultimately decided this paper is well-written and has content which is of general interest to the ICLR community.", "reviews": [{"review_id": "HJgSwyBKvr-0", "review_text": "This paper first discusses some concepts related to disentanglement. The authors propose to decompose disentanglement into two distinct concepts: consistency and restrictiveness. Then, a calculus of disentanglement is introduced to reveal the relationship between restrictiveness and consistency. The proposed concepts are applied to analyze weak supervision methods. This paper is well structured. The presentation is easy to follow. The problem discussed is important to the machine learning community. The concepts discussed are supported by a large number of experiments. The assumption that disentanglement can be decomposed into consistency and restrictiveness might be flawed. Let us consider a generator $g(Z)$ that always generates the same image for all $Z \\sim p(Z)$. Note that $g(Z)$ gives perfect consistency and perfect restrictiveness as defined in Equation (3) and (6). However, we consider $g(Z)$ is a bad generator, and we do not think the corresponding latent representation $Z$ achieves perfect disentanglement. Note that such $Z$, in general, gives low values in the existing disentanglement metrics. This implies that we might need to introduce a third component to disentanglement, which I call it relevance. We should additionally assume that different $z_{ \\setminus I}$ leads to different generated images. It might be challenging to measure relevance quantitatively under the probabilistic framework, but I believe this is necessary. In summary, I think the idea presented is interesting and useful. I believe this paper is promising and impactful after proper revision. However, I do not recommend acceptance because it looks technically flawed. Minor: In Figure 5, the illustration is clear to me, but I am not sure how the vertical axis simultaneously represents two variables $z_2, z_3$. In the table on page 5, $n$ represents the number of dimensions, right? ", "rating": "8: Accept", "reply_text": "Dear Reviewer , Thank you for acknowledging the significance of the problem being tackled in this paper . We would like to address your concern regarding the issue of degenerate generators that always output the same image for all choices of $ Z $ . In our paper , we referred to such a latent space $ Z $ as being \u201c uninformative \u201d . This scenario is explicitly prevented by our requirement , stated on page 3 , that our analysis is subject to the condition that \u201c $ g ( Z ) $ =d= $ g^ * ( S ) $ are equal in distribution \u201d . We would like to emphasize that the decomposition of disentanglement into restrictiveness and consistency is appropriate when this condition ( $ g ( Z ) $ =d= $ g^ * ( S ) $ ) is satisfied , otherwise we would indeed be admitting degenerate models that have uninformative latent spaces . We addressed this point once again on page 6 , stating that \u201c The distribution matching requirement $ g ( Z ) $ =d= $ g^ * ( S ) $ ensures latent code informativeness , i.e. , preventing trivial solutions where the latent code is uninformative ( see Theorem 7 for formal statement ) \u201d In the appendix , Theorem 7 formalizes what it means for the latent space to be informative and states that informativeness of the latent space is guaranteed when $ g ( Z ) $ =d= $ g^ * ( S ) $ . The formal statement and proof are available on Page 33 . In other words , our proposed concepts of consistency and restrictiveness are best thought of as complementing latent code informativeness , and not as replacements for checking the informativeness of the latent code . We also wish to note that our theoretical guarantees in Theorem 1 explicitly require $ g ( Z ) $ =d= $ g^ * ( S ) $ . This is because the distribution matching setup in Theorem 1 implies distribution matching of $ g ( Z ) $ with $ g^ * ( S ) $ . As such , with respect to our theoretical analysis , we hope that you will agree that our submission takes careful measures to explicitly combat the type of degeneracy that you pointed out . In practice , when distribution matching is not guaranteed , we fully support that practitioners should check for both latent code informativeness in addition to restrictiveness and consistency . Ultimately , we note that generator restrictiveness and consistency are concepts that complement latent code informativeness , and not replacements for it . We will strive to make this point even clearer when we update the paper . -- - Regarding minor comments : In Figure 2 , the way to interpret the vertical axis is that each row corresponds to a randomly sampled choice of $ ( z_2 , z_3 ) $ . This is stated in the caption as , \u201c each row denotes a fixed choice of $ ( z_2 , z_3 ) $ \u201d . In the calculus , you are correct that $ n $ denotes the number of dimensions . We shall make this point clear when updating our paper ."}, {"review_id": "HJgSwyBKvr-1", "review_text": " The paper tries to bring some theoretical foundation to the weakly supervised disentanglement. Overall it is a good contribution, but the message of the paper is not clear. The authors propose two notions: consistency and restrictiveness, which they don't imply each other. However, the experiment on real data shows that they are highly correlated. Up until the experiment section, the paper is well written (although a bit verbose). It seems that it is great but unfinished work. The paper is well written, but in my opinion, there is too much verbosity on page 4-5 on rather trivial definitions consistency and restrictiveness and a big box in the calculus of disentanglement that steals space from the main results. In my opinion, those sections can be reduced so that other theorem can be covered. In my opinion, the theorem nine should be part of the main text. I understand the definition of \"Sufficiency for Disentanglement \" but it is not clear why it is important. Sure, it is a strong definition that says for any $\\mathcal{H}$ (and not a subset) the algorithm ($\\mathcal{A}$) should be able to match the distribution of the observation but why is it a big deal according to the next paragraph? I don't see any proof that Eq.11 should be between [0,1]. Yes, g is optimal, and if you enter suboptimal values to it, one expects the nominator to be less than dominator. However, g a function that is optimal in expectation, which does not mean for every s value it nominator is less than the denominator. In fact, some of the values in fig 3 are small negatives. Fig 3 is not explained well: you are showing normalized consistency and restiveness. First of all, what is the dataset you tried this on? Second, why some values are negative?! These are supposed to be between [0,1]. Third, what is the take-home-message of this figure? the first two matrices from left show that the factors are consistent b/c they are almost diagonal. The third one from left shows that the algorithm you used is not restrictive? Then are you suggesting this as a metric of evaluation? I am not sure I understand the first figure from the right. Overall, the authors perform a significant amount of experiments, but they did a poor job in summarizing the results. Finally, the authors claim \"...We believe this correlation between consistency and restrictiveness to have been a general source of confusion in the disentanglement literature, causing many to either observe or believe that restricted labeling or share pairing on $S_i$ (which only guarantees consistency) is sufficient for disentangling Si ...\" Each of those methods should be analyzed separately to ensure that their algorithms do not induce restiveness. I just don't see the natural connection between your figure 4 and this conclusion that you made. Minor: Where is the proof for Theorem 1? In the Supp, it starts with Theorem 8, I guess you meant Lemma 8? You need to clean up the Supp so that one can find the proof easily. I suggest restructuring the Supp to less and finally proof of Thorem 1.", "rating": "8: Accept", "reply_text": "Dear Reviewer , Thank you for your feedback ! We wish to address your concerns as follows . Regarding the message of the paper -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - The goal of this paper is to clarify some confusion regarding the concept of disentanglement in the current literature , and to build up a theoretical framework that clarifies the guarantees actually conferred by several popular weak supervision methods Regarding the seeming verbosity of the definitions -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- As evident from Figure 2 , consistency and restrictiveness are distinct concepts that play critical roles in theory . We agree that there is a noticeable contrast in the simplicity of the intuition of consistency/restrictiveness versus the lengthy mathematical description . Although those concepts are intuitive , the mathematical formalism we give is carefully designed with several important subtleties in mind : 1 . The specific sampling procedure in Eq ( 1 , 2 ) and Eq ( 4 , 5 ) are important for ensuring that the definition of disentanglement allows for correlated but interpretable features ( similar to Suter et al 2018 ) . We note that many existing definitions for disentanglement break down when the ground truth factors are correlated , and so we believe it is important to break away from the trend of making the definition of disentanglement implicitly reliant on the assumption of statistically independent ground truth factors . 2.Since consistency and restrictiveness are asymmetric concepts , generator-side consistency and restrictiveness and encoder-side consistency and restrictiveness are highly related , but not completely identical concepts . And this is the reason why Theorem 1 explicitly provides guarantee for both generator and encoder-side consistency . We aim to further simplify our exposition in future iterations of the paper . Regarding the Sufficiency for Disentanglement Formalism -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - The primary significance of this section is in formalizing what is meant by particular supervision method being insufficient . Our definition of sufficiency aims to distinguish the guarantees that arise solely from the choice of supervision versus the inductive bias of architecture or the objective function . Locatello et al. \u2019 s impossibility result is restricted to a specific kind of learning algorithm ( matching p_data ( x ) with p_theta ( x ) ) . In contrast , our definition for sufficiency is agnostic to the choice of learning algorithm and inductive bias . Regarding normalized consistency/restrictiveness scores -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- The proof for why the score is bounded between [ 0 , 1 ] directly follows from Lemma 1 in the Appendix I.2.1 . We have updated the paper to make this connection explicit . Because the scores in the figure are estimated via monte carlo sampling , the monte carlo estimator is not guaranteed to be within the interval [ 0 , 1 ] . However , we hope it is evident from the magnitude of the negative numbers ( and from Figures 8 , 9 , 10 ) that the small negative values are noisy estimates of a score of zero ."}, {"review_id": "HJgSwyBKvr-2", "review_text": "Summary The paper tries to construct a theoretical framework to rigorously analyze the disentanglement guarantees of weak supervision algorithms. In particular, it focuses on two concepts, consistency and restrictiveness which provides a formalism that precisely distinguishes when disentanglement arises from supervision versus model inductive bias. Strengths The framework uses two simple concepts, consistency and restrictiveness for both generator and decoder. It also gives rise to a calculus. It is very useful to demonstrate the conditions under which various supervision strategies guarantee disentanglement. The paper also did a good job clarifying how consistency and restrictiveness differ from other disentanglement concepts used in the literature. Weaknesses The paper does not propose effective methods for disentanglement in the weak supervision setting. The experimental section uses very toy datasets. It is not clear how the weak supervision signal can come from in realistic applications.", "rating": "3: Weak Reject", "reply_text": "Dear Reviewer , Thank you for acknowledging the significance of our theoretical framework . The goal of this paper is to clarify some confusion regarding the concept of disentanglement in the current literature , and to build up a theoretical framework that clarifies the guarantees actually conferred by several popular weak supervision methods . And we hope that you will re-assess the merits of our paper with this perspective in mind . On the Significance of our Theoretical Analysis -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - First , we would like to emphasize the inherent value of studying the theoretical guarantees of various weak supervision methods . Theorem 2 shows that existing approaches such as restricted-labeling in style-content disentanglement literature do not actually provide disentanglement guarantees . In contrast , employing our calculus and Theorem 1 allows us to design weak supervision methods that guarantee disentanglement . We believe our demonstration is of inherent value , as it exemplifies the theoretical analysis of guarantees that have so far eluded the disentanglement community . In light of the findings in Locatello et al . ( 2019 ) regarding the existing literature 's reliance on model inductive bias , we hope the reviewer will agree that providing a proper theoretical framework for understanding weak supervision is both timely and valuable . On the Significance of the Synthetic Experiments -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - The experiment section can broadly be divided into two categories : 1 . Experiments to test our theoretical guarantees ( Sections 6.2.1 and 6.2.3 ) Sections 6.2.1 and 6.2.3 primarily serve as demonstrations that the guarantees in Theorem 1 can be achieved in practice with machine learning models on synthetic datasets . Since ground truth factors are available on synthetic datasets , we used this as an opportunity to take extensive measurements to validate the various facets of our theoretical statements ( Figures 3-5 and 7-16 ) . Furthermore , the synthetic datasets that we chose are common benchmarks used in the existing disentanglement literature ( Locatello et al.2019 ; Burgess et al.2018 ; Kim et al.2018 ; Ridgeway et al.2018 ; Denton et al.2017 ; Mathieu et al.2016 ; Watters et al.2019 ) .The performances of our models on existing disentanglement metrics ( Figure 13 ) can also be directly compared with the scores reported in Locatello et al . ( 2019 ) .We agree that the use of non-synthetic data would further enhance the validation of these theoretical guarantees , but we hope that this does not detract from the legitimacy and extensive nature of our existing experiments . 2.Experiments that assess the gap between theory and practice ( 6.2.2 ) Figure 4 of Section 6.2.2 addresses the following question : if Theorem 2 states that disentanglement is not guaranteed in , for example , style-content disentanglement , why have we as a community not established this as common knowledge yet ? Figure 4 shows that the correlation between consistency and restrictiveness is quite strong across models tested across a broad range of hyperparameters . This finding leads us to make the following two conclusions . 1.It is easy to mistake the practical reliability of style-content disentanglement as a theoretical guarantee . 2.The practical reliability of style-content disentanglement is poorly understood and we wish to call attention to the need to provide a proper theoretical characterization of this reliability . We believe both conclusions are important in contextualizing the current literature on weakly supervised disentanglement , and hope that more researchers will be aware of these findings . On the Practicality of Weak Supervision Methods with Guarantees -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Since our paper shows examples of weak supervision methods that guarantee disentanglement , the reviewer is rightfully concerned about whether these methods can scale in practice . We believe that the scalability of these methods ultimately need to be addressed on a case-by-case basis in practice . While not within the scope of our paper , we acknowledge that the following questions are both important and challenging : 1 . What is the actual cost of weak supervision methods with guarantees for a particular setting ? 2.Are there settings that admit cheaper types of weak supervision methods with guarantees , compared to the specific methods analyzed in this paper ? 3.In what settings are weak supervision methods ( that do not have guarantees ) practically reliable ? And when they are reliable , why are they reliable ? We believe our paper naturally inspires these important questions . If the reviewer believes it is appropriate , we would like to include these questions as concluding thoughts in the paper to facilitate further discussion on weakly supervised disentanglement ."}], "0": {"review_id": "HJgSwyBKvr-0", "review_text": "This paper first discusses some concepts related to disentanglement. The authors propose to decompose disentanglement into two distinct concepts: consistency and restrictiveness. Then, a calculus of disentanglement is introduced to reveal the relationship between restrictiveness and consistency. The proposed concepts are applied to analyze weak supervision methods. This paper is well structured. The presentation is easy to follow. The problem discussed is important to the machine learning community. The concepts discussed are supported by a large number of experiments. The assumption that disentanglement can be decomposed into consistency and restrictiveness might be flawed. Let us consider a generator $g(Z)$ that always generates the same image for all $Z \\sim p(Z)$. Note that $g(Z)$ gives perfect consistency and perfect restrictiveness as defined in Equation (3) and (6). However, we consider $g(Z)$ is a bad generator, and we do not think the corresponding latent representation $Z$ achieves perfect disentanglement. Note that such $Z$, in general, gives low values in the existing disentanglement metrics. This implies that we might need to introduce a third component to disentanglement, which I call it relevance. We should additionally assume that different $z_{ \\setminus I}$ leads to different generated images. It might be challenging to measure relevance quantitatively under the probabilistic framework, but I believe this is necessary. In summary, I think the idea presented is interesting and useful. I believe this paper is promising and impactful after proper revision. However, I do not recommend acceptance because it looks technically flawed. Minor: In Figure 5, the illustration is clear to me, but I am not sure how the vertical axis simultaneously represents two variables $z_2, z_3$. In the table on page 5, $n$ represents the number of dimensions, right? ", "rating": "8: Accept", "reply_text": "Dear Reviewer , Thank you for acknowledging the significance of the problem being tackled in this paper . We would like to address your concern regarding the issue of degenerate generators that always output the same image for all choices of $ Z $ . In our paper , we referred to such a latent space $ Z $ as being \u201c uninformative \u201d . This scenario is explicitly prevented by our requirement , stated on page 3 , that our analysis is subject to the condition that \u201c $ g ( Z ) $ =d= $ g^ * ( S ) $ are equal in distribution \u201d . We would like to emphasize that the decomposition of disentanglement into restrictiveness and consistency is appropriate when this condition ( $ g ( Z ) $ =d= $ g^ * ( S ) $ ) is satisfied , otherwise we would indeed be admitting degenerate models that have uninformative latent spaces . We addressed this point once again on page 6 , stating that \u201c The distribution matching requirement $ g ( Z ) $ =d= $ g^ * ( S ) $ ensures latent code informativeness , i.e. , preventing trivial solutions where the latent code is uninformative ( see Theorem 7 for formal statement ) \u201d In the appendix , Theorem 7 formalizes what it means for the latent space to be informative and states that informativeness of the latent space is guaranteed when $ g ( Z ) $ =d= $ g^ * ( S ) $ . The formal statement and proof are available on Page 33 . In other words , our proposed concepts of consistency and restrictiveness are best thought of as complementing latent code informativeness , and not as replacements for checking the informativeness of the latent code . We also wish to note that our theoretical guarantees in Theorem 1 explicitly require $ g ( Z ) $ =d= $ g^ * ( S ) $ . This is because the distribution matching setup in Theorem 1 implies distribution matching of $ g ( Z ) $ with $ g^ * ( S ) $ . As such , with respect to our theoretical analysis , we hope that you will agree that our submission takes careful measures to explicitly combat the type of degeneracy that you pointed out . In practice , when distribution matching is not guaranteed , we fully support that practitioners should check for both latent code informativeness in addition to restrictiveness and consistency . Ultimately , we note that generator restrictiveness and consistency are concepts that complement latent code informativeness , and not replacements for it . We will strive to make this point even clearer when we update the paper . -- - Regarding minor comments : In Figure 2 , the way to interpret the vertical axis is that each row corresponds to a randomly sampled choice of $ ( z_2 , z_3 ) $ . This is stated in the caption as , \u201c each row denotes a fixed choice of $ ( z_2 , z_3 ) $ \u201d . In the calculus , you are correct that $ n $ denotes the number of dimensions . We shall make this point clear when updating our paper ."}, "1": {"review_id": "HJgSwyBKvr-1", "review_text": " The paper tries to bring some theoretical foundation to the weakly supervised disentanglement. Overall it is a good contribution, but the message of the paper is not clear. The authors propose two notions: consistency and restrictiveness, which they don't imply each other. However, the experiment on real data shows that they are highly correlated. Up until the experiment section, the paper is well written (although a bit verbose). It seems that it is great but unfinished work. The paper is well written, but in my opinion, there is too much verbosity on page 4-5 on rather trivial definitions consistency and restrictiveness and a big box in the calculus of disentanglement that steals space from the main results. In my opinion, those sections can be reduced so that other theorem can be covered. In my opinion, the theorem nine should be part of the main text. I understand the definition of \"Sufficiency for Disentanglement \" but it is not clear why it is important. Sure, it is a strong definition that says for any $\\mathcal{H}$ (and not a subset) the algorithm ($\\mathcal{A}$) should be able to match the distribution of the observation but why is it a big deal according to the next paragraph? I don't see any proof that Eq.11 should be between [0,1]. Yes, g is optimal, and if you enter suboptimal values to it, one expects the nominator to be less than dominator. However, g a function that is optimal in expectation, which does not mean for every s value it nominator is less than the denominator. In fact, some of the values in fig 3 are small negatives. Fig 3 is not explained well: you are showing normalized consistency and restiveness. First of all, what is the dataset you tried this on? Second, why some values are negative?! These are supposed to be between [0,1]. Third, what is the take-home-message of this figure? the first two matrices from left show that the factors are consistent b/c they are almost diagonal. The third one from left shows that the algorithm you used is not restrictive? Then are you suggesting this as a metric of evaluation? I am not sure I understand the first figure from the right. Overall, the authors perform a significant amount of experiments, but they did a poor job in summarizing the results. Finally, the authors claim \"...We believe this correlation between consistency and restrictiveness to have been a general source of confusion in the disentanglement literature, causing many to either observe or believe that restricted labeling or share pairing on $S_i$ (which only guarantees consistency) is sufficient for disentangling Si ...\" Each of those methods should be analyzed separately to ensure that their algorithms do not induce restiveness. I just don't see the natural connection between your figure 4 and this conclusion that you made. Minor: Where is the proof for Theorem 1? In the Supp, it starts with Theorem 8, I guess you meant Lemma 8? You need to clean up the Supp so that one can find the proof easily. I suggest restructuring the Supp to less and finally proof of Thorem 1.", "rating": "8: Accept", "reply_text": "Dear Reviewer , Thank you for your feedback ! We wish to address your concerns as follows . Regarding the message of the paper -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - The goal of this paper is to clarify some confusion regarding the concept of disentanglement in the current literature , and to build up a theoretical framework that clarifies the guarantees actually conferred by several popular weak supervision methods Regarding the seeming verbosity of the definitions -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- As evident from Figure 2 , consistency and restrictiveness are distinct concepts that play critical roles in theory . We agree that there is a noticeable contrast in the simplicity of the intuition of consistency/restrictiveness versus the lengthy mathematical description . Although those concepts are intuitive , the mathematical formalism we give is carefully designed with several important subtleties in mind : 1 . The specific sampling procedure in Eq ( 1 , 2 ) and Eq ( 4 , 5 ) are important for ensuring that the definition of disentanglement allows for correlated but interpretable features ( similar to Suter et al 2018 ) . We note that many existing definitions for disentanglement break down when the ground truth factors are correlated , and so we believe it is important to break away from the trend of making the definition of disentanglement implicitly reliant on the assumption of statistically independent ground truth factors . 2.Since consistency and restrictiveness are asymmetric concepts , generator-side consistency and restrictiveness and encoder-side consistency and restrictiveness are highly related , but not completely identical concepts . And this is the reason why Theorem 1 explicitly provides guarantee for both generator and encoder-side consistency . We aim to further simplify our exposition in future iterations of the paper . Regarding the Sufficiency for Disentanglement Formalism -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - The primary significance of this section is in formalizing what is meant by particular supervision method being insufficient . Our definition of sufficiency aims to distinguish the guarantees that arise solely from the choice of supervision versus the inductive bias of architecture or the objective function . Locatello et al. \u2019 s impossibility result is restricted to a specific kind of learning algorithm ( matching p_data ( x ) with p_theta ( x ) ) . In contrast , our definition for sufficiency is agnostic to the choice of learning algorithm and inductive bias . Regarding normalized consistency/restrictiveness scores -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- The proof for why the score is bounded between [ 0 , 1 ] directly follows from Lemma 1 in the Appendix I.2.1 . We have updated the paper to make this connection explicit . Because the scores in the figure are estimated via monte carlo sampling , the monte carlo estimator is not guaranteed to be within the interval [ 0 , 1 ] . However , we hope it is evident from the magnitude of the negative numbers ( and from Figures 8 , 9 , 10 ) that the small negative values are noisy estimates of a score of zero ."}, "2": {"review_id": "HJgSwyBKvr-2", "review_text": "Summary The paper tries to construct a theoretical framework to rigorously analyze the disentanglement guarantees of weak supervision algorithms. In particular, it focuses on two concepts, consistency and restrictiveness which provides a formalism that precisely distinguishes when disentanglement arises from supervision versus model inductive bias. Strengths The framework uses two simple concepts, consistency and restrictiveness for both generator and decoder. It also gives rise to a calculus. It is very useful to demonstrate the conditions under which various supervision strategies guarantee disentanglement. The paper also did a good job clarifying how consistency and restrictiveness differ from other disentanglement concepts used in the literature. Weaknesses The paper does not propose effective methods for disentanglement in the weak supervision setting. The experimental section uses very toy datasets. It is not clear how the weak supervision signal can come from in realistic applications.", "rating": "3: Weak Reject", "reply_text": "Dear Reviewer , Thank you for acknowledging the significance of our theoretical framework . The goal of this paper is to clarify some confusion regarding the concept of disentanglement in the current literature , and to build up a theoretical framework that clarifies the guarantees actually conferred by several popular weak supervision methods . And we hope that you will re-assess the merits of our paper with this perspective in mind . On the Significance of our Theoretical Analysis -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - First , we would like to emphasize the inherent value of studying the theoretical guarantees of various weak supervision methods . Theorem 2 shows that existing approaches such as restricted-labeling in style-content disentanglement literature do not actually provide disentanglement guarantees . In contrast , employing our calculus and Theorem 1 allows us to design weak supervision methods that guarantee disentanglement . We believe our demonstration is of inherent value , as it exemplifies the theoretical analysis of guarantees that have so far eluded the disentanglement community . In light of the findings in Locatello et al . ( 2019 ) regarding the existing literature 's reliance on model inductive bias , we hope the reviewer will agree that providing a proper theoretical framework for understanding weak supervision is both timely and valuable . On the Significance of the Synthetic Experiments -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - The experiment section can broadly be divided into two categories : 1 . Experiments to test our theoretical guarantees ( Sections 6.2.1 and 6.2.3 ) Sections 6.2.1 and 6.2.3 primarily serve as demonstrations that the guarantees in Theorem 1 can be achieved in practice with machine learning models on synthetic datasets . Since ground truth factors are available on synthetic datasets , we used this as an opportunity to take extensive measurements to validate the various facets of our theoretical statements ( Figures 3-5 and 7-16 ) . Furthermore , the synthetic datasets that we chose are common benchmarks used in the existing disentanglement literature ( Locatello et al.2019 ; Burgess et al.2018 ; Kim et al.2018 ; Ridgeway et al.2018 ; Denton et al.2017 ; Mathieu et al.2016 ; Watters et al.2019 ) .The performances of our models on existing disentanglement metrics ( Figure 13 ) can also be directly compared with the scores reported in Locatello et al . ( 2019 ) .We agree that the use of non-synthetic data would further enhance the validation of these theoretical guarantees , but we hope that this does not detract from the legitimacy and extensive nature of our existing experiments . 2.Experiments that assess the gap between theory and practice ( 6.2.2 ) Figure 4 of Section 6.2.2 addresses the following question : if Theorem 2 states that disentanglement is not guaranteed in , for example , style-content disentanglement , why have we as a community not established this as common knowledge yet ? Figure 4 shows that the correlation between consistency and restrictiveness is quite strong across models tested across a broad range of hyperparameters . This finding leads us to make the following two conclusions . 1.It is easy to mistake the practical reliability of style-content disentanglement as a theoretical guarantee . 2.The practical reliability of style-content disentanglement is poorly understood and we wish to call attention to the need to provide a proper theoretical characterization of this reliability . We believe both conclusions are important in contextualizing the current literature on weakly supervised disentanglement , and hope that more researchers will be aware of these findings . On the Practicality of Weak Supervision Methods with Guarantees -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Since our paper shows examples of weak supervision methods that guarantee disentanglement , the reviewer is rightfully concerned about whether these methods can scale in practice . We believe that the scalability of these methods ultimately need to be addressed on a case-by-case basis in practice . While not within the scope of our paper , we acknowledge that the following questions are both important and challenging : 1 . What is the actual cost of weak supervision methods with guarantees for a particular setting ? 2.Are there settings that admit cheaper types of weak supervision methods with guarantees , compared to the specific methods analyzed in this paper ? 3.In what settings are weak supervision methods ( that do not have guarantees ) practically reliable ? And when they are reliable , why are they reliable ? We believe our paper naturally inspires these important questions . If the reviewer believes it is appropriate , we would like to include these questions as concluding thoughts in the paper to facilitate further discussion on weakly supervised disentanglement ."}}