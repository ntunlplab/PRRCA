{"year": "2017", "forum": "HJV1zP5xg", "title": "Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models", "decision": "Reject", "meta_review": "Unfortunately, even after the reviewers adjusted their scores, this paper remains very close to the decision boundary. It presents a thorough empirical evaluation, but the improvements are fairly models. The area chair is also not convinced the idea itself will be very influential and change the way people do decoding since it feels a bit ad hoc (as pointed out by reviewer 1). Overall, this paper did not meet the bar for acceptance at ICLR this year.", "reviews": [{"review_id": "HJV1zP5xg-0", "review_text": "This paper considers the problem of decoding diverge solutions from neural sequence models. It basically adds an additional term to the log-likelihood of standard neural sequence models, and this additional term will encourage the solutions to be diverse. In addition to solve the inference, this paper uses a modified beam search. On the plus side, there is not much work on producing diverse solutions in RNN/LSTM models. This paper represents one of the few works on this topic. And this paper is well-written and easy to follow. The novel of this paper is relatively small. There has been a lot of prior work on producing diverse models in the area of probailistic graphical models. Most of them introduce an additional term in the objective function to encourage diversity. From that perspective, the solution proposed in this paper is not that different from previous work. Of course, one can argue that most previous work focues on probabilistic graphical models, while this paper focuses on RNN/LSTM models. But since RNN/LSTM can be simply interpreted as a probabilistic model, I would consider it a small novelty. The diverse beam search seems to straightforward, i.e. it partitions the beam search space into groups, and does not consider the diversity within group (in order to reduce the search space). To me, this seems to be a simple trick. Note most previous work on diverse solutions in probabilistic graphical models usually involve developing some nontrivial algorithmic solutions, e.g. in order to achieve efficiency. In comparison, the proposed solution in this paper seems to be simplistic for a paper. The experimental results how improvement over previous methods (Li & Jurafsky, 2015, 2016). But it is hard to say how rigorous the comparisons are, since they are based on the authors' own implementation of (Li & Jurasky, 2015, 2016). --------------- update: given that the authors made the code available (I do hope the code will remain publicly available), this has alleviated some of my concerns about the rigor of the experiments. I will raise my rate to 6.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We appreciate that the reviewers effort and are glad they found our paper well-written and clear . We agree that diverse decoding in RNNs is an important but understudied task that this paper works to address . 1.Novelty We agree there is a large body of work on producing diverse outputs in the context of probabilistic graphical models ( we discuss these in Section 4 ) and RNN models can be viewed as a special class of PGM ( specifically a T-order Markov Chain ) . However , we believe a crucial problem and contribution has been missed by the reviewer , so please allow us to restate . To the best of our knowledge , all diverse M-Best methods proposed in the classical PGM literature assume access to a tractable black-box 1-best or MAP inference algorithm . Since RNNs are equivalent to a T-th order Markov Chain , exact MAP inference is intractable and thus a direct applications of classical diverse M-Best techniques is infeasible and new techniques must be developed ( which is what our paper does ) . As we discuss in our related work ( Section 4 ) , the closest to this goal is the work of Gimpel et al.2013 , who apply DivMBest ( Batra et al.2012 ) to RNNs treating beam search as a black box inference technique . Unfortunately , this method is extremely wasteful both in terms of computation and time \u2014 it makes M sequential calls to beam search ( of arbitrary size B ) and retains only the most likely sentence , thus wastefully discarding B-1 outputs at each stage . By integrating diversity within beam search , we overcome these shortcomings by running parallel beam searches with staggered time offsets , obtaining significant time-savings . As a result , our method decodes diverse lists while being comparable to a single run of classical beam search in both computation and memory requirements . This is a significant contribution and improvement over classical BS ( in terms of diversity ) and the work of Gimpel et al . ( in terms of computation and time ) . 2.Comparisons to our own reimplementation We are surprised and disappointed that the reviewer expresses doubt about rigor of our experiments citing our own reimplementation of Li and Jurafsky , 2016 and Li et al. , 2015 . As we state in the paper ( Section 5 ) and in our previous response to the reviewer below , this is not our choice \u2014 the implementation of the diverse decoding scheme used in either papers is not publicly available . In the interest of transparency , our reimplementation of Li and Jurafsky , 2016 is made available here https : //github.com/ashwinkalyan/dbs/tree/lj16 and of Li et al.2015 is available here : https : //github.com/ashwinkalyan/dbs/tree/li15 . As stated previously , parameters of all methods are tuned using grid search to optimize for oracle accuracies on a held-out validation set \u2014 to ensure a fair comparison . We are at a loss for what else we could do to ensure a transparent , fair , and rigorous evaluation , and are open to concrete suggestions ."}, {"review_id": "HJV1zP5xg-1", "review_text": " [ Summary ] This paper presents a new modified beam search algorithm that promotes diverse beam candidates. It is a well known problem \u2014with both RNNs and also non-neural language models\u2014 that beam search tends to generate beam candidates that are very similar with each other, which can cause two separate but related problems: (1) search error: beam search may not be able to discover a globally optimal solution as they can easily fall out of the beam early on, (2) simple, common, non-diverse output: the resulting output text tends to be generic and common. This paper aims to address the second problem (2) by modifying the search objective function itself so that there is a distinct term that scores diversity among the beam candidates. In other words, the goal of the presented algorithm is not to reduce the search error of the original objective function. In contrast, stack decoding and future cost estimation, common practices in phrase-based SMT, aim to address the search error problem. [ Merits ] I think the Diverse Beam Search (DBS) algorithm proposed by the authors has some merits. It may be useful when we cannot rely on traditional beam search on the original objective function either because the trained model is not strong enough, or because of the search error, or because the objective itself does not align with the goal of the application. [ Weaknesses ] It is however not entirely clear how the proposed method compares against more traditional approaches like stack decoding and future cost estimation, on tasks like machine translation, as the authors compare their algorithm mainly against L&J\u2019s diverse LM models and simple beam search. In fact, modification to the objective function has been applied even in the neural MT context. For example, see equation (14) in page 12 of the following paper: \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\" (https://arxiv.org/pdf/1609.08144v2.pdf) where the attention coverage term serves a role similar to stack decoding (though unlike stack decoding, the objective term is entirely re-defined, more similarly to DBS proposed in this work), and the length penalty may have an effect that indirectly promotes more informative (thus more likely diverse) responses. Comparison against these existing algorithms would make the proposed work more complete. Also, I have a mixed feeling about computing and reporting only *oracle* BLUE, CIDEr, METEOR, etc. Especially given how these oracle scores are very close to each other, and that developing a high performing ranking has not been addressed in this work (and that doing so must be not all that trivial), I\u2019m somewhat skeptical how much of DBS results make a practical difference. **** [Update after the author responses] **** The authors addressed some of my concerns by adding a new baseline comparison against Wu et al. 2016. Thus I will raise my score to 6. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for the feedback . Comparison to Google 's Neural Machine Translation System : Bridging the Gap between Human and Machine Translation : As noted by the reviewer , this paper uses two methods for diverse decodings \u2014 ( 1 ) modified objective that includes a coverage penalty and ( 2 ) length normalization . ( eq.14 ) The coverage penalty term as proposed in that paper ( using attention over the inputs to define \u2018 coverage \u2019 ) is intricately tied to the task of NMT and unlike DBS does not generalize to other sequence decoding tasks ( e.g.image captioning , visual question generation , dialog , etc ) . Unlike NMT , some input information can be ignored in other tasks . In contrast , the length-normalization term to select the top-B completed beams can be easily implemented for any decoding scenario . Thus , following your request , we have updated the paper to include comparison to this for both captioning and machine translation . Following the experimental setup in the paper , for fairness to all techniques , we tune the strength \\alpha through a grid search for the oracle accuracy on a held-out validation set ( 0.8 and 0.6 for captioning on PASCAL-50S and 0.6 for MT ) . Table 1 and 2 in the updated pdf show results on captioning and MT respectively . We find that DBS length normalization helps over BS in the order of 0.4 BLEU points , but performs 0.2 BLEU points worse than DBS on MT . Thank you for this suggestion . We also investigate the importance of the length term ( in the Discussion section of the Appendix ) by computing the correlation between the length and the accuracy obtained for each generated hypothesis . On the PASCAL-50S dataset , we observe that the correlation with length and SPICE is insignificant for all decoding methods - BS , DBS and L & J16 . \ufffc Significance of DBS results : The oracle accuracy is a measure of the maximum accuracy that can be achieved by a list of M decoded solutions ( assuming access to a perfect re-ranker ) . As the goal of our paper is to develop an efficient diverse decoding technique , coming up with better re-ranking methods is an entirely different problem that is beyond the scope of this work . We perform additional analysis between the beam budget and corresponding oracle accuracy of the generated lists ( presented in the Discussion section in the supplementary ) . We notice that DBS generates high-scoring sequences at smaller beam sizes as compared to the baselines -- meaning that it utilizes the beam budget better to explore the search space . In this context , we believe that efficient diverse decoding techniques can help us use simpler re-rankers that need to perform fewer comparisons to select the top-1 solution . Also , we would like to point out that the gains obtained from diverse decoding on NMT are consistent with L & J16 -- oracle @ 20 increases by a score of 0.6 due to DBS , compared to using BS . ( L & J16 obtain a score increase of 0.3 due to diverse decoding at B=200 ) . While it is possible that machine translation as a task does not require significant diversity in its outputs , DBS shows the potential of obtaining competitive gains provided access to a good re-ranker . Finally , we note that oracle accuracies are a well-established performance metric , used by a line of previous work -- Batra et al. , 2012 , Prasad et al. , 2014 , Kirillov et al. , 2015 and Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles ( Lee et al. , 2016 ) ."}, {"review_id": "HJV1zP5xg-2", "review_text": " The paper addresses an important problem - namely on how to improve diversity in responses. It is applaudable that the authors show results on several tasks showing the applicability across different problems. In my view there are two weaknesses at this point 1) the improvements (for essentially all tasks) seem rather minor and do not really fit the overall claim of the paper 2) the approach seems quite ad hoc and it unclear to me if this is something that will and should be widely adopted. Having said this the gist of the proposed solution seems interesting but somewhat premature. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your feedback . We appreciate the note about the broad applicability of our work demonstrated with results on several tasks . Can you kindly explain the terms used in the weaknesses listed by you ? The current review simply states opinion without pointing to anything concrete in the paper and as such , is not something we can use to improve the paper . 1. \u201c Improvements are minor and do not \u2026 fit the \u2026 claim of the paper \u201d We present quantitative results on two applications \u2014 image captioning and machine translation . On both applications , under all standard metrics ( SPICE , CIDER , BLEU , METEOR ) , our approach outperforms two strong baselines on all settings ( oracle @ 1,5,10,20 using a beam size of 20 for all methods ) except one setting ( see table 4 , M=1 ) . Moreover , the improvements of our work over recent competitive baselines ( e.g.Li and Jurafsky , 2016 ) are typically larger than the improvements of the baselines over classical beam search . Further , as we discuss in Section 5.2 , results averaged over the entire test set may be a pessimistic measure of the gains due to diverse decoding because not all instances need diversity . In the context of image captioning , \u201c simple \u201d image scenes do not need diversity in captions ( because there may not be much to say ) , while \u201c complex \u201d scenes may benefit more from diversity in generated captions . We provide relevant examples in the supplementary to illustrate this point . Interestingly , note that a more recent work by Li et al.https : //arxiv.org/pdf/1611.08562v1.pdf refer to this aspect of our paper and develop techniques to control the diversity strength while decoding the output . In this context , we would like to know what makes these improvements appear \u201c minor \u201d . And how do they not fit the claims of the paper ? 2. \u201c The approach is ad hoc \u201d We present a formal objective to optimize , describe why exact optimization of that objective is intractable even for small sequences , and provide a doubly-greedy algorithm that combines ideas from beam search ( greedy in time ) and diverse M-Best methods from PGM literature ( greedy in solutions ) . What makes our method ad hoc ? 3. \u201c gist of the proposed solution seems interesting but somewhat premature \u201d We developed a general beam search replacement , demonstrated its applicability and results on 4 different applications ( image captioning , machine translation , dialog , visual question generation ) , presented parameter sensitivity plots , ablation studies with 4 different diversity measures , released our codebase ( including our reimplementation of baselines ) , and an online interactive demo to visualize the working of the algorithm . What makes this premature ?"}], "0": {"review_id": "HJV1zP5xg-0", "review_text": "This paper considers the problem of decoding diverge solutions from neural sequence models. It basically adds an additional term to the log-likelihood of standard neural sequence models, and this additional term will encourage the solutions to be diverse. In addition to solve the inference, this paper uses a modified beam search. On the plus side, there is not much work on producing diverse solutions in RNN/LSTM models. This paper represents one of the few works on this topic. And this paper is well-written and easy to follow. The novel of this paper is relatively small. There has been a lot of prior work on producing diverse models in the area of probailistic graphical models. Most of them introduce an additional term in the objective function to encourage diversity. From that perspective, the solution proposed in this paper is not that different from previous work. Of course, one can argue that most previous work focues on probabilistic graphical models, while this paper focuses on RNN/LSTM models. But since RNN/LSTM can be simply interpreted as a probabilistic model, I would consider it a small novelty. The diverse beam search seems to straightforward, i.e. it partitions the beam search space into groups, and does not consider the diversity within group (in order to reduce the search space). To me, this seems to be a simple trick. Note most previous work on diverse solutions in probabilistic graphical models usually involve developing some nontrivial algorithmic solutions, e.g. in order to achieve efficiency. In comparison, the proposed solution in this paper seems to be simplistic for a paper. The experimental results how improvement over previous methods (Li & Jurafsky, 2015, 2016). But it is hard to say how rigorous the comparisons are, since they are based on the authors' own implementation of (Li & Jurasky, 2015, 2016). --------------- update: given that the authors made the code available (I do hope the code will remain publicly available), this has alleviated some of my concerns about the rigor of the experiments. I will raise my rate to 6.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We appreciate that the reviewers effort and are glad they found our paper well-written and clear . We agree that diverse decoding in RNNs is an important but understudied task that this paper works to address . 1.Novelty We agree there is a large body of work on producing diverse outputs in the context of probabilistic graphical models ( we discuss these in Section 4 ) and RNN models can be viewed as a special class of PGM ( specifically a T-order Markov Chain ) . However , we believe a crucial problem and contribution has been missed by the reviewer , so please allow us to restate . To the best of our knowledge , all diverse M-Best methods proposed in the classical PGM literature assume access to a tractable black-box 1-best or MAP inference algorithm . Since RNNs are equivalent to a T-th order Markov Chain , exact MAP inference is intractable and thus a direct applications of classical diverse M-Best techniques is infeasible and new techniques must be developed ( which is what our paper does ) . As we discuss in our related work ( Section 4 ) , the closest to this goal is the work of Gimpel et al.2013 , who apply DivMBest ( Batra et al.2012 ) to RNNs treating beam search as a black box inference technique . Unfortunately , this method is extremely wasteful both in terms of computation and time \u2014 it makes M sequential calls to beam search ( of arbitrary size B ) and retains only the most likely sentence , thus wastefully discarding B-1 outputs at each stage . By integrating diversity within beam search , we overcome these shortcomings by running parallel beam searches with staggered time offsets , obtaining significant time-savings . As a result , our method decodes diverse lists while being comparable to a single run of classical beam search in both computation and memory requirements . This is a significant contribution and improvement over classical BS ( in terms of diversity ) and the work of Gimpel et al . ( in terms of computation and time ) . 2.Comparisons to our own reimplementation We are surprised and disappointed that the reviewer expresses doubt about rigor of our experiments citing our own reimplementation of Li and Jurafsky , 2016 and Li et al. , 2015 . As we state in the paper ( Section 5 ) and in our previous response to the reviewer below , this is not our choice \u2014 the implementation of the diverse decoding scheme used in either papers is not publicly available . In the interest of transparency , our reimplementation of Li and Jurafsky , 2016 is made available here https : //github.com/ashwinkalyan/dbs/tree/lj16 and of Li et al.2015 is available here : https : //github.com/ashwinkalyan/dbs/tree/li15 . As stated previously , parameters of all methods are tuned using grid search to optimize for oracle accuracies on a held-out validation set \u2014 to ensure a fair comparison . We are at a loss for what else we could do to ensure a transparent , fair , and rigorous evaluation , and are open to concrete suggestions ."}, "1": {"review_id": "HJV1zP5xg-1", "review_text": " [ Summary ] This paper presents a new modified beam search algorithm that promotes diverse beam candidates. It is a well known problem \u2014with both RNNs and also non-neural language models\u2014 that beam search tends to generate beam candidates that are very similar with each other, which can cause two separate but related problems: (1) search error: beam search may not be able to discover a globally optimal solution as they can easily fall out of the beam early on, (2) simple, common, non-diverse output: the resulting output text tends to be generic and common. This paper aims to address the second problem (2) by modifying the search objective function itself so that there is a distinct term that scores diversity among the beam candidates. In other words, the goal of the presented algorithm is not to reduce the search error of the original objective function. In contrast, stack decoding and future cost estimation, common practices in phrase-based SMT, aim to address the search error problem. [ Merits ] I think the Diverse Beam Search (DBS) algorithm proposed by the authors has some merits. It may be useful when we cannot rely on traditional beam search on the original objective function either because the trained model is not strong enough, or because of the search error, or because the objective itself does not align with the goal of the application. [ Weaknesses ] It is however not entirely clear how the proposed method compares against more traditional approaches like stack decoding and future cost estimation, on tasks like machine translation, as the authors compare their algorithm mainly against L&J\u2019s diverse LM models and simple beam search. In fact, modification to the objective function has been applied even in the neural MT context. For example, see equation (14) in page 12 of the following paper: \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\" (https://arxiv.org/pdf/1609.08144v2.pdf) where the attention coverage term serves a role similar to stack decoding (though unlike stack decoding, the objective term is entirely re-defined, more similarly to DBS proposed in this work), and the length penalty may have an effect that indirectly promotes more informative (thus more likely diverse) responses. Comparison against these existing algorithms would make the proposed work more complete. Also, I have a mixed feeling about computing and reporting only *oracle* BLUE, CIDEr, METEOR, etc. Especially given how these oracle scores are very close to each other, and that developing a high performing ranking has not been addressed in this work (and that doing so must be not all that trivial), I\u2019m somewhat skeptical how much of DBS results make a practical difference. **** [Update after the author responses] **** The authors addressed some of my concerns by adding a new baseline comparison against Wu et al. 2016. Thus I will raise my score to 6. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for the feedback . Comparison to Google 's Neural Machine Translation System : Bridging the Gap between Human and Machine Translation : As noted by the reviewer , this paper uses two methods for diverse decodings \u2014 ( 1 ) modified objective that includes a coverage penalty and ( 2 ) length normalization . ( eq.14 ) The coverage penalty term as proposed in that paper ( using attention over the inputs to define \u2018 coverage \u2019 ) is intricately tied to the task of NMT and unlike DBS does not generalize to other sequence decoding tasks ( e.g.image captioning , visual question generation , dialog , etc ) . Unlike NMT , some input information can be ignored in other tasks . In contrast , the length-normalization term to select the top-B completed beams can be easily implemented for any decoding scenario . Thus , following your request , we have updated the paper to include comparison to this for both captioning and machine translation . Following the experimental setup in the paper , for fairness to all techniques , we tune the strength \\alpha through a grid search for the oracle accuracy on a held-out validation set ( 0.8 and 0.6 for captioning on PASCAL-50S and 0.6 for MT ) . Table 1 and 2 in the updated pdf show results on captioning and MT respectively . We find that DBS length normalization helps over BS in the order of 0.4 BLEU points , but performs 0.2 BLEU points worse than DBS on MT . Thank you for this suggestion . We also investigate the importance of the length term ( in the Discussion section of the Appendix ) by computing the correlation between the length and the accuracy obtained for each generated hypothesis . On the PASCAL-50S dataset , we observe that the correlation with length and SPICE is insignificant for all decoding methods - BS , DBS and L & J16 . \ufffc Significance of DBS results : The oracle accuracy is a measure of the maximum accuracy that can be achieved by a list of M decoded solutions ( assuming access to a perfect re-ranker ) . As the goal of our paper is to develop an efficient diverse decoding technique , coming up with better re-ranking methods is an entirely different problem that is beyond the scope of this work . We perform additional analysis between the beam budget and corresponding oracle accuracy of the generated lists ( presented in the Discussion section in the supplementary ) . We notice that DBS generates high-scoring sequences at smaller beam sizes as compared to the baselines -- meaning that it utilizes the beam budget better to explore the search space . In this context , we believe that efficient diverse decoding techniques can help us use simpler re-rankers that need to perform fewer comparisons to select the top-1 solution . Also , we would like to point out that the gains obtained from diverse decoding on NMT are consistent with L & J16 -- oracle @ 20 increases by a score of 0.6 due to DBS , compared to using BS . ( L & J16 obtain a score increase of 0.3 due to diverse decoding at B=200 ) . While it is possible that machine translation as a task does not require significant diversity in its outputs , DBS shows the potential of obtaining competitive gains provided access to a good re-ranker . Finally , we note that oracle accuracies are a well-established performance metric , used by a line of previous work -- Batra et al. , 2012 , Prasad et al. , 2014 , Kirillov et al. , 2015 and Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles ( Lee et al. , 2016 ) ."}, "2": {"review_id": "HJV1zP5xg-2", "review_text": " The paper addresses an important problem - namely on how to improve diversity in responses. It is applaudable that the authors show results on several tasks showing the applicability across different problems. In my view there are two weaknesses at this point 1) the improvements (for essentially all tasks) seem rather minor and do not really fit the overall claim of the paper 2) the approach seems quite ad hoc and it unclear to me if this is something that will and should be widely adopted. Having said this the gist of the proposed solution seems interesting but somewhat premature. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your feedback . We appreciate the note about the broad applicability of our work demonstrated with results on several tasks . Can you kindly explain the terms used in the weaknesses listed by you ? The current review simply states opinion without pointing to anything concrete in the paper and as such , is not something we can use to improve the paper . 1. \u201c Improvements are minor and do not \u2026 fit the \u2026 claim of the paper \u201d We present quantitative results on two applications \u2014 image captioning and machine translation . On both applications , under all standard metrics ( SPICE , CIDER , BLEU , METEOR ) , our approach outperforms two strong baselines on all settings ( oracle @ 1,5,10,20 using a beam size of 20 for all methods ) except one setting ( see table 4 , M=1 ) . Moreover , the improvements of our work over recent competitive baselines ( e.g.Li and Jurafsky , 2016 ) are typically larger than the improvements of the baselines over classical beam search . Further , as we discuss in Section 5.2 , results averaged over the entire test set may be a pessimistic measure of the gains due to diverse decoding because not all instances need diversity . In the context of image captioning , \u201c simple \u201d image scenes do not need diversity in captions ( because there may not be much to say ) , while \u201c complex \u201d scenes may benefit more from diversity in generated captions . We provide relevant examples in the supplementary to illustrate this point . Interestingly , note that a more recent work by Li et al.https : //arxiv.org/pdf/1611.08562v1.pdf refer to this aspect of our paper and develop techniques to control the diversity strength while decoding the output . In this context , we would like to know what makes these improvements appear \u201c minor \u201d . And how do they not fit the claims of the paper ? 2. \u201c The approach is ad hoc \u201d We present a formal objective to optimize , describe why exact optimization of that objective is intractable even for small sequences , and provide a doubly-greedy algorithm that combines ideas from beam search ( greedy in time ) and diverse M-Best methods from PGM literature ( greedy in solutions ) . What makes our method ad hoc ? 3. \u201c gist of the proposed solution seems interesting but somewhat premature \u201d We developed a general beam search replacement , demonstrated its applicability and results on 4 different applications ( image captioning , machine translation , dialog , visual question generation ) , presented parameter sensitivity plots , ablation studies with 4 different diversity measures , released our codebase ( including our reimplementation of baselines ) , and an online interactive demo to visualize the working of the algorithm . What makes this premature ?"}}