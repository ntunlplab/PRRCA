{"year": "2017", "forum": "HJSCGD9ex", "title": "Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context", "decision": "Reject", "meta_review": "While the reviewers find the core idea intriguing, the method needs a clearer explanation and a more thorough comparison to related work.", "reviews": [{"review_id": "HJSCGD9ex-0", "review_text": "This paper discusses multi-sense embedddings and proposes learning those by using aligned text across languages. Further, the paper suggests that adding more languages helps improve word sense disambiguation (as some ambiguities can be carried across language pairs). While this idea in itself isn't new, the authors propose a particular setup for learning multi-sense embeddings by exploiting multilingual data. Broadly this is fine, but unfortunately the paper then falls short in a number of ways. For one, the model section is unnecessarily convoluted for what is a nice idea that could be described in a far more concise fashion. Next (and more importantly), comparison with other work is lacking to such an extent that it is impossible to evaluate the merits of the proposed model in an objective fashion. This paper could be a lot stronger if the learned embeddings were evaluated in downstream tasks and evaluated against other published methods. In the current version there is too little of this, leaving us with mostly relative results between model variants and t-SNE plots that don't really add anything to the story.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for you comments . We will work to make the model description easier to understand . We will also evaluate our embeddings on other downstream tasks to improve the comparison with existing works ."}, {"review_id": "HJSCGD9ex-1", "review_text": "this work aims to address representation of multi-sense words by exploiting multilingual context. Experiments on word sense induction and word similarity in context show that the proposed solution improves over the baseline. From a computational linguistics perspective, the fact that languages less similar to English help more is intriguing. I see following problem with this work: - the paper is hard to follow and hard to see what's new compared to the baseline model [1]. A paragraph of discussion should clearly compare and contrast with that work. - the proposed model is a slight variation of the previous work [1] thus the experimental setup should be designed in a way so that we compare which part helps improvement and how much. thus MONO has not been exposed the same training data and we can't be sure that the proposed model is better because MONO does not observe the data or lacks the computational power. I suggest following baseline: turning multilingual data to monolingual one using the alignment, then train the baseline model[1] on this pseudo monolingual data. - the paper provides good benchmarks for intrinsic evaluation but the message could be conveyed more strongly if we see improvement in a downstream task. [1] https://arxiv.org/pdf/1502.07257v2.pdf", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your comments . We will improve the writing and experimental comparison in the next version . We would like to note that MONO is exposed to same amount of training data , because we ensure that the number of words in the context window are same ( by using a bigger context parameter for MONO ) . Indeed , MONO is unable to process multilingual data , but that is a limitation of the modeling itself . We will try the pseudo monolingual experiment you suggested ."}, {"review_id": "HJSCGD9ex-2", "review_text": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context. Overall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low. Overall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results. Pros: Interesting extension of skipgram to capture polysemy. Cons: The paper is not clearly written. Results reported in the paper seems pretty low.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for the comments and suggestions . We will simplify the model description per your suggestion ."}], "0": {"review_id": "HJSCGD9ex-0", "review_text": "This paper discusses multi-sense embedddings and proposes learning those by using aligned text across languages. Further, the paper suggests that adding more languages helps improve word sense disambiguation (as some ambiguities can be carried across language pairs). While this idea in itself isn't new, the authors propose a particular setup for learning multi-sense embeddings by exploiting multilingual data. Broadly this is fine, but unfortunately the paper then falls short in a number of ways. For one, the model section is unnecessarily convoluted for what is a nice idea that could be described in a far more concise fashion. Next (and more importantly), comparison with other work is lacking to such an extent that it is impossible to evaluate the merits of the proposed model in an objective fashion. This paper could be a lot stronger if the learned embeddings were evaluated in downstream tasks and evaluated against other published methods. In the current version there is too little of this, leaving us with mostly relative results between model variants and t-SNE plots that don't really add anything to the story.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for you comments . We will work to make the model description easier to understand . We will also evaluate our embeddings on other downstream tasks to improve the comparison with existing works ."}, "1": {"review_id": "HJSCGD9ex-1", "review_text": "this work aims to address representation of multi-sense words by exploiting multilingual context. Experiments on word sense induction and word similarity in context show that the proposed solution improves over the baseline. From a computational linguistics perspective, the fact that languages less similar to English help more is intriguing. I see following problem with this work: - the paper is hard to follow and hard to see what's new compared to the baseline model [1]. A paragraph of discussion should clearly compare and contrast with that work. - the proposed model is a slight variation of the previous work [1] thus the experimental setup should be designed in a way so that we compare which part helps improvement and how much. thus MONO has not been exposed the same training data and we can't be sure that the proposed model is better because MONO does not observe the data or lacks the computational power. I suggest following baseline: turning multilingual data to monolingual one using the alignment, then train the baseline model[1] on this pseudo monolingual data. - the paper provides good benchmarks for intrinsic evaluation but the message could be conveyed more strongly if we see improvement in a downstream task. [1] https://arxiv.org/pdf/1502.07257v2.pdf", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your comments . We will improve the writing and experimental comparison in the next version . We would like to note that MONO is exposed to same amount of training data , because we ensure that the number of words in the context window are same ( by using a bigger context parameter for MONO ) . Indeed , MONO is unable to process multilingual data , but that is a limitation of the modeling itself . We will try the pseudo monolingual experiment you suggested ."}, "2": {"review_id": "HJSCGD9ex-2", "review_text": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from multiple languages are used to train the model. Therefore, the context words of a given target word can be either from the same sentence, or from an aligned sentence in a different language. This allows to learn multilingual embedding. The second difference is that each word is represented by multiple vectors, one for each of its different senses. A latent variable z models which sense should be used, given the context. Overall, I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea. The model introduced in this paper is a nice generalization of the skipgram model in that direction. However, I found the paper a bit hard to follow. The formulation might probably be simplified (e.g. why not consider a target word w and a context c, where c is either in the source or target language. Since all factors are independent, this should not change the model much, and would make the presentation easier). The performance of all models reported in Table 2 & 3 seem pretty low. Overall, I like the main idea of the paper, which is to represent word senses by latent variables in a probabilistic model. I feel that the method could be presented more clearly, which would make the paper much stronger. I also have some concerns regarding the experimental results. Pros: Interesting extension of skipgram to capture polysemy. Cons: The paper is not clearly written. Results reported in the paper seems pretty low.", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thanks for the comments and suggestions . We will simplify the model description per your suggestion ."}}