{"year": "2020", "forum": "S1eZYeHFDS", "title": "Deep Learning For Symbolic Mathematics", "decision": "Accept (Spotlight)", "meta_review": "The paper presents a deep learning approach for tasks such as symbolic integration and solving differential equations. \n\nThe reviewers were positive and the paper has had extensive discussion, which we hope has been positive for the authors. \n\nWe look forward to seeing the engagement with this work at the conference.", "reviews": [{"review_id": "S1eZYeHFDS-0", "review_text": "In this paper, the authors propose a method for generating two types of symbolic mathematics problems, integration and differential equations, and their solutions. The purpose of the method is to generate datasets for training transformer neural networks that solve integration and differential-equation problems. The authors note that while solving these problems is very difficult, generating solutions first and corresponding problems next automatically is feasible, and their method realizes this observation. The authors report that transformer networks trained on the synthetically generated solution-problem pairs outperform existing symbolic solvers for integration and differential equation. Here are the reasons that I like the paper. The observation that solving a symbolic mathematics problem is often a pattern matching process is interesting. It is surprising to know that a transformer network designed to translated the generating problem-solution pairs backward (from problem to solution) works better than the solvers in Mathematica and Matlab. Also, I like nice cute tricks used in the authors' method for generating solution-problem pairs, such as the syntactic condition on a possible position of some constant. The paper is overall clearly written. I presume that when the authors compare their learned solvers with Mathematica and Matlab, they used a dataset generated by their method. I feel that this comparison is somewhat unfair, although it still impresses me that even for this dataset, the authors' solvers beat Mathematica and Matlab. I suggest to try at least one more experiment on a dataset not generated by the authors' method (integration and differential equation problems from math textbooks or other sources) if possible. * p3: Why is it important to have a generator that produces the four expression trees in p3 with equal or almost equal probabilities? Do you have any semi-formal or informal justification that the distribution of such a generator better matches the kind of expressions arising in the real world? * p4: f(x)/x)) ===> f(x)/x) * \"If this equation can be solved in c1\", p5: How realistic is this assumption? * p5: 1/2 e^x(...) ===> 0 = 1/2 e^x(...) * p5: If you have a thought or an observation on the impact of each of the data-cleaning steps in Section 3.4, I suggest you to share this in the paper. * p6: Why did you remove expressions with more than 512 tokens? * p6: compare to ===> compared to * p7: Would you put the reminder of the size of the training set in Section 4.4? It only mentions that of the test set currently. * p8: 1-(4x^2 ===> (1-(4x^2", "rating": "8: Accept", "reply_text": "Thank you very much for your review and comments . We address them in turn : ==== \u201c I presume that when the authors compare their learned solvers with Mathematica and Matlab , they used a dataset generated by their method. \u201d This is correct : we test our model and Mathematica on a held out sample from the generated sample ( and mention at the end of paragraph 4.5 that this creates a favorable situation for our model ) . Since the submission , we tried to experiment on integration for samples generated with different methods . More precisely , we generated \u201c forward \u201d samples of random functions that SymPy knows how to integrate . This gives a good approximation of what Computer Algebras are good for . Examination of the samples shows that in backward samples , derivatives tend to be longer than primitives , whereas the opposite holds for forward samples . Unsurprisingly , a model trained on backward samples performs poorly on forward examples . But a forward-trained model achieves the same performance on forward data as a backward-trained model on backward data : this suggests that the performance is linked to data generation , and we actually observe that a model trained on the combination of backward and forward data achieves a good performance on all samples . These new results are in the updated version of the paper . ===== p3 : Why is it important to have a generator that produces the four expression trees in p3 with equal or almost equal probabilities ? Do you have any semi-formal or informal justification that the distribution of such a generator better matches the kind of expressions arising in the real world ? We have no idea of the actual distribution of expressions \u201c in the wild \u201d ( provided this has a meaning ) . Since we have no reason to consider an expression more relevant than another , we decided to sample all of them with the same probability . Since there is a one to one mapping from expressions to decorated trees ( thanks to the prefix notation ) , we want to sample them uniformly , which means that all trees have to be sampled with the same probability . ===== `` If this equation can be solved in c1 '' , p5 : How realistic is this assumption ? Formally , the function F ( x , y , c1 ) is the equation of the level curves of the function f , which we originally generated . The equation dF/dx = 0 corresponds to the gradient of F along x . Solving this equation in c1 amounts to finding an equation of the level curves of the gradient . In practice , we found that we can solve in c1 about 50 % of the time . If we can not , we simply discard the initial expression . ===== p5 : If you have a thought or an observation on the impact of each of the data-cleaning steps in Section 3.4 , I suggest you to share this in the paper . Equation simplification , like the use of small integer coefficients in expressions , limits the need for our model to carry out ( and learn ) arithmetic simplification in addition to the main task ( integration of equation solving ) . This will reduce , or rather , bias , the generated expressions , by reducing the number of constants ( i.e.leaves different from \u2018 x \u2019 in the expression tree ) , and eliminating certain sequences of operators ( exp ( log ( ) ) , sin ( arcsin ( ) ) , and so on . We consider it as a way to improve learning by focusing on the task at hand . Coefficient simplification is a trick of our method to generate differential equations . This step makes the elimination of constants c1 and c2 easier , but the generated equations and solutions remain the same . Invalid expression removal allows us to avoid exceptions when evaluating the functions . Since they only concern constants , they have very little impact on the problem . An alternative would be to replace the invalid sub-expressions by valid ones ( see also our reply to reviewer 1 on this point ) . ===== p6 : Why did you remove expressions with more than 512 tokens ? We found that with very large expressions , the transformer model is subject to out of memory errors , which requires to use a smaller batch size at training time . To keep a large batch size ( and to make training faster ) , we set this limit of 512 tokens . Overall , this is only discards a tiny fraction of the generated expressions . ==== p7 : Would you put the reminder of the size of the training set in Section 4.4 ? It only mentions that of the test set currently . Yes , we added a new Table ( table 1 in the updated version of the paper ) with statistics about our datasets . Thank you for the suggestion ."}, {"review_id": "S1eZYeHFDS-1", "review_text": "It is rather interesting for a humble academic to review this paper. It already has a discussion, which I find very valuable, and many tweets and social media exposure and endorsements. It is onerous to review in this setting. The paper makes a valuable contribution. The adversarial discussions in this website and the unhelpful hype can in this case be addressed to some extent by the authors. I will start with discussing this. Clearly, the title is too broad. This is not deep learning for symbolic mathematics. In no way does this paper address the essence of what is understood by \"symbolic mathematics\". What the authors address is mapping sequences of discrete quantities to other sequences of discrete quantities. The sequences in this paper correspond to function-integral i/o sequences, and 1st/2nd ODEs-function i/o sequences. I will leave it to the authors to come up with a more informative title, but something like deep learning or transformers for symbolic (1d) integration and simple ODEs with be far more accurate. To hammer this point, note that Section 3 discusses removing \"invalid\" expressions: log(0) or sqrt(-2). However, it is the manipulation of infinity and imaginary numbers that could be considered to be one of the greatest achievements of symbolic mathematics over the last couple of hundred years. It is reasonable to expect neural nets to do this one day, because humans can, but this should come with results. It's too early to make the claim in the paper title. Sentences such as \"This suggest (sic) that some deeper understanding of mathematics has been achieved by the model.\" and \"These results are surprising given the incapacity of neural models to perform simpler tasks ...\" are speculative, potentially inaccurate and likely to increase hype. This hype is not needed. Hype and over-claiming aside, I did enjoy reading this paper. The public commenters have already asked important questions about methodology and related work on neural programming that the authors have addressed in comments. I look forward to these being incorporated in the revised pdf. A big part of the paper is about generating the datasets, and I therefore sympathise with the comment about requesting either a dataset release or the generating code. I see no obvious ethical concerns in this case, and the authors have already kindly offered to do this. This is a commendable and important service to our community and for this alone I would be inclined to vote for acceptance at ICLR. The paper is clear and well written. However (i) it would be good to show several examples of input and output sequences (as done already in this website) and (ii) the Experiments section needs work. I'll expand on this next. The seq2seq transformer with 8 heads, 6 layers and dimensionality 512 is a sensible choice. The authors should however explain why they expect this architecture to be able to map the sequences they adopt. That is, it is well known that a deep neural network is just a skeleton for an algorithm. By estimating the parameters, we are coming up with (fitting) the algorithm for the given datasets. What is the resulting algorithm? Why are 6 layers enough? Here some visualization would be helpful. See for example https://arxiv.org/pdf/1904.02679.pdf and https://arxiv.org/pdf/1906.04341.pdf For greater understanding of the problem, it may be useful to also try sparse transformers eg https://arxiv.org/abs/1805.08241 Beam search is a crucial component of the current solution. However, the authors simply cite Koehn 2004 for this. First, that work used language models to compute probabilities for beam search. I assume no language models are used in this case. What I'm getting to is that there are not enough details about the beam search in this paper. The authors should include pseudocode for the beam search and give a few examples. The paper (even better thesis) of Koehn is a good template for what should be included. This is important and should be explained. For Mathematica, it would be useful to state it does other things and has not been optimized for the two tasks addressed in this paper only. It would also be useful, now that you have more time, to run it for a week or two and get answers not only for 30s but also for 60s. How often does it take longer than 30s? How do you score it then? Please do include train and test curves. This would be helpful too. I will of course consider revising my score once the paper is updated. Thanks for constructing this dataset and writing this paper. It is very interesting and promising. ", "rating": "6: Weak Accept", "reply_text": "Thank you very much for your review and comments . We address your questions in order . PART 1/2 ===== Hype / Overclaiming We had no control over the discussions on the Internet prior to the review , and took no part in them , nor did we encourage them by communicating on our work or publishing on arXiv before review . This is a side effect of the open review process , together with the very interesting adversarial discussions we just had . In the paper , we tried to be prudent and not overclaim , by explaining that we work with a dataset generated by our model and use standard differential equation solvers that may work better on different sets of equations . We also mention , at the end of paragraph 4.5 \u201d When comparing with Matlab and Mathematica , we work from a data set generated for our model and use their standard differential equation solvers . Different sets of equations , and advanced techniques for solving them ( e.g.transforming them before introducing them in the solver ) would probably result in smaller performance gaps. \u201d ===== On sqrt ( -2 ) and log ( 0 ) , and the \u201c cleaning \u201d of some formulas The main reason why we eliminated such constants ( and very large values such as exp ( exp ( exp ( 5 ) ) ) is that they made life difficult for SymPy and NumPy , which we use to test and verify our results . They tended to cause unwanted ( and sometimes very difficult to catch ) exceptions , and even server crashes . Since our model works on symbols ; and does not care for actual numeric values , these constants ( as opposed to functions of variable x ) had no impact on actual integration or equation solving , they could have been replaced by anything . Operating in the complex domain is also possible . We took the decision to discard complex equations arbitrarily , but we could easily add them back . However , on a deeper level , and in the specific case of symbolic integration , we do not think that adding infinity or operating in the complex domain would be an improvement . The objective of symbolic integration consists in finding a solution to an indefinite integral without adding new symbols , and in the smallest possible algebraic extension of the original field ( here , an extension of Q since our constants are integers ) . We believe this is true for other tasks of symbolic mathematics . ===== On the two examples you provide `` These results are surprising given the incapacity of neural models to perform simpler tasks like addition and multiplication '' - > The difficulty to perform such calculations with neural networks is documented ( see the reference in paragraph 2 of our introduction ) . We actually tested transformers on such problems ( this was the original objective of our project ) , and were surprised to find that integration , a much more difficult task from a human point of view , seemed much easier for our model . We will clarify this . `` This suggest ( sic ) that some deeper understanding of mathematics has been achieved by the model . '' - > We removed this sentence from the paper , but we consider that recovering equivalent expressions ( i.e.alternative solutions of the problems ) through beam search , is a very important finding . As shown in Table 4 ( Table 6 in the updated version of the paper ) , the model consistently recovers correct solutions that have very different representations . This is very surprising , and does suggest something important is at work . We have no explanation to offer so far , but we believe it is a very important observation . ===== Code / datasets Yes , as promised , we will make our code and datasets public after the review process . ===== Network architecture We decided to consider the same transformer configuration as Vaswani et al. , i.e.6 layers and a dimensionality of 512 , with 8 heads . We tried to increase the number of layers , the number of heads , dimensionality , but did not observe significant improvements with larger models . On the other hand , we found that very small models ( c.f.our response to Forough ) still perform well on function integration , even when they are only composed of 2 layers of dimension 128 . Our observation was that transformers perform well on the considered tasks , and are also very robust to the choice of hyper-parameters , unlike what people observed in machine translation . Machine translation systems typically benefit from advanced learning rate schedulers ( either with linear or cosine decay , with many hyper-parameters ) . These schedulers did not bring any improvements in our case , and we simply use a constant learning rate of 10^ ( -4 ) ."}, {"review_id": "S1eZYeHFDS-2", "review_text": "The authors use a Transformer neural network, originally architected for the purpose of language translation, to solve nontrivial mathematical equations, specifically integrals, first-order differential equations, and second-order differential equations. They also developed rigorous methods for sampling from a large space of relevant equations, which is critical for assembling the type of dataset needed for training such a data-intensive model. Both the philosophical question posed by the paper (i.e. can neural networks designed for natural language sequence-to-sequence mappings be meaningfully applied to symbolic mathematics) and the resulting answer (i.e. yes, and such a neural network outperforms SOTA commercially-available systems) are interested in their own right, and together make a strong case for paper acceptance. Details appearing in the OpenReview comments which should be explicitly specified in the paper before publication: 1) How large was the generated training set (40M), and how does this compare to the space of all equations under consideration (1e34). 2) The authors employ beam search in a non-standard manner, where they check for appearance of the equation solution among all of the generated candidates, rather than selecting the top-1. The fact that the reported accuracy with width-10 and width-50 beam searches are in effect measuring top-10 and top-50 accuracy should be clearly stated. ", "rating": "8: Accept", "reply_text": "Thank you very much for your review and your comments . We address them in the updated version of the paper . In particular , we added a new table ( Table 1 of the updated version ) with statistics about the considered training sets , and the length of expressions . We also added a figure ( Figure 1 ) that represents the number of trees and expressions for different numbers of operators and leaves . At the end of Section 4.3 , we clarified our use of beam search , and explained how it differs from what people usually do in machine translation ( i.e.only returning the hypothesis of the beam with the highest score ) ."}], "0": {"review_id": "S1eZYeHFDS-0", "review_text": "In this paper, the authors propose a method for generating two types of symbolic mathematics problems, integration and differential equations, and their solutions. The purpose of the method is to generate datasets for training transformer neural networks that solve integration and differential-equation problems. The authors note that while solving these problems is very difficult, generating solutions first and corresponding problems next automatically is feasible, and their method realizes this observation. The authors report that transformer networks trained on the synthetically generated solution-problem pairs outperform existing symbolic solvers for integration and differential equation. Here are the reasons that I like the paper. The observation that solving a symbolic mathematics problem is often a pattern matching process is interesting. It is surprising to know that a transformer network designed to translated the generating problem-solution pairs backward (from problem to solution) works better than the solvers in Mathematica and Matlab. Also, I like nice cute tricks used in the authors' method for generating solution-problem pairs, such as the syntactic condition on a possible position of some constant. The paper is overall clearly written. I presume that when the authors compare their learned solvers with Mathematica and Matlab, they used a dataset generated by their method. I feel that this comparison is somewhat unfair, although it still impresses me that even for this dataset, the authors' solvers beat Mathematica and Matlab. I suggest to try at least one more experiment on a dataset not generated by the authors' method (integration and differential equation problems from math textbooks or other sources) if possible. * p3: Why is it important to have a generator that produces the four expression trees in p3 with equal or almost equal probabilities? Do you have any semi-formal or informal justification that the distribution of such a generator better matches the kind of expressions arising in the real world? * p4: f(x)/x)) ===> f(x)/x) * \"If this equation can be solved in c1\", p5: How realistic is this assumption? * p5: 1/2 e^x(...) ===> 0 = 1/2 e^x(...) * p5: If you have a thought or an observation on the impact of each of the data-cleaning steps in Section 3.4, I suggest you to share this in the paper. * p6: Why did you remove expressions with more than 512 tokens? * p6: compare to ===> compared to * p7: Would you put the reminder of the size of the training set in Section 4.4? It only mentions that of the test set currently. * p8: 1-(4x^2 ===> (1-(4x^2", "rating": "8: Accept", "reply_text": "Thank you very much for your review and comments . We address them in turn : ==== \u201c I presume that when the authors compare their learned solvers with Mathematica and Matlab , they used a dataset generated by their method. \u201d This is correct : we test our model and Mathematica on a held out sample from the generated sample ( and mention at the end of paragraph 4.5 that this creates a favorable situation for our model ) . Since the submission , we tried to experiment on integration for samples generated with different methods . More precisely , we generated \u201c forward \u201d samples of random functions that SymPy knows how to integrate . This gives a good approximation of what Computer Algebras are good for . Examination of the samples shows that in backward samples , derivatives tend to be longer than primitives , whereas the opposite holds for forward samples . Unsurprisingly , a model trained on backward samples performs poorly on forward examples . But a forward-trained model achieves the same performance on forward data as a backward-trained model on backward data : this suggests that the performance is linked to data generation , and we actually observe that a model trained on the combination of backward and forward data achieves a good performance on all samples . These new results are in the updated version of the paper . ===== p3 : Why is it important to have a generator that produces the four expression trees in p3 with equal or almost equal probabilities ? Do you have any semi-formal or informal justification that the distribution of such a generator better matches the kind of expressions arising in the real world ? We have no idea of the actual distribution of expressions \u201c in the wild \u201d ( provided this has a meaning ) . Since we have no reason to consider an expression more relevant than another , we decided to sample all of them with the same probability . Since there is a one to one mapping from expressions to decorated trees ( thanks to the prefix notation ) , we want to sample them uniformly , which means that all trees have to be sampled with the same probability . ===== `` If this equation can be solved in c1 '' , p5 : How realistic is this assumption ? Formally , the function F ( x , y , c1 ) is the equation of the level curves of the function f , which we originally generated . The equation dF/dx = 0 corresponds to the gradient of F along x . Solving this equation in c1 amounts to finding an equation of the level curves of the gradient . In practice , we found that we can solve in c1 about 50 % of the time . If we can not , we simply discard the initial expression . ===== p5 : If you have a thought or an observation on the impact of each of the data-cleaning steps in Section 3.4 , I suggest you to share this in the paper . Equation simplification , like the use of small integer coefficients in expressions , limits the need for our model to carry out ( and learn ) arithmetic simplification in addition to the main task ( integration of equation solving ) . This will reduce , or rather , bias , the generated expressions , by reducing the number of constants ( i.e.leaves different from \u2018 x \u2019 in the expression tree ) , and eliminating certain sequences of operators ( exp ( log ( ) ) , sin ( arcsin ( ) ) , and so on . We consider it as a way to improve learning by focusing on the task at hand . Coefficient simplification is a trick of our method to generate differential equations . This step makes the elimination of constants c1 and c2 easier , but the generated equations and solutions remain the same . Invalid expression removal allows us to avoid exceptions when evaluating the functions . Since they only concern constants , they have very little impact on the problem . An alternative would be to replace the invalid sub-expressions by valid ones ( see also our reply to reviewer 1 on this point ) . ===== p6 : Why did you remove expressions with more than 512 tokens ? We found that with very large expressions , the transformer model is subject to out of memory errors , which requires to use a smaller batch size at training time . To keep a large batch size ( and to make training faster ) , we set this limit of 512 tokens . Overall , this is only discards a tiny fraction of the generated expressions . ==== p7 : Would you put the reminder of the size of the training set in Section 4.4 ? It only mentions that of the test set currently . Yes , we added a new Table ( table 1 in the updated version of the paper ) with statistics about our datasets . Thank you for the suggestion ."}, "1": {"review_id": "S1eZYeHFDS-1", "review_text": "It is rather interesting for a humble academic to review this paper. It already has a discussion, which I find very valuable, and many tweets and social media exposure and endorsements. It is onerous to review in this setting. The paper makes a valuable contribution. The adversarial discussions in this website and the unhelpful hype can in this case be addressed to some extent by the authors. I will start with discussing this. Clearly, the title is too broad. This is not deep learning for symbolic mathematics. In no way does this paper address the essence of what is understood by \"symbolic mathematics\". What the authors address is mapping sequences of discrete quantities to other sequences of discrete quantities. The sequences in this paper correspond to function-integral i/o sequences, and 1st/2nd ODEs-function i/o sequences. I will leave it to the authors to come up with a more informative title, but something like deep learning or transformers for symbolic (1d) integration and simple ODEs with be far more accurate. To hammer this point, note that Section 3 discusses removing \"invalid\" expressions: log(0) or sqrt(-2). However, it is the manipulation of infinity and imaginary numbers that could be considered to be one of the greatest achievements of symbolic mathematics over the last couple of hundred years. It is reasonable to expect neural nets to do this one day, because humans can, but this should come with results. It's too early to make the claim in the paper title. Sentences such as \"This suggest (sic) that some deeper understanding of mathematics has been achieved by the model.\" and \"These results are surprising given the incapacity of neural models to perform simpler tasks ...\" are speculative, potentially inaccurate and likely to increase hype. This hype is not needed. Hype and over-claiming aside, I did enjoy reading this paper. The public commenters have already asked important questions about methodology and related work on neural programming that the authors have addressed in comments. I look forward to these being incorporated in the revised pdf. A big part of the paper is about generating the datasets, and I therefore sympathise with the comment about requesting either a dataset release or the generating code. I see no obvious ethical concerns in this case, and the authors have already kindly offered to do this. This is a commendable and important service to our community and for this alone I would be inclined to vote for acceptance at ICLR. The paper is clear and well written. However (i) it would be good to show several examples of input and output sequences (as done already in this website) and (ii) the Experiments section needs work. I'll expand on this next. The seq2seq transformer with 8 heads, 6 layers and dimensionality 512 is a sensible choice. The authors should however explain why they expect this architecture to be able to map the sequences they adopt. That is, it is well known that a deep neural network is just a skeleton for an algorithm. By estimating the parameters, we are coming up with (fitting) the algorithm for the given datasets. What is the resulting algorithm? Why are 6 layers enough? Here some visualization would be helpful. See for example https://arxiv.org/pdf/1904.02679.pdf and https://arxiv.org/pdf/1906.04341.pdf For greater understanding of the problem, it may be useful to also try sparse transformers eg https://arxiv.org/abs/1805.08241 Beam search is a crucial component of the current solution. However, the authors simply cite Koehn 2004 for this. First, that work used language models to compute probabilities for beam search. I assume no language models are used in this case. What I'm getting to is that there are not enough details about the beam search in this paper. The authors should include pseudocode for the beam search and give a few examples. The paper (even better thesis) of Koehn is a good template for what should be included. This is important and should be explained. For Mathematica, it would be useful to state it does other things and has not been optimized for the two tasks addressed in this paper only. It would also be useful, now that you have more time, to run it for a week or two and get answers not only for 30s but also for 60s. How often does it take longer than 30s? How do you score it then? Please do include train and test curves. This would be helpful too. I will of course consider revising my score once the paper is updated. Thanks for constructing this dataset and writing this paper. It is very interesting and promising. ", "rating": "6: Weak Accept", "reply_text": "Thank you very much for your review and comments . We address your questions in order . PART 1/2 ===== Hype / Overclaiming We had no control over the discussions on the Internet prior to the review , and took no part in them , nor did we encourage them by communicating on our work or publishing on arXiv before review . This is a side effect of the open review process , together with the very interesting adversarial discussions we just had . In the paper , we tried to be prudent and not overclaim , by explaining that we work with a dataset generated by our model and use standard differential equation solvers that may work better on different sets of equations . We also mention , at the end of paragraph 4.5 \u201d When comparing with Matlab and Mathematica , we work from a data set generated for our model and use their standard differential equation solvers . Different sets of equations , and advanced techniques for solving them ( e.g.transforming them before introducing them in the solver ) would probably result in smaller performance gaps. \u201d ===== On sqrt ( -2 ) and log ( 0 ) , and the \u201c cleaning \u201d of some formulas The main reason why we eliminated such constants ( and very large values such as exp ( exp ( exp ( 5 ) ) ) is that they made life difficult for SymPy and NumPy , which we use to test and verify our results . They tended to cause unwanted ( and sometimes very difficult to catch ) exceptions , and even server crashes . Since our model works on symbols ; and does not care for actual numeric values , these constants ( as opposed to functions of variable x ) had no impact on actual integration or equation solving , they could have been replaced by anything . Operating in the complex domain is also possible . We took the decision to discard complex equations arbitrarily , but we could easily add them back . However , on a deeper level , and in the specific case of symbolic integration , we do not think that adding infinity or operating in the complex domain would be an improvement . The objective of symbolic integration consists in finding a solution to an indefinite integral without adding new symbols , and in the smallest possible algebraic extension of the original field ( here , an extension of Q since our constants are integers ) . We believe this is true for other tasks of symbolic mathematics . ===== On the two examples you provide `` These results are surprising given the incapacity of neural models to perform simpler tasks like addition and multiplication '' - > The difficulty to perform such calculations with neural networks is documented ( see the reference in paragraph 2 of our introduction ) . We actually tested transformers on such problems ( this was the original objective of our project ) , and were surprised to find that integration , a much more difficult task from a human point of view , seemed much easier for our model . We will clarify this . `` This suggest ( sic ) that some deeper understanding of mathematics has been achieved by the model . '' - > We removed this sentence from the paper , but we consider that recovering equivalent expressions ( i.e.alternative solutions of the problems ) through beam search , is a very important finding . As shown in Table 4 ( Table 6 in the updated version of the paper ) , the model consistently recovers correct solutions that have very different representations . This is very surprising , and does suggest something important is at work . We have no explanation to offer so far , but we believe it is a very important observation . ===== Code / datasets Yes , as promised , we will make our code and datasets public after the review process . ===== Network architecture We decided to consider the same transformer configuration as Vaswani et al. , i.e.6 layers and a dimensionality of 512 , with 8 heads . We tried to increase the number of layers , the number of heads , dimensionality , but did not observe significant improvements with larger models . On the other hand , we found that very small models ( c.f.our response to Forough ) still perform well on function integration , even when they are only composed of 2 layers of dimension 128 . Our observation was that transformers perform well on the considered tasks , and are also very robust to the choice of hyper-parameters , unlike what people observed in machine translation . Machine translation systems typically benefit from advanced learning rate schedulers ( either with linear or cosine decay , with many hyper-parameters ) . These schedulers did not bring any improvements in our case , and we simply use a constant learning rate of 10^ ( -4 ) ."}, "2": {"review_id": "S1eZYeHFDS-2", "review_text": "The authors use a Transformer neural network, originally architected for the purpose of language translation, to solve nontrivial mathematical equations, specifically integrals, first-order differential equations, and second-order differential equations. They also developed rigorous methods for sampling from a large space of relevant equations, which is critical for assembling the type of dataset needed for training such a data-intensive model. Both the philosophical question posed by the paper (i.e. can neural networks designed for natural language sequence-to-sequence mappings be meaningfully applied to symbolic mathematics) and the resulting answer (i.e. yes, and such a neural network outperforms SOTA commercially-available systems) are interested in their own right, and together make a strong case for paper acceptance. Details appearing in the OpenReview comments which should be explicitly specified in the paper before publication: 1) How large was the generated training set (40M), and how does this compare to the space of all equations under consideration (1e34). 2) The authors employ beam search in a non-standard manner, where they check for appearance of the equation solution among all of the generated candidates, rather than selecting the top-1. The fact that the reported accuracy with width-10 and width-50 beam searches are in effect measuring top-10 and top-50 accuracy should be clearly stated. ", "rating": "8: Accept", "reply_text": "Thank you very much for your review and your comments . We address them in the updated version of the paper . In particular , we added a new table ( Table 1 of the updated version ) with statistics about the considered training sets , and the length of expressions . We also added a figure ( Figure 1 ) that represents the number of trees and expressions for different numbers of operators and leaves . At the end of Section 4.3 , we clarified our use of beam search , and explained how it differs from what people usually do in machine translation ( i.e.only returning the hypothesis of the beam with the highest score ) ."}}