{"year": "2017", "forum": "Bkfwyw5xg", "title": "Investigating Different Context Types and Representations for Learning Word Embeddings", "decision": "Reject", "meta_review": "Reviewers agree that the findings are not clear enough to be of interest, though the effort to do a controlled study is appreciated.", "reviews": [{"review_id": "Bkfwyw5xg-0", "review_text": "This paper analyzes dependency trees vs standard window contexts for word vector learning. While that's a good goal I believe the paper falls short of a thorough analysis of the subject matter. It does not analyze Glove like objective functions which often work better than the algorithms used here. It doesn't compare in absolute terms to other published vectors or models. It fails to gain any particularly interesting insights that will modify other people's work. It fails to push the state of the art or make available new resources for people. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , A new version of this paper is uploaded and we are exited to share the results with you . Please see our recent comment for more information . Thanks ."}, {"review_id": "Bkfwyw5xg-1", "review_text": "This paper evaluates how different context types affect the quality of word embeddings on a plethora of benchmarks. I am ambivalent about this paper. On one hand, it continues an important line of work in decoupling various parameters from the embedding algorithms (this time focusing on context); on the other hand, I am not sure I understand what the conclusion from these experiments is. There does not appear to be a significant and consistent advantage to any one context type. Why is this? Are the benchmarks sensitive enough to detect these differences, if they exist? While I am OK with this paper being accepted, I would rather see a more elaborate version of it, which tries to answer these more fundamental questions. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear reviewer , A new version of this paper is uploaded and we are exited to share the results with you . Please see our recent comment for more information . Thanks ."}, {"review_id": "Bkfwyw5xg-2", "review_text": "This paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like CBOW or Skip-Gram, with a focus one the issue of bound (word+dependency type, 'She-nsubj') vs. unbound (word alone, 'She') representations for context at training time. The empirical results are extremely mixed, and no specific novel method consistently outperforms existing methods. The paper is systematic and I have no major concerns about its soundness. However, I don't think that this paper is of broad interest to the ICLR community. The paper is focused on a fairly narrow detail of representation learning that is entirely specific to NLP, and its results are primarily negative. A short paper at an ACL conference would be a more reasonable target.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , A new version of this paper is uploaded and we are exited to share the results with you . Please see our recent comment for more information . Thanks ."}], "0": {"review_id": "Bkfwyw5xg-0", "review_text": "This paper analyzes dependency trees vs standard window contexts for word vector learning. While that's a good goal I believe the paper falls short of a thorough analysis of the subject matter. It does not analyze Glove like objective functions which often work better than the algorithms used here. It doesn't compare in absolute terms to other published vectors or models. It fails to gain any particularly interesting insights that will modify other people's work. It fails to push the state of the art or make available new resources for people. ", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , A new version of this paper is uploaded and we are exited to share the results with you . Please see our recent comment for more information . Thanks ."}, "1": {"review_id": "Bkfwyw5xg-1", "review_text": "This paper evaluates how different context types affect the quality of word embeddings on a plethora of benchmarks. I am ambivalent about this paper. On one hand, it continues an important line of work in decoupling various parameters from the embedding algorithms (this time focusing on context); on the other hand, I am not sure I understand what the conclusion from these experiments is. There does not appear to be a significant and consistent advantage to any one context type. Why is this? Are the benchmarks sensitive enough to detect these differences, if they exist? While I am OK with this paper being accepted, I would rather see a more elaborate version of it, which tries to answer these more fundamental questions. ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear reviewer , A new version of this paper is uploaded and we are exited to share the results with you . Please see our recent comment for more information . Thanks ."}, "2": {"review_id": "Bkfwyw5xg-2", "review_text": "This paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like CBOW or Skip-Gram, with a focus one the issue of bound (word+dependency type, 'She-nsubj') vs. unbound (word alone, 'She') representations for context at training time. The empirical results are extremely mixed, and no specific novel method consistently outperforms existing methods. The paper is systematic and I have no major concerns about its soundness. However, I don't think that this paper is of broad interest to the ICLR community. The paper is focused on a fairly narrow detail of representation learning that is entirely specific to NLP, and its results are primarily negative. A short paper at an ACL conference would be a more reasonable target.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear reviewer , A new version of this paper is uploaded and we are exited to share the results with you . Please see our recent comment for more information . Thanks ."}}