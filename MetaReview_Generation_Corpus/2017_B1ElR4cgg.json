{"year": "2017", "forum": "B1ElR4cgg", "title": "Adversarially Learned Inference", "decision": "Accept (Poster)", "meta_review": "The reviewers were positive about this paper and agree that it will make a contribution to the community.", "reviews": [{"review_id": "B1ElR4cgg-0", "review_text": "After reading the rebuttal, I decided to increase my score. I think ALI somehow stabilizes the GAN training as demonstrated in Fig. 8 and learns a reasonable inference network. --------------- Initial Review: This paper proposes a new method for learning an inference network in the GAN framework. ALI's objective is to match the joint distribution of hidden and visible units imposed by an encoder and decoder network. ALI is trained on multiple datasets, and it seems to have a good reconstruction even though it does not have an explicit reconstruction term in the cost function. This shows it is learning a decent inference network for GAN. There are currently many ways to learn an inference network for GANs: One can learn an inference network after training the GAN by sampling from the GAN and learning a separate network to map X to Z. There is also the infoGAN approach (not cited) which trains the inference network at the same time with the generative path. I think this paper should have an extensive comparison with these other methods and have a discussion for why ALI's inference network is superior to previous works. Since ALI's inference network is stochastic, it would be great if different reconstructions of a same image is included. I believe the inference network of the BiGAN paper is deterministic which is the main difference with this work. So maybe it is worth highlighting this difference. The quality of samples is very good, but there is no quantitative experiment to compare ALI's samples with other GAN variants. So I am not sure if learning an inference network has contributed to better generative samples. Maybe including an inception score for comparison can help. There are two sets of semi-supervised results: The first one concatenate the hidden layers of the inference network and uses an L2-SVM afterwards. Ideally, concatenating feature maps is not the best way for semi-supervised learning and one would want to train the semi-supervised path at the same time with the generative path. It would have been much more interesting if part of the hidden code was a categorical distribution and another part of it was a continuous distribution like Gaussian, and the inference network on the categorical latent variable was used directly for classification (like semi-supervised VAE). In this case, the inference network would be trained at the same time with the generative path. Also if the authors can show that ALI can disentangle factors of variations with a discrete latent variable like infoGAN, it will significantly improve the quality of the paper. The second semi-supervised learning results show that ALI can match the state-of-the-art. But my impression is that the significant gain is mainly coming from the adaptation of Salimans et al. (2016) in which the discriminator is used for classification. It is unclear to me why learning an inference network help the discriminator do a better job in classification. How do we know the proposed method is improving the stability of the GAN? My understanding is that one of the main points of learning an inference network is to learn a mapping from the image to the high-level features such as class labels. So it would have been more interesting if the inference path was directly used for semi-supervised learning as I explained above.", "rating": "7: Good paper, accept", "reply_text": "We thank you for you feedback . REVIEWER POINT \u201c I think this paper should have an extensive comparison with these other methods and have a discussion for why ALI 's inference network is superior to previous works. \u201d RESPONSE The reviewer raises an important and salient point that , while we have shown that ALI does learn to do inference reasonably well , the paper doesn \u2019 t do enough to directly compare with alternative ways of doing feedforward inference in a GAN setting . To address these concerns , we will shortly add two new sections to the paper : ( 1 ) a review of alternative approaches and ( 2 ) a new experiment to highlight the role of the inference network during learning . These additions are summarized below . Here is a list of alternative approaches and why they may or may not be fit for comparison with ALI : * Learning the inverse mapping from GAN samples : This corresponds to learning an encoder to reconstruct Z , i.e.encode ( decode ( Z ~ p ( Z ) ) ) ~= Z . We are not aware of any work that reports results for this approach . Could you point out to such work if it exists ? * InfoGAN : While InfoGAN should be cited as related work , InfoGAN actually does not do inference , it only estimates the discrete latent code which describes specific aspects of the image . This is why the InfoGAN paper doesn \u2019 t show any reconstructions , rather it shows generated samples where they vary the latent code . Additionally , InfoGAN uses a fixed reconstruction cost for the latent code C and requires a tractable approximate posterior , q ( C|X ) , that can be sampled from and evaluated . ALI only requires that inference networks can be sampled from , allowing it to represent arbitrarily complex posterior distributions . Combining InfoGAN and ALI could be an exciting area for future work . * Post-hoc learned inference : As verification that learning inference jointly with generation is beneficial , one can first train a GAN and then freeze the decoder and learn the encoder using the procedure proposed by ALI . In this setting , the encoder and the decoder can not interact together during training and the encoder must work with whatever the decoder has learned during GAN training . To address this point we performed an experiment on a toy dataset for which q ( X ) is a 2D gaussian mixture with 25 mixture components laid out on a grid . The covariance matrices and centroids have been chosen such that the distribution exhibits lots of modes separated by large low-probability regions , which makes it a decently hard task despite the 2D nature of the dataset . We trained ALI and GAN on 100,000 q ( X ) samples . The decoder and discriminator architectures are identical between ALI and GAN . Each model was trained 10 times using Adam with random learning rate and beta_1 values , and the weights were initialized by drawing from a gaussian distribution with a random standard deviation . We measured the extent to which the trained models covered all 25 modes by drawing 10,000 samples from their p ( X ) distribution and assigning each sample to a q ( X ) mixture component according to the mixture responsibilities . We defined a dropped mode as one that wasn \u2019 t assigned to * any * sample ( which is a generous definition ) . Using this definition , we found that ALI models covered 13.4 \u00b1 5.8 modes on average ( min : 8 , max : 25 ) while GAN models covered 10.4 \u00b1 9.2 modes on average ( min : 1 , max : 22 ) . We then selected the best-covering ALI and GAN models , and the GAN model was augmented with the following inference mechanisms : * Learned inverse mapping * Post-hoc learned inference The encoders learned for GAN inference have the same architecture as ALI \u2019 s encoder . We then compared each model \u2019 s inference capabilities by reconstructing 10,000 held-out samples from q ( X ) . A figure summarizing the experiment can be found at https : //raw.githubusercontent.com/IshmaelBelghazi/ALI/master/paper/mixture_plot.png . The three columns correspond to the three different strategies for learning inference : 1 . ALI ( our proposed strategy ) . 2.Learning an inverse mapping from GAN samples . 3.Post-hoc learned inference The five rows correspond to : 1 . X ~ q ( X ) samples , i.e.test set examples , colour-coded by mixture component . They 're the same for all three columns . 2.Z_hat ~ q ( Z | X ) samples , i.e.the latent codes , also colour-coded . 3.X_hat ~ p ( X | Z = Z_hat ) samples , i.e.the reconstructions , also colour-coded . 4.Z ~ p ( Z ) samples , i.e.prior samples . They 're the same for all three columns . 5.X_tilde ~ p ( X | Z ) samples , i.e.generator samples . Here is what we observe : * The ALI encoder models a marginal distribution q ( Z ) that matches p ( Z ) fairly well ( row 2 , column 1 ) . The learned representation does a decent job at clustering and organizing the different mixture components . * The GAN generator ( row 5 , columns 2-3 ) has more trouble reaching all the modes than the ALI generator ( row 5 , column 1 ) , even over 10 runs of hyperparameter search . * Learning an inverse mapping from GAN samples does not work very well : the encoder has trouble covering the prior marginally and the way it clusters mixture components is not very well organized ( row 2 , column 2 ) . * Learning inference post-hoc does n't work as well as training the encoder and the decoder jointly . As had been discussed above , it appears that adversarial training benefits from learning inference at training time in terms of mode coverage . This also negatively impacts how the latent space is organized ( row 2 , column 3 ) . However , it appears to be better at matching q ( Z ) and p ( Z ) than when inference is learned through inverse mapping from GAN samples . To summarize , this experiment provides evidence that adversarial training benefits from learning an inference mechanism jointly with the decoder . Furthermore , it shows that our proposed approach for learning inference in an adversarial setting is superior to the other approaches investigated . We will update the manuscript shortly to incorporate these additional results and cite the appropriate relevant work . REVIEWER POINT \u201c Since ALI 's inference network is stochastic , it would be great if different reconstructions of a same image is included . I believe the inference network of the BiGAN paper is deterministic which is the main difference with this work . So maybe it is worth highlighting this difference. \u201d RESPONSE Our experience is that the added stochasticity does not make much of a difference : at the end of training , very little noise ends up being injected at the encoder \u2019 s output . This falls in line with the invertibility results derived by Donahue et al . ( 2016 ) .We agree that left unexplained , this difference may confuse readers and we will update the manuscript to address this question . REVIEWER POINT \u201c The quality of samples is very good , but there is no quantitative experiment to compare ALI 's samples with other GAN variants . So I am not sure if learning an inference network has contributed to better generative samples . Maybe including an inception score for comparison can help. \u201d RESPONSE We do not claim that learning an inference network contributes to better generative samples , simply that doing so does not come at the expense of sample quality . However , as explained above , experiments on a toy dataset suggest that ALI is better at mode coverage than GAN . Regarding the use of the Inception score , we are hesitant to use it , as Odena et al . ( 2016 ) [ 1 ] found that \u201c [ the ] Inception accuracy can not measure whether a model has collapsed . A model that simply memorized one example from each ImageNet class would do very well by this metric. \u201d REVIEWER POINT \u201c There are two sets of semi-supervised results [ ... ] \u201d RESPONSE The point which we try to make with the semi-supervised results is that : * In the first method , one can train a shallow classifier using learned features from an unsupervised model . We used the * exact same * procedure as DCGAN to build an L2-SVM on top of existing features , with the exception that the features were taken from the inference network \u2019 s high-level representation as opposed to the discriminator . In this case ALI outperformed the results reported in the DCGAN paper , which suggests that for this procedure the inference network buys us something over the discriminator . To ensure that the comparison is fair , we are currently running an experiment in which DCGAN and ALI share the same architecture . We will update the manuscript when it is complete . * In the second method , one co-trains the discriminator for label classification . With this procedure ALI matches the more recent \u201c Improved methods for training GANs \u201d results while using a simpler architecture ( no feature matching ) . In this setting , the inference network * is * used , as it provides one of the two inputs which the discriminator uses to produce its prediction . While an inference network on categorical variables like in semi-supervised VAEs does sound elegant and straightforward , it is not directly applicable to ALI . Like GANs , ALI requires that the conditional distributions p ( x | z ) and q ( z | x ) can be sampled from in a way that allows gradient backpropagation , which can not be achieved in a straightforward manner using discrete random variables . [ 1 ] Odena , A. , Olah , C. , & Shlens , J . ( 2016 ) .Conditional Image Synthesis With Auxiliary Classifier GANs . arXiv preprint arXiv:1610.09585 ."}, {"review_id": "B1ElR4cgg-1", "review_text": "This is a parallel work with BiGAN. The idea is using auto encoder to provide extra information for discriminator. This approach seems is promising from reported result.", "rating": "7: Good paper, accept", "reply_text": "We thank you for your review ."}, {"review_id": "B1ElR4cgg-2", "review_text": "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,z is then modeled using a joint generator model p(x,z)=p(z)p(x|z). Both q and p are then trained by trying to fool a discriminator. This constitutes a worthwhile extension of GANs: giving GANs the ability to do inference opens up many applications that could previously only be addressed by e.g. VAEs. The results are very promising. The CIFAR-10 samples are the best I've seen so far (not counting methods that use class labels). Matching the semi-supervised results from Salimans et al. without feature matching also indicates the proposed method may improve the stability of training GANs.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank you for your feedback ."}], "0": {"review_id": "B1ElR4cgg-0", "review_text": "After reading the rebuttal, I decided to increase my score. I think ALI somehow stabilizes the GAN training as demonstrated in Fig. 8 and learns a reasonable inference network. --------------- Initial Review: This paper proposes a new method for learning an inference network in the GAN framework. ALI's objective is to match the joint distribution of hidden and visible units imposed by an encoder and decoder network. ALI is trained on multiple datasets, and it seems to have a good reconstruction even though it does not have an explicit reconstruction term in the cost function. This shows it is learning a decent inference network for GAN. There are currently many ways to learn an inference network for GANs: One can learn an inference network after training the GAN by sampling from the GAN and learning a separate network to map X to Z. There is also the infoGAN approach (not cited) which trains the inference network at the same time with the generative path. I think this paper should have an extensive comparison with these other methods and have a discussion for why ALI's inference network is superior to previous works. Since ALI's inference network is stochastic, it would be great if different reconstructions of a same image is included. I believe the inference network of the BiGAN paper is deterministic which is the main difference with this work. So maybe it is worth highlighting this difference. The quality of samples is very good, but there is no quantitative experiment to compare ALI's samples with other GAN variants. So I am not sure if learning an inference network has contributed to better generative samples. Maybe including an inception score for comparison can help. There are two sets of semi-supervised results: The first one concatenate the hidden layers of the inference network and uses an L2-SVM afterwards. Ideally, concatenating feature maps is not the best way for semi-supervised learning and one would want to train the semi-supervised path at the same time with the generative path. It would have been much more interesting if part of the hidden code was a categorical distribution and another part of it was a continuous distribution like Gaussian, and the inference network on the categorical latent variable was used directly for classification (like semi-supervised VAE). In this case, the inference network would be trained at the same time with the generative path. Also if the authors can show that ALI can disentangle factors of variations with a discrete latent variable like infoGAN, it will significantly improve the quality of the paper. The second semi-supervised learning results show that ALI can match the state-of-the-art. But my impression is that the significant gain is mainly coming from the adaptation of Salimans et al. (2016) in which the discriminator is used for classification. It is unclear to me why learning an inference network help the discriminator do a better job in classification. How do we know the proposed method is improving the stability of the GAN? My understanding is that one of the main points of learning an inference network is to learn a mapping from the image to the high-level features such as class labels. So it would have been more interesting if the inference path was directly used for semi-supervised learning as I explained above.", "rating": "7: Good paper, accept", "reply_text": "We thank you for you feedback . REVIEWER POINT \u201c I think this paper should have an extensive comparison with these other methods and have a discussion for why ALI 's inference network is superior to previous works. \u201d RESPONSE The reviewer raises an important and salient point that , while we have shown that ALI does learn to do inference reasonably well , the paper doesn \u2019 t do enough to directly compare with alternative ways of doing feedforward inference in a GAN setting . To address these concerns , we will shortly add two new sections to the paper : ( 1 ) a review of alternative approaches and ( 2 ) a new experiment to highlight the role of the inference network during learning . These additions are summarized below . Here is a list of alternative approaches and why they may or may not be fit for comparison with ALI : * Learning the inverse mapping from GAN samples : This corresponds to learning an encoder to reconstruct Z , i.e.encode ( decode ( Z ~ p ( Z ) ) ) ~= Z . We are not aware of any work that reports results for this approach . Could you point out to such work if it exists ? * InfoGAN : While InfoGAN should be cited as related work , InfoGAN actually does not do inference , it only estimates the discrete latent code which describes specific aspects of the image . This is why the InfoGAN paper doesn \u2019 t show any reconstructions , rather it shows generated samples where they vary the latent code . Additionally , InfoGAN uses a fixed reconstruction cost for the latent code C and requires a tractable approximate posterior , q ( C|X ) , that can be sampled from and evaluated . ALI only requires that inference networks can be sampled from , allowing it to represent arbitrarily complex posterior distributions . Combining InfoGAN and ALI could be an exciting area for future work . * Post-hoc learned inference : As verification that learning inference jointly with generation is beneficial , one can first train a GAN and then freeze the decoder and learn the encoder using the procedure proposed by ALI . In this setting , the encoder and the decoder can not interact together during training and the encoder must work with whatever the decoder has learned during GAN training . To address this point we performed an experiment on a toy dataset for which q ( X ) is a 2D gaussian mixture with 25 mixture components laid out on a grid . The covariance matrices and centroids have been chosen such that the distribution exhibits lots of modes separated by large low-probability regions , which makes it a decently hard task despite the 2D nature of the dataset . We trained ALI and GAN on 100,000 q ( X ) samples . The decoder and discriminator architectures are identical between ALI and GAN . Each model was trained 10 times using Adam with random learning rate and beta_1 values , and the weights were initialized by drawing from a gaussian distribution with a random standard deviation . We measured the extent to which the trained models covered all 25 modes by drawing 10,000 samples from their p ( X ) distribution and assigning each sample to a q ( X ) mixture component according to the mixture responsibilities . We defined a dropped mode as one that wasn \u2019 t assigned to * any * sample ( which is a generous definition ) . Using this definition , we found that ALI models covered 13.4 \u00b1 5.8 modes on average ( min : 8 , max : 25 ) while GAN models covered 10.4 \u00b1 9.2 modes on average ( min : 1 , max : 22 ) . We then selected the best-covering ALI and GAN models , and the GAN model was augmented with the following inference mechanisms : * Learned inverse mapping * Post-hoc learned inference The encoders learned for GAN inference have the same architecture as ALI \u2019 s encoder . We then compared each model \u2019 s inference capabilities by reconstructing 10,000 held-out samples from q ( X ) . A figure summarizing the experiment can be found at https : //raw.githubusercontent.com/IshmaelBelghazi/ALI/master/paper/mixture_plot.png . The three columns correspond to the three different strategies for learning inference : 1 . ALI ( our proposed strategy ) . 2.Learning an inverse mapping from GAN samples . 3.Post-hoc learned inference The five rows correspond to : 1 . X ~ q ( X ) samples , i.e.test set examples , colour-coded by mixture component . They 're the same for all three columns . 2.Z_hat ~ q ( Z | X ) samples , i.e.the latent codes , also colour-coded . 3.X_hat ~ p ( X | Z = Z_hat ) samples , i.e.the reconstructions , also colour-coded . 4.Z ~ p ( Z ) samples , i.e.prior samples . They 're the same for all three columns . 5.X_tilde ~ p ( X | Z ) samples , i.e.generator samples . Here is what we observe : * The ALI encoder models a marginal distribution q ( Z ) that matches p ( Z ) fairly well ( row 2 , column 1 ) . The learned representation does a decent job at clustering and organizing the different mixture components . * The GAN generator ( row 5 , columns 2-3 ) has more trouble reaching all the modes than the ALI generator ( row 5 , column 1 ) , even over 10 runs of hyperparameter search . * Learning an inverse mapping from GAN samples does not work very well : the encoder has trouble covering the prior marginally and the way it clusters mixture components is not very well organized ( row 2 , column 2 ) . * Learning inference post-hoc does n't work as well as training the encoder and the decoder jointly . As had been discussed above , it appears that adversarial training benefits from learning inference at training time in terms of mode coverage . This also negatively impacts how the latent space is organized ( row 2 , column 3 ) . However , it appears to be better at matching q ( Z ) and p ( Z ) than when inference is learned through inverse mapping from GAN samples . To summarize , this experiment provides evidence that adversarial training benefits from learning an inference mechanism jointly with the decoder . Furthermore , it shows that our proposed approach for learning inference in an adversarial setting is superior to the other approaches investigated . We will update the manuscript shortly to incorporate these additional results and cite the appropriate relevant work . REVIEWER POINT \u201c Since ALI 's inference network is stochastic , it would be great if different reconstructions of a same image is included . I believe the inference network of the BiGAN paper is deterministic which is the main difference with this work . So maybe it is worth highlighting this difference. \u201d RESPONSE Our experience is that the added stochasticity does not make much of a difference : at the end of training , very little noise ends up being injected at the encoder \u2019 s output . This falls in line with the invertibility results derived by Donahue et al . ( 2016 ) .We agree that left unexplained , this difference may confuse readers and we will update the manuscript to address this question . REVIEWER POINT \u201c The quality of samples is very good , but there is no quantitative experiment to compare ALI 's samples with other GAN variants . So I am not sure if learning an inference network has contributed to better generative samples . Maybe including an inception score for comparison can help. \u201d RESPONSE We do not claim that learning an inference network contributes to better generative samples , simply that doing so does not come at the expense of sample quality . However , as explained above , experiments on a toy dataset suggest that ALI is better at mode coverage than GAN . Regarding the use of the Inception score , we are hesitant to use it , as Odena et al . ( 2016 ) [ 1 ] found that \u201c [ the ] Inception accuracy can not measure whether a model has collapsed . A model that simply memorized one example from each ImageNet class would do very well by this metric. \u201d REVIEWER POINT \u201c There are two sets of semi-supervised results [ ... ] \u201d RESPONSE The point which we try to make with the semi-supervised results is that : * In the first method , one can train a shallow classifier using learned features from an unsupervised model . We used the * exact same * procedure as DCGAN to build an L2-SVM on top of existing features , with the exception that the features were taken from the inference network \u2019 s high-level representation as opposed to the discriminator . In this case ALI outperformed the results reported in the DCGAN paper , which suggests that for this procedure the inference network buys us something over the discriminator . To ensure that the comparison is fair , we are currently running an experiment in which DCGAN and ALI share the same architecture . We will update the manuscript when it is complete . * In the second method , one co-trains the discriminator for label classification . With this procedure ALI matches the more recent \u201c Improved methods for training GANs \u201d results while using a simpler architecture ( no feature matching ) . In this setting , the inference network * is * used , as it provides one of the two inputs which the discriminator uses to produce its prediction . While an inference network on categorical variables like in semi-supervised VAEs does sound elegant and straightforward , it is not directly applicable to ALI . Like GANs , ALI requires that the conditional distributions p ( x | z ) and q ( z | x ) can be sampled from in a way that allows gradient backpropagation , which can not be achieved in a straightforward manner using discrete random variables . [ 1 ] Odena , A. , Olah , C. , & Shlens , J . ( 2016 ) .Conditional Image Synthesis With Auxiliary Classifier GANs . arXiv preprint arXiv:1610.09585 ."}, "1": {"review_id": "B1ElR4cgg-1", "review_text": "This is a parallel work with BiGAN. The idea is using auto encoder to provide extra information for discriminator. This approach seems is promising from reported result.", "rating": "7: Good paper, accept", "reply_text": "We thank you for your review ."}, "2": {"review_id": "B1ElR4cgg-2", "review_text": "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,z is then modeled using a joint generator model p(x,z)=p(z)p(x|z). Both q and p are then trained by trying to fool a discriminator. This constitutes a worthwhile extension of GANs: giving GANs the ability to do inference opens up many applications that could previously only be addressed by e.g. VAEs. The results are very promising. The CIFAR-10 samples are the best I've seen so far (not counting methods that use class labels). Matching the semi-supervised results from Salimans et al. without feature matching also indicates the proposed method may improve the stability of training GANs.", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "We thank you for your feedback ."}}