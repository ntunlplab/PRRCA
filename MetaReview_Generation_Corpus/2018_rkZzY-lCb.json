{"year": "2018", "forum": "rkZzY-lCb", "title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "decision": "Reject", "meta_review": "The paper presents an approach for learning continuous-valued vector representations combining multiple input feature sets of different types, in both unsupervised and supervised settings.  The revised paper is a merger of the original submission and another ICLR submission.  This meta-review takes into account all of the comments on both submissions and revisions.\n\nThe merged paper is an improvement over the two separate ones.  However, the contribution over previous work is still a bit unclear.  It still does not sufficiently compare to/discuss in the context of other recent work on combining multiple feature groups.\n\nThe experiments are also quite limited.  The idea is introduced as extremely general, but the experiments focus on a small number of specific tasks, some of them non-standard.", "reviews": [{"review_id": "rkZzY-lCb-0", "review_text": "Summary: This paper proposes an approach to learn embeddings for structured datasets i.e. datasets which have heterogeneous set of features, as opposed to just words or just pixels. The paper proposes an approach called Feat2vec that relies on Structured Deep-In Factorization machines-- a paper that is concurrently under review at ICLR2018, which I haven't read in depth. The paper compares against a Word2vec baseline that pools all the heterogeneous content learns just one set of embeddings. Results are shown on IMDB movies and a proprietary education platform datasets. In both the tasks, Feat2vec leads to significant reduction in error compared to Word2vec. Comments: The paper is well written and addresses an important problem of learning word embeddings when there is inherent structure in the feature space. It is a very practically relevant problem. The novelty of the proposed approach seems limited in light of the related paper that is concurrently under review at ICLR2018, on which this paper heavily relies. Perhaps the authors should consider combining the two papers into one complete paper? The structured deep-in factorization machines allow higher-level interactions in embedding learning which allows the authors to learn embeddings for heterogeneous set of features. The sampling approaches proposed seem pretty straightforward adaptations of existing methods and not novel enough. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the constructive comments . Your main criticism for the paper was that the contribution of our work was not significant enough to justify the two publications that we were aiming for . Following your suggestion , we have combined the two papers and added the relevant parts of the other paper ( we only extended our submission with the results that would be relevant to the combined version ) . While the original paper only addressed unsupervised learning of embeddings , the revised manuscript also addresses supervised learning of embeddings . We demonstrate that our general supervised method can have better performance than recently published single purpose methods ( DeepCoNN and Collaborative Topic Regression ) on two publicly available datasets , Yelp and CiteULike . We also explain in more detail how Feat2Vec extends Factorization Machines . We hope that this major revision address your reservations ."}, {"review_id": "rkZzY-lCb-1", "review_text": "SUMMARY. The paper presents an extension of word2vec for structured features. The authors introduced a new compatibility function between features and, as in the skipgram approach, they propose a variation of negative sampling to deal with structured features. The learned representation of features is tested on a recommendation-like task. ---------- OVERALL JUDGMENT The paper is not clear and thus I am not sure what I can learn from it. From what is written on the paper I have trouble to understand the definition of the model the authors propose and also an actual NLP task where the representation induced by the model can be useful. For this reason, I would suggest the authors make clear with a more formal notation, and the use of examples, what the model is supposed to achieve. ---------- DETAILED COMMENTS When the authors refer to word2vec is not clear if they are referring to skipgram or cbow algorithm, please make it clear. Bottom of page one: \"a positive example is 'semantic'\", please, use another expression to describe observable examples, 'semantic' does not make sense in this context. Levi and Goldberg (2014) do not say anything about factorization machines, could the authors clarify this point? Equation (4), what do i and j stand for? what does \\beta represent? is it the embedding vector? How is this formula related to skipgram or cbow? The introduction of structured deep-in factorization machine should be more clear with examples that give the intuition on the rationale of the model. The experimental section is rather poor, first, the authors only compare themselves with word2ve (cbow), it is not clear what the reader should learn from the results the authors got. Finally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.", "rating": "2: Strong rejection", "reply_text": "Thank you for your helpful comments . Because another reviewer suggested merging our two ICLR submissions , we underwent a major revision of the paper and now have two main contributions -- this is , we can calculate embeddings in a supervised setting ( labels are available ) , and in an unsupervised setting ( labels are not available ) . You stated two main criticisms to the paper : * References . You mentioned that the most striking flaw of the paper is lack of references . We added roughly three times more citations ( we increased references from ~12 to ~36 ) . We believe that the paper is now much better situated in the literature . * Evaluation . To our knowledge we are the first ones to propose learning unsupervised embeddings for multiple feature types . The Word2Vec algorithms are other unsupervised embedding methods ( though , W2V only works with words ) , and that is why we compare with them . Because of the major revision of the paper , we believe we improved the empirical result section significantly . We added 2 additional datasets ( total of 4 ) , and added 4 baselines altogether ( CBOW W2V , Matrix Factorization , Collaborative Topic Regression and DeepCoNN ) Other detailed comments : We removed the reference of Levy & Goldberg ( but the general point is that factorization machines are a general case of matrix factorization ) We rewrote the introduction to make more salient our contributions , and we believe that it is now more clear what the model achieves . We streamlined the notation . Additionally , we clarified the language surrounding Word2Vec . We hope that these major revisions address your reservations ."}, {"review_id": "rkZzY-lCb-2", "review_text": "This paper provides a clean way of learning embeddings for structured features that can be discrete -- indicating presence / absence of a certain quality. Further, these features can be structured i.e. a set of them are of the same 'type'. Unlike, word2vec there is no hard constraint that similar objects must have similar representations and so, the learnt embeddings reflect the likelihood of the observed features. Therefore, this can be used as a multi-label classifier by using two feature types -- the input and the set of categories. This proposed scheme is evaluated on two datasets -- movies and education in a retrieval setting. I would like to see an evaluation of these features in a classification setting to further demonstrate the utility of these embeddings as compared to directly embedding the discrete features and then performing a K-way classification. For example, I am aware of -- http://manikvarma.org/downloads/XC/XMLRepository.html contains some interesting datasets which have a large number of discrete features and classes. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your informative comments on our paper . We have added experiments for supervised Feat2Vec , which includes a multi-label prediction task on a public dataset ( CiteULike ) benchmarked against other state of the art methods . We hope that this experiment at least partially addresses your desire to see Feat2Vec in a K-way classification task . We would also like to point you to the ranking task done classifying the director of a film based on its task members . The 2.43 % Top-1 Precision can be imagined as the performance of the unsupervised F2V embedding algorithm on a K-way classification task ( as compared to Word2Vec \u2019 s CBOW algorithm ) ."}], "0": {"review_id": "rkZzY-lCb-0", "review_text": "Summary: This paper proposes an approach to learn embeddings for structured datasets i.e. datasets which have heterogeneous set of features, as opposed to just words or just pixels. The paper proposes an approach called Feat2vec that relies on Structured Deep-In Factorization machines-- a paper that is concurrently under review at ICLR2018, which I haven't read in depth. The paper compares against a Word2vec baseline that pools all the heterogeneous content learns just one set of embeddings. Results are shown on IMDB movies and a proprietary education platform datasets. In both the tasks, Feat2vec leads to significant reduction in error compared to Word2vec. Comments: The paper is well written and addresses an important problem of learning word embeddings when there is inherent structure in the feature space. It is a very practically relevant problem. The novelty of the proposed approach seems limited in light of the related paper that is concurrently under review at ICLR2018, on which this paper heavily relies. Perhaps the authors should consider combining the two papers into one complete paper? The structured deep-in factorization machines allow higher-level interactions in embedding learning which allows the authors to learn embeddings for heterogeneous set of features. The sampling approaches proposed seem pretty straightforward adaptations of existing methods and not novel enough. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for the constructive comments . Your main criticism for the paper was that the contribution of our work was not significant enough to justify the two publications that we were aiming for . Following your suggestion , we have combined the two papers and added the relevant parts of the other paper ( we only extended our submission with the results that would be relevant to the combined version ) . While the original paper only addressed unsupervised learning of embeddings , the revised manuscript also addresses supervised learning of embeddings . We demonstrate that our general supervised method can have better performance than recently published single purpose methods ( DeepCoNN and Collaborative Topic Regression ) on two publicly available datasets , Yelp and CiteULike . We also explain in more detail how Feat2Vec extends Factorization Machines . We hope that this major revision address your reservations ."}, "1": {"review_id": "rkZzY-lCb-1", "review_text": "SUMMARY. The paper presents an extension of word2vec for structured features. The authors introduced a new compatibility function between features and, as in the skipgram approach, they propose a variation of negative sampling to deal with structured features. The learned representation of features is tested on a recommendation-like task. ---------- OVERALL JUDGMENT The paper is not clear and thus I am not sure what I can learn from it. From what is written on the paper I have trouble to understand the definition of the model the authors propose and also an actual NLP task where the representation induced by the model can be useful. For this reason, I would suggest the authors make clear with a more formal notation, and the use of examples, what the model is supposed to achieve. ---------- DETAILED COMMENTS When the authors refer to word2vec is not clear if they are referring to skipgram or cbow algorithm, please make it clear. Bottom of page one: \"a positive example is 'semantic'\", please, use another expression to describe observable examples, 'semantic' does not make sense in this context. Levi and Goldberg (2014) do not say anything about factorization machines, could the authors clarify this point? Equation (4), what do i and j stand for? what does \\beta represent? is it the embedding vector? How is this formula related to skipgram or cbow? The introduction of structured deep-in factorization machine should be more clear with examples that give the intuition on the rationale of the model. The experimental section is rather poor, first, the authors only compare themselves with word2ve (cbow), it is not clear what the reader should learn from the results the authors got. Finally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.", "rating": "2: Strong rejection", "reply_text": "Thank you for your helpful comments . Because another reviewer suggested merging our two ICLR submissions , we underwent a major revision of the paper and now have two main contributions -- this is , we can calculate embeddings in a supervised setting ( labels are available ) , and in an unsupervised setting ( labels are not available ) . You stated two main criticisms to the paper : * References . You mentioned that the most striking flaw of the paper is lack of references . We added roughly three times more citations ( we increased references from ~12 to ~36 ) . We believe that the paper is now much better situated in the literature . * Evaluation . To our knowledge we are the first ones to propose learning unsupervised embeddings for multiple feature types . The Word2Vec algorithms are other unsupervised embedding methods ( though , W2V only works with words ) , and that is why we compare with them . Because of the major revision of the paper , we believe we improved the empirical result section significantly . We added 2 additional datasets ( total of 4 ) , and added 4 baselines altogether ( CBOW W2V , Matrix Factorization , Collaborative Topic Regression and DeepCoNN ) Other detailed comments : We removed the reference of Levy & Goldberg ( but the general point is that factorization machines are a general case of matrix factorization ) We rewrote the introduction to make more salient our contributions , and we believe that it is now more clear what the model achieves . We streamlined the notation . Additionally , we clarified the language surrounding Word2Vec . We hope that these major revisions address your reservations ."}, "2": {"review_id": "rkZzY-lCb-2", "review_text": "This paper provides a clean way of learning embeddings for structured features that can be discrete -- indicating presence / absence of a certain quality. Further, these features can be structured i.e. a set of them are of the same 'type'. Unlike, word2vec there is no hard constraint that similar objects must have similar representations and so, the learnt embeddings reflect the likelihood of the observed features. Therefore, this can be used as a multi-label classifier by using two feature types -- the input and the set of categories. This proposed scheme is evaluated on two datasets -- movies and education in a retrieval setting. I would like to see an evaluation of these features in a classification setting to further demonstrate the utility of these embeddings as compared to directly embedding the discrete features and then performing a K-way classification. For example, I am aware of -- http://manikvarma.org/downloads/XC/XMLRepository.html contains some interesting datasets which have a large number of discrete features and classes. ", "rating": "7: Good paper, accept", "reply_text": "Thank you for your informative comments on our paper . We have added experiments for supervised Feat2Vec , which includes a multi-label prediction task on a public dataset ( CiteULike ) benchmarked against other state of the art methods . We hope that this experiment at least partially addresses your desire to see Feat2Vec in a K-way classification task . We would also like to point you to the ranking task done classifying the director of a film based on its task members . The 2.43 % Top-1 Precision can be imagined as the performance of the unsupervised F2V embedding algorithm on a K-way classification task ( as compared to Word2Vec \u2019 s CBOW algorithm ) ."}}