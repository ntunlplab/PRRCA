{"year": "2017", "forum": "BJAFbaolg", "title": "Learning to Generate Samples from Noise through Infusion Training", "decision": "Accept (Poster)", "meta_review": "Infusion training is a new, somewhat heuristic, procedure for training deep generative models. It's an interesting novel idea and a good paper, which has also been improved after the authors have been responsive to reviewer feedback.", "reviews": [{"review_id": "BJAFbaolg-0", "review_text": "This paper trains a generative model which transforms noise into model samples by a gradual denoising process. It is similar to a generative model based on diffusion. Unlike the diffusion approach: - It uses only a small number of denoising steps, and is thus far more computationally efficient. - Rather than consisting of a reverse trajectory, the conditional chain for the approximate posterior jumps to q(z(0) | x), and then runs in the same direction as the generative model. This allows the inference chain to behave like a perturbation around the generative model, that pulls it towards the data. (This also seems somewhat related to ladder networks.) - There is no tractable variational bound on the log likelihood. I liked the idea, and found the visual sample quality given a short chain impressive. The inpainting results were particularly nice, since one shot inpainting is not possible under most generative modeling frameworks. It would be much more convincing to have a log likelihood comparison that doesn't depend on Parzen likelihoods. Detailed comments follow: Sec. 2: \"theta(0) the\" -> \"theta(0) be the\" \"theta(t) the\" -> \"theta(t) be the\" \"what we will be using\" -> \"which we will be doing\" I like that you infer q(z^0|x), and then run inference in the same order as the generative chain. This reminds me slightly of ladder networks. \"q*. Having learned\" -> \"q*. [paragraph break] Having learned\" Sec 3.3: \"learn to inverse\" -> \"learn to reverse\" Sec. 4: \"For each experiments\" -> \"For each experiment\" How sensitive are your results to infusion rate? Sec. 5: \"appears to provide more accurate models\" I don't think you showed this -- there's no direct comparison to the Sohl-Dickstein paper. Fig 4. -- neat! ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks for your careful review , and useful suggestions . > > \u201c It would be much more convincing to have a log likelihood comparison that does n't depend on Parzen likelihoods. \u201d We updated our paper with a lower bound estimate of the log-likelihood as well as an Importance Sampling estimate . > > \u201c How sensitive are your results to infusion rate ? \u201d In the last revision , we add an appendix showing the impact of the infusion rate on the lower bound and in term of sampling quality . We also corrected the typos that you mentioned . Thank you !"}, {"review_id": "BJAFbaolg-1", "review_text": "The paper presents a method for training a generative model via an iterative denoising procedure. The denoising process is initialized with a random sample from a crude approximation to the data distribution and produces a high quality sample via multiple denoising steps. Training is performed by setting-up a Markov chain that slowly blends propositions from the current denoising model with a real example from the data distribution; using this chain the current denoising model is updated towards reproducing the changed, \"better\", samples from the blending process. This is a clearly written paper that considers an interesting approach for training generative models. I was intrigued by the simplicity of the presented approach and really enjoyed reading the paper. The proposed method is novel although it has clear ties to other recent work aiming to use denoising models for sampling from distributions such as the work by Sohl-Dickstein and the recent work on using DAEs as generative models. I think this general direction of research is important. The proposed procedure takes inspiration from the perspective of generating samples by minimizing an energy function via transitions along a Markov chain and, if successful, it can potentially sidestep many problems of current procedures for training directed generative models such as: - convergence and mode coverage problems as in generative adversarial networks - problems with modeling multi-modal distributions which can arise when a too restrictive approximate inference model is paired with a powerful generative model That being said, another method that seems promising for addressing these issues that also has some superficially similarity to the presented work is the idea of combining Hamiltonian Monte Carlo inference with variational inference as in [1]. As such I am not entirely convinced that the method presented here will be able to perform better than the mentioned paper; although it might be simpler to train. Similarly, although I agree that using a MCMC chain to generate samples via a MC-EM like procedure is likely very costly I am not convinced such a procedure won't at least also work reasonably well for the simple MNIST example. In general a more direct comparison between different inference methods using an MCMC chain like procedure would be nice to have but I understand that this is perhaps out of the scope of this paper. One thing that I would have expected, however, is a direct comparison to the procedure from Sohl-Dickstein in terms of sampling steps and generation quality as it is so directly related. Other major points (good and bad): - Although in general the method is explained well some training details are missing. Most importantly it is never mentioned how alpha or omega are set (I am assuming omega is 0.01 as that is the increase mentioned in the experimental setup). It is also unclear how alpha affects the capabilities of the generator. While it intuitively seems reasonable to use a small alpha over many steps to ensure slow blending of the two distributions it is not clear how necessary this is or at what point the procedure would break (I assume alpha = 1 won't work as the generator then would have to magically denoise a sample from the relatively uninformative draw from p0 ?). The authors do mention in one of the figure captions that the denoising model does not produce good samples in only 1-2 steps but that might also be an artifact of training the model with small alpha (at least I see no a priori reason for this). More experiments should be carried out here. - No infusion chains or generating chains are shown for any of the more complicated data distributions, this is unfortunate as I feel these would be interesting to look at. - The paper does a good job at evaluating the model with respect to several different metrics. The bound on the log-likelihood is nice to have as well! - Unfortunately the current approach does not come with any theoretical guarantees. It is unclear for what choices of alpha the procedure will work and whether there is some deeper connection to MCMC sampling or energy based models. In my eyes this does not subtract from the value of the paper but would perhaps be worth a short sentence in the conclusion. Minor points: - The second reference seems broken - Figure 3 starts at 100 epochs and, as a result, contains little information. Perhaps it would be more useful to show the complete training procedure and put the x-axis on a log-scale ? - The explanation regarding the convolutional networks you use makes no sense to me. You write that you use the same structure as in the \"Improved GANs\" paper which, unlike your model, generates samples from a fixed length random input. I thus suppose you don't really use a generator with 1 fully connected network followed by up-convolutions but rather have several stages of convolutions followed by a fully connected layer and then up-convolutions ? - The choice of parametrizing the variance via a sigmoid output unit is somewhat unusual, was there a specific reason for this choice ? - footnote 1 contains errors: \"This allow to\" -> \"allows to\", \"few informations\" -> \"little information\". \"This force the network\" -> \"forces\" - Page 1 error: etc... - Page 4 error: \"operator should to learn\" [1] Markov Chain Monte Carlo and Variational Inference: Bridging the Gap, Tim Salimans and Diedrik P. Kingma and Max Welling, ICML 2015 >>> Update <<<< Copied here from my response below: I believe the response of the authors clarifies all open issues. I strongly believe the paper should be accepted to the conference. The only remaining issue I have with the paper is that, as the authors acknowledge the architecture of the generator is likely highly sub-optimal and might hamper the performance of the method in the evaluation. This however does not at all subtract from any of the main points of the paper. I am thus keeping my score as a clear accept. I want to emphasize that I believe the paper should be published (just in case the review process results in some form of cut-off threshold that is high due to overall \"inflated\" review scores). ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your careful and very useful review . We corrected the typos that you mentioned . We address your comments below : > > `` another method that seems promising for addressing these issues that also has some superficially similarity to the presented work is the idea of combining Hamiltonian Monte Carlo inference with variational inference as in [ 1 ] . As such I am not entirely convinced that the method presented here will be able to perform better than the mentioned paper ; although it might be simpler to train . Similarly , although I agree that using a MCMC chain to generate samples via a MC-EM like procedure is likely very costly I am not convinced such a procedure wo n't at least also work reasonably well for the simple MNIST example . In general a more direct comparison between different inference methods using an MCMC chain like procedure would be nice to have but I understand that this is perhaps out of the scope of this paper . '' Thank you for pointing out the connection with the very interesting work of Salimans , Kingma & Welling , which we now include in our related works section . It will indeed be interesting to compare our more heuristic infusion approach with this method . We leave this as future work . > > \u201c One thing that I would have expected , however , is a direct comparison to the procedure from Sohl-Dickstein in terms of sampling steps and generation quality as it is so directly related. \u201d Note that on MNIST , the log-likelihood estimation ( Parzen-based ) that they report for their diffusion model ( 317 bits = 220 nats ) is worse than what we obtain with our model ( 312 nats estimated with Parzen ; 409 nats with the importance-sampling estimator ) . And our samples look arguably better . It obviously was ( and still is ) our plan to do a more extensive side-by-side comparison . But to be able to run experiments , starting from their code proved challenging , so we instead chose to prioritize developing and implementing proper log-likelihood estimation for our method to enable more trustworthy comparisons in the future before reimplementing their method in our framework . > > \u201c Unfortunately the current approach does not come with any theoretical guarantees . [ ... ] whether there is some deeper connection to MCMC sampling or energy based models . In my eyes this does not subtract from the value of the paper but would perhaps be worth a short sentence in the conclusion. \u201d We added the following sentence to our conclusion : \u201c While we empirically verified that the proposed infusion training procedure does result in increasing log-likielihood estimates , it remains a heuristic surrogate for the intractable likelihood , one for which we did not here derive any theoretical guarantee . Future work shall attempt to do so , or at least to clarify the relationship and quantify the compromises achieved with respect to other Markov Chain methods including Sohl-Dickstein et al.2015 and Salimans et al.2015. \u201d > > \u201d Although in general the method is explained well some training details are missing . Most importantly it is never mentioned how alpha or omega are set . [ ... ] \u201d We added more details in the appendix , regarding how to set the infusion rate , together with experimental curves . > > \u201d No infusion chains or generating chains are shown for any of the more complicated data distributions , this is unfortunate as I feel these would be interesting to look at. \u201d We added chains on CIFAR10 and CelebA in the Appendix of the paper . > > \u201d The explanation regarding the convolutional networks you use makes no sense to me . You write that you use the same structure as in the `` Improved GANs '' paper which , unlike your model , generates samples from a fixed length random input . I thus suppose you do n't really use a generator with 1 fully connected network followed by up-convolutions but rather have several stages of convolutions followed by a fully connected layer and then up-convolutions ? \u201d We really did use a generator with 1 fully connected network followed by up-convolutions . The main difference with the structure of `` Improved GANs '' paper is the input size ( We use a matrix of the image size instead of a fixed length random vector ) . We agree that this kind of architecture is probably suboptimal from the auto-encoder point of view . We didn \u2019 t devote much energy in this work on optimizing the architecture , as our main focus was the new training method . We think there is place for a lot of architectural improvement ( convolutional , resnet , ... ) we leave this as future work . > > \u201c The choice of parametrizing the variance via a sigmoid output unit is somewhat unusual , was there a specific reason for this choice ? \u201d We just thought it made sense from a stability perspective to have the variance in a finite range that we could control . We didn \u2019 t try anything else , but other choices are certainly possible and would likely work just as well ."}, {"review_id": "BJAFbaolg-2", "review_text": "Summary: This paper introduces a heuristic approach for training a deep directed generative model, where similar to the transition operator of a Markov chain each layer samples from the same conditional distribution. Similar to optimizing a variational lower bound, the approach is to approximate the gradient by replacing the posterior over latents with an alternative distribution. However, the approximating distribution is not updated to improve the lower bound but heuristically constructed in each step. A further difference to variational optimization is that the conditional distributions are optimized greedily rather than following the gradient of the joint log-likelihood. Review: The proposed approach is interesting and to me seems worth exploring more. Given that there are approaches for training the same class of models which are 1) theoretically more sound, 2) of similar computational complexity, and 3) work well in practice (e.g. Rezende & Mohamed, 2015), I am nevertheless not sure of its potential to generate impact. My bigger concern, however, is that the empirical evaluation is still quite limited. I appreciate the authors included proper estimates of the log-likelihood. This will enable and encourage future comparisons with this method on continuous MNIST. However, the authors should point out that the numbers taken from Wu et al. (2016) are not representative of the performance of a VAE. (From the paper: \u201cTherefore, the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model.\u201d \u201cSuch observation models can easily achieve much higher log-likelihood scores, [\u2026].\u201d) Comparisons with inpainting results using other methods would have been nice. How practical is the proposed approach compared to other approaches? Similar to the diffusion approach by Sohl-Dickstein et al. (2015), the proposed approach seems to be both efficient and effective for inpainting. Not making this a bigger point and performing the proper evaluations seems like a missed opportunity. Minor: \u2013 I am missing citations for \u201cordered visible dimension sampling\u201d \u2013 Typos and frequent incorrect use of \\citet and \\citep", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your careful , well informed , and very useful review . Regarding log-likelihood estimates , to improve upon the limitations of the Parzen estimator we had for our first revision implemented a lower-bound estimator and used it for model evaluation . Although we initially feared it might suffer from too high variance , following your suggestion , we have since implemented an importance sampling based estimator . And it was able to measure significantly higher log likelihood , thank you for the suggestion ! Future work will include a proper AIS estimator for our model . > > \u201c However , the authors should point out that the numbers taken from Wu et al . ( 2016 ) are not representative of the performance of a VAE . ( From the paper : \u201c Therefore , the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model. \u201d \u201c Such observation models can easily achieve much higher log-likelihood scores , [ \u2026 ] . \u201d ) \u201c Thank you for pointing this out ! We updated the results table with the performance obtained when using an isotropic gaussian output ( which naturally does yields poorer log-likelihood ) to be more comparable with Wu et al . ( 2016 ) .We clarify this issue in the caption of the table . Regarding the work of Rezende & Mohamed , 2015 it is indeed a very interesting and much related work . Thank you for pointing it out . We now reference it in the paper , and mention in the conclusion that we will perform empirical comparisons with it as part of our future work . While the variational approach of Rezende & Mohamed indeed stands on more solid theoretical ground , the statistical/computational performance tradeoffs need to be assessed empirically . Also a situation where our more heuristic approach could prove interesting : it can straightforwardly be used in discretes spaces as well ( infusion using mixtures of multinomials , which we did in some of our early unreported experiments ) , while extension of Rezende & Mohamed , 2015 to discrete spaces does not look as obvious . We also corrected the typos and added the missing reference . Thank you very much !"}], "0": {"review_id": "BJAFbaolg-0", "review_text": "This paper trains a generative model which transforms noise into model samples by a gradual denoising process. It is similar to a generative model based on diffusion. Unlike the diffusion approach: - It uses only a small number of denoising steps, and is thus far more computationally efficient. - Rather than consisting of a reverse trajectory, the conditional chain for the approximate posterior jumps to q(z(0) | x), and then runs in the same direction as the generative model. This allows the inference chain to behave like a perturbation around the generative model, that pulls it towards the data. (This also seems somewhat related to ladder networks.) - There is no tractable variational bound on the log likelihood. I liked the idea, and found the visual sample quality given a short chain impressive. The inpainting results were particularly nice, since one shot inpainting is not possible under most generative modeling frameworks. It would be much more convincing to have a log likelihood comparison that doesn't depend on Parzen likelihoods. Detailed comments follow: Sec. 2: \"theta(0) the\" -> \"theta(0) be the\" \"theta(t) the\" -> \"theta(t) be the\" \"what we will be using\" -> \"which we will be doing\" I like that you infer q(z^0|x), and then run inference in the same order as the generative chain. This reminds me slightly of ladder networks. \"q*. Having learned\" -> \"q*. [paragraph break] Having learned\" Sec 3.3: \"learn to inverse\" -> \"learn to reverse\" Sec. 4: \"For each experiments\" -> \"For each experiment\" How sensitive are your results to infusion rate? Sec. 5: \"appears to provide more accurate models\" I don't think you showed this -- there's no direct comparison to the Sohl-Dickstein paper. Fig 4. -- neat! ", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thanks for your careful review , and useful suggestions . > > \u201c It would be much more convincing to have a log likelihood comparison that does n't depend on Parzen likelihoods. \u201d We updated our paper with a lower bound estimate of the log-likelihood as well as an Importance Sampling estimate . > > \u201c How sensitive are your results to infusion rate ? \u201d In the last revision , we add an appendix showing the impact of the infusion rate on the lower bound and in term of sampling quality . We also corrected the typos that you mentioned . Thank you !"}, "1": {"review_id": "BJAFbaolg-1", "review_text": "The paper presents a method for training a generative model via an iterative denoising procedure. The denoising process is initialized with a random sample from a crude approximation to the data distribution and produces a high quality sample via multiple denoising steps. Training is performed by setting-up a Markov chain that slowly blends propositions from the current denoising model with a real example from the data distribution; using this chain the current denoising model is updated towards reproducing the changed, \"better\", samples from the blending process. This is a clearly written paper that considers an interesting approach for training generative models. I was intrigued by the simplicity of the presented approach and really enjoyed reading the paper. The proposed method is novel although it has clear ties to other recent work aiming to use denoising models for sampling from distributions such as the work by Sohl-Dickstein and the recent work on using DAEs as generative models. I think this general direction of research is important. The proposed procedure takes inspiration from the perspective of generating samples by minimizing an energy function via transitions along a Markov chain and, if successful, it can potentially sidestep many problems of current procedures for training directed generative models such as: - convergence and mode coverage problems as in generative adversarial networks - problems with modeling multi-modal distributions which can arise when a too restrictive approximate inference model is paired with a powerful generative model That being said, another method that seems promising for addressing these issues that also has some superficially similarity to the presented work is the idea of combining Hamiltonian Monte Carlo inference with variational inference as in [1]. As such I am not entirely convinced that the method presented here will be able to perform better than the mentioned paper; although it might be simpler to train. Similarly, although I agree that using a MCMC chain to generate samples via a MC-EM like procedure is likely very costly I am not convinced such a procedure won't at least also work reasonably well for the simple MNIST example. In general a more direct comparison between different inference methods using an MCMC chain like procedure would be nice to have but I understand that this is perhaps out of the scope of this paper. One thing that I would have expected, however, is a direct comparison to the procedure from Sohl-Dickstein in terms of sampling steps and generation quality as it is so directly related. Other major points (good and bad): - Although in general the method is explained well some training details are missing. Most importantly it is never mentioned how alpha or omega are set (I am assuming omega is 0.01 as that is the increase mentioned in the experimental setup). It is also unclear how alpha affects the capabilities of the generator. While it intuitively seems reasonable to use a small alpha over many steps to ensure slow blending of the two distributions it is not clear how necessary this is or at what point the procedure would break (I assume alpha = 1 won't work as the generator then would have to magically denoise a sample from the relatively uninformative draw from p0 ?). The authors do mention in one of the figure captions that the denoising model does not produce good samples in only 1-2 steps but that might also be an artifact of training the model with small alpha (at least I see no a priori reason for this). More experiments should be carried out here. - No infusion chains or generating chains are shown for any of the more complicated data distributions, this is unfortunate as I feel these would be interesting to look at. - The paper does a good job at evaluating the model with respect to several different metrics. The bound on the log-likelihood is nice to have as well! - Unfortunately the current approach does not come with any theoretical guarantees. It is unclear for what choices of alpha the procedure will work and whether there is some deeper connection to MCMC sampling or energy based models. In my eyes this does not subtract from the value of the paper but would perhaps be worth a short sentence in the conclusion. Minor points: - The second reference seems broken - Figure 3 starts at 100 epochs and, as a result, contains little information. Perhaps it would be more useful to show the complete training procedure and put the x-axis on a log-scale ? - The explanation regarding the convolutional networks you use makes no sense to me. You write that you use the same structure as in the \"Improved GANs\" paper which, unlike your model, generates samples from a fixed length random input. I thus suppose you don't really use a generator with 1 fully connected network followed by up-convolutions but rather have several stages of convolutions followed by a fully connected layer and then up-convolutions ? - The choice of parametrizing the variance via a sigmoid output unit is somewhat unusual, was there a specific reason for this choice ? - footnote 1 contains errors: \"This allow to\" -> \"allows to\", \"few informations\" -> \"little information\". \"This force the network\" -> \"forces\" - Page 1 error: etc... - Page 4 error: \"operator should to learn\" [1] Markov Chain Monte Carlo and Variational Inference: Bridging the Gap, Tim Salimans and Diedrik P. Kingma and Max Welling, ICML 2015 >>> Update <<<< Copied here from my response below: I believe the response of the authors clarifies all open issues. I strongly believe the paper should be accepted to the conference. The only remaining issue I have with the paper is that, as the authors acknowledge the architecture of the generator is likely highly sub-optimal and might hamper the performance of the method in the evaluation. This however does not at all subtract from any of the main points of the paper. I am thus keeping my score as a clear accept. I want to emphasize that I believe the paper should be published (just in case the review process results in some form of cut-off threshold that is high due to overall \"inflated\" review scores). ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your careful and very useful review . We corrected the typos that you mentioned . We address your comments below : > > `` another method that seems promising for addressing these issues that also has some superficially similarity to the presented work is the idea of combining Hamiltonian Monte Carlo inference with variational inference as in [ 1 ] . As such I am not entirely convinced that the method presented here will be able to perform better than the mentioned paper ; although it might be simpler to train . Similarly , although I agree that using a MCMC chain to generate samples via a MC-EM like procedure is likely very costly I am not convinced such a procedure wo n't at least also work reasonably well for the simple MNIST example . In general a more direct comparison between different inference methods using an MCMC chain like procedure would be nice to have but I understand that this is perhaps out of the scope of this paper . '' Thank you for pointing out the connection with the very interesting work of Salimans , Kingma & Welling , which we now include in our related works section . It will indeed be interesting to compare our more heuristic infusion approach with this method . We leave this as future work . > > \u201c One thing that I would have expected , however , is a direct comparison to the procedure from Sohl-Dickstein in terms of sampling steps and generation quality as it is so directly related. \u201d Note that on MNIST , the log-likelihood estimation ( Parzen-based ) that they report for their diffusion model ( 317 bits = 220 nats ) is worse than what we obtain with our model ( 312 nats estimated with Parzen ; 409 nats with the importance-sampling estimator ) . And our samples look arguably better . It obviously was ( and still is ) our plan to do a more extensive side-by-side comparison . But to be able to run experiments , starting from their code proved challenging , so we instead chose to prioritize developing and implementing proper log-likelihood estimation for our method to enable more trustworthy comparisons in the future before reimplementing their method in our framework . > > \u201c Unfortunately the current approach does not come with any theoretical guarantees . [ ... ] whether there is some deeper connection to MCMC sampling or energy based models . In my eyes this does not subtract from the value of the paper but would perhaps be worth a short sentence in the conclusion. \u201d We added the following sentence to our conclusion : \u201c While we empirically verified that the proposed infusion training procedure does result in increasing log-likielihood estimates , it remains a heuristic surrogate for the intractable likelihood , one for which we did not here derive any theoretical guarantee . Future work shall attempt to do so , or at least to clarify the relationship and quantify the compromises achieved with respect to other Markov Chain methods including Sohl-Dickstein et al.2015 and Salimans et al.2015. \u201d > > \u201d Although in general the method is explained well some training details are missing . Most importantly it is never mentioned how alpha or omega are set . [ ... ] \u201d We added more details in the appendix , regarding how to set the infusion rate , together with experimental curves . > > \u201d No infusion chains or generating chains are shown for any of the more complicated data distributions , this is unfortunate as I feel these would be interesting to look at. \u201d We added chains on CIFAR10 and CelebA in the Appendix of the paper . > > \u201d The explanation regarding the convolutional networks you use makes no sense to me . You write that you use the same structure as in the `` Improved GANs '' paper which , unlike your model , generates samples from a fixed length random input . I thus suppose you do n't really use a generator with 1 fully connected network followed by up-convolutions but rather have several stages of convolutions followed by a fully connected layer and then up-convolutions ? \u201d We really did use a generator with 1 fully connected network followed by up-convolutions . The main difference with the structure of `` Improved GANs '' paper is the input size ( We use a matrix of the image size instead of a fixed length random vector ) . We agree that this kind of architecture is probably suboptimal from the auto-encoder point of view . We didn \u2019 t devote much energy in this work on optimizing the architecture , as our main focus was the new training method . We think there is place for a lot of architectural improvement ( convolutional , resnet , ... ) we leave this as future work . > > \u201c The choice of parametrizing the variance via a sigmoid output unit is somewhat unusual , was there a specific reason for this choice ? \u201d We just thought it made sense from a stability perspective to have the variance in a finite range that we could control . We didn \u2019 t try anything else , but other choices are certainly possible and would likely work just as well ."}, "2": {"review_id": "BJAFbaolg-2", "review_text": "Summary: This paper introduces a heuristic approach for training a deep directed generative model, where similar to the transition operator of a Markov chain each layer samples from the same conditional distribution. Similar to optimizing a variational lower bound, the approach is to approximate the gradient by replacing the posterior over latents with an alternative distribution. However, the approximating distribution is not updated to improve the lower bound but heuristically constructed in each step. A further difference to variational optimization is that the conditional distributions are optimized greedily rather than following the gradient of the joint log-likelihood. Review: The proposed approach is interesting and to me seems worth exploring more. Given that there are approaches for training the same class of models which are 1) theoretically more sound, 2) of similar computational complexity, and 3) work well in practice (e.g. Rezende & Mohamed, 2015), I am nevertheless not sure of its potential to generate impact. My bigger concern, however, is that the empirical evaluation is still quite limited. I appreciate the authors included proper estimates of the log-likelihood. This will enable and encourage future comparisons with this method on continuous MNIST. However, the authors should point out that the numbers taken from Wu et al. (2016) are not representative of the performance of a VAE. (From the paper: \u201cTherefore, the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model.\u201d \u201cSuch observation models can easily achieve much higher log-likelihood scores, [\u2026].\u201d) Comparisons with inpainting results using other methods would have been nice. How practical is the proposed approach compared to other approaches? Similar to the diffusion approach by Sohl-Dickstein et al. (2015), the proposed approach seems to be both efficient and effective for inpainting. Not making this a bigger point and performing the proper evaluations seems like a missed opportunity. Minor: \u2013 I am missing citations for \u201cordered visible dimension sampling\u201d \u2013 Typos and frequent incorrect use of \\citet and \\citep", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your careful , well informed , and very useful review . Regarding log-likelihood estimates , to improve upon the limitations of the Parzen estimator we had for our first revision implemented a lower-bound estimator and used it for model evaluation . Although we initially feared it might suffer from too high variance , following your suggestion , we have since implemented an importance sampling based estimator . And it was able to measure significantly higher log likelihood , thank you for the suggestion ! Future work will include a proper AIS estimator for our model . > > \u201c However , the authors should point out that the numbers taken from Wu et al . ( 2016 ) are not representative of the performance of a VAE . ( From the paper : \u201c Therefore , the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model. \u201d \u201c Such observation models can easily achieve much higher log-likelihood scores , [ \u2026 ] . \u201d ) \u201c Thank you for pointing this out ! We updated the results table with the performance obtained when using an isotropic gaussian output ( which naturally does yields poorer log-likelihood ) to be more comparable with Wu et al . ( 2016 ) .We clarify this issue in the caption of the table . Regarding the work of Rezende & Mohamed , 2015 it is indeed a very interesting and much related work . Thank you for pointing it out . We now reference it in the paper , and mention in the conclusion that we will perform empirical comparisons with it as part of our future work . While the variational approach of Rezende & Mohamed indeed stands on more solid theoretical ground , the statistical/computational performance tradeoffs need to be assessed empirically . Also a situation where our more heuristic approach could prove interesting : it can straightforwardly be used in discretes spaces as well ( infusion using mixtures of multinomials , which we did in some of our early unreported experiments ) , while extension of Rezende & Mohamed , 2015 to discrete spaces does not look as obvious . We also corrected the typos and added the missing reference . Thank you very much !"}}