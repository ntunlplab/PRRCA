{"year": "2020", "forum": "H1gN6kSFwS", "title": "Learning Neural Causal Models from Unknown Interventions", "decision": "Reject", "meta_review": "This paper proposes a metalearning objective to infer causal graphs from data based on masked neural networks to capture arbitrary conditional relationships. While the authors agree that the paper contains various interesting ideas, the theoretical and conceptual underpinnings of the proposed methodology are still lacking and the experiments cannot sufficiently make up for this. The method is definitely worth exploring more and a revision is likely to be accepted at another venue.", "reviews": [{"review_id": "H1gN6kSFwS-0", "review_text": "This paper proposes a MAML objective to learn causal graphs from data. The data in question is randomized but the algorithm does not have access to the identity of the intervention variable. So there is an added layer of complexity of deciphering which variable was intervened on. The MAML objective, in this case, links the causal structure to the slow-moving parameter theta_slow. The novelty of the paper seems to be in the application of the MAML framework to causal discovery which is interesting to me. I think a little theory about the sensitivity of the claim of ' theta slow changes relate to the causal structure ' is important. Even showing empirically which sort of graphs and functions become issues for the model would be useful. Here are my issues with the paper: - No error bars for cross-entropy are reported in the experiments. - The acyclic regularizer does not reject large length cycles than 3. - The ability to predict interventions seems to drop off sharply as the number of nodes increases. This suggests an inability to scale to more than 20 variables. - The experimental setup of uniformly sampling an intervening variable seems artificial to me. - MLP-specification of the SCM also seemed a bit artificial to me. Overall, the experiments look reasonable and the method itself seems interesting although further work is needed to show it is useful. (writing comments) The paper could use a more structured re-write. I had trouble tracking terms around the paper. For example, there seems to be a difference between P_i and P because the former uses theta_i and the latter only uses theta_slow only. --------------------------------- Updated score to 6 after rebuttal.", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the feedback . We have conducted additional experiments based on the feedback and will update our paper once the experiments are completed . Our paper is related to MAML like procedures for meta-learning , but goes beyond the usual setting , making a significant contribution through developing more sophisticated algorithms that enable causal structure learning . The difficulties those changes addressed are intrinsic to causal structure learning , especially in the challenging unknown-intervention scenario that we have set ourselves . The challenges we solve are 1 ) how to handle unknown interventions , 2 ) how to avoid an exponential search over all possible DAGs , 3 ) how to model the effect of the intervention , and finally 4 ) how to model the underlying causal structure . Q. \u201c No error bars for cross-entropy are reported in the experiments. \u201d We thank the reviewer for pointing this out . We have conducted additional experiments and will update our paper once the experiments have been completed . Q. \u201c The acyclic regularizer does not reject large length cycles than 3. \u2018 We appreciate the reviewer \u2019 s concern . The regularizer can be extended to length-n cycles , however , this becomes more computationally demanding as n increases . However , we found that a smaller n does not affect our model empirically . As shown in Figure 2 , 3 and 4 , our model did not learn cycles of any length greater than 2 . In fact , we have found that even completely removing this regularizer does not hurt the asymptotic performance of our model . The regularizer helps the model to converge faster , however , the model still converges reasonably fast without the regularizer , as shown in Figure 6 Right . Q. \u201c The ability to predict interventions seems to drop off sharply as the number of nodes increases. \u201d We are aware of this limitation . It makes sense that guessing which node has been intervened becomes harder as the number of nodes increases and we find that empirically , without surprise . We agree that it is a challenge to scale to larger graphs ( namely graphs with more than 20 variables ) , however even for the sizes of graphs we consider our paper finds greatly improved solutions and this is already a significant advance over past work . One extension we hope will help to overcome this difficulty would be to perform a soft prediction of the interventional nodes , instead of the hard decision that we have now . We also would like to highlight that the intervention prediction performs significantly better than random at all times . One note on the recent papers on this topic : although ICP and non-linear ICP consider a larger number of covariates , they only aim to identify the causal parents of one variable . This task alone already has exponential cost , which would be further increased if the algorithm were applied for reconstructing the whole graph by applying it iteratively to each node . Due to the computational cost , this is infeasible for larger graphs .. Other recent papers e.g . [ 1 ] likewise only consider similar number of variables given the computational cost of the proposed algorithms . In contrast one contribution of our paper is a proposal how to avoid an exponential search over all possible DAGs . [ 1 ] .Ghassami , AmirEmad , Saber Salehkaleybar , Negar Kiyavash , and Kun Zhang . `` Learning causal structures using regression invariance . '' In Advances in Neural Information Processing Systems , pp . 3011-3021 . 2017.Q. \u201c The experimental setup of uniformly sampling an intervening variable seems artificial to me. \u201d We thank the reviewer for pointing this out . We agree that in the real world , interventions rarely appear to be chosen uniformly randomly . However , given the lack of better real-world causal structures than those from the BNLearn graph repository , and the lack of a commonly-agreed intervention probability on each node , uniform sampling seemed reasonable . Doing otherwise would have required us to justify why we picked those specific intervention probabilities . However , if the reviewer has suggestions for specific non-uniform intervention probabilities , we will be happy to perform additional experiments with them ."}, {"review_id": "H1gN6kSFwS-1", "review_text": "The paper develops a learning-based causal inference method that performs multiple tasks jointly: i) scalable discovery of the underlying Structured Causal Model (SCM) by modeling both structural assignments and the SCM as a continuously parameterized chain of distributions, ii) identification of the intervened variables, which are not known to the model a-priori unlike the mainstream causal inference setups, iii) achieving the two aforementioned goals using meta-learning driven heuristics, i.e. interventions cause distributional shifts. While the paper adopts the core design choices from recent prior art (Bengio et al., 2019), the proposed methodology (especially ii)) is sufficiently novel to be published as a main-track conference paper. The paper is very well-written, follows a concrete and easy-to-follow story line. It solves multiple ambitious problems end-to-end and justifies the methodological novelty claims by a properly conducted set of experiments. The paper also successfully employs simple and useful but forgotten old techniques such as fast/slow parameter decomposition in the proposed model pipeline. The intervention prediction heuristic is splendid. It is simple, sensible, and has been proven by experiments to be very effective. I would rate this as the primary novelty presented in this paper. The paper can be improved if the below relatively minor concerns are addressed: i) It would be informative if the paper had a paragraph discussing also the fundamental limitations of the approach more openly. For instance, the choice of the neural net architecture used for the structural assignment might have a huge impact on the outcome, especially because the same architecture is repetitively used for all variables of the SCM. Furthermore, treatment of each variable with a fully independent neural net could cause overparameterization as the SCM grows in number of variables. ii) The paper makes a strong scalability claim across the variable size thanks to independent Bernoullis assigned on the adjacency matrix entries. However, it reports results only for very small SCMs. It is understandable that given the premature stage of the causal inference research might not grant standardized data sets at a larger scale, but at least lack of this quantitative scalability test could be acknowledged and the related claims could be a little bit softened. iii) I do not buy the argument in the first paragraph of Sec 3.5 about why the structural assignment functions need to be independent. As the model does not pose a distribution on neural net weights, sharing some weights (i.e. conditioning on them) would only bring conditional independence across the variables. I do not see a solid reason to try to avoid this. What is wrong for multiple variables to share some functional characteristics in their structural assignment? After all, some sort of conditional independence will be inevitable in modeling. If the variables share the same architecture, this is also conditional independence, not full independence. Relaxing the independence assumption and allowing some weight sharing could be beneficial at least for scalability of the model, could even bring about improved model fit due to cross-variable knowledge transfer. Overall, none of the aforementioned three weaknesses is fundamental. In the status-quo, this is a spectactular research paper and my initial vote is an accept.", "rating": "8: Accept", "reply_text": "We are grateful to the reviewer for their enthusiastic feedback and comments ! Q : \u201c It would be informative if the paper had a paragraph discussing also the fundamental limitations of the approach more openly . For instance , the choice of the neural net architecture used for the structural assignment might have a huge impact on the outcome , especially because the same architecture is repetitively used for all variables of the SCM. \u201d We thank the reviewer for pointing this out . We had chosen to implement all variables using the same neural network architecture for computational reasons ( vectorization , batching ) , but it indeed might have had a significant impact on the learning process . A wider variety of architectures , incorporating heterogeneity in each variable \u2019 s model , would strengthen the case for the approach . There are , however , recent demonstrations that overparameterized neural networks can generalize well ( with some regularization ) [ 1 ] . This suggests that we may get away with deliberate over-parametrization , whether of each module separately or the whole network globally . The reviewer \u2019 s proposal below to allow some cross-variable parameter sharing is compatible with the latter ; The right capacity and level of sharing for each variable would then be allocated according to the different pressures from the data and the training objective . [ 1 ] .Belkin , Mikhail , Daniel Hsu , Siyuan Ma , and Soumik Mandal . `` Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off . '' Proceedings of the National Academy of Sciences 116 , no . 32 ( 2019 ) : 15849-15854 . Q. \u201c The paper makes a strong scalability claim across the variable size thanks to independent Bernoullis assigned on the adjacency matrix entries . However , it reports results only for very small SCMs . It is understandable that given the premature stage of the causal inference research might not grant standardized data sets at a larger scale , but at least lack of this quantitative scalability test could be acknowledged and the related claims could be a little bit softened. \u201d We thank the reviewer for pointing this out . We agree with the reviewer \u2019 s point and a necessary continuation of our work is to demonstrate scaling to larger graphs available from e.g.the Bayesian Networks Repository . We will soften our scalability claims to better accord with the size of the problems solved in the paper . Q. \u201c I do not buy the argument in the first paragraph of Sec 3.5 about why the structural assignment functions need to be independent . As the model does not pose a distribution on neural net weights , sharing some weights ( i.e.conditioning on them ) would only bring conditional independence across the variables . I do not see a solid reason to try to avoid this . What is wrong for multiple variables to share some functional characteristics in their structural assignment ? After all , some sort of conditional independence will be inevitable in modeling . If the variables share the same architecture , this is also conditional independence , not full independence . Relaxing the independence assumption and allowing some weight sharing could be beneficial at least for scalability of the model , could even bring about improved model fit due to cross-variable knowledge transfer. \u201d We appreciate the thought-provoking idea from the reviewer of cross-variable knowledge transfer via sharing . This is especially applicable to the real world setting , where it is likely that functional characteristics will be shared between variables of a similar nature . We will gladly investigate further this issue . Overall , we would like to thank the reviewer for the positive feedback and comments . We will perform the changes the reviewer recommends and relax the enforced independences to see if scalability or performance gains materialize ."}, {"review_id": "H1gN6kSFwS-2", "review_text": "This paper proposes an SCM-model based on masked neural networks to capture arbitrary conditional relationships combined with meta-learning-style adaptation to reflect the effects of various unknown interventions. Overall the paper is well written and easy to follow, but some conceptual issues remain. - How come there is hardly any discussion of the identifiability issue beyond the few sentences in A.3. This is one of the key issues in learning SCMs and it is strange that the concept of \"faithfulness\" is not even mentioned in the paper. In general, there is hardly any discussion of what conditions are required for the proposed estimates to even be valid. The authors seem to be optimistically assuming that their neural network + metalearning model will somehow pick up on the correct structure, without any actual conceptual investigation of this issue. - The massive downside of neural nets is all the various hyperparameters one has to set (eg. architecture, optimizer, activations, etc). In this setting, how do the authors propose selecting hyperparameter values? How does the reader know the authors did not simply tune their hyperparameters to best match the underlying ground truth (I assume the proposed methodology has many more hyperparameters and thus more degrees of freedom here). I would like to see the empirical performance of different variants of your model with different hyperparameter values to assess its sensitivity to these choices. - Why does one even care about the graph being acylic in this setting? The mere fact that the authors require a regularizer to ensure acylicity suggests this approach is prone to mis-identifying the ground truth structure (which is always acyclic in the experiments). - One main reason for SCM modeling in science and policy-making is for analysts to better understand the data generating phenomena. However your use of neural networks here seems to hamper interpretability, so how do you reconcile this issue? Also is your sparsity regularizer satisfactory to confidently diagnose presence/absence of an edge (in constrast to statistical hypothesis tests, say based on conditional independence). Isn't this heavily influenced by the particular sparsity-regularizer value that happened to be selected? - Related papers that utilize the same idea of predicting a variable conditioned on subset of other variables via neural network + masking strategy: Ivanov et al (2019). VARIATIONAL AUTOENCODER WITH ARBITRARY CONDITIONING. https://openreview.net/pdf?id=SyxtJh0qYm Li et al (2019). Flow Models for Arbitrary Conditional Likelihoods. https://arxiv.org/abs/1909.06319 Yoon et al. GAIN: Missing data imputation using generative adversarial nets. Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, 2018. http://proceedings.mlr.press/v80/yoon18a.html Douglas et al. A universal marginalizer for amortized inference in generative models. arXiv preprint arXiv:1711.00695, 2017 For clarity, the authors should highlight the differences of their approach from these works (beyond the causal setting). - Given the lack of theoretical / conceptual guarantees that the methodology will work, our faith in the proposed methodology rests entirely on the empirical experiments. However, I find these a bit too basic to be very convincing, and would at least like to see more methods being compared (in particular for the simulated graphs as well). - The authors should describe what are the underlying interventions in each dataset a bit more. - The Figures should be better explained (took me a while to figure out what dots/colors represent). - Why do the authors report cross entropy loss in Table 1? To my knowledge this is not a standard metric for measuring the quality of structure-estimates. - Instead of ICP (which is constrained to be linear which is unrealistically simple), why don't the authors compare against nonlinearICP (which is more flexible like their neural networks): Heinze-Deml et al (2018). Invariant Causal Prediction for Nonlinear Models. https://arxiv.org/pdf/1706.08576.pdf", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for such detailed feedback . We are conducting additional experiments based on the feedback and will update the paper and rebuttal once the experiments are completed . The reviewer expresses several general concerns about the use of neural networks for causal inference , focusing on attributes such as their large design space and their interpretability . We would like to underscore that this paper is intended as a step from today \u2019 s completely non-causal neural networks towards incorporating more of the abilities required for handling causality . As such , our proposed method will indeed retain most of the benefits and limitations of neural networks , but improve on them by identifying causal structures . Q. \u201d How come there is hardly any discussion of the identifiability issue beyond the few sentences in A.3 . This is one of the key issues in learning SCMs and it is strange that the concept of `` faithfulness '' is not even mentioned in the paper . \u2026.In general , there is hardly any discussion of what conditions are required for the proposed estimates to even be valid . The authors seem to be optimistically assuming that their neural network + metalearning model will somehow pick up on the correct structure , without any actual conceptual investigation of this issue. \u201d Because our task setup allows a random intervention over any variable , per ( Eberhardt et al. , 2012 ) it is at least in theory possible to identify the correct graph . The rest of the paper was mostly directed at showing that this is not only possible in theory but in practice as well . We thank the reviewer for mentioning that some discussion of faithfulness would enhance the paper . There are several aspects that are relevant as listed below . Our model does indeed assume faithfulness , however , this is not a limitation in practice . Because of the continuous evolution of the functional parameters for the conditional distributions MLP , we believe that occurrences of unfaithful populations will be extremely short-lived and exceedingly rare to begin with . Lastly , because our procedure invokes an outer-loop optimization procedure , gradient estimate errors induced by unfaithfulness can be compensated . The faithfulness assumption ( Pearl 2009 , Peters et al.2017 ) implies that any d-separation in the graph corresponds to a conditional independence in the data generating random variables . Under the assumption of faithfulness and a sufficiently large sample size , the Markov blanket can consistently be recovered given the availability of an efficient feature selection algorithm [ 1 ] . Neural Networks have been shown to be able to learn good features [ 2 , 3 ] and require large datasets for training , which we assumed to be given here . We agree with the reviewer that similarly to the already mentioned assumptions of Markov equivalence and causal sufficiency ( see A.3 PRELIMINARIES ) we will add a discussion on faithfulness and the assumptions of the availability of large datasets to the manuscript . [ 1 ] J.-P.Pellet and A. Elisseeff . Using markov blankets for causal structure learning . Journal of Machine Learning Research , 2008 [ 2 ] Bengio , Yoshua . Learning deep architectures for AI . Foundations and trends in Machine Learning , 2009 [ 3 ] Bengio , Yoshua et . al , Representation learning : A review and new perspectives , arxiv 1206.5538 , 2012"}], "0": {"review_id": "H1gN6kSFwS-0", "review_text": "This paper proposes a MAML objective to learn causal graphs from data. The data in question is randomized but the algorithm does not have access to the identity of the intervention variable. So there is an added layer of complexity of deciphering which variable was intervened on. The MAML objective, in this case, links the causal structure to the slow-moving parameter theta_slow. The novelty of the paper seems to be in the application of the MAML framework to causal discovery which is interesting to me. I think a little theory about the sensitivity of the claim of ' theta slow changes relate to the causal structure ' is important. Even showing empirically which sort of graphs and functions become issues for the model would be useful. Here are my issues with the paper: - No error bars for cross-entropy are reported in the experiments. - The acyclic regularizer does not reject large length cycles than 3. - The ability to predict interventions seems to drop off sharply as the number of nodes increases. This suggests an inability to scale to more than 20 variables. - The experimental setup of uniformly sampling an intervening variable seems artificial to me. - MLP-specification of the SCM also seemed a bit artificial to me. Overall, the experiments look reasonable and the method itself seems interesting although further work is needed to show it is useful. (writing comments) The paper could use a more structured re-write. I had trouble tracking terms around the paper. For example, there seems to be a difference between P_i and P because the former uses theta_i and the latter only uses theta_slow only. --------------------------------- Updated score to 6 after rebuttal.", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the feedback . We have conducted additional experiments based on the feedback and will update our paper once the experiments are completed . Our paper is related to MAML like procedures for meta-learning , but goes beyond the usual setting , making a significant contribution through developing more sophisticated algorithms that enable causal structure learning . The difficulties those changes addressed are intrinsic to causal structure learning , especially in the challenging unknown-intervention scenario that we have set ourselves . The challenges we solve are 1 ) how to handle unknown interventions , 2 ) how to avoid an exponential search over all possible DAGs , 3 ) how to model the effect of the intervention , and finally 4 ) how to model the underlying causal structure . Q. \u201c No error bars for cross-entropy are reported in the experiments. \u201d We thank the reviewer for pointing this out . We have conducted additional experiments and will update our paper once the experiments have been completed . Q. \u201c The acyclic regularizer does not reject large length cycles than 3. \u2018 We appreciate the reviewer \u2019 s concern . The regularizer can be extended to length-n cycles , however , this becomes more computationally demanding as n increases . However , we found that a smaller n does not affect our model empirically . As shown in Figure 2 , 3 and 4 , our model did not learn cycles of any length greater than 2 . In fact , we have found that even completely removing this regularizer does not hurt the asymptotic performance of our model . The regularizer helps the model to converge faster , however , the model still converges reasonably fast without the regularizer , as shown in Figure 6 Right . Q. \u201c The ability to predict interventions seems to drop off sharply as the number of nodes increases. \u201d We are aware of this limitation . It makes sense that guessing which node has been intervened becomes harder as the number of nodes increases and we find that empirically , without surprise . We agree that it is a challenge to scale to larger graphs ( namely graphs with more than 20 variables ) , however even for the sizes of graphs we consider our paper finds greatly improved solutions and this is already a significant advance over past work . One extension we hope will help to overcome this difficulty would be to perform a soft prediction of the interventional nodes , instead of the hard decision that we have now . We also would like to highlight that the intervention prediction performs significantly better than random at all times . One note on the recent papers on this topic : although ICP and non-linear ICP consider a larger number of covariates , they only aim to identify the causal parents of one variable . This task alone already has exponential cost , which would be further increased if the algorithm were applied for reconstructing the whole graph by applying it iteratively to each node . Due to the computational cost , this is infeasible for larger graphs .. Other recent papers e.g . [ 1 ] likewise only consider similar number of variables given the computational cost of the proposed algorithms . In contrast one contribution of our paper is a proposal how to avoid an exponential search over all possible DAGs . [ 1 ] .Ghassami , AmirEmad , Saber Salehkaleybar , Negar Kiyavash , and Kun Zhang . `` Learning causal structures using regression invariance . '' In Advances in Neural Information Processing Systems , pp . 3011-3021 . 2017.Q. \u201c The experimental setup of uniformly sampling an intervening variable seems artificial to me. \u201d We thank the reviewer for pointing this out . We agree that in the real world , interventions rarely appear to be chosen uniformly randomly . However , given the lack of better real-world causal structures than those from the BNLearn graph repository , and the lack of a commonly-agreed intervention probability on each node , uniform sampling seemed reasonable . Doing otherwise would have required us to justify why we picked those specific intervention probabilities . However , if the reviewer has suggestions for specific non-uniform intervention probabilities , we will be happy to perform additional experiments with them ."}, "1": {"review_id": "H1gN6kSFwS-1", "review_text": "The paper develops a learning-based causal inference method that performs multiple tasks jointly: i) scalable discovery of the underlying Structured Causal Model (SCM) by modeling both structural assignments and the SCM as a continuously parameterized chain of distributions, ii) identification of the intervened variables, which are not known to the model a-priori unlike the mainstream causal inference setups, iii) achieving the two aforementioned goals using meta-learning driven heuristics, i.e. interventions cause distributional shifts. While the paper adopts the core design choices from recent prior art (Bengio et al., 2019), the proposed methodology (especially ii)) is sufficiently novel to be published as a main-track conference paper. The paper is very well-written, follows a concrete and easy-to-follow story line. It solves multiple ambitious problems end-to-end and justifies the methodological novelty claims by a properly conducted set of experiments. The paper also successfully employs simple and useful but forgotten old techniques such as fast/slow parameter decomposition in the proposed model pipeline. The intervention prediction heuristic is splendid. It is simple, sensible, and has been proven by experiments to be very effective. I would rate this as the primary novelty presented in this paper. The paper can be improved if the below relatively minor concerns are addressed: i) It would be informative if the paper had a paragraph discussing also the fundamental limitations of the approach more openly. For instance, the choice of the neural net architecture used for the structural assignment might have a huge impact on the outcome, especially because the same architecture is repetitively used for all variables of the SCM. Furthermore, treatment of each variable with a fully independent neural net could cause overparameterization as the SCM grows in number of variables. ii) The paper makes a strong scalability claim across the variable size thanks to independent Bernoullis assigned on the adjacency matrix entries. However, it reports results only for very small SCMs. It is understandable that given the premature stage of the causal inference research might not grant standardized data sets at a larger scale, but at least lack of this quantitative scalability test could be acknowledged and the related claims could be a little bit softened. iii) I do not buy the argument in the first paragraph of Sec 3.5 about why the structural assignment functions need to be independent. As the model does not pose a distribution on neural net weights, sharing some weights (i.e. conditioning on them) would only bring conditional independence across the variables. I do not see a solid reason to try to avoid this. What is wrong for multiple variables to share some functional characteristics in their structural assignment? After all, some sort of conditional independence will be inevitable in modeling. If the variables share the same architecture, this is also conditional independence, not full independence. Relaxing the independence assumption and allowing some weight sharing could be beneficial at least for scalability of the model, could even bring about improved model fit due to cross-variable knowledge transfer. Overall, none of the aforementioned three weaknesses is fundamental. In the status-quo, this is a spectactular research paper and my initial vote is an accept.", "rating": "8: Accept", "reply_text": "We are grateful to the reviewer for their enthusiastic feedback and comments ! Q : \u201c It would be informative if the paper had a paragraph discussing also the fundamental limitations of the approach more openly . For instance , the choice of the neural net architecture used for the structural assignment might have a huge impact on the outcome , especially because the same architecture is repetitively used for all variables of the SCM. \u201d We thank the reviewer for pointing this out . We had chosen to implement all variables using the same neural network architecture for computational reasons ( vectorization , batching ) , but it indeed might have had a significant impact on the learning process . A wider variety of architectures , incorporating heterogeneity in each variable \u2019 s model , would strengthen the case for the approach . There are , however , recent demonstrations that overparameterized neural networks can generalize well ( with some regularization ) [ 1 ] . This suggests that we may get away with deliberate over-parametrization , whether of each module separately or the whole network globally . The reviewer \u2019 s proposal below to allow some cross-variable parameter sharing is compatible with the latter ; The right capacity and level of sharing for each variable would then be allocated according to the different pressures from the data and the training objective . [ 1 ] .Belkin , Mikhail , Daniel Hsu , Siyuan Ma , and Soumik Mandal . `` Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off . '' Proceedings of the National Academy of Sciences 116 , no . 32 ( 2019 ) : 15849-15854 . Q. \u201c The paper makes a strong scalability claim across the variable size thanks to independent Bernoullis assigned on the adjacency matrix entries . However , it reports results only for very small SCMs . It is understandable that given the premature stage of the causal inference research might not grant standardized data sets at a larger scale , but at least lack of this quantitative scalability test could be acknowledged and the related claims could be a little bit softened. \u201d We thank the reviewer for pointing this out . We agree with the reviewer \u2019 s point and a necessary continuation of our work is to demonstrate scaling to larger graphs available from e.g.the Bayesian Networks Repository . We will soften our scalability claims to better accord with the size of the problems solved in the paper . Q. \u201c I do not buy the argument in the first paragraph of Sec 3.5 about why the structural assignment functions need to be independent . As the model does not pose a distribution on neural net weights , sharing some weights ( i.e.conditioning on them ) would only bring conditional independence across the variables . I do not see a solid reason to try to avoid this . What is wrong for multiple variables to share some functional characteristics in their structural assignment ? After all , some sort of conditional independence will be inevitable in modeling . If the variables share the same architecture , this is also conditional independence , not full independence . Relaxing the independence assumption and allowing some weight sharing could be beneficial at least for scalability of the model , could even bring about improved model fit due to cross-variable knowledge transfer. \u201d We appreciate the thought-provoking idea from the reviewer of cross-variable knowledge transfer via sharing . This is especially applicable to the real world setting , where it is likely that functional characteristics will be shared between variables of a similar nature . We will gladly investigate further this issue . Overall , we would like to thank the reviewer for the positive feedback and comments . We will perform the changes the reviewer recommends and relax the enforced independences to see if scalability or performance gains materialize ."}, "2": {"review_id": "H1gN6kSFwS-2", "review_text": "This paper proposes an SCM-model based on masked neural networks to capture arbitrary conditional relationships combined with meta-learning-style adaptation to reflect the effects of various unknown interventions. Overall the paper is well written and easy to follow, but some conceptual issues remain. - How come there is hardly any discussion of the identifiability issue beyond the few sentences in A.3. This is one of the key issues in learning SCMs and it is strange that the concept of \"faithfulness\" is not even mentioned in the paper. In general, there is hardly any discussion of what conditions are required for the proposed estimates to even be valid. The authors seem to be optimistically assuming that their neural network + metalearning model will somehow pick up on the correct structure, without any actual conceptual investigation of this issue. - The massive downside of neural nets is all the various hyperparameters one has to set (eg. architecture, optimizer, activations, etc). In this setting, how do the authors propose selecting hyperparameter values? How does the reader know the authors did not simply tune their hyperparameters to best match the underlying ground truth (I assume the proposed methodology has many more hyperparameters and thus more degrees of freedom here). I would like to see the empirical performance of different variants of your model with different hyperparameter values to assess its sensitivity to these choices. - Why does one even care about the graph being acylic in this setting? The mere fact that the authors require a regularizer to ensure acylicity suggests this approach is prone to mis-identifying the ground truth structure (which is always acyclic in the experiments). - One main reason for SCM modeling in science and policy-making is for analysts to better understand the data generating phenomena. However your use of neural networks here seems to hamper interpretability, so how do you reconcile this issue? Also is your sparsity regularizer satisfactory to confidently diagnose presence/absence of an edge (in constrast to statistical hypothesis tests, say based on conditional independence). Isn't this heavily influenced by the particular sparsity-regularizer value that happened to be selected? - Related papers that utilize the same idea of predicting a variable conditioned on subset of other variables via neural network + masking strategy: Ivanov et al (2019). VARIATIONAL AUTOENCODER WITH ARBITRARY CONDITIONING. https://openreview.net/pdf?id=SyxtJh0qYm Li et al (2019). Flow Models for Arbitrary Conditional Likelihoods. https://arxiv.org/abs/1909.06319 Yoon et al. GAIN: Missing data imputation using generative adversarial nets. Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, 2018. http://proceedings.mlr.press/v80/yoon18a.html Douglas et al. A universal marginalizer for amortized inference in generative models. arXiv preprint arXiv:1711.00695, 2017 For clarity, the authors should highlight the differences of their approach from these works (beyond the causal setting). - Given the lack of theoretical / conceptual guarantees that the methodology will work, our faith in the proposed methodology rests entirely on the empirical experiments. However, I find these a bit too basic to be very convincing, and would at least like to see more methods being compared (in particular for the simulated graphs as well). - The authors should describe what are the underlying interventions in each dataset a bit more. - The Figures should be better explained (took me a while to figure out what dots/colors represent). - Why do the authors report cross entropy loss in Table 1? To my knowledge this is not a standard metric for measuring the quality of structure-estimates. - Instead of ICP (which is constrained to be linear which is unrealistically simple), why don't the authors compare against nonlinearICP (which is more flexible like their neural networks): Heinze-Deml et al (2018). Invariant Causal Prediction for Nonlinear Models. https://arxiv.org/pdf/1706.08576.pdf", "rating": "3: Weak Reject", "reply_text": "We thank the reviewer for such detailed feedback . We are conducting additional experiments based on the feedback and will update the paper and rebuttal once the experiments are completed . The reviewer expresses several general concerns about the use of neural networks for causal inference , focusing on attributes such as their large design space and their interpretability . We would like to underscore that this paper is intended as a step from today \u2019 s completely non-causal neural networks towards incorporating more of the abilities required for handling causality . As such , our proposed method will indeed retain most of the benefits and limitations of neural networks , but improve on them by identifying causal structures . Q. \u201d How come there is hardly any discussion of the identifiability issue beyond the few sentences in A.3 . This is one of the key issues in learning SCMs and it is strange that the concept of `` faithfulness '' is not even mentioned in the paper . \u2026.In general , there is hardly any discussion of what conditions are required for the proposed estimates to even be valid . The authors seem to be optimistically assuming that their neural network + metalearning model will somehow pick up on the correct structure , without any actual conceptual investigation of this issue. \u201d Because our task setup allows a random intervention over any variable , per ( Eberhardt et al. , 2012 ) it is at least in theory possible to identify the correct graph . The rest of the paper was mostly directed at showing that this is not only possible in theory but in practice as well . We thank the reviewer for mentioning that some discussion of faithfulness would enhance the paper . There are several aspects that are relevant as listed below . Our model does indeed assume faithfulness , however , this is not a limitation in practice . Because of the continuous evolution of the functional parameters for the conditional distributions MLP , we believe that occurrences of unfaithful populations will be extremely short-lived and exceedingly rare to begin with . Lastly , because our procedure invokes an outer-loop optimization procedure , gradient estimate errors induced by unfaithfulness can be compensated . The faithfulness assumption ( Pearl 2009 , Peters et al.2017 ) implies that any d-separation in the graph corresponds to a conditional independence in the data generating random variables . Under the assumption of faithfulness and a sufficiently large sample size , the Markov blanket can consistently be recovered given the availability of an efficient feature selection algorithm [ 1 ] . Neural Networks have been shown to be able to learn good features [ 2 , 3 ] and require large datasets for training , which we assumed to be given here . We agree with the reviewer that similarly to the already mentioned assumptions of Markov equivalence and causal sufficiency ( see A.3 PRELIMINARIES ) we will add a discussion on faithfulness and the assumptions of the availability of large datasets to the manuscript . [ 1 ] J.-P.Pellet and A. Elisseeff . Using markov blankets for causal structure learning . Journal of Machine Learning Research , 2008 [ 2 ] Bengio , Yoshua . Learning deep architectures for AI . Foundations and trends in Machine Learning , 2009 [ 3 ] Bengio , Yoshua et . al , Representation learning : A review and new perspectives , arxiv 1206.5538 , 2012"}}