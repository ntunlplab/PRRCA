{"year": "2019", "forum": "Skluy2RcK7", "title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "decision": "Reject", "meta_review": "The paper examined the folk-knowledge that there are highly selective units in popular CNN architectures, and performed a detailed analysis of recent measures of unit selectivity, as well as introducing a novel one. The finding that units are not extremely selective in CNNs was intriguing to some (not all) reviewers. Further, they show recent measures of selectivity dramatically over-estimate selectivity.\n\nThere was not tight agreement amongst the reviewers on the paper's rating, but it trended towards rejection. Weaknesses highlighted by reviewers include lack of visual clarity in their demonstrations, the use of a several-generations-old CNN architecture, as well as a lack of enthusiasm for the findings.", "reviews": [{"review_id": "Skluy2RcK7-0", "review_text": "Summary: This paper explores different metrics to measure the \u2018selectivity\u2019 of single neurons for a class in deep neural networks. Using AlexNet as the model under study, the paper shows strengths and weaknesses of several recent methods in the literature. The paper conducts a psychophysics experiment to see if human subjects can reliably label images generated through activation maximization techniques. Major comments: This paper undertakes a careful analysis of different ways of measuring single-unit selectivity for a class. The conclusions drawn are that no neurons exhibit true localist selectivity, and most have some more complex selectivity. Some of the specific examples make this point very nicely (for instance, a unit that responds very strongly to several custard apples and would appear to be a custard apple detector, except that it responds extremely weakly to other custard apples). This is a somewhat negative result that may be useful in advancing the field away from single neuron analyses, which may be misleading. One worry is that the methods applied are looking for a very strong form of selectivity. In particular, even the output layer is judged to contain a low percentage of selective units according to the definitions in the paper. It may be worth considering slightly weakened versions of the metrics that allow for some errors. It would be useful to add discussion of the connections between these metrics and generalization performance. The class conditional selectivity metric, for instance, may not measure localist coding very directly, but it does correlate with important performance metrics like generalization performance. The discussion in Morcos 2018 suggests that high single unit selectivity is detrimental to generalization. Do these correlations persist using other metrics? The psychophysics experiment with human subjects appears to have been done to a high standard, and yields the result that only the very highest layers of a network yield interpretable images. This is somewhat interesting but unlikely to be that surprising, as selectivity for objects in lower layers is not a claim made by many works. In these lower layers, selectivity for \u2018object parts\u2019 is a claim that has been made and could potentially be addressed by the data collected. Overall this paper critically analyzes single unit selectivity measures, reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding. The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank R1 for their constructive comments and encouragement ! Please see the main reply to your general , main points . Below is our reply to your specific comments . > > R1 would like us to assess the role of selectivity and generalization as shown in Morcos ( 2018 ) . Response : In fact , Morcos et al.did not show this ( they showed that generalization related to a concept called \u201c single directions \u201d , but they never associated their selectivity measure CCMAS to generalization ) . We agree this is an interesting question , but it goes outside the scope of comparing selectivity measures . We would note that the Bowers ( 2016 ) paper was specifically concerned with the issue of generalization and selectivity in the context of a recurrent network , and in that paper , selectivity was required in order to generalize . In future work , it would be interesting to compare how selectivity and generalization relate in feedforward and recurrent networks . > > R1 : Overall this paper critically analyzes single unit selectivity measures , reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding . The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many . Response : We agree that the fact that we did not find 100 % -selective units in AlexNet might not too surprising , but that is only one contribution . The main and most important contribution in our work is that existing measures of selectivity in established literature can be misleading . That is impeding the community \u2019 s understanding and advancement of the Interpretability research . As noted above , our findings also highlight an interesting question for future research , namely , what are the conditions that do lead to 100 % selectivity , as observed by Bowers et al . ( 2014 , 2016 ) ."}, {"review_id": "Skluy2RcK7-1", "review_text": "Summary - This paper analyzes the selectivity of individual units in CNNs. The authors analyze existing techniques such as precision selectivity, class-conditional mean activity selection and localist sensitivity. These methods are analyzed in the context of AlexNet and ImageNet. The authors also use Activation Maximization (AM) techniques for visualizing single-unit representations in CNNs. Paper strengths - The authors have minutely examined each of the metrics and the underlying assumptions they make. - Example - Number of images used for computing the precision threshold in Zhou et al., 2014; The wrongly stated range of CCMAS [0, 1]. Considering the second highest CCMAS class is a good way of handling multiple classes that activate a single unit. - The results of this paper are surprising compared to existing work. The authors have made a surprising discovery and done a good job of both presenting it well and experimentally validating it. The paper raises interesting questions and this should inspire future work in understanding networks. - Figure 2 is insightful - It compares the various different interpretations of selectivity for a single unit in fc6. It shows how the mean activating class and the maximally activating class can be semantically very different. It also shows that despite the high precision and CCMAS score, the unit cannot be labelled as a detector for the single concept \"custard apple\". More such results are presented in the Appendix (e.g. Fig A6) - The human study in Section 3.3 is a good way to evaluate the generated AM images. Paper weaknesses - One of the major weaknesses of this paper is that it uses only ImageNet images to evaluate the units. As this is limited to 1000 classes, the authors cannot probe other visual concepts such as color, texture, materials for the units. As an example, Network dissection (Zhou et al., 2017) proposes a dataset called Broden which has many diverse sets of visual concepts labeled. This paper focuses only on one definition of selectivity - selecting objects. This should be made explicit and the authors have not done a good job of clarifying this assumption or showing that it exists. - All of the analysis is limited to AlexNet. With modern architectures that use residual/skip connections, it is not clear how well this analysis will generalize. It is an open question if the authors work overfits to AlexNet. - The jitterplots are hard to understand especially if there are many overlapping \"dots\" (samples). Since the y-axis values are not really meaningful anyway, using a histogram to see how many samples have a particular activation value is easier. A possible suggestion for Figure 2(a): split into two parts - 1) histogram of all samples; 2) histogram of the highest mean activating class. - The organization of the paper could be improved. The sections in the paper are not well connected.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank R2 for their constructive comments and encouragement ! Please see the main reply to all reviewers for the main points . Below is our reply to your specific comments . > > R2 points out that we are only concerned with object selectivity whereas Zhou et al . ( 2017 ) are concerned with different forms of selectivity , including selectivity to colour , etc . Response : This is true , and we have now emphasized that the focus of this paper is on object selectivity . There may well have been units selective to colour that our analyses may have missed , but this does not impact on our conclusion that the precision measure provides a misleading measure of selectivity ( not only misleading for objects , but for the same reason , misleading for colour , etc . ) . > > R2 said : It is an open question if the authors work overfits to AlexNet . Response : The method of comparing selectivity measures could be applied to any NN , and AlexNet 's activation patterns are similar to other NNs , so we think another NN would also show similar qualitative pattern of low object selectivity in the hidden layers , and we still expect the selectivity metrics to underestimate this . Our preliminary results with other networks do look similar . Where AlexNet differs , perhaps , is in the quality and style of AM images that are found , so that part of our analysis may be different , and this is something we intend to investigate in the future ."}, {"review_id": "Skluy2RcK7-2", "review_text": "This is a paper with scattered potentially interesting ideas. But the execution is limited and the writing poor with critical details lacking. A major limitation of the paper is that it is not clear what contribution it makes. Some of the analyses are indeed interesting but 1) these analyses are mostly descriptive and 2) they are limited to one particular (outdated) architecture. How would batch norm or residual connections or any of the developments that have happened since AlexNet affect these results? As a side note, the references/comparisons between AlexNet and recurrent nets (see abstract, etc) are misleading. This is based on the claim that Bowers et al (2014) qualitatively different results but this is for entirely different domains (words). Indeed what could have made potentially the work more relevant would have been to show some kind of benchmarking between AlexNet and alternative architectures (possibly RNNs). As such the current study does not contribute much except for comparing different semi-arbitrary measures of selectivity for one specific (outdated) network architecture trained on a particular problem (ILSVRC). **** Minor points: The study is limited to correctly classified images as stated on page 3. This seems like a major confound in a study aimed at understanding the visual representations learned. It seems to me that the conclusions of the paper could be heavily biased because of this (when computing any measure based on inter and intraclass responses). In general, this is a relatively poorly written paper which would be hard to reproduce. For instance, the image generation for activating units (assuming it is novel) could be interesting but it is not even described with sufficient details so as to reproduce the results.", "rating": "3: Clear rejection", "reply_text": "> > R3 said that our results would be hard to reproduce . Response : The procedures for computing precision and CCMAS measures have been published elsewhere and cited ( and we explain how they are computed ) , and we have provided the equation for computing top-class selectivity . We also cite the paper that describes how to generate the images that maximally activated the units . In order to facilitate replication we have uploaded a file that contains all the activations of correctly identified images as an h5 file and provide a link in the paper . > > R3 said the image generation for activating units ( assuming it is novel ) could be interesting but it is not even described with sufficient details so as to reproduce the results . Response : The process of generating Activation Maximization ( AM ) images follow exactly a state-of-the-art AM method in Nguyen et al.2017 via their open-source code . We thank the reviewer for pointing this out ! : ) We have updated the manuscript to add more details and make this clearer . > > R3 said that \u2018 The study is limited to correctly classified images as stated on page 3 . This seems like a major confound in a study aimed at understanding the visual representations learned. \u2019 Response : We do not understand this point . It is not appropriate to compute the selectivity of a unit when misclassified images are included . For the sake of argument , imagine you have found a unit that appears to be 100 % selective to DOGS . What should you conclude if the unit does not activate to an image of a DOG that is misclassified as a CAT . Should you conclude that it is not a 100 % DOG detector ? Of course not \u2013 the DOG detector did not fire because the model did not know it was a DOG . If you are interested in whether a unit is selective to a given category the model needs to correctly identify the category . It is an interesting question as to why models sometimes misclassify images , but goes beyond the topic of this paper ."}], "0": {"review_id": "Skluy2RcK7-0", "review_text": "Summary: This paper explores different metrics to measure the \u2018selectivity\u2019 of single neurons for a class in deep neural networks. Using AlexNet as the model under study, the paper shows strengths and weaknesses of several recent methods in the literature. The paper conducts a psychophysics experiment to see if human subjects can reliably label images generated through activation maximization techniques. Major comments: This paper undertakes a careful analysis of different ways of measuring single-unit selectivity for a class. The conclusions drawn are that no neurons exhibit true localist selectivity, and most have some more complex selectivity. Some of the specific examples make this point very nicely (for instance, a unit that responds very strongly to several custard apples and would appear to be a custard apple detector, except that it responds extremely weakly to other custard apples). This is a somewhat negative result that may be useful in advancing the field away from single neuron analyses, which may be misleading. One worry is that the methods applied are looking for a very strong form of selectivity. In particular, even the output layer is judged to contain a low percentage of selective units according to the definitions in the paper. It may be worth considering slightly weakened versions of the metrics that allow for some errors. It would be useful to add discussion of the connections between these metrics and generalization performance. The class conditional selectivity metric, for instance, may not measure localist coding very directly, but it does correlate with important performance metrics like generalization performance. The discussion in Morcos 2018 suggests that high single unit selectivity is detrimental to generalization. Do these correlations persist using other metrics? The psychophysics experiment with human subjects appears to have been done to a high standard, and yields the result that only the very highest layers of a network yield interpretable images. This is somewhat interesting but unlikely to be that surprising, as selectivity for objects in lower layers is not a claim made by many works. In these lower layers, selectivity for \u2018object parts\u2019 is a claim that has been made and could potentially be addressed by the data collected. Overall this paper critically analyzes single unit selectivity measures, reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding. The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many. ", "rating": "5: Marginally below acceptance threshold", "reply_text": "We thank R1 for their constructive comments and encouragement ! Please see the main reply to your general , main points . Below is our reply to your specific comments . > > R1 would like us to assess the role of selectivity and generalization as shown in Morcos ( 2018 ) . Response : In fact , Morcos et al.did not show this ( they showed that generalization related to a concept called \u201c single directions \u201d , but they never associated their selectivity measure CCMAS to generalization ) . We agree this is an interesting question , but it goes outside the scope of comparing selectivity measures . We would note that the Bowers ( 2016 ) paper was specifically concerned with the issue of generalization and selectivity in the context of a recurrent network , and in that paper , selectivity was required in order to generalize . In future work , it would be interesting to compare how selectivity and generalization relate in feedforward and recurrent networks . > > R1 : Overall this paper critically analyzes single unit selectivity measures , reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding . The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many . Response : We agree that the fact that we did not find 100 % -selective units in AlexNet might not too surprising , but that is only one contribution . The main and most important contribution in our work is that existing measures of selectivity in established literature can be misleading . That is impeding the community \u2019 s understanding and advancement of the Interpretability research . As noted above , our findings also highlight an interesting question for future research , namely , what are the conditions that do lead to 100 % selectivity , as observed by Bowers et al . ( 2014 , 2016 ) ."}, "1": {"review_id": "Skluy2RcK7-1", "review_text": "Summary - This paper analyzes the selectivity of individual units in CNNs. The authors analyze existing techniques such as precision selectivity, class-conditional mean activity selection and localist sensitivity. These methods are analyzed in the context of AlexNet and ImageNet. The authors also use Activation Maximization (AM) techniques for visualizing single-unit representations in CNNs. Paper strengths - The authors have minutely examined each of the metrics and the underlying assumptions they make. - Example - Number of images used for computing the precision threshold in Zhou et al., 2014; The wrongly stated range of CCMAS [0, 1]. Considering the second highest CCMAS class is a good way of handling multiple classes that activate a single unit. - The results of this paper are surprising compared to existing work. The authors have made a surprising discovery and done a good job of both presenting it well and experimentally validating it. The paper raises interesting questions and this should inspire future work in understanding networks. - Figure 2 is insightful - It compares the various different interpretations of selectivity for a single unit in fc6. It shows how the mean activating class and the maximally activating class can be semantically very different. It also shows that despite the high precision and CCMAS score, the unit cannot be labelled as a detector for the single concept \"custard apple\". More such results are presented in the Appendix (e.g. Fig A6) - The human study in Section 3.3 is a good way to evaluate the generated AM images. Paper weaknesses - One of the major weaknesses of this paper is that it uses only ImageNet images to evaluate the units. As this is limited to 1000 classes, the authors cannot probe other visual concepts such as color, texture, materials for the units. As an example, Network dissection (Zhou et al., 2017) proposes a dataset called Broden which has many diverse sets of visual concepts labeled. This paper focuses only on one definition of selectivity - selecting objects. This should be made explicit and the authors have not done a good job of clarifying this assumption or showing that it exists. - All of the analysis is limited to AlexNet. With modern architectures that use residual/skip connections, it is not clear how well this analysis will generalize. It is an open question if the authors work overfits to AlexNet. - The jitterplots are hard to understand especially if there are many overlapping \"dots\" (samples). Since the y-axis values are not really meaningful anyway, using a histogram to see how many samples have a particular activation value is easier. A possible suggestion for Figure 2(a): split into two parts - 1) histogram of all samples; 2) histogram of the highest mean activating class. - The organization of the paper could be improved. The sections in the paper are not well connected.", "rating": "6: Marginally above acceptance threshold", "reply_text": "We thank R2 for their constructive comments and encouragement ! Please see the main reply to all reviewers for the main points . Below is our reply to your specific comments . > > R2 points out that we are only concerned with object selectivity whereas Zhou et al . ( 2017 ) are concerned with different forms of selectivity , including selectivity to colour , etc . Response : This is true , and we have now emphasized that the focus of this paper is on object selectivity . There may well have been units selective to colour that our analyses may have missed , but this does not impact on our conclusion that the precision measure provides a misleading measure of selectivity ( not only misleading for objects , but for the same reason , misleading for colour , etc . ) . > > R2 said : It is an open question if the authors work overfits to AlexNet . Response : The method of comparing selectivity measures could be applied to any NN , and AlexNet 's activation patterns are similar to other NNs , so we think another NN would also show similar qualitative pattern of low object selectivity in the hidden layers , and we still expect the selectivity metrics to underestimate this . Our preliminary results with other networks do look similar . Where AlexNet differs , perhaps , is in the quality and style of AM images that are found , so that part of our analysis may be different , and this is something we intend to investigate in the future ."}, "2": {"review_id": "Skluy2RcK7-2", "review_text": "This is a paper with scattered potentially interesting ideas. But the execution is limited and the writing poor with critical details lacking. A major limitation of the paper is that it is not clear what contribution it makes. Some of the analyses are indeed interesting but 1) these analyses are mostly descriptive and 2) they are limited to one particular (outdated) architecture. How would batch norm or residual connections or any of the developments that have happened since AlexNet affect these results? As a side note, the references/comparisons between AlexNet and recurrent nets (see abstract, etc) are misleading. This is based on the claim that Bowers et al (2014) qualitatively different results but this is for entirely different domains (words). Indeed what could have made potentially the work more relevant would have been to show some kind of benchmarking between AlexNet and alternative architectures (possibly RNNs). As such the current study does not contribute much except for comparing different semi-arbitrary measures of selectivity for one specific (outdated) network architecture trained on a particular problem (ILSVRC). **** Minor points: The study is limited to correctly classified images as stated on page 3. This seems like a major confound in a study aimed at understanding the visual representations learned. It seems to me that the conclusions of the paper could be heavily biased because of this (when computing any measure based on inter and intraclass responses). In general, this is a relatively poorly written paper which would be hard to reproduce. For instance, the image generation for activating units (assuming it is novel) could be interesting but it is not even described with sufficient details so as to reproduce the results.", "rating": "3: Clear rejection", "reply_text": "> > R3 said that our results would be hard to reproduce . Response : The procedures for computing precision and CCMAS measures have been published elsewhere and cited ( and we explain how they are computed ) , and we have provided the equation for computing top-class selectivity . We also cite the paper that describes how to generate the images that maximally activated the units . In order to facilitate replication we have uploaded a file that contains all the activations of correctly identified images as an h5 file and provide a link in the paper . > > R3 said the image generation for activating units ( assuming it is novel ) could be interesting but it is not even described with sufficient details so as to reproduce the results . Response : The process of generating Activation Maximization ( AM ) images follow exactly a state-of-the-art AM method in Nguyen et al.2017 via their open-source code . We thank the reviewer for pointing this out ! : ) We have updated the manuscript to add more details and make this clearer . > > R3 said that \u2018 The study is limited to correctly classified images as stated on page 3 . This seems like a major confound in a study aimed at understanding the visual representations learned. \u2019 Response : We do not understand this point . It is not appropriate to compute the selectivity of a unit when misclassified images are included . For the sake of argument , imagine you have found a unit that appears to be 100 % selective to DOGS . What should you conclude if the unit does not activate to an image of a DOG that is misclassified as a CAT . Should you conclude that it is not a 100 % DOG detector ? Of course not \u2013 the DOG detector did not fire because the model did not know it was a DOG . If you are interested in whether a unit is selective to a given category the model needs to correctly identify the category . It is an interesting question as to why models sometimes misclassify images , but goes beyond the topic of this paper ."}}