{"year": "2017", "forum": "Hy-2G6ile", "title": "Gated Multimodal Units for Information Fusion", "decision": "Invite to Workshop Track", "meta_review": "The authors propose a Gated Muiltimodal Unit to combine multi-modal information (visual and textual). They also collect a large dataset of movie summers and posters. Overall, the reviewers were quite positive, while AR4 points to related models and feels that the contribution in the current version is too weak for ICLR. The AC read the paper and the authors responses but tends to agree with AR4. The authors are encouraged to strengthen their work and resubmit to a future conference.", "reviews": [{"review_id": "Hy-2G6ile-0", "review_text": "This paper proposed The Gated Multimodal Unit (GMU) model for information fusion. The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates. The paper collected a large genre dataset from IMDB and showed that GMU gets good performance. The proposed approach seems quite interesting, and the audience may expect it can be used in general scenarios beyond movie genre prediction. So it is quite straightforward that the paper should test the algorithm in other applications, which was not done yet. That is the biggest shortcoming of this paper in my opinions. Another concern lies in how to evaluate the performance of information fusion. The abstract claims \"The model improves the macro f-score performance of single-modality models by 30% and 4% with respect to visual and textual information respectively\", however, such an improvement is off the key. If two modals are complementary to each other, the fusion results will always be higher. The key fact is how much better than baselines the proposed GMU is. There is a long list of techniques for fusions, so it is difficult to conduct an impressive comparison on only one real dataset. I think GMU did a nice work on movie dataset, but I would also expect other techniques, including fine-tuning, dropout, distillation may help too. It would be nice if the author could compare these techniques. I also hope this paper could talk in more details the connection with mixture-of-expert (MoE) model. Both models are based on the nonlinear gated functions, while both method may suffer from local minimum for optimization on small datasets. I would like more in-depth discussion in their similarity and difference. To gain more attention for GMU, I would encourage the author to open-source their code and try more datasets.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your review . Our comments are embedded below . `` .. the paper should test the algorithm in other applications ... '' . We agree the model should be tested in more applications . However , as stated in another submission related to multimodal learning ( https : //openreview.net/forum ? id=rJJ3YU5ge ) and to the best of our knowledge , there are not standard multimodal datasets , most of the open multimodal datasets task involves the mapping from one modality to another ( e.g.image captioning ) rather than finding a way to combining them to improve the performance in the particular task . Indeed , this was the main motivation to build a publicly available dataset . We \u2019 ll evaluate another preliminary dataset we have been collecting composed of books with their covers , however we would appreciate any suggestion for other standard dataset to be included as well . `` Another concern lies in how to evaluate the performance of information fusion . The abstract claims `` The model improves the macro f-score performance of single-modality models by 30 % and 4 % with respect to visual and textual information respectively '' , however , such an improvement is off the key . If two modals are complementary to each other , the fusion results will always be higher . The key fact is how much better than baselines the proposed GMU is . '' We agree that the main comparison it is not with single but with multimodal approaches , and thus the abstract should emphasize it . Unfortunately , the phrase you quote was part of one of the first versions of our paper and we missed to update it with our last findings ( we \u2019 ll update it in the next revision ) . We compared the model with two early fusion models ( concatenate and linear sum ) which have proven to be a good way to combine multimodal features . We also compared with a simpler late fusion strategy ( avg_probs ) . GMU obtained better results in all metric reported for this multilabel task . `` ... I would also expect other techniques , including fine-tuning , dropout , distillation may help too . It would be nice if the author could compare these techniques . '' We initially avoided fine-tuning VGG and the word vectors because it could easily overfit our dataset ( ~16K training samples Vs. 138M ( VGG ) , 12M ( word vectors ) of parameters ) . We included dropout as regularization strategy , but it is not clear for us how can be used as fusion strategy . We 'll try fine-tuning both representations and look at distillation as a late fusion strategy . `` I also hope this paper could talk in more details the connection with mixture-of-expert ( MoE ) model . Both models are based on the nonlinear gated functions , while both method may suffer from local minimum for optimization on small datasets . I would like more in-depth discussion in their similarity and difference . '' We \u2019 ll add a more detailed discussion of MoE Vs GMU . We \u2019 ll also train the MoE with the best model of each modality , and discuss the results . `` To gain more attention for GMU , I would encourage the author to open-source their code and try more datasets . '' So far , we \u2019 ve focused on releasing the dataset , but we also plan to release the code as soon as possible . We want to refactor it so that it could be easy to use and to reproduce these results ."}, {"review_id": "Hy-2G6ile-1", "review_text": "Paper proposes Gated Muiltimodal Unit, a building block for connectionist models capable of handling multiple modalities. (Figure 2) The bimodal case returns weighted activation by gains of gating units, do you do anything special to keep multi-modal case weighted as well? I.e. how the equation for h in section 3.1 would look like for multi-modal case. Also what\u2019s the rationale for using tanh nonlinearity (over, say RELU), is it somehow experimentally optimised choice? I would find interesting a discussion on a possibility of handling missing data in case one or more modalities are unavailable at test time. Is this possible in the current model to back-off to fewer modalities? Synthetic example may suggest that\u2019s in fact possible. Those numbers, perhaps, could be added to table 2. In the synthetic experiment, you should compare MGU with the fully-connected MLP model really, with similar complexity - that is - at least two hidden units (as GMU has two such for each modality) followed by logistic regression. At least in terms of capability of drawing decision boundary, those should be comparable. I think, broader discussion shall be written on the related work associated with mixture of experts models (which is fact are very similar conceptually) as well as multiplicative RNN models [1]. Also, gating unit in LSTM can, in principle, play very similar role when multiple modalities are spliced in the input. Overall, the paper is interesting, so is the associated (and to be released) dataset. Minor comments/typos: Sec. 3.3: layers and a MLP (see Section 3.4) -> layers and an MLP Apologies for unacceptably late review. [1] Multiplicative LSTM for sequence modelling B Krause, L Lu, I Murray, S Renals ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your review . These are our comments : 1 . We proposed untied weights for the multi-modal case , i.e.there is a different linear transformation for each gate ( rendered latex : http : //i.imgur.com/zzyq27I.gif ) : h_i = tanh ( W_i x_i ) \\\\ z_i = \\sigma ( W_ { z_i } [ x_1 , x_2 , ... , x_k ] ) \\\\ h = \\sum_i z_i h_i Since we have not addressed the multi-modal scenario , this formulation is opened to experimental evaluation . 2.Following the gated units in recurrent networks ( e.g GRUs , LSTMs ) , we fixed this tanh activation function . However , this is also a choice to be made when building the neural network architecture . 3.An MLP with two hidden units is also able to solve the task . However , it is not clear how the model is dealing with the added noise , you can see the plot for the same synthetic dataset used in Figure 7 using the MLP with 2 hidden units in http : //i.imgur.com/Bjsdlbl.png 4 . We agree.We \u2019 ll extend the discussion and experimentation for the comparison with other gated models ."}, {"review_id": "Hy-2G6ile-2", "review_text": "The paper introduces Gated Multimodal Units GMUs, which use multiplicative weights to select the degree to which a hidden unit will consider different modalities in determining its activation. The paper also introduces a new dataset, \"Multimodal IMDb,\" consisting of over 25k movie summaries, with their posters, and labeled genres. GMUs are related to \"mixture of experts\" in that different examples will be classified by different parts of the model, (but rather than routing/gating entire examples, individual hidden units are gated separately). They are related to attention models in that different parts of the input are weighted differently; there the emphasis is on gating modalities of input. The dataset is a very nice contribution, and there are many experiments varying text representation and single-modality vs two-modality. What the paper is lacking is a careful discussion, experimentation and analysis in comparison to other multiplicative gate models---which is the core intellectual contribution of the paper. For example, I could imagine that a mixture of experts or attention models or other gated models might perform very well, and at the very least provide interesting scientific comparative analysis. I encourage the authors to continue the work, and submit a revised paper when ready. As is, I consider the paper to be a good workshop paper, but not ready for a major conference.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks for your review . We will focus on including other gated models for comparison and including a more elaborated comparison between GMU and other multiplicative architectures . We also thank you for suggesting our work to the workshop , we would be glad to share it on this event ."}], "0": {"review_id": "Hy-2G6ile-0", "review_text": "This paper proposed The Gated Multimodal Unit (GMU) model for information fusion. The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates. The paper collected a large genre dataset from IMDB and showed that GMU gets good performance. The proposed approach seems quite interesting, and the audience may expect it can be used in general scenarios beyond movie genre prediction. So it is quite straightforward that the paper should test the algorithm in other applications, which was not done yet. That is the biggest shortcoming of this paper in my opinions. Another concern lies in how to evaluate the performance of information fusion. The abstract claims \"The model improves the macro f-score performance of single-modality models by 30% and 4% with respect to visual and textual information respectively\", however, such an improvement is off the key. If two modals are complementary to each other, the fusion results will always be higher. The key fact is how much better than baselines the proposed GMU is. There is a long list of techniques for fusions, so it is difficult to conduct an impressive comparison on only one real dataset. I think GMU did a nice work on movie dataset, but I would also expect other techniques, including fine-tuning, dropout, distillation may help too. It would be nice if the author could compare these techniques. I also hope this paper could talk in more details the connection with mixture-of-expert (MoE) model. Both models are based on the nonlinear gated functions, while both method may suffer from local minimum for optimization on small datasets. I would like more in-depth discussion in their similarity and difference. To gain more attention for GMU, I would encourage the author to open-source their code and try more datasets.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for your review . Our comments are embedded below . `` .. the paper should test the algorithm in other applications ... '' . We agree the model should be tested in more applications . However , as stated in another submission related to multimodal learning ( https : //openreview.net/forum ? id=rJJ3YU5ge ) and to the best of our knowledge , there are not standard multimodal datasets , most of the open multimodal datasets task involves the mapping from one modality to another ( e.g.image captioning ) rather than finding a way to combining them to improve the performance in the particular task . Indeed , this was the main motivation to build a publicly available dataset . We \u2019 ll evaluate another preliminary dataset we have been collecting composed of books with their covers , however we would appreciate any suggestion for other standard dataset to be included as well . `` Another concern lies in how to evaluate the performance of information fusion . The abstract claims `` The model improves the macro f-score performance of single-modality models by 30 % and 4 % with respect to visual and textual information respectively '' , however , such an improvement is off the key . If two modals are complementary to each other , the fusion results will always be higher . The key fact is how much better than baselines the proposed GMU is . '' We agree that the main comparison it is not with single but with multimodal approaches , and thus the abstract should emphasize it . Unfortunately , the phrase you quote was part of one of the first versions of our paper and we missed to update it with our last findings ( we \u2019 ll update it in the next revision ) . We compared the model with two early fusion models ( concatenate and linear sum ) which have proven to be a good way to combine multimodal features . We also compared with a simpler late fusion strategy ( avg_probs ) . GMU obtained better results in all metric reported for this multilabel task . `` ... I would also expect other techniques , including fine-tuning , dropout , distillation may help too . It would be nice if the author could compare these techniques . '' We initially avoided fine-tuning VGG and the word vectors because it could easily overfit our dataset ( ~16K training samples Vs. 138M ( VGG ) , 12M ( word vectors ) of parameters ) . We included dropout as regularization strategy , but it is not clear for us how can be used as fusion strategy . We 'll try fine-tuning both representations and look at distillation as a late fusion strategy . `` I also hope this paper could talk in more details the connection with mixture-of-expert ( MoE ) model . Both models are based on the nonlinear gated functions , while both method may suffer from local minimum for optimization on small datasets . I would like more in-depth discussion in their similarity and difference . '' We \u2019 ll add a more detailed discussion of MoE Vs GMU . We \u2019 ll also train the MoE with the best model of each modality , and discuss the results . `` To gain more attention for GMU , I would encourage the author to open-source their code and try more datasets . '' So far , we \u2019 ve focused on releasing the dataset , but we also plan to release the code as soon as possible . We want to refactor it so that it could be easy to use and to reproduce these results ."}, "1": {"review_id": "Hy-2G6ile-1", "review_text": "Paper proposes Gated Muiltimodal Unit, a building block for connectionist models capable of handling multiple modalities. (Figure 2) The bimodal case returns weighted activation by gains of gating units, do you do anything special to keep multi-modal case weighted as well? I.e. how the equation for h in section 3.1 would look like for multi-modal case. Also what\u2019s the rationale for using tanh nonlinearity (over, say RELU), is it somehow experimentally optimised choice? I would find interesting a discussion on a possibility of handling missing data in case one or more modalities are unavailable at test time. Is this possible in the current model to back-off to fewer modalities? Synthetic example may suggest that\u2019s in fact possible. Those numbers, perhaps, could be added to table 2. In the synthetic experiment, you should compare MGU with the fully-connected MLP model really, with similar complexity - that is - at least two hidden units (as GMU has two such for each modality) followed by logistic regression. At least in terms of capability of drawing decision boundary, those should be comparable. I think, broader discussion shall be written on the related work associated with mixture of experts models (which is fact are very similar conceptually) as well as multiplicative RNN models [1]. Also, gating unit in LSTM can, in principle, play very similar role when multiple modalities are spliced in the input. Overall, the paper is interesting, so is the associated (and to be released) dataset. Minor comments/typos: Sec. 3.3: layers and a MLP (see Section 3.4) -> layers and an MLP Apologies for unacceptably late review. [1] Multiplicative LSTM for sequence modelling B Krause, L Lu, I Murray, S Renals ", "rating": "7: Good paper, accept", "reply_text": "Thanks for your review . These are our comments : 1 . We proposed untied weights for the multi-modal case , i.e.there is a different linear transformation for each gate ( rendered latex : http : //i.imgur.com/zzyq27I.gif ) : h_i = tanh ( W_i x_i ) \\\\ z_i = \\sigma ( W_ { z_i } [ x_1 , x_2 , ... , x_k ] ) \\\\ h = \\sum_i z_i h_i Since we have not addressed the multi-modal scenario , this formulation is opened to experimental evaluation . 2.Following the gated units in recurrent networks ( e.g GRUs , LSTMs ) , we fixed this tanh activation function . However , this is also a choice to be made when building the neural network architecture . 3.An MLP with two hidden units is also able to solve the task . However , it is not clear how the model is dealing with the added noise , you can see the plot for the same synthetic dataset used in Figure 7 using the MLP with 2 hidden units in http : //i.imgur.com/Bjsdlbl.png 4 . We agree.We \u2019 ll extend the discussion and experimentation for the comparison with other gated models ."}, "2": {"review_id": "Hy-2G6ile-2", "review_text": "The paper introduces Gated Multimodal Units GMUs, which use multiplicative weights to select the degree to which a hidden unit will consider different modalities in determining its activation. The paper also introduces a new dataset, \"Multimodal IMDb,\" consisting of over 25k movie summaries, with their posters, and labeled genres. GMUs are related to \"mixture of experts\" in that different examples will be classified by different parts of the model, (but rather than routing/gating entire examples, individual hidden units are gated separately). They are related to attention models in that different parts of the input are weighted differently; there the emphasis is on gating modalities of input. The dataset is a very nice contribution, and there are many experiments varying text representation and single-modality vs two-modality. What the paper is lacking is a careful discussion, experimentation and analysis in comparison to other multiplicative gate models---which is the core intellectual contribution of the paper. For example, I could imagine that a mixture of experts or attention models or other gated models might perform very well, and at the very least provide interesting scientific comparative analysis. I encourage the authors to continue the work, and submit a revised paper when ready. As is, I consider the paper to be a good workshop paper, but not ready for a major conference.", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thanks for your review . We will focus on including other gated models for comparison and including a more elaborated comparison between GMU and other multiplicative architectures . We also thank you for suggesting our work to the workshop , we would be glad to share it on this event ."}}