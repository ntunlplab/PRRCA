{"year": "2021", "forum": "xrLrpG3Ep1X", "title": "Domain-Free Adversarial Splitting for Domain Generalization", "decision": "Reject", "meta_review": "The paper is proposing a domain generalization method based on the intuition that an invariant model would work for any split of train/val. Hence, the method uses adversarial train/val splits during training. The paper is reviewed by three expert reviews and none of them championed the paper to be accepted. I carefully checked the reviews and the authors' response and agree with the reviewers. Specifically:\n\n- R#1: Argues that the paper is not ready for publication. Also argues the optimization problem is only a motivation as it is not directly solved. This is an important issue and it needs to be addressed in a conclusive manner.\n- R#2: Argues empirical studies do not show the value of train/val splitting. I partially disagree with this issue but it is clear that more qualitative and quantitative study is needed to properly justify the proposed method.\n- R#3: Argues the contribution is not enough for publication. The paper is clearly novel but the contribution and novelty is not presented in a clear manner. Moreover, the empirical study does not complement the novelty. Hence, I disagree with the comment.\n\nOverall, I believe the paper proposes an interesting idea. However, the presentation and empirical studies need to be improved significantly. I recommend authors to address these issues and submit to the next conference.\n\n", "reviews": [{"review_id": "xrLrpG3Ep1X-0", "review_text": "$ Paper $ $ summary $ This paper focuses on domain generalization , targeting the challenging scenario where the training set might not include different sources ; even under the presence of different sources , the problem formulation does not takes into account domain labels . The proposed solution is based on meta-learning , following the path drawn by Li et al.AAAI 2018 ; the Authors propose to adversarially split the training set in meta-train and meta-validation sets , and then update the current model in a direction that fosters good generalization performance on the meta-test . Results on standard benchmarks are encouraging . $ Pros $ - The proposed idea is rather interesting , enabling to apply meta-learning solutions also in absence of domain labels . In particular , I like the idea of finding meta-train and meta-test splits in an adversarial fashion . This is crucial , since randomly splitting the training set in meta-train and meta-validation would not be helpful , since it would lead to episodes where meta-train and meta-test are iid . - The Authors provide a theoretical interpretation of their approach ( due to my background , I was not able to properly review it though ) $ Cons $ - My main concern is related to the way the maximization problem is tackled , in the objective in Eq . ( 5 ) .I have reviewed Appendix C , but I can not understand how convergence would require so few iterations . Even restricting the size of $ S_v $ as mentioned in Section 3. , the number of possible sample combinations that generate couples ( $ S_v $ , $ S_t $ ) is huge -- if I understood the process correctly , then with $ |S_v|=K $ and $ |S|=N $ , the number of combinations is $ \\binom { N } { K } $ -- and for each of them the gradients that lead to the meta-update are different . Could the authors comment on this ? Am I missing something ? Related to this point , I am also concerned by the ablation study in Table 5 - where it is shown that , while helpful , the adversarial strategy does not help very significantly in the whole picture . - The overall writing could be improved . Sentences like `` this model can be further transfored to a minimax problem '' in the Abstract are not properly exposed , and there are several examples throughout the manuscript . There is a misconception related to prior work : Carlucci et al.2019 ( as well as Volpi et al.2018 ) also tackles the case where the training data only comprises a single source domain . This should be clarified in the Introduction/Related work . $ Review $ $ summary $ I like the idea this paper starts from , and I like the proposed solution . I still do not properly understand how the maximization problem at the core of the method is approached , and I believe that the paper needs some exhaustive proof checking to improve the overall writing . I look forward reading the Author response and iterating the discussion . - Post-rebuttal comments- I thank the Authors for their explanations . Yet , I still believe that this work is not ready for publication . Random splitting and adversarial splitting perform very comparably ( 1 % is not a lot ) , in my opinion casting some doubts on how meaningful the solution found to the proposed optimization problem is . The Authors included a toy example in the Appendix , but this did not mitigate my concerns on the original manuscript 's experiments . I still believe that the core idea is very interesting , and hope that it will be further investigated by the Authors for a subsequent submission .", "rating": "5: Marginally below acceptance threshold", "reply_text": "__R1-Q3__ : Improving the overall writing Thanks for your suggestions . We will replace \u201c This model can be further transformed to a min-max problem \u201d by \u201c To achieve this goal , we propose a min-max optimization problem \u201d in Abstract . The similar sentences will be revised accordingly in Sect.1 and Sect . 3.We will carefully revise the whole paper to improve the overall writing . We will discuss the works of Carlucci et al.2019 and Volpi et al.2018 in the Introduction and Related Works . They tackle the setting that training set comprises a single domain , and the train and test data are from different domains . Our domain-free setting method is flexible without assumptions on the requirement of domain labels and different domains of training and test data . Moreover , in methodology , these two methods mainly focus on augmenting new data to increase training data . Our method adversarially splits training dataset to train learner via meta-learning approach to enhance the generalization ability of learner . Experimental results in Table 3 show that our proposed DFAS outperforms JiGen ( Carlucci et al.2019 ) ( 66.6 % vs. 54.6 % ) ."}, {"review_id": "xrLrpG3Ep1X-1", "review_text": "This paper proposes to unify adversarial training and meta-learning in domain-free generalization where labels of source domains are unavailable . To maximize the domain shift between the subsets of meta-train and meta-val , adversarial training is leveraged to find the worst-case train/val splits . Extensive experiments on benchmark datasets under different settings demonstrate the effectiveness of the proposed method . Pros : + The idea of adversarial train/val splitting in meta-learning is interesting . + The paper provides extensive experiments on benchmark datasets under different settings with multiple/single source domains and achieves state-of-the-art results on both PACS and Office-Home datasets . + The paper provides an upper bound of the generalization error on unseen target domains , which is implicitly minimized by the proposed method . Major Cons : - The effectiveness of adversarial train/val splitting is not well justified . Typically , meta-learning based methods ( MASF and MetaReg ) have no overlap between domains used for meta-train and meta-val . This is how the domain discrepancy between meta-train and meta-val can be modeled . However , DFAS has the issue that the same domain may be used in both meta-train and meta-val , which significantly limits the domain transportation and may yield limited domain generalization capacity in comparison with MASF and MetaReg . So why DFAS outperforms MASF and MetaReg in terms of domain generalization ? More experiments and discussion are suggested to justify this point . - The difference between adversarial splitting and domain-label-based splitting is unclear . Additional experiments are suggested to empirically show the difference . - The proposed adversarial train/val splitting is computationally expensive since it needs to rank all samples in each iteration . According to the ablation results on PACS ( Tab.5 ) , improvements over randomly selected train/val splitting seem quite limited . More details about the convergence of alternative iteration should be provided . - Fig.4 shows the objective function remains unchanged after the 3rd iteration . Will the splitting results be changed after this stage ? Minor Cons : - It would be better to see an ablation study on the effect of margin m in Eq.6 . - Standard deviation of the reported results should be provided . After rebuttal : It is highly appreciated that the authors provide additional evidence in response to my reviews . My previous concerns about effectiveness and efficiency are addressed to some extent , however , this also means the original submission needs significant modification to address the concerns . I like the idea in general and the problem is well-motivated but it needs more work for a complete version . I would encourage the authors to further improve the quality of the paper .", "rating": "5: Marginally below acceptance threshold", "reply_text": "__R2-Q3__ : Effectiveness of adversarial splitting over random splitting To show the effectiveness of adversarial splitting over random splitting , we conduct additional ablation experiments on PACS dataset in both MSDS and SSDS settings and report the results as below . Table R2-3 : Ablation results on PACS in MSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Rand-split Adv-split A C P S Avg N N N 80.2 75.5 95.9 70.1 80.4 Y N N 82.5 77.5 95.2 75.6 82.7 N Y N 80.6 76.8 95.6 78.1 82.8 N N Y 83.1 77.0 94.8 79.3 83.6 Y Y N 83.2 78.6 95.8 79.5 84.3 Y N Y 84.2 79.5 95.8 82.1 85.4 Table R2-4 : Ablation results on PACS in SSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Adv-split Rand-split A $ \\rightarrow $ C A $ \\rightarrow $ P A $ \\rightarrow $ S C $ \\rightarrow $ A C $ \\rightarrow $ P C $ \\rightarrow $ S P $ \\rightarrow $ A P $ \\rightarrow $ C P $ \\rightarrow $ S S $ \\rightarrow $ A S $ \\rightarrow $ C S $ \\rightarrow $ P Avg \uff2e N N 63.7 95.6 63.5 72.0 86.5 73.3 68.4 32.7 42.2 41.6 60.3 49.3 62.4 Y N N 64.5 95.4 67.2 69.8 87.2 73.3 67.2 31.7 38.5 44.3 67.9 49.8 63.1 \uff2e Y N 65.8 94.8 64.4 71.2 85.2 74.2 68.7 32.2 39.5 52.4 64.6 56.6 64.1 N N Y 67.6 95.2 66.2 76.9 88.4 73.5 70.4 30.5 35.3 52.7 67.7 57.3 65.1 Y Y N 67.2 95.3 63.7 70.8 85.3 75.5 70.0 37.2 45.9 53.5 64.5 55.8 65.4 Y N Y 67.5 In Table R2-4 , ( $ L_2 $ -norm + Adv-split ) ( 66.6 % ) outperforms ( $ L_2 $ -norm + Rand-split ) ( 65.4 % ) by 1.2 % , and Adv-split ( 65.1 % ) outperforms Rand-split ( 64.1 % ) by 1.0 % in SSDS setting . These results demonstrate that the adversarial splitting stably outperforms the random splitting in different experimental settings . __R2-Q4__ : Computational cost of the adversarial splitting algorithm Since we only update the worst splitting per epoch , instead of at each step of updating parameters , the computational cost is only slightly higher than that of random splitting . To show this , we compare the total training times of the adversarial splitting and random spitting in the same number of steps ( 20000 ) as bellow . Table R2-5 : Total training time ( hour ) of the adversarial splitting and random spitting Adv-split Rand-split Time 6.23h 5.90h From R2-5 , the training time of Adv-split is only 5.6 % ( 0.33/5.90 ) higher than Rand-split . __R2-Q5__ : Convergence of the alternative iteration algorithm The alternative iteration algorithm converges in our experiments . We have reported the target error curves in Appendix A to show this . Please see Fig.2 for the details . We also find it converges on Office-Home and CIFAR-10 datasets . We will provide more training curves ( e.g.losses ) of more tasks in the revised version . __R2-Q6__ : Will the splitting results be changed after the 3rd iteration ? To show whether the splitting is changed after the 3rd iteration , we count the ratio of changed sample indexes in $ S_v $ at each iteration , as in Table R2-6 . Table R2-6 : Ratio of changed sample indexes in $ S_v $ at each iteration Iteration 1 2 3 4 5 6 Ratio ( % ) 44.0 4.5 0.0 0.0 0.0 0.0 Table R2-6 shows that the splitting is not changed when the value of objective function converges . __R2-Q7__ : Effect of margin $ m $ We analyze the effect of $ m $ in MSDS setting on PACS dataset . Table R2-7 : Analysis of hyper-parameter $ m $ in task A on PACS in MSDS setting $ m $ 0.10 0.15 0.20 0.25 0.30 Acc ( % ) 83.9 83.7 84.2 84.0 83.6 Table R2-7 shows that the result is not sensitive to the value of $ m $ . __R2-Q8__ : Standard deviation We report standard deviations of the results of experiment on PACS in MSDS setting in Table R2-8 . Table R2-8 : Results with standard deviations of experiment on PACS in MSDS setting A C P S Avg DFAS 84.2 $ \\pm $ 0.1 79.5 $ \\pm $ 0.3 95.8 $ \\pm $ 0.1 82.1 $ \\pm $ 0.4 85.4 Table R2-8 shows that the results of DFAS are stable . Standard deviations of the results of other experiments will be included in the revised version ."}, {"review_id": "xrLrpG3Ep1X-2", "review_text": "The paper provides a novel way to combine meta-learning and adversarial training for domain generalisation . Different from existing methods , the authors propose to split the training dataset into train/val subsets in an iteratively adversarial way , regardless of domain labels , by which the model can be trained to learn to generalise well from training subset to val subset via meta-learning in each iteration . Reason for score : Overall , I vote for accepting . It \u2019 s ingenious that the paper proposes to ignore domain labels to enhance the learned model \u2019 s generalization ability towards domain shift problems . The major concern of mine is that the paper provides limited explanation of how the meta-learning algorithm , Model-Agnostic Meta-Learning ( MAML ) , is utilized in the training process ( see detailed in cons ) . 1.The paper proposes to discard domain labels when training a model to generalise well , by which the original training set containing several domains can be seen as a large labelless domain and then splitted into training/val subsets to simulate domain shift , hence MAML can be used here for the training process . 2.The authors incorporate the min-max optimization method following adversarial training to let the model be more effective in learning domain shifts between training/val subsets . 3.One of the paper \u2019 s contributions is that it surprisingly find that L2 -normalization can help mitigate gradient explosion in the MAML algorithm . 4.The paper provides comprehensive experiments of different domain shift settings as well as theoretical proofs to evaluate the proposed method , which are quite solid and convincing . Cons : 1.It would be better if the paper provides more details in ablation study , for example , it mentions that DFAS-3 finds the hardest val-subset only based on loss by setting \\alpha = 0 in Eqn . ( 5 ) , there can be more analysis about the hyper-parameter of \u03b1 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the positive comments on our paper . __R3-Q1__ : More details of ablation study We add more ablation experiments on PACS dataset in both MSDS and SSDS settings , of which the results are reported in Table R3-1 and Table R3-2 respectively . Table R3-1 : Ablation results on PACS in MSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Rand-split Adv-split A C P S Avg N N N 80.2 75.5 95.9 70.1 80.4 Y N N 82.5 77.5 95.2 75.6 82.7 N Y N 80.6 76.8 95.6 78.1 82.8 N N Y 83.1 77.0 94.8 79.3 83.6 Y Y N 83.2 78.6 95.8 79.5 84.3 Y N Y 84.2 79.5 95.8 82.1 85.4 Table R3-2 : Ablation results on PACS in SSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Adv-split Rand-split A $ \\rightarrow $ C A $ \\rightarrow $ P A $ \\rightarrow $ S C $ \\rightarrow $ A C $ \\rightarrow $ P C $ \\rightarrow $ S P $ \\rightarrow $ A P $ \\rightarrow $ C P $ \\rightarrow $ S S $ \\rightarrow $ A S $ \\rightarrow $ C S $ \\rightarrow $ P Avg \uff2e N N 63.7 95.6 63.5 72.0 86.5 73.3 68.4 32.7 42.2 41.6 60.3 49.3 62.4 Y N N 64.5 95.4 67.2 69.8 87.2 73.3 67.2 31.7 38.5 44.3 67.9 49.8 63.1 \uff2e Y N 65.8 94.8 64.4 71.2 85.2 74.2 68.7 32.2 39.5 52.4 64.6 56.6 64.1 N N Y 67.6 95.2 66.2 76.9 88.4 73.5 70.4 30.5 35.3 52.7 67.7 57.3 65.1 Y Y N 67.2 95.3 63.7 70.8 85.3 75.5 70.0 37.2 45.9 53.5 64.5 55.8 65.4 Y N Y 67.5 Adv-split indicates that we update the worst splitting by solving the maximization problem in Eq . ( 5 ) per epoch . The results show that $ L_2 $ -norm + Adv-split ( i.e. , DFAS ) achieves the best performance in both MSDS ( 85.4 % ) and SSDS ( 66.6 % ) settings . $ L_2 $ -norm and Adv-split are both effective in both MSDS and SSDS settings . __R3-Q2__ : Analysis of hyper-parameter $ \\alpha $ We evaluate the effect of $ \\alpha $ in MSDS setting on PACS dataset . The results are reported as below . Table R3-3 : Analysis of hyper-parameter $ \\alpha $ in task A on PACS in MSDS setting $ \\alpha $ 1e-7 1e-6 1e-5 1e-4 1e-3 Acc ( % ) 83.\uff14 83.9 84.2 83.7 82.6 The ACC is stable to the values of $ \\alpha $ in large range of 1e-6 to 1e-4 . Small $ \\alpha $ results in small step-size for parameter updating in meta-learning framework , and limits the benefits from meta-learning and adversarial splitting . Larger $ \\alpha $ results in larger step-size for gradient descent based network updates , which may fail to decrease the training loss from the optimization perspective ."}, {"review_id": "xrLrpG3Ep1X-3", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper proposes a new approach for domain generalization which minimizes the generalization error across train-validation split with the largest domain gap . The paper further gives theoretical bound on the generalization error of the proposed method . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : The paper proposes a new approach for domain generalization . The idea of perform meta-learning from the train to validation split is already employed by previous works ( Balaji et al. , 2018 ; Li et al. , 2019b ; 2018a ; Dou et al. , 2019 ) . The novelty of the paper falls mostly on performing meta-learning on the train-validation split with the largest domain gap . The paper gives a theoretical bound on the generalization error to unseen target domain . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : The paper needs to update the model parameter , the initialized parameters and the train-validation split , which may not converge or converges very slowly . Though empirical results show that the convergence of the method is fast , some theoretical demonstrations are needed for the convergence speed of different updates . The contribution of the paper is a little incremental . Meta-learning based domain generalization methods are not novel . The only novelty of the paper is performing meta-learning on the train-validation split with the largest domain gap , which is an incremental contribution over meta-learning based domain generalization ( demonstrated by the ablation study ) . As shown in Table 1 , Baseline w/L2 outperforms Baseline by 2.3 % but DFAS outperforms Baseline w/L2 only by 2.7 % . This means that the main performance gain is from L2 while the other contributions has very small performance gain ( less than 1 % ) . However , L2-normalization ( Finn et al. , 2017 ; Dou et al. , 2019 ) is a widely-used techniques for meta-learning and domain generalization , which is not counted as a novel contribution for the paper . The authors need to further demonstrate that the main contribution : meta-learning on the train-validation split with the largest domain gap , has huge performance gain . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # I lean to rejecting the paper since the performance gain is mostly falls on the L2-normalization but the main contribution of the paper : performing meta-learning across the train-val split with the largest domain gap , does not have much performance gain .", "rating": "5: Marginally below acceptance threshold", "reply_text": "__R4-Q3__ : Clarifying ablation results of the performance contributions of adversarial splitting and feature $ L_2 $ -normalization We respectfully disagree on the comment that \u201c Baseline w/ $ L_2 $ outperforms Baseline by 2.3 % but DFAS outperforms Baseline w/ $ L_2 $ only by 2.7 % . This means that the main performance gain is from $ L_2 $ while the other contributions has very small performance gain ( less than 1 % ) \u201d . We first recall the definitions of different methods in Table 5 ( not Table 1 ) . Baseline : Aggregating three source domains to train learner . Baseline w/ $ L_2 $ : Applying feature $ L_2 $ -normalization over Baseline . DFAS : Performing both adversarial splitting ( Eq . ( 2 ) ) and feature $ L_2 $ -normalization over Baseline . DFAS-1 : Only performing adversarial splitting model ( Eq . ( 2 ) ) without utilizing feature $ L_2 $ -normalization over Baseline . The results in Table 5 shows that Baseline w/ $ L_2 $ ( 82.7 % ) outperforms Baseline ( 80.4 % ) by 2.3 % . DFAS ( 85.4 % ) outperforms Baseline ( 80.4 % ) and Baseline w/ $ L_2 $ ( 82.7 % ) by 5.0 % and 2.7 % respectively ( i.e. , 5.0 % = 2.7 % + 2.3 % ) . This indicates that both adversarial splitting ( contributed 2.7 % improvement ) and feature $ L_2 $ -normalization ( contributed 2.3 % improvement ) significantly contribute to total performance gain of 5.0 % over Baseline . Moreover , DFAS-1 ( only with additional adversarial splitting over Baseline ) ( 83.6 % ) outperforms Baseline ( 80.4 % ) by 3.2 % , indicating that the adversarial splitting is indeed effective . __R4-Q4__ : Theoretical demonstrations for convergence speed Thanks for this question . It is an interesting research direction to analyze convergence speed of our adversarial training algorithm . Our min-max optimization is based on iteratively updating the worst-case splitting and the parameters of learner with meta-learning . As a deep meta-learning-based training algorithm , both these two sub-optimization problems are non-convex problems . It is interesting but non-trivial to analyze their convergence speed . We have reported the target error curves in Fig.2 in Appendix A , and empirically find that our algorithm converges in our training tasks . In the adversarial training algorithm , we only update the worst-case splitting per epoch . The training time of our method is only slightly longer than that of random-splitting-based meta-learning method ( 6.23 hours vs. 5.90 hours ) . Please refer to R2-Q4 in the response to Reviewer2 for the discussion on computational time . As this work mainly focuses on the novel adversarial training framework with theoretical analysis on generalization error to target domain from the machine-learning theory perspective , its convergence speed analysis from the optimization perspective will be left in our future work ."}], "0": {"review_id": "xrLrpG3Ep1X-0", "review_text": "$ Paper $ $ summary $ This paper focuses on domain generalization , targeting the challenging scenario where the training set might not include different sources ; even under the presence of different sources , the problem formulation does not takes into account domain labels . The proposed solution is based on meta-learning , following the path drawn by Li et al.AAAI 2018 ; the Authors propose to adversarially split the training set in meta-train and meta-validation sets , and then update the current model in a direction that fosters good generalization performance on the meta-test . Results on standard benchmarks are encouraging . $ Pros $ - The proposed idea is rather interesting , enabling to apply meta-learning solutions also in absence of domain labels . In particular , I like the idea of finding meta-train and meta-test splits in an adversarial fashion . This is crucial , since randomly splitting the training set in meta-train and meta-validation would not be helpful , since it would lead to episodes where meta-train and meta-test are iid . - The Authors provide a theoretical interpretation of their approach ( due to my background , I was not able to properly review it though ) $ Cons $ - My main concern is related to the way the maximization problem is tackled , in the objective in Eq . ( 5 ) .I have reviewed Appendix C , but I can not understand how convergence would require so few iterations . Even restricting the size of $ S_v $ as mentioned in Section 3. , the number of possible sample combinations that generate couples ( $ S_v $ , $ S_t $ ) is huge -- if I understood the process correctly , then with $ |S_v|=K $ and $ |S|=N $ , the number of combinations is $ \\binom { N } { K } $ -- and for each of them the gradients that lead to the meta-update are different . Could the authors comment on this ? Am I missing something ? Related to this point , I am also concerned by the ablation study in Table 5 - where it is shown that , while helpful , the adversarial strategy does not help very significantly in the whole picture . - The overall writing could be improved . Sentences like `` this model can be further transfored to a minimax problem '' in the Abstract are not properly exposed , and there are several examples throughout the manuscript . There is a misconception related to prior work : Carlucci et al.2019 ( as well as Volpi et al.2018 ) also tackles the case where the training data only comprises a single source domain . This should be clarified in the Introduction/Related work . $ Review $ $ summary $ I like the idea this paper starts from , and I like the proposed solution . I still do not properly understand how the maximization problem at the core of the method is approached , and I believe that the paper needs some exhaustive proof checking to improve the overall writing . I look forward reading the Author response and iterating the discussion . - Post-rebuttal comments- I thank the Authors for their explanations . Yet , I still believe that this work is not ready for publication . Random splitting and adversarial splitting perform very comparably ( 1 % is not a lot ) , in my opinion casting some doubts on how meaningful the solution found to the proposed optimization problem is . The Authors included a toy example in the Appendix , but this did not mitigate my concerns on the original manuscript 's experiments . I still believe that the core idea is very interesting , and hope that it will be further investigated by the Authors for a subsequent submission .", "rating": "5: Marginally below acceptance threshold", "reply_text": "__R1-Q3__ : Improving the overall writing Thanks for your suggestions . We will replace \u201c This model can be further transformed to a min-max problem \u201d by \u201c To achieve this goal , we propose a min-max optimization problem \u201d in Abstract . The similar sentences will be revised accordingly in Sect.1 and Sect . 3.We will carefully revise the whole paper to improve the overall writing . We will discuss the works of Carlucci et al.2019 and Volpi et al.2018 in the Introduction and Related Works . They tackle the setting that training set comprises a single domain , and the train and test data are from different domains . Our domain-free setting method is flexible without assumptions on the requirement of domain labels and different domains of training and test data . Moreover , in methodology , these two methods mainly focus on augmenting new data to increase training data . Our method adversarially splits training dataset to train learner via meta-learning approach to enhance the generalization ability of learner . Experimental results in Table 3 show that our proposed DFAS outperforms JiGen ( Carlucci et al.2019 ) ( 66.6 % vs. 54.6 % ) ."}, "1": {"review_id": "xrLrpG3Ep1X-1", "review_text": "This paper proposes to unify adversarial training and meta-learning in domain-free generalization where labels of source domains are unavailable . To maximize the domain shift between the subsets of meta-train and meta-val , adversarial training is leveraged to find the worst-case train/val splits . Extensive experiments on benchmark datasets under different settings demonstrate the effectiveness of the proposed method . Pros : + The idea of adversarial train/val splitting in meta-learning is interesting . + The paper provides extensive experiments on benchmark datasets under different settings with multiple/single source domains and achieves state-of-the-art results on both PACS and Office-Home datasets . + The paper provides an upper bound of the generalization error on unseen target domains , which is implicitly minimized by the proposed method . Major Cons : - The effectiveness of adversarial train/val splitting is not well justified . Typically , meta-learning based methods ( MASF and MetaReg ) have no overlap between domains used for meta-train and meta-val . This is how the domain discrepancy between meta-train and meta-val can be modeled . However , DFAS has the issue that the same domain may be used in both meta-train and meta-val , which significantly limits the domain transportation and may yield limited domain generalization capacity in comparison with MASF and MetaReg . So why DFAS outperforms MASF and MetaReg in terms of domain generalization ? More experiments and discussion are suggested to justify this point . - The difference between adversarial splitting and domain-label-based splitting is unclear . Additional experiments are suggested to empirically show the difference . - The proposed adversarial train/val splitting is computationally expensive since it needs to rank all samples in each iteration . According to the ablation results on PACS ( Tab.5 ) , improvements over randomly selected train/val splitting seem quite limited . More details about the convergence of alternative iteration should be provided . - Fig.4 shows the objective function remains unchanged after the 3rd iteration . Will the splitting results be changed after this stage ? Minor Cons : - It would be better to see an ablation study on the effect of margin m in Eq.6 . - Standard deviation of the reported results should be provided . After rebuttal : It is highly appreciated that the authors provide additional evidence in response to my reviews . My previous concerns about effectiveness and efficiency are addressed to some extent , however , this also means the original submission needs significant modification to address the concerns . I like the idea in general and the problem is well-motivated but it needs more work for a complete version . I would encourage the authors to further improve the quality of the paper .", "rating": "5: Marginally below acceptance threshold", "reply_text": "__R2-Q3__ : Effectiveness of adversarial splitting over random splitting To show the effectiveness of adversarial splitting over random splitting , we conduct additional ablation experiments on PACS dataset in both MSDS and SSDS settings and report the results as below . Table R2-3 : Ablation results on PACS in MSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Rand-split Adv-split A C P S Avg N N N 80.2 75.5 95.9 70.1 80.4 Y N N 82.5 77.5 95.2 75.6 82.7 N Y N 80.6 76.8 95.6 78.1 82.8 N N Y 83.1 77.0 94.8 79.3 83.6 Y Y N 83.2 78.6 95.8 79.5 84.3 Y N Y 84.2 79.5 95.8 82.1 85.4 Table R2-4 : Ablation results on PACS in SSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Adv-split Rand-split A $ \\rightarrow $ C A $ \\rightarrow $ P A $ \\rightarrow $ S C $ \\rightarrow $ A C $ \\rightarrow $ P C $ \\rightarrow $ S P $ \\rightarrow $ A P $ \\rightarrow $ C P $ \\rightarrow $ S S $ \\rightarrow $ A S $ \\rightarrow $ C S $ \\rightarrow $ P Avg \uff2e N N 63.7 95.6 63.5 72.0 86.5 73.3 68.4 32.7 42.2 41.6 60.3 49.3 62.4 Y N N 64.5 95.4 67.2 69.8 87.2 73.3 67.2 31.7 38.5 44.3 67.9 49.8 63.1 \uff2e Y N 65.8 94.8 64.4 71.2 85.2 74.2 68.7 32.2 39.5 52.4 64.6 56.6 64.1 N N Y 67.6 95.2 66.2 76.9 88.4 73.5 70.4 30.5 35.3 52.7 67.7 57.3 65.1 Y Y N 67.2 95.3 63.7 70.8 85.3 75.5 70.0 37.2 45.9 53.5 64.5 55.8 65.4 Y N Y 67.5 In Table R2-4 , ( $ L_2 $ -norm + Adv-split ) ( 66.6 % ) outperforms ( $ L_2 $ -norm + Rand-split ) ( 65.4 % ) by 1.2 % , and Adv-split ( 65.1 % ) outperforms Rand-split ( 64.1 % ) by 1.0 % in SSDS setting . These results demonstrate that the adversarial splitting stably outperforms the random splitting in different experimental settings . __R2-Q4__ : Computational cost of the adversarial splitting algorithm Since we only update the worst splitting per epoch , instead of at each step of updating parameters , the computational cost is only slightly higher than that of random splitting . To show this , we compare the total training times of the adversarial splitting and random spitting in the same number of steps ( 20000 ) as bellow . Table R2-5 : Total training time ( hour ) of the adversarial splitting and random spitting Adv-split Rand-split Time 6.23h 5.90h From R2-5 , the training time of Adv-split is only 5.6 % ( 0.33/5.90 ) higher than Rand-split . __R2-Q5__ : Convergence of the alternative iteration algorithm The alternative iteration algorithm converges in our experiments . We have reported the target error curves in Appendix A to show this . Please see Fig.2 for the details . We also find it converges on Office-Home and CIFAR-10 datasets . We will provide more training curves ( e.g.losses ) of more tasks in the revised version . __R2-Q6__ : Will the splitting results be changed after the 3rd iteration ? To show whether the splitting is changed after the 3rd iteration , we count the ratio of changed sample indexes in $ S_v $ at each iteration , as in Table R2-6 . Table R2-6 : Ratio of changed sample indexes in $ S_v $ at each iteration Iteration 1 2 3 4 5 6 Ratio ( % ) 44.0 4.5 0.0 0.0 0.0 0.0 Table R2-6 shows that the splitting is not changed when the value of objective function converges . __R2-Q7__ : Effect of margin $ m $ We analyze the effect of $ m $ in MSDS setting on PACS dataset . Table R2-7 : Analysis of hyper-parameter $ m $ in task A on PACS in MSDS setting $ m $ 0.10 0.15 0.20 0.25 0.30 Acc ( % ) 83.9 83.7 84.2 84.0 83.6 Table R2-7 shows that the result is not sensitive to the value of $ m $ . __R2-Q8__ : Standard deviation We report standard deviations of the results of experiment on PACS in MSDS setting in Table R2-8 . Table R2-8 : Results with standard deviations of experiment on PACS in MSDS setting A C P S Avg DFAS 84.2 $ \\pm $ 0.1 79.5 $ \\pm $ 0.3 95.8 $ \\pm $ 0.1 82.1 $ \\pm $ 0.4 85.4 Table R2-8 shows that the results of DFAS are stable . Standard deviations of the results of other experiments will be included in the revised version ."}, "2": {"review_id": "xrLrpG3Ep1X-2", "review_text": "The paper provides a novel way to combine meta-learning and adversarial training for domain generalisation . Different from existing methods , the authors propose to split the training dataset into train/val subsets in an iteratively adversarial way , regardless of domain labels , by which the model can be trained to learn to generalise well from training subset to val subset via meta-learning in each iteration . Reason for score : Overall , I vote for accepting . It \u2019 s ingenious that the paper proposes to ignore domain labels to enhance the learned model \u2019 s generalization ability towards domain shift problems . The major concern of mine is that the paper provides limited explanation of how the meta-learning algorithm , Model-Agnostic Meta-Learning ( MAML ) , is utilized in the training process ( see detailed in cons ) . 1.The paper proposes to discard domain labels when training a model to generalise well , by which the original training set containing several domains can be seen as a large labelless domain and then splitted into training/val subsets to simulate domain shift , hence MAML can be used here for the training process . 2.The authors incorporate the min-max optimization method following adversarial training to let the model be more effective in learning domain shifts between training/val subsets . 3.One of the paper \u2019 s contributions is that it surprisingly find that L2 -normalization can help mitigate gradient explosion in the MAML algorithm . 4.The paper provides comprehensive experiments of different domain shift settings as well as theoretical proofs to evaluate the proposed method , which are quite solid and convincing . Cons : 1.It would be better if the paper provides more details in ablation study , for example , it mentions that DFAS-3 finds the hardest val-subset only based on loss by setting \\alpha = 0 in Eqn . ( 5 ) , there can be more analysis about the hyper-parameter of \u03b1 .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thanks for the positive comments on our paper . __R3-Q1__ : More details of ablation study We add more ablation experiments on PACS dataset in both MSDS and SSDS settings , of which the results are reported in Table R3-1 and Table R3-2 respectively . Table R3-1 : Ablation results on PACS in MSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Rand-split Adv-split A C P S Avg N N N 80.2 75.5 95.9 70.1 80.4 Y N N 82.5 77.5 95.2 75.6 82.7 N Y N 80.6 76.8 95.6 78.1 82.8 N N Y 83.1 77.0 94.8 79.3 83.6 Y Y N 83.2 78.6 95.8 79.5 84.3 Y N Y 84.2 79.5 95.8 82.1 85.4 Table R3-2 : Ablation results on PACS in SSDS setting ( Y : Yes , N : No ) $ L_2 $ -norm Adv-split Rand-split A $ \\rightarrow $ C A $ \\rightarrow $ P A $ \\rightarrow $ S C $ \\rightarrow $ A C $ \\rightarrow $ P C $ \\rightarrow $ S P $ \\rightarrow $ A P $ \\rightarrow $ C P $ \\rightarrow $ S S $ \\rightarrow $ A S $ \\rightarrow $ C S $ \\rightarrow $ P Avg \uff2e N N 63.7 95.6 63.5 72.0 86.5 73.3 68.4 32.7 42.2 41.6 60.3 49.3 62.4 Y N N 64.5 95.4 67.2 69.8 87.2 73.3 67.2 31.7 38.5 44.3 67.9 49.8 63.1 \uff2e Y N 65.8 94.8 64.4 71.2 85.2 74.2 68.7 32.2 39.5 52.4 64.6 56.6 64.1 N N Y 67.6 95.2 66.2 76.9 88.4 73.5 70.4 30.5 35.3 52.7 67.7 57.3 65.1 Y Y N 67.2 95.3 63.7 70.8 85.3 75.5 70.0 37.2 45.9 53.5 64.5 55.8 65.4 Y N Y 67.5 Adv-split indicates that we update the worst splitting by solving the maximization problem in Eq . ( 5 ) per epoch . The results show that $ L_2 $ -norm + Adv-split ( i.e. , DFAS ) achieves the best performance in both MSDS ( 85.4 % ) and SSDS ( 66.6 % ) settings . $ L_2 $ -norm and Adv-split are both effective in both MSDS and SSDS settings . __R3-Q2__ : Analysis of hyper-parameter $ \\alpha $ We evaluate the effect of $ \\alpha $ in MSDS setting on PACS dataset . The results are reported as below . Table R3-3 : Analysis of hyper-parameter $ \\alpha $ in task A on PACS in MSDS setting $ \\alpha $ 1e-7 1e-6 1e-5 1e-4 1e-3 Acc ( % ) 83.\uff14 83.9 84.2 83.7 82.6 The ACC is stable to the values of $ \\alpha $ in large range of 1e-6 to 1e-4 . Small $ \\alpha $ results in small step-size for parameter updating in meta-learning framework , and limits the benefits from meta-learning and adversarial splitting . Larger $ \\alpha $ results in larger step-size for gradient descent based network updates , which may fail to decrease the training loss from the optimization perspective ."}, "3": {"review_id": "xrLrpG3Ep1X-3", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper proposes a new approach for domain generalization which minimizes the generalization error across train-validation split with the largest domain gap . The paper further gives theoretical bound on the generalization error of the proposed method . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : The paper proposes a new approach for domain generalization . The idea of perform meta-learning from the train to validation split is already employed by previous works ( Balaji et al. , 2018 ; Li et al. , 2019b ; 2018a ; Dou et al. , 2019 ) . The novelty of the paper falls mostly on performing meta-learning on the train-validation split with the largest domain gap . The paper gives a theoretical bound on the generalization error to unseen target domain . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : The paper needs to update the model parameter , the initialized parameters and the train-validation split , which may not converge or converges very slowly . Though empirical results show that the convergence of the method is fast , some theoretical demonstrations are needed for the convergence speed of different updates . The contribution of the paper is a little incremental . Meta-learning based domain generalization methods are not novel . The only novelty of the paper is performing meta-learning on the train-validation split with the largest domain gap , which is an incremental contribution over meta-learning based domain generalization ( demonstrated by the ablation study ) . As shown in Table 1 , Baseline w/L2 outperforms Baseline by 2.3 % but DFAS outperforms Baseline w/L2 only by 2.7 % . This means that the main performance gain is from L2 while the other contributions has very small performance gain ( less than 1 % ) . However , L2-normalization ( Finn et al. , 2017 ; Dou et al. , 2019 ) is a widely-used techniques for meta-learning and domain generalization , which is not counted as a novel contribution for the paper . The authors need to further demonstrate that the main contribution : meta-learning on the train-validation split with the largest domain gap , has huge performance gain . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # I lean to rejecting the paper since the performance gain is mostly falls on the L2-normalization but the main contribution of the paper : performing meta-learning across the train-val split with the largest domain gap , does not have much performance gain .", "rating": "5: Marginally below acceptance threshold", "reply_text": "__R4-Q3__ : Clarifying ablation results of the performance contributions of adversarial splitting and feature $ L_2 $ -normalization We respectfully disagree on the comment that \u201c Baseline w/ $ L_2 $ outperforms Baseline by 2.3 % but DFAS outperforms Baseline w/ $ L_2 $ only by 2.7 % . This means that the main performance gain is from $ L_2 $ while the other contributions has very small performance gain ( less than 1 % ) \u201d . We first recall the definitions of different methods in Table 5 ( not Table 1 ) . Baseline : Aggregating three source domains to train learner . Baseline w/ $ L_2 $ : Applying feature $ L_2 $ -normalization over Baseline . DFAS : Performing both adversarial splitting ( Eq . ( 2 ) ) and feature $ L_2 $ -normalization over Baseline . DFAS-1 : Only performing adversarial splitting model ( Eq . ( 2 ) ) without utilizing feature $ L_2 $ -normalization over Baseline . The results in Table 5 shows that Baseline w/ $ L_2 $ ( 82.7 % ) outperforms Baseline ( 80.4 % ) by 2.3 % . DFAS ( 85.4 % ) outperforms Baseline ( 80.4 % ) and Baseline w/ $ L_2 $ ( 82.7 % ) by 5.0 % and 2.7 % respectively ( i.e. , 5.0 % = 2.7 % + 2.3 % ) . This indicates that both adversarial splitting ( contributed 2.7 % improvement ) and feature $ L_2 $ -normalization ( contributed 2.3 % improvement ) significantly contribute to total performance gain of 5.0 % over Baseline . Moreover , DFAS-1 ( only with additional adversarial splitting over Baseline ) ( 83.6 % ) outperforms Baseline ( 80.4 % ) by 3.2 % , indicating that the adversarial splitting is indeed effective . __R4-Q4__ : Theoretical demonstrations for convergence speed Thanks for this question . It is an interesting research direction to analyze convergence speed of our adversarial training algorithm . Our min-max optimization is based on iteratively updating the worst-case splitting and the parameters of learner with meta-learning . As a deep meta-learning-based training algorithm , both these two sub-optimization problems are non-convex problems . It is interesting but non-trivial to analyze their convergence speed . We have reported the target error curves in Fig.2 in Appendix A , and empirically find that our algorithm converges in our training tasks . In the adversarial training algorithm , we only update the worst-case splitting per epoch . The training time of our method is only slightly longer than that of random-splitting-based meta-learning method ( 6.23 hours vs. 5.90 hours ) . Please refer to R2-Q4 in the response to Reviewer2 for the discussion on computational time . As this work mainly focuses on the novel adversarial training framework with theoretical analysis on generalization error to target domain from the machine-learning theory perspective , its convergence speed analysis from the optimization perspective will be left in our future work ."}}