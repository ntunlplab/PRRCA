{"year": "2021", "forum": "gl3D-xY7wLq", "title": "Noise or Signal: The Role of Image Backgrounds in Object Recognition", "decision": "Accept (Poster)", "meta_review": "The paper investigates the tendency of image recognition models to depend on image backgrounds, and propose a suite of datasets to study this phenomenon.\n\nAll the reviewers agree that the paper investigates an important problem, is well-written and contains several interesting insights that should be of interest to the community. I recommend acceptance.\n", "reviews": [{"review_id": "gl3D-xY7wLq-0", "review_text": "The submission performs similar foreground-background analysis for object recognition as in [ 1 ] , but with more modern networks in mind . As such , the main takeaways indicate that this phenomenon still exists - networks today continue to suffer from background bias as they did four years ago with AlexNet , although maybe to a lesser extent . This submission curates more careful evaluation setups by using segmentation of foreground objects , tiled backgrounds to create multiple datasets that serve to illustrate the trends in a more disambiguated way . Is there some way to quantify the overall diversity of adversarial backgrounds ? For example , is it possible that owing to strong correlations of a few objects with easily-learned backgrounds , these few backgrounds always cause misclassification for other objects ? Could there be a way to detect such backgrounds ? The Appendix says `` The ORIGINAL-trained model performs similarly on NO-FG and ONLY-BG-B , indicating that it does not use object shape effectively \u201d but there seems to be a 10 % gap in Table 5 , indicating that the shape mask is fairly useful . The IN-9L numbers seem 21 % up instead of 13 % . Am I misreading this table ? Re . `` Indeed , the ONLY-BG trend observed in Figure 8 suggests that\u2026 \u201d , could an additional possibility be that around 20 % of classes are fully correlated with their backgrounds ? I.e.how can we know how much of the findings are to do with model `` failure '' , and not dataset quirks ? In summary , ( + ) While it is not particularly surprising to learn that backgrounds can be misleading even with the correct foreground or that there exists vulnerability to adversarially picked backgrounds , given the evidence we have of background biases already , it can be useful to have a quantification of the \u201c BG-gap \u201d for a range of modern models . ( - ) The takeaways are mostly already recognised from the many works that have pointed out reliance of object recognition models on backgrounds . The experiments provide a quantified view of how much modern networks trained on the particular datasets rely on backgrounds , but it is unclear how widely applicable this information is , given that this only analyses a specific dataset . The curated datasets might be useful for benchmarking progress ; however , if one were to set up the goal of providing such a testset , then perhaps it might be more appropriate to curate an entire testset of adversarial backgrounds alone ( rather than mixed-rand ) across a range of modern networks and for all of ImageNet , which , along with the usual test set would provide a background-robustness sanity check ( with the caveat from the authors that backgrounds may actually be informative when the foreground is confusing ) . [ 1 ] Object recognition with and without objects , Zhu et al.2017 Post Rebuttal : I appreciate the authors ' responses . The `` novelty '' over Zhu et al.was never under question in my review , I was mostly confused about how to weigh the significance of the findings , how useful it is to know some numbers for the version of the dataset created by the authors ( which is not really the original Imagenet classification task ) , and if the submission actually does `` pinpoint '' what the problems are , how and when they manifest , to what extent the dataset is responsible vs. the training choices . Having read the other reviews , responses , looked at the updates , I 'm still unsure -- if there were something in this paper that was new or surprising and not more or less already known from existing works ( perhaps not precise numbers , but then the paper is essentially using a synthetic , modified Imagenet anyway ) , I 'd be more enthusiastic about pushing up the rating . But as of now , I 'm retaining my initial rating .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your time and constructive feedback . We will first address the topic of novelty , then address your specific questions in the next comment . == `` ( - ) The takeaways are mostly already recognised from the many works that have pointed out reliance of object recognition models on backgrounds . The experiments provide a quantified view of how much modern networks trained on the particular datasets rely on backgrounds , but it is unclear how widely applicable this information is , given that this only analyses a specific dataset . '' We believe that , given the growing interest in out of distribution classification and understanding model biases , it \u2019 s important to have a toolkit for pinpointing the exact challenges and evaluating our progress on these fronts . Our focus on ImageNet is motivated by the fact that it is the most widely used dataset for academic research , and many pre-trained models for it are already in use . The only prior work that has a similar focus on ImageNet is the work of Zhu et . al. , and , as discussed in the Related Works section ( and in the next paragraph ) , there are a number of new insights that our work contributes compared to it . We do not claim to be the first to point out that models can rely on backgrounds -- many works that we cite already study this . We do believe that the following are new contributions that appear first in our work , and welcome a discussion about which aspects are valuable . ( As a note , many of the following comparisons are also in Appendix E. ) Specific comparison to Zhu et . al : 1 ) Compared to Zhu et . al , we properly segment foregrounds using GrabCut ( as opposed to using rectangular bounding boxes only , which may leave large portions of the background ) . 2 ) Compared to Zhu et . al , we combine FG and BG signal in various ways to gain a finer-grained understanding . For example , comparing MIXED-SAME with MIXED-RAND helps to isolate the effects of changing the background class . In contrast , Zhu et . al focuses on analyzing classification with only BG , which corresponds to just the ONLY-BG-B sub-dataset that we also include in our analysis . 3 ) Compared to Zhu et . al , which only studies AlexNet , we analyze a much larger set of more modern architectures . Contributions we believe are novel in comparison to all prior works ( including Zhu et.al ) : 1 ) We study the relationship between the improvement of these newer architectures on ImageNet and their improvement on background-dependence in Section 4 . 2 ) We analyze adversarial backgrounds and just how much models can use background signal . We find , interestingly , that models can be frequently fooled by adversarial backgrounds . 3 ) We analyze how different training methods ( randomizing backgrounds during training , training with more data or more fine-grained classes ) can decrease background dependence . 4 ) We analyze the BGs and FGs of individual images to show that backgrounds are actually required on certain images - this is Figure 7 . 5 ) Our toolkit and code will become publicly available upon release of this work , so that others may also easily evaluate the background dependence of their own models . Our code is compatible with any ImageNet-trained model . 6 ) Our method for separating FGs and BGs can be achieved without human-annotated foreground segmentation . These human annotations can be expensive and do not exist for ImageNet ."}, {"review_id": "gl3D-xY7wLq-1", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper studies the effect of background noise on image classification tasks for neural networks . The paper suggests the following based on empirical results from ImageNet classifiers . 1.It is possible to achieve reasonable accuracy by just using the background information . 2.Image classification models suffer from a decrease in accuracy if inference images have a different background . 3.Image classification models have higher accuracy tends to depend on the background image less . The paper also introduces a toolkit for evaluating the ImageNet classifiers ' dependence on background images . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper provides a detailed quantitative analysis of the effects of using different backgrounds ( both training and testing ) . It constructs various synthetic test dataset that analyzes different scenarios . 2.The result sections ( sections 3 and 4 ) are well structured and carefully study the impact of using different backgrounds . 3.The proposed toolkit can be used to evaluate the model 's reliance on the background . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : 1 . The key concern about the paper is the lack of novelty . While the synthetic dataset was constructed to study the effects of background in detail , the findings from the paper are not new . 2.The experiments do not study/relate how data augmentation techniques affect background reliance . The paper also mentions OOD techniques such as distributionally robust optimization ( Sagawa et al , 2020 ) , but does not study how these techniques affect background reliance . Moreover , I can not find a discussion on which factors in training might force the model to less rely on image backgrounds ( or robust to foreground images ) . 3.The dataset mainly used , IN-9 , is also a small dataset that contains less than 50,000 train images . Moreover , the paper only considers the ImageNet type dataset . Some results may not hold for the other datasets . The authors do not address this in the manuscript . 4.There are some minor concerns about the experimental set-up used in the paper that I describe in the section below . 5.Writings can be significantly improved . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Questions : 1 . On page 5 , it says , `` MIXED-RAND models perform poorly on datasets with only backgrounds and no foregrounds . '' What is the insight from this experiment ? Does this imply that the model might be learning shape features as it is doing better than random ? 2.For images processed with GrabCut , would n't the model use shape-related features along with the background ? If it is learning the shape features , can the positive correlation in section 4 mean that a stronger model might be learning more shape features ? 3.What is each point in figure 8 represent ? Is it using different architectures ? 4.Appendix B.1 , does n't the change in the number of classes also result in a change in total dataset size ? 5.What is the main insight of this paper when training neural networks ? 6.What are the main contributions of the toolkit ? How accurate is the segmentation ? Minor notes : * On page 1 , `` standard models misclassify 88 % of images ... '' -- > does this refer to 88 % of test images ? * On page 1 , I do n't understand this sentence : `` tend to simultaneously exploit background correlations more . '' Is there a stronger correlation between backgrounds for more accurate models ? * For figure 2 , what is the test accuracy for a model trained on the original dataset ( original/original ) ? * In table 2 , `` on select test sets ... '' -- > selected . * In figure 3 , I do n't understand what it means by `` note that the gap decreases much more on the right side of the graph . '' * It is n't easy to interpret table 3 . It will be easier to understand if it contains some illustrative examples . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # I raised my score based on the author 's response .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your time and constructive feedback . We will first address the topic of novelty , then address further questions in the next comment . == `` The key concern about the paper is the lack of novelty . While the synthetic dataset was constructed to study the effects of background in detail , the findings from the paper are not new . '' As we state in our paper , we do not view the finding that models do use background info as the contribution of our work ( nor a new finding altogether ) . We provide a number of relevant prior work citations in the introduction and related works about this topic . We do believe that the following are new contributions that appear first in our work , and welcome a discussion about which aspects are valuable . ( As a note , many of the following comparisons are also in Appendix E. ) Contributions we believe are novel in comparison to all prior works : 1 ) We study the relationship between the improvement of these newer architectures on ImageNet and their improvement on background-dependence in Section 4 . 2 ) We analyze adversarial backgrounds and just how much models can use background signal . We find , interestingly , that models can be frequently fooled by adversarial backgrounds . 3 ) We analyze how different training methods ( randomizing backgrounds during training , training with more data or more fine-grained classes ) can decrease background dependence . 4 ) We analyze the BGs and FGs of individual images to show that backgrounds are actually required on certain images - this is Figure 7 . 5 ) Our toolkit and code will become publicly available upon release of this work , so that others may also easily evaluate the background dependence of their own models . Our code is compatible with any ImageNet-trained model . 6 ) Our method for separating FGs and BGs can be achieved without human-annotated foreground segmentation . These human annotations can be expensive and do not exist for ImageNet . Next , we compare more explicitly with Zhu et . al specifically , the only other work we are aware of that also focuses on ImageNet : 1 ) Compared to Zhu et . al , we properly segment foregrounds using GrabCut ( as opposed to using rectangular bounding boxes only , which may leave large portions of the background ) . 2 ) Compared to Zhu et . al , we combine FG and BG signal in various ways to gain a finer-grained understanding . For example , comparing MIXED-SAME with MIXED-RAND helps to isolate the effects of changing the background class . In contrast , Zhu et . al focuses on analyzing classification with only BG , which corresponds to just the ONLY-BG-B sub-dataset that we also include in our analysis . 3 ) Compared to Zhu et . al , which only studies AlexNet , we analyze a much larger set of more modern architectures . We would love to clarify this point better by including a more detailed discussion of the most relevant related works ( e.g.Zhu et.al ) earlier on in the paper , which Reviewer 4 also suggests . Would you find this helpful ? Are there some other suggestions you might have ?"}, {"review_id": "gl3D-xY7wLq-2", "review_text": "I think this a very good contribution to ICLR given the topic and the quality of the submission ( originality , contribution to the stare of the art , experimental evidence , etc ) although the study might need to be supported in a more theoretical framework to make it worth of an oral presentation ( I would recommend a poster or short presentation ) Some of the strong points of the submission are summarized as follows : 1 . Studies in the interpretability of the results of deep learning models is a very important aspect , as well as the robustness of the obtained models in a variety of circumstances and under adversarial attacks . 2.A sufficient introduction and motivations sections , but I would suggest introducing the state of the art at the beginning of the paper as it would help to get a better grasp of how the works builds upon previous work . 3.The state of the art ( despite the previous comment ) contextualizes the subject matter in a succinct but comprehensive manner . Although there are certain aspects that could be improved , such as including a table outlining in a clearer manner the contributions of the authors in this context . 4.The experimental design is good , showing a careful analysis to validate the proposal and several ablation studies to assess the validity of the authors ' hypotheses 5 . The foundations for the method are presented in great detail in a formalized manner and provides sufficient elements ( i.e.examples ) to assess the validity of the proposed approach . However , there are certain things that in my opinion could be improved : 1 . The authors make a very interesting contribution that leverages knowledge from several research areas and thus , sometimes the contributions with regards to the state of the art are difficult to follow . I would suggest making a table summarizing the main features of some previous works so the readers can better grasp the limitations of those previous works and understand better the improvements in each of the areas outlined in this research 2 . The organization of the paper is confusing , some effort should be given at creating a clearer layout that makes the paper easier to read and follow the flow of ideas . 3.Future work could be further elaborated and discussion in specific domains ( medical imaging , for instance ) could be further discussed . 4.The abstract mentions that the proposed work can be used as a blueprint for assessing the out of distribution performance of deep learning models , but this aspect is not sufficiently explored in my opinion .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your time , your positive feedback , and your suggestions . == As you suggested , we will revise our submission to discuss prior state of the art works more towards the beginning of the paper , and will also clearly highlight what we view as the main new contributions of the paper . == Thank you for the suggestion . We will also include references to studies of background usage in medical imaging in our related works . == Finally , regarding out-of-distribution performance , we view background dependence ( and changing backgrounds ) as probably the most basic example of distribution shift one can imagine . Thus , our study of backgrounds is just one particular case of distribution shift , but the questions we ask about backgrounds apply more generally to other forms of distribution shifts . We want to understand to what degree it is a problem in standard models , how it has changed over time , and how we can make models be more robust to it . Finally , we need a fine-grained benchmark for evaluating it , which is what we aimed to do for image backgrounds in this work ."}, {"review_id": "gl3D-xY7wLq-3", "review_text": "The authors presented a comprehensive study on the role of background in image classification . They designed a new set of data and a lot of experiments to find answers to the following questions : ( 1 ) How much decrease in classification accuracy if the background signal is removed ? ( 2 ) Can a model successfully classify an image solely based on its background ? ( 3 ) Will an image be misclassified if the image 's background is replaced by a different background ? ( 4 ) With the advance of the model architecture , are the more advanced models like ResNet more robust to background effect ? The paper is well written , and the figures and tables are clearly presented . The newly created dataset ImageNet-9 , that contains background- and foreground-free images , are publicly available . Comments : - I am not sure if I understand the purpose for presenting the ONLY-BG-T results in Figure 7 . In my opinion , by comparing the BG-Required numbers in MIXED-RAND and ORIGINAL models , it is already clear enough to demonstrate that the background is a necessary component for many images to obtain correct classification . - As shown in the section of related work , similar topics have been studied before . One of the main contributions of this paper is the newly created dataset . It can be generally useful for ML research in robustness and out-of-distribution detection .", "rating": "7: Good paper, accept", "reply_text": "Thank you for the positive feedback ! You are correct that presenting results comparing the BG-Required numbers for ORIGINAL vs. MIXED-RAND already conveys the main point that backgrounds are more necessary for models trained on ORIGINAL . We include a ONLY-BG-T-trained model in the same plot for completeness , as the 5 categories of images ( BG Irrelevant , BG Required , BG Fools , BG+FG Required , BG+FG Fools ) are determined by test performance on the 3 datasets of ORIGINAL , MIXED-RAND , and ONLY-BG-T ."}], "0": {"review_id": "gl3D-xY7wLq-0", "review_text": "The submission performs similar foreground-background analysis for object recognition as in [ 1 ] , but with more modern networks in mind . As such , the main takeaways indicate that this phenomenon still exists - networks today continue to suffer from background bias as they did four years ago with AlexNet , although maybe to a lesser extent . This submission curates more careful evaluation setups by using segmentation of foreground objects , tiled backgrounds to create multiple datasets that serve to illustrate the trends in a more disambiguated way . Is there some way to quantify the overall diversity of adversarial backgrounds ? For example , is it possible that owing to strong correlations of a few objects with easily-learned backgrounds , these few backgrounds always cause misclassification for other objects ? Could there be a way to detect such backgrounds ? The Appendix says `` The ORIGINAL-trained model performs similarly on NO-FG and ONLY-BG-B , indicating that it does not use object shape effectively \u201d but there seems to be a 10 % gap in Table 5 , indicating that the shape mask is fairly useful . The IN-9L numbers seem 21 % up instead of 13 % . Am I misreading this table ? Re . `` Indeed , the ONLY-BG trend observed in Figure 8 suggests that\u2026 \u201d , could an additional possibility be that around 20 % of classes are fully correlated with their backgrounds ? I.e.how can we know how much of the findings are to do with model `` failure '' , and not dataset quirks ? In summary , ( + ) While it is not particularly surprising to learn that backgrounds can be misleading even with the correct foreground or that there exists vulnerability to adversarially picked backgrounds , given the evidence we have of background biases already , it can be useful to have a quantification of the \u201c BG-gap \u201d for a range of modern models . ( - ) The takeaways are mostly already recognised from the many works that have pointed out reliance of object recognition models on backgrounds . The experiments provide a quantified view of how much modern networks trained on the particular datasets rely on backgrounds , but it is unclear how widely applicable this information is , given that this only analyses a specific dataset . The curated datasets might be useful for benchmarking progress ; however , if one were to set up the goal of providing such a testset , then perhaps it might be more appropriate to curate an entire testset of adversarial backgrounds alone ( rather than mixed-rand ) across a range of modern networks and for all of ImageNet , which , along with the usual test set would provide a background-robustness sanity check ( with the caveat from the authors that backgrounds may actually be informative when the foreground is confusing ) . [ 1 ] Object recognition with and without objects , Zhu et al.2017 Post Rebuttal : I appreciate the authors ' responses . The `` novelty '' over Zhu et al.was never under question in my review , I was mostly confused about how to weigh the significance of the findings , how useful it is to know some numbers for the version of the dataset created by the authors ( which is not really the original Imagenet classification task ) , and if the submission actually does `` pinpoint '' what the problems are , how and when they manifest , to what extent the dataset is responsible vs. the training choices . Having read the other reviews , responses , looked at the updates , I 'm still unsure -- if there were something in this paper that was new or surprising and not more or less already known from existing works ( perhaps not precise numbers , but then the paper is essentially using a synthetic , modified Imagenet anyway ) , I 'd be more enthusiastic about pushing up the rating . But as of now , I 'm retaining my initial rating .", "rating": "5: Marginally below acceptance threshold", "reply_text": "Thank you for your time and constructive feedback . We will first address the topic of novelty , then address your specific questions in the next comment . == `` ( - ) The takeaways are mostly already recognised from the many works that have pointed out reliance of object recognition models on backgrounds . The experiments provide a quantified view of how much modern networks trained on the particular datasets rely on backgrounds , but it is unclear how widely applicable this information is , given that this only analyses a specific dataset . '' We believe that , given the growing interest in out of distribution classification and understanding model biases , it \u2019 s important to have a toolkit for pinpointing the exact challenges and evaluating our progress on these fronts . Our focus on ImageNet is motivated by the fact that it is the most widely used dataset for academic research , and many pre-trained models for it are already in use . The only prior work that has a similar focus on ImageNet is the work of Zhu et . al. , and , as discussed in the Related Works section ( and in the next paragraph ) , there are a number of new insights that our work contributes compared to it . We do not claim to be the first to point out that models can rely on backgrounds -- many works that we cite already study this . We do believe that the following are new contributions that appear first in our work , and welcome a discussion about which aspects are valuable . ( As a note , many of the following comparisons are also in Appendix E. ) Specific comparison to Zhu et . al : 1 ) Compared to Zhu et . al , we properly segment foregrounds using GrabCut ( as opposed to using rectangular bounding boxes only , which may leave large portions of the background ) . 2 ) Compared to Zhu et . al , we combine FG and BG signal in various ways to gain a finer-grained understanding . For example , comparing MIXED-SAME with MIXED-RAND helps to isolate the effects of changing the background class . In contrast , Zhu et . al focuses on analyzing classification with only BG , which corresponds to just the ONLY-BG-B sub-dataset that we also include in our analysis . 3 ) Compared to Zhu et . al , which only studies AlexNet , we analyze a much larger set of more modern architectures . Contributions we believe are novel in comparison to all prior works ( including Zhu et.al ) : 1 ) We study the relationship between the improvement of these newer architectures on ImageNet and their improvement on background-dependence in Section 4 . 2 ) We analyze adversarial backgrounds and just how much models can use background signal . We find , interestingly , that models can be frequently fooled by adversarial backgrounds . 3 ) We analyze how different training methods ( randomizing backgrounds during training , training with more data or more fine-grained classes ) can decrease background dependence . 4 ) We analyze the BGs and FGs of individual images to show that backgrounds are actually required on certain images - this is Figure 7 . 5 ) Our toolkit and code will become publicly available upon release of this work , so that others may also easily evaluate the background dependence of their own models . Our code is compatible with any ImageNet-trained model . 6 ) Our method for separating FGs and BGs can be achieved without human-annotated foreground segmentation . These human annotations can be expensive and do not exist for ImageNet ."}, "1": {"review_id": "gl3D-xY7wLq-1", "review_text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Summary : The paper studies the effect of background noise on image classification tasks for neural networks . The paper suggests the following based on empirical results from ImageNet classifiers . 1.It is possible to achieve reasonable accuracy by just using the background information . 2.Image classification models suffer from a decrease in accuracy if inference images have a different background . 3.Image classification models have higher accuracy tends to depend on the background image less . The paper also introduces a toolkit for evaluating the ImageNet classifiers ' dependence on background images . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Pros : 1 . The paper provides a detailed quantitative analysis of the effects of using different backgrounds ( both training and testing ) . It constructs various synthetic test dataset that analyzes different scenarios . 2.The result sections ( sections 3 and 4 ) are well structured and carefully study the impact of using different backgrounds . 3.The proposed toolkit can be used to evaluate the model 's reliance on the background . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Cons : 1 . The key concern about the paper is the lack of novelty . While the synthetic dataset was constructed to study the effects of background in detail , the findings from the paper are not new . 2.The experiments do not study/relate how data augmentation techniques affect background reliance . The paper also mentions OOD techniques such as distributionally robust optimization ( Sagawa et al , 2020 ) , but does not study how these techniques affect background reliance . Moreover , I can not find a discussion on which factors in training might force the model to less rely on image backgrounds ( or robust to foreground images ) . 3.The dataset mainly used , IN-9 , is also a small dataset that contains less than 50,000 train images . Moreover , the paper only considers the ImageNet type dataset . Some results may not hold for the other datasets . The authors do not address this in the manuscript . 4.There are some minor concerns about the experimental set-up used in the paper that I describe in the section below . 5.Writings can be significantly improved . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # Questions : 1 . On page 5 , it says , `` MIXED-RAND models perform poorly on datasets with only backgrounds and no foregrounds . '' What is the insight from this experiment ? Does this imply that the model might be learning shape features as it is doing better than random ? 2.For images processed with GrabCut , would n't the model use shape-related features along with the background ? If it is learning the shape features , can the positive correlation in section 4 mean that a stronger model might be learning more shape features ? 3.What is each point in figure 8 represent ? Is it using different architectures ? 4.Appendix B.1 , does n't the change in the number of classes also result in a change in total dataset size ? 5.What is the main insight of this paper when training neural networks ? 6.What are the main contributions of the toolkit ? How accurate is the segmentation ? Minor notes : * On page 1 , `` standard models misclassify 88 % of images ... '' -- > does this refer to 88 % of test images ? * On page 1 , I do n't understand this sentence : `` tend to simultaneously exploit background correlations more . '' Is there a stronger correlation between backgrounds for more accurate models ? * For figure 2 , what is the test accuracy for a model trained on the original dataset ( original/original ) ? * In table 2 , `` on select test sets ... '' -- > selected . * In figure 3 , I do n't understand what it means by `` note that the gap decreases much more on the right side of the graph . '' * It is n't easy to interpret table 3 . It will be easier to understand if it contains some illustrative examples . # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # I raised my score based on the author 's response .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your time and constructive feedback . We will first address the topic of novelty , then address further questions in the next comment . == `` The key concern about the paper is the lack of novelty . While the synthetic dataset was constructed to study the effects of background in detail , the findings from the paper are not new . '' As we state in our paper , we do not view the finding that models do use background info as the contribution of our work ( nor a new finding altogether ) . We provide a number of relevant prior work citations in the introduction and related works about this topic . We do believe that the following are new contributions that appear first in our work , and welcome a discussion about which aspects are valuable . ( As a note , many of the following comparisons are also in Appendix E. ) Contributions we believe are novel in comparison to all prior works : 1 ) We study the relationship between the improvement of these newer architectures on ImageNet and their improvement on background-dependence in Section 4 . 2 ) We analyze adversarial backgrounds and just how much models can use background signal . We find , interestingly , that models can be frequently fooled by adversarial backgrounds . 3 ) We analyze how different training methods ( randomizing backgrounds during training , training with more data or more fine-grained classes ) can decrease background dependence . 4 ) We analyze the BGs and FGs of individual images to show that backgrounds are actually required on certain images - this is Figure 7 . 5 ) Our toolkit and code will become publicly available upon release of this work , so that others may also easily evaluate the background dependence of their own models . Our code is compatible with any ImageNet-trained model . 6 ) Our method for separating FGs and BGs can be achieved without human-annotated foreground segmentation . These human annotations can be expensive and do not exist for ImageNet . Next , we compare more explicitly with Zhu et . al specifically , the only other work we are aware of that also focuses on ImageNet : 1 ) Compared to Zhu et . al , we properly segment foregrounds using GrabCut ( as opposed to using rectangular bounding boxes only , which may leave large portions of the background ) . 2 ) Compared to Zhu et . al , we combine FG and BG signal in various ways to gain a finer-grained understanding . For example , comparing MIXED-SAME with MIXED-RAND helps to isolate the effects of changing the background class . In contrast , Zhu et . al focuses on analyzing classification with only BG , which corresponds to just the ONLY-BG-B sub-dataset that we also include in our analysis . 3 ) Compared to Zhu et . al , which only studies AlexNet , we analyze a much larger set of more modern architectures . We would love to clarify this point better by including a more detailed discussion of the most relevant related works ( e.g.Zhu et.al ) earlier on in the paper , which Reviewer 4 also suggests . Would you find this helpful ? Are there some other suggestions you might have ?"}, "2": {"review_id": "gl3D-xY7wLq-2", "review_text": "I think this a very good contribution to ICLR given the topic and the quality of the submission ( originality , contribution to the stare of the art , experimental evidence , etc ) although the study might need to be supported in a more theoretical framework to make it worth of an oral presentation ( I would recommend a poster or short presentation ) Some of the strong points of the submission are summarized as follows : 1 . Studies in the interpretability of the results of deep learning models is a very important aspect , as well as the robustness of the obtained models in a variety of circumstances and under adversarial attacks . 2.A sufficient introduction and motivations sections , but I would suggest introducing the state of the art at the beginning of the paper as it would help to get a better grasp of how the works builds upon previous work . 3.The state of the art ( despite the previous comment ) contextualizes the subject matter in a succinct but comprehensive manner . Although there are certain aspects that could be improved , such as including a table outlining in a clearer manner the contributions of the authors in this context . 4.The experimental design is good , showing a careful analysis to validate the proposal and several ablation studies to assess the validity of the authors ' hypotheses 5 . The foundations for the method are presented in great detail in a formalized manner and provides sufficient elements ( i.e.examples ) to assess the validity of the proposed approach . However , there are certain things that in my opinion could be improved : 1 . The authors make a very interesting contribution that leverages knowledge from several research areas and thus , sometimes the contributions with regards to the state of the art are difficult to follow . I would suggest making a table summarizing the main features of some previous works so the readers can better grasp the limitations of those previous works and understand better the improvements in each of the areas outlined in this research 2 . The organization of the paper is confusing , some effort should be given at creating a clearer layout that makes the paper easier to read and follow the flow of ideas . 3.Future work could be further elaborated and discussion in specific domains ( medical imaging , for instance ) could be further discussed . 4.The abstract mentions that the proposed work can be used as a blueprint for assessing the out of distribution performance of deep learning models , but this aspect is not sufficiently explored in my opinion .", "rating": "8: Top 50% of accepted papers, clear accept", "reply_text": "Thank you for your time , your positive feedback , and your suggestions . == As you suggested , we will revise our submission to discuss prior state of the art works more towards the beginning of the paper , and will also clearly highlight what we view as the main new contributions of the paper . == Thank you for the suggestion . We will also include references to studies of background usage in medical imaging in our related works . == Finally , regarding out-of-distribution performance , we view background dependence ( and changing backgrounds ) as probably the most basic example of distribution shift one can imagine . Thus , our study of backgrounds is just one particular case of distribution shift , but the questions we ask about backgrounds apply more generally to other forms of distribution shifts . We want to understand to what degree it is a problem in standard models , how it has changed over time , and how we can make models be more robust to it . Finally , we need a fine-grained benchmark for evaluating it , which is what we aimed to do for image backgrounds in this work ."}, "3": {"review_id": "gl3D-xY7wLq-3", "review_text": "The authors presented a comprehensive study on the role of background in image classification . They designed a new set of data and a lot of experiments to find answers to the following questions : ( 1 ) How much decrease in classification accuracy if the background signal is removed ? ( 2 ) Can a model successfully classify an image solely based on its background ? ( 3 ) Will an image be misclassified if the image 's background is replaced by a different background ? ( 4 ) With the advance of the model architecture , are the more advanced models like ResNet more robust to background effect ? The paper is well written , and the figures and tables are clearly presented . The newly created dataset ImageNet-9 , that contains background- and foreground-free images , are publicly available . Comments : - I am not sure if I understand the purpose for presenting the ONLY-BG-T results in Figure 7 . In my opinion , by comparing the BG-Required numbers in MIXED-RAND and ORIGINAL models , it is already clear enough to demonstrate that the background is a necessary component for many images to obtain correct classification . - As shown in the section of related work , similar topics have been studied before . One of the main contributions of this paper is the newly created dataset . It can be generally useful for ML research in robustness and out-of-distribution detection .", "rating": "7: Good paper, accept", "reply_text": "Thank you for the positive feedback ! You are correct that presenting results comparing the BG-Required numbers for ORIGINAL vs. MIXED-RAND already conveys the main point that backgrounds are more necessary for models trained on ORIGINAL . We include a ONLY-BG-T-trained model in the same plot for completeness , as the 5 categories of images ( BG Irrelevant , BG Required , BG Fools , BG+FG Required , BG+FG Fools ) are determined by test performance on the 3 datasets of ORIGINAL , MIXED-RAND , and ONLY-BG-T ."}}