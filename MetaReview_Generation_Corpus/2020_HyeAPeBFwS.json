{"year": "2020", "forum": "HyeAPeBFwS", "title": "Quantifying uncertainty with GAN-based priors", "decision": "Reject", "meta_review": "This paper suggests a Bayesian approach to make inference about latent variables for image inference tasks. While the idea in the paper seems elegant and simple, reviewers pointed out a few concerns, including lack of comparisons, missing references, and requested for more extensive validations. While a few comments might have been misunderstandings (eg lack of quantification - seems to be resolved by author\u2019s comments), other comments are not (eg equation (8) needs further justification even if the final results don\u2019t use it). We encourage authors to carefully review comments and edit the manuscript (perhaps some appendix items should be in the main to reduce confusion) for resubmitting to future conferences. ", "reviews": [{"review_id": "HyeAPeBFwS-0", "review_text": "Summary of the paper: The paper proposes a Bayesian approach to make inference about latent variables such as un-corrupted images. The prior distribution plays a key role in this task. The authors use a GAN to estimate this prior distribution. Then, standard Bayesian techniques such a Hamilton Monte Carlo are used to make inference about the latent variables. Detailed comments: Eq. (8) is expected to give very bad results. The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y. The paper does not address learning any model parameters. e.g. the amount of noise. A more principled approach would be to estimate the prior parameters using maximum likelihood estimation. That has already been done in the case of the variational autoencoder. The variational autoencoder is an already known method that can be used to solve the problem formulated by the authors. It also automatically proposes an inference network that can be used for recognition. If the likelihood is Gaussian and p(x|z) is also Gaussian, one can directly marginalize x and work with p(y|z) and p(z). The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model. It is not clear how the HMC parameters are fixed. The experiments do not have error bars (Figure 4.) This questions the significance of the results. My overall impression is that there is little novelty in the proposed approach. Namely, using a GAN to learn the prior distribution, and then very well known techniques to infer the original input image. I have missed some references to related work on inverse problems. An example is: https://arxiv.org/pdf/1712.03353.pdf Is the original figure contained in the training set used to infer the GAN. If so that can lead to biased results. I have missed a simple baseline in which one simply finds the training image that is closest to the corrupted observed or partially observed image. My overall impression is that there is not much novelty in the paper as it is simply a combination of well known techniques. E.g. GANs and Bayesian inference with Monte Carlo methods. ", "rating": "3: Weak Reject", "reply_text": "Thank you for your valuable feedback ! After carefully reading your comments we plan to modify the manuscript as discussed below ( the planned changes are shown by * * \u2026 * * ) . We would appreciate it if you could let us know whether the proposed changes address your concerns , or whether we have misinterpreted your comments . -- -- - `` Eq . ( 8 ) is expected to give very bad results . The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y . '' We agree that it is in general a bad idea to use this equation , especially when the likelihood is very informative . However , we have found that for likelihoods that are not very informative this method is still useful . Furthermore , we would like to point out that we do not use this equation for the results shown in the manuscript , but rather use MCMC ( eq . ( 9 ) ) for all the results . * * We will include this discussion in the revised manuscript . * * -- -- - `` The paper does not address learning any model parameters . e.g.the amount of noise . '' You are right , we do not learn parameters associated with the noise in this work . We do however learn the parameters associated with the forward model by mapping them back to the latent space of the GAN . This is most clear in the context of the physics-based model ( Section 3.2 ) , where we parameterize forward model using pixel-wise values of the initial temperature , and then learn these parameters using the proposed method . We note that the proposed approach can easily be extended to regime where likelihood is also unknown by incorporating likelihood-free inference methods like ABC or meta-learning approaches . * * We will include this discussion the revised version * * . -- -- - `` A more principled approach would be to estimate the prior parameters using maximum likelihood estimation . That has already been done in the case of the variational autoencoder . The variational autoencoder is an already known method that can be used to solve the problem formulated by the authors . It also automatically proposes an inference network that can be used for recognition . If the likelihood is Gaussian and p ( x|z ) is also Gaussian , one can directly marginalize x and work with p ( y|z ) and p ( z ) . The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model . '' We agree that we were lacking a proof that demonstrated the convergence of the proposed method for computing point estimates of the posterior . * * We have now derived this proof and will include it in the Appendix . * * In a nutshell , this proof establishes that with increasing the expressivity of the generator and the discriminator ( increasing number weights ) the point estimates computed using the proposed approach converges to the true point estimates of the posterior . We agree that using a variational autoencoder ( VAE ) in lieu of a GAN is an interesting extension of the proposed approach and that this can be accomplished in different ways . * * We are working on writing a concise description of these ideas and will include in the revised manuscript . * * However , we would like to point out that for image recovery tasks GANs have consistently demonstrated better performance than VAEs , as the latter tend to smear out images due to their maximum likelihood loss . While the idea of using corrupted images to train the VAE and inferring the latent variable , which would be the - un-corrupted image is very interesting and using VAE with max . likelihood loss is an intriguing option , there are some major drawbacks of using it in the proposed Bayesian inference setting . \u2022 It is well-known that image samples produced by VAEs are quite blurry and of poorer quality than GAN and fail to match the true data distribution . It is shown in earlier studies that they fail to match marginal distribution not only in visible space but also in latent space [ 1 ] . Since , the focus of our paper is to use these distributions as priors , we believe that it is better to select a model for these distributions and hence GAN is our preferred choice . \u2022 Furthermore , VAEs are explicit density model and we have to select a model family ( like Gaussian ) for the latent variables . Therefore , in a setting where we treat un-corrupted images as latent variables ( as suggested by the reviewer ) , and use max . likelihood as our loss function , we are forcing the latent variables to be close to that chosen family of distributions . This , might fail to capture complex inferred joint probability distribution seen in the examples considered in this manuscript , which is far from Gaussian ( or any other simple distribution ) . It is also against the spirit of this work , where we want to make as few assumption as possible for our prior and use data to guide its final form . [ 1 ] .Rosca , M. , Lakshminarayanan , B. , & Mohamed , S. ( 2018 ) . Distribution Matching in Variational Inference . ArXiv , abs/1802.06847 ."}, {"review_id": "HyeAPeBFwS-1", "review_text": "The paper studies the Bayesian inferences with the generative adversarial network (GAN). In the first half of the paper, the general framework of the Bayes estimation is introduced. Then, The authors proposed how to incorporate GAN to the Bayesian inference. Some computational methods for calculating the mean of the statistic under the posterior distribution are described. Then, numerical experiments using MNIST and Celeb-A datasets are presented. Though the Bayesian inference using GAN is a natural idea, learning algorithms proposed in this paper are simple and are not intensively developed. In numerical experiments, there is no comparison with major competitors besides random sampling in the active learning setup. Hence, the effectiveness and advantage of the proposed methods are not clear. - In active learning, the proposed method should be compared with other methods such as Bayesian DNN using dropout, etc. - How does the estimation accuracy of GAN relate to the estimation accuracy of the proposed method? Showing a quantitative description would be nice. ", "rating": "3: Weak Reject", "reply_text": "Thank you for your valuable feedback ! After carefully reading it , we plan to modify the manuscript as discussed below ( the planned changes are shown by * * \u2026 * * ) . We would appreciate it if you could let us know whether the proposed changes address your concerns , or whether we have misinterpreted your comments . \u2022 You have raised an interesting question about how the accuracy of the GAN impacts the accuracy of the proposed method . In order to address this , we have developed analytical estimates for the error in the point estimates computed using the proposed approach and show that these are intimately tied to error in computing the point estimates for the prior using the GAN . We have also demonstrated that as the generator and the discriminator of the GAN become more expressive this error tends to zero , and the exact point estimates , for both the prior and the posterior , are recovered . * * In the revised manuscript , we will include this mathematical analysis in the Appendix and refer to it in the main text . * * \u2022 We note that our method of inferring the desired image from the measured image is an unsupervised method ; for training we only need a set of desired images to construct the prior . We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty . In that regard , the calculation of point-wise variance ( our metric of uncertainty ) is possible only using our approach , and therefore a direct comparison is not possible , since other supervised methods ( explained below ) can not work in this setting where only set of desired images are available . * * We will clarify this unique aspect in the revised version of the manuscript . * * \u2022 There has been some work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network [ 1 , 2 ] . In these articles the authors have used methods like Bayesian dropout and variational autoencoder to compute uncertainty in the inferred images . * * We will refer to these works in the revised version to better orient reader . * * [ 1 ] .A . Kendall and Y. Gal , \u201c What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision ? \u201d , NIPS ( 2017 ) . [ 2 ] .Kohl , S.A. , Romera-Paredes , B. , Meyer , C. , Fauw , J.D. , Ledsam , J.R. , Maier-Hein , K.H. , Eslami , S.M. , Rezende , D.J. , & Ronneberger , O . \u201c A Probabilistic U-Net for Segmentation of Ambiguous Images \u201d , NeurIPS ( 2018 ) ."}, {"review_id": "HyeAPeBFwS-2", "review_text": "This paper proposes to use a trained GAN model as the prior distribution for Bayesian inference to quantify the uncertainty. As for me, the best application of this paper is to restore a corrupted image, which shares a lot of common properties in image restoration, denoising and image reconstruction. I do like the extension of applying the idea in physics problems. And the results demonstrate at some extent, the proposed method could evaluate some uncertainty. The idea is pretty simple and the paper is easy to read. Nonetheless, there are some issues: A big issue of this paper is the deviation of purpose and method. As the paper claims to quantify the uncertainty, the paper is supposed to give specific quantitative metric or values to probe the uncertainty. However, the paper demonstrates to us only the ability, not exactly \u201cquantification\u201d. I\u2019d like to see a specific metric of uncertainty that could only be calculated through the proposed method. There are some grammar issues in the paper. For example. \u201c\u2026we the MAP\u2026\u201d in the 7th page. Given my major issue seems to be quite problematic, I currently would weakly reject this paper. But I don\u2019t have a full picture over this area, I\u2019ll read the rebuttal and see if I could raise the score.", "rating": "3: Weak Reject", "reply_text": "Thank you for your valuable feedback ! After carefully reviewing it , we plan to modify the manuscript as discussed below ( the planned changes are shown by * * ... * * ) . We would appreciate it if you could let us know whether the proposed changes address your concerns , or whether we have misinterpreted your comments . `` A big issue of this paper is the deviation of purpose and method . As the paper claims to quantify the uncertainty , the paper is supposed to give specific quantitative metric or values to probe the uncertainty . However , the paper demonstrates to us only the ability , not exactly 'quantification ' . I \u2019 d like to see a specific metric of uncertainty that could only be calculated through the proposed method . '' You are right , the main purpose of the method is to quantify uncertainty in the task of image inference . Given this , we treat the inference as a stochastic problem , and develop an expression for the probability density function of the inferred image ( i.e.joint pdf for each pixel of the inferred image ) . Once this is done , we sample from this distribution and compute any appropriate point estimate that can quantify the uncertainty in the inference . In our work , we have chosen the `` pixel-wise '' variance as this metric . Note that this metric is a field and not a scalar quantity and is plotted as an image . We have computed this metric for every example in the manuscript ( see last row of figure 2 , 3 , 5 etc ) . * * However , we have been remiss in not highlighting , or bringing the reader \u2019 s attention to it . In the revised version of the paper we will do this . * * Some more things to note : 1 . In one example ( Figure 4 ) we compute a scalar metric ( that is the average variance/per pixel over the entire image ) for the inferred images , and show that this measure increases with increasing noise in the input , as it should . * * In the revised version , we will draw the reader 's attention to this example . * * 2.We note that our method of inferring the desired image from the measured image is an unsupervised method ; in that for training we only need a set of desired images to construct the prior . We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty . In that regards , the calculation of pixel-wise variance ( our metric of uncertainty ) in an unsupervised setting is possible only using our approach . * * We will clarify this unique aspect in the revised version of the manuscript . * * 3.We note that there has been recent work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network . In these articles the authors have used methods like Bayesian dropout to compute uncertainty in the inferred images [ 1 ] . Similar to what we have done , these authors have also plotted the point-wise variance as a quantitative metric of uncertainty . * * We will refer to these works in the revised version to better orient the readers . * * 4.We note that we have gone beyond just computing the metric of uncertainty ( point-wise variance ) and also described how it might be useful in making the subsequent measurement in the context of an active learning approach , which to the best of our knowledge has not been done previously in Bayesian deep learning applied to image inference . `` There are some grammar issues in the paper . For example . '\u2026we the MAP\u2026 ' in the 7th page . '' * * We are doing a through scrub of manuscript in order to catch these . * * [ 1 ] .A . Kendall and Y. Gal , \u201c What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision ? \u201d , NIPS ( 2017 ) ."}], "0": {"review_id": "HyeAPeBFwS-0", "review_text": "Summary of the paper: The paper proposes a Bayesian approach to make inference about latent variables such as un-corrupted images. The prior distribution plays a key role in this task. The authors use a GAN to estimate this prior distribution. Then, standard Bayesian techniques such a Hamilton Monte Carlo are used to make inference about the latent variables. Detailed comments: Eq. (8) is expected to give very bad results. The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y. The paper does not address learning any model parameters. e.g. the amount of noise. A more principled approach would be to estimate the prior parameters using maximum likelihood estimation. That has already been done in the case of the variational autoencoder. The variational autoencoder is an already known method that can be used to solve the problem formulated by the authors. It also automatically proposes an inference network that can be used for recognition. If the likelihood is Gaussian and p(x|z) is also Gaussian, one can directly marginalize x and work with p(y|z) and p(z). The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model. It is not clear how the HMC parameters are fixed. The experiments do not have error bars (Figure 4.) This questions the significance of the results. My overall impression is that there is little novelty in the proposed approach. Namely, using a GAN to learn the prior distribution, and then very well known techniques to infer the original input image. I have missed some references to related work on inverse problems. An example is: https://arxiv.org/pdf/1712.03353.pdf Is the original figure contained in the training set used to infer the GAN. If so that can lead to biased results. I have missed a simple baseline in which one simply finds the training image that is closest to the corrupted observed or partially observed image. My overall impression is that there is not much novelty in the paper as it is simply a combination of well known techniques. E.g. GANs and Bayesian inference with Monte Carlo methods. ", "rating": "3: Weak Reject", "reply_text": "Thank you for your valuable feedback ! After carefully reading your comments we plan to modify the manuscript as discussed below ( the planned changes are shown by * * \u2026 * * ) . We would appreciate it if you could let us know whether the proposed changes address your concerns , or whether we have misinterpreted your comments . -- -- - `` Eq . ( 8 ) is expected to give very bad results . The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y . '' We agree that it is in general a bad idea to use this equation , especially when the likelihood is very informative . However , we have found that for likelihoods that are not very informative this method is still useful . Furthermore , we would like to point out that we do not use this equation for the results shown in the manuscript , but rather use MCMC ( eq . ( 9 ) ) for all the results . * * We will include this discussion in the revised manuscript . * * -- -- - `` The paper does not address learning any model parameters . e.g.the amount of noise . '' You are right , we do not learn parameters associated with the noise in this work . We do however learn the parameters associated with the forward model by mapping them back to the latent space of the GAN . This is most clear in the context of the physics-based model ( Section 3.2 ) , where we parameterize forward model using pixel-wise values of the initial temperature , and then learn these parameters using the proposed method . We note that the proposed approach can easily be extended to regime where likelihood is also unknown by incorporating likelihood-free inference methods like ABC or meta-learning approaches . * * We will include this discussion the revised version * * . -- -- - `` A more principled approach would be to estimate the prior parameters using maximum likelihood estimation . That has already been done in the case of the variational autoencoder . The variational autoencoder is an already known method that can be used to solve the problem formulated by the authors . It also automatically proposes an inference network that can be used for recognition . If the likelihood is Gaussian and p ( x|z ) is also Gaussian , one can directly marginalize x and work with p ( y|z ) and p ( z ) . The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model . '' We agree that we were lacking a proof that demonstrated the convergence of the proposed method for computing point estimates of the posterior . * * We have now derived this proof and will include it in the Appendix . * * In a nutshell , this proof establishes that with increasing the expressivity of the generator and the discriminator ( increasing number weights ) the point estimates computed using the proposed approach converges to the true point estimates of the posterior . We agree that using a variational autoencoder ( VAE ) in lieu of a GAN is an interesting extension of the proposed approach and that this can be accomplished in different ways . * * We are working on writing a concise description of these ideas and will include in the revised manuscript . * * However , we would like to point out that for image recovery tasks GANs have consistently demonstrated better performance than VAEs , as the latter tend to smear out images due to their maximum likelihood loss . While the idea of using corrupted images to train the VAE and inferring the latent variable , which would be the - un-corrupted image is very interesting and using VAE with max . likelihood loss is an intriguing option , there are some major drawbacks of using it in the proposed Bayesian inference setting . \u2022 It is well-known that image samples produced by VAEs are quite blurry and of poorer quality than GAN and fail to match the true data distribution . It is shown in earlier studies that they fail to match marginal distribution not only in visible space but also in latent space [ 1 ] . Since , the focus of our paper is to use these distributions as priors , we believe that it is better to select a model for these distributions and hence GAN is our preferred choice . \u2022 Furthermore , VAEs are explicit density model and we have to select a model family ( like Gaussian ) for the latent variables . Therefore , in a setting where we treat un-corrupted images as latent variables ( as suggested by the reviewer ) , and use max . likelihood as our loss function , we are forcing the latent variables to be close to that chosen family of distributions . This , might fail to capture complex inferred joint probability distribution seen in the examples considered in this manuscript , which is far from Gaussian ( or any other simple distribution ) . It is also against the spirit of this work , where we want to make as few assumption as possible for our prior and use data to guide its final form . [ 1 ] .Rosca , M. , Lakshminarayanan , B. , & Mohamed , S. ( 2018 ) . Distribution Matching in Variational Inference . ArXiv , abs/1802.06847 ."}, "1": {"review_id": "HyeAPeBFwS-1", "review_text": "The paper studies the Bayesian inferences with the generative adversarial network (GAN). In the first half of the paper, the general framework of the Bayes estimation is introduced. Then, The authors proposed how to incorporate GAN to the Bayesian inference. Some computational methods for calculating the mean of the statistic under the posterior distribution are described. Then, numerical experiments using MNIST and Celeb-A datasets are presented. Though the Bayesian inference using GAN is a natural idea, learning algorithms proposed in this paper are simple and are not intensively developed. In numerical experiments, there is no comparison with major competitors besides random sampling in the active learning setup. Hence, the effectiveness and advantage of the proposed methods are not clear. - In active learning, the proposed method should be compared with other methods such as Bayesian DNN using dropout, etc. - How does the estimation accuracy of GAN relate to the estimation accuracy of the proposed method? Showing a quantitative description would be nice. ", "rating": "3: Weak Reject", "reply_text": "Thank you for your valuable feedback ! After carefully reading it , we plan to modify the manuscript as discussed below ( the planned changes are shown by * * \u2026 * * ) . We would appreciate it if you could let us know whether the proposed changes address your concerns , or whether we have misinterpreted your comments . \u2022 You have raised an interesting question about how the accuracy of the GAN impacts the accuracy of the proposed method . In order to address this , we have developed analytical estimates for the error in the point estimates computed using the proposed approach and show that these are intimately tied to error in computing the point estimates for the prior using the GAN . We have also demonstrated that as the generator and the discriminator of the GAN become more expressive this error tends to zero , and the exact point estimates , for both the prior and the posterior , are recovered . * * In the revised manuscript , we will include this mathematical analysis in the Appendix and refer to it in the main text . * * \u2022 We note that our method of inferring the desired image from the measured image is an unsupervised method ; for training we only need a set of desired images to construct the prior . We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty . In that regard , the calculation of point-wise variance ( our metric of uncertainty ) is possible only using our approach , and therefore a direct comparison is not possible , since other supervised methods ( explained below ) can not work in this setting where only set of desired images are available . * * We will clarify this unique aspect in the revised version of the manuscript . * * \u2022 There has been some work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network [ 1 , 2 ] . In these articles the authors have used methods like Bayesian dropout and variational autoencoder to compute uncertainty in the inferred images . * * We will refer to these works in the revised version to better orient reader . * * [ 1 ] .A . Kendall and Y. Gal , \u201c What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision ? \u201d , NIPS ( 2017 ) . [ 2 ] .Kohl , S.A. , Romera-Paredes , B. , Meyer , C. , Fauw , J.D. , Ledsam , J.R. , Maier-Hein , K.H. , Eslami , S.M. , Rezende , D.J. , & Ronneberger , O . \u201c A Probabilistic U-Net for Segmentation of Ambiguous Images \u201d , NeurIPS ( 2018 ) ."}, "2": {"review_id": "HyeAPeBFwS-2", "review_text": "This paper proposes to use a trained GAN model as the prior distribution for Bayesian inference to quantify the uncertainty. As for me, the best application of this paper is to restore a corrupted image, which shares a lot of common properties in image restoration, denoising and image reconstruction. I do like the extension of applying the idea in physics problems. And the results demonstrate at some extent, the proposed method could evaluate some uncertainty. The idea is pretty simple and the paper is easy to read. Nonetheless, there are some issues: A big issue of this paper is the deviation of purpose and method. As the paper claims to quantify the uncertainty, the paper is supposed to give specific quantitative metric or values to probe the uncertainty. However, the paper demonstrates to us only the ability, not exactly \u201cquantification\u201d. I\u2019d like to see a specific metric of uncertainty that could only be calculated through the proposed method. There are some grammar issues in the paper. For example. \u201c\u2026we the MAP\u2026\u201d in the 7th page. Given my major issue seems to be quite problematic, I currently would weakly reject this paper. But I don\u2019t have a full picture over this area, I\u2019ll read the rebuttal and see if I could raise the score.", "rating": "3: Weak Reject", "reply_text": "Thank you for your valuable feedback ! After carefully reviewing it , we plan to modify the manuscript as discussed below ( the planned changes are shown by * * ... * * ) . We would appreciate it if you could let us know whether the proposed changes address your concerns , or whether we have misinterpreted your comments . `` A big issue of this paper is the deviation of purpose and method . As the paper claims to quantify the uncertainty , the paper is supposed to give specific quantitative metric or values to probe the uncertainty . However , the paper demonstrates to us only the ability , not exactly 'quantification ' . I \u2019 d like to see a specific metric of uncertainty that could only be calculated through the proposed method . '' You are right , the main purpose of the method is to quantify uncertainty in the task of image inference . Given this , we treat the inference as a stochastic problem , and develop an expression for the probability density function of the inferred image ( i.e.joint pdf for each pixel of the inferred image ) . Once this is done , we sample from this distribution and compute any appropriate point estimate that can quantify the uncertainty in the inference . In our work , we have chosen the `` pixel-wise '' variance as this metric . Note that this metric is a field and not a scalar quantity and is plotted as an image . We have computed this metric for every example in the manuscript ( see last row of figure 2 , 3 , 5 etc ) . * * However , we have been remiss in not highlighting , or bringing the reader \u2019 s attention to it . In the revised version of the paper we will do this . * * Some more things to note : 1 . In one example ( Figure 4 ) we compute a scalar metric ( that is the average variance/per pixel over the entire image ) for the inferred images , and show that this measure increases with increasing noise in the input , as it should . * * In the revised version , we will draw the reader 's attention to this example . * * 2.We note that our method of inferring the desired image from the measured image is an unsupervised method ; in that for training we only need a set of desired images to construct the prior . We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty . In that regards , the calculation of pixel-wise variance ( our metric of uncertainty ) in an unsupervised setting is possible only using our approach . * * We will clarify this unique aspect in the revised version of the manuscript . * * 3.We note that there has been recent work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network . In these articles the authors have used methods like Bayesian dropout to compute uncertainty in the inferred images [ 1 ] . Similar to what we have done , these authors have also plotted the point-wise variance as a quantitative metric of uncertainty . * * We will refer to these works in the revised version to better orient the readers . * * 4.We note that we have gone beyond just computing the metric of uncertainty ( point-wise variance ) and also described how it might be useful in making the subsequent measurement in the context of an active learning approach , which to the best of our knowledge has not been done previously in Bayesian deep learning applied to image inference . `` There are some grammar issues in the paper . For example . '\u2026we the MAP\u2026 ' in the 7th page . '' * * We are doing a through scrub of manuscript in order to catch these . * * [ 1 ] .A . Kendall and Y. Gal , \u201c What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision ? \u201d , NIPS ( 2017 ) ."}}