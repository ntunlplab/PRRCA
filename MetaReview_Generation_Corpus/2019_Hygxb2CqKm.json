{"year": "2019", "forum": "Hygxb2CqKm", "title": "Stable Recurrent Models", "decision": "Accept (Poster)", "meta_review": "The paper presents both theoretical analysis (based upon lambda-stability) and experimental evidence on stability of recurrent neural networks. The results are convincing but is concerns with a restricted definition of stability. Even with this restriction acceptance is recommended. ", "reviews": [{"review_id": "Hygxb2CqKm-0", "review_text": "+ An interesting problem to study on the stability of RNNs + Investigation of spectral normalization to sequential predictions is worthwhile, especially Figure 2 + Some theoretical justification of SGD for learning dynamic systems following Hardt et al. (2016b). - The take-home message of the paper is not clear. First, it defines a notion of stability based on Lipchitz-continuity and proves SGD can learn it. Then the experiments show such a definition is actually not correct, but rather a data-dependent one. - The theory only looks at the instantaneous dynamics from time t to t+1, without unrolling the RNNs over time. Then it is not much different from analyzing feed-forward networks. The theorem on SGD is remotely related to the contribution of the paper. - The spectral normalization technique that is actually used in experiments is not new", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your comments and feedback . We address each of your concerns below . Take-home message : The message of the paper is that sequence learning happens , or can be made to happen , in the stable regime . The Lipschitz definition of stability ( eq.2 ) and the \u201c data-dependent \u201d definition introduced in the experiments are complementary . The data-dependent definition is just a relaxation of the Lipschitz criteria -- we only require equation 2 to hold for inputs from the data-distribution . For the proofs and the majority of the experiments , the strict Lipschitz condition suffices . Most models can be made stable in the sense of equation 2 without performance loss . For LSTMs on language modeling , the data-dependent version illustrates even the nominally unstable LSTMs are close to the stable regime -- a truly unstable model would not satisfy even this weaker definition . We view results with both definitions as evidence recurrent models trained in practice operate in the stable regime . Instantaneous dynamics : The theory in our paper does consider unrolling the RNNs over time . While the stability condition is stated purely in terms of the the state-transition function from step t to step t+1 , the main theoretical results ( Proposition 3 and Theorem 1 ) specifically concern the unrolled RNN . In particular , our results show that the unrolled ( stable ) RNN can be approximated by a feed-forward network . Spectral Normalization : In our experiments , our focus is more on comparing the performance of stable and unstable models and less on the particular form of normalization used to achieve stability . In the RNN case , enforcing stability via constraining the spectral norm of the recurrent matrix is fairly routine . In the LSTM case , the stability conditions given in Proposition 2 are new and allow one to experiment with stable LSTMs . The updated version of the paper includes a discussion of these other works ."}, {"review_id": "Hygxb2CqKm-1", "review_text": "This is an interesting paper that I expect will generate some interest within the ICLR community and from deep learning researchers in general. The definition of stability is both intuitive and sound and the connection to exploding gradients is perhaps the most interesting and useful part of the paper. The sufficient conditions yield practical techniques for increasing the stability of, e.g., an LSTM, by constraining the weight matrices. They also show that stable recurrent models can be approximated by models with finite historical windows, e.g., truncated RNNs. Experiments in Sec 4 suggest that stable models produced by constraining standard RNN architectures can compete with their unconstrained unstable counterparts, and often without necessitating significant changes to architecture or hyperparameters. The perhaps most interesting observations are in Sec 4.3, in which the authors claim that even fundamentally unstable models, e.g., unconstrained RNNs, often operate in a stable regime, at least when being applied to in-sample data. I lean toward acceptance at the moment, but I am eager to discuss with the authors and other reviewers as I am not 100% confident that I fully understood the theory. SUMMARY This paper proposes a simple, generic definition of \u201cstability\u201d for recurrent, non-linear dynamical systems such as RNNs: that given two hidden states h, h\u2019, the difference between their updated states given input x is bounded by the product between the difference between the states themselves and a small multiplier. The paper then immediately draws a connection between stability, asserting that unstable models are prone to gradient explosions during gradient descent-based training. In Sec 2.2, the paper presents sufficient conditions for basic RNNs and LSTMs to be stable. Secs 3.2 and 3.3 argue that stable recurrent models can be approximated by feedforward models during both inference and training with a finite history horizon, such as a RNN with a truncated history. Experiments in language and music modeling substantiate this claim: constrained, stable models are competitive with standard unconstrained models. Sec 4.3 sheds some light on this phenomenon, arguing that there is a weaker form of data-dependent stability and that even unstable models may operate in a stable regime for some problems, thus explaining the parity between stable and unstable models. STRENGTHS * This paper is surprisingly engaging and easy to read. * The theorems are clearly stated and the proofs appear sound to me, though I will admit that I am not confident that I would catch a significant bug. * This paper provides a new (to me, anyway) and thought-provoking analysis of RNNs. In particular, I was especially interested in the observation that stable models can be approximated by truncated models and that there is a connection between stability and long-term dependencies. This seems consistent with the fact that for many problems, non-recurrent models (ConvNets, Transformers, etc.) are often competitive with more complex architectures. WEAKNESSES * In practice it seems as though stability may depend on not only choice of model architecture but also the data themselves. There is probably no good way to know a priori what the stability characteristics of a given data set are, making it tough to apply the ideas of this paper in practice * The literature review seems a bit limited and appears to ignore the growing body of work on constraining RNN weight matrices to address both exploding and vanishing gradients. For example, I am pretty confident that the singular thresholding trick for renormalizing neural net weights has been described in the literature previously. * Although stable and unstable models appear to be competitive in experiments, the theoretical analysis provides no insights into stability and how it relates to accuracy.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your detailed comments and feedback . We agree it is difficult to know a priori whether particular dataset will be amenable to stable models . However , stability can still be a clarifying idea in practice . Given a dataset where stable models perform comparably with unstable models , either the dataset does not require long-term memory ( i.e.feed-forward approximation suffices ) , or the unstable models do not take advantage of it . We conjecture most recurrent models successfully trained in practice are operating in the stable regime . To further test this claim , it would be interesting to find datasets ( if any ) where unstable models significantly outperform stable models , or datasets where non-recurrent models aren \u2019 t competitive with their recurrent counterparts . In the revision , we added discussion of the several recent works constraining RNN matrices . These works try to keep the model just outside the stable regime to avoid vanishing gradients and side-step exploding gradients ( i.e.take lambda ~ 1 ) . The spectral norm thresholding technique for RNNs is straightforward , whereas the stability conditions for the LSTM is new . In either case , our focus is on using these techniques to understand the consequences of imposing stability on recurrent models . In general , answering the question of accuracy is fairly delicate . We \u2019 re able to show stable and truncated/feed-forward models have the same accuracy . Bounds relating the accuracy of an unstable model with the accuracy of an stable one almost certainly require further assumptions on the data distribution . Obtaining such accuracy bounds for neural networks has been elusive , and part of the contribution of our work is proving a connection between the performance two model classes ( stable RNNs and truncated/feed-forward models ) without needing to resolve these questions ."}, {"review_id": "Hygxb2CqKm-2", "review_text": "In this paper, the authors study the stability property of recurrent neural networks. Adopting the definition of stability from the dynamical system literature, the authors present a generic definition of stable recurrent models and provide sufficient conditions of stable linear RNNs and LSTMs. The authors also study the \"feed-forward\" approximation of recurrent networks and theoretically show that the approximation works for both inference and training. Experimental studies compare the performance of stable and unstable models on various tasks. The paper is well-written and very pleasant to read. The notations are clear and the claims are relatively easy to follow. The theoretical analysis in Section 3 is novel, interesting and solid. However, the reviewer has concerns about the motivation of the presented analysis and insufficient empirical results. The stability property only eliminates the exploding gradient problem, but not the vanishing gradient problem. The reviewer suspects that a stable recurrent model always suffers from vanishing gradient. Therefore, stability might not necessarily be a desirable property. There has been a line of work that constrain the weight matrix in RNNs to be orthogonal or unitary so that the gradient won't explode, e.g. [1], [2], [3]. It seems that the orthogonal or unitary conditions are stronger than the stability condition, and are probably less prone to the vanishing gradient problem. The vanishing gradient problem is also related to the analysis in Section 3. If a recurrent network is very stable and has vanishing gradient, then a small perturbation of the initial hidden state has little effect on later time steps. This intuitively explains why it can be well approximated by using only the last k time steps. However, the recurrent model itself might not be a desirable model. In other words, although Theorem 1 shows that $y_T$ and $y_T^k$ can be arbitrarily close, $y_T$ might not be a good prediction. The experimental study seems weak. Again, in the RNN case, constraining the singular values of the weight matrix is not a new idea. Furthermore, the results in Table 1 seem to suggest that the stable models perform worse than unstable ones. What is the benefit in using stable models? Proposition 2 is only a sufficient condition of a stable LSTM and it seems very restrictive, as the authors point out. This might explain the worse performance of the stable LSTMs in Table 1. The reviewer was expecting more experimental results to support the claims in Section 3. For example, an empirically study of the difference between a recurrent model and a \"feed-forward\" or truncation approximation. Minor comments: * Lemma 1: $\\lambda$-contractive => $\\lambda$-contractive in $h$? * Theorem 1: $k=O(...)$ => $k=\\Omega(...)$? Intuitively, a bigger k leads to a better feed-forward approximation. [1] Martin Arjovsky, Amar Shah, and Yoshua Bengio. Unitary evolution recurrent neural networks. ICML, 2016. [2] Scott Wisdom, Thomas Powers, John Hershey, Jonathan Le Roux, and Les Atlas. Full-capacity unitary recurrent neural networks. NIPS, 2016. [3] Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal. On orthogonality and learning recurrent networks with long term dependencies. ICML, 2017.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your detailed comments and feedback . We have incorporated some of these suggestions into a revision of the paper . We discuss your concerns below . Motivation of stable models : There are two reasons to consider stability in recurrent models : 1 ) Stability is natural criterion for learnability in recurrent models . Outside the stable regime , learning recurrent models requires a delicate mix of heuristics . Studying stable models addresses whether this collection of tricks is actually necessary , and our results suggest a better-behaved model class can solve many of the same problems . 2 ) Understanding whether models trained in practice are in the stable regime helps answer when recurrent models are truly necessary . As the reviewer noted , whether the stable model is \u201c desirable \u201d depends on experimentation . However , when a stable model achieves similar performance with an unstable model , the conclusion is a feed-forward network suffices to solve the task . We demonstrate sequence learning happens in the stable regime , and this helps explain the widespread success of feed-forward models on sequence problems . Vanishing Gradients : Stable recurrent models always have vanishing gradients , and vanishing gradients are an important part of proving our approximation results . However , vanishing gradients are not unique to stable models . In the updated version of the paper , we show unstable language models also exhibit vanishing gradients . This corroborates the evidence in section 4.3 showing these models operate in the stable regime . The cited unitary RNN models may help reduce vanishing gradients . Even in these works , there is still gradient decay over time ( e.g.Figure 4 , ii in [ 1 ] ) , but the rate of decay is slower . The updated version of the paper includes a brief discussion of these works . At minimum , these models have not yet seen widespread use , and our work demonstrates models frequently trained in practice are either stable or can be made stable without performance loss . Empirical study of the difference between recurrent and truncated models : In the revision , we added experiments studying truncation in the unstable models and also show unstable models satisfy a qualitative version of Theorem 1 . All of the models considered , including the LSTM language models , exhibit sharply diminishing returns to larger values of the truncation parameter . As predicted by theorem 1 , the difference between the truncated and full recurrent matrix during training becomes small for moderate values of the truncation parameter . Comparison between stable and unstable models : We disagree with the interpretation of Table 1 . Except for the LSTM language models , the variation in performance between stable and unstable models is within standard-error . We do not retune the hyperparameters when imposing stability , and the near equivalence of the results is evidence the unstable models do not offer a large performance boost . For the LSTM language models , in section 4.3 and 4.4 , we argue the unstable LSTM language models are close to the stable regime , and the gap between stable and unstable models is an artifact of the particular way we impose stability ."}], "0": {"review_id": "Hygxb2CqKm-0", "review_text": "+ An interesting problem to study on the stability of RNNs + Investigation of spectral normalization to sequential predictions is worthwhile, especially Figure 2 + Some theoretical justification of SGD for learning dynamic systems following Hardt et al. (2016b). - The take-home message of the paper is not clear. First, it defines a notion of stability based on Lipchitz-continuity and proves SGD can learn it. Then the experiments show such a definition is actually not correct, but rather a data-dependent one. - The theory only looks at the instantaneous dynamics from time t to t+1, without unrolling the RNNs over time. Then it is not much different from analyzing feed-forward networks. The theorem on SGD is remotely related to the contribution of the paper. - The spectral normalization technique that is actually used in experiments is not new", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your comments and feedback . We address each of your concerns below . Take-home message : The message of the paper is that sequence learning happens , or can be made to happen , in the stable regime . The Lipschitz definition of stability ( eq.2 ) and the \u201c data-dependent \u201d definition introduced in the experiments are complementary . The data-dependent definition is just a relaxation of the Lipschitz criteria -- we only require equation 2 to hold for inputs from the data-distribution . For the proofs and the majority of the experiments , the strict Lipschitz condition suffices . Most models can be made stable in the sense of equation 2 without performance loss . For LSTMs on language modeling , the data-dependent version illustrates even the nominally unstable LSTMs are close to the stable regime -- a truly unstable model would not satisfy even this weaker definition . We view results with both definitions as evidence recurrent models trained in practice operate in the stable regime . Instantaneous dynamics : The theory in our paper does consider unrolling the RNNs over time . While the stability condition is stated purely in terms of the the state-transition function from step t to step t+1 , the main theoretical results ( Proposition 3 and Theorem 1 ) specifically concern the unrolled RNN . In particular , our results show that the unrolled ( stable ) RNN can be approximated by a feed-forward network . Spectral Normalization : In our experiments , our focus is more on comparing the performance of stable and unstable models and less on the particular form of normalization used to achieve stability . In the RNN case , enforcing stability via constraining the spectral norm of the recurrent matrix is fairly routine . In the LSTM case , the stability conditions given in Proposition 2 are new and allow one to experiment with stable LSTMs . The updated version of the paper includes a discussion of these other works ."}, "1": {"review_id": "Hygxb2CqKm-1", "review_text": "This is an interesting paper that I expect will generate some interest within the ICLR community and from deep learning researchers in general. The definition of stability is both intuitive and sound and the connection to exploding gradients is perhaps the most interesting and useful part of the paper. The sufficient conditions yield practical techniques for increasing the stability of, e.g., an LSTM, by constraining the weight matrices. They also show that stable recurrent models can be approximated by models with finite historical windows, e.g., truncated RNNs. Experiments in Sec 4 suggest that stable models produced by constraining standard RNN architectures can compete with their unconstrained unstable counterparts, and often without necessitating significant changes to architecture or hyperparameters. The perhaps most interesting observations are in Sec 4.3, in which the authors claim that even fundamentally unstable models, e.g., unconstrained RNNs, often operate in a stable regime, at least when being applied to in-sample data. I lean toward acceptance at the moment, but I am eager to discuss with the authors and other reviewers as I am not 100% confident that I fully understood the theory. SUMMARY This paper proposes a simple, generic definition of \u201cstability\u201d for recurrent, non-linear dynamical systems such as RNNs: that given two hidden states h, h\u2019, the difference between their updated states given input x is bounded by the product between the difference between the states themselves and a small multiplier. The paper then immediately draws a connection between stability, asserting that unstable models are prone to gradient explosions during gradient descent-based training. In Sec 2.2, the paper presents sufficient conditions for basic RNNs and LSTMs to be stable. Secs 3.2 and 3.3 argue that stable recurrent models can be approximated by feedforward models during both inference and training with a finite history horizon, such as a RNN with a truncated history. Experiments in language and music modeling substantiate this claim: constrained, stable models are competitive with standard unconstrained models. Sec 4.3 sheds some light on this phenomenon, arguing that there is a weaker form of data-dependent stability and that even unstable models may operate in a stable regime for some problems, thus explaining the parity between stable and unstable models. STRENGTHS * This paper is surprisingly engaging and easy to read. * The theorems are clearly stated and the proofs appear sound to me, though I will admit that I am not confident that I would catch a significant bug. * This paper provides a new (to me, anyway) and thought-provoking analysis of RNNs. In particular, I was especially interested in the observation that stable models can be approximated by truncated models and that there is a connection between stability and long-term dependencies. This seems consistent with the fact that for many problems, non-recurrent models (ConvNets, Transformers, etc.) are often competitive with more complex architectures. WEAKNESSES * In practice it seems as though stability may depend on not only choice of model architecture but also the data themselves. There is probably no good way to know a priori what the stability characteristics of a given data set are, making it tough to apply the ideas of this paper in practice * The literature review seems a bit limited and appears to ignore the growing body of work on constraining RNN weight matrices to address both exploding and vanishing gradients. For example, I am pretty confident that the singular thresholding trick for renormalizing neural net weights has been described in the literature previously. * Although stable and unstable models appear to be competitive in experiments, the theoretical analysis provides no insights into stability and how it relates to accuracy.", "rating": "7: Good paper, accept", "reply_text": "Thank you for your detailed comments and feedback . We agree it is difficult to know a priori whether particular dataset will be amenable to stable models . However , stability can still be a clarifying idea in practice . Given a dataset where stable models perform comparably with unstable models , either the dataset does not require long-term memory ( i.e.feed-forward approximation suffices ) , or the unstable models do not take advantage of it . We conjecture most recurrent models successfully trained in practice are operating in the stable regime . To further test this claim , it would be interesting to find datasets ( if any ) where unstable models significantly outperform stable models , or datasets where non-recurrent models aren \u2019 t competitive with their recurrent counterparts . In the revision , we added discussion of the several recent works constraining RNN matrices . These works try to keep the model just outside the stable regime to avoid vanishing gradients and side-step exploding gradients ( i.e.take lambda ~ 1 ) . The spectral norm thresholding technique for RNNs is straightforward , whereas the stability conditions for the LSTM is new . In either case , our focus is on using these techniques to understand the consequences of imposing stability on recurrent models . In general , answering the question of accuracy is fairly delicate . We \u2019 re able to show stable and truncated/feed-forward models have the same accuracy . Bounds relating the accuracy of an unstable model with the accuracy of an stable one almost certainly require further assumptions on the data distribution . Obtaining such accuracy bounds for neural networks has been elusive , and part of the contribution of our work is proving a connection between the performance two model classes ( stable RNNs and truncated/feed-forward models ) without needing to resolve these questions ."}, "2": {"review_id": "Hygxb2CqKm-2", "review_text": "In this paper, the authors study the stability property of recurrent neural networks. Adopting the definition of stability from the dynamical system literature, the authors present a generic definition of stable recurrent models and provide sufficient conditions of stable linear RNNs and LSTMs. The authors also study the \"feed-forward\" approximation of recurrent networks and theoretically show that the approximation works for both inference and training. Experimental studies compare the performance of stable and unstable models on various tasks. The paper is well-written and very pleasant to read. The notations are clear and the claims are relatively easy to follow. The theoretical analysis in Section 3 is novel, interesting and solid. However, the reviewer has concerns about the motivation of the presented analysis and insufficient empirical results. The stability property only eliminates the exploding gradient problem, but not the vanishing gradient problem. The reviewer suspects that a stable recurrent model always suffers from vanishing gradient. Therefore, stability might not necessarily be a desirable property. There has been a line of work that constrain the weight matrix in RNNs to be orthogonal or unitary so that the gradient won't explode, e.g. [1], [2], [3]. It seems that the orthogonal or unitary conditions are stronger than the stability condition, and are probably less prone to the vanishing gradient problem. The vanishing gradient problem is also related to the analysis in Section 3. If a recurrent network is very stable and has vanishing gradient, then a small perturbation of the initial hidden state has little effect on later time steps. This intuitively explains why it can be well approximated by using only the last k time steps. However, the recurrent model itself might not be a desirable model. In other words, although Theorem 1 shows that $y_T$ and $y_T^k$ can be arbitrarily close, $y_T$ might not be a good prediction. The experimental study seems weak. Again, in the RNN case, constraining the singular values of the weight matrix is not a new idea. Furthermore, the results in Table 1 seem to suggest that the stable models perform worse than unstable ones. What is the benefit in using stable models? Proposition 2 is only a sufficient condition of a stable LSTM and it seems very restrictive, as the authors point out. This might explain the worse performance of the stable LSTMs in Table 1. The reviewer was expecting more experimental results to support the claims in Section 3. For example, an empirically study of the difference between a recurrent model and a \"feed-forward\" or truncation approximation. Minor comments: * Lemma 1: $\\lambda$-contractive => $\\lambda$-contractive in $h$? * Theorem 1: $k=O(...)$ => $k=\\Omega(...)$? Intuitively, a bigger k leads to a better feed-forward approximation. [1] Martin Arjovsky, Amar Shah, and Yoshua Bengio. Unitary evolution recurrent neural networks. ICML, 2016. [2] Scott Wisdom, Thomas Powers, John Hershey, Jonathan Le Roux, and Les Atlas. Full-capacity unitary recurrent neural networks. NIPS, 2016. [3] Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal. On orthogonality and learning recurrent networks with long term dependencies. ICML, 2017.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your detailed comments and feedback . We have incorporated some of these suggestions into a revision of the paper . We discuss your concerns below . Motivation of stable models : There are two reasons to consider stability in recurrent models : 1 ) Stability is natural criterion for learnability in recurrent models . Outside the stable regime , learning recurrent models requires a delicate mix of heuristics . Studying stable models addresses whether this collection of tricks is actually necessary , and our results suggest a better-behaved model class can solve many of the same problems . 2 ) Understanding whether models trained in practice are in the stable regime helps answer when recurrent models are truly necessary . As the reviewer noted , whether the stable model is \u201c desirable \u201d depends on experimentation . However , when a stable model achieves similar performance with an unstable model , the conclusion is a feed-forward network suffices to solve the task . We demonstrate sequence learning happens in the stable regime , and this helps explain the widespread success of feed-forward models on sequence problems . Vanishing Gradients : Stable recurrent models always have vanishing gradients , and vanishing gradients are an important part of proving our approximation results . However , vanishing gradients are not unique to stable models . In the updated version of the paper , we show unstable language models also exhibit vanishing gradients . This corroborates the evidence in section 4.3 showing these models operate in the stable regime . The cited unitary RNN models may help reduce vanishing gradients . Even in these works , there is still gradient decay over time ( e.g.Figure 4 , ii in [ 1 ] ) , but the rate of decay is slower . The updated version of the paper includes a brief discussion of these works . At minimum , these models have not yet seen widespread use , and our work demonstrates models frequently trained in practice are either stable or can be made stable without performance loss . Empirical study of the difference between recurrent and truncated models : In the revision , we added experiments studying truncation in the unstable models and also show unstable models satisfy a qualitative version of Theorem 1 . All of the models considered , including the LSTM language models , exhibit sharply diminishing returns to larger values of the truncation parameter . As predicted by theorem 1 , the difference between the truncated and full recurrent matrix during training becomes small for moderate values of the truncation parameter . Comparison between stable and unstable models : We disagree with the interpretation of Table 1 . Except for the LSTM language models , the variation in performance between stable and unstable models is within standard-error . We do not retune the hyperparameters when imposing stability , and the near equivalence of the results is evidence the unstable models do not offer a large performance boost . For the LSTM language models , in section 4.3 and 4.4 , we argue the unstable LSTM language models are close to the stable regime , and the gap between stable and unstable models is an artifact of the particular way we impose stability ."}}