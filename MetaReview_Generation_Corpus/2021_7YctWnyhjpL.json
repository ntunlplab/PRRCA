{"year": "2021", "forum": "7YctWnyhjpL", "title": "Multi-Task Learning by a Top-Down Control Network", "decision": "Reject", "meta_review": "The paper is very interesting and novel, and all reviewers are of the same opinion. \nThe main concern, however, is on the experimental section that is limited to image classification benchmarks and that some critical comparisons are missing (e.g. clarify factors that play key role in improvement, more computation and therefore more free parameters, how about non discriminative tasks, etc). \nThe heterogeneity question is in my opinion only partially answered by the authors but I also feel proper handling of this matter would require a proper multi-task setup and different target for the work.\nI also personally find applicability of the approach quite limited, I encourage the authors to further improve their work as I feel that with a proper revision would make a nice contribution for the community.", "reviews": [{"review_id": "7YctWnyhjpL-0", "review_text": "In this paper a novel top-down control network is introduced for multi-task learning . Different from the traditional bottom-up attention models , the authors introduce a top-down module to modify the activation of recognition network based on different tasks . Specifically\uff0cthe proposed module consists of three identical networks , which are BU1 , TD , BU2 streams . Given the input , the BU1 is firstly trained , and then the TD streams is trained by assigning the specific labels . After that , the BU2 is updated with the top-down parameters . Experimental results demonstrate the effectiveness of proposed model . Strength : 1 . It is interesting to introduce the semantic information from the top layer to guide the feature representation learning . Weakness : Although the experimental results show the better performance on the image classification , there are exist several unclear parts : 1 . The definition of multi-task in this paper refers to the different dataset \u2019 s classification ? Or referring to the different tasks , e.g.localization , classification , and attributes predication . In my opinion , the authors should provide more details on designing the validation experiments . And the proposed model should be tested on different tasks instead of only on the task of visual recognition . 2.Some bottom-up based model e.g.FiLM should be used as the baselines to validate the advantage of introducing the top-down stream . 3.If the top-down stream would make the recognition be sensitive for the visual variations ? Or the classification results may be dependent on the number of training samples ? 4.If the proposed model would be helpful for transfer learning ?", "rating": "7: Good paper, accept", "reply_text": "We would like to thank the reviewer for the positive feedback . We list below answers to specific concerns raised in the review : 1 . Similar concerns were raised by other reviewers . Please see our answer to all reviewers . 2.Regarding FiLM : There are two differences between FiLM and our approach . First , it keeps an initial backbone unaltered . Second , it uses both multiplicative and additive learned parameters in the modulation part . We tested these two aspects of FiLM adapted to the backbones used in the experiments . ( The Resnet-101 network used in the original FiLM is larger than the networks used in our model ) . | | | FiLM | Ours | | -- | -- | -- | -- | |MNIST |2 digits ( by loc ) | 95.42| 96.67| | | 4 digits |92.99 |94.64| | |9 digits | 75.75 | 88.07 | | |9 digits ( by ref ) |33.27 | 72.25 | |CLEVR | | 62.03 | 96.83 | 3 . Our recognition results naturally increased with the number of training examples . We found evidence in two results that our model can be trained with a smaller number of examples compared with alternatives . First , our \u201c stress test \u201d results , increasing CLEVR tasks to 1645 , in table 4a of the original paper , obtains better results than alternatives by a large gap . In this test , the number of examples is reduced to less than 45 training examples for each task in an epoch . Second , we compared results of the multi-mnist task with a controlled number of examples for the number \u2018 3 \u2019 in the top-left location ( new experiment ) . The reported accuracy below is for testing specifically instances of images with \u2018 3 \u2019 at the top-left . Learning starts faster and remains higher up to a large number of examples . |Number of examples|Ours | chmod | || -- || | 0 | 0 | 0 | | 10 | 0 | 0 | |100 | 50.59 | 0 | | 1000 | 85.54 | 26.44 | | 10000 | 94.85 | 72.87 | 4 . Use in transfer learning . This is a general interesting issue for future studies which we have not studied in detail . One attractive possibility is to use the learned task embedding in the network , for at least some aspects of transfer leaning . An example along this line is described in experiment 2 of the general response ."}, {"review_id": "7YctWnyhjpL-1", "review_text": "This paper presents a new architecture for multi-task learning that uses a top-down control network to modulate the activations of the main ( bottom-up ) recognition network . The model is applied to four datasets/tasks : multi-MNIST , CLEVR , CELEB-A , and CUB-200 , demonstrating good performance compared with baselines . I have the following comments and questions : - The proposed architecture requires the equivalent of three forward/backward passes : BU1 , TD , and BU2 . The number of parameters is used gauge complexity in Table 2 and Figure 3 but FLOPs might be a better metric here since BU1 and BU2 share parameters . How do the models compare in terms of FLOPs to baselines ? - The datasets/tasks used herein are homogenous and therefore straightforward for multi-task learning . How does the proposed architecture fair in a more challenging setting involving heterogeneous tasks , e.g. , Misra et al. , 2016 ? - Re `` In some of the experiments of CLEVR and CUB-200 datasets we added an auxiliary loss at the end of the TD stream . The target in this case is a 224x224 mask , where a single pixel , blurred by a Gaussian kernel ( s.d.3 pixels ) was labeled as the target location . `` , How was this mask obtained ? How do the models perform without the use of this auxiliary loss ? Why was this loss only used in CLEVR and CUB-200 ? Minor : - Add references to first column in Table 2 . To conclude , the proposed architecture is novel , the paper is clear , but the experimental work leaves some questions unanswered .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank for the thoughtful review . Please find our response to your concerns in the following . 1.Regarding the amount of computation , the closest model to ours in terms of computations is the extended channel modulation , which uses about the same overall number of parameters and number of operations ( flops ) . This model performs better than the original channel modulation , but performs significantly less well than our model ( Tables 2 , 4b in the original paper ) . Other architectures : Single task architecture uses more computations when the number of tasks exceeds 3 . The number of operations in Multi-branched architectures linearly increases with the number of tasks . We will finally note that though the number of flops is of large interest , the number of parameters can become , given memory restrictions , of central importance . 2.Task heterogeneity : This is a very interesting question ; aspects of this question are addressed in the general response . In the revised paper we discuss this question both in the description of the added experiment , as well as in the final discussion . 3.The single pixel coordinates were obtained from the GT annotations of the relevant datasets ( CLEVR and CUB-200 ) , and then blurred with a Gaussian kernel and used as an auxiliary loss . This was not used in Celeb-A since the dataset does not provide location annotations . The main reason we used this auxiliary loss is to demonstrate our ability to produce task-dependent spatial maps in inference time , helping interpretability of the result by locating intermediate objects of interest . For a fair comparison we add the exact ground truth information to other baselines ( indicated with v on the \u2018 loc \u2019 column in table 3a and 3c ) ."}, {"review_id": "7YctWnyhjpL-2", "review_text": "The paper propose a way to combine image information and task information as controllers for multi-task learning . In this way , the authors expect to extract more task/image specific features in a shared backbone . The proposed method seems novel and intuitive . Though there are some typos and grammar mistakes , overall the paper is easy to follow . My major concerns are the followings : 1. the claim that the proposed scheme provides scalability with the number of tasks is stretching : the number of tasks still need to predefine and the number of task heads are not optimized compared to previous algorithms . 2.While there is improvement in performance , but it is not clear what factors causes the improvement . As compared to previous schemes the proposed model needs much more computationally ( two bottom up runs and a top-down run ) and utilizes more information . 3.All the tasks are classification tasks /discriminative models . It is not demonstrated if this would be working with a mixture of generative/discriminative tasks . If possible , as the TD and BU 's are sharing the same structures , it would be interesting to explore what are learned by visualizing the weights in each channels and layers . and further explore which feature map is heavily used for which specific task . These weights/activation distributions will help us to better understand what is actually learned in the proposed scheme . The task spatial maps seems to be a good start , but it would be better if the author provide more analysis on intermediate layer activations", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank for the thoughtful and constructive review . Please find our response to your concerns in the following : 1 . Regarding scalability : in the general response we describe an additional experiment where a task is added to the network by learning a new task embedding without changing the main backbone . This illustrates that at least in some cases it is possible to add tasks to the already trained network . There is also evidence for scalability in the results that in our model it is possible to increase the number of tasks ( e.g.1645 in the CLEVR task ) and the accuracy remains high compared with alternative approaches . Regarding optimizing the number of heads and number of tasks is an interesting issue . In the general response we show an example in this direction , where we use 2 branches for 20 tasks , for two major families of tasks ( discriminative or generative ) . We finally note that in most previous models the number of branches is simply equal to the number of tasks , with no optimization . 2.Where the improvement is coming from : We analyzed some aspects of this question in our ablation studies that evaluate the contribution of image content and TD context to the results accuracy . As discussed later below ( the last point ) it will be of interest to study more in the future the specific contributions of different components of the scheme . Regarding the amount of computation , the closest model to ours in terms of computations is the extended channel modulation , which uses about the same overall number of parameters and number of operations ( flops ) . This model performs better than the original channel modulation , but performs significantly less well than our model ( Tables 2 , 4b in the original paper ) . In terms of information used we use image and task information , similar to other models . We also use in several cases auxiliary losses , but in the relevant tests , we added these losses to the alternative models , so we believe the comparisons were unbiased . 3.Combining discriminative and generative tasks . This combination is of general interest and it has not been studied in the multi-task literature in the past . We added an experiment that tests explicitly an aspect of this capacity in our model , described in the general response ( first experiment ) . 4.Studying and visualizing the roles of different model components : one possible approach that can be used to address some of these issues is by readout experiments from different components of the system . We applied this in our study of task selectivity in the last layer before the fully connected layers in the network . The higher selectivity index of our method is likely to be related to the increased gap in performance with respect to alternative models . A particularly interesting component to test further would be the representations developed in the task-embedding component of the TD net ."}], "0": {"review_id": "7YctWnyhjpL-0", "review_text": "In this paper a novel top-down control network is introduced for multi-task learning . Different from the traditional bottom-up attention models , the authors introduce a top-down module to modify the activation of recognition network based on different tasks . Specifically\uff0cthe proposed module consists of three identical networks , which are BU1 , TD , BU2 streams . Given the input , the BU1 is firstly trained , and then the TD streams is trained by assigning the specific labels . After that , the BU2 is updated with the top-down parameters . Experimental results demonstrate the effectiveness of proposed model . Strength : 1 . It is interesting to introduce the semantic information from the top layer to guide the feature representation learning . Weakness : Although the experimental results show the better performance on the image classification , there are exist several unclear parts : 1 . The definition of multi-task in this paper refers to the different dataset \u2019 s classification ? Or referring to the different tasks , e.g.localization , classification , and attributes predication . In my opinion , the authors should provide more details on designing the validation experiments . And the proposed model should be tested on different tasks instead of only on the task of visual recognition . 2.Some bottom-up based model e.g.FiLM should be used as the baselines to validate the advantage of introducing the top-down stream . 3.If the top-down stream would make the recognition be sensitive for the visual variations ? Or the classification results may be dependent on the number of training samples ? 4.If the proposed model would be helpful for transfer learning ?", "rating": "7: Good paper, accept", "reply_text": "We would like to thank the reviewer for the positive feedback . We list below answers to specific concerns raised in the review : 1 . Similar concerns were raised by other reviewers . Please see our answer to all reviewers . 2.Regarding FiLM : There are two differences between FiLM and our approach . First , it keeps an initial backbone unaltered . Second , it uses both multiplicative and additive learned parameters in the modulation part . We tested these two aspects of FiLM adapted to the backbones used in the experiments . ( The Resnet-101 network used in the original FiLM is larger than the networks used in our model ) . | | | FiLM | Ours | | -- | -- | -- | -- | |MNIST |2 digits ( by loc ) | 95.42| 96.67| | | 4 digits |92.99 |94.64| | |9 digits | 75.75 | 88.07 | | |9 digits ( by ref ) |33.27 | 72.25 | |CLEVR | | 62.03 | 96.83 | 3 . Our recognition results naturally increased with the number of training examples . We found evidence in two results that our model can be trained with a smaller number of examples compared with alternatives . First , our \u201c stress test \u201d results , increasing CLEVR tasks to 1645 , in table 4a of the original paper , obtains better results than alternatives by a large gap . In this test , the number of examples is reduced to less than 45 training examples for each task in an epoch . Second , we compared results of the multi-mnist task with a controlled number of examples for the number \u2018 3 \u2019 in the top-left location ( new experiment ) . The reported accuracy below is for testing specifically instances of images with \u2018 3 \u2019 at the top-left . Learning starts faster and remains higher up to a large number of examples . |Number of examples|Ours | chmod | || -- || | 0 | 0 | 0 | | 10 | 0 | 0 | |100 | 50.59 | 0 | | 1000 | 85.54 | 26.44 | | 10000 | 94.85 | 72.87 | 4 . Use in transfer learning . This is a general interesting issue for future studies which we have not studied in detail . One attractive possibility is to use the learned task embedding in the network , for at least some aspects of transfer leaning . An example along this line is described in experiment 2 of the general response ."}, "1": {"review_id": "7YctWnyhjpL-1", "review_text": "This paper presents a new architecture for multi-task learning that uses a top-down control network to modulate the activations of the main ( bottom-up ) recognition network . The model is applied to four datasets/tasks : multi-MNIST , CLEVR , CELEB-A , and CUB-200 , demonstrating good performance compared with baselines . I have the following comments and questions : - The proposed architecture requires the equivalent of three forward/backward passes : BU1 , TD , and BU2 . The number of parameters is used gauge complexity in Table 2 and Figure 3 but FLOPs might be a better metric here since BU1 and BU2 share parameters . How do the models compare in terms of FLOPs to baselines ? - The datasets/tasks used herein are homogenous and therefore straightforward for multi-task learning . How does the proposed architecture fair in a more challenging setting involving heterogeneous tasks , e.g. , Misra et al. , 2016 ? - Re `` In some of the experiments of CLEVR and CUB-200 datasets we added an auxiliary loss at the end of the TD stream . The target in this case is a 224x224 mask , where a single pixel , blurred by a Gaussian kernel ( s.d.3 pixels ) was labeled as the target location . `` , How was this mask obtained ? How do the models perform without the use of this auxiliary loss ? Why was this loss only used in CLEVR and CUB-200 ? Minor : - Add references to first column in Table 2 . To conclude , the proposed architecture is novel , the paper is clear , but the experimental work leaves some questions unanswered .", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank for the thoughtful review . Please find our response to your concerns in the following . 1.Regarding the amount of computation , the closest model to ours in terms of computations is the extended channel modulation , which uses about the same overall number of parameters and number of operations ( flops ) . This model performs better than the original channel modulation , but performs significantly less well than our model ( Tables 2 , 4b in the original paper ) . Other architectures : Single task architecture uses more computations when the number of tasks exceeds 3 . The number of operations in Multi-branched architectures linearly increases with the number of tasks . We will finally note that though the number of flops is of large interest , the number of parameters can become , given memory restrictions , of central importance . 2.Task heterogeneity : This is a very interesting question ; aspects of this question are addressed in the general response . In the revised paper we discuss this question both in the description of the added experiment , as well as in the final discussion . 3.The single pixel coordinates were obtained from the GT annotations of the relevant datasets ( CLEVR and CUB-200 ) , and then blurred with a Gaussian kernel and used as an auxiliary loss . This was not used in Celeb-A since the dataset does not provide location annotations . The main reason we used this auxiliary loss is to demonstrate our ability to produce task-dependent spatial maps in inference time , helping interpretability of the result by locating intermediate objects of interest . For a fair comparison we add the exact ground truth information to other baselines ( indicated with v on the \u2018 loc \u2019 column in table 3a and 3c ) ."}, "2": {"review_id": "7YctWnyhjpL-2", "review_text": "The paper propose a way to combine image information and task information as controllers for multi-task learning . In this way , the authors expect to extract more task/image specific features in a shared backbone . The proposed method seems novel and intuitive . Though there are some typos and grammar mistakes , overall the paper is easy to follow . My major concerns are the followings : 1. the claim that the proposed scheme provides scalability with the number of tasks is stretching : the number of tasks still need to predefine and the number of task heads are not optimized compared to previous algorithms . 2.While there is improvement in performance , but it is not clear what factors causes the improvement . As compared to previous schemes the proposed model needs much more computationally ( two bottom up runs and a top-down run ) and utilizes more information . 3.All the tasks are classification tasks /discriminative models . It is not demonstrated if this would be working with a mixture of generative/discriminative tasks . If possible , as the TD and BU 's are sharing the same structures , it would be interesting to explore what are learned by visualizing the weights in each channels and layers . and further explore which feature map is heavily used for which specific task . These weights/activation distributions will help us to better understand what is actually learned in the proposed scheme . The task spatial maps seems to be a good start , but it would be better if the author provide more analysis on intermediate layer activations", "rating": "5: Marginally below acceptance threshold", "reply_text": "We would like to thank for the thoughtful and constructive review . Please find our response to your concerns in the following : 1 . Regarding scalability : in the general response we describe an additional experiment where a task is added to the network by learning a new task embedding without changing the main backbone . This illustrates that at least in some cases it is possible to add tasks to the already trained network . There is also evidence for scalability in the results that in our model it is possible to increase the number of tasks ( e.g.1645 in the CLEVR task ) and the accuracy remains high compared with alternative approaches . Regarding optimizing the number of heads and number of tasks is an interesting issue . In the general response we show an example in this direction , where we use 2 branches for 20 tasks , for two major families of tasks ( discriminative or generative ) . We finally note that in most previous models the number of branches is simply equal to the number of tasks , with no optimization . 2.Where the improvement is coming from : We analyzed some aspects of this question in our ablation studies that evaluate the contribution of image content and TD context to the results accuracy . As discussed later below ( the last point ) it will be of interest to study more in the future the specific contributions of different components of the scheme . Regarding the amount of computation , the closest model to ours in terms of computations is the extended channel modulation , which uses about the same overall number of parameters and number of operations ( flops ) . This model performs better than the original channel modulation , but performs significantly less well than our model ( Tables 2 , 4b in the original paper ) . In terms of information used we use image and task information , similar to other models . We also use in several cases auxiliary losses , but in the relevant tests , we added these losses to the alternative models , so we believe the comparisons were unbiased . 3.Combining discriminative and generative tasks . This combination is of general interest and it has not been studied in the multi-task literature in the past . We added an experiment that tests explicitly an aspect of this capacity in our model , described in the general response ( first experiment ) . 4.Studying and visualizing the roles of different model components : one possible approach that can be used to address some of these issues is by readout experiments from different components of the system . We applied this in our study of task selectivity in the last layer before the fully connected layers in the network . The higher selectivity index of our method is likely to be related to the increased gap in performance with respect to alternative models . A particularly interesting component to test further would be the representations developed in the task-embedding component of the TD net ."}}