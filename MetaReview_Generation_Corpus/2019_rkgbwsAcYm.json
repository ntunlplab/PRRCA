{"year": "2019", "forum": "rkgbwsAcYm", "title": "DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NETWORKS", "decision": "Accept (Poster)", "meta_review": "This paper argues that each layer of a network may have some channels useful for and some not useful for transfer learning. The main contribution is an approach which identifies the useful channels through an attention based mechanism. The reviewers agree that this work offers a valuable new approach that offers modest improvements over prior work. \n\nThe authors should take care to refine their definition of behavior regularization, including/expanding on the discussion from the rebuttal phase. The authors are also encouraged to experiment with other architecture backbones and report both overall performance as well as run time for learning with the larger models. \n", "reviews": [{"review_id": "rkgbwsAcYm-0", "review_text": "Authors present a new regularisation approach named DELTA (Deep Learning Transfer using feature map with attention). What it does is preserving the outer layer outputs of the target network (in a transfer learning scenario) instead of constraining the weights of the neural network. I am not sure how this approach helps preserve the semantics. Authors state that the distance between source/target networks is characterised by DELTA using their outer layer outputs. This distance is then used in the loss function and through back-propagation incorporates knowledge from the source network. The results demonstrate some marginal improvement in the datasets used when compared with L^2 and L^2-SP. More importantly I think the paper needs some attention in its format as the concepts are not very clear. It has some elements of novelty but not yet there. Authors have addressed most of my issues and hence I have revised my decision.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and constructive comments . We summarize the major concerns of Reviewer 2 as following : Q1 . There needs evidence of ( statistically ) significant performance boosting Response : Thanks for your comments . In our experiments , we run DELTA and other baselines for multiple times under various settings , then estimate the mean accuracy with error bars in Tables 1 . We further compare the worst-case performance ( the lowest accuracy ) of DELTA to the best-case performance ( the highest accuracy ) of rest baselines under each setting . The results suggest that DELTA can always perform better than the baseline algorithms , as its worst-case performance is marginally better than the best-case performance of baselines in our experiments . To address your comments , we will include supplementary experiments on some new neural architectures ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . The new results will be compared and reported in our incoming revision . Q2.What is the major contributions made in this paper . Response : Thanks for your comment . Our key innovation is the concept that we call `` unactivated channel re-usage \u201d . Specifically we demonstrate by experiments and case studies that , when we perform transfer learning in CNN , some of the convolution channels are useless in transfer learning . In contrast to the common belief that lower level convolution channels are for common feature extraction , higher level channels are for task-specific feature extraction , we demonstrate that there are channels that are useful ( and useless ) at all different levels . Our technical contribution is to find an approach to identify those \u201c transferable channels \u201d and preserve them through regularization and identify those \u201c untransferable channels \u201d and reuse them , using an attention mechanism with feature map regularization . Compared to existing deep transfer learning paradigms reusing the weights of outer layers of source networks , DELTA intends to constrain on the difference of the outputs ( e.g. , feature maps ) rather than the weights between source/target networks . Compared to the knowledge distillation alike solution ( if they are adopted for transfer learning ) , DELTA proposes a novel attention mechanism to make target network stay focused on the important features with high discriminant powers for knowledge transfer . To the best of knowledge , we are the first to regularize the divergence of the feature maps outputted by the outer layers of the source/target networks , with attention mechanisms , for deep transfer learning . Using image classification and case studies we demonstrate the usefulness of our insights . In addition , we plan to further demonstrate the utility of the proposed methods by adding supplementary experiments on both new architecture ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . Those results will be reported in our new version . [ 1 ] C.Wah , S.Branson , P.Welinder , P.Perona , andS.Belongie . The caltech-ucsd birds-200-2011 dataset . California Institute of Technology , 2011 . 6 , 7 , 8 [ 2 ] L. Bossard , M. Guillaumin , and L. Van Gool . Food-101\u2013mining discriminative components with random forests . In ECCV , 2014 . 6 , 8"}, {"review_id": "rkgbwsAcYm-1", "review_text": "Summary The paper describes using the technique of modifying the weights for the outer layers, used in teacher-student network for same task, to transfer learning for different tasks by modifying the loss function and pre-training using target network labels to emphasize the neurons that are considered important for prediction. The technique seems to be no more/slightly better than the Lsquare SP, but exceeds when used with attention. Improvements - the amount of training time needed to pre-train using the L-square FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor - The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.) would be a good add", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review and encouraging comments . We summarize Reviewer 1 \u2019 s major concerns as following two questions and we try to respond these two answers accordingly . Q1. \u201c the amount of training time needed to pre-train using the L-2 FE and target labels should be mentioned as it seems that for large network , and large data , this can be a factor \u201d Response : Thanks for the comment . We totally agree that the time-consumption of L2-FE adaption and attention learning should be considered as the overhead of our method . Indeed , the time spent by L2-FE adaption and attention learning is no more than 50 % of overall training time . For example , DELTA ( w/o Attention ) requires 139 minutes on Caltech30 task transferring from Resnet-101 pre-trained model , while DELTA ( with Attention ) consumes 197 minutes ( 42 % more than DELTA w/o Attention which doesn \u2019 t need L2-FE adaption and attention learning ) . Furthermore , L2-SP takes124 minutes and L2 spends 115 minutes on the same task in the same settings . It is thus reasonable to conclude the extra time consumption on L2-FE adaption and attention learning does not add a significant overhead to common deep transfer learning practices . When we further breakdown such time overhead , we found that the major overhead is due to the attention learning , where for each filter forward inference is needed to estimate the contribution of such filter to the overall accuracy . It should not be a significant performance bottleneck even for a large dataset , as the number of filters needed to evaluate might be fixed with given scratch for transfer learning . Note that one key contribution made in this manuscript is to improve the deep transfer learning via feature-map based regularization through introducing attention mechanism . All in all , many thanks for your comments . We are revising the manuscript , including the discussion on time consumption , accordingly . Q.2 The choice of Resnet , at least one of the more recent networks for object detection ( Inception , YOLO etc . ) would be a good add Response : Thanks for comments . We agree to incorporate more results and neural network architectures . We are revising the manuscript with supplementary experiments on both new architecture ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . The results of above experiments will be reported in our new version . [ 1 ] C.Wah , S.Branson , P.Welinder , P.Perona , andS.Belongie . The caltech-ucsd birds-200-2011 dataset . California Institute of Technology , 2011 . 6 , 7 , 8 [ 2 ] L. Bossard , M. Guillaumin , and L. Van Gool . Food-101\u2013mining discriminative components with random forests . In ECCV , 2014 . 6 , 8"}, {"review_id": "rkgbwsAcYm-2", "review_text": "This is a reasonable paper based on a simple intuition. The authors have noticed that some of the state of the art methods (they use Li et al - ICML18 as the main reference) are using only some simple normalization for improving the transfer learning and as such they propose preserving the outer layer output of the target network and aligning it with the one of the source network. On top of that they also propose modeling the difference of feature maps considering an attention mechanism obtain through supervised learning. The idea in itself is interesting and valuable. However, I have had some difficulty in understanding precisely how the \"behavior\" is really regularized. While I understand what is depicted in Figure 1 I'm not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs. In the evaluation, the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this. I would have liked to see experiments on some larger datasets that are commonly used in computer vision (e.g., Caltech 256 is rather old even if it has been used in Li et al.). The quantitative results in Table 1 and 2 indicate some slight improvement but I'm not completely convinced that this is really significant in the end. The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image (in this case the result might also be correct but the examples presented are not too eloquent). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and encouraging comments . We summarize and respond Reviewer 3 \u2019 s concerns as follow . Q1.I have had some difficulty in understanding precisely how the `` behavior '' is really regularized . While I understand what is depicted in Figure 1 I 'm not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs Response : Thanks for your comments . Yes , one intuition of our regularizer for deep transfer learning is to ensure the \u201c behavior \u201d of outer layers of the target network being similar to the source one . In this context , \u201c behavior \u201d suggests functional preservation where similar inputs will produce similar outputs . To measure similarity , however , is difficult . Using feature map is a reasonable choice but such choice has many problems . First of all , feature maps/outer layer outputs are large with noise and redundancy . We have to understand which parts of feature maps ( outputs ) would help for the classification on the target task ( rather than source task ) . In this way , an attention mechanism has been proposed to re-weight the output of each filter in out layers . Then , with the obtained attention , we characterize the divergence of feature maps/outputs between source/target networks as the attention-weighted squared-Euclidian distance between the feature maps . In this way , the regularizer to \u201c correlate \u201d the output has been designed . We further leverage some optimization paradigms , such as starting point as reference , to accelerate the deep transfer learning with better efficiency and effectiveness . Please refer to our methodologies section for details . Q2.the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this . I would have liked to see experiments on some larger datasets that are commonly used in computer vision Response : Thanks for your comments . Yes , eventually , handling large target dataset is an interesting topic in deep transfer learning research . Actually , we usually assume the target dataset size is relevantly small . As was stated in the first paragraph of the first section , the deep transfer learning studied here is originally motivated by the need of deep learning from small datasets . In such cases , CNNs are not be able to learn generalizable features from the small training sets , while weights of pre-trained networks with rich features learned from large datasets are assumed to help . To address your comments , we will include the results of supplementary experiments on both new architecture ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . The new results will be reported in our incoming revision . [ 1 ] C.Wah , S.Branson , P.Welinder , P.Perona , andS.Belongie . The caltech-ucsd birds-200-2011 dataset . California Institute of Technology , 2011 . 6 , 7 , 8 [ 2 ] L. Bossard , M. Guillaumin , and L. Van Gool . Food-101\u2013mining discriminative components with random forests . In ECCV , 2014 . 6 , 8 Q3.The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image Response : Thanks for your comments for catching the possible location bias . In our experiments we do not find evidence that our attention mechanism has a strong central bias . It pays attention to the parts of feature maps that are with discriminant capacities . The attention illustrated on dog images is just a coincidence . In our revised version , we plan to present more attention results to avoid the impression of central bias ."}], "0": {"review_id": "rkgbwsAcYm-0", "review_text": "Authors present a new regularisation approach named DELTA (Deep Learning Transfer using feature map with attention). What it does is preserving the outer layer outputs of the target network (in a transfer learning scenario) instead of constraining the weights of the neural network. I am not sure how this approach helps preserve the semantics. Authors state that the distance between source/target networks is characterised by DELTA using their outer layer outputs. This distance is then used in the loss function and through back-propagation incorporates knowledge from the source network. The results demonstrate some marginal improvement in the datasets used when compared with L^2 and L^2-SP. More importantly I think the paper needs some attention in its format as the concepts are not very clear. It has some elements of novelty but not yet there. Authors have addressed most of my issues and hence I have revised my decision.", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and constructive comments . We summarize the major concerns of Reviewer 2 as following : Q1 . There needs evidence of ( statistically ) significant performance boosting Response : Thanks for your comments . In our experiments , we run DELTA and other baselines for multiple times under various settings , then estimate the mean accuracy with error bars in Tables 1 . We further compare the worst-case performance ( the lowest accuracy ) of DELTA to the best-case performance ( the highest accuracy ) of rest baselines under each setting . The results suggest that DELTA can always perform better than the baseline algorithms , as its worst-case performance is marginally better than the best-case performance of baselines in our experiments . To address your comments , we will include supplementary experiments on some new neural architectures ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . The new results will be compared and reported in our incoming revision . Q2.What is the major contributions made in this paper . Response : Thanks for your comment . Our key innovation is the concept that we call `` unactivated channel re-usage \u201d . Specifically we demonstrate by experiments and case studies that , when we perform transfer learning in CNN , some of the convolution channels are useless in transfer learning . In contrast to the common belief that lower level convolution channels are for common feature extraction , higher level channels are for task-specific feature extraction , we demonstrate that there are channels that are useful ( and useless ) at all different levels . Our technical contribution is to find an approach to identify those \u201c transferable channels \u201d and preserve them through regularization and identify those \u201c untransferable channels \u201d and reuse them , using an attention mechanism with feature map regularization . Compared to existing deep transfer learning paradigms reusing the weights of outer layers of source networks , DELTA intends to constrain on the difference of the outputs ( e.g. , feature maps ) rather than the weights between source/target networks . Compared to the knowledge distillation alike solution ( if they are adopted for transfer learning ) , DELTA proposes a novel attention mechanism to make target network stay focused on the important features with high discriminant powers for knowledge transfer . To the best of knowledge , we are the first to regularize the divergence of the feature maps outputted by the outer layers of the source/target networks , with attention mechanisms , for deep transfer learning . Using image classification and case studies we demonstrate the usefulness of our insights . In addition , we plan to further demonstrate the utility of the proposed methods by adding supplementary experiments on both new architecture ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . Those results will be reported in our new version . [ 1 ] C.Wah , S.Branson , P.Welinder , P.Perona , andS.Belongie . The caltech-ucsd birds-200-2011 dataset . California Institute of Technology , 2011 . 6 , 7 , 8 [ 2 ] L. Bossard , M. Guillaumin , and L. Van Gool . Food-101\u2013mining discriminative components with random forests . In ECCV , 2014 . 6 , 8"}, "1": {"review_id": "rkgbwsAcYm-1", "review_text": "Summary The paper describes using the technique of modifying the weights for the outer layers, used in teacher-student network for same task, to transfer learning for different tasks by modifying the loss function and pre-training using target network labels to emphasize the neurons that are considered important for prediction. The technique seems to be no more/slightly better than the Lsquare SP, but exceeds when used with attention. Improvements - the amount of training time needed to pre-train using the L-square FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor - The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.) would be a good add", "rating": "7: Good paper, accept", "reply_text": "Thank you for your review and encouraging comments . We summarize Reviewer 1 \u2019 s major concerns as following two questions and we try to respond these two answers accordingly . Q1. \u201c the amount of training time needed to pre-train using the L-2 FE and target labels should be mentioned as it seems that for large network , and large data , this can be a factor \u201d Response : Thanks for the comment . We totally agree that the time-consumption of L2-FE adaption and attention learning should be considered as the overhead of our method . Indeed , the time spent by L2-FE adaption and attention learning is no more than 50 % of overall training time . For example , DELTA ( w/o Attention ) requires 139 minutes on Caltech30 task transferring from Resnet-101 pre-trained model , while DELTA ( with Attention ) consumes 197 minutes ( 42 % more than DELTA w/o Attention which doesn \u2019 t need L2-FE adaption and attention learning ) . Furthermore , L2-SP takes124 minutes and L2 spends 115 minutes on the same task in the same settings . It is thus reasonable to conclude the extra time consumption on L2-FE adaption and attention learning does not add a significant overhead to common deep transfer learning practices . When we further breakdown such time overhead , we found that the major overhead is due to the attention learning , where for each filter forward inference is needed to estimate the contribution of such filter to the overall accuracy . It should not be a significant performance bottleneck even for a large dataset , as the number of filters needed to evaluate might be fixed with given scratch for transfer learning . Note that one key contribution made in this manuscript is to improve the deep transfer learning via feature-map based regularization through introducing attention mechanism . All in all , many thanks for your comments . We are revising the manuscript , including the discussion on time consumption , accordingly . Q.2 The choice of Resnet , at least one of the more recent networks for object detection ( Inception , YOLO etc . ) would be a good add Response : Thanks for comments . We agree to incorporate more results and neural network architectures . We are revising the manuscript with supplementary experiments on both new architecture ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . The results of above experiments will be reported in our new version . [ 1 ] C.Wah , S.Branson , P.Welinder , P.Perona , andS.Belongie . The caltech-ucsd birds-200-2011 dataset . California Institute of Technology , 2011 . 6 , 7 , 8 [ 2 ] L. Bossard , M. Guillaumin , and L. Van Gool . Food-101\u2013mining discriminative components with random forests . In ECCV , 2014 . 6 , 8"}, "2": {"review_id": "rkgbwsAcYm-2", "review_text": "This is a reasonable paper based on a simple intuition. The authors have noticed that some of the state of the art methods (they use Li et al - ICML18 as the main reference) are using only some simple normalization for improving the transfer learning and as such they propose preserving the outer layer output of the target network and aligning it with the one of the source network. On top of that they also propose modeling the difference of feature maps considering an attention mechanism obtain through supervised learning. The idea in itself is interesting and valuable. However, I have had some difficulty in understanding precisely how the \"behavior\" is really regularized. While I understand what is depicted in Figure 1 I'm not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs. In the evaluation, the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this. I would have liked to see experiments on some larger datasets that are commonly used in computer vision (e.g., Caltech 256 is rather old even if it has been used in Li et al.). The quantitative results in Table 1 and 2 indicate some slight improvement but I'm not completely convinced that this is really significant in the end. The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image (in this case the result might also be correct but the examples presented are not too eloquent). ", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your review and encouraging comments . We summarize and respond Reviewer 3 \u2019 s concerns as follow . Q1.I have had some difficulty in understanding precisely how the `` behavior '' is really regularized . While I understand what is depicted in Figure 1 I 'm not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs Response : Thanks for your comments . Yes , one intuition of our regularizer for deep transfer learning is to ensure the \u201c behavior \u201d of outer layers of the target network being similar to the source one . In this context , \u201c behavior \u201d suggests functional preservation where similar inputs will produce similar outputs . To measure similarity , however , is difficult . Using feature map is a reasonable choice but such choice has many problems . First of all , feature maps/outer layer outputs are large with noise and redundancy . We have to understand which parts of feature maps ( outputs ) would help for the classification on the target task ( rather than source task ) . In this way , an attention mechanism has been proposed to re-weight the output of each filter in out layers . Then , with the obtained attention , we characterize the divergence of feature maps/outputs between source/target networks as the attention-weighted squared-Euclidian distance between the feature maps . In this way , the regularizer to \u201c correlate \u201d the output has been designed . We further leverage some optimization paradigms , such as starting point as reference , to accelerate the deep transfer learning with better efficiency and effectiveness . Please refer to our methodologies section for details . Q2.the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this . I would have liked to see experiments on some larger datasets that are commonly used in computer vision Response : Thanks for your comments . Yes , eventually , handling large target dataset is an interesting topic in deep transfer learning research . Actually , we usually assume the target dataset size is relevantly small . As was stated in the first paragraph of the first section , the deep transfer learning studied here is originally motivated by the need of deep learning from small datasets . In such cases , CNNs are not be able to learn generalizable features from the small training sets , while weights of pre-trained networks with rich features learned from large datasets are assumed to help . To address your comments , we will include the results of supplementary experiments on both new architecture ( inception v3 ) and datasets ( CUB-200-2011 [ 1 ] , Food-101 [ 2 ] ) . The new results will be reported in our incoming revision . [ 1 ] C.Wah , S.Branson , P.Welinder , P.Perona , andS.Belongie . The caltech-ucsd birds-200-2011 dataset . California Institute of Technology , 2011 . 6 , 7 , 8 [ 2 ] L. Bossard , M. Guillaumin , and L. Van Gool . Food-101\u2013mining discriminative components with random forests . In ECCV , 2014 . 6 , 8 Q3.The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image Response : Thanks for your comments for catching the possible location bias . In our experiments we do not find evidence that our attention mechanism has a strong central bias . It pays attention to the parts of feature maps that are with discriminant capacities . The attention illustrated on dog images is just a coincidence . In our revised version , we plan to present more attention results to avoid the impression of central bias ."}}