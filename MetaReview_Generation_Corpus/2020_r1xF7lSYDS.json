{"year": "2020", "forum": "r1xF7lSYDS", "title": "Transferable Recognition-Aware Image Processing", "decision": "Reject", "meta_review": "This paper presents several models for recognition-aware image enhancement. The authors propose to enhance the image quality in the presence of image degradation (e.g., low-resolution, noise, compression artifacts) as well as to improve the recognition accuracy in a joint model. While acknowledging that the paper is addressing an interesting direction, the reviewers and AC note the following potential weaknesses: presentation clarity, limited technical contributions, insufficient empirical evidence. AC can confirm all the reviewers have read the rebuttal and have contributed to the discussion. All the reviewers and AC agree that the rebuttal was informative, and the authors have partially addressed some of the concerns (e.g. additional experiments). R2 has raised the score from reject to weak reject. However, at this stage AC suggest the manuscript is below the acceptance bar and needs a major revision before submitting for another round of reviews. We hope the reviews are useful for improving and revising the paper.", "reviews": [{"review_id": "r1xF7lSYDS-0", "review_text": "Claims: The paper presents a concept of \"recognition-aware (RA) image processing\": when one enhances image in a some way, not only human judjement should be taken into account, but also performance of various computer vision application using that image. As an example of processing tasks, authors take super-resolution, denoising and JPEG-artifacts removal. Downstream applications covered are image classification and object detection. Authors propose a several training schemas to solve this problem and discuss a limitations of each one: - \"simple\" preprocessing, when the only image enhancement loss is optimized - \"RA\" joint optimization of recognition and enhancement loss (supervised and unsupervised) - a variant when two images are created: one for human and one for machine. **** Recommendation: strong accept **** Comments: Experiments are vast and performed on a variety of CNN architectures: ResNets, DenseNet ant VGGNet. Because one cannot predict, which computer vision tasks will be needed in the future, the natural question arise: how the results got for one set of tasks, architectures and image enhancement types transfer to another. Paper carefully studies this aspect as well. Overall paper is well written and is pleasure to read. While reading, I made notes to ask in review - just to see the my questions answered in a next section. Authors also provide source code for training. I haven`t run them though, but glanced through them. Weaknesses: I cannot really find a significant one. As a minor points: - I would recommend to cite not the last papers for image enhancement porblems themselves like super-resolution and denoising: these are old problems with rich history, e.g. L. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based noise removal algorithms Physica D, 60 (1992), pp. 259\u2013268. - \"Transformer\" is probably bad name for deep learning component, as it is already widely used for a specific seq2seq architecture **** After rebuttal: I am now even more convinced that paper should be accepted.", "rating": "8: Accept", "reply_text": "Thank you for your positive feedback ! We are glad to see your acknowledgement on our contributions , and we are happy address your concerns below : 1 . In the updated revision , we \u2019 ve added a few citations of classic papers on super-resolution and denoising , in the first sentence of related work : \u201c Image processing/enhancement problems such as super-resolution and denoising have a long history [ 1,2,3,4 ] . \u201d [ 1 ] Tsai , R. Multiframe image restoration and registration . Advance Computer Visual and Image Processing 1 ( 1984 ) : 317-339 . [ 2 ] Park S C , Park M K , Kang M G. Super-resolution image reconstruction : a technical overview . IEEE signal processing magazine , 2003 , 20 ( 3 ) : 21-36 . [ 3 ] Rudin L I , Osher S , Fatemi E. Nonlinear total variation based noise removal algorithms . Physica D : nonlinear phenomena , 1992 , 60 ( 1-4 ) : 259-268 . [ 4 ] Cand\u00e8s E J , Romberg J , Tao T. Robust uncertainty principles : Exact signal reconstruction from highly incomplete frequency information . IEEE Transactions on information theory , 2006 , 52 ( 2 ) : 489-509 . 2.Thanks for your suggestion on the naming of the \u201c Transformer \u201d . We are also considering renaming it possibly into \u201c transforming model \u201d . But to keep the naming consistent throughout the discussion period , we will keep the original name for now . Thank you for your review again ! Any further questions or suggestions are welcome ."}, {"review_id": "r1xF7lSYDS-1", "review_text": "This paper presents several models for visual recognition in the presence of image degradation (e.g., low-resolution, noise, compression artifacts). In the models, an image enhancement network is placed in front of a recognition model and trained together with the recognizer to improve the recognition accuracy as well as to enhance the image quality. The proposed approach is simple, straightforward, yet effective. It has been also shown that the image enhancement module is transferable between different recognition tasks and architectures. Although the paper addresses a timely topic and the performance gain is substantial, my current decision is reject mainly because of its weakness in technical novelty and contribution. The proposed models are simple and straightforward combinations of two separate networks, one for image enhancement and the other for recognition. This approach also makes the entire networks overly heavy, and introduces hyper-parameters (e.g., lambda) that have to be carefully tuned. Overall, it was hard to find interesting ideas that future readers may learn from the paper. Other comments: The 2nd model based on knowledge distillation (KD) is called \"unsupervised\", which however sounds weird. As already mentioned in the manuscript, the teacher network for KD is trained in a fully supervised manner for the target task, so it cannot be considered as an unsupervised model. Further, the advantage of the 2nd model is marginal in practice. The advantage of the transformer in the 3rd model is not clearly discussed. It is unknown in the paper why the 3rd model with the transformer works best in the experiments. Also, regarding the main goal of the paper (i.e., image enhancement not for human but for recognition networks), the reason for adopting the transformer is hard to understand. The degrees of image corruption (e.g., down-sampling, noise, compression) applied during testing are not mentioned at all, although they are important to understand the empirical advantage of the proposed models. The transferability is one of the most important benefit of the proposed model, but not convincing sufficiently. The proposed models are transferable between different object categories, but the plain models seem to be also transferable, sometime more transparently. Also, it is not clearly discussed what makes the proposed models attaining the transferability. It would be nice to apply the proposed models to the ImageNet-C benchmark. Missing references - Studying Very Low Resolution Recognition Using Deep Networks, CVPR 2016 - Benchmarking Neural Network Robustness to Common Corruptions and Perturbations, ICLR 2019", "rating": "1: Reject", "reply_text": "In the table below , we examine the transferability of RA Processing between recognition architectures , using the same two tasks `` snow '' and `` speckle_noise '' , with corruption level 5 . Note the recognition loss used during training is from a ResNet-18 , and we evaluate the improvement over plain processing on ResNet-50/101 , DenseNet-121 and VGG-16 . We observe that the improvement over plain processing is transferable among different architectures . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Corruption Type Snow Speckle noise -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Evaluation on R18 R50 R101 D121 V16 R18 R50 R101 D121 V16 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- No Processing 10.7 16.6 20.9 21.7 10.5 7.7 11.7 14.5 18.6 7.1 Plain Processing 34.5 39.1 44.6 41.1 27.4 36.6 42.4 47.7 43.0 31.3 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 6.Missing reference . Thanks for pointing us to the related works . We have added the missing references in the related work section . Thank you again for your detailed review ! We hope our answers address your concerns . If you have any further questions , we are very happy to answer . [ 1 ] Colorful Image Colorization . Zhang et al.ECCV 2016 . [ 2 ] EnhanceNet : Single Image Super-resolution through Automated Texture Synthesis . Sajjadi et al.ICCV 2017 . [ 3 ] Delving into Transferable Adversarial Examples and Black-box Attacks . Liu et al.ICLR 2017 . [ 4 ] The Space of Transferable Adversarial Examples . Tram\u00e8r et al.2017 ."}, {"review_id": "r1xF7lSYDS-2", "review_text": "The goal in this work is to improve machine interpretability of images. The authors main claims are: - Their proposed approach improves image recognition accuracy even without knowing subsequent recognition tasks and recognition models used to perform them (transferable model to different recognition models/tasks). - For this they propose what they call \u201cRecognition-Aware\u201d processing that combines image processing loss and recognition loss. - The approach is evaluated on three image processing tasks with two downstream recognition tasks: o Image super-resolution, de-noising, and JPEG-de-blocking processing tasks, with o Image classification and object detection recognition tasks. The paper is well written and organized, experiments carried are extensive but the reuse of known neural networks, many simplifications (shortcuts), a not clear enough methodology (see below), limited processing & recognition tasks used to support it, do not justify in our opinion the main (over-arching) work\u2019s claim: - In 3.2 optimizing recognition loss/Last paragraph: \u201cInterestingly, we find that image processing models trained with the loss of one recognition model R1, can also boost the performance when evaluated using recognition model R2, even if model R2 has a different architecture, recognizes a different set of categories or even is trained for a different task.\u201d. The paper would greatly benefit (to understand the context of the work or the explanations provided) from clarification of the many under-defined, not clearly introduced concepts it carries: - Meaning of \u201cNetwork\u201d is not clearly defined: o Abstract: \u201cimage processing network\u201d. o Introduction: \u201cthe network maps an image to a semantic label\u201d o Later in the paper only networks introduced are deep neural networks. That should be clear from beginning of the paper. - \u201cRetraining/Adaptation\u201d in 1st paragraph page 2. - In 1. Introduction/Paragraph 1: You use \u201c.. techniques .. have been proposed for making the output images look natural to human\u201d: o Noise is part of nature. A de-noised (smoothed) image is not \u201cmore natural\u201d. o Enhanced (processed) images are not necessarily \u201cmore\u201d natural, rather they take advantage of the human visual perception characteristics to enhance recognition for example. - In 1. Introduction/Paragraph 3: o \u201c.. of great importance that the processed images be recognizable\u201d Should explain the concept of image recognition! Because it could be related to contained objects, overall description (for captioning for example) etc. - \u201cImage processing\u201d in the context of the paper is intended only as \u201cimage enhancement for recognition\u201d. Pattern detection, segmentation, object extraction etc. are not included in this restrictive definition. Should specify for example: image enhancement and restoration. - Figure 1: As an illustration, it\u2019s completely counterproductive for your discourse as many simple image recognition algorithms would recognize the bird even in the noisy image. - In 3. Unsupervised optimization of recognition loss: The \u201cunsupervised RA\u201d process is not clear enough to us especially the statement: o \u201c.. only \u201cunsupervised\u201d for training model P, but the target pre-trained model R can still be trained in full supervision.\u201d. - \u201cWe may not know what network architectures (e.g. ResNet or VGG) will be used for inference, what object categories the downstream model recognizes (e.g. animals or scenes), or even what task will be performed on the processed image (e.g. classification or detection)\u201d. o Is your goal a universal \u201crecognition model\u201d applicable to anything? - I also have some trouble with the terminology: o In 1. Introduction/Paragraph 4: \u201cIt is also important that the enhanced machine semantics is not specific to any concrete recognition model\u201d: \u201cenhanced machine semantics\u201d! o In 1. Introduction/Paragraph 4: \u201c..transferable among different recognition architectures..\u201d. Does \u201carchitectures\u201d refer to deep neural networks (DNN)? If yes, is recognition performed only by DNN? What about the preceding bullet (\u201cis not specific to any concrete recognition model\u201d)? - In 1. Introduction/Paragraph 3: o \u201c.. we argue that image processing systems should maintain/enhance machine semantics\u201d. Do not see what\u2019s to argue here? o \u201cRecognition-Aware Image Processing\u201d is it simply put Image Processing techniques for recognition enhancement (\u201cRecognition\u201d still needs to be defined)? - In 2 Related work : o \u201c .. we assume we do not have the control on the recognition model, as it might be on the cloud or decided in the future, thus we advocate adapting the image processing model only. This also ensures the recognition model is not harmed on natural images.\u201d Care to explain? o : \u201cto achieve better recover the face identity from low-resolution images\u201d, Typo? - In 1. Introduction/Paragraph 1: o \u201c .. might not look \u201cnatural\u201d to machines\u201d: Care to explain this concept? \uf0a7 Would advise to just keep the second part of the sentence. - In 1. Introduction/Paragraph 2: \u201cOne could specifically train a recognition model only on these output images produced by the de-noising model to achieve better performance on such images, but the performance on natural images can be harmed.\u201d Care to explain?. o More complicated images (noisier, multiple obstructions etc.) are recognized nowadays and true to actual applications. - 3.4 using an intermediate transformer/Last paragraph: o \u201c .. that there are two instances for each image (the output of model P and T), one is \u201cfor human\u201d and the other is \u201cfor machines\u201d.\u201d: \uf0a7 The \u201cTransformer\u201d characteristics are not clearly defined for the intended output (For machines?). \uf0a7 Why is output of model T not represented in Figure 2 (Right)?", "rating": "3: Weak Reject", "reply_text": "Fourth paragraph : 1 . About the Transformer model . a ) Transformer characteristics Here the transformer T takes an input image from the image processing model P , and output an image that is optimized for machine recognition , thus creating the \u201c two instances of images \u201d situation . With the help of T , the processing model P focuses on optimizing the processing loss and T focuses on optimizing the recognition loss ( Eqn.6 ) .Because the recognition loss is only imposed on the output of T , and the gradient is cut off from flowing back to P , it is as if there \u2019 s no recognition loss to P. Thus the output of P ( input of T ) is guaranteed not affected as for human perception . In the last paragraph of section 3.4 we discussed the pros and cons of using this Transformer model instead of using the most simple variant of our method ( RA Processing ) : it can guarantee performance for human perception in terms of output from P , but also create this \u201c two-image \u201d situation . In practice one can choose whether to use the Transformer based on practical needs . b ) Figure 2 ( right ) . This is mainly due to the space/page width limit and the \u201c recognition loss \u201d part is the same as Figure 2 left ( dashed box , \u201c Recognition Loss \u201d ) , so we use this to save some space . We are happy to include the full figure for clarity if needed . Thank you again for your detailed review ! We hope our response addresses your concerns . Any further questions or suggestions are welcome . [ 1 ] Classification-driven dynamic image enhancement . Sharma et al.2018 . [ 2 ] Task-driven super resolution : Object detection in low-resolution images . Haris et al.2018 . [ 3 ] Benchmarking neural network robustness to common corruptions and perturbations . Hendrycks et al.2019 . [ 4 ] Episodic training for domain generalization . Li et al.2019 . [ 5 ] Generalizing across domains via cross-gradient training . Shankar et al.2018 ."}], "0": {"review_id": "r1xF7lSYDS-0", "review_text": "Claims: The paper presents a concept of \"recognition-aware (RA) image processing\": when one enhances image in a some way, not only human judjement should be taken into account, but also performance of various computer vision application using that image. As an example of processing tasks, authors take super-resolution, denoising and JPEG-artifacts removal. Downstream applications covered are image classification and object detection. Authors propose a several training schemas to solve this problem and discuss a limitations of each one: - \"simple\" preprocessing, when the only image enhancement loss is optimized - \"RA\" joint optimization of recognition and enhancement loss (supervised and unsupervised) - a variant when two images are created: one for human and one for machine. **** Recommendation: strong accept **** Comments: Experiments are vast and performed on a variety of CNN architectures: ResNets, DenseNet ant VGGNet. Because one cannot predict, which computer vision tasks will be needed in the future, the natural question arise: how the results got for one set of tasks, architectures and image enhancement types transfer to another. Paper carefully studies this aspect as well. Overall paper is well written and is pleasure to read. While reading, I made notes to ask in review - just to see the my questions answered in a next section. Authors also provide source code for training. I haven`t run them though, but glanced through them. Weaknesses: I cannot really find a significant one. As a minor points: - I would recommend to cite not the last papers for image enhancement porblems themselves like super-resolution and denoising: these are old problems with rich history, e.g. L. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based noise removal algorithms Physica D, 60 (1992), pp. 259\u2013268. - \"Transformer\" is probably bad name for deep learning component, as it is already widely used for a specific seq2seq architecture **** After rebuttal: I am now even more convinced that paper should be accepted.", "rating": "8: Accept", "reply_text": "Thank you for your positive feedback ! We are glad to see your acknowledgement on our contributions , and we are happy address your concerns below : 1 . In the updated revision , we \u2019 ve added a few citations of classic papers on super-resolution and denoising , in the first sentence of related work : \u201c Image processing/enhancement problems such as super-resolution and denoising have a long history [ 1,2,3,4 ] . \u201d [ 1 ] Tsai , R. Multiframe image restoration and registration . Advance Computer Visual and Image Processing 1 ( 1984 ) : 317-339 . [ 2 ] Park S C , Park M K , Kang M G. Super-resolution image reconstruction : a technical overview . IEEE signal processing magazine , 2003 , 20 ( 3 ) : 21-36 . [ 3 ] Rudin L I , Osher S , Fatemi E. Nonlinear total variation based noise removal algorithms . Physica D : nonlinear phenomena , 1992 , 60 ( 1-4 ) : 259-268 . [ 4 ] Cand\u00e8s E J , Romberg J , Tao T. Robust uncertainty principles : Exact signal reconstruction from highly incomplete frequency information . IEEE Transactions on information theory , 2006 , 52 ( 2 ) : 489-509 . 2.Thanks for your suggestion on the naming of the \u201c Transformer \u201d . We are also considering renaming it possibly into \u201c transforming model \u201d . But to keep the naming consistent throughout the discussion period , we will keep the original name for now . Thank you for your review again ! Any further questions or suggestions are welcome ."}, "1": {"review_id": "r1xF7lSYDS-1", "review_text": "This paper presents several models for visual recognition in the presence of image degradation (e.g., low-resolution, noise, compression artifacts). In the models, an image enhancement network is placed in front of a recognition model and trained together with the recognizer to improve the recognition accuracy as well as to enhance the image quality. The proposed approach is simple, straightforward, yet effective. It has been also shown that the image enhancement module is transferable between different recognition tasks and architectures. Although the paper addresses a timely topic and the performance gain is substantial, my current decision is reject mainly because of its weakness in technical novelty and contribution. The proposed models are simple and straightforward combinations of two separate networks, one for image enhancement and the other for recognition. This approach also makes the entire networks overly heavy, and introduces hyper-parameters (e.g., lambda) that have to be carefully tuned. Overall, it was hard to find interesting ideas that future readers may learn from the paper. Other comments: The 2nd model based on knowledge distillation (KD) is called \"unsupervised\", which however sounds weird. As already mentioned in the manuscript, the teacher network for KD is trained in a fully supervised manner for the target task, so it cannot be considered as an unsupervised model. Further, the advantage of the 2nd model is marginal in practice. The advantage of the transformer in the 3rd model is not clearly discussed. It is unknown in the paper why the 3rd model with the transformer works best in the experiments. Also, regarding the main goal of the paper (i.e., image enhancement not for human but for recognition networks), the reason for adopting the transformer is hard to understand. The degrees of image corruption (e.g., down-sampling, noise, compression) applied during testing are not mentioned at all, although they are important to understand the empirical advantage of the proposed models. The transferability is one of the most important benefit of the proposed model, but not convincing sufficiently. The proposed models are transferable between different object categories, but the plain models seem to be also transferable, sometime more transparently. Also, it is not clearly discussed what makes the proposed models attaining the transferability. It would be nice to apply the proposed models to the ImageNet-C benchmark. Missing references - Studying Very Low Resolution Recognition Using Deep Networks, CVPR 2016 - Benchmarking Neural Network Robustness to Common Corruptions and Perturbations, ICLR 2019", "rating": "1: Reject", "reply_text": "In the table below , we examine the transferability of RA Processing between recognition architectures , using the same two tasks `` snow '' and `` speckle_noise '' , with corruption level 5 . Note the recognition loss used during training is from a ResNet-18 , and we evaluate the improvement over plain processing on ResNet-50/101 , DenseNet-121 and VGG-16 . We observe that the improvement over plain processing is transferable among different architectures . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Corruption Type Snow Speckle noise -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Evaluation on R18 R50 R101 D121 V16 R18 R50 R101 D121 V16 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- No Processing 10.7 16.6 20.9 21.7 10.5 7.7 11.7 14.5 18.6 7.1 Plain Processing 34.5 39.1 44.6 41.1 27.4 36.6 42.4 47.7 43.0 31.3 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 6.Missing reference . Thanks for pointing us to the related works . We have added the missing references in the related work section . Thank you again for your detailed review ! We hope our answers address your concerns . If you have any further questions , we are very happy to answer . [ 1 ] Colorful Image Colorization . Zhang et al.ECCV 2016 . [ 2 ] EnhanceNet : Single Image Super-resolution through Automated Texture Synthesis . Sajjadi et al.ICCV 2017 . [ 3 ] Delving into Transferable Adversarial Examples and Black-box Attacks . Liu et al.ICLR 2017 . [ 4 ] The Space of Transferable Adversarial Examples . Tram\u00e8r et al.2017 ."}, "2": {"review_id": "r1xF7lSYDS-2", "review_text": "The goal in this work is to improve machine interpretability of images. The authors main claims are: - Their proposed approach improves image recognition accuracy even without knowing subsequent recognition tasks and recognition models used to perform them (transferable model to different recognition models/tasks). - For this they propose what they call \u201cRecognition-Aware\u201d processing that combines image processing loss and recognition loss. - The approach is evaluated on three image processing tasks with two downstream recognition tasks: o Image super-resolution, de-noising, and JPEG-de-blocking processing tasks, with o Image classification and object detection recognition tasks. The paper is well written and organized, experiments carried are extensive but the reuse of known neural networks, many simplifications (shortcuts), a not clear enough methodology (see below), limited processing & recognition tasks used to support it, do not justify in our opinion the main (over-arching) work\u2019s claim: - In 3.2 optimizing recognition loss/Last paragraph: \u201cInterestingly, we find that image processing models trained with the loss of one recognition model R1, can also boost the performance when evaluated using recognition model R2, even if model R2 has a different architecture, recognizes a different set of categories or even is trained for a different task.\u201d. The paper would greatly benefit (to understand the context of the work or the explanations provided) from clarification of the many under-defined, not clearly introduced concepts it carries: - Meaning of \u201cNetwork\u201d is not clearly defined: o Abstract: \u201cimage processing network\u201d. o Introduction: \u201cthe network maps an image to a semantic label\u201d o Later in the paper only networks introduced are deep neural networks. That should be clear from beginning of the paper. - \u201cRetraining/Adaptation\u201d in 1st paragraph page 2. - In 1. Introduction/Paragraph 1: You use \u201c.. techniques .. have been proposed for making the output images look natural to human\u201d: o Noise is part of nature. A de-noised (smoothed) image is not \u201cmore natural\u201d. o Enhanced (processed) images are not necessarily \u201cmore\u201d natural, rather they take advantage of the human visual perception characteristics to enhance recognition for example. - In 1. Introduction/Paragraph 3: o \u201c.. of great importance that the processed images be recognizable\u201d Should explain the concept of image recognition! Because it could be related to contained objects, overall description (for captioning for example) etc. - \u201cImage processing\u201d in the context of the paper is intended only as \u201cimage enhancement for recognition\u201d. Pattern detection, segmentation, object extraction etc. are not included in this restrictive definition. Should specify for example: image enhancement and restoration. - Figure 1: As an illustration, it\u2019s completely counterproductive for your discourse as many simple image recognition algorithms would recognize the bird even in the noisy image. - In 3. Unsupervised optimization of recognition loss: The \u201cunsupervised RA\u201d process is not clear enough to us especially the statement: o \u201c.. only \u201cunsupervised\u201d for training model P, but the target pre-trained model R can still be trained in full supervision.\u201d. - \u201cWe may not know what network architectures (e.g. ResNet or VGG) will be used for inference, what object categories the downstream model recognizes (e.g. animals or scenes), or even what task will be performed on the processed image (e.g. classification or detection)\u201d. o Is your goal a universal \u201crecognition model\u201d applicable to anything? - I also have some trouble with the terminology: o In 1. Introduction/Paragraph 4: \u201cIt is also important that the enhanced machine semantics is not specific to any concrete recognition model\u201d: \u201cenhanced machine semantics\u201d! o In 1. Introduction/Paragraph 4: \u201c..transferable among different recognition architectures..\u201d. Does \u201carchitectures\u201d refer to deep neural networks (DNN)? If yes, is recognition performed only by DNN? What about the preceding bullet (\u201cis not specific to any concrete recognition model\u201d)? - In 1. Introduction/Paragraph 3: o \u201c.. we argue that image processing systems should maintain/enhance machine semantics\u201d. Do not see what\u2019s to argue here? o \u201cRecognition-Aware Image Processing\u201d is it simply put Image Processing techniques for recognition enhancement (\u201cRecognition\u201d still needs to be defined)? - In 2 Related work : o \u201c .. we assume we do not have the control on the recognition model, as it might be on the cloud or decided in the future, thus we advocate adapting the image processing model only. This also ensures the recognition model is not harmed on natural images.\u201d Care to explain? o : \u201cto achieve better recover the face identity from low-resolution images\u201d, Typo? - In 1. Introduction/Paragraph 1: o \u201c .. might not look \u201cnatural\u201d to machines\u201d: Care to explain this concept? \uf0a7 Would advise to just keep the second part of the sentence. - In 1. Introduction/Paragraph 2: \u201cOne could specifically train a recognition model only on these output images produced by the de-noising model to achieve better performance on such images, but the performance on natural images can be harmed.\u201d Care to explain?. o More complicated images (noisier, multiple obstructions etc.) are recognized nowadays and true to actual applications. - 3.4 using an intermediate transformer/Last paragraph: o \u201c .. that there are two instances for each image (the output of model P and T), one is \u201cfor human\u201d and the other is \u201cfor machines\u201d.\u201d: \uf0a7 The \u201cTransformer\u201d characteristics are not clearly defined for the intended output (For machines?). \uf0a7 Why is output of model T not represented in Figure 2 (Right)?", "rating": "3: Weak Reject", "reply_text": "Fourth paragraph : 1 . About the Transformer model . a ) Transformer characteristics Here the transformer T takes an input image from the image processing model P , and output an image that is optimized for machine recognition , thus creating the \u201c two instances of images \u201d situation . With the help of T , the processing model P focuses on optimizing the processing loss and T focuses on optimizing the recognition loss ( Eqn.6 ) .Because the recognition loss is only imposed on the output of T , and the gradient is cut off from flowing back to P , it is as if there \u2019 s no recognition loss to P. Thus the output of P ( input of T ) is guaranteed not affected as for human perception . In the last paragraph of section 3.4 we discussed the pros and cons of using this Transformer model instead of using the most simple variant of our method ( RA Processing ) : it can guarantee performance for human perception in terms of output from P , but also create this \u201c two-image \u201d situation . In practice one can choose whether to use the Transformer based on practical needs . b ) Figure 2 ( right ) . This is mainly due to the space/page width limit and the \u201c recognition loss \u201d part is the same as Figure 2 left ( dashed box , \u201c Recognition Loss \u201d ) , so we use this to save some space . We are happy to include the full figure for clarity if needed . Thank you again for your detailed review ! We hope our response addresses your concerns . Any further questions or suggestions are welcome . [ 1 ] Classification-driven dynamic image enhancement . Sharma et al.2018 . [ 2 ] Task-driven super resolution : Object detection in low-resolution images . Haris et al.2018 . [ 3 ] Benchmarking neural network robustness to common corruptions and perturbations . Hendrycks et al.2019 . [ 4 ] Episodic training for domain generalization . Li et al.2019 . [ 5 ] Generalizing across domains via cross-gradient training . Shankar et al.2018 ."}}