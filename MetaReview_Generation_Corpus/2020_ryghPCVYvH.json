{"year": "2020", "forum": "ryghPCVYvH", "title": "Generative Restricted Kernel Machines", "decision": "Reject", "meta_review": "The paper proposes a way to use kernel method for multi-view generation. The points are mapped into a common subspace (with CNN feature extractor and kernel on top), and then a generation procedure from a latent point is given. \nI found the paper not easy to ready and follow; the idea of using CNN + kernel methods have been around for some years (for example, see \"Impostor networks\" by Lebedev et. al), and explicit feature map shows that kernel is just an additional layer to the network. Overall, the approach is straightforward, the generation can be quite slow and the benefits are not clear. The reviewers are mildly negative, so I think this time this paper can not be accepted.", "reviews": [{"review_id": "ryghPCVYvH-0", "review_text": "There exists two papers: [1] Multimodal Learning with Deep Boltzmann Machines, http://jmlr.org/papers/volume15/srivastava14b/srivastava14b.pdf [2] Deep Restricted Kernel Machines Using Conjugate Feature Duality, ftp://ftp.esat.kuleuven.ac.be/stadius/suykens/reports/deepRKM1.pdf In particular [2] considers a model, which is similar to a Boltzmann machine, but at the same time it is based on kernel features, and uses structure of the corresponding optimization problem to obtain a solution in a semi-explicit way. The authors of the considered paper 1) generalise a multimodal variant of the Boltzmann machine from [1] (which uses a special cross-product term to take into account dependency between modalities) to the case of kernel machines, 2) demonstrate on several typical datasets that using explicit deep network features it is possible to model images and data with two modalities (faces/textual description of faces). Comments: - From the description of the functionals L1 and L2 (bottom of page 4 and top of the page 5) the reader can think that the authors tune parameters (zeta_1,theta_1) and (zeta_2,theta_2) for each sample point separately - The authors claimed that the experiments were done both for kernel features and for explicit features based on neural networks. However, in the experimental section there are no results obtained when using implicit kernels. Nothings is told on how to select kernel parameters - The authors claimed that thanks to PCA-like definition of latent vectors they are orthogonal which is similar to disentangle representations. However, there are no any empirical evidences whether it is possible to benefit somehow from that orthogonal property, as well as there is no comparison with approaches to construct disentangle\u0432 latent representation for other types of generative models. Conclusions: - In general the text is accurately written, the work is well organised. - Still I was not able to understand the main idea of the paper. a) if the main idea of the paper that the authors propose some new method for generative modeling of multi-modal data, then the authors should make significantly more diverse experiments and ablation studies. Actually, this is not the case of the current work. The authors did not provide any quantitate measure and comparison with existing approaches; b) if the main idea is to present a new approach, then still I would not call the approach completely new, as it is based on well-known ideas and its benefits are completely not obvious. I guess that the paper can be published, but only after issues in a) are addressed.", "rating": "6: Weak Accept", "reply_text": "We would like to thank the reviewer for the review and helpful suggestions . 1 ) \u201c From the description of the functionals L1 and L2 ( bottom of page 4 and top of the page 5 ) the reader can think that the authors tune parameters ( zeta_1 , theta_1 ) and ( zeta_2 , theta_2 ) for each sample point separately \u201d We thank the reviewer for pointing this out , this is a typo and we changed this in the paper . 2 ) \u201c The authors claimed that the experiments were done both for kernel features and for explicit features based on neural networks . However , in the experimental section there are no results obtained when using implicit kernels . Nothings is told on how to select kernel parameters. \u201d Experiments with implicit feature maps where already shown on Figure 4a . Table 1 in the appendix shows the hyperparameters used for the experiments . The bandwidth of the Gaussian kernel for generation corresponds to the bandwidth that gave the best performance determined by cross-validation on the MNIST classification problem . 3 ) \u201c The authors claimed that thanks to PCA-like definition of latent vectors they are orthogonal which is similar to disentangle representations . However , there are no any empirical evidence whether it is possible to benefit somehow from that orthogonal property , as well as there is no comparison with approaches to construct disentangle\u0432 latent representation for other types of generative models. \u201d The definition of disentanglement in the literature is not that precise . However many believe that a representation with statistically independent variables is a good starting point [ 1,2 ] . This already gives an indication that the model could resemble a disentangled representation . This is confirmed by the empirical evidence on Figure 5 . We explore the learned uncorrelated-features by traversing along the ( orthogonal ) eigenvectors on the celebA and Dsprites dataset . These are common datasets to demonstrate disentanglement , where we repeat the experiments of [ 3 ] for the proposed Gen-RKM . For the Dsprites dataset , notice that the first and second components correspond to the y and x positions respectively . Rows 3 and 4 show the same for hearts . On the celebA dataset , rows 5 and 6 shows the reconstructed images while traversing along the principal components . When moving along the first component from left-to-right , the hair-color of the woman changes , while preserving the face structure . Whereas traversal along the second component , transforms a man to woman while preserving the orientation . When the number of principal components were 2 while training , the brightness and background light-source corresponds to the two largest variances in the dataset . This small example demonstrates how we can interpret the different components of the latent representation learned by the Gen-RKM . The latent space dimension in the RKM setting has a similar interpretation as the number of hidden units in a restricted Boltzmann machine , where in the specific case of the RKM these hidden units are uncorrelated ."}, {"review_id": "ryghPCVYvH-1", "review_text": "This paper presents a model and training framework for generating samples based on restricted kernel machines. It is extended to multi-view generation and uncorrelated feature representation learning. - The paper is well-written and well-organized. Notations and claims are clear. - The idea of a multi-view generation model based on restricted kernel machines is interesting. However, the paper seems to be limited to model definition and algorithm overview without a performance evaluating analysis. - The experimental evaluations are not satisfactory. Although it is claimed in the paper that the model is able to generate high quality images, it is very hard to be confirmed with these experiments. There is no concrete attempt at comparing the performance of the model to the other used methodologies. Generating high quality images with multiple views is an interesting problem, and there are good works in the field addressing the issues. To name a few: Zhu, Z., Luo, P., Wang, X., Tang, X.: Multi-view perceptron: a deep model for learning face identity and view representations. In: Advances in Neural Information Processing Systems (NIPS). pp. 217\u2013225, (2014) Kan, M., Shan, S., Chen, X.: Multi-view deep network for cross-view classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4847\u20134855, (2016) Yin, X., Liu, X.: Multi-task convolutional neural network for pose-invariant face recognition. IEEE Transactions on Image Processing (2017) Yim, J., Jung, H., Yoo, B., Choi, C., Park, D., Kim, J.: Rotating your face using multitask deep neural network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 676\u2013684, (2015) Yu Tian, Xi Peng , Long Zhao, Shaoting Zhang , ,Dimitris N. Metaxas , CR-GAN: Learning Complete Representations for Multi-view Generation, arXiv: 1806.11191, 2018. There might be differences between these works and the paper, it is common to evaluate the quality of the generation to other models in terms of accuracy or in the classification tasks. Unfortunately, there is no such quantitative analysis in the paper. So the advantages of the proposed model is not very clear since there is not enough quantitative performance analysis. It would be interesting to see complexity analysis to evaluate the computational costs. Overall, I do not recommend this paper for publication. The experimental results are not satisfactory, and the paper needs improvements in that regard. ** update: I would like to thank the authors for their comments. However, I still see major issues in the paper unresolved and my review remains the same. ", "rating": "3: Weak Reject", "reply_text": "We \u2019 d like to thank the reviewer for their review and helpful suggestions . 1 ) \u201c The experimental evaluations are not satisfactory . Although it is claimed in the paper that the model is able to generate high quality images , it is very hard to be confirmed with these experiments . There is no concrete attempt at comparing the performance of the model to the other used methodologies. \u201d We thank the reviewer for the feedback and agree with the statement . We extended the experimental section with additional experiments . The details are discussed in point 5 in the response to Reviewer 4 . 2 ) \u201c There might be differences between these works and the paper , it is common to evaluate the quality of the generation to other models in terms of accuracy or in the classification tasks . Unfortunately , there is no such quantitative analysis in the paper. \u201d Using the classification accuracy to assess the performance is an interesting approach . This however requires delicate fine-tuning of the parameters of the classifier and generative models . We therefore feel that other metrics are more suitable ( see above comment ) and leave the evaluation of the classification performance for future work as it requires a seperate in-depth study . 3 ) \u201c It would be interesting to see complexity analysis to evaluate the computational costs. \u201d We discuss the computational costs of the algorithm in Section 4 . Scalability is known to be an issue for kernel PCA , where the SVD has a complexity O ( n^3 ) with n the size of the dataset . This was hedged using mini-batches , which results in a complexity O ( m^3 ) with m the size of the mini-batch . If the size of the mini-batch is still too large , we propose to use the covariance matrix instead of the kernel matrix , the complexity is now O ( d^3 ) , with d the size of the final layer of the feature map . If both the mini-batch size and the final layer are large , the method is rather slow ( still cubic complexity ) . We hope this addresses the reviewer \u2019 s concerns ."}, {"review_id": "ryghPCVYvH-2", "review_text": "This is a very good paper, building on the idea of Restricted Kernel Machines (drawing a nice parallel between Restricted Bolzman Machines and tools available in the Kernel modelling literature). In this manuscript, the author(s) extend the work to a generative model setting to achieve multi-view generation -- a generative model that can explain correlated variables from a common subspace. The manuscript is well-written and easy to follow and the algorithmic details are clear. Image generation is illustrated on standard datasets (MNIST / CIFAR / CelebA). While the framework and learning algorithm are good, and novel extensions to what appears to be previous work of the authors, I am less persuaded by the empirical work. Latent variable-based generative modes such as this (and this is motivated in the introduction to the paper) should be judged on if they can extract anything useful about the problem domain in the latent representations that we can interpret. This is not the case here -- the results presented are examples of images that the models can generate. No critical appraisal is given about when the models might fail or when one ought to resort to this approach and not a sample from the plethora of variants of VAE we read about. What have we learnt about images / hand-written characters / faces of popular people from a study like this? From the above empirical results point of view, I do not think this manuscript is ready for publication, despite what I see as the elegance of the framework. ", "rating": "3: Weak Reject", "reply_text": "We \u2019 d like to thank the reviewer for their review and helpful suggestions . 1 ) \u201c This is a very good paper , building on the idea of Restricted Kernel Machines ( drawing a nice parallel between Restricted Bolzman Machines and tools available in the Kernel modelling literature ) . In this manuscript , the author ( s ) extend the work to a generative model setting to achieve multi-view generation -- a generative model that can explain correlated variables from a common subspace . The manuscript is well-written and easy to follow and the algorithmic details are clear . Image generation is illustrated on standard datasets ( MNIST / CIFAR / CelebA ) . \u201d We thank you for the appreciation . 2 ) \u201c Latent variable-based generative modes such as this ( and this is motivated in the introduction to the paper ) should be judged on if they can extract anything useful about the problem domain in the latent representations that we can interpret. \u201d The interpretation of the latent space was addressed in point 3 in the response to Reviewer 4 . 3 ) \u201c When one ought to resort to this approach and not a sample from the plethora of variants of VAE we read about. \u201d The comparison between Gen-RKM and the different VAE variants was done in point 4 in the response to Reviewer 4 . 4 ) \u201c No critical appraisal is given about when the models might fail \u201d 4.1 ) Scalability towards large datasets could be an issue as the computational complexity of the SVD is O ( n^3 ) with n the size of the dataset . This was hedged using mini-batches , which results in a complexity O ( m^3 ) with m the size of the mini-batch . If the size of the mini-batch is still too large , we propose to use the covariance matrix instead of the kernel matrix , the complexity is now O ( d^3 ) , with d the size of the final layer of the feature map . If both the mini-batch size and the final layer are large , the method is rather slow ( still cubic complexity ) . 4.2 ) The model has difficulties converging when the eigenvalue spectrum of the kernel matrix decreases rapidly , which means that most information is captured in a few principal components , while the rest of the components are noise . The presence of this noise hinders the convergence of the method as these eigenvectors can change drastically without affecting the reconstruction loss ( small eigenvalue ) . It is therefore important to select the number of latent variables in proportion with the size of the mini-batch and the corresponding spectrum of the kernel matrix ( the diversity within a mini-batch affects the eigenvalue spectrum of the kernel matrix ) . 5 ) \u201c From the above empirical results point of view , I do not think this manuscript is ready for publication , despite what I see as the elegance of the framework. \u201d We agree with the comment and extended the experimental section with multiple comparisons . The details are discussed in point 5 in the response to Reviewer 4 . We hope this addresses the reviewer \u2019 s concerns ."}], "0": {"review_id": "ryghPCVYvH-0", "review_text": "There exists two papers: [1] Multimodal Learning with Deep Boltzmann Machines, http://jmlr.org/papers/volume15/srivastava14b/srivastava14b.pdf [2] Deep Restricted Kernel Machines Using Conjugate Feature Duality, ftp://ftp.esat.kuleuven.ac.be/stadius/suykens/reports/deepRKM1.pdf In particular [2] considers a model, which is similar to a Boltzmann machine, but at the same time it is based on kernel features, and uses structure of the corresponding optimization problem to obtain a solution in a semi-explicit way. The authors of the considered paper 1) generalise a multimodal variant of the Boltzmann machine from [1] (which uses a special cross-product term to take into account dependency between modalities) to the case of kernel machines, 2) demonstrate on several typical datasets that using explicit deep network features it is possible to model images and data with two modalities (faces/textual description of faces). Comments: - From the description of the functionals L1 and L2 (bottom of page 4 and top of the page 5) the reader can think that the authors tune parameters (zeta_1,theta_1) and (zeta_2,theta_2) for each sample point separately - The authors claimed that the experiments were done both for kernel features and for explicit features based on neural networks. However, in the experimental section there are no results obtained when using implicit kernels. Nothings is told on how to select kernel parameters - The authors claimed that thanks to PCA-like definition of latent vectors they are orthogonal which is similar to disentangle representations. However, there are no any empirical evidences whether it is possible to benefit somehow from that orthogonal property, as well as there is no comparison with approaches to construct disentangle\u0432 latent representation for other types of generative models. Conclusions: - In general the text is accurately written, the work is well organised. - Still I was not able to understand the main idea of the paper. a) if the main idea of the paper that the authors propose some new method for generative modeling of multi-modal data, then the authors should make significantly more diverse experiments and ablation studies. Actually, this is not the case of the current work. The authors did not provide any quantitate measure and comparison with existing approaches; b) if the main idea is to present a new approach, then still I would not call the approach completely new, as it is based on well-known ideas and its benefits are completely not obvious. I guess that the paper can be published, but only after issues in a) are addressed.", "rating": "6: Weak Accept", "reply_text": "We would like to thank the reviewer for the review and helpful suggestions . 1 ) \u201c From the description of the functionals L1 and L2 ( bottom of page 4 and top of the page 5 ) the reader can think that the authors tune parameters ( zeta_1 , theta_1 ) and ( zeta_2 , theta_2 ) for each sample point separately \u201d We thank the reviewer for pointing this out , this is a typo and we changed this in the paper . 2 ) \u201c The authors claimed that the experiments were done both for kernel features and for explicit features based on neural networks . However , in the experimental section there are no results obtained when using implicit kernels . Nothings is told on how to select kernel parameters. \u201d Experiments with implicit feature maps where already shown on Figure 4a . Table 1 in the appendix shows the hyperparameters used for the experiments . The bandwidth of the Gaussian kernel for generation corresponds to the bandwidth that gave the best performance determined by cross-validation on the MNIST classification problem . 3 ) \u201c The authors claimed that thanks to PCA-like definition of latent vectors they are orthogonal which is similar to disentangle representations . However , there are no any empirical evidence whether it is possible to benefit somehow from that orthogonal property , as well as there is no comparison with approaches to construct disentangle\u0432 latent representation for other types of generative models. \u201d The definition of disentanglement in the literature is not that precise . However many believe that a representation with statistically independent variables is a good starting point [ 1,2 ] . This already gives an indication that the model could resemble a disentangled representation . This is confirmed by the empirical evidence on Figure 5 . We explore the learned uncorrelated-features by traversing along the ( orthogonal ) eigenvectors on the celebA and Dsprites dataset . These are common datasets to demonstrate disentanglement , where we repeat the experiments of [ 3 ] for the proposed Gen-RKM . For the Dsprites dataset , notice that the first and second components correspond to the y and x positions respectively . Rows 3 and 4 show the same for hearts . On the celebA dataset , rows 5 and 6 shows the reconstructed images while traversing along the principal components . When moving along the first component from left-to-right , the hair-color of the woman changes , while preserving the face structure . Whereas traversal along the second component , transforms a man to woman while preserving the orientation . When the number of principal components were 2 while training , the brightness and background light-source corresponds to the two largest variances in the dataset . This small example demonstrates how we can interpret the different components of the latent representation learned by the Gen-RKM . The latent space dimension in the RKM setting has a similar interpretation as the number of hidden units in a restricted Boltzmann machine , where in the specific case of the RKM these hidden units are uncorrelated ."}, "1": {"review_id": "ryghPCVYvH-1", "review_text": "This paper presents a model and training framework for generating samples based on restricted kernel machines. It is extended to multi-view generation and uncorrelated feature representation learning. - The paper is well-written and well-organized. Notations and claims are clear. - The idea of a multi-view generation model based on restricted kernel machines is interesting. However, the paper seems to be limited to model definition and algorithm overview without a performance evaluating analysis. - The experimental evaluations are not satisfactory. Although it is claimed in the paper that the model is able to generate high quality images, it is very hard to be confirmed with these experiments. There is no concrete attempt at comparing the performance of the model to the other used methodologies. Generating high quality images with multiple views is an interesting problem, and there are good works in the field addressing the issues. To name a few: Zhu, Z., Luo, P., Wang, X., Tang, X.: Multi-view perceptron: a deep model for learning face identity and view representations. In: Advances in Neural Information Processing Systems (NIPS). pp. 217\u2013225, (2014) Kan, M., Shan, S., Chen, X.: Multi-view deep network for cross-view classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4847\u20134855, (2016) Yin, X., Liu, X.: Multi-task convolutional neural network for pose-invariant face recognition. IEEE Transactions on Image Processing (2017) Yim, J., Jung, H., Yoo, B., Choi, C., Park, D., Kim, J.: Rotating your face using multitask deep neural network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 676\u2013684, (2015) Yu Tian, Xi Peng , Long Zhao, Shaoting Zhang , ,Dimitris N. Metaxas , CR-GAN: Learning Complete Representations for Multi-view Generation, arXiv: 1806.11191, 2018. There might be differences between these works and the paper, it is common to evaluate the quality of the generation to other models in terms of accuracy or in the classification tasks. Unfortunately, there is no such quantitative analysis in the paper. So the advantages of the proposed model is not very clear since there is not enough quantitative performance analysis. It would be interesting to see complexity analysis to evaluate the computational costs. Overall, I do not recommend this paper for publication. The experimental results are not satisfactory, and the paper needs improvements in that regard. ** update: I would like to thank the authors for their comments. However, I still see major issues in the paper unresolved and my review remains the same. ", "rating": "3: Weak Reject", "reply_text": "We \u2019 d like to thank the reviewer for their review and helpful suggestions . 1 ) \u201c The experimental evaluations are not satisfactory . Although it is claimed in the paper that the model is able to generate high quality images , it is very hard to be confirmed with these experiments . There is no concrete attempt at comparing the performance of the model to the other used methodologies. \u201d We thank the reviewer for the feedback and agree with the statement . We extended the experimental section with additional experiments . The details are discussed in point 5 in the response to Reviewer 4 . 2 ) \u201c There might be differences between these works and the paper , it is common to evaluate the quality of the generation to other models in terms of accuracy or in the classification tasks . Unfortunately , there is no such quantitative analysis in the paper. \u201d Using the classification accuracy to assess the performance is an interesting approach . This however requires delicate fine-tuning of the parameters of the classifier and generative models . We therefore feel that other metrics are more suitable ( see above comment ) and leave the evaluation of the classification performance for future work as it requires a seperate in-depth study . 3 ) \u201c It would be interesting to see complexity analysis to evaluate the computational costs. \u201d We discuss the computational costs of the algorithm in Section 4 . Scalability is known to be an issue for kernel PCA , where the SVD has a complexity O ( n^3 ) with n the size of the dataset . This was hedged using mini-batches , which results in a complexity O ( m^3 ) with m the size of the mini-batch . If the size of the mini-batch is still too large , we propose to use the covariance matrix instead of the kernel matrix , the complexity is now O ( d^3 ) , with d the size of the final layer of the feature map . If both the mini-batch size and the final layer are large , the method is rather slow ( still cubic complexity ) . We hope this addresses the reviewer \u2019 s concerns ."}, "2": {"review_id": "ryghPCVYvH-2", "review_text": "This is a very good paper, building on the idea of Restricted Kernel Machines (drawing a nice parallel between Restricted Bolzman Machines and tools available in the Kernel modelling literature). In this manuscript, the author(s) extend the work to a generative model setting to achieve multi-view generation -- a generative model that can explain correlated variables from a common subspace. The manuscript is well-written and easy to follow and the algorithmic details are clear. Image generation is illustrated on standard datasets (MNIST / CIFAR / CelebA). While the framework and learning algorithm are good, and novel extensions to what appears to be previous work of the authors, I am less persuaded by the empirical work. Latent variable-based generative modes such as this (and this is motivated in the introduction to the paper) should be judged on if they can extract anything useful about the problem domain in the latent representations that we can interpret. This is not the case here -- the results presented are examples of images that the models can generate. No critical appraisal is given about when the models might fail or when one ought to resort to this approach and not a sample from the plethora of variants of VAE we read about. What have we learnt about images / hand-written characters / faces of popular people from a study like this? From the above empirical results point of view, I do not think this manuscript is ready for publication, despite what I see as the elegance of the framework. ", "rating": "3: Weak Reject", "reply_text": "We \u2019 d like to thank the reviewer for their review and helpful suggestions . 1 ) \u201c This is a very good paper , building on the idea of Restricted Kernel Machines ( drawing a nice parallel between Restricted Bolzman Machines and tools available in the Kernel modelling literature ) . In this manuscript , the author ( s ) extend the work to a generative model setting to achieve multi-view generation -- a generative model that can explain correlated variables from a common subspace . The manuscript is well-written and easy to follow and the algorithmic details are clear . Image generation is illustrated on standard datasets ( MNIST / CIFAR / CelebA ) . \u201d We thank you for the appreciation . 2 ) \u201c Latent variable-based generative modes such as this ( and this is motivated in the introduction to the paper ) should be judged on if they can extract anything useful about the problem domain in the latent representations that we can interpret. \u201d The interpretation of the latent space was addressed in point 3 in the response to Reviewer 4 . 3 ) \u201c When one ought to resort to this approach and not a sample from the plethora of variants of VAE we read about. \u201d The comparison between Gen-RKM and the different VAE variants was done in point 4 in the response to Reviewer 4 . 4 ) \u201c No critical appraisal is given about when the models might fail \u201d 4.1 ) Scalability towards large datasets could be an issue as the computational complexity of the SVD is O ( n^3 ) with n the size of the dataset . This was hedged using mini-batches , which results in a complexity O ( m^3 ) with m the size of the mini-batch . If the size of the mini-batch is still too large , we propose to use the covariance matrix instead of the kernel matrix , the complexity is now O ( d^3 ) , with d the size of the final layer of the feature map . If both the mini-batch size and the final layer are large , the method is rather slow ( still cubic complexity ) . 4.2 ) The model has difficulties converging when the eigenvalue spectrum of the kernel matrix decreases rapidly , which means that most information is captured in a few principal components , while the rest of the components are noise . The presence of this noise hinders the convergence of the method as these eigenvectors can change drastically without affecting the reconstruction loss ( small eigenvalue ) . It is therefore important to select the number of latent variables in proportion with the size of the mini-batch and the corresponding spectrum of the kernel matrix ( the diversity within a mini-batch affects the eigenvalue spectrum of the kernel matrix ) . 5 ) \u201c From the above empirical results point of view , I do not think this manuscript is ready for publication , despite what I see as the elegance of the framework. \u201d We agree with the comment and extended the experimental section with multiple comparisons . The details are discussed in point 5 in the response to Reviewer 4 . We hope this addresses the reviewer \u2019 s concerns ."}}