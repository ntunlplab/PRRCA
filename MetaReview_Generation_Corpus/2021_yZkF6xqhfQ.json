{"year": "2021", "forum": "yZkF6xqhfQ", "title": "Do Transformers Understand Polynomial Simplification? ", "decision": "Reject", "meta_review": "While the reviewers find the experiments in the paper somewhat interesting, they find that the paper does not sufficiently address whether the limitations shown for models in this paper translate to larger models and other, more realistic, tasks, or an artifact of the setup considered in the paper.  Overall the takeaways seem unclear from the paper and I believe it is not ready for acceptance.  Addressing the issues raised by reviewers and having a more clear discussion on connections to existing results will help the paper.", "reviews": [{"review_id": "yZkF6xqhfQ-0", "review_text": "The paper studies the capability of the transformer architecture to perform rewriting to normal form in a simplified polynomial setting . It is a continuation of the research by Piotrowski et al ( PUBK ) in the area of using neural nets to do symbolic rewriting , followed later by Lample & Charton ( LC ) . Several datasets are generated , using various constraints on the sizes of coefficients , etc . Using infix vs prefix notation is also analyzed . The number of variables is either 1 or 2 , which seems insufficient . Already PUBK shows that going from 2 to 3 ( poly 5 vs poly6 ) variables reduces the performance considerably . The main difference to PUBK is that the unnormalized polynomials are generated in a simpler format ( sum of products of factors ) that makes ( or should make ) the normalization procedure very simple . And that the evaluation is done step-wise , similar e.g.to work of Gauthier [ 3 ] . The setting is a bit problematic when compared to the full setting also by forcing the normalization to be done in a particular `` obvious '' way . A richer set of rewriting steps consisting e.g.of finding common factors ( as e.g.in 2 * ( 2x+1 ) * ( y+1 ) * ( z+2 ) + 2 * ( 2x+1 ) * ( y+1 ) * ( z+3 ) ) could lead to shorter rewriting sequences . These two issues - very simple polynomials and very constrained rewriting rules - imply that the setting is insufficient to answer the question posed by the title . My overall feeling is that the paper shows a lot of experimental data , but it does not bring sufficiently interesting new insights . Some more comments : The poor generalization ( e.g.Table 16 ) of the transformer to symbolic data generated differently is not very surprising . Still , I am missing information about testing transformers trained on fewer variables on data with more variables . On page 5 the authors say `` We make sure that the simplified versions of the input polynomial in the training batches , do not collide with any endpoints in the test and validation set . '' == > How was this done ? PUBK shows that one simple kind of replacement in data ( CONST instead of all digits ) leads to very large train/test overlaps in LC . But PUBK says that this is initial and much more needs to be done . A simple improvement suggested there is measuring the Levenshtein distance as in Wang et al. , 2018 . [ 1 ] .I would expect much more on this topic given the previous work and their issues . Compared with Zombori et al . [ 2 ] , none of the settings is ever shown to learn perfectly a usable ( even if simple ) algorithm . p2 : `` As a state-of-the-art model , we explore Transformers . While both Graph Neural Networks and Transformers have been used for single-step representation learning of symbolic theorems and single step goal-theorem scoring , Transformer-based sequence-to-sequence networks have shown superior- ity in end-to-end tasks in integration , differential equations '' == > Various versions of tree neural nets have been used quite successfully by Gauthier for related symbolic tasks [ 3 ] . Similarly for guiding theorem provers , in particular in ENIGMA [ 4 ] . Prefix vs infix : see [ 5 ] for previous related work on this and more . p2 : symbolic re-write== > symbolic rewriting p2 : the facstep in the example is unclear/confusing - X^1 is replaced just by X . == > What is the underlying representation ? Can you give a more illustrative example of facstep ? References : [ 1 ] Qingxiang Wang , Cezary Kaliszyk , Josef Urban : First Experiments with Neural Translation of Informal to Formal Mathematics . CICM 2018 : 255-270 [ 2 ] Zsolt Zombori , Adri\u00e1n Csisz\u00e1rik , Henryk Michalewski , Cezary Kaliszyk , Josef Urban : Towards Finding Longer Proofs . CoRR abs/1905.13100 ( 2019 ) [ 3 ] Thibault Gauthier : Deep Reinforcement Learning for Synthesizing Functions in Higher-Order Logic . LPAR 2020 : 230-248 [ 4 ] Karel Chvalovsk\u00fd , Jan Jakubuv , Martin Suda , Josef Urban : ENIGMA-NG : Efficient Neural and Gradient-Boosted Inference Guidance for E. CADE 2019 : 197-215 [ 5 ] Bartosz Piotrowski , Josef Urban : Stateful Premise Selection by Recurrent Neural Networks . LPAR 2020 : 409-422 UPDATE The response says : `` With the straightforward use of Transformers , where the model has only seen a single variable in training , there \u2019 s no information for the model about what to do with the second variable and thus it will not generalize to the two variable case . Training on two variable-polynomials and testing on two variable-polynomials has relatively low accuracies in our experiment . This suggests that training on single variable-polynomials and testing on two variable-polynomials will result in even lower accuracies . With more work , one may be able to design a model with appropriate inductive bias that understands the concept of multiple variables . This is beyond our scope . '' I am afraid that this makes the study rather insufficient for me . The problem of representing variables , eigenvariables/skolems , and capturing structural similarity between different theories and signatures is ubiquitous in the ML-for-TP area . Practically all useful systems developed so far - both features-based and DL-based - have to address this . The authors ' answer is `` our representation is unsuitable '' . The observation that if you have no shared representation of variables , you will get little/no generalization is a no-brainer and there is hardly any need to publish negative papers about it . In particular , in a conference about * representations * and some 15 years after first useful systems dealing with such issues have been developed . There are many fixes to this - see e.g.Gauthier 's representation of variables in his Tree NNs , etc . My score will stand , but I would like to encourage the authors to dig deeper and follow the suggestions given in this and other reviews . The general topic of learnability of symbolic rewriting by various neural architectures is certainly interesting , potentially very useful , and far from well understood .", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear Reviewer , we appreciate your detailed comments on the work . We put your comments in quotes , followed by our responses . \u201c The number of variables is either 1 or 2 \u201d : This relates to the main aim of the work . The main aim is to test Transformers on the polynomial simplification task in a fine-grained manner ; i.e.from step-wise understanding all the way down to basic operator level understanding . While it is true that we could have looked at more variables , our results for two variables already show considerable decrease in accuracy . Claimed similarity with Gauthier [ 3 ] : Indeed , many of the works on neural theorem provers cited in the paper produce stepwise proofs and Gauthier [ 3 ] appears to be in the same category . As explained in the paper , our setting is distinct from these in that no search is involved and thus the task is much simpler . \u201c These two issues - very simple polynomials and very constrained rewriting rules - imply that the setting is insufficient to answer the question posed by the title. \u201d : We agree that the precise task that we study is a special type of polynomial simplification . However , we think the above comment is misplaced for several reasons : ( 1 ) While the title of the paper does mention polynomial simplification without qualification , the task is very clearly specified in the paper from the beginning and there 's no claim that we are studying * the * polynomial simplification task . To our knowledge , there 's no * canonical * polynomial simplification task . Indeed , there \u2019 s no limit to how complex one can allow the rewrite steps to be . Given this , we think that the title is descriptive and not unreasonable as it is difficult to specify the details in the title . ( 2 ) Our negative results show that Transformers fail even for such a simple task in some of the settings ( e.g. , two variables results in Table 2 ) . This strongly suggests that Transformers will fail if we increase the complexity of the task , e.g.by allowing richer rewrite rules or increasing the number of variables . For negative results , failure on a simpler task is a * stronger * result . ( 3 ) Allowing richer rewriting rules is interesting in its own right but not relevant for our purpose here which is to study what Transformers allow us to do in a very simple setting . Forcing the normalization to be done in the unique ( or \u201c obvious \u201d ) way is an important design feature of our study that enables us to do this . We can of course give up on uniqueness and generate a dataset without unique proofs , and increase the complexity of the task in other ways . We suspect that that will further degrade the performance of Transformers . \u201c it does not bring sufficiently interesting new insights \u201d : Please see our general response . \u201c Still , I am missing information about testing transformers trained on fewer variables on data with more variables. \u201d : With the straightforward use of Transformers , where the model has only seen a single variable in training , there \u2019 s no information for the model about what to do with the second variable and thus it will not generalize to the two variable case . Training on two variable-polynomials and testing on two variable-polynomials has relatively low accuracies in our experiment . This suggests that training on single variable-polynomials and testing on two variable-polynomials will result in even lower accuracies . With more work , one may be able to design a model with appropriate inductive bias that understands the concept of multiple variables . This is beyond our scope . Train Test Disjoint : We ensure that no unnormalized polynomial in train set simplifies to the same polynomial and one in the test set . This ensures that none of the intermediate steps could also be the same . CONST substitution by PUBK : The CONST substitution done by PUBK [ 1 ] on the LC [ 2 ] dataset is not applicable for the polynomial dataset as here arithmetic is an integral part of our task , which is not the case for integration . \u201c Compared with Zombori et al . [ 2 ] , none of the settings is ever shown to learn perfectly a usable ( even if simple ) algorithm \u201d : This comment too seems to stem from a misunderstanding of our goals . We are not sure which result in [ 2 ] is being referred to here . \u201c What is the underlying representation ? Can you give a more illustrative example of facstep ? \u201d The underlying representation is simply the inorder ( infix ) or preorder ( prefix ) traversal of the expression tree . So , 2 * x1 ^ 2 * x2 is written as [ 2 , MUL , x1 , EXP , 2 , MUL , x2 ] in infix . Facstep example : 2 * x1 ^ 1 + 1 * x2 - > 2 * x1 + x2 Representation : [ 2 , MUL , x1 , EXP , 1 , ADD , 1 , MUL , x2 ] - > [ 2 , MUL , x1 , ADD , x2 ]"}, {"review_id": "yZkF6xqhfQ-1", "review_text": "The paper `` Do Transformers Understand Polynomial Simplification ? '' introduces a new reasoning task ( convert polynomials into a normal form ) and studies the performance and errors of Transformers on this task . The task itself is quite simple : given a randomly generated term involving small constants , variables , additions , and multiplications , bring the term into a well-defined normal form . Each task has to be solved in a unique sequence of steps . The authors study the performance of Transformers to either simplify the expressions step by step or to predict the simplified version directly . Contributions I highly appreciate : - Contrasting step-wise generation of proofs vs end-point prediction . - Contrasting different representations of formulas : prefix notation appears to be better than infix notation . - Observation that transformers struggle with multiplication . Questions to the authors : - The task is pretty simple compared to other ( mathematical ) reasoning tasks studied in the literature . The task is also not very useful as a prediction target , because it can be solved with a simple algorithm , as far as I can see . The paper essentially claims that this allows us to study Transformers better . What insights were produced here that could n't have been produced on more challenging benchmark from the literature ? - Why is it important for your paper that proofs are unique ? Do we simply train Transformers to execute a simple algorithm ? If so , how does that relate to the existing theorem proving and reasoning approaches where we usually have many possible proofs for a task . - What is the point of `` establishing baselines '' if the task is essentially solved already with moderately-sized Transformers ? - What can be learned from the curriculum learning experiments ? The way the curriculum is defined here appears to essentially require a synthetic benchmark for which we can generate examples of different hardness levels . So how could this help for real problems ? - Introduction and Conclusion : The paper claims that training on the two variable case leads to better performance on the one variable case than training on it directly . This sounds very much like an artifact that could stem from the lack of training data or so . How is this possible ? Minor comments : p.1 , pargraph 1 : I believe Hahn et al also propose an `` end-to-end '' task using Transformers instead of embedding their approach in an existing neuro-symbolic system . p.1 , paragraph 2 : The reference to Lample & Charton is slightly off : It was published in ICLR 2020. p.2 , paragraph 1 : `` we observe that the system can understand candidate sub-expressions ... '' I am always wary of the use of `` understand '' in the context of neural networks , as it is not very clear what it means . p2.related work : I do not understand how you contrast your work to the existing theorem proving works : There are a number of neural theorem provers ( HOList , GamePad , GPT-f , and probably some more ) that also generate proofs step by step . They might employ more advanced search ideas , but I think it would be good to state why your paper does not want to go in this direction . p.2 , Section 3 : How does Sympy `` ensure correctness '' ? There could be bugs in the code even if you did n't write the code yourself ? p.2 , footnote : `` an unique '' - > `` a unique '' p.3 , last paragraph : remove `` Hence '' . Additional details about the training setup would be appreciated . For example , how many training steps/epochs did you train for ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your kind and encouraging comments . Please find our response for individual comments below . We put your comments in quotes , followed by our response . \u201c The task is also not very useful as a prediction target , because it can be solved with a simple algorithm , as far as I can see . The paper essentially claims that this allows us to study Transformers better . What insights were produced here that could n't have been produced on more challenging benchmark from the literature ? \u201d : We agree that the final goal of this line of research is to design models that can learn to solve problems that we do n't already know how to solve . Several recent works in ATP frameworks cited in the paper have attempted to do this . The accuracies achieved remain low . This could be for various reasons including deficiencies of the models and/or of data . To understand the situation better , it seems reasonable to first check if our models are able to solve much simpler problems where we have fine-grained control over various aspects of the dataset ( this is impossible for ATP frameworks ) . For some examples of insights from our work , please see our common response . Unique Proofs : In keeping with our general philosophy of having a very simple setting , unique proofs simplify the task of the Transformer as at each step it has a unique step to perform . ( If the proofs are not unique , then one could use RL/MCTS-based approaches as is done in many papers or learn the most probable next steps as in language models . ) \u201c What is the point of `` establishing baselines '' if the task is essentially solved already with moderately-sized Transformers ? \u201d : It is true that the task can be solved by a simple algorithm , however the task using Transformers as the model is not solved ( Low accuracies in Table 1 and 2 ) . Thus , our results can serve as a baseline for this problem . \u201c What can be learned from the curriculum learning experiments ? The way the curriculum is defined here appears to essentially require a synthetic benchmark for which we can generate examples of different hardness levels . So how could this help for real problems ? \u201d This is a good point . Certainly new curriculums will be needed for real problems . CL Experiments : First a note that , by using synthetic dataset generation , our goal was to eliminate the concerns such as \u201c lack of data \u201d . Since , even in this setting , Transformers perform poorly , in many configurations , we wanted to employ traditional techniques such as CL to see whether such available techniques may improve the performance of Transformers . We observe that for many configurations , there is surprising improvement when CL is employed carefully . But , its inability to show a steady performance improvement again shows why more work is required for improving Transformers \u2019 performance even for a seemingly simpler task of polynomial simplification . \u201c Introduction and Conclusion : The paper claims that training on the two variable case leads to better performance on the one variable case than training on it directly . This sounds very much like an artifact that could stem from the lack of training data or so . How is this possible ? \u201d : While we don \u2019 t have an explanation for this observation , we remark that : it can \u2019 t be an artefact of the data . Both 1-var and 2-var models converge after similar number of steps ( # Train column in Table 1 and 2 ) . Thus , 1-var models see more single variable polynomials than 2-var models . But the 2-var model gets polynomials sampled from the 2 var distribution . ( Table 1 and 2 ) It could happen that with 2 variables , the task of collecting variables together is better exemplified . In the sense that the tougher task model is performing good on a simpler task \u201c p.2 , paragraph 1 : `` we observe that the system can understand candidate sub-expressions ... '' I am always wary of the use of `` understand '' in the context of neural networks , as it is not very clear what it means. \u201d : We agree . A better title would have been \u201c Can Transformers Perform Polynomial Simplification. \u201d \u201c For example , how many training steps/epochs did you train for ? \u201d As the data is generated on the fly , number of examples seen = number of training steps . # EE and # Train columns in the result tables correspond to the number of training steps . We will update the draft if we see more details are required for reproduction of the results ."}, {"review_id": "yZkF6xqhfQ-2", "review_text": "The authors analyze the performance of Transformer models on simplifying polynomials and - importantly - generating proofs at the same time . This is a very nice idea that allows to study the performance of Transformers in depth and at the same time in an important setting where verification is performed as part of running the model . And the authors show a strong baseline , with models performing very well in a number of settings . A few areas seem to have been neglected though . For one , the authors only train a 4-layer 4-head model , which is quite small as far as Transformers go . Maybe it 's irrelevant for this problem - but having at least one bigger model as a point of comparison would be good . Next , the out-of-distribution question warrants more experiments . Can the Transformers simplify polynomials with way more factors than trained on ? With a higher number of variables ? Higher degrees ? The authors also show that one main problem for Transformers is learning to multiply the coefficients . But - assuming this reviewer understood correctly - the authors do not apply the proof requirement to multiplication . E.g. , for `` 12 * 3 '' the model has to immediately output `` 36 '' rather than `` 10 * 3 + 2 * 3 = 30 + 6 = 36 '' . Maybe this could help the Transformer learn and be more resilient to coefficient size ? So while the current version of the paper is ok , there are a few areas for improvement which prevent it from being a clear accept .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer , thank you for your encouraging comments . Please find our response below . \u201c For one , the authors only train a 4-layer 4-head model , which is quite small as far as Transformers go. \u201d : We plan to perform these experiments in future . However , as mentioned in the general response , such a choice does not conflict with our premise and the obtained insights . \u201c Can the Transformers simplify polynomials with way more factors than trained on ? With a higher number of variables ? Higher degrees ? \u201d : For OOD evaluation , we evaluate by increasing more factors , higher coefficients , and higher exponents . The comparison of MEDIUM COEFF , MEDIUM TERMS & MEDIUM DEGREE ( Table 16 ) shows this data . For 2 variables and other settings , please check Tables 14 , 15 . Finer Steps in Arithmetic Multiplication question : You are correct in stating that we do not add such finer steps for arithmetic multiplication . However , our results show ( Table 9 for annotated proofs ) that Transformers suffer on longer proofs . Since , the above modification will generate even longer proofs , we suspect the setting will lead to even worse results . Having said that , we do plan to perform experiments where the difficulty in integer factorization is \u201c outsourced \u201d by making an external program ( a standard integer multiplication program ) perform integer multiplication and letting the Transformers handle only symbolic manipulation . As the experimentation over all variations will take time , we believe we will be able to include the results in the final version upon acceptance ."}, {"review_id": "yZkF6xqhfQ-3", "review_text": "This paper studies the efficacy of transformers on a polynomial simplification tasks . There are two main motivations for this work : Piotrowski et al and , Lample and Sarton ( references in the paper ) . The paper is set out to explore the capability of transformer networks of creating muti-step proofs . One of the contributions of the paper is the creation of dataset of polynomial simplifications . They use the method in Lample and Charleston to generate a large random dataset of polynomials represented as a sum of products . Each term in that product is a product of a small set of factors . So the basic question is : how do we represent this polynomial by a formula of minimum length , in which each operation is one of the + , - or * . This is a hard question for sure . But is this question as hard as in Lample and Sarton ? Is it hard as computing integrals of expressions ? Everybofy knows that computing integrals is hard . In fact , it is much harder than computing partial derivatives . How hard is it to give a representation of a sum of products ? It might be hard . But is it as hard as the above ? I ca n't tell , but this paper does not even specify what is a baseline . When do we believe that something is important . This paper fails to specify what is an interesting message and fails to specify that message .", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . Please see our general response , as most of the objections/concerns are related to the basic premise of the work . In short , our aim is not to test on harder problems , but to test the transformer 's ability to do multi-step reasoning . Within the scope of a somewhat simpler setting of polynomial simplification tasks , our results map out the strengths and weaknesses of Transformers ."}], "0": {"review_id": "yZkF6xqhfQ-0", "review_text": "The paper studies the capability of the transformer architecture to perform rewriting to normal form in a simplified polynomial setting . It is a continuation of the research by Piotrowski et al ( PUBK ) in the area of using neural nets to do symbolic rewriting , followed later by Lample & Charton ( LC ) . Several datasets are generated , using various constraints on the sizes of coefficients , etc . Using infix vs prefix notation is also analyzed . The number of variables is either 1 or 2 , which seems insufficient . Already PUBK shows that going from 2 to 3 ( poly 5 vs poly6 ) variables reduces the performance considerably . The main difference to PUBK is that the unnormalized polynomials are generated in a simpler format ( sum of products of factors ) that makes ( or should make ) the normalization procedure very simple . And that the evaluation is done step-wise , similar e.g.to work of Gauthier [ 3 ] . The setting is a bit problematic when compared to the full setting also by forcing the normalization to be done in a particular `` obvious '' way . A richer set of rewriting steps consisting e.g.of finding common factors ( as e.g.in 2 * ( 2x+1 ) * ( y+1 ) * ( z+2 ) + 2 * ( 2x+1 ) * ( y+1 ) * ( z+3 ) ) could lead to shorter rewriting sequences . These two issues - very simple polynomials and very constrained rewriting rules - imply that the setting is insufficient to answer the question posed by the title . My overall feeling is that the paper shows a lot of experimental data , but it does not bring sufficiently interesting new insights . Some more comments : The poor generalization ( e.g.Table 16 ) of the transformer to symbolic data generated differently is not very surprising . Still , I am missing information about testing transformers trained on fewer variables on data with more variables . On page 5 the authors say `` We make sure that the simplified versions of the input polynomial in the training batches , do not collide with any endpoints in the test and validation set . '' == > How was this done ? PUBK shows that one simple kind of replacement in data ( CONST instead of all digits ) leads to very large train/test overlaps in LC . But PUBK says that this is initial and much more needs to be done . A simple improvement suggested there is measuring the Levenshtein distance as in Wang et al. , 2018 . [ 1 ] .I would expect much more on this topic given the previous work and their issues . Compared with Zombori et al . [ 2 ] , none of the settings is ever shown to learn perfectly a usable ( even if simple ) algorithm . p2 : `` As a state-of-the-art model , we explore Transformers . While both Graph Neural Networks and Transformers have been used for single-step representation learning of symbolic theorems and single step goal-theorem scoring , Transformer-based sequence-to-sequence networks have shown superior- ity in end-to-end tasks in integration , differential equations '' == > Various versions of tree neural nets have been used quite successfully by Gauthier for related symbolic tasks [ 3 ] . Similarly for guiding theorem provers , in particular in ENIGMA [ 4 ] . Prefix vs infix : see [ 5 ] for previous related work on this and more . p2 : symbolic re-write== > symbolic rewriting p2 : the facstep in the example is unclear/confusing - X^1 is replaced just by X . == > What is the underlying representation ? Can you give a more illustrative example of facstep ? References : [ 1 ] Qingxiang Wang , Cezary Kaliszyk , Josef Urban : First Experiments with Neural Translation of Informal to Formal Mathematics . CICM 2018 : 255-270 [ 2 ] Zsolt Zombori , Adri\u00e1n Csisz\u00e1rik , Henryk Michalewski , Cezary Kaliszyk , Josef Urban : Towards Finding Longer Proofs . CoRR abs/1905.13100 ( 2019 ) [ 3 ] Thibault Gauthier : Deep Reinforcement Learning for Synthesizing Functions in Higher-Order Logic . LPAR 2020 : 230-248 [ 4 ] Karel Chvalovsk\u00fd , Jan Jakubuv , Martin Suda , Josef Urban : ENIGMA-NG : Efficient Neural and Gradient-Boosted Inference Guidance for E. CADE 2019 : 197-215 [ 5 ] Bartosz Piotrowski , Josef Urban : Stateful Premise Selection by Recurrent Neural Networks . LPAR 2020 : 409-422 UPDATE The response says : `` With the straightforward use of Transformers , where the model has only seen a single variable in training , there \u2019 s no information for the model about what to do with the second variable and thus it will not generalize to the two variable case . Training on two variable-polynomials and testing on two variable-polynomials has relatively low accuracies in our experiment . This suggests that training on single variable-polynomials and testing on two variable-polynomials will result in even lower accuracies . With more work , one may be able to design a model with appropriate inductive bias that understands the concept of multiple variables . This is beyond our scope . '' I am afraid that this makes the study rather insufficient for me . The problem of representing variables , eigenvariables/skolems , and capturing structural similarity between different theories and signatures is ubiquitous in the ML-for-TP area . Practically all useful systems developed so far - both features-based and DL-based - have to address this . The authors ' answer is `` our representation is unsuitable '' . The observation that if you have no shared representation of variables , you will get little/no generalization is a no-brainer and there is hardly any need to publish negative papers about it . In particular , in a conference about * representations * and some 15 years after first useful systems dealing with such issues have been developed . There are many fixes to this - see e.g.Gauthier 's representation of variables in his Tree NNs , etc . My score will stand , but I would like to encourage the authors to dig deeper and follow the suggestions given in this and other reviews . The general topic of learnability of symbolic rewriting by various neural architectures is certainly interesting , potentially very useful , and far from well understood .", "rating": "4: Ok but not good enough - rejection", "reply_text": "Dear Reviewer , we appreciate your detailed comments on the work . We put your comments in quotes , followed by our responses . \u201c The number of variables is either 1 or 2 \u201d : This relates to the main aim of the work . The main aim is to test Transformers on the polynomial simplification task in a fine-grained manner ; i.e.from step-wise understanding all the way down to basic operator level understanding . While it is true that we could have looked at more variables , our results for two variables already show considerable decrease in accuracy . Claimed similarity with Gauthier [ 3 ] : Indeed , many of the works on neural theorem provers cited in the paper produce stepwise proofs and Gauthier [ 3 ] appears to be in the same category . As explained in the paper , our setting is distinct from these in that no search is involved and thus the task is much simpler . \u201c These two issues - very simple polynomials and very constrained rewriting rules - imply that the setting is insufficient to answer the question posed by the title. \u201d : We agree that the precise task that we study is a special type of polynomial simplification . However , we think the above comment is misplaced for several reasons : ( 1 ) While the title of the paper does mention polynomial simplification without qualification , the task is very clearly specified in the paper from the beginning and there 's no claim that we are studying * the * polynomial simplification task . To our knowledge , there 's no * canonical * polynomial simplification task . Indeed , there \u2019 s no limit to how complex one can allow the rewrite steps to be . Given this , we think that the title is descriptive and not unreasonable as it is difficult to specify the details in the title . ( 2 ) Our negative results show that Transformers fail even for such a simple task in some of the settings ( e.g. , two variables results in Table 2 ) . This strongly suggests that Transformers will fail if we increase the complexity of the task , e.g.by allowing richer rewrite rules or increasing the number of variables . For negative results , failure on a simpler task is a * stronger * result . ( 3 ) Allowing richer rewriting rules is interesting in its own right but not relevant for our purpose here which is to study what Transformers allow us to do in a very simple setting . Forcing the normalization to be done in the unique ( or \u201c obvious \u201d ) way is an important design feature of our study that enables us to do this . We can of course give up on uniqueness and generate a dataset without unique proofs , and increase the complexity of the task in other ways . We suspect that that will further degrade the performance of Transformers . \u201c it does not bring sufficiently interesting new insights \u201d : Please see our general response . \u201c Still , I am missing information about testing transformers trained on fewer variables on data with more variables. \u201d : With the straightforward use of Transformers , where the model has only seen a single variable in training , there \u2019 s no information for the model about what to do with the second variable and thus it will not generalize to the two variable case . Training on two variable-polynomials and testing on two variable-polynomials has relatively low accuracies in our experiment . This suggests that training on single variable-polynomials and testing on two variable-polynomials will result in even lower accuracies . With more work , one may be able to design a model with appropriate inductive bias that understands the concept of multiple variables . This is beyond our scope . Train Test Disjoint : We ensure that no unnormalized polynomial in train set simplifies to the same polynomial and one in the test set . This ensures that none of the intermediate steps could also be the same . CONST substitution by PUBK : The CONST substitution done by PUBK [ 1 ] on the LC [ 2 ] dataset is not applicable for the polynomial dataset as here arithmetic is an integral part of our task , which is not the case for integration . \u201c Compared with Zombori et al . [ 2 ] , none of the settings is ever shown to learn perfectly a usable ( even if simple ) algorithm \u201d : This comment too seems to stem from a misunderstanding of our goals . We are not sure which result in [ 2 ] is being referred to here . \u201c What is the underlying representation ? Can you give a more illustrative example of facstep ? \u201d The underlying representation is simply the inorder ( infix ) or preorder ( prefix ) traversal of the expression tree . So , 2 * x1 ^ 2 * x2 is written as [ 2 , MUL , x1 , EXP , 2 , MUL , x2 ] in infix . Facstep example : 2 * x1 ^ 1 + 1 * x2 - > 2 * x1 + x2 Representation : [ 2 , MUL , x1 , EXP , 1 , ADD , 1 , MUL , x2 ] - > [ 2 , MUL , x1 , ADD , x2 ]"}, "1": {"review_id": "yZkF6xqhfQ-1", "review_text": "The paper `` Do Transformers Understand Polynomial Simplification ? '' introduces a new reasoning task ( convert polynomials into a normal form ) and studies the performance and errors of Transformers on this task . The task itself is quite simple : given a randomly generated term involving small constants , variables , additions , and multiplications , bring the term into a well-defined normal form . Each task has to be solved in a unique sequence of steps . The authors study the performance of Transformers to either simplify the expressions step by step or to predict the simplified version directly . Contributions I highly appreciate : - Contrasting step-wise generation of proofs vs end-point prediction . - Contrasting different representations of formulas : prefix notation appears to be better than infix notation . - Observation that transformers struggle with multiplication . Questions to the authors : - The task is pretty simple compared to other ( mathematical ) reasoning tasks studied in the literature . The task is also not very useful as a prediction target , because it can be solved with a simple algorithm , as far as I can see . The paper essentially claims that this allows us to study Transformers better . What insights were produced here that could n't have been produced on more challenging benchmark from the literature ? - Why is it important for your paper that proofs are unique ? Do we simply train Transformers to execute a simple algorithm ? If so , how does that relate to the existing theorem proving and reasoning approaches where we usually have many possible proofs for a task . - What is the point of `` establishing baselines '' if the task is essentially solved already with moderately-sized Transformers ? - What can be learned from the curriculum learning experiments ? The way the curriculum is defined here appears to essentially require a synthetic benchmark for which we can generate examples of different hardness levels . So how could this help for real problems ? - Introduction and Conclusion : The paper claims that training on the two variable case leads to better performance on the one variable case than training on it directly . This sounds very much like an artifact that could stem from the lack of training data or so . How is this possible ? Minor comments : p.1 , pargraph 1 : I believe Hahn et al also propose an `` end-to-end '' task using Transformers instead of embedding their approach in an existing neuro-symbolic system . p.1 , paragraph 2 : The reference to Lample & Charton is slightly off : It was published in ICLR 2020. p.2 , paragraph 1 : `` we observe that the system can understand candidate sub-expressions ... '' I am always wary of the use of `` understand '' in the context of neural networks , as it is not very clear what it means . p2.related work : I do not understand how you contrast your work to the existing theorem proving works : There are a number of neural theorem provers ( HOList , GamePad , GPT-f , and probably some more ) that also generate proofs step by step . They might employ more advanced search ideas , but I think it would be good to state why your paper does not want to go in this direction . p.2 , Section 3 : How does Sympy `` ensure correctness '' ? There could be bugs in the code even if you did n't write the code yourself ? p.2 , footnote : `` an unique '' - > `` a unique '' p.3 , last paragraph : remove `` Hence '' . Additional details about the training setup would be appreciated . For example , how many training steps/epochs did you train for ?", "rating": "6: Marginally above acceptance threshold", "reply_text": "Thank you for your kind and encouraging comments . Please find our response for individual comments below . We put your comments in quotes , followed by our response . \u201c The task is also not very useful as a prediction target , because it can be solved with a simple algorithm , as far as I can see . The paper essentially claims that this allows us to study Transformers better . What insights were produced here that could n't have been produced on more challenging benchmark from the literature ? \u201d : We agree that the final goal of this line of research is to design models that can learn to solve problems that we do n't already know how to solve . Several recent works in ATP frameworks cited in the paper have attempted to do this . The accuracies achieved remain low . This could be for various reasons including deficiencies of the models and/or of data . To understand the situation better , it seems reasonable to first check if our models are able to solve much simpler problems where we have fine-grained control over various aspects of the dataset ( this is impossible for ATP frameworks ) . For some examples of insights from our work , please see our common response . Unique Proofs : In keeping with our general philosophy of having a very simple setting , unique proofs simplify the task of the Transformer as at each step it has a unique step to perform . ( If the proofs are not unique , then one could use RL/MCTS-based approaches as is done in many papers or learn the most probable next steps as in language models . ) \u201c What is the point of `` establishing baselines '' if the task is essentially solved already with moderately-sized Transformers ? \u201d : It is true that the task can be solved by a simple algorithm , however the task using Transformers as the model is not solved ( Low accuracies in Table 1 and 2 ) . Thus , our results can serve as a baseline for this problem . \u201c What can be learned from the curriculum learning experiments ? The way the curriculum is defined here appears to essentially require a synthetic benchmark for which we can generate examples of different hardness levels . So how could this help for real problems ? \u201d This is a good point . Certainly new curriculums will be needed for real problems . CL Experiments : First a note that , by using synthetic dataset generation , our goal was to eliminate the concerns such as \u201c lack of data \u201d . Since , even in this setting , Transformers perform poorly , in many configurations , we wanted to employ traditional techniques such as CL to see whether such available techniques may improve the performance of Transformers . We observe that for many configurations , there is surprising improvement when CL is employed carefully . But , its inability to show a steady performance improvement again shows why more work is required for improving Transformers \u2019 performance even for a seemingly simpler task of polynomial simplification . \u201c Introduction and Conclusion : The paper claims that training on the two variable case leads to better performance on the one variable case than training on it directly . This sounds very much like an artifact that could stem from the lack of training data or so . How is this possible ? \u201d : While we don \u2019 t have an explanation for this observation , we remark that : it can \u2019 t be an artefact of the data . Both 1-var and 2-var models converge after similar number of steps ( # Train column in Table 1 and 2 ) . Thus , 1-var models see more single variable polynomials than 2-var models . But the 2-var model gets polynomials sampled from the 2 var distribution . ( Table 1 and 2 ) It could happen that with 2 variables , the task of collecting variables together is better exemplified . In the sense that the tougher task model is performing good on a simpler task \u201c p.2 , paragraph 1 : `` we observe that the system can understand candidate sub-expressions ... '' I am always wary of the use of `` understand '' in the context of neural networks , as it is not very clear what it means. \u201d : We agree . A better title would have been \u201c Can Transformers Perform Polynomial Simplification. \u201d \u201c For example , how many training steps/epochs did you train for ? \u201d As the data is generated on the fly , number of examples seen = number of training steps . # EE and # Train columns in the result tables correspond to the number of training steps . We will update the draft if we see more details are required for reproduction of the results ."}, "2": {"review_id": "yZkF6xqhfQ-2", "review_text": "The authors analyze the performance of Transformer models on simplifying polynomials and - importantly - generating proofs at the same time . This is a very nice idea that allows to study the performance of Transformers in depth and at the same time in an important setting where verification is performed as part of running the model . And the authors show a strong baseline , with models performing very well in a number of settings . A few areas seem to have been neglected though . For one , the authors only train a 4-layer 4-head model , which is quite small as far as Transformers go . Maybe it 's irrelevant for this problem - but having at least one bigger model as a point of comparison would be good . Next , the out-of-distribution question warrants more experiments . Can the Transformers simplify polynomials with way more factors than trained on ? With a higher number of variables ? Higher degrees ? The authors also show that one main problem for Transformers is learning to multiply the coefficients . But - assuming this reviewer understood correctly - the authors do not apply the proof requirement to multiplication . E.g. , for `` 12 * 3 '' the model has to immediately output `` 36 '' rather than `` 10 * 3 + 2 * 3 = 30 + 6 = 36 '' . Maybe this could help the Transformer learn and be more resilient to coefficient size ? So while the current version of the paper is ok , there are a few areas for improvement which prevent it from being a clear accept .", "rating": "6: Marginally above acceptance threshold", "reply_text": "Dear Reviewer , thank you for your encouraging comments . Please find our response below . \u201c For one , the authors only train a 4-layer 4-head model , which is quite small as far as Transformers go. \u201d : We plan to perform these experiments in future . However , as mentioned in the general response , such a choice does not conflict with our premise and the obtained insights . \u201c Can the Transformers simplify polynomials with way more factors than trained on ? With a higher number of variables ? Higher degrees ? \u201d : For OOD evaluation , we evaluate by increasing more factors , higher coefficients , and higher exponents . The comparison of MEDIUM COEFF , MEDIUM TERMS & MEDIUM DEGREE ( Table 16 ) shows this data . For 2 variables and other settings , please check Tables 14 , 15 . Finer Steps in Arithmetic Multiplication question : You are correct in stating that we do not add such finer steps for arithmetic multiplication . However , our results show ( Table 9 for annotated proofs ) that Transformers suffer on longer proofs . Since , the above modification will generate even longer proofs , we suspect the setting will lead to even worse results . Having said that , we do plan to perform experiments where the difficulty in integer factorization is \u201c outsourced \u201d by making an external program ( a standard integer multiplication program ) perform integer multiplication and letting the Transformers handle only symbolic manipulation . As the experimentation over all variations will take time , we believe we will be able to include the results in the final version upon acceptance ."}, "3": {"review_id": "yZkF6xqhfQ-3", "review_text": "This paper studies the efficacy of transformers on a polynomial simplification tasks . There are two main motivations for this work : Piotrowski et al and , Lample and Sarton ( references in the paper ) . The paper is set out to explore the capability of transformer networks of creating muti-step proofs . One of the contributions of the paper is the creation of dataset of polynomial simplifications . They use the method in Lample and Charleston to generate a large random dataset of polynomials represented as a sum of products . Each term in that product is a product of a small set of factors . So the basic question is : how do we represent this polynomial by a formula of minimum length , in which each operation is one of the + , - or * . This is a hard question for sure . But is this question as hard as in Lample and Sarton ? Is it hard as computing integrals of expressions ? Everybofy knows that computing integrals is hard . In fact , it is much harder than computing partial derivatives . How hard is it to give a representation of a sum of products ? It might be hard . But is it as hard as the above ? I ca n't tell , but this paper does not even specify what is a baseline . When do we believe that something is important . This paper fails to specify what is an interesting message and fails to specify that message .", "rating": "4: Ok but not good enough - rejection", "reply_text": "Thank you for your review . Please see our general response , as most of the objections/concerns are related to the basic premise of the work . In short , our aim is not to test on harder problems , but to test the transformer 's ability to do multi-step reasoning . Within the scope of a somewhat simpler setting of polynomial simplification tasks , our results map out the strengths and weaknesses of Transformers ."}}