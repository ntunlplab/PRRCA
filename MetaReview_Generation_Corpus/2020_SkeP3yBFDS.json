{"year": "2020", "forum": "SkeP3yBFDS", "title": "Reducing Computation in Recurrent Networks by Selectively Updating State Neurons", "decision": "Reject", "meta_review": "This paper introduces a new RNN architecture which uses a small network to decide which cells get updated at each time step, with the goal of reducing computational cost.  The idea makes sense, although it requires the use of a heuristic gradient estimator because of the non-differentiability of the update gate.\n\nThe main problem with this paper in my view is that the reduction in FLOPS was not demonstrated to correspond to a reduction in wallclock time, and I don't expect it would, since the sparse updates are different for each example in each batch, and only affect one hidden unit at a time.  The only discussion of this problem is \"we compute the FLOPs for each method as a surrogate for wall-clock time, which is hardware-dependent and often fluctuates dramatically in practice.\"  Because this method reduces predictive accuracy, the reduction in FLOPS should be worth it!\n\nMinor criticism:\n1) Figure 1 is confusing, showing not the proposed architecture in general but instead the connections remaining after computing the sparse updates.\n", "reviews": [{"review_id": "SkeP3yBFDS-0", "review_text": "Summary: This paper proposes selective activation RNN (SA-RNN), by using an update coordinator to determine which subset of the RNN\u2019s hidden state dimensions should be updated at a given timestep. The proposed loss term is then a sum of the original objective (e.g. classification) and a weighted sum of the probability that each dimension will be updated for each timestep. The method is evaluated on 3 time series datasets: Seizures, TwitterBuzz, Yahoo. Decision: Weak Reject. Although the authors tackle a challenging problem, their empirical results are lacking to provably demonstrate that their approach outperforms existing baselines. Supporting Arguments/Feedback: The authors compare SA-RNN to 5 baselines: random updates, clockwork RNN, phased LSTM, Skip RNN, and VC-GRU. Although I appreciated the authors\u2019 comparison across the suite of methods with respect to various metrics (e.g. # FLOPS, proportion of neurons that weren\u2019t updated, etc.), the experiments were conducted on datasets that were relatively simple. For example, in prior work, the empirical evaluations were on much larger-scale datasets such as Wikipedia [Shen et. al 2019], real clinical data sources [Liu et. al 2018], and Charades videos [Campos et. al 2018], among others. I would be very interested to see how this training procedure fairs when evaluated on much more complex tasks, and would make the results about computational speedups at train/test time much more convincing. Questions: - I\u2019m curious if you tried different types of gradient estimators to get around the non-differentiability rather than the straight-through estimator. Also how was the slope-annealing conducted (e.g. annealing schedule)? ", "rating": "6: Weak Accept", "reply_text": "Thank you very much for your constructive review . Per your suggestion , we have run further experiments on more complicated data that we hope will convince you of both the merit of our proposed method along with this line of research with respect to previous approaches . We revised the paper , adding a new section to the beginning of the appendix that describes the \u201c Adding \u201d task , which asks a network to learn to sum two values in a long sequence of sampled values given a mask indicating the indices to be summed , along with our results . We invite you to take a look at the new section but we highlight our main findings as follows : To add a new perspective on complexity in our experiments we tested long-term dependencies as part of this new experiment , following the lead of the literature [ 1-3 ] . As shown in our Appendix , we found that even in the presence of extremely long-term dependencies ( up to 500 timesteps ) , our proposed SA-RNN solves the task perfectly with a very low number of FLOPs and very few state updates compared to the other data-reactive method SkipRNN . As expected , the standard GRU also solves the task while Random Skips does not . Regarding your Gradient Estimation and Slope-Annealing question : In our experiments , we used the straight-through estimator to be comparable to the literature , including [ 3 ] and [ 4 ] . Plus , we were pleased to have achieved our empirically-good results with these basic settings . However , we agree that this is an interesting question , as it is unlikely that the same estimator is the absolute best for all possible tasks . Thus , there is potentially room for further tuning by designing update pattern-specific gradient estimation . For slope-annealing we used the parameters and setting as described in [ 4 ] , gradually increasing the slope of the hard sigma function as the model trains , starting at slope $ \\alpha=1 $ and increasing according to the schedule $ a = \\min ( 5 , 1+0.04 * N_ { epoch } ) $ . We have added information about both of these settings to our experimental description in our paper to assure full reproducibility . [ 1 ] Henaff , M. , Szlam , A. , LeCun , Y . \u201c Recurrent Orthogonal Networks and Long-Memory Tasks \u201d , ICML 2015 . [ 2 ] Neil , D. , Pfeiffer , M. , Liu , S.-C. , \u201c Phased LSTM : Accelerating Recurrent Network Training for Long or Event-based Sequences \u201d , NeurIPS 2016 . [ 3 ] Campos , V. , Jou , B. , Giro-i-Nieto , X. , Torres , J. , Chang , S.-F. \u201c SkipRNN : Learning to Skip State Updates in Recurrent Neural Networks \u201d , ICLR 2018 . [ 4 ] Chung , J. , Ahn , S. , Bengio , Y . \u201c Hierarchical Multiscale Recurrent Neural Networks \u201d , ICLR 2017 ."}, {"review_id": "SkeP3yBFDS-1", "review_text": "This paper attempts to reduce computation in recurrent neural networks. Instead of artificially determining the update pattern for updating the states, the authors propose SA-RNN to predict discrete update patterns automatically through optimization driven entirely by the input data. Experiments on publicly-available datasets show that the proposed method has competitive performance with even fewer updates. Pros: Overall, I think the idea of this paper is clear and the whole paper is easy to follow. The experiments clearly show the advantage of the proposed method claimed by the authors. Cons: 1. Some expressions need to be improved. For example, in \u201cThis way, representations can be learned while solving a sequential learning task while minimizing the number of updates, subsequently reducing compute time.\u201d two \u201cwhile\u201ds are not elegant and there should be an \u201cIn\u201d before \u201cthis way\u201d. In \u201cWe augment an RNN with an update coordinator that adaptively controls the coordinate directions in which to update the hidden state on the fly\u201d, the usage of \u201cin which to\u201d is not right. I suggest the authors to thoroughly proofread the whole paper and improve the presentation. 2. Since this paper focuses on the efficiency of RNN, I suggest the authors could provide the time complexity comparisons. Merely the comparisons on skip of neurons cannot show the advantage on the efficiency. ", "rating": "6: Weak Accept", "reply_text": "We thank you for your time and effort in reviewing our work and your positive response to our proposed method and experimental results , especially given your expertise in the area . Concerning your suggestions to improve the presentation itself , we have undertaken a careful round of proof-reading to improve the readability of the manuscript . In addition , we had a colleague in the English department provide additional editing suggestions . We have now uploaded a new version of the paper addressing both your specific edits as well as this general round of proof-reading . We invite you to take a look at the revised presentation . Timing comparisons : Metrics such as wall-clock time greatly depend on factors outside the model such as implementation strategy , machine learning framework , and hardware specifics . To target the methodological differences between our compared methods , we compute and report the FLOPs instead . This is independent of hardware and implementation . Instead , it directly compares the computational requirements of the update-mechanisms , as described in [ 1 ] for a fairer comparison . [ 1 ] Campos et . al , \u201c SkipRNN : Learning to Skip State Updates in Recurrent Neural Networks \u201d , ICLR 2018 ."}, {"review_id": "SkeP3yBFDS-2", "review_text": "A main problem with RNN is to update all hidden dimensions in each time step. The authors proposed selective-activation RNN (SA-RNN), which modifies each state of RNN by adding an update coordinator which is modeled as a lightweight neural network. The coordinator, based on the incoming data, makes a discrete decision to update or not update each individual hidden dimension. A multi-objective optimization problem is defined to both solving a sequential learning task and minimizing the number of updates in each time step. The authors evaluated their networks on three public benchmark datasets and achieved good results compared to the state-of-the-art ones. The papers is well-written. The idea proposed in this paper is interesting and it is presented very well. There is also an extensive evaluation. ", "rating": "6: Weak Accept", "reply_text": "We greatly appreciate your positive feedback on our method , presentation , and experimental results , especially given your expertise in the area ."}], "0": {"review_id": "SkeP3yBFDS-0", "review_text": "Summary: This paper proposes selective activation RNN (SA-RNN), by using an update coordinator to determine which subset of the RNN\u2019s hidden state dimensions should be updated at a given timestep. The proposed loss term is then a sum of the original objective (e.g. classification) and a weighted sum of the probability that each dimension will be updated for each timestep. The method is evaluated on 3 time series datasets: Seizures, TwitterBuzz, Yahoo. Decision: Weak Reject. Although the authors tackle a challenging problem, their empirical results are lacking to provably demonstrate that their approach outperforms existing baselines. Supporting Arguments/Feedback: The authors compare SA-RNN to 5 baselines: random updates, clockwork RNN, phased LSTM, Skip RNN, and VC-GRU. Although I appreciated the authors\u2019 comparison across the suite of methods with respect to various metrics (e.g. # FLOPS, proportion of neurons that weren\u2019t updated, etc.), the experiments were conducted on datasets that were relatively simple. For example, in prior work, the empirical evaluations were on much larger-scale datasets such as Wikipedia [Shen et. al 2019], real clinical data sources [Liu et. al 2018], and Charades videos [Campos et. al 2018], among others. I would be very interested to see how this training procedure fairs when evaluated on much more complex tasks, and would make the results about computational speedups at train/test time much more convincing. Questions: - I\u2019m curious if you tried different types of gradient estimators to get around the non-differentiability rather than the straight-through estimator. Also how was the slope-annealing conducted (e.g. annealing schedule)? ", "rating": "6: Weak Accept", "reply_text": "Thank you very much for your constructive review . Per your suggestion , we have run further experiments on more complicated data that we hope will convince you of both the merit of our proposed method along with this line of research with respect to previous approaches . We revised the paper , adding a new section to the beginning of the appendix that describes the \u201c Adding \u201d task , which asks a network to learn to sum two values in a long sequence of sampled values given a mask indicating the indices to be summed , along with our results . We invite you to take a look at the new section but we highlight our main findings as follows : To add a new perspective on complexity in our experiments we tested long-term dependencies as part of this new experiment , following the lead of the literature [ 1-3 ] . As shown in our Appendix , we found that even in the presence of extremely long-term dependencies ( up to 500 timesteps ) , our proposed SA-RNN solves the task perfectly with a very low number of FLOPs and very few state updates compared to the other data-reactive method SkipRNN . As expected , the standard GRU also solves the task while Random Skips does not . Regarding your Gradient Estimation and Slope-Annealing question : In our experiments , we used the straight-through estimator to be comparable to the literature , including [ 3 ] and [ 4 ] . Plus , we were pleased to have achieved our empirically-good results with these basic settings . However , we agree that this is an interesting question , as it is unlikely that the same estimator is the absolute best for all possible tasks . Thus , there is potentially room for further tuning by designing update pattern-specific gradient estimation . For slope-annealing we used the parameters and setting as described in [ 4 ] , gradually increasing the slope of the hard sigma function as the model trains , starting at slope $ \\alpha=1 $ and increasing according to the schedule $ a = \\min ( 5 , 1+0.04 * N_ { epoch } ) $ . We have added information about both of these settings to our experimental description in our paper to assure full reproducibility . [ 1 ] Henaff , M. , Szlam , A. , LeCun , Y . \u201c Recurrent Orthogonal Networks and Long-Memory Tasks \u201d , ICML 2015 . [ 2 ] Neil , D. , Pfeiffer , M. , Liu , S.-C. , \u201c Phased LSTM : Accelerating Recurrent Network Training for Long or Event-based Sequences \u201d , NeurIPS 2016 . [ 3 ] Campos , V. , Jou , B. , Giro-i-Nieto , X. , Torres , J. , Chang , S.-F. \u201c SkipRNN : Learning to Skip State Updates in Recurrent Neural Networks \u201d , ICLR 2018 . [ 4 ] Chung , J. , Ahn , S. , Bengio , Y . \u201c Hierarchical Multiscale Recurrent Neural Networks \u201d , ICLR 2017 ."}, "1": {"review_id": "SkeP3yBFDS-1", "review_text": "This paper attempts to reduce computation in recurrent neural networks. Instead of artificially determining the update pattern for updating the states, the authors propose SA-RNN to predict discrete update patterns automatically through optimization driven entirely by the input data. Experiments on publicly-available datasets show that the proposed method has competitive performance with even fewer updates. Pros: Overall, I think the idea of this paper is clear and the whole paper is easy to follow. The experiments clearly show the advantage of the proposed method claimed by the authors. Cons: 1. Some expressions need to be improved. For example, in \u201cThis way, representations can be learned while solving a sequential learning task while minimizing the number of updates, subsequently reducing compute time.\u201d two \u201cwhile\u201ds are not elegant and there should be an \u201cIn\u201d before \u201cthis way\u201d. In \u201cWe augment an RNN with an update coordinator that adaptively controls the coordinate directions in which to update the hidden state on the fly\u201d, the usage of \u201cin which to\u201d is not right. I suggest the authors to thoroughly proofread the whole paper and improve the presentation. 2. Since this paper focuses on the efficiency of RNN, I suggest the authors could provide the time complexity comparisons. Merely the comparisons on skip of neurons cannot show the advantage on the efficiency. ", "rating": "6: Weak Accept", "reply_text": "We thank you for your time and effort in reviewing our work and your positive response to our proposed method and experimental results , especially given your expertise in the area . Concerning your suggestions to improve the presentation itself , we have undertaken a careful round of proof-reading to improve the readability of the manuscript . In addition , we had a colleague in the English department provide additional editing suggestions . We have now uploaded a new version of the paper addressing both your specific edits as well as this general round of proof-reading . We invite you to take a look at the revised presentation . Timing comparisons : Metrics such as wall-clock time greatly depend on factors outside the model such as implementation strategy , machine learning framework , and hardware specifics . To target the methodological differences between our compared methods , we compute and report the FLOPs instead . This is independent of hardware and implementation . Instead , it directly compares the computational requirements of the update-mechanisms , as described in [ 1 ] for a fairer comparison . [ 1 ] Campos et . al , \u201c SkipRNN : Learning to Skip State Updates in Recurrent Neural Networks \u201d , ICLR 2018 ."}, "2": {"review_id": "SkeP3yBFDS-2", "review_text": "A main problem with RNN is to update all hidden dimensions in each time step. The authors proposed selective-activation RNN (SA-RNN), which modifies each state of RNN by adding an update coordinator which is modeled as a lightweight neural network. The coordinator, based on the incoming data, makes a discrete decision to update or not update each individual hidden dimension. A multi-objective optimization problem is defined to both solving a sequential learning task and minimizing the number of updates in each time step. The authors evaluated their networks on three public benchmark datasets and achieved good results compared to the state-of-the-art ones. The papers is well-written. The idea proposed in this paper is interesting and it is presented very well. There is also an extensive evaluation. ", "rating": "6: Weak Accept", "reply_text": "We greatly appreciate your positive feedback on our method , presentation , and experimental results , especially given your expertise in the area ."}}