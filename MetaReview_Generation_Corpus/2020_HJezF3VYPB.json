{"year": "2020", "forum": "HJezF3VYPB", "title": "Federated Adversarial Domain Adaptation", "decision": "Accept (Poster)", "meta_review": "This paper studies an interesting new problem, federated domain adaptation, and proposes an approach based on dynamic attention, federated adversarial alignment, and representation disentanglement.\n\nReviewers generally agree that the paper contributes a novel approach to an interesting problem with theoretical guarantees and empirical justification. While many professional concerns were raised by the reviewers, the authors managed to perform an effective rebuttal with a major revision, which addressed the concerns convincingly. AC believes that the updated version is acceptable.\n\nHence I recommend acceptance.", "reviews": [{"review_id": "HJezF3VYPB-0", "review_text": "This paper introduces an unsupervised federated domain adaptation (UFDA) problem and proposes a new model called Federated Adversarial Domain Adaptation (FADA) to transfer the knowledge learned from distributed source domains to an unlabeled target domain. This paper uses a dynamic attention mechanism by leveraging the gap statistics to transfer distributed source knowledge. This paper also proposes a method to disentangle the domain-invariant features from domain-specific features, using adversarial training. Moreover, a theoretical generalization bound for UFDA is derived. An extensive empirical evaluation is performed on UFDA vision and linguistic benchmarks. This paper should be rejected because the total pipeline seems ad-hoc except for optimizing the weight of the source domain in the attention mechanism. Although the derivation of generalization bound for FDA in Sec.3 is excellent, it only demonstrates the importance of the weight $\\alpha$. This result is trivial if we assume to have the same source domain as the target and utterly unrelated source domain to the target domain. It seems that proving why minimizing the gap statistics contributes to FADA is more essential in the dynamic attention mechanism. Because representation disentanglement has no relation with the derived theory, it would be better to clarify whether this method is original or not. In the UFDA setting, the reviewer has doubts about whether it is realistic that the source node has a rich labeled data assuming our smartphones. Also, the assumption that the system cannot access the source data but must access all source feature seems a significant limitation in terms of privacy issues and communication cost between the target node and the source nodes. It is unclear what is the final target classifier. If the target can access the teaching signal (e.g., labels or tags) in the source domains, it would be better to mention whether this situation violates the assumption the authors raised or not. Minor comments 1) What is T(p, q, \\theta) in the section of Representation Disentanglement? 2) What is C_s in eq.6? C_{s_i}? 3) In Fig.3, it is not proper to discuss the size of intra-class variance by just looking at the figures because the t-SNE is a non-linear mapping. It is better to show quantitative scores, such as the value of the Fisher criterion.", "rating": "6: Weak Accept", "reply_text": "[ Rebuttal 2/2 ] 5 . Whether it is realistic that the source node has a rich labeled data assuming the smartphone . -We are not assuming that our framework works narrowly on the smartphone network . In fact , our model works on data generated by networks of mobile , IoT devices , or other networks in which data privacy is important and domain shift is significant . -Federated learning aims to accumulate the gradient from different nodes to train a large model . In our case , we are aiming to train a good target model based on the gradient from multiple source domains . When the source node has no rich labeled data , our model can accumulate the gradient from each source domain and train a good model . 6.The assumption that the system must access all source features seems a significant limitation in terms of privacy issue and communication cost . -As shown in Figure 1 ( a ) , the model and the data are locally stored . The global discriminator only gets access to the output vectors . Since the model of each domain is not shared , it is infeasible to reconstruct the data for a specific domain using the output vectors of that domain . Even though the feature space is aligned , it is still impractical to recover the original data without the parameters of the feature extractor . -In terms of the communication cost , the source domains need to send a small-size feature vector for each data ( 4kb for 1024-dimensional float feature vectors ) . In addition , the communication cost for transmitting the feature vector is smaller than that for transmitting the gradient of neural networks . Transmitting the gradient of neural networks is a basic setting for federated learning [ 6 ] . 7.It is unclear what is the final target classifier . -The target domain is updated with the gradients from classifiers trained on the source domain since there is no label information in the target domain . ( We have updated the Algorithm 1 and adversarial feature alignment section to make this clear.Refer to the red text in the revision paper ) 8 . If the target can access the teaching signal ( e.g.labels or tags ) in the source domain , it would be better to mention whether this situation violates the assumption the authors raised or not . -The target can not get access to labels or tags from the source domain . The target domain can get access to the gradients from the source domain without violating the federated learning assumption . Minor Comments 1 . What is $ T ( p , q , \\theta ) $ ? $ T ( p , q , \\theta ) $ is the neural network parameteralized by $ \\theta $ to estimate the mutual information between $ \\mathcal { P } $ and $ \\mathcal { Q } $ , we refer the reviewer to `` mutual information nueral network '' [ 7 ] for more details . 2.What is $ C_s $ in Eq.6 ? The $ C_s $ is the class identifier , which helps to extract the domain-specific features . We have clarified and revised the notations in our revision paper . We also updated Figure 1 and Algorithm 1 to better illustrate our approach . [ 1 ] Federated Machine Learning : Concept and Applications . Qiang Yang et al.ACM Trans . Intell.Syst.Technol.2019 [ 2 ] Moment Matching for Multi-Source Domain Adaptation . Peng et al.ICCV 2019 . [ 3 ] Towards a Definition of Disentangled Representations . Higgins , et al.DeepMind 2018 . [ 4 ] Estimating the number of clusters in a dataset via the gap statistic . Journal of the Royal Statistical Society , 2001 . [ 5 ] Representation learning : A review and new perspectives . Bengio Yoshua , PAMI 2013 [ 6 ] Federated Learning : Strategies for Improving Communication Efficiency . Jakub Kone\u010dn\u00fd , NIPS Workshop 2016 . [ 7 ] MINE : Mutual Information Neural Estimation . Mohamed Ishmael Belghazi , ICML 2018 ."}, {"review_id": "HJezF3VYPB-1", "review_text": "The paper proposed and studied the unsupervised federated domain adaption problem, which aims to transfer knowledge from source nodes to a new node with different data distribution. To address the problem, a federated adversarial domain adaption (FADA) algorithm is introduced in the paper. The key idea of the algorithm is to update the target model by aggregating the gradients from source nodes, and also leverage adversarial adaption techniques to reduce the discrepancy between source features and target features. Overall, the problem studied in the paper is interesting, theoretical analysis on the error bound is provided in the paper, and the effectiveness of the proposed method has been validated in various datasets. Although the technical contributions of the paper are solid, I still have several concerns about it. 1. The proposed algorithm is not described very clearly in section 4. According to the paper, DI is used to identify the domain from the output of Gi and Gt and align the features from those domains, then how is it related to the disentanglement in Eq 6. Also in Eq 6, symbol C_s was not introduced in the previous context, which makes it confusing to understand this objective. 2. It would be better if the author(s) can provide some complexity analysis of the proposed algorithm. 3. The paper still contains some typos and unresolved reference issues. ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the overall positive feedback on our paper . We have updated the details of the algorithm in section 4 . 1.The proposed algorithm is not described very clearly in Section 4 . Thank you for pointing this out . We admit that the notations in the Federated Adversarial Alignment and Representation Disentanglement part are unclear , which has also been mentioned by Reviewer # 1 . We want to mention the following response is the same with the response to Reviewer # 1 , 2nd concerns . We have revised the paper as follows to make it more clear ( refer to the revision paper ) : i ) we standardized the notation occurred in the paper and made a table to explain each notation in the supplementary material ( Table 6 ) . ii ) we update Figure1 ( b ) and Algorithm 1 to make the notations consistent and clear . iii ) we edit Equation 4~7 to clarify which parameters will the loss optimizes on . iv ) we have added high-level intuition to our paper to help readers better understand the method section . -In summary , we clarify the notation in the Federated Adversarial Alignment and Representation Disentanglement as follows : $ DI $ | domain identifier | align the domain pair ( $ G_i $ , $ G_t $ ) $ D $ | disentangler | disentangle the feature to domain-invariant feature $ f_ { di } $ and domain-specific feature $ f_ { ds } $ . $ C $ | classifier | predict the labels for input features $ CI $ | class identify | first trained with task loss , then train with the adversarial loss to extract domain-specific features . $ G_i $ |feature generator | extract features for $ \\mathcal { D } _ { S_i } $ $ G_t $ | feature generator | extract features for $ { \\mathcal { D } } _t $ $ M $ | MI estimator | estimate the mutual information between $ f_ { di } $ and $ f_ { ds } $ . -Equation 4 has been revised to : $ $ \\underset { \\Theta^ { DI_i } } { \\mathcal { L } _ { { adv } _ { DI_i } } } ( \\mathbf { X } ^ { S_i } , \\mathbf { X } ^T , G_i , G_t ) =- \\mathbb { E } _ { \\mathbf { x } ^ { s_i } \\sim \\mathbf { X } ^ { s_i } } \\left [ \\log DI_i ( G_i ( \\mathbf { x } ^ { s_i } ) ) ] -\\mathbb { E } _ { \\mathbf { x } ^t \\sim \\mathbf { X } ^t } [ \\log ( 1 - DI_i ( G_t ( \\mathbf { x } ^ { t } ) ) ) \\right ] $ $ The $ \\mathcal { L } _ { { adv } _ { DI } } $ will update the parameter of $ DI $ , i.e. $ \\Theta^ { DI } $ . -Equation 5 has been revised to : $ $ \\underset { \\Theta^ { G_i } , \\Theta^ { G_t } } { \\mathcal { L } _ { { adv } _G } } ( \\mathbf { X } ^ { S_i } , \\mathbf { X } ^T , DI_i ) = - \\mathbb { E } _ { \\mathbf { x } ^ { s_i } \\sim \\mathbf { X } ^ { s_i } } [ \\log DI_i ( G_ { i } ( \\mathbf { x } ^ { s_i } ) ) ] - \\mathbb { E } _ { \\mathbf { x } ^t \\sim \\mathbf { X } ^t } [ \\log DI_i ( G_t ( \\mathbf { x } ^t ) ) ] $ $ The $ \\mathcal { L } _ { { adv } _G } $ will update the parameter of $ G_i $ and $ G_t $ , i.e. $ \\Theta^ { G_i } $ and $ \\Theta^ { G_t } $ . These two objectives are to train the domain classifier $ DI $ and ( $ G_i $ , $ G_t $ ) in an adversarial manner : we first train $ DI $ to identify which domain are the features come from , then we train the generator ( $ G_i $ , $ G_t $ ) to confuse the $ DI $ . The aim is to align the distributions of the features generated by ( $ G_i $ , $ G_t $ ) . -Equation 6 has been revised to : $ $ \\underset { \\Theta^ { G_i } , \\Theta^ { D_i } , \\Theta^ { C_i } , \\Theta^ { CI_i } } { \\mathcal { L } _ { cross-entropy } } = -\\mathbb { E } _ { ( \\mathbf { x } ^ { s_i } , \\mathbf { y } ^ { s_i } ) \\sim\\widehat { \\mathcal { D } } _ { s_i } } \\sum_ { k=1 } ^ { K } 1 [ k=\\mathbf { y } ^ { s_i } ] log ( C_i ( f_ { di } ) ) -\\mathbb { E } _ { ( \\mathbf { x } ^ { s_i } , \\mathbf { y } ^ { s_i } ) \\sim\\widehat { \\mathcal { D } } _ { s_i } } \\sum_ { k=1 } ^ { K } 1 [ k=\\mathbf { y } ^ { s_i } ] log ( CI_i ( f_ { ds } ) ) $ $ The $ \\mathcal { L } _ { cross-entropy } $ is minimized over the parameters of the feature generator $ G_i $ , the disentangler $ D_i $ , the classifier $ C $ , and the class identifier $ CI $ , i.e. $ \\Theta^ { G_i } $ , $ \\Theta^ { D_i } $ , $ \\Theta^ { C } $ , $ \\Theta^ { CI } $ . -Equation 7 has been revised to : $ $ \\underset { \\Theta^ { D_i } , \\Theta^ { G_i } } { \\mathcal { L } _ { ent } } = - \\frac { 1 } { N_ { s_i } } \\sum_ { j=1 } ^ { N_ { s_i } } \\log CI_i ( f^j_ { ds } ) = - \\frac { 1 } { N_ { s_i } } \\sum_ { j=1 } ^ { N_ { s_i } } \\log CI_i ( D_i ( G_i ( \\mathbf { x } ^ { s_i } ) ) ) $ $ The $ { \\mathcal { L } _ { ent } } $ is minimized over the parameters of the feature generator $ G_i $ , the disentangler $ D_i $ , i.e. $ \\Theta^ { G_i } $ , $ \\Theta^ { D_i } $ . Feature disentanglement facilitates the knowledge transfer by extracting $ f_ { di } $ and dispelling $ f_ { ds } $ 2 . Complexity analysis of the proposed algorithm . -From Algorithm 1 , we observe that the four processes , i.e.feature extraction , domain alignment , domain disentangle , and mutual information minimization are linear with N , where N is the number of source domains . Thus , the time complexity of operations on deep neural networks is O ( N ) . -The most time-consuming part of the dynamic attention model is the KMeans algorithm . The average complexity is given by $ O ( knT ) $ , where $ k $ is the number of clusters , $ n $ is the number of samples from the target domain , and $ T $ is the number of iteration for the KMeans algorithm . Take digit experiment as an example , k=10 , n=128 , T=1000 , it takes 0.21 second . 3.Typos and unresolved reference issues We have revised the typos unresolved reference in the updated pdf submission ."}, {"review_id": "HJezF3VYPB-2", "review_text": "The authors present a novel algorithm for dealing with domain adaptation in the setting of federated learning (classification, specifically). That is, they tackle the issue of learning a model on a new domain when access to the data points used in training the source models is not possible due to privacy constraints. The approach uses the gradients of the source models, reweighed to account for the differing shifts between the different sources and the target domain, to fit the model on the target domain. The authors motivate their approach by providing a novel bound on the generalization error of transfer learning when the hypothesis function used on the target domain is a convex combination of hypotheses fitted on multiple source domains. This bound shows that the weighted sum of divergences in the symmetric difference hypothesis space controls the generalization error, so the authors aim at deriving feature representations and using aggregation weights that ensure this weighted sum is small. The authors use a novel dynamic attention model to get the aggregation weights: they cluster the features in the target domain, and measure how much the intra-cluster variation decreases when information from a given source domain is incorporated. The aggregation weights for the model updates on the target domain are then weighed using a softmax transform of these contribution weights. The motivation up through and including section 3 is clear, the theoretical results are presented clearly, but the model details in section 4 are unclear: - In the dynamic attention mechanism, how does one a priori choose the number of clusters in computing the gap statistics, and what is the impact? - the notation in the federated adversarial alignment section is unclear: what *exactly* are the model coefficients Theta that are being updated? - the statement \"optimize following objective\" is made several times. this is ambiguous, and should be corrected to \"miminize\" following objective. - the representation disentanglement process is intricate, and only vaguely addressed. how does one fit the neural net and use (8)? where is the l2 reconstruction loss balanced with the mutual information? the vagueness of this section means Algorithm 1 is not well-specified. The experiments are reasonable, and compare to baseline domain adaptation methods. The problem considered is of interest, and the approach is novel and interesting. However, the algorithm is not described in sufficient detail. After reading the paper, and spending considerable time rereading section 4, I still do not understand how Algorithm 1 is implemented in practice. For that reason I lean towards reject. I will update my score if the authors clarify the details of Algorithm 1. Comments: - the symmetric difference hypothesis space is incorrectly called the HdeltaH divergence in section 3 ", "rating": "3: Weak Reject", "reply_text": "[ Rebuttal Part 2/2 ] The $ { \\mathcal { L } _ { ent } } $ is minimized over the parameters of the feature generator $ G_i $ , the disentangler $ D_i $ , i.e. $ \\Theta^ { G_i } $ , $ \\Theta^ { D_i } $ . Feature disentanglement facilitates the knowledge transfer by extracting $ f_ { di } $ and dispelling $ f_ { ds } $ 3 . `` Optimize following objective '' should be `` minimizing following objective '' . We thank the reviewer for pointing this out . We have revised it in the revision paper . 4.The representation disentanglement process is intricate and only vaguely addressed . How to fit the neural net and use ( 8 ) ? Where is l2 reconstruction loss balanced with the mutual information ? -We have revised the representation disentanglement section ( refer to the red text in our paper ) -To fit our model to the neural network , one should implement each module in our paper and connect them following Figure 1 ( b ) . We have released the hyper-parameters of each module in the supplemental materials . To better illustrate this , we have revised all the equations in our paper with the detailed module names . ( Also , we have released our code in the submission ) . -To use Equation ( 8 ) , one should implement the $ T ( p , q , \\Theta ) $ as a neural network . We adopt the implementation of the paper `` Mutual Information Neural Estimator '' in our code . -The balance of the l2 reconstruction and mutual information can be achieved by adjusting the hyper-parameters of the l2 loss and mutual information loss . We revised the paper to better illustrate this . 5.Comments : symmetric difference space is incorrectly called $ \\mathcal { H } \\Delta\\mathcal { H } $ . We have revised this typo in the revision paper . Thanks again for pointing this out !"}], "0": {"review_id": "HJezF3VYPB-0", "review_text": "This paper introduces an unsupervised federated domain adaptation (UFDA) problem and proposes a new model called Federated Adversarial Domain Adaptation (FADA) to transfer the knowledge learned from distributed source domains to an unlabeled target domain. This paper uses a dynamic attention mechanism by leveraging the gap statistics to transfer distributed source knowledge. This paper also proposes a method to disentangle the domain-invariant features from domain-specific features, using adversarial training. Moreover, a theoretical generalization bound for UFDA is derived. An extensive empirical evaluation is performed on UFDA vision and linguistic benchmarks. This paper should be rejected because the total pipeline seems ad-hoc except for optimizing the weight of the source domain in the attention mechanism. Although the derivation of generalization bound for FDA in Sec.3 is excellent, it only demonstrates the importance of the weight $\\alpha$. This result is trivial if we assume to have the same source domain as the target and utterly unrelated source domain to the target domain. It seems that proving why minimizing the gap statistics contributes to FADA is more essential in the dynamic attention mechanism. Because representation disentanglement has no relation with the derived theory, it would be better to clarify whether this method is original or not. In the UFDA setting, the reviewer has doubts about whether it is realistic that the source node has a rich labeled data assuming our smartphones. Also, the assumption that the system cannot access the source data but must access all source feature seems a significant limitation in terms of privacy issues and communication cost between the target node and the source nodes. It is unclear what is the final target classifier. If the target can access the teaching signal (e.g., labels or tags) in the source domains, it would be better to mention whether this situation violates the assumption the authors raised or not. Minor comments 1) What is T(p, q, \\theta) in the section of Representation Disentanglement? 2) What is C_s in eq.6? C_{s_i}? 3) In Fig.3, it is not proper to discuss the size of intra-class variance by just looking at the figures because the t-SNE is a non-linear mapping. It is better to show quantitative scores, such as the value of the Fisher criterion.", "rating": "6: Weak Accept", "reply_text": "[ Rebuttal 2/2 ] 5 . Whether it is realistic that the source node has a rich labeled data assuming the smartphone . -We are not assuming that our framework works narrowly on the smartphone network . In fact , our model works on data generated by networks of mobile , IoT devices , or other networks in which data privacy is important and domain shift is significant . -Federated learning aims to accumulate the gradient from different nodes to train a large model . In our case , we are aiming to train a good target model based on the gradient from multiple source domains . When the source node has no rich labeled data , our model can accumulate the gradient from each source domain and train a good model . 6.The assumption that the system must access all source features seems a significant limitation in terms of privacy issue and communication cost . -As shown in Figure 1 ( a ) , the model and the data are locally stored . The global discriminator only gets access to the output vectors . Since the model of each domain is not shared , it is infeasible to reconstruct the data for a specific domain using the output vectors of that domain . Even though the feature space is aligned , it is still impractical to recover the original data without the parameters of the feature extractor . -In terms of the communication cost , the source domains need to send a small-size feature vector for each data ( 4kb for 1024-dimensional float feature vectors ) . In addition , the communication cost for transmitting the feature vector is smaller than that for transmitting the gradient of neural networks . Transmitting the gradient of neural networks is a basic setting for federated learning [ 6 ] . 7.It is unclear what is the final target classifier . -The target domain is updated with the gradients from classifiers trained on the source domain since there is no label information in the target domain . ( We have updated the Algorithm 1 and adversarial feature alignment section to make this clear.Refer to the red text in the revision paper ) 8 . If the target can access the teaching signal ( e.g.labels or tags ) in the source domain , it would be better to mention whether this situation violates the assumption the authors raised or not . -The target can not get access to labels or tags from the source domain . The target domain can get access to the gradients from the source domain without violating the federated learning assumption . Minor Comments 1 . What is $ T ( p , q , \\theta ) $ ? $ T ( p , q , \\theta ) $ is the neural network parameteralized by $ \\theta $ to estimate the mutual information between $ \\mathcal { P } $ and $ \\mathcal { Q } $ , we refer the reviewer to `` mutual information nueral network '' [ 7 ] for more details . 2.What is $ C_s $ in Eq.6 ? The $ C_s $ is the class identifier , which helps to extract the domain-specific features . We have clarified and revised the notations in our revision paper . We also updated Figure 1 and Algorithm 1 to better illustrate our approach . [ 1 ] Federated Machine Learning : Concept and Applications . Qiang Yang et al.ACM Trans . Intell.Syst.Technol.2019 [ 2 ] Moment Matching for Multi-Source Domain Adaptation . Peng et al.ICCV 2019 . [ 3 ] Towards a Definition of Disentangled Representations . Higgins , et al.DeepMind 2018 . [ 4 ] Estimating the number of clusters in a dataset via the gap statistic . Journal of the Royal Statistical Society , 2001 . [ 5 ] Representation learning : A review and new perspectives . Bengio Yoshua , PAMI 2013 [ 6 ] Federated Learning : Strategies for Improving Communication Efficiency . Jakub Kone\u010dn\u00fd , NIPS Workshop 2016 . [ 7 ] MINE : Mutual Information Neural Estimation . Mohamed Ishmael Belghazi , ICML 2018 ."}, "1": {"review_id": "HJezF3VYPB-1", "review_text": "The paper proposed and studied the unsupervised federated domain adaption problem, which aims to transfer knowledge from source nodes to a new node with different data distribution. To address the problem, a federated adversarial domain adaption (FADA) algorithm is introduced in the paper. The key idea of the algorithm is to update the target model by aggregating the gradients from source nodes, and also leverage adversarial adaption techniques to reduce the discrepancy between source features and target features. Overall, the problem studied in the paper is interesting, theoretical analysis on the error bound is provided in the paper, and the effectiveness of the proposed method has been validated in various datasets. Although the technical contributions of the paper are solid, I still have several concerns about it. 1. The proposed algorithm is not described very clearly in section 4. According to the paper, DI is used to identify the domain from the output of Gi and Gt and align the features from those domains, then how is it related to the disentanglement in Eq 6. Also in Eq 6, symbol C_s was not introduced in the previous context, which makes it confusing to understand this objective. 2. It would be better if the author(s) can provide some complexity analysis of the proposed algorithm. 3. The paper still contains some typos and unresolved reference issues. ", "rating": "6: Weak Accept", "reply_text": "We thank the reviewer for the overall positive feedback on our paper . We have updated the details of the algorithm in section 4 . 1.The proposed algorithm is not described very clearly in Section 4 . Thank you for pointing this out . We admit that the notations in the Federated Adversarial Alignment and Representation Disentanglement part are unclear , which has also been mentioned by Reviewer # 1 . We want to mention the following response is the same with the response to Reviewer # 1 , 2nd concerns . We have revised the paper as follows to make it more clear ( refer to the revision paper ) : i ) we standardized the notation occurred in the paper and made a table to explain each notation in the supplementary material ( Table 6 ) . ii ) we update Figure1 ( b ) and Algorithm 1 to make the notations consistent and clear . iii ) we edit Equation 4~7 to clarify which parameters will the loss optimizes on . iv ) we have added high-level intuition to our paper to help readers better understand the method section . -In summary , we clarify the notation in the Federated Adversarial Alignment and Representation Disentanglement as follows : $ DI $ | domain identifier | align the domain pair ( $ G_i $ , $ G_t $ ) $ D $ | disentangler | disentangle the feature to domain-invariant feature $ f_ { di } $ and domain-specific feature $ f_ { ds } $ . $ C $ | classifier | predict the labels for input features $ CI $ | class identify | first trained with task loss , then train with the adversarial loss to extract domain-specific features . $ G_i $ |feature generator | extract features for $ \\mathcal { D } _ { S_i } $ $ G_t $ | feature generator | extract features for $ { \\mathcal { D } } _t $ $ M $ | MI estimator | estimate the mutual information between $ f_ { di } $ and $ f_ { ds } $ . -Equation 4 has been revised to : $ $ \\underset { \\Theta^ { DI_i } } { \\mathcal { L } _ { { adv } _ { DI_i } } } ( \\mathbf { X } ^ { S_i } , \\mathbf { X } ^T , G_i , G_t ) =- \\mathbb { E } _ { \\mathbf { x } ^ { s_i } \\sim \\mathbf { X } ^ { s_i } } \\left [ \\log DI_i ( G_i ( \\mathbf { x } ^ { s_i } ) ) ] -\\mathbb { E } _ { \\mathbf { x } ^t \\sim \\mathbf { X } ^t } [ \\log ( 1 - DI_i ( G_t ( \\mathbf { x } ^ { t } ) ) ) \\right ] $ $ The $ \\mathcal { L } _ { { adv } _ { DI } } $ will update the parameter of $ DI $ , i.e. $ \\Theta^ { DI } $ . -Equation 5 has been revised to : $ $ \\underset { \\Theta^ { G_i } , \\Theta^ { G_t } } { \\mathcal { L } _ { { adv } _G } } ( \\mathbf { X } ^ { S_i } , \\mathbf { X } ^T , DI_i ) = - \\mathbb { E } _ { \\mathbf { x } ^ { s_i } \\sim \\mathbf { X } ^ { s_i } } [ \\log DI_i ( G_ { i } ( \\mathbf { x } ^ { s_i } ) ) ] - \\mathbb { E } _ { \\mathbf { x } ^t \\sim \\mathbf { X } ^t } [ \\log DI_i ( G_t ( \\mathbf { x } ^t ) ) ] $ $ The $ \\mathcal { L } _ { { adv } _G } $ will update the parameter of $ G_i $ and $ G_t $ , i.e. $ \\Theta^ { G_i } $ and $ \\Theta^ { G_t } $ . These two objectives are to train the domain classifier $ DI $ and ( $ G_i $ , $ G_t $ ) in an adversarial manner : we first train $ DI $ to identify which domain are the features come from , then we train the generator ( $ G_i $ , $ G_t $ ) to confuse the $ DI $ . The aim is to align the distributions of the features generated by ( $ G_i $ , $ G_t $ ) . -Equation 6 has been revised to : $ $ \\underset { \\Theta^ { G_i } , \\Theta^ { D_i } , \\Theta^ { C_i } , \\Theta^ { CI_i } } { \\mathcal { L } _ { cross-entropy } } = -\\mathbb { E } _ { ( \\mathbf { x } ^ { s_i } , \\mathbf { y } ^ { s_i } ) \\sim\\widehat { \\mathcal { D } } _ { s_i } } \\sum_ { k=1 } ^ { K } 1 [ k=\\mathbf { y } ^ { s_i } ] log ( C_i ( f_ { di } ) ) -\\mathbb { E } _ { ( \\mathbf { x } ^ { s_i } , \\mathbf { y } ^ { s_i } ) \\sim\\widehat { \\mathcal { D } } _ { s_i } } \\sum_ { k=1 } ^ { K } 1 [ k=\\mathbf { y } ^ { s_i } ] log ( CI_i ( f_ { ds } ) ) $ $ The $ \\mathcal { L } _ { cross-entropy } $ is minimized over the parameters of the feature generator $ G_i $ , the disentangler $ D_i $ , the classifier $ C $ , and the class identifier $ CI $ , i.e. $ \\Theta^ { G_i } $ , $ \\Theta^ { D_i } $ , $ \\Theta^ { C } $ , $ \\Theta^ { CI } $ . -Equation 7 has been revised to : $ $ \\underset { \\Theta^ { D_i } , \\Theta^ { G_i } } { \\mathcal { L } _ { ent } } = - \\frac { 1 } { N_ { s_i } } \\sum_ { j=1 } ^ { N_ { s_i } } \\log CI_i ( f^j_ { ds } ) = - \\frac { 1 } { N_ { s_i } } \\sum_ { j=1 } ^ { N_ { s_i } } \\log CI_i ( D_i ( G_i ( \\mathbf { x } ^ { s_i } ) ) ) $ $ The $ { \\mathcal { L } _ { ent } } $ is minimized over the parameters of the feature generator $ G_i $ , the disentangler $ D_i $ , i.e. $ \\Theta^ { G_i } $ , $ \\Theta^ { D_i } $ . Feature disentanglement facilitates the knowledge transfer by extracting $ f_ { di } $ and dispelling $ f_ { ds } $ 2 . Complexity analysis of the proposed algorithm . -From Algorithm 1 , we observe that the four processes , i.e.feature extraction , domain alignment , domain disentangle , and mutual information minimization are linear with N , where N is the number of source domains . Thus , the time complexity of operations on deep neural networks is O ( N ) . -The most time-consuming part of the dynamic attention model is the KMeans algorithm . The average complexity is given by $ O ( knT ) $ , where $ k $ is the number of clusters , $ n $ is the number of samples from the target domain , and $ T $ is the number of iteration for the KMeans algorithm . Take digit experiment as an example , k=10 , n=128 , T=1000 , it takes 0.21 second . 3.Typos and unresolved reference issues We have revised the typos unresolved reference in the updated pdf submission ."}, "2": {"review_id": "HJezF3VYPB-2", "review_text": "The authors present a novel algorithm for dealing with domain adaptation in the setting of federated learning (classification, specifically). That is, they tackle the issue of learning a model on a new domain when access to the data points used in training the source models is not possible due to privacy constraints. The approach uses the gradients of the source models, reweighed to account for the differing shifts between the different sources and the target domain, to fit the model on the target domain. The authors motivate their approach by providing a novel bound on the generalization error of transfer learning when the hypothesis function used on the target domain is a convex combination of hypotheses fitted on multiple source domains. This bound shows that the weighted sum of divergences in the symmetric difference hypothesis space controls the generalization error, so the authors aim at deriving feature representations and using aggregation weights that ensure this weighted sum is small. The authors use a novel dynamic attention model to get the aggregation weights: they cluster the features in the target domain, and measure how much the intra-cluster variation decreases when information from a given source domain is incorporated. The aggregation weights for the model updates on the target domain are then weighed using a softmax transform of these contribution weights. The motivation up through and including section 3 is clear, the theoretical results are presented clearly, but the model details in section 4 are unclear: - In the dynamic attention mechanism, how does one a priori choose the number of clusters in computing the gap statistics, and what is the impact? - the notation in the federated adversarial alignment section is unclear: what *exactly* are the model coefficients Theta that are being updated? - the statement \"optimize following objective\" is made several times. this is ambiguous, and should be corrected to \"miminize\" following objective. - the representation disentanglement process is intricate, and only vaguely addressed. how does one fit the neural net and use (8)? where is the l2 reconstruction loss balanced with the mutual information? the vagueness of this section means Algorithm 1 is not well-specified. The experiments are reasonable, and compare to baseline domain adaptation methods. The problem considered is of interest, and the approach is novel and interesting. However, the algorithm is not described in sufficient detail. After reading the paper, and spending considerable time rereading section 4, I still do not understand how Algorithm 1 is implemented in practice. For that reason I lean towards reject. I will update my score if the authors clarify the details of Algorithm 1. Comments: - the symmetric difference hypothesis space is incorrectly called the HdeltaH divergence in section 3 ", "rating": "3: Weak Reject", "reply_text": "[ Rebuttal Part 2/2 ] The $ { \\mathcal { L } _ { ent } } $ is minimized over the parameters of the feature generator $ G_i $ , the disentangler $ D_i $ , i.e. $ \\Theta^ { G_i } $ , $ \\Theta^ { D_i } $ . Feature disentanglement facilitates the knowledge transfer by extracting $ f_ { di } $ and dispelling $ f_ { ds } $ 3 . `` Optimize following objective '' should be `` minimizing following objective '' . We thank the reviewer for pointing this out . We have revised it in the revision paper . 4.The representation disentanglement process is intricate and only vaguely addressed . How to fit the neural net and use ( 8 ) ? Where is l2 reconstruction loss balanced with the mutual information ? -We have revised the representation disentanglement section ( refer to the red text in our paper ) -To fit our model to the neural network , one should implement each module in our paper and connect them following Figure 1 ( b ) . We have released the hyper-parameters of each module in the supplemental materials . To better illustrate this , we have revised all the equations in our paper with the detailed module names . ( Also , we have released our code in the submission ) . -To use Equation ( 8 ) , one should implement the $ T ( p , q , \\Theta ) $ as a neural network . We adopt the implementation of the paper `` Mutual Information Neural Estimator '' in our code . -The balance of the l2 reconstruction and mutual information can be achieved by adjusting the hyper-parameters of the l2 loss and mutual information loss . We revised the paper to better illustrate this . 5.Comments : symmetric difference space is incorrectly called $ \\mathcal { H } \\Delta\\mathcal { H } $ . We have revised this typo in the revision paper . Thanks again for pointing this out !"}}